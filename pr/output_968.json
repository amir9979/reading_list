'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS By a'
[{"title": "BRAVE: Broadening the visual encoding of vision-language models", "link": "https://arxiv.org/pdf/2404.07204", "details": "OF Kar, A Tonioni, P Poklukar, A Kulshrestha, A Zamir\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models (VLMs) are typically composed of a vision encoder, eg CLIP, and a language model (LM) that interprets the encoded features to solve downstream tasks. Despite remarkable progress, VLMs are subject to several \u2026"}, {"title": "Pre-training enhanced unsupervised contrastive domain adaptation for industrial equipment remaining useful life prediction", "link": "https://www.sciencedirect.com/science/article/pii/S1474034624001654", "details": "H Li, P Cao, X Wang, Y Li, B Yi, M Huang - Advanced Engineering Informatics, 2024", "abstract": "An essential task in industrial intelligence is to accurately predict the remaining useful life (RUL) of industrial equipment, and there has been tremendous progress in RUL prediction based on data-driven methods. However, these methods rely heavily \u2026"}, {"title": "Unsupervised Microscopy Video Denoising", "link": "https://arxiv.org/pdf/2404.12163", "details": "M Aiyetigbo, A Korte, E Anderson, R Chalhoub\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper, we introduce a novel unsupervised network to denoise microscopy videos featured by image sequences captured by a fixed location microscopy camera. Specifically, we propose a DeepTemporal Interpolation method, leveraging \u2026"}, {"title": "Intrinsic LoRA: A Generalist Approach for Discovering Knowledge in Generative Models", "link": "https://openreview.net/pdf%3Fid%3DxHKWN3Yi6U", "details": "X Du, N Kolkin, G Shakhnarovich, A Bhattad - Synthetic Data for Computer Vision Workshop \u2026", "abstract": "Generative models have been shown to be capable of creating images that closely mimic real scenes, suggesting they inherently encode scene representations. We introduce Intrinsic LoRA (I-LoRA), a general approach that uses Low-Rank \u2026"}, {"title": "Improving the spatial resolution of solar images using super-resolution diffusion generative adversarial networks", "link": "https://www.aanda.org/articles/aa/pdf/forth/aa49100-23.pdf", "details": "W Song, Y Ma, H Sun, X Zhao, G Lin - 2024", "abstract": "Context. High-spatial-resolution solar images contribute to the study of small-scale structures on the Sun. The Helioseismic and Magnetic Imager (HMI) conducts continuous full-disk observations of the Sun at a fixed cadence, accumulating a \u2026"}, {"title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies", "link": "https://arxiv.org/pdf/2404.06395", "details": "S Hu, Y Tu, X Han, C He, G Cui, X Long, Z Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This \u2026"}, {"title": "Harnessing the Power of Large Vision Language Models for Synthetic Image Detection", "link": "https://arxiv.org/pdf/2404.02726", "details": "M Keita, W Hamidouche, H Bougueffa, A Hadid\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In recent years, the emergence of models capable of generating images from text has attracted considerable interest, offering the possibility of creating realistic images from text descriptions. Yet these advances have also raised concerns about the \u2026"}, {"title": "ORacle: Large Vision-Language Models for Knowledge-Guided Holistic OR Domain Modeling", "link": "https://arxiv.org/pdf/2404.07031", "details": "E \u00d6zsoy, C Pellegrini, M Keicher, N Navab - arXiv preprint arXiv:2404.07031, 2024", "abstract": "Every day, countless surgeries are performed worldwide, each within the distinct settings of operating rooms (ORs) that vary not only in their setups but also in the personnel, tools, and equipment used. This inherent diversity poses a substantial \u2026"}, {"title": "RS-LLaVA: A Large Vision-Language Model for Joint Captioning and Question Answering in Remote Sensing Imagery", "link": "https://www.mdpi.com/2072-4292/16/9/1477", "details": "Y Bazi, L Bashmal, MM Al Rahhal, R Ricci, F Melgani - Remote Sensing, 2024", "abstract": "In this paper, we delve into the innovative application of large language models (LLMs) and their extension, large vision-language models (LVLMs), in the field of remote sensing (RS) image analysis. We particularly emphasize their multi-tasking \u2026"}]
