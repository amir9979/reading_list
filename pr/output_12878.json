[{"title": "How to Bridge the Gap between Modalities: Survey on Multimodal Large Language Model", "link": "https://ieeexplore.ieee.org/abstract/document/10841938/", "details": "S Song, X Li, S Li, S Zhao, J Yu, J Ma, X Mao, W Zhang\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "We explore Multimodal Large Language Models (MLLMs), which integrate LLMs like GPT-4 to handle multimodal data, including text, images, audio, and more. MLLMs demonstrate capabilities such as generating image captions and answering image \u2026"}, {"title": "Parameter-Inverted Image Pyramid Networks for Visual Perception and Multimodal Understanding", "link": "https://arxiv.org/pdf/2501.07783", "details": "Z Wang, X Zhu, X Yang, G Luo, H Li, C Tian, W Dou\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Image pyramids are widely adopted in top-performing methods to obtain multi-scale features for precise visual perception and understanding. However, current image pyramids use the same large-scale model to process multiple resolutions of images \u2026"}, {"title": "Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions", "link": "https://arxiv.org/pdf/2501.10011", "details": "Z Tan, Y Li, S Meng, X Yuan, W Li, T Mo, B Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Current popular Large Vision-Language Models (LVLMs) are suffering from Hallucinations on Object Attributes (HoOA), leading to incorrect determination of fine- grained attributes in the input images. Leveraging significant advancements in 3D \u2026"}, {"title": "VCF: An effective Vision-Centric Framework for Visual Question Answering", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225002085", "details": "F Wang, L Peng, S Cao, Z Yang, R Zhang, G An - Neurocomputing, 2025", "abstract": "Recently, the wide application of large language models in the field of Visual Question Answering (VQA) has significantly boosted the progress in this field. Despite achieved advancements, LLMs cannot fully perceive and comprehend visual \u2026"}, {"title": "Language models encode the value of numbers linearly", "link": "https://aclanthology.org/2025.coling-main.47.pdf", "details": "F Zhu, D Dai, Z Sui - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have exhibited impressive competence in various tasks, but their internal mechanisms on mathematical problems are still under- explored. In this paper, we study a fundamental question: how language models \u2026"}, {"title": "Reasoning Language Models: A Blueprint", "link": "https://arxiv.org/pdf/2501.11223%3F", "details": "M Besta, J Barth, E Schreiber, A Kubicek, A Catarino\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning language models (RLMs), also known as Large Reasoning Models (LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have redefined AI's problem-solving capabilities by extending large language models \u2026"}, {"title": "Evaluating Generalization Capability of Language Models across Abductive, Deductive and Inductive Logical Reasoning", "link": "https://aclanthology.org/2025.coling-main.330.pdf", "details": "Y Sheng, W Wen, L Li, D Zeng - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Transformer-based language models (LMs) have demonstrated remarkable performance on many natural language tasks, yet to what extent LMs possess the capability of generalizing to unseen logical rules remains not explored sufficiently. In \u2026"}, {"title": "Advancing General Multimodal Capability of Vision-language Models with Pyramid-descent Visual Position Encoding", "link": "https://arxiv.org/pdf/2501.10967", "details": "Z Chen, M Li, Z Chen, N Du, X Li, Y Zou - arXiv preprint arXiv:2501.10967, 2025", "abstract": "Vision-language Models (VLMs) have shown remarkable capabilities in advancing general artificial intelligence, yet the irrational encoding of visual positions persists in inhibiting the models' comprehensive perception performance across different levels \u2026"}, {"title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "link": "https://arxiv.org/pdf/2501.16961%3F", "details": "M Raza, N Milic-Frayling - arXiv preprint arXiv:2501.16961, 2025", "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that \u2026"}]
