[{"title": "VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis", "link": "https://arxiv.org/pdf/2410.08397", "details": "A Hoopes, VI Butoi, JV Guttag, AV Dalca - arXiv preprint arXiv:2410.08397, 2024", "abstract": "We present VoxelPrompt, an agent-driven vision-language framework that tackles diverse radiological tasks through joint modeling of natural language, image volumes, and analytical metrics. VoxelPrompt is multi-modal and versatile \u2026"}, {"title": "TULIP: Token-length Upgraded CLIP", "link": "https://arxiv.org/pdf/2410.10034", "details": "I Najdenkoska, MM Derakhshani, YM Asano\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We address the challenge of representing long captions in vision-language models, such as CLIP. By design these models are limited by fixed, absolute positional encodings, restricting inputs to a maximum of 77 tokens and hindering performance \u2026"}]
