[{"title": "A deep-learning framework to predict cancer treatment response from histopathology images through imputed transcriptomics", "link": "https://repository.icr.ac.uk/bitstream/handle/internal/6313/s43018-024-00793-2.pdf%3Fsequence%3D2%26isAllowed%3Dy", "details": "DT Hoang, G Dinstag, ED Shulman, LC Hermida\u2026 - Nature Cancer, 2024", "abstract": "Advances in artificial intelligence have paved the way for leveraging hematoxylin and eosin-stained tumor slides for precision oncology. We present ENLIGHT\u2013 DeepPT, an indirect two-step approach consisting of (1) DeepPT, a deep-learning \u2026"}, {"title": "Dilation Before Automated Diabetic Retinopathy Screening Performed in the Primary Care Setting", "link": "https://www.annfammed.org/content/annalsfm/22/4/356.full-text.pdf", "details": "J Yun, S Schell, K Gulley, ME Johansen - The Annals of Family Medicine, 2024", "abstract": "2Heritage College of Osteopathic Medicine at Ohio University, Dublin, Ohio perform screening at the point of care. The proportion of our diabetic population with sufficient diabetic retinopathy results (ie, retinal photos the software could interpret as positive \u2026"}, {"title": "SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images", "link": "https://arxiv.org/pdf/2407.00664", "details": "Z Yang, H Liu, X Wang - arXiv preprint arXiv:2407.00664, 2024", "abstract": "Cancer survival prediction is a challenging task that involves analyzing of the tumor microenvironment within Whole Slide Image (WSI). Previous methods cannot effectively capture the intricate interaction features among instances within the local \u2026"}, {"title": "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale", "link": "https://arxiv.org/pdf/2407.02118", "details": "W Zheng, W Pan, X Xu, L Qin, L Yue, M Zhou - arXiv preprint arXiv:2407.02118, 2024", "abstract": "In recent years, Large Language Models (LLMs) have made significant strides towards Artificial General Intelligence. However, training these models from scratch requires substantial computational resources and vast amounts of text data. In this \u2026"}, {"title": "Financial Knowledge Large Language Model", "link": "https://arxiv.org/pdf/2407.00365", "details": "C Yang, C Xu, Y Qi - arXiv preprint arXiv:2407.00365, 2024", "abstract": "Artificial intelligence is making significant strides in the finance industry, revolutionizing how data is processed and interpreted. Among these technologies, large language models (LLMs) have demonstrated substantial potential to transform \u2026"}, {"title": "Composable Interventions for Language Models", "link": "https://arxiv.org/pdf/2407.06483", "details": "A Kolbeinsson, K O'Brien, T Huang, S Gao, S Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Test-time interventions for language models can enhance factual accuracy, mitigate harmful outputs, and improve model efficiency without costly retraining. But despite a flood of new methods, different types of interventions are largely developing \u2026"}, {"title": "CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images", "link": "https://openreview.net/pdf%3Fid%3DmXj5EV6PyD", "details": "TN Saada, V Di-Proietto, K Von Loga, B Schmauch\u2026 - MICCAI Workshop on \u2026", "abstract": "Multiple Instance Learning (MIL) models have proven effective for cancer prognosis from Whole Slide Images. However, the original MIL formulation incorrectly assumes the patches of the same image to be independent, leading to a loss of spatial context \u2026"}, {"title": "Language models, like humans, show content effects on reasoning tasks", "link": "https://academic.oup.com/pnasnexus/article/3/7/pgae233/7712372", "details": "AK Lampinen, I Dasgupta, SCY Chan, HR Sheahan\u2026 - PNAS nexus, 2024", "abstract": "Abstract reasoning is a key ability for an intelligent system. Large language models (LMs) achieve above-chance performance on abstract reasoning tasks but exhibit many imperfections. However, human abstract reasoning is also imperfect. Human \u2026"}]
