[{"title": "HaluCheck: Explainable and verifiable automation for detecting hallucinations in LLM responses", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425003343", "details": "S Heo, S Son, H Park - Expert Systems with Applications, 2025", "abstract": "Large language models have become integral to various aspects of modern life, but a critical challenge persists: hallucinations. This work contributes to expert systems research by providing a systematic framework for enhancing AI reliability and \u2026"}, {"title": "Invariance Pair-Guided Learning: Enhancing Robustness in Neural Networks", "link": "https://arxiv.org/pdf/2502.18975", "details": "M Surner, A Khelil, L Bothmann - arXiv preprint arXiv:2502.18975, 2025", "abstract": "Out-of-distribution generalization of machine learning models remains challenging since the models are inherently bound to the training data distribution. This especially manifests, when the learned models rely on spurious correlations. Most of \u2026"}, {"title": "Handwritten Character Image Generation for Effective Data Augmentation", "link": "https://www.jstage.jst.go.jp/article/transinf/advpub/0/advpub_2024EDP7201/_pdf", "details": "CS LEOW, T KITAGAWA, H YAJIMA, H NISHIZAKI - IEICE Transactions on Information \u2026, 2025", "abstract": "This study introduces data augmentation techniques to enhance training datasets for a Japanese handwritten character classification model, addressing the high cost of collecting extensive handwritten character data. A novel method is proposed to \u2026"}, {"title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "link": "https://proceedings.neurips.cc/paper_files/paper/2024/file/e142fd2b70f10db2543c64bca1417de8-Paper-Conference.pdf", "details": "W JIAWEI, R Jiang, C Yang, Z Wu, R Shibasaki\u2026 - Advances in Neural \u2026, 2025", "abstract": "This paper introduces a novel approach using Large Language Models (LLMs) integrated into an agent framework for flexible and effective personal mobility generation. LLMs overcome the limitations of previous models by effectively \u2026"}, {"title": "Towards label-only membership inference attack against pre-trained large language models", "link": "https://arxiv.org/pdf/2502.18943", "details": "Y He, B Li, L Liu, Z Ba, W Dong, Y Li, Z Qin, K Ren\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Membership Inference Attacks (MIAs) aim to predict whether a data sample belongs to the model's training set or not. Although prior research has extensively explored MIAs in Large Language Models (LLMs), they typically require accessing to complete \u2026"}, {"title": "Sliding Window Attention Training for Efficient Large Language Models", "link": "https://arxiv.org/pdf/2502.18845", "details": "Z Fu, W Song, Y Wang, X Wu, Y Zheng, Y Zhang, D Xu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in transformer-based Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks. However, their quadratic computational complexity concerning sequence length remains a significant \u2026"}, {"title": "A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)", "link": "https://arxiv.org/pdf/2502.03450", "details": "Y Chen, H Sawhney, N Gyd\u00e9, Y Jian, J Saunders\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Scene graphs have emerged as a structured and serializable environment representation for grounded spatial reasoning with Large Language Models (LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason \u2026"}, {"title": "FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models", "link": "https://arxiv.org/pdf/2502.18573", "details": "R Marinescu, D Bhattacharjya, J Lee, T Tchrakian\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have demonstrated vast capabilities on generative tasks in recent years, yet they struggle with guaranteeing the factual correctness of the generated content. This makes these models unreliable in realistic situations \u2026"}]
