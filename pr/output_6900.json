[{"title": "RAG-Modulo: Solving Sequential Tasks using Experience, Critics, and Language Models", "link": "https://arxiv.org/pdf/2409.12294", "details": "A Jain, C Jermaine, V Unhelkar - arXiv preprint arXiv:2409.12294, 2024", "abstract": "Large language models (LLMs) have recently emerged as promising tools for solving challenging robotic tasks, even in the presence of action and observation uncertainties. Recent LLM-based decision-making methods (also referred to as LLM \u2026"}, {"title": "Towards Reliable Medical Question Answering: Techniques and Challenges in Mitigating Hallucinations in Language Models", "link": "https://arxiv.org/pdf/2408.13808", "details": "DK Pham, BQ Vo - arXiv preprint arXiv:2408.13808, 2024", "abstract": "The rapid advancement of large language models (LLMs) has significantly impacted various domains, including healthcare and biomedicine. However, the phenomenon of hallucination, where LLMs generate outputs that deviate from factual accuracy or \u2026"}, {"title": "RAD-Bench: Evaluating Large Language Models Capabilities in Retrieval Augmented Dialogues", "link": "https://arxiv.org/pdf/2409.12558", "details": "TL Kuo, FT Liao, MW Hsieh, FC Chang, PC Hsu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In real-world applications with Large Language Models (LLMs), external retrieval mechanisms-such as Search-Augmented Generation (SAG), tool utilization, and Retrieval-Augmented Generation (RAG)-are often employed to enhance the quality \u2026"}, {"title": "Revolutionizing Database Q&A with Large Language Models: Comprehensive Benchmark and Evaluation", "link": "https://arxiv.org/pdf/2409.04475", "details": "Y Zheng, B Li, Z Lin, Y Luo, X Zhou, C Lin, J Su, G Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The development of Large Language Models (LLMs) has revolutionized Q&A across various industries, including the database domain. However, there is still a lack of a comprehensive benchmark to evaluate the capabilities of different LLMs and their \u2026"}, {"title": "Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data", "link": "https://arxiv.org/pdf/2409.12437", "details": "J Zhou, A Ghaddar, G Zhang, L Ma, Y Hu, S Pal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite recent advances in training and prompting strategies for Large Language Models (LLMs), these models continue to face challenges with complex logical reasoning tasks that involve long reasoning chains. In this work, we explore the \u2026"}, {"title": "Towards a Unified View of Preference Learning for Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2409.02795", "details": "B Gao, F Song, Y Miao, Z Cai, Z Yang, L Chen, H Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to \u2026"}, {"title": "A Comprehensive Evaluation of Quantized Instruction-Tuned Large Language Models: An Experimental Analysis up to 405B", "link": "https://arxiv.org/pdf/2409.11055", "details": "J Lee, S Park, J Kwon, J Oh, Y Kwon - arXiv preprint arXiv:2409.11055, 2024", "abstract": "Prior research works have evaluated quantized LLMs using limited metrics such as perplexity or a few basic knowledge tasks and old datasets. Additionally, recent large- scale models such as Llama 3.1 with up to 405B have not been thoroughly \u2026"}, {"title": "Booster: Tackling Harmful Fine-tuing for Large Language Models via Attenuating Harmful Perturbation", "link": "https://arxiv.org/pdf/2409.01586", "details": "T Huang, S Hu, F Ilhan, SF Tekin, L Liu - arXiv preprint arXiv:2409.01586, 2024", "abstract": "Harmful fine-tuning issue\\citep {qi2023fine} poses serious safety concerns for Large language models' fine-tuning-as-a-service. While existing defenses\\citep {huang2024vaccine, rosati2024representation} have been proposed to mitigate the \u2026"}, {"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}]
