[{"title": "SelfPrompt: Confidence-Aware Semi-Supervised Tuning for Robust Vision-Language Model Adaptation", "link": "https://arxiv.org/pdf/2501.14148", "details": "S Roy, A Etemad - arXiv preprint arXiv:2501.14148, 2025", "abstract": "We present SelfPrompt, a novel prompt-tuning approach for vision-language models (VLMs) in a semi-supervised learning setup. Existing methods for tuning VLMs in semi-supervised setups struggle with the negative impact of the miscalibrated VLMs \u2026"}, {"title": "Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation", "link": "https://arxiv.org/pdf/2501.14166", "details": "CD Nguyen, X Wu, T Nguyen, S Zhao, K Le\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Previous research on multimodal entity linking (MEL) has primarily employed contrastive learning as the primary objective. However, using the rest of the batch as negative samples without careful consideration, these studies risk leveraging easy \u2026"}, {"title": "Handwritten Character Image Generation for Effective Data Augmentation", "link": "https://www.jstage.jst.go.jp/article/transinf/advpub/0/advpub_2024EDP7201/_pdf", "details": "CS LEOW, T KITAGAWA, H YAJIMA, H NISHIZAKI - IEICE Transactions on Information \u2026, 2025", "abstract": "This study introduces data augmentation techniques to enhance training datasets for a Japanese handwritten character classification model, addressing the high cost of collecting extensive handwritten character data. A novel method is proposed to \u2026"}]
