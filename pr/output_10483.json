[{"title": "Large Language Model Federated Learning with Blockchain and Unlearning for Cross-Organizational Collaboration", "link": "https://arxiv.org/pdf/2412.13551", "details": "X Zuo, M Wang, T Zhu, S Yu, W Zhou - arXiv preprint arXiv:2412.13551, 2024", "abstract": "Large language models (LLMs) have transformed the way computers understand and process human language, but using them effectively across different organizations remains still difficult. When organizations work together to improve \u2026"}, {"title": "Explore Theory of Mind: Program-guided adversarial data generation for theory of mind reasoning", "link": "https://arxiv.org/pdf/2412.12175", "details": "M Sclar, J Yu, M Fazel-Zarandi, Y Tsvetkov, Y Bisk\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Do large language models (LLMs) have theory of mind? A plethora of papers and benchmarks have been introduced to evaluate if current models have been able to develop this key ability of social intelligence. However, all rely on limited datasets \u2026"}, {"title": "Few-shot Steerable Alignment: Adapting Rewards and LLM Policies with Neural Processes", "link": "https://arxiv.org/pdf/2412.13998", "details": "K Kobalczyk, C Fanconi, H Sun, M van der Schaar - arXiv preprint arXiv:2412.13998, 2024", "abstract": "As large language models (LLMs) become increasingly embedded in everyday applications, ensuring their alignment with the diverse preferences of individual users has become a critical challenge. Currently deployed approaches typically \u2026"}, {"title": "Learning to Verify Summary Facts with Fine-Grained LLM Feedback", "link": "https://arxiv.org/pdf/2412.10689", "details": "J Oh, J Choi, NHY Kim, T Yun, H Song - arXiv preprint arXiv:2412.10689, 2024", "abstract": "Training automatic summary fact verifiers often faces the challenge of a lack of human-labeled data. In this paper, we explore alternative way of leveraging Large Language Model (LLM) generated feedback to address the inherent limitation of \u2026"}]
