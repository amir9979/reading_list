[{"title": "Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "link": "https://arxiv.org/pdf/2405.10431", "details": "S Furniturewala, S Jandial, A Java, P Banerjee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing debiasing techniques are typically training-based or require access to the model's internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine \u2026"}, {"title": "Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models", "link": "https://arxiv.org/pdf/2406.02061", "details": "M Nezhurina, L Cipolina-Kun, M Cherti, J Jitsev - arXiv preprint arXiv:2406.02061, 2024", "abstract": "Large Language Models (LLMs) are often described as being instances of foundation models-that is, models that transfer strongly across various tasks and conditions in few-show or zero-shot manner, while exhibiting scaling laws that \u2026"}, {"title": "Large Language Models Can Self-Correct with Minimal Effort", "link": "https://arxiv.org/pdf/2405.14092", "details": "Z Wu, Q Zeng, Z Zhang, Z Tan, C Shen, M Jiang - arXiv preprint arXiv:2405.14092, 2024", "abstract": "Intrinsic self-correct was a method that instructed large language models (LLMs) to verify and correct their responses without external feedback. Unfortunately, the study concluded that the LLMs could not self-correct reasoning yet. We find that a simple \u2026"}, {"title": "Scaling Laws for Discriminative Classification in Large Language Models", "link": "https://arxiv.org/pdf/2405.15765", "details": "D Wyatte, F Tahmasbi, M Li, T Markovich - arXiv preprint arXiv:2405.15765, 2024", "abstract": "Modern large language models (LLMs) represent a paradigm shift in what can plausibly be expected of machine learning models. The fact that LLMs can effectively generate sensible answers to a diverse range of queries suggests that they would be \u2026"}, {"title": "A Systematic Analysis on the Temporal Generalization of Language Models in Social Media", "link": "https://arxiv.org/pdf/2405.13017", "details": "A Ushio, J Camacho-Collados - arXiv preprint arXiv:2405.13017, 2024", "abstract": "In machine learning, temporal shifts occur when there are differences between training and test splits in terms of time. For streaming data such as news or social media, models are commonly trained on a fixed corpus from a certain period of time \u2026"}, {"title": "Do Language Models Enjoy Their Own Stories? Prompting Large Language Models for Automatic Story Evaluation", "link": "https://arxiv.org/pdf/2405.13769", "details": "C Chhun, FM Suchanek, C Clavel - arXiv preprint arXiv:2405.13769, 2024", "abstract": "Storytelling is an integral part of human experience and plays a crucial role in social interactions. Thus, Automatic Story Evaluation (ASE) and Generation (ASG) could benefit society in multiple ways, but they are challenging tasks which require high \u2026"}, {"title": "Phase Transitions in the Output Distribution of Large Language Models", "link": "https://arxiv.org/pdf/2405.17088", "details": "J Arnold, F Holtorf, F Sch\u00e4fer, N L\u00f6rch - arXiv preprint arXiv:2405.17088, 2024", "abstract": "In a physical system, changing parameters such as temperature can induce a phase transition: an abrupt change from one state of matter to another. Analogous phenomena have recently been observed in large language models. Typically, the \u2026"}, {"title": "Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models", "link": "https://arxiv.org/pdf/2405.16282", "details": "A Kumar, R Morabito, S Umbet, J Kabbara, A Emami - arXiv preprint arXiv \u2026, 2024", "abstract": "As the use of Large Language Models (LLMs) becomes more widespread, understanding their self-evaluation of confidence in generated responses becomes increasingly important as it is integral to the reliability of the output of these models \u2026"}, {"title": "Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs", "link": "https://arxiv.org/pdf/2405.15485", "details": "S Guo, A Didolkar, NR Ke, A Goyal, F Husz\u00e1r\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We are beginning to see progress in language model assisted scientific discovery. Motivated by the use of LLMs as a general scientific assistant, this paper assesses the domain knowledge of LLMs through its understanding of different mathematical \u2026"}]
