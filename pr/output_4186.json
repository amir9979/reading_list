[{"title": "Language Models Encode Collaborative Signals in Recommendation", "link": "https://arxiv.org/pdf/2407.05441", "details": "L Sheng, A Zhang, Y Zhang, Y Chen, X Wang, TS Chua - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent studies empirically indicate that language models (LMs) encode rich world knowledge beyond mere semantics, attracting significant attention across various fields. However, in the recommendation domain, it remains uncertain whether LMs \u2026"}, {"title": "Steering Language Models with Game-Theoretic Solvers", "link": "https://openreview.net/pdf%3Fid%3D5QLtIodDmu", "details": "I Gemp, R Patel, Y Bachrach, M Lanctot, V Dasagi\u2026 - Agentic Markets Workshop at ICML \u2026", "abstract": "Mathematical models of strategic interactions among rational agents have long been studied in game theory. However the interactions studied are often over a small set of discrete actions which is very different from how humans communicate in natural \u2026"}, {"title": "Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation", "link": "https://arxiv.org/pdf/2407.08441", "details": "R Cantini, G Cosenza, A Orsino, D Talia - arXiv preprint arXiv:2407.08441, 2024", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, demonstrating remarkable computational power and linguistic capabilities. However, these models are inherently prone to various biases stemming from their training \u2026"}, {"title": "Patch-Level Training for Large Language Models", "link": "https://arxiv.org/pdf/2407.12665", "details": "C Shao, F Meng, J Zhou - arXiv preprint arXiv:2407.12665, 2024", "abstract": "As Large Language Models (LLMs) achieve remarkable progress in language understanding and generation, their training efficiency has become a critical concern. Traditionally, LLMs are trained to predict the next token in a sequence \u2026"}, {"title": "On the attribution of confidence to large language models", "link": "https://arxiv.org/pdf/2407.08388", "details": "G Keeling, W Street - arXiv preprint arXiv:2407.08388, 2024", "abstract": "Credences are mental states corresponding to degrees of confidence in propositions. Attribution of credences to Large Language Models (LLMs) is commonplace in the empirical literature on LLM evaluation. Yet the theoretical basis \u2026"}, {"title": "Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models", "link": "https://openreview.net/pdf%3Fid%3DcQWsTeTSkZ", "details": "S Lotfi, Y Kuang, MA Finzi, B Amos, M Goldblum\u2026 - ICML 2024 Workshop on \u2026", "abstract": "Large language models (LLMs) with billions of parameters excel at predicting the next token in a sequence. Recent work computes non-vacuous compression-based generalization bounds for LLMs, but these bounds are vacuous for large models at \u2026"}, {"title": "ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts", "link": "https://arxiv.org/pdf/2407.09447", "details": "AF Hardy, H Liu, B Lange, MJ Kochenderfer - arXiv preprint arXiv:2407.09447, 2024", "abstract": "Typical schemes for automated red-teaming large language models (LLMs) focus on discovering prompts that trigger a frozen language model (the defender) to generate toxic text. This often results in the prompting model (the adversary) producing text \u2026"}, {"title": "Beyond Instruction Following: Evaluating Rule Following of Large Language Models", "link": "https://arxiv.org/pdf/2407.08440", "details": "W Sun, C Zhang, X Zhang, Z Huang, H Xu, P Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Although Large Language Models (LLMs) have demonstrated strong instruction- following ability to be helpful, they are further supposed to be controlled and guided by rules in real-world scenarios to be safe, and accurate in responses. This demands \u2026"}, {"title": "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale", "link": "https://arxiv.org/pdf/2407.02118", "details": "W Zheng, W Pan, X Xu, L Qin, L Yue, M Zhou - arXiv preprint arXiv:2407.02118, 2024", "abstract": "In recent years, Large Language Models (LLMs) have made significant strides towards Artificial General Intelligence. However, training these models from scratch requires substantial computational resources and vast amounts of text data. In this \u2026"}]
