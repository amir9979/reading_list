[{"title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models", "link": "https://arxiv.org/pdf/2410.18785%3F", "details": "Q Li, X Liu, Z Tang, P Dong, Z Li, X Pan, X Chu - arXiv preprint arXiv:2410.18785, 2024", "abstract": "Model editing has become an increasingly popular alternative for efficiently updating knowledge within language models. Current methods mainly focus on reliability, generalization, and locality, with many methods excelling across these criteria. Some \u2026"}, {"title": "Reducing the Scope of Language Models with Circuit Breakers", "link": "https://arxiv.org/pdf/2410.21597", "details": "D Yunis, S Huo, C Gunasekara, D Contractor - arXiv preprint arXiv:2410.21597, 2024", "abstract": "Language models are now deployed in a wide variety of user-facing applications, often for specific purposes like answering questions about documentation or acting as coding assistants. As these models are intended for particular purposes, they \u2026"}, {"title": "Analysing the Residual Stream of Language Models Under Knowledge Conflicts", "link": "https://arxiv.org/pdf/2410.16090", "details": "Y Zhao, X Du, G Hong, AP Gema, A Devoto, H Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) can store a significant amount of factual knowledge in their parameters. However, their parametric knowledge may conflict with the information provided in the context. Such conflicts can lead to undesirable model \u2026"}, {"title": "To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2410.06765", "details": "J Lin, H Chen, D Zhu, X Shen - arXiv preprint arXiv:2410.06765, 2024", "abstract": "In recent years, multimodal large language models (MLLMs) have garnered significant attention from both industry and academia. However, there is still considerable debate on constructing MLLM architectures, particularly regarding the \u2026"}, {"title": "Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679722", "details": "Y Shi, Q Tan, X Wu, S Zhong, K Zhou, N Liu - Proceedings of the 33rd ACM \u2026, 2024", "abstract": "Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging \u2026"}, {"title": "Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes", "link": "https://arxiv.org/pdf/2410.16930", "details": "BR Christ, Z Gottesman, J Kropko, T Hartvigsen - arXiv preprint arXiv:2410.16930, 2024", "abstract": "Math reasoning is a highly active area of Large Language Model (LLM) research because it is a hallmark of artificial intelligence. However, few works have explored how math reasoning is encoded within LLM parameters and if it is a skill that can be \u2026"}, {"title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?", "link": "https://arxiv.org/pdf/2410.13854", "details": "C Zhang, X Feng, Y Bai, X Du, J Hou, K Deng, G Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the capabilities of Multimodal Large Language Models (MLLMs) continue to improve, the need for higher-order capability evaluation of MLLMs is increasing. However, there is a lack of work evaluating MLLM for higher-order perception and \u2026"}, {"title": "Baichuan-omni technical report", "link": "https://arxiv.org/pdf/2410.08565", "details": "Y Li, H Sun, M Lin, T Li, G Dong, T Zhang, B Ding\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The salient multimodal capabilities and interactive experience of GPT-4o highlight its critical role in practical applications, yet it lacks a high-performing open-source counterpart. In this paper, we introduce Baichuan-Omni, the first open-source 7B \u2026"}, {"title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models", "link": "https://arxiv.org/pdf/2410.18252", "details": "M Noukhovitch, S Huang, S Xhonneux, A Hosseini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously generating from the large language model (LLM) policy, labelling with a reward model, and learning using feedback on the LLM's own outputs. While performant, this \u2026"}]
