[{"title": "Thompson Sampling for the Multinomial Logit Bandit", "link": "https://pubsonline.informs.org/doi/abs/10.1287/moor.2020.0096", "details": "S Agrawal, V Avadhanula, V Goyal, A Zeevi - Mathematics of Operations Research, 2025", "abstract": "We consider a dynamic combinatorial optimization problem where at each time step, the decision maker selects a subset of cardinality K from N possible items and observes a feedback in the form of the index of one of the items in the said subset or \u2026"}, {"title": "MPTSNet: Integrating Multiscale Periodic Local Patterns and Global Dependencies for Multivariate Time Series Classification", "link": "https://arxiv.org/pdf/2503.05582%3F", "details": "Y Mu, M Shahzad, XX Zhu - arXiv preprint arXiv:2503.05582, 2025", "abstract": "Multivariate Time Series Classification (MTSC) is crucial in extensive practical applications, such as environmental monitoring, medical EEG analysis, and action recognition. Real-world time series datasets typically exhibit complex dynamics. To \u2026"}, {"title": "MSNet: Multi-task self-supervised network for time series classification", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525000923", "details": "D Huang, X Lv, Y Zhang - Pattern Recognition Letters, 2025", "abstract": "Learning rich representations from unlabeled temporal data is essential for effective time series classification. Most existing self-supervised learning methods for time series focus on a single task, often relying on contrastive learning or reconstruction \u2026"}, {"title": "Towards Imperceptible Adversarial Attacks for Time Series Classification with Local Perturbations and Frequency Analysis", "link": "https://arxiv.org/pdf/2503.19519", "details": "W Gu, R Zhong, J Zhang, MR Lyu - arXiv preprint arXiv:2503.19519, 2025", "abstract": "Adversarial attacks in time series classification (TSC) models have recently gained attention due to their potential to compromise model robustness. Imperceptibility is crucial, as adversarial examples detected by the human vision system (HVS) can \u2026"}, {"title": "Minimax Bayesian Neural Networks", "link": "https://www.mdpi.com/1099-4300/27/4/340", "details": "J Hong, EE Kuruoglu - Entropy, 2025", "abstract": "Robustness is an important issue in deep learning, and Bayesian neural networks (BNNs) provide means of robustness analysis, while the minimax method is a conservative choice in the classical Bayesian field. Recently, researchers have \u2026"}, {"title": "SEQFUSION: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting", "link": "https://arxiv.org/pdf/2503.02836", "details": "TJ Huang, XY Chen, HJ Ye - arXiv preprint arXiv:2503.02836, 2025", "abstract": "Unlike traditional time-series forecasting methods that require extensive in-task data for training, zero-shot forecasting can directly predict future values given a target time series without additional training data. Current zero-shot approaches primarily rely \u2026"}, {"title": "MAD-DGTD: Multivariate time series Anomaly Detection based on Dynamic Graph structure learning with Time Delay", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225005594", "details": "K Wang, J Kong, M Zhang, M Jiang, T Liu - Neurocomputing, 2025", "abstract": "Anomaly detection of multivariate time series data is extremely important in the industrial operation maintenance of Internet of Things (IoT). Researchers have found that the relationship between multiple sensors can be modeled as graph structure \u2026"}, {"title": "User-friendly Foundation Model Adapters for Multivariate Time Series Classification", "link": "https://romilbert.github.io/adapters/adapters_multisa.pdf", "details": "R Ilbert, V Feofanov, M Tiomoko, I Redko, T Palpanas", "abstract": "Foundation models, while highly effective, are often resource-intensive, requiring substantial inference time and memory. This paper addresses the challenge of making these models more accessible with limited computational resources through \u2026"}, {"title": "Language Model Uncertainty Quantification with Attention Chain", "link": "https://arxiv.org/pdf/2503.19168", "details": "Y Li, R Qiang, L Moukheiber, C Zhang - arXiv preprint arXiv:2503.19168, 2025", "abstract": "Accurately quantifying a large language model's (LLM) predictive uncertainty is crucial for judging the reliability of its answers. While most existing research focuses on short, directly answerable questions with closed-form outputs (eg, multiple \u2026"}]
