[{"title": "Mutual Prompt Leaning for Vision Language Models", "link": "https://link.springer.com/article/10.1007/s11263-024-02243-z", "details": "S Long, Z Zhao, J Yuan, Z Tan, J Liu, J Feng, S Wang\u2026 - International Journal of \u2026, 2024", "abstract": "Large pre-trained vision language models (VLMs) have demonstrated impressive representation learning capabilities, but their transferability across various downstream tasks heavily relies on prompt learning. Since VLMs consist of text and \u2026"}, {"title": "Attention Prompting on Image for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2409.17143", "details": "R Yu, W Yu, X Wang - arXiv preprint arXiv:2409.17143, 2024", "abstract": "Compared with Large Language Models (LLMs), Large Vision-Language Models (LVLMs) can also accept images as input, thus showcasing more interesting emergent capabilities and demonstrating impressive performance on various vision \u2026"}, {"title": "TLDR: Token-Level Detective Reward Model for Large Vision Language Models", "link": "https://arxiv.org/pdf/2410.04734", "details": "D Fu, T Xiao, R Wang, W Zhu, P Zhang, G Pang, R Jia\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Although reward models have been successful in improving multimodal large language models, the reward models themselves remain brutal and contain minimal information. Notably, existing reward models only mimic human annotations by \u2026"}, {"title": "A Unified Hallucination Mitigation Framework for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2409.16494", "details": "Y Chang, L Jing, X Zhang, Y Zhang - arXiv preprint arXiv:2409.16494, 2024", "abstract": "Hallucination is a common problem for Large Vision-Language Models (LVLMs) with long generations which is difficult to eradicate. The generation with hallucinations is partially inconsistent with the image content. To mitigate hallucination, current \u2026"}, {"title": "Neural-Symbolic Collaborative Distillation: Advancing Small Language Models for Complex Reasoning Tasks", "link": "https://arxiv.org/pdf/2409.13203", "details": "H Liao, S He, Y Xu, Y Zhang, K Liu, J Zhao - arXiv preprint arXiv:2409.13203, 2024", "abstract": "In this paper, we propose $\\textbf {Ne} $ ural-$\\textbf {Sy} $ mbolic $\\textbf {C} $ ollaborative $\\textbf {D} $ istillation ($\\textbf {NesyCD} $), a novel knowledge distillation method for learning the complex reasoning abilities of Large Language \u2026"}, {"title": "Can Transformers Learn $ n $-gram Language Models?", "link": "https://arxiv.org/pdf/2410.03001", "details": "A Svete, N Borenstein, M Zhou, I Augenstein\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Much theoretical work has described the ability of transformers to represent formal languages. However, linking theoretical results to empirical performance is not straightforward due to the complex interplay between the architecture, the learning \u2026"}, {"title": "ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogue", "link": "https://arxiv.org/pdf/2409.17610", "details": "Z Li, C Zou, S Ma, Z Yang, C Du, Y Tang, Z Cao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rocketing prosperity of large language models (LLMs) in recent years has boosted the prevalence of vision-language models (VLMs) in the medical sector. In our online medical consultation scenario, a doctor responds to the texts and images \u2026"}, {"title": "Reasoning Elicitation in Language Models via Counterfactual Feedback", "link": "https://arxiv.org/pdf/2410.03767", "details": "A H\u00fcy\u00fck, X Xu, J Maasch, AV Nori, J Gonz\u00e1lez - arXiv preprint arXiv:2410.03767, 2024", "abstract": "Despite the increasing effectiveness of language models, their reasoning capabilities remain underdeveloped. In particular, causal reasoning through counterfactual question answering is lacking. This work aims to bridge this gap. We first derive \u2026"}, {"title": "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "link": "https://arxiv.org/pdf/2410.05077", "details": "FM Molfese, S Conia, R Orlando, R Navigli - arXiv preprint arXiv:2410.05077, 2024", "abstract": "Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have \u2026"}]
