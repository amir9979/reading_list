[{"title": "Integrating clinical knowledge and imaging for medical report generation", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525001783", "details": "M Zhao, J Liu, H Shen, B Yan, M Pei, Y Wang - Pattern Recognition Letters, 2025", "abstract": "Medical report generation is an important cross-modal task in the field of medicine, aiming to automatically generate professional and accurate reports for given medical images. Integrating clinical knowledge into the task of medical report generation can \u2026"}, {"title": "Dual-Masked Contrastive Learning Based Hypergraph Foundation Model for Whole Slide Images", "link": "https://www.sciencedirect.com/science/article/pii/S0031320325006557", "details": "X Zhou, S Ding, W Zhang, J Li, J Wang, J Chen, J Shi - Pattern Recognition, 2025", "abstract": "The spatial and contextual information in whole slide images (WSIs) is crucial for improving the diagnostic accuracy of computer-aided diagnosis (CAD). Although existing hypergraph-based methods have shown their effectiveness in capturing \u2026"}, {"title": "Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning", "link": "https://arxiv.org/pdf/2506.07044", "details": "W Xu, HP Chan, L Li, M Aljunied, R Yuan, J Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in understanding common visual elements, largely due to their large- scale datasets and advanced training strategies. However, their effectiveness in \u2026", "entry_id": "http://arxiv.org/abs/2506.07044v3", "updated": "2025-06-11 09:12:18", "published": "2025-06-08 08:47:30", "authors": "LASA Team;Weiwen Xu;Hou Pong Chan;Long Li;Mahani Aljunied;Ruifeng Yuan;Jianyu Wang;Chenghao Xiao;Guizhen Chen;Chaoqun Liu;Zhaodonghui Li;Yu Sun;Junao Shen;Chaojun Wang;Jie Tan;Deli Zhao;Tingyang Xu;Hao Zhang;Yu Rong", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities in understanding common visual elements, largely due to their\nlarge-scale datasets and advanced training strategies. However, their\neffectiveness in medical applications remains limited due to the inherent\ndiscrepancies between data and tasks in medical scenarios and those in the\ngeneral domain. Concretely, existing medical MLLMs face the following critical\nlimitations: (1) limited coverage of medical knowledge beyond imaging, (2)\nheightened susceptibility to hallucinations due to suboptimal data curation\nprocesses, (3) lack of reasoning capabilities tailored for complex medical\nscenarios. To address these challenges, we first propose a comprehensive data\ncuration procedure that (1) efficiently acquires rich medical knowledge data\nnot only from medical imaging but also from extensive medical texts and\ngeneral-domain data; and (2) synthesizes accurate medical captions, visual\nquestion answering (VQA), and reasoning samples. As a result, we build a\nmultimodal dataset enriched with extensive medical knowledge. Building on the\ncurated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu\nundergoes multi-stage training to embed medical expertise and enhance its\ntask-solving capabilities progressively. Besides, we preliminarily explore the\npotential of applying reinforcement learning with verifiable rewards paradigm\nto enhance Lingshu's medical reasoning ability. Additionally, we develop\nMedEvalKit, a unified evaluation framework that consolidates leading multimodal\nand textual medical benchmarks for standardized, fair, and efficient model\nassessment. We evaluate the performance of Lingshu on three fundamental medical\ntasks, multimodal QA, text-based QA, and medical report generation. The results\nshow that Lingshu consistently outperforms the existing open-source multimodal\nmodels on most tasks ...", "comment": "Technical Report, 53 pages, 25 tables, and 16 figures", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI;cs.CV", "links": "http://arxiv.org/abs/2506.07044v3;http://arxiv.org/pdf/2506.07044v3", "pdf_url": "http://arxiv.org/pdf/2506.07044v3"}, {"title": "Contour-Aware contrastive learning for 3D knee segmentation from MR images", "link": "https://link.springer.com/article/10.1007/s10044-025-01494-x", "details": "X Dong, L Zhang, X Zhao, S Zhou, Y Wang, J Xia\u2026 - Pattern Analysis and \u2026, 2025", "abstract": "Automatic segmentation of knee MR images plays an important role in the diagnosis and treatment of knee osteoarthritis. Existing deep learning-based methods usually require considerable annotated samples, and manual labeling of knee MR images is \u2026"}, {"title": "CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray", "link": "https://arxiv.org/pdf/2506.07984", "details": "M Lin, G Holste, S Wang, Y Zhou, Y Wei, I Banerjee\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The CXR-LT series is a community-driven initiative designed to enhance lung disease classification using chest X-rays (CXR). It tackles challenges in open long- tailed lung disease classification and enhances the measurability of state-of-the-art \u2026", "entry_id": "http://arxiv.org/abs/2506.07984v1", "updated": "2025-06-09 17:53:31", "published": "2025-06-09 17:53:31", "authors": "Mingquan Lin;Gregory Holste;Song Wang;Yiliang Zhou;Yishu Wei;Imon Banerjee;Pengyi Chen;Tianjie Dai;Yuexi Du;Nicha C. Dvornek;Yuyan Ge;Zuowei Guo;Shouhei Hanaoka;Dongkyun Kim;Pablo Messina;Yang Lu;Denis Parra;Donghyun Son;\u00c1lvaro Soto;Aisha Urooj;Ren\u00e9 Vidal;Yosuke Yamagishi;Zefan Yang;Ruichi Zhang;Yang Zhou;Leo Anthony Celi;Ronald M. Summers;Zhiyong Lu;Hao Chen;Adam Flanders;George Shih;Zhangyang Wang;Yifan Peng", "summary": "The CXR-LT series is a community-driven initiative designed to enhance lung\ndisease classification using chest X-rays (CXR). It tackles challenges in open\nlong-tailed lung disease classification and enhances the measurability of\nstate-of-the-art techniques. The first event, CXR-LT 2023, aimed to achieve\nthese goals by providing high-quality benchmark CXR data for model development\nand conducting comprehensive evaluations to identify ongoing issues impacting\nlung disease classification performance. Building on the success of CXR-LT\n2023, the CXR-LT 2024 expands the dataset to 377,110 chest X-rays (CXRs) and 45\ndisease labels, including 19 new rare disease findings. It also introduces a\nnew focus on zero-shot learning to address limitations identified in the\nprevious event. Specifically, CXR-LT 2024 features three tasks: (i) long-tailed\nclassification on a large, noisy test set, (ii) long-tailed classification on a\nmanually annotated \"gold standard\" subset, and (iii) zero-shot generalization\nto five previously unseen disease findings. This paper provides an overview of\nCXR-LT 2024, detailing the data curation process and consolidating\nstate-of-the-art solutions, including the use of multimodal models for rare\ndisease detection, advanced generative approaches to handle noisy labels, and\nzero-shot learning strategies for unseen diseases. Additionally, the expanded\ndataset enhances disease coverage to better represent real-world clinical\nsettings, offering a valuable resource for future research. By synthesizing the\ninsights and innovations of participating teams, we aim to advance the\ndevelopment of clinically realistic and generalizable diagnostic models for\nchest radiography.", "comment": "17 pages, 3 figures", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.LG", "links": "http://arxiv.org/abs/2506.07984v1;http://arxiv.org/pdf/2506.07984v1", "pdf_url": "http://arxiv.org/pdf/2506.07984v1"}, {"title": "PELM: A Deep Learning Model for Early Detection of Pneumonia in Chest Radiography", "link": "https://www.mdpi.com/2076-3417/15/12/6487", "details": "E Yanar, F Hardala\u00e7, K Ayturan - Applied Sciences, 2025", "abstract": "Pneumonia remains a leading cause of respiratory morbidity and mortality, underscoring the need for rapid and accurate diagnosis to enable timely treatment and prevent complications. This study introduces PELM (Pneumonia Ensemble \u2026"}]
