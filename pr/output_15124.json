[{"title": "Narrative coherence in neural language models", "link": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1572076/pdf", "details": "A Acciai, L Guerrisi, P Perconti, A Plebe, R Suriano\u2026 - Frontiers in Psychology, 2025", "abstract": "Neural language models, although at first approximation they may be simply described as predictors of the next token in a given sequence, surprisingly exhibit linguistic behaviors akin to human ones. This suggests the existence of an \u2026"}, {"title": "A Study for Language Models as Agents for Strategic Decision-making Environments", "link": "https://koreascience.kr/article/JAKO202509439605810.pdf", "details": "J Oh, SY Yun - Journal of Internet Computing and Services, 2025", "abstract": "Abstract Language Models (LMs) have proven highly effective in reasoning, understanding, and decision-making tasks. However, Large Language Models (LLMs) like GPT-4 face challenges when deployed in real-time complex \u2026"}, {"title": "Unveiling the mist over 3d vision-language understanding: Object-centric evaluation with chain-of-analysis", "link": "https://arxiv.org/pdf/2503.22420", "details": "J Huang, B Jia, Y Wang, Z Zhu, X Linghu, Q Li, SC Zhu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing 3D vision-language (3D-VL) benchmarks fall short in evaluating 3D-VL models, creating a\" mist\" that obscures rigorous insights into model capabilities and 3D-VL tasks. This mist persists due to three key limitations. First, flawed test data, like \u2026"}, {"title": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "link": "https://arxiv.org/pdf/2504.07416", "details": "J Park, S Kim, B Yoon, K Choi - arXiv preprint arXiv:2504.07416, 2025", "abstract": "Recent advancements in multi-modal models have significantly improved vision- language alignment in radiology. However, existing approaches struggle to effectively utilize complex radiology reports for learning, rely on low-resolution \u2026"}, {"title": "GPBench: A Comprehensive and Fine-Grained Benchmark for Evaluating Large Language Models as General Practitioners", "link": "https://arxiv.org/pdf/2503.17599", "details": "Z Li, Y Yang, J Lang, W Jiang, Y Zhao, S Li, D Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "General practitioners (GPs) serve as the cornerstone of primary healthcare systems by providing continuous and comprehensive medical services. However, due to community-oriented nature of their practice, uneven training and resource gaps, the \u2026"}, {"title": "Summarization Metrics for Spanish and Basque: Do Automatic Scores and LLM-Judges Correlate with Humans?", "link": "https://arxiv.org/pdf/2503.17039", "details": "J Barnes, N Perez, A Bonet-Jover, B Altuna - arXiv preprint arXiv:2503.17039, 2025", "abstract": "Studies on evaluation metrics and LLM-as-a-Judge models for automatic text summarization have largely been focused on English, limiting our understanding of their effectiveness in other languages. Through our new dataset BASSE (BAsque \u2026"}, {"title": "How Can Objects Help Video-Language Understanding?", "link": "https://arxiv.org/pdf/2504.07454", "details": "Z Tang, S Wang, J Cho, J Yoo, C Sun - arXiv preprint arXiv:2504.07454, 2025", "abstract": "How multimodal large language models (MLLMs) perceive the visual world remains a mystery. To one extreme, object and relation modeling may be implicitly implemented with inductive biases, for example by treating objects as tokens. To the \u2026"}, {"title": "DeCAP: Context-Adaptive Prompt Generation for Debiasing Zero-shot Question Answering in Large Language Models", "link": "https://arxiv.org/pdf/2503.19426%3F", "details": "S Bae, YS Choi, JH Lee - arXiv preprint arXiv:2503.19426, 2025", "abstract": "While Large Language Models (LLMs) excel in zero-shot Question Answering (QA), they tend to expose biases in their internal knowledge when faced with socially sensitive questions, leading to a degradation in performance. Existing zero-shot \u2026"}, {"title": "Diagnostic accuracy and clinical value of a domain-specific multimodal generative AI model for chest radiograph report generation", "link": "https://pubs.rsna.org/doi/abs/10.1148/radiol.241476", "details": "EK Hong, J Ham, B Roh, J Gu, B Park, S Kang, K You\u2026 - Radiology, 2025", "abstract": "Background Generative artificial intelligence (AI) is anticipated to alter radiology workflows, requiring a clinical value assessment for frequent examinations like chest radiograph interpretation. Purpose To develop and evaluate the diagnostic accuracy \u2026"}]
