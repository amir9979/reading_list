[{"title": "Is On-Device AI Broken and Exploitable? Assessing the Trust and Ethics in Small Language Models", "link": "https://arxiv.org/pdf/2406.05364", "details": "K Nakka, J Dani, N Saxena - arXiv preprint arXiv:2406.05364, 2024", "abstract": "In this paper, we present a very first study to investigate trust and ethical implications of on-device artificial intelligence (AI), focusing on''small''language models (SLMs) amenable for personal devices like smartphones. While on-device SLMs promise \u2026"}, {"title": "ULTRAFEEDBACK: Boosting Language Models with Scaled AI Feedback", "link": "https://openreview.net/pdf%3Fid%3DBOorDpKHiJ", "details": "G Cui, L Yuan, N Ding, G Yao, B He, W Zhu, Y Ni, G Xie\u2026 - Forty-first International Conference \u2026", "abstract": "Learning from human feedback has become a pivot technique in aligning large language models (LLMs) with human preferences. However, acquiring vast and premium human feedback is bottlenecked by time, labor, and human capability \u2026"}, {"title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2405.18218", "details": "Y Zhang, Y Li, X Wang, Q Shen, B Plank, B Bischl\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Overparametrized transformer networks are the state-of-the-art architecture for Large Language Models (LLMs). However, such models contain billions of parameters making large compute a necessity, while raising environmental concerns. To \u2026"}, {"title": "Enhancing Storage and Computational Efficiency in Federated Multimodal Learning for Large-Scale Models", "link": "https://openreview.net/pdf%3Fid%3DQgvBcOsF4B", "details": "Z Zhang, F Qi, C Xu - Forty-first International Conference on Machine \u2026", "abstract": "The remarkable generalization of large-scale models has recently gained significant attention in multimodal research. However, deploying heterogeneous large-scale models with different modalities under Federated Learning (FL) to protect data \u2026"}, {"title": "From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR", "link": "https://www.cs.emory.edu/~jyang71/files/hypehr-pf.pdf", "details": "R Xu, Y Lu, C Liu, Y Chen, Y Sun, X Hu, JC Ho, C Yang - Proceedings of Machine \u2026, 2024", "abstract": "Abstract Electronic Health Records (EHRs) contain rich patient information and are crucial for clinical research and practice. In recent years, deep learning models have been applied to EHRs, but they often rely on massive features, which may not be \u2026"}, {"title": "LCS: A Language Converter Strategy for Zero-Shot Neural Machine Translation", "link": "https://arxiv.org/pdf/2406.02876", "details": "Z Sun, Y Liu, F Meng, J Xu, Y Chen, J Zhou - arXiv e-prints, 2024", "abstract": "Multilingual neural machine translation models generally distinguish translation directions by the language tag (LT) in front of the source or target sentences. However, current LT strategies cannot indicate the desired target language as \u2026"}, {"title": "Revisiting Pre-training of Embedding Layers in Transformer-based Neural Machine Translation", "link": "https://www.jstage.jst.go.jp/article/jnlp/31/2/31_534/_pdf", "details": "M Neishi, N Yoshinaga - Journal of Natural Language Processing, 2024", "abstract": "Recent trends in the pre-training and fine-tuning paradigm have made significant advances in several natural language processing tasks, including machine translation (MT), particularly for low-resource situations. However, it is reported that \u2026"}, {"title": "Exploring and Mitigating Shortcut Learning for Generative Large Language Models", "link": "https://aclanthology.org/2024.lrec-main.602.pdf", "details": "Z Sun, Y Xiao, J Li, Y Ji, W Chen, M Zhang - Proceedings of the 2024 Joint \u2026, 2024", "abstract": "Recent generative large language models (LLMs) have exhibited incredible instruction-following capabilities while keeping strong task completion ability, even without task-specific fine-tuning. Some works attribute this to the bonus of the new \u2026"}, {"title": "Benchmarking Vision-Language Contrastive Methods for Medical Representation Learning", "link": "https://arxiv.org/pdf/2406.07450", "details": "S Roy, Y Parhizkar, F Ogidi, VR Khazaie, M Colacci\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We perform a comprehensive benchmarking of contrastive frameworks for learning multimodal representations in the medical domain. Through this study, we aim to answer the following research questions:(i) How transferable are general-domain \u2026"}]
