[{"title": "KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models", "link": "https://arxiv.org/pdf/2408.03297", "details": "R Zhang, Y Xu, Y Xiao, R Zhu, X Jiang, X Chu, J Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "By integrating external knowledge, Retrieval-Augmented Generation (RAG) has become an effective strategy for mitigating the hallucination problems that large language models (LLMs) encounter when dealing with knowledge-intensive tasks \u2026"}, {"title": "Comparing Pre-trained Human Language Models: Is it Better with Human Context as Groups, Individual Traits, or Both?", "link": "https://aclanthology.org/2024.wassa-1.26.pdf", "details": "N Soni, N Balasubramanian, H Schwartz, D Hovy - Proceedings of the 14th Workshop \u2026, 2024", "abstract": "Pre-trained language models consider the context of neighboring words and documents but lack any author context of the human generating the text. However, language depends on the author's states, traits, social, situational, and \u2026"}, {"title": "Reinforcement Learning-Driven LLM Agent for Automated Attacks on LLMs", "link": "https://aclanthology.org/2024.privatenlp-1.17.pdf", "details": "X Wang, J Peng, K Xu, H Yao, T Chen - Proceedings of the Fifth Workshop on Privacy \u2026, 2024", "abstract": "Recently, there has been a growing focus on conducting attacks on large language models (LLMs) to assess LLMs' safety. Yet, existing attack methods face challenges, including the need to access model weights or merely ensuring LLMs output harmful \u2026"}, {"title": "Hierarchical syntactic structure in human-like language models", "link": "https://aclanthology.org/2024.cmcl-1.6.pdf", "details": "M Wolfman, D Dunagan, J Brennan, J Hale - \u2026 of the Workshop on Cognitive Modeling \u2026, 2024", "abstract": "Abstract Language models (LMs) are a meeting point for cognitive modeling and computational linguistics. How should they be designed to serve as adequate cognitive models? To address this question, this study contrasts two Transformer \u2026"}, {"title": "EXAONE 3.0 7.8 B Instruction Tuned Language Model", "link": "https://arxiv.org/pdf/2408.03541", "details": "LG Research, S An, K Bae, E Choi, SJ Choi, Y Choi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce EXAONE 3.0 instruction-tuned language model, the first open model in the family of Large Language Models (LLMs) developed by LG AI Research. Among different model sizes, we publicly release the 7.8 B instruction-tuned model to \u2026"}, {"title": "Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement", "link": "https://arxiv.org/pdf/2408.03092", "details": "L Yu, B Yu, H Yu, F Huang, Y Li - arXiv preprint arXiv:2408.03092, 2024", "abstract": "Merging Large Language Models (LLMs) aims to amalgamate multiple homologous LLMs into one with all the capabilities. Ideally, any LLMs sharing the same backbone should be mergeable, irrespective of whether they are Fine-Tuned (FT) with minor \u2026"}, {"title": "Fine-tuning language models for joint rewriting and completion of code with potential bugs", "link": "https://www.amazon.science/publications/fine-tuning-language-models-for-joint-rewriting-and-completion-of-code-with-potential-bugs", "details": "D Wang, J Zhao, H Pei, S Tan, S Zha - 2024", "abstract": "Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs \u2026"}, {"title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models", "link": "https://arxiv.org/pdf/2408.02416", "details": "Z Liang, H Hu, Q Ye, Y Xiao, H Li - arXiv preprint arXiv:2408.02416, 2024", "abstract": "The drastic increase of large language models'(LLMs) parameters has led to a new research direction of fine-tuning-free downstream customization by prompts, ie, task descriptions. While these prompt-based services (eg OpenAI's GPTs) play an \u2026"}, {"title": "Fine-tuning Language Models for Triple Extraction with Data Augmentation", "link": "https://aclanthology.org/2024.kallm-1.12.pdf", "details": "Y Zhang, T Sadler, MR Taesiri, W Xu, M Reformat - Proceedings of the 1st Workshop \u2026, 2024", "abstract": "Advanced language models with impressive capabilities to process textual information can more effectively extract high-quality triples, which are the building blocks of knowledge graphs. Our work examines language models' abilities to extract \u2026"}]
