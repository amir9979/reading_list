[{"title": "Privacy preserving strategies for electronic health records in the era of large language models", "link": "https://www.nature.com/articles/s41746-025-01429-0", "details": "J Jonnagaddala, ZSY Wong - npj Digital Medicine, 2025", "abstract": "Electronic health records (EHRs) secondary usage with large language models (LLMs) raise privacy challenges. National regulations like GDPR and HIPAA offer protection frameworks, but specific strategies are needed to mitigate risk in \u2026"}, {"title": "Toward a Computable Phenotype for Determining Eligibility of Lung Cancer Screening Using Electronic Health Records", "link": "https://ascopubs.org/doi/pdfdirect/10.1200/CCI.24.00139", "details": "S Yang, Y Huang, X Lou, T Lyu, R Wei, HJ Mehta, Y Wu\u2026 - JCO Clinical Cancer \u2026, 2025", "abstract": "PURPOSE Lung cancer screening (LCS) has the potential to reduce mortality and detect lung cancer at its early stages, but the high false-positive rate associated with low-dose computed tomography (LDCT) for LCS acts as a barrier to its widespread \u2026"}, {"title": "A machine learning approach to leveraging electronic health records for enhanced omics analysis", "link": "https://www.nature.com/articles/s42256-024-00974-9", "details": "SJ Mataraso, CA Espinosa, D Seong, SM Reincke\u2026 - Nature Machine Intelligence, 2025", "abstract": "Omics studies produce a large number of measurements, enabling the development, validation and interpretation of systems-level biological models. Large cohorts are required to power these complex models; yet, the cohort size remains limited due to \u2026"}, {"title": "ChartAdapter: Large Vision-Language Model for Chart Summarization", "link": "https://arxiv.org/pdf/2412.20715", "details": "P Xu, Y Ding, W Fan - arXiv preprint arXiv:2412.20715, 2024", "abstract": "Chart summarization, which focuses on extracting key information from charts and interpreting it in natural language, is crucial for generating and delivering insights through effective and accessible data analysis. Traditional methods for chart \u2026"}, {"title": "Technical Report: Small Language Model for Japanese Clinical and Medicine", "link": "https://arxiv.org/pdf/2412.16423", "details": "S Watanabe - arXiv preprint arXiv:2412.16423, 2024", "abstract": "This report presents a small language model (SLM) for Japanese clinical and medicine, named NCVC-slm-1. This 1B parameters model was trained using Japanese text classified to be of high-quality. Moreover, NCVC-slm-1 was \u2026"}]
