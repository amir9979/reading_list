[{"title": "Foundation Model of Electronic Medical Records for Adaptive Risk Estimation", "link": "https://arxiv.org/pdf/2502.06124", "details": "P Renc, MK Grzeszczyk, N Oufattole, D Goode, Y Jia\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS), an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS predicts future PHTs using transformer-based architectures. The Adaptive Risk \u2026"}, {"title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "link": "https://arxiv.org/pdf/2502.05142", "details": "Z Yang, X Xu, J Zhang, G Wang, MK Kalra, P Yan - arXiv preprint arXiv:2502.05142, 2025", "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data \u2026"}, {"title": "A Data-Efficient Pan-Tumor Foundation Model for Oncology CT Interpretation", "link": "https://arxiv.org/pdf/2502.06171", "details": "W Lei, H Chen, Z Zhang, L Luo, Q Xiao, Y Gu, P Gao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Artificial intelligence-assisted imaging analysis has made substantial strides in tumor diagnosis and management. Here we present PASTA, a pan-tumor CT foundation model that achieves state-of-the-art performance on 45 of 46 representative \u2026"}, {"title": "EVEv2: Improved Baselines for Encoder-Free Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06788", "details": "H Diao, X Li, Y Cui, Y Wang, H Deng, T Pan, W Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing encoder-free vision-language models (VLMs) are rapidly narrowing the performance gap with their encoder-based counterparts, highlighting the promising potential for unified multimodal systems with structural simplicity and efficient \u2026"}, {"title": "DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control", "link": "https://arxiv.org/pdf/2502.05855", "details": "J Wen, Y Zhu, J Li, Z Tang, C Shen, F Feng - arXiv preprint arXiv:2502.05855, 2025", "abstract": "Enabling robots to perform diverse tasks across varied environments is a central challenge in robot learning. While vision-language-action (VLA) models have shown promise for generalizable robot skills, realizing their full potential requires \u2026"}, {"title": "Retrieving Filter Spectra in CNN for Explainable Sleep Stage Classification", "link": "https://arxiv.org/pdf/2502.06478", "details": "S Goerttler, Y Wang, E Eldele, F He, M Wu - arXiv preprint arXiv:2502.06478, 2025", "abstract": "Despite significant advances in deep learning-based sleep stage classification, the clinical adoption of automatic classification models remains slow. One key challenge is the lack of explainability, as many models function as black boxes with millions of \u2026"}, {"title": "Large Language Models and Large Multimodal Models in Medical Imaging: A Primer for Physicians", "link": "https://jnm.snmjournals.org/content/66/2/173.abstract", "details": "TJ Bradshaw, X Tie, J Warner, J Hu, Q Li, X Li - Journal of Nuclear Medicine, 2025", "abstract": "Large language models (LLMs) are poised to have a disruptive impact on health care. Numerous studies have demonstrated promising applications of LLMs in medical imaging, and this number will grow as LLMs further evolve into large \u2026"}]
