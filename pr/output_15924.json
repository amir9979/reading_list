[{"title": "AutoSSVH: Exploring Automated Frame Sampling for Efficient Self-Supervised Video Hashing", "link": "https://arxiv.org/pdf/2504.03587", "details": "N Lian, J Li, J Wang, R Luo, Y Wang, ST Xia, B Chen - arXiv preprint arXiv \u2026, 2025", "abstract": "Self-Supervised Video Hashing (SSVH) compresses videos into hash codes for efficient indexing and retrieval using unlabeled training videos. Existing approaches rely on random frame sampling to learn video features and treat all frames equally \u2026"}, {"title": "MambaMIM: Pre-training Mamba with state space token interpolation and its application to medical image segmentation", "link": "https://www.sciencedirect.com/science/article/pii/S1361841525001537", "details": "F Tang, B Nian, Y Li, Z Jiang, J Yang, W Liu, SK Zhou - Medical Image Analysis, 2025", "abstract": "Recently, the state space model Mamba has demonstrated efficient long-sequence modeling capabilities, particularly for addressing long-sequence visual tasks in 3D medical imaging. However, existing generative self-supervised learning methods \u2026"}, {"title": "Automated Learning of Semantic Embedding Representations for Diffusion Models", "link": "https://epubs.siam.org/doi/pdf/10.1137/1.9781611978520.1", "details": "L Jiang, Y Cai - Proceedings of the 2025 SIAM International \u2026, 2025", "abstract": "Generative models capture the true distribution of data, yielding semantically rich representations. Denoising diffusion models (DDMs) exhibit superior generative capabilities, though efficient representation learning for them are lacking. In this \u2026"}, {"title": "REJEPA: A Novel Joint-Embedding Predictive Architecture for Efficient Remote Sensing Image Retrieval", "link": "https://arxiv.org/pdf/2504.03169", "details": "S Choudhury, Y Salunkhe, S Mehrotra, B Banerjee - arXiv preprint arXiv:2504.03169, 2025", "abstract": "The rapid expansion of remote sensing image archives demands the development of strong and efficient techniques for content-based image retrieval (RS-CBIR). This paper presents REJEPA (Retrieval with Joint-Embedding Predictive Architecture), an \u2026"}, {"title": "The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer", "link": "https://arxiv.org/pdf/2504.10462", "details": "W Lei, J Wang, H Wang, X Li, JH Liew, J Feng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces SAIL, a single transformer unified multimodal large language model (MLLM) that integrates raw pixel encoding and language decoding within a singular architecture. Unlike existing modular MLLMs, which rely on a pre-trained \u2026"}, {"title": "Multiview Point Cloud Registration via Optimization in an Autoencoder Latent Space", "link": "https://arxiv.org/pdf/2504.21467", "details": "L Vedrenne, S Faisan, D Fortun - arXiv preprint arXiv:2504.21467, 2025", "abstract": "Point cloud rigid registration is a fundamental problem in 3D computer vision. In the multiview case, we aim to find a set of 6D poses to align a set of objects. Methods based on pairwise registration rely on a subsequent synchronization algorithm \u2026"}]
