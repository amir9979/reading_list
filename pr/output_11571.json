[{"title": "Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models", "link": "https://arxiv.org/pdf/2501.04945", "details": "Q Ren, J Zeng, Q He, J Liang, Y Xiao, W Zhou, Z Sun\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "It is crucial for large language models (LLMs) to follow instructions that involve multiple constraints. However, soft constraints are semantically related and difficult to verify through automated methods. These constraints remain a significant challenge \u2026"}, {"title": "Dynamic Skill Adaptation for Large Language Models", "link": "https://arxiv.org/pdf/2412.19361%3F", "details": "J Chen, D Yang - arXiv preprint arXiv:2412.19361, 2024", "abstract": "We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework to adapt novel and complex skills to Large Language Models (LLMs). Compared with previous work which learns from human-curated and static data in random orders \u2026"}, {"title": "Physics Reasoner: Knowledge-Augmented Reasoning for Solving Physics Problems with Large Language Models", "link": "https://arxiv.org/pdf/2412.13791", "details": "X Pang, R Hong, Z Zhou, F Lv, X Yang, Z Liang, B Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Physics problems constitute a significant aspect of reasoning, necessitating complicated reasoning ability and abundant physics knowledge. However, existing large language models (LLMs) frequently fail due to a lack of knowledge or incorrect \u2026"}, {"title": "How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models", "link": "https://arxiv.org/pdf/2501.01741", "details": "S Corbo, L Bancale, V De Gennaro, L Lestingi, V Scotti\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Language is a deep-rooted means of perpetration of stereotypes and discrimination. Large Language Models (LLMs), now a pervasive technology in our everyday lives, can cause extensive harm when prone to generating toxic responses. The standard \u2026"}, {"title": "Analyzing Memorization in Large Language Models through the Lens of Model Attribution", "link": "https://arxiv.org/pdf/2501.05078", "details": "TR Menta, S Agrawal, C Agarwal - arXiv preprint arXiv:2501.05078, 2025", "abstract": "Large Language Models (LLMs) are prevalent in modern applications but often memorize training data, leading to privacy breaches and copyright issues. Existing research has mainly focused on posthoc analyses, such as extracting memorized \u2026"}, {"title": "CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models", "link": "https://arxiv.org/pdf/2501.05255", "details": "Y Song, C Lothritz, X Tang, S Ezzini, J Klein\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Interacting with a software system via a chatbot can be challenging, especially when the chatbot needs to generate API calls, in the right order and with the right parameters, to communicate with the system. API calling in chatbot systems poses \u2026"}, {"title": "LLM+ AL: Bridging Large Language Models and Action Languages for Complex Reasoning about Actions", "link": "https://arxiv.org/pdf/2501.00830", "details": "A Ishay, J Lee - arXiv preprint arXiv:2501.00830, 2025", "abstract": "Large Language Models (LLMs) have made significant strides in various intelligent tasks but still struggle with complex action reasoning tasks that require systematic search. To address this limitation, we propose a method that bridges the natural \u2026"}, {"title": "Adaptive Pruning for Large Language Models with Structural Importance Awareness", "link": "https://arxiv.org/pdf/2412.15127", "details": "H Zheng, J Ren, Y Sun, R Zhang, W Zhang, Z Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The recent advancements in large language models (LLMs) have significantly improved language understanding and generation capabilities. However, it is difficult to deploy LLMs on resource-constrained edge devices due to their high \u2026"}, {"title": "InfAlign: Inference-aware language model alignment", "link": "https://arxiv.org/pdf/2412.19792%3F", "details": "A Balashankar, Z Sun, J Berant, J Eisenstein, M Collins\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model alignment has become a critical step in training modern generative language models. The goal of alignment is to finetune a reference model such that the win rate of a sample from the aligned model over a sample from the reference \u2026"}]
