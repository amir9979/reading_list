[{"title": "Identifying and Mitigating Social Bias Knowledge in Language Models", "link": "https://aclanthology.org/2025.findings-naacl.39.pdf", "details": "R Chen, Y Li, J Yang, Y Feng, JT Zhou, J Wu, Z Liu - Findings of the Association for \u2026, 2025", "abstract": "Generating fair and accurate predictions plays a pivotal role in deploying pre-trained language models (PLMs) in the real world. However, existing debiasing methods may inevitably generate incorrect or nonsensical predictions as they are designed \u2026"}, {"title": "Optimizing Hidden Markov Language Models: An Empirical Study of Reparameterization and Initialization Techniques", "link": "https://aclanthology.org/2025.findings-naacl.429.pdf", "details": "I Lee, T Berg-Kirkpatrick - Findings of the Association for Computational \u2026, 2025", "abstract": "Abstract Hidden Markov models (HMMs) are valuable for their ability to provide exact and tractable inference. However, learning an HMM in an unsupervised manner involves a non-convex optimization problem that is plagued by poor local optima \u2026"}, {"title": "Atoxia: Red-teaming Large Language Models with Target Toxic Answers", "link": "https://aclanthology.org/2025.findings-naacl.179.pdf", "details": "Y Du, Z Li, P Cheng, X Wan, A Gao - Findings of the Association for Computational \u2026, 2025", "abstract": "Despite the substantial advancements in artificial intelligence, large language models (LLMs) remain being challenged by generation safety. With adversarial jailbreaking prompts, one can effortlessly induce LLMs to output harmful content \u2026"}, {"title": "Insightbuddy-ai: Medication extraction and entity linking using pre-trained language models and ensemble learning", "link": "https://aclanthology.org/2025.naacl-srw.2.pdf", "details": "P Romero, L Han, G Nenadic - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "This paper presents our system, InsightBuddy-AI, designed for extracting medication mentions and their associated attributes, and for linking these entities to established clinical terminology resources, including SNOMED-CT, the British National \u2026"}, {"title": "Platonic Grounding for Efficient Multimodal Language Models", "link": "https://arxiv.org/pdf/2504.19327", "details": "M Choraria, X Wu, A Bhimaraju, N Sekhar, Y Wu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The hyperscaling of data and parameter count in Transformer-based models is yielding diminishing performance improvement, especially when weighed against training costs. Such plateauing indicates the importance of methods for more efficient \u2026"}, {"title": "Toward Generalizable Evaluation in the LLM Era: A Survey Beyond Benchmarks", "link": "https://arxiv.org/pdf/2504.18838", "details": "Y Cao, S Hong, X Li, J Ying, Y Ma, H Liang, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) are advancing at an amazing speed and have become indispensable across academia, industry, and daily applications. To keep pace with the status quo, this survey probes the core challenges that the rise of LLMs \u2026"}, {"title": "VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning", "link": "https://arxiv.org/pdf/2504.19627", "details": "R Luo, R Shan, L Chen, Z Liu, L Wang, M Yang, X Xia - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like embodied intelligence due to their strong vision-language reasoning abilities. However, current LVLMs process entire images at the token level, which is inefficient \u2026"}, {"title": "Biases in Opinion Dynamics in Multi-Agent Systems of Large Language Models: A Case Study on Funding Allocation", "link": "https://aclanthology.org/2025.findings-naacl.101.pdf", "details": "P Cisneros-Velarde - Findings of the Association for Computational \u2026, 2025", "abstract": "We study the evolution of opinions inside a population of interacting large language models (LLMs). Every LLM needs to decide how much funding to allocate to an item with three initial possibilities: full, partial, or no funding. We identify biases that drive \u2026"}, {"title": "Where is the answer? An empirical study of positional bias for parametric knowledge extraction in language model", "link": "https://aclanthology.org/2025.naacl-long.58.pdf", "details": "K Saito, CY Lee, K Sohn, Y Ushiku - Proceedings of the 2025 Conference of the \u2026, 2025", "abstract": "Abstract Language model (LM) stores diverse factual knowledge in their parameters, which is learned during self-supervised training on unlabeled documents and is made extractable by instruction-tuning. For knowledge-intensive tasks, it is essential \u2026"}]
