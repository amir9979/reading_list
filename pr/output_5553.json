[{"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "Understanding the Interplay of Scale, Data, and Bias in Language Models: A Case Study with BERT", "link": "https://arxiv.org/pdf/2407.21058", "details": "M Ali, S Panda, Q Shen, M Wick, A Kobren - arXiv preprint arXiv:2407.21058, 2024", "abstract": "In the current landscape of language model research, larger models, larger datasets and more compute seems to be the only way to advance towards intelligence. While there have been extensive studies of scaling laws and models' scaling behaviors, the \u2026"}, {"title": "Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models", "link": "https://arxiv.org/pdf/2407.20271", "details": "H Tang, Y Liu, X Liu, K Zhang, Y Zhang, Q Liu, E Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in machine learning, especially in Natural Language Processing (NLP), have led to the development of sophisticated models trained on vast datasets, but this progress has raised concerns about potential sensitive \u2026"}, {"title": "Goldfish: Monolingual Language Models for 350 Languages", "link": "https://arxiv.org/pdf/2408.10441", "details": "TA Chang, C Arnett, Z Tu, BK Bergen - arXiv preprint arXiv:2408.10441, 2024", "abstract": "For many low-resource languages, the only available language models are large multilingual models trained on many languages simultaneously. However, using FLORES perplexity as a metric, we find that these models perform worse than \u2026"}, {"title": "Enhancing One-shot Pruned Pre-trained Language Models through Sparse-Dense-Sparse Mechanism", "link": "https://arxiv.org/pdf/2408.10473", "details": "G Li, X Zhao, L Liu, Z Li, D Li, L Tian, J He, A Sirasao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained language models (PLMs) are engineered to be robust in contextual understanding and exhibit outstanding performance in various natural language processing tasks. However, their considerable size incurs significant computational \u2026"}, {"title": "Physician experiences of electronic health records interoperability and its practical impact on care delivery in the English NHS: A cross-sectional survey study", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/07/26/2024.07.25.24311018.full.pdf", "details": "E Li, O Lounsbury, M Hasnain, H Ashrafian, A Darzi\u2026 - medRxiv, 2024", "abstract": "Background: The lack of interoperability has been a well-recognised limitation associated with the use of electronic health records (EHR). However, less is known about how it manifests for frontline NHS staff when delivering care, how it impacts \u2026"}, {"title": "Boosting entity recognition by leveraging cross-task domain models for weak supervision", "link": "https://www.amazon.science/publications/boosting-entity-recognition-by-leveraging-cross-task-domain-models-for-weak-supervision", "details": "S Agrawal, S Merugu, V Sembium - 2024", "abstract": "Entity Recognition (ER) is a common natural language processing task encountered in a number of real-world applications. For common domains and named entities such as places and organisations, there exists sufficient high quality annotated data \u2026"}, {"title": "Contrastive Learning on Medical Intents for Sequential Prescription Recommendation", "link": "https://arxiv.org/pdf/2408.10259", "details": "AH Moghaddam, MN Kerdabadi, M Liu, Z Yao - arXiv preprint arXiv:2408.10259, 2024", "abstract": "Recent advancements in sequential modeling applied to Electronic Health Records (EHR) have greatly influenced prescription recommender systems. While the recent literature on drug recommendation has shown promising performance, the study of \u2026"}, {"title": "Enhancing Genetic Risk Prediction Through Federated Semi-supervised Transfer Learning with Inaccurate Electronic Health Record Data", "link": "https://link.springer.com/article/10.1007/s12561-024-09449-2", "details": "Y Lu, T Gu, R Duan - Statistics in Biosciences, 2024", "abstract": "Large-scale genomics data combined with Electronic Health Records (EHRs) illuminate the path towards personalized disease management and enhanced medical interventions. However, the absence of \u201cgold standard\u201d disease labels \u2026"}]
