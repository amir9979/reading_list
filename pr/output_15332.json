[{"title": "Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models", "link": "https://arxiv.org/pdf/2503.15888", "details": "B Bi, S Liu, Y Wang, Y Xu, J Fang, L Mei, X Cheng - arXiv preprint arXiv:2503.15888, 2025", "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucinations in Large Language Models (LLMs) by integrating external knowledge. However, conflicts between parametric knowledge and retrieved context pose challenges, particularly when \u2026"}, {"title": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models", "link": "https://arxiv.org/pdf/2503.18923", "details": "M Cao, P Hu, Y Wang, J Gu, H Tang, H Zhao, J Dong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we \u2026"}, {"title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation", "link": "https://arxiv.org/pdf/2504.02438", "details": "C Cheng, J Guan, W Wu, R Yan - arXiv preprint arXiv:2504.02438, 2025", "abstract": "Long-form video processing fundamentally challenges vision-language models (VLMs) due to the high computational costs of handling extended temporal sequences. Existing token pruning and feature merging methods often sacrifice \u2026"}, {"title": "CoMP: Continual Multimodal Pre-training for Vision Foundation Models", "link": "https://arxiv.org/pdf/2503.18931", "details": "Y Chen, L Meng, W Peng, Z Wu, YG Jiang - arXiv preprint arXiv:2503.18931, 2025", "abstract": "Pre-trained Vision Foundation Models (VFMs) provide strong visual representations for a wide range of applications. In this paper, we continually pre-train prevailing VFMs in a multimodal manner such that they can effortlessly process visual inputs of \u2026"}, {"title": "Breaking the Encoder Barrier for Seamless Video-Language Understanding", "link": "https://arxiv.org/pdf/2503.18422", "details": "H Li, Y Zhang, L Guo, X Yue, J Liu - arXiv preprint arXiv:2503.18422, 2025", "abstract": "Most Video-Large Language Models (Video-LLMs) adopt an encoder-decoder framework, where a vision encoder extracts frame-wise features for processing by a language model. However, this approach incurs high computational costs \u2026"}, {"title": "ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection", "link": "https://arxiv.org/pdf/2504.00695", "details": "X Zhu, Z Gu, S Zheng, T Wang, T Li, H Feng, Y Xiao - arXiv preprint arXiv:2504.00695, 2025", "abstract": "Pre-training large language models (LLMs) necessitates enormous diverse textual corpora, making effective data selection a key challenge for balancing computational resources and model performance. Current methodologies primarily emphasize data \u2026"}, {"title": "RRGMambaFormer: A hybrid Transformer-Mamba architecture for radiology report generation", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425010413", "details": "H Li, S Liu, H Wang, X Jiang, M Jiu, L Chen, Y Lu, S Li\u2026 - Expert Systems with \u2026, 2025", "abstract": "Radiology report generation (RRG) is a critical yet time-consuming task in clinical practice, requiring a high level of expertise to ensure accuracy. Automating this process using generative AI has the potential to significantly enhance efficiency and \u2026"}, {"title": "Slow-Fast Architecture for Video Multi-Modal Large Language Models", "link": "https://arxiv.org/pdf/2504.01328", "details": "M Shi, S Wang, CY Chen, J Jain, K Wang, J Xiong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Balancing temporal resolution and spatial detail under limited compute budget remains a key challenge for video-based multi-modal large language models (MLLMs). Existing methods typically compress video representations using \u2026"}, {"title": "Uncertainty Quantification and Confidence Calibration in Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2503.15850", "details": "X Liu, T Chen, L Da, C Chen, Z Lin, H Wei - arXiv preprint arXiv:2503.15850, 2025", "abstract": "Large Language Models (LLMs) excel in text generation, reasoning, and decision- making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce \u2026"}]
