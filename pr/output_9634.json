[{"title": "Large language models for extracting histopathologic diagnoses from electronic health records", "link": "https://www.medrxiv.org/content/10.1101/2024.11.27.24318083.full.pdf", "details": "B Johnson, T Bath, X Huang, M Lamm, A Earles\u2026 - medRxiv, 2024", "abstract": "Background & Aims Accurate data resources are essential for impactful medical research. To date, most large-scale studies have relied on structured sources, such as International Classification of Diseases codes, to determine patient diagnoses \u2026"}, {"title": "Joint Vision-Language Social Bias Removal for CLIP", "link": "https://arxiv.org/pdf/2411.12785", "details": "H Zhang, Y Guo, M Kankanhalli - arXiv preprint arXiv:2411.12785, 2024", "abstract": "Vision-Language (VL) pre-trained models such as CLIP show prominent capabilities in various downstream tasks. Despite this promise, VL models are notoriously limited by their inherent social biases. A typical demonstration is that VL models often \u2026"}, {"title": "AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset", "link": "https://arxiv.org/pdf/2411.15640", "details": "T Olatunji, C Nimo, A Owodunni, T Abdullahi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in large language model (LLM) performance on medical multiple choice question (MCQ) benchmarks have stimulated interest from healthcare providers and patients globally. Particularly in low-and middle-income \u2026"}]
