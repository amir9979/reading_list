[{"title": "CARE-SD: classifier-based analysis for recognizing provider stigmatizing and doubt marker labels in electronic health records: model development and validation", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae310/7933303", "details": "A Walker, A Thorne, S Das, J Love, HLF Cooper\u2026 - Journal of the American Medical \u2026", "abstract": "Objective To detect and classify features of stigmatizing and biased language in intensive care electronic health records (EHRs) using natural language processing techniques. Materials and Methods We first created a lexicon and regular expression \u2026"}, {"title": "VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models", "link": "https://arxiv.org/pdf/2412.01822", "details": "BK Lee, R Hachiuma, YCF Wang, YM Ro, YH Wu - arXiv preprint arXiv:2412.01822, 2024", "abstract": "The recent surge in high-quality visual instruction tuning samples from closed-source vision-language models (VLMs) such as GPT-4V has accelerated the release of open-source VLMs across various model sizes. However, scaling VLMs to improve \u2026"}, {"title": "Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual Language Models from Southeast Asia", "link": "https://arxiv.org/pdf/2412.07303", "details": "LCL Gamboa, M Lee - arXiv preprint arXiv:2412.07303, 2024", "abstract": "Bias studies on multilingual models confirm the presence of gender-related stereotypes in masked models processing languages with high NLP resources. We expand on this line of research by introducing Filipino CrowS-Pairs and Filipino \u2026"}, {"title": "Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective", "link": "https://arxiv.org/pdf/2412.00554", "details": "Y Zhou, B Di Eugenio, L Cheng - arXiv preprint arXiv:2412.00554, 2024", "abstract": "This paper studies the performance of large language models (LLMs), particularly regarding demographic fairness, in solving real-world healthcare tasks. We evaluate state-of-the-art LLMs with three prevalent learning frameworks across six diverse \u2026"}, {"title": "Advancing Myopia To Holism: Fully Contrastive Language-Image Pre-training", "link": "https://arxiv.org/pdf/2412.00440", "details": "H Wang, C Ju, W Lin, S Xiao, M Chen, Y Huang, C Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In rapidly evolving field of vision-language models (VLMs), contrastive language- image pre-training (CLIP) has made significant strides, becoming foundation for various downstream tasks. However, relying on one-to-one (image, text) contrastive \u2026"}]
