[{"title": "Leveraging Self Weak-supervision for Improved VLM Performance", "link": "https://openreview.net/pdf%3Fid%3DksjzXcHdle", "details": "S Roy, A Etemad - Adaptive Foundation Models: Evolving AI for \u2026", "abstract": "In this work, we present SelfPrompt, a novel semi-supervised prompt-tuning approach for tuning vision-language models (VLMs) in a semi-supervised learning setup. Existing methods for tuning VLMs in semi-supervised setup struggle with the \u2026"}, {"title": "CALAMITA: Challenge the Abilities of LAnguage Models in ITAlian", "link": "https://clic2024.ilc.cnr.it/wp-content/uploads/2024/12/116_calamita_preface_long.pdf", "details": "G Attanasio, P Basile, F Borazio, D Croce, M Francis\u2026 - Proceedings of the 10th \u2026, 2024", "abstract": "The rapid development of Large Language Models (LLMs) has called for robust benchmarks to assess their abilities, track progress, and compare iterations. While existing benchmarks provide extensive evaluations across diverse tasks, they \u2026"}, {"title": "BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices", "link": "https://arxiv.org/pdf/2411.10640", "details": "X Lu, Y Chen, C Chen, H Tan, B Chen, Y Xie, R Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence and growing popularity of multimodal large language models (MLLMs) have significant potential to enhance various aspects of daily life, from improving communication to facilitating learning and problem-solving. Mobile \u2026"}]
