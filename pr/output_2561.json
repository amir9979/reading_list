[{"title": "Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective", "link": "https://arxiv.org/pdf/2405.16747", "details": "A Tomihari, I Sato - arXiv preprint arXiv:2405.16747, 2024", "abstract": "The two-stage fine-tuning (FT) method, linear probing then fine-tuning (LP-FT), consistently outperforms linear probing (LP) and FT alone in terms of accuracy for both in-distribution (ID) and out-of-distribution (OOD) data. This success is largely \u2026"}, {"title": "What Makes Good Few-shot Examples for Vision-Language Models?", "link": "https://arxiv.org/pdf/2405.13532", "details": "Z Guo, J Lu, X Liu, R Zhao, ZX Qian, F Tan - arXiv preprint arXiv:2405.13532, 2024", "abstract": "Despite the notable advancements achieved by leveraging pre-trained vision- language (VL) models through few-shot tuning for downstream tasks, our detailed empirical study highlights a significant dependence of few-shot learning outcomes \u2026"}, {"title": "Data Fusion for Heterogeneous Treatment Effect Estimation with Multi-Task Gaussian Processes", "link": "https://arxiv.org/pdf/2405.20957", "details": "E Dimitriou, E Fong, K Diaz-Ordaz, B Lehmann - arXiv preprint arXiv:2405.20957, 2024", "abstract": "Bridging the gap between internal and external validity is crucial for heterogeneous treatment effect estimation. Randomised controlled trials (RCTs), favoured for their internal validity due to randomisation, often encounter challenges in generalising \u2026"}, {"title": "Theoretical Analysis of Meta Reinforcement Learning: Generalization Bounds and Convergence Guarantees", "link": "https://arxiv.org/pdf/2405.13290", "details": "C Wang, M Sui, D Sun, Z Zhang, Y Zhou - arXiv preprint arXiv:2405.13290, 2024", "abstract": "This research delves deeply into Meta Reinforcement Learning (Meta RL) through a exploration focusing on defining generalization limits and ensuring convergence. By employing a approach this article introduces an innovative theoretical framework to \u2026"}, {"title": "Exploring and Mitigating Shortcut Learning for Generative Large Language Models", "link": "https://aclanthology.org/2024.lrec-main.602.pdf", "details": "Z Sun, Y Xiao, J Li, Y Ji, W Chen, M Zhang - Proceedings of the 2024 Joint \u2026, 2024", "abstract": "Recent generative large language models (LLMs) have exhibited incredible instruction-following capabilities while keeping strong task completion ability, even without task-specific fine-tuning. Some works attribute this to the bonus of the new \u2026"}, {"title": "A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks", "link": "https://arxiv.org/pdf/2405.10251", "details": "X Ni, P Li - arXiv preprint arXiv:2405.10251, 2024", "abstract": "Recent efforts have evaluated large language models (LLMs) in areas such as commonsense reasoning, mathematical reasoning, and code generation. However, to the best of our knowledge, no work has specifically investigated the performance \u2026"}, {"title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?", "link": "https://arxiv.org/pdf/2405.16908", "details": "G Yona, R Aharoni, M Geva - arXiv preprint arXiv:2405.16908, 2024", "abstract": "We posit that large language models (LLMs) should be capable of expressing their intrinsic uncertainty in natural language. For example, if the LLM is equally likely to output two contradicting answers to the same question, then its generated response \u2026"}, {"title": "BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation", "link": "https://arxiv.org/pdf/2405.17039", "details": "C Jia, P Wang, Z Li, YC Li, Z Zhang, N Tang, Y Yu - arXiv preprint arXiv:2405.17039, 2024", "abstract": "Large language models (LLMs) have catalyzed a paradigm shift in natural language processing, yet their limited controllability poses a significant challenge for downstream applications. We aim to address this by drawing inspiration from the \u2026"}, {"title": "Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models", "link": "https://arxiv.org/pdf/2405.16833", "details": "CY Hsu, YL Tsai, CH Lin, PY Chen, CM Yu, CY Huang - arXiv preprint arXiv \u2026, 2024", "abstract": "While large language models (LLMs) such as Llama-2 or GPT-4 have shown impressive zero-shot performance, fine-tuning is still necessary to enhance their performance for customized datasets, domain-specific tasks, or other private needs \u2026"}]
