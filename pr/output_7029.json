[{"title": "Harnessing the Intrinsic Knowledge of Pretrained Language Models for Challenging Text Classification Settings", "link": "https://arxiv.org/pdf/2408.15650", "details": "L Gao - arXiv preprint arXiv:2408.15650, 2024", "abstract": "Text classification is crucial for applications such as sentiment analysis and toxic text filtering, but it still faces challenges due to the complexity and ambiguity of natural language. Recent advancements in deep learning, particularly transformer \u2026"}, {"title": "Rethinking Backdoor Detection Evaluation for Language Models", "link": "https://arxiv.org/pdf/2409.00399", "details": "J Yan, WJ Mo, X Ren, R Jia - arXiv preprint arXiv:2409.00399, 2024", "abstract": "Backdoor attacks, in which a model behaves maliciously when given an attacker- specified trigger, pose a major security risk for practitioners who depend on publicly released language models. Backdoor detection methods aim to detect whether a \u2026"}, {"title": "(Un) explainable Technology", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DeNUdEQAAQBAJ%26oi%3Dfnd%26pg%3DPR7%26ots%3Dk6CCF_bJZ2%26sig%3DNeky0LX-XEC7F-rJYN1Y8R_uRYQ", "details": "H Kempt", "abstract": "This book project started as a continuation and summarization of my PhD thesis in which I developed a pragmatic perspective on the role of explainability in medical decision-making. However, as I noticed how this topic cannot be fully appreciated \u2026"}]
