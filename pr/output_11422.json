[{"title": "Use of Attention Maps to Enrich Discriminability in Deep Learning Prediction Models Using Longitudinal Data from Electronic Health Records", "link": "https://www.mdpi.com/2076-3417/15/1/146", "details": "LA Carrasco-Ribelles, M Cabrera-Bean\u2026 - Applied Sciences, 2024", "abstract": "Featured Application A better discrimination in a prediction model does not imply a better interpretability. In healthcare, where transparency is crucial, both discriminability and interpretability should be checked before stating that a new \u2026"}, {"title": "Towards Compatible Fine-tuning for Vision-Language Model Updates", "link": "https://arxiv.org/pdf/2412.20895", "details": "Z Wang, J Liang, L Sheng, R He, Z Wang, T Tan - arXiv preprint arXiv:2412.20895, 2024", "abstract": "So far, efficient fine-tuning has become a popular strategy for enhancing the capabilities of foundation models on downstream tasks by learning plug-and-play modules. However, existing methods overlook a crucial issue: if the underlying \u2026"}, {"title": "A Sequential Optimal Learning Approach to Automated Prompt Engineering in Large Language Models", "link": "https://arxiv.org/pdf/2501.03508", "details": "S Wang, S Moazeni, D Klabjan - arXiv preprint arXiv:2501.03508, 2025", "abstract": "Designing effective prompts is essential to guiding large language models (LLMs) toward desired responses. Automated prompt engineering aims to reduce reliance on manual effort by streamlining the design, refinement, and optimization of natural \u2026"}, {"title": "Anonymization by Design of Language Modeling", "link": "https://arxiv.org/pdf/2501.02407", "details": "A Boutet, ZE Kazdam, L Magnana, H Zimmermann - arXiv preprint arXiv:2501.02407, 2025", "abstract": "Rapid advances in Natural Language Processing (NLP) have revolutionized many fields, including healthcare. However, these advances raise significant privacy concerns, especially when models specialized on sensitive data can memorize and \u2026"}]
