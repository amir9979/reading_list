[{"title": "Language Models Encode the Value of Numbers Linearly", "link": "https://aclanthology.org/2025.coling-main.47.pdf", "details": "F Zhu, D Dai, Z Sui - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have exhibited impressive competence in various tasks, but their internal mechanisms on mathematical problems are still under- explored. In this paper, we study a fundamental question: how language models \u2026"}, {"title": "Factual Knowledge Assessment of Language Models Using Distractors", "link": "https://aclanthology.org/2025.coling-main.537.pdf", "details": "HA Khodja, F Bechet, Q Brabant, A Nasr, G Lecorv\u00e9 - Proceedings of the 31st \u2026, 2025", "abstract": "Abstract Language models encode extensive factual knowledge within their parameters. The accurate assessment of this knowledge is crucial for understanding and improving these models. In the literature, factual knowledge assessment often \u2026"}, {"title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "link": "https://arxiv.org/pdf/2501.16961%3F", "details": "M Raza, N Milic-Frayling - arXiv preprint arXiv:2501.16961, 2025", "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that \u2026"}, {"title": "Advancing Math Reasoning in Language Models: The Impact of Problem-Solving Data, Data Synthesis Methods, and Training Stages", "link": "https://arxiv.org/pdf/2501.14002", "details": "Z Chen, T Liu, M Tian, Q Tong, W Luo, Z Liu - arXiv preprint arXiv:2501.14002, 2025", "abstract": "Advancements in LLMs have significantly expanded their capabilities across various domains. However, mathematical reasoning remains a challenging area, prompting the development of math-specific LLMs. These models typically follow a two-stage \u2026"}, {"title": "RealCritic: Towards Effectiveness-Driven Evaluation of Language Model Critiques", "link": "https://arxiv.org/pdf/2501.14492", "details": "Z Tang, Z Li, Z Xiao, T Ding, R Sun, B Wang, D Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Critiques are important for enhancing the performance of Large Language Models (LLMs), enabling both self-improvement and constructive feedback for others by identifying flaws and suggesting improvements. However, evaluating the critique \u2026"}, {"title": "Chain-of-Specificity: Enhancing Task-Specific Constraint Adherence in Large Language Models", "link": "https://aclanthology.org/2025.coling-main.164.pdf", "details": "K Wei, J Zhong, H Zhang, F Zhang, D Zhang, L Jin\u2026 - Proceedings of the 31st \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) exhibit remarkable generative capabilities, enabling the generation of valuable information. Despite these advancements, previous research found that LLMs sometimes struggle with adhering to specific \u2026"}, {"title": "Topology-of-Question-Decomposition: Enhancing Large Language Models with Information Retrieval for Knowledge-Intensive Tasks", "link": "https://aclanthology.org/2025.coling-main.191.pdf", "details": "W Li, J Wang, LC Yu, X Zhang - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) are increasingly deployed for general problem- solving across various domains yet remain constrained to chaining immediate reasoning steps and depending solely on parametric knowledge. Integrating an \u2026"}, {"title": "PSSD: Making Large Language Models Self-denial via Human Psyche Structure", "link": "https://openreview.net/pdf%3Fid%3D80BpkRq6xe", "details": "J Liao, Z Liao, X Zhao - THE WEB CONFERENCE 2025", "abstract": "The enhance of accuracy in reasoning results of LLMs arouses the community's interests, wherein pioneering studies investigate post-hoc strategies to rectify potential mistakes. Despite extensive efforts, they are all stuck in a state of resource \u2026"}, {"title": "ArithmeticGPT: empowering small-size large language models with advanced arithmetic skills", "link": "https://link.springer.com/article/10.1007/s10994-024-06681-1", "details": "Z Liu, Y Zheng, Z Yin, J Chen, T Liu, M Tian, W Luo - Machine Learning, 2025", "abstract": "Large language models (LLMs) have shown remarkable capabilities in understanding and generating language across a wide range of domains. However, their performance in advanced arithmetic calculation remains a significant challenge \u2026"}]
