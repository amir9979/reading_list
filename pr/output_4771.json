[{"title": "Vision-Language Models under Cultural and Inclusive Considerations", "link": "https://arxiv.org/pdf/2407.06177", "details": "A Karamolegkou, P Rust, Y Cao, R Cui, A S\u00f8gaard\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large vision-language models (VLMs) can assist visually impaired people by describing images from their daily lives. Current evaluation datasets may not reflect diverse cultural user backgrounds or the situational context of this use case. To \u2026"}, {"title": "IGU-Aug: Information-guided unsupervised augmentation and pixel-wise contrastive learning for medical image analysis", "link": "https://ieeexplore.ieee.org/abstract/document/10620395/", "details": "Q Quan, Q Yao, H Zhu, SK Zhou - IEEE Transactions on Medical Imaging, 2024", "abstract": "Contrastive learning (CL) is a form of self-supervised learning and has been widely used for various tasks. Different from widely studied instance-level contrastive learning, pixel-wise contrastive learning mainly helps with pixel-wise dense \u2026"}, {"title": "Multi-task prompt tuning with soft context sharing for vision-language models", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224010610", "details": "K Ding, Y Wang, P Liu, Q Yu, H Zhang, S Xiang, C Pan - Neurocomputing, 2024", "abstract": "Vision-language models have recently shown great potential on many tasks in computer vision. Meanwhile, prior work demonstrates prompt tuning designed for vision-language models could acquire superior performance on few-shot image \u2026"}, {"title": "Gemma 2: Improving Open Language Models at a Practical Size", "link": "https://arxiv.org/pdf/2408.00118", "details": "G Team, M Riviere, S Pathak, PG Sessa, C Hardin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Large Language Model Powered Agents for Information Retrieval", "link": "https://ink.library.smu.edu.sg/cgi/viewcontent.cgi%3Farticle%3D10107%26context%3Dsis_research", "details": "A Zhang, Y Deng, Y Lin, X Chen, JR Wen, TS Chua - Proceedings of the 47th \u2026, 2024", "abstract": "The vital goal of information retrieval today extends beyond merely connecting users with relevant information they search for. It also aims to enrich the diversity, personalization, and interactivity of that connection, ensuring the information retrieval \u2026"}, {"title": "Improving cardiac cine MRI using a deep learning-based ESPIRiT reconstruction with self attention", "link": "https://archive.ismrm.org/2023/4974.html", "details": "T Jao, C Sandino, S Vasanawala", "abstract": "Synopsis Keywords: Heart, Machine Learning/Artificial Intelligence, Deep Learning, Unrolled, Self Attention, CINEA deep learning based ESPIRiT (DL-ESPIRiT) was recently proposed to reconstruct dynamic MRI data with higher reconstruction \u2026"}, {"title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation", "link": "https://arxiv.org/pdf/2408.00764", "details": "M Hu, P Zhao, C Xu, Q Sun, J Lou, Q Lin, P Luo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Model (LLM) based agents have garnered significant attention and are becoming increasingly popular. Furthermore, planning ability is a crucial component of an LLM-based agent, involving interaction with the environment and \u2026"}, {"title": "Closing the gap between open-source and commercial large language models for medical evidence summarization", "link": "https://arxiv.org/pdf/2408.00588", "details": "G Zhang, Q Jin, Y Zhou, S Wang, BR Idnay, Y Luo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) hold great promise in summarizing medical evidence. Most recent studies focus on the application of proprietary LLMs. Using proprietary LLMs introduces multiple risk factors, including a lack of transparency \u2026"}]
