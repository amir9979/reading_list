[{"title": "A Knowledge Graph Embedding Model for Answering Factoid Entity Questions", "link": "https://dl.acm.org/doi/pdf/10.1145/3678003", "details": "P Jafarzadeh, F Ensan, M Ali Akbar Alavi\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Factoid entity questions (FEQ), which seek answers in the form of a single entity from knowledge sources such as DBpedia and Wikidata, constitute a substantial portion of user queries in search engines. This paper introduces the Knowledge Graph \u2026"}, {"title": "M\u00e9dicoBERT: A Medical Language Model for Spanish Natural Language Processing Tasks with a Question-Answering Application Using Hyperparameter \u2026", "link": "https://www.mdpi.com/2076-3417/14/16/7031", "details": "J Padilla Cuevas, JA Reyes-Ortiz\u2026 - Applied Sciences, 2024", "abstract": "The increasing volume of medical information available in digital format presents a significant challenge for researchers seeking to extract relevant information. Manually analyzing voluminous data is a time-consuming process that constrains \u2026"}, {"title": "TracKGE: Transformer with Relation-pattern Adaptive Contrastive Learning for Knowledge Graph Embedding", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124008529", "details": "M Wang, Z Li, J Wang, W Zou, J Zhou, J Gan - Knowledge-Based Systems, 2024", "abstract": "Abstract Knowledge Graphs, fundamental to intelligent applications, are increasingly critical in various domains, enhancing tasks like precise searching and personalized recommendation. Effectively representing entities and relationships in these graphs \u2026"}, {"title": "A Closer Look at Benchmarking Self-Supervised Pre-training with Image Classification", "link": "https://arxiv.org/pdf/2407.12210", "details": "M Marks, M Knott, N Kondapaneni, E Cole, T Defraeye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-supervised learning (SSL) is a machine learning approach where the data itself provides supervision, eliminating the need for external labels. The model is forced to learn about the data structure or context by solving a pretext task. With SSL, models \u2026"}, {"title": "A Systematic Evaluation of GPT-4V's Multimodal Capability for Chest X-ray Image Analysis", "link": "https://www.sciencedirect.com/science/article/pii/S2950162824000535", "details": "Y Liu, Y Li, Z Wang, X Liang, L Liu, L Wang, L Cui, Z Tu\u2026 - Meta-Radiology, 2024", "abstract": "This work evaluates GPT-4V's multimodal capability for medical image analysis, focusing on three representative tasks radiology report generation, medical visual question answering, and medical visual grounding. For the evaluation, a set of \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}, {"title": "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated", "link": "https://arxiv.org/pdf/2407.10969", "details": "H Wang, S Ma, R Wang, F Wei - arXiv preprint arXiv:2407.10969, 2024", "abstract": "We introduce, Q-Sparse, a simple yet effective approach to training sparsely- activated large language models (LLMs). Q-Sparse enables full sparsity of activations in LLMs which can bring significant efficiency gains in inference. This is \u2026"}, {"title": "Evaluating Large Language Models with fmeval", "link": "https://arxiv.org/pdf/2407.12872", "details": "P Schw\u00f6bel, L Franceschi, MB Zafar, K Vasist\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "fmeval is an open source library to evaluate large language models (LLMs) in a range of tasks. It helps practitioners evaluate their model for task performance and along multiple responsible AI dimensions. This paper presents the library and \u2026"}, {"title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models", "link": "https://arxiv.org/pdf/2407.10873", "details": "R Zhang, F Liu, X Lin, Z Wang, Z Lu, Q Zhang - arXiv preprint arXiv:2407.10873, 2024", "abstract": "Automated heuristic design (AHD) has gained considerable attention for its potential to automate the development of effective heuristics. The recent advent of large language models (LLMs) has paved a new avenue for AHD, with initial efforts \u2026"}]
