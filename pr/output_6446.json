[{"title": "Revisiting Prompt Pretraining of Vision-Language Models", "link": "https://arxiv.org/pdf/2409.06166", "details": "Z Chen, L Yang, S Chen, Z Chen, J Liang, X Li - arXiv preprint arXiv:2409.06166, 2024", "abstract": "Prompt learning is an effective method to customize Vision-Language Models (VLMs) for various downstream tasks, involving tuning very few parameters of input prompt tokens. Recently, prompt pretraining in large-scale dataset (eg, ImageNet \u2026"}, {"title": "VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation", "link": "https://arxiv.org/pdf/2409.04429", "details": "Y Wu, Z Zhang, J Chen, H Tang, D Li, Y Fang, L Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "VILA-U is a Unified foundation model that integrates Video, Image, Language understanding and generation. Traditional visual language models (VLMs) use separate modules for understanding and generating visual content, which can lead \u2026"}, {"title": "A Practical Gated Recurrent Transformer Network Incorporating Multiple Fusions for Video Denoising", "link": "https://arxiv.org/pdf/2409.06603", "details": "K Guo, S Choi, J Choi, LH Kim - arXiv preprint arXiv:2409.06603, 2024", "abstract": "State-of-the-art (SOTA) video denoising methods employ multi-frame simultaneous denoising mechanisms, resulting in significant delays (eg, 16 frames), making them impractical for real-time cameras. To overcome this limitation, we propose a multi \u2026"}, {"title": "Center-to-Edge Denoising Diffusion Probabilistic Models with Cross-domain Attention for Undersampled MRI Reconstruction", "link": "https://www.researchgate.net/profile/Shuo-Li-42/publication/383664629_Center-to-Edge_Denoising_Diffusion_Probabilistic_Models_with_Cross-domain_Attention_for_Undersampled_MRI_Reconstruction/links/66d5f2e0fa5e11512c4828f7/Center-to-Edge-Denoising-Diffusion-Probabilistic-Models-with-Cross-domain-Attention-for-Undersampled-MRI-Reconstruction.pdf", "details": "J Zhao, S Li", "abstract": "Integrating dual-domain (ie frequency domain and spatial domain) information for magnetic resonance imaging (MRI) reconstruction from undersampled measurements greatly improves imaging efficiency. However, it is still a challenging \u2026"}, {"title": "FuzzCoder: Byte-level Fuzzing Test via Large Language Model", "link": "https://arxiv.org/pdf/2409.01944", "details": "L Yang, J Yang, C Wei, G Niu, G Zhang, Y Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Fuzzing is an important dynamic program analysis technique designed for finding vulnerabilities in complex software. Fuzzing involves presenting a target program with crafted malicious input to cause crashes, buffer overflows, memory errors, and \u2026"}, {"title": "REFINE-LM: Mitigating Language Model Stereotypes via Reinforcement Learning", "link": "https://arxiv.org/pdf/2408.09489", "details": "R Qureshi, N Es-Sebbani, L Gal\u00e1rraga, Y Graham\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the introduction of (large) language models, there has been significant concern about the unintended bias such models may inherit from their training data. A number of studies have shown that such models propagate gender stereotypes, as \u2026"}]
