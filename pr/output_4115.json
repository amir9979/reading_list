[{"title": "Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models", "link": "https://arxiv.org/pdf/2406.14091", "details": "D Lee, D Rim, M Choi, J Choo - arXiv preprint arXiv:2406.14091, 2024", "abstract": "Although language models (LMs) demonstrate exceptional capabilities on various tasks, they are potentially vulnerable to extraction attacks, which represent a significant privacy risk. To mitigate the privacy concerns of LMs, machine unlearning \u2026"}, {"title": "Identifying Speakers in Dialogue Transcripts: A Text-based Approach Using Pretrained Language Models", "link": "https://arxiv.org/pdf/2407.12094", "details": "M Nguyen, F Dernoncourt, S Yoon, H Deilamsalehy\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce an approach to identifying speaker names in dialogue transcripts, a crucial task for enhancing content accessibility and searchability in digital media archives. Despite the advancements in speech recognition, the task of text-based \u2026"}, {"title": "A Novel cascaded deep architecture with weak-supervision for video crowd counting and density estimation", "link": "https://link.springer.com/article/10.1007/s00500-024-09681-4", "details": "SK Tripathy, S Srivastava, D Bajaj, R Srivastava - Soft Computing, 2024", "abstract": "Video-based crowd counting is an essential surveillance tool that plays a crucial role in mitigating crowd catastrophes by facilitating the development and implementation of efficient crowd management methods. The deep learning approaches using \u2026"}, {"title": "The Art of Saying No: Contextual Noncompliance in Language Models", "link": "https://arxiv.org/pdf/2407.12043", "details": "F Brahman, S Kumar, V Balachandran, P Dasigi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Chat-based language models are designed to be helpful, yet they should not comply with every user request. While most existing work primarily focuses on refusal of\" unsafe\" queries, we posit that the scope of noncompliance should be broadened. We \u2026"}, {"title": "Scaling Laws for Linear Complexity Language Models", "link": "https://arxiv.org/pdf/2406.16690", "details": "X Shen, D Li, R Leng, Z Qin, W Sun, Y Zhong - arXiv preprint arXiv:2406.16690, 2024", "abstract": "The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their \u2026"}, {"title": "Efficient Expert Pruning for Sparse Mixture-of-Experts Language Models: Enhancing Performance and Reducing Inference Costs", "link": "https://arxiv.org/pdf/2407.00945", "details": "E Liu, J Zhu, Z Lin, X Ning, MB Blaschko, S Yan, G Dai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large language models (LLMs) has led to architectures with billions to trillions of parameters, posing significant deployment challenges due to their substantial demands on memory, processing power, and energy \u2026"}, {"title": "Steering Without Side Effects: Improving Post-Deployment Control of Language Models", "link": "https://arxiv.org/pdf/2406.15518", "details": "AC Stickland, A Lyzhov, J Pfau, S Mahdi, SR Bowman - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) have been shown to behave unexpectedly post- deployment. For example, new jailbreaks continually arise, allowing model misuse, despite extensive red-teaming and adversarial training from developers. Given most \u2026"}, {"title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought", "link": "https://arxiv.org/pdf/2406.13940", "details": "Y Zhang, Q Chen, M Li, W Che, L Qin - arXiv preprint arXiv:2406.13940, 2024", "abstract": "Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention. Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning \u2026"}, {"title": "First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning", "link": "https://arxiv.org/pdf/2406.16078", "details": "Y Aoki, K Kudo, T Kuribayashi, S Sone, M Taniguchi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multi-step reasoning is widely adopted in the community to explore the better performance of language models (LMs). We report on the systematic strategy that LMs use in this process. Our controlled experiments reveal that LMs rely more \u2026"}]
