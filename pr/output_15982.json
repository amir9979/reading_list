[{"title": "Turing Machine Evaluation for Large Language Model", "link": "https://arxiv.org/pdf/2504.20771", "details": "H Wu, Z Han, H Huang, C Zhang - arXiv preprint arXiv:2504.20771, 2025", "abstract": "With the rapid development and widespread application of Large Language Models (LLMs), rigorous evaluation has become particularly crucial. This research adopts a novel perspective, focusing on evaluating the core computational reasoning ability of \u2026"}, {"title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models", "link": "https://arxiv.org/pdf/2504.05258%3F", "details": "A Bazaga, R Blloshmi, B Byrne, A de Gispert - arXiv preprint arXiv:2504.05258, 2025", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating coherent text, understanding context, and performing reasoning tasks. However, they struggle with temporal reasoning, which requires processing time-related information \u2026"}, {"title": "DeepCritic: Deliberate Critique with Large Language Models", "link": "https://arxiv.org/pdf/2505.00662", "details": "W Yang, J Chen, Y Lin, JR Wen - arXiv preprint arXiv:2505.00662, 2025", "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem. Leveraging LLMs as critique models to achieve automated supervision is a \u2026"}, {"title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark", "link": "https://arxiv.org/pdf/2504.07749%3F", "details": "V Mikhailov, T Enstad, D Samuel, HC Farseth\u00e5s\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces NorEval, a new and comprehensive evaluation suite for large- scale standardized benchmarking of Norwegian generative language models (LMs). NorEval consists of 24 high-quality human-created datasets--of which five are \u2026"}, {"title": "prompt4vis: prompting large language models with example mining for tabular data visualization", "link": "https://link.springer.com/article/10.1007/s00778-025-00912-0", "details": "S Li, X Chen, Y Song, Y Song, CJ Zhang, F Hao\u2026 - The VLDB Journal, 2025", "abstract": "We are currently in the epoch of Large Language Models (LLMs), which have transformed numerous technological domains within the database community. In this paper, we examine the application of LLMs in text-to-visualization (text-to-vis). The \u2026"}, {"title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2504.07887", "details": "R Cantini, A Orsino, M Ruggiero, D Talia - arXiv preprint arXiv:2504.07887, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, driving advancements in machine translation, summarization, and conversational agents. However, their increasing integration into critical societal domains has raised \u2026"}, {"title": "A Temporal Knowledge Graph Generation Dataset Supervised Distantly by Large Language Models", "link": "https://www.nature.com/articles/s41597-025-05062-0", "details": "J Zhu, Y Fu, J Zhou, D Chen - Scientific Data, 2025", "abstract": "Abstract Knowledge graphs can be constructed by extracting triples from documents, which denotes document-level relation extraction. Each triple illustrates a fact composed of two entities and a relation. However, temporal information \u2026"}, {"title": "Large language models could be rote learners", "link": "https://arxiv.org/pdf/2504.08300", "details": "Y Xu, R Hu, H Ying, J Wu, X Shi, W Lin - arXiv preprint arXiv:2504.08300, 2025", "abstract": "Multiple-choice question (MCQ) benchmarks are widely used for evaluating Large Language Models (LLMs), yet their reliability is undermined by benchmark contamination. In this study, we reframe contamination as an inherent aspect of \u2026"}, {"title": "Exploring Human-Like Thinking in Search Simulations with Large Language Models", "link": "https://arxiv.org/pdf/2504.07570", "details": "E Zhang, X Wang, P Gong, Z Yang, J Mao - arXiv preprint arXiv:2504.07570, 2025", "abstract": "Simulating user search behavior is a critical task in information retrieval, which can be employed for user behavior modeling, data augmentation, and system evaluation. Recent advancements in large language models (LLMs) have opened up new \u2026"}]
