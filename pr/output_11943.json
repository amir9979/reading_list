[{"title": "Language Models Encode the Value of Numbers Linearly", "link": "https://aclanthology.org/2025.coling-main.47.pdf", "details": "F Zhu, D Dai, Z Sui - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have exhibited impressive competence in various tasks, but their internal mechanisms on mathematical problems are still under- explored. In this paper, we study a fundamental question: how language models \u2026"}, {"title": "Evaluating Generalization Capability of Language Models across Abductive, Deductive and Inductive Logical Reasoning", "link": "https://aclanthology.org/2025.coling-main.330.pdf", "details": "Y Sheng, W Wen, L Li, D Zeng - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Transformer-based language models (LMs) have demonstrated remarkable performance on many natural language tasks, yet to what extent LMs possess the capability of generalizing to unseen logical rules remains not explored sufficiently. In \u2026"}, {"title": "Classifying Unstructured Text in Electronic Health Records for Mental Health Prediction Models: Large Language Model Evaluation Study", "link": "https://medinform.jmir.org/2025/1/e65454/", "details": "NC Cardamone, M Olfson, T Schmutte, L Ungar, T Liu\u2026 - JMIR Medical Informatics, 2025", "abstract": "Background: Prediction models have demonstrated a range of applications across medicine, including using electronic health record (EHR) data to identify hospital readmission and mortality risk. Large language models (LLMs) can transform \u2026"}, {"title": "Efficient Vocabulary Reduction for Small Language Models", "link": "https://aclanthology.org/2025.coling-industry.64.pdf", "details": "Y Nozaki, D Nakashima, R Sato, N Asaba - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "The increasing size of large language models (LLMs) poses significant challenges due to their high computational costs and energy consumption, making their deployment in industrial settings difficult. Small language models (SLMs) have been \u2026"}, {"title": "MiniMedGPT: Efficient Large Vision-Language Model for medical Visual Question Answering", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525000017", "details": "AR Alsabbagh, T Mansour, M Al-Kharabsheh\u2026 - Pattern Recognition Letters, 2025", "abstract": "Abstract While Large Vision-Language Models (LVLMs) like GPT-4 and Gemini demonstrate significant potential, their utilization in the medical domain remains largely unexplored. This is due to challenges attributed to prolonged training and \u2026"}, {"title": "Zero-shot and Few-shot Learning with Instruction-following LLMs for Claim Matching in Automated Fact-checking", "link": "https://aclanthology.org/2025.coling-main.650.pdf", "details": "D Pisarevskaya, A Zubiaga - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "The claim matching (CM) task can benefit an automated fact-checking pipeline by putting together claims that can be resolved with the same fact-check. In this work, we are the first to explore zero-shot and few-shot learning approaches to the task \u2026"}]
