[{"title": "Bootstrapping Language Models with DPO Implicit Rewards", "link": "https://arxiv.org/pdf/2406.09760", "details": "C Chen, Z Liu, C Du, T Pang, Q Liu, A Sinha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Human alignment in large language models (LLMs) is an active area of research. A recent groundbreaking work, direct preference optimization (DPO), has greatly simplified the process from past work in reinforcement learning from human feedback \u2026"}, {"title": "Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models", "link": "https://openreview.net/pdf%3Fid%3DcQWsTeTSkZ", "details": "S Lotfi, Y Kuang, MA Finzi, B Amos, M Goldblum\u2026 - ICML 2024 Workshop on \u2026", "abstract": "Large language models (LLMs) with billions of parameters excel at predicting the next token in a sequence. Recent work computes non-vacuous compression-based generalization bounds for LLMs, but these bounds are vacuous for large models at \u2026"}, {"title": "A Survey on Human Preference Learning for Large Language Models", "link": "https://arxiv.org/pdf/2406.11191", "details": "R Jiang, K Chen, X Bai, Z He, J Li, M Yang, T Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The recent surge of versatile large language models (LLMs) largely depends on aligning increasingly capable foundation models with human intentions by preference learning, enhancing LLMs with excellent applicability and effectiveness in \u2026"}, {"title": "Evaluating machine learning approaches for multi-label classification of unstructured electronic health records with a generative large language model", "link": "https://www.medrxiv.org/content/10.1101/2024.06.24.24309441.full.pdf", "details": "D Vithanage, C Deng, L Wang, M Yin, M Alkhalaf\u2026 - medRxiv, 2024", "abstract": "Multi-label classification of unstructured electronic health records (EHR) poses challenges due to the inherent semantic complexity in textual data. Advances in natural language processing (NLP) using large language models (LLMs) show \u2026"}, {"title": "Large Language Models are Interpretable Learners", "link": "https://arxiv.org/pdf/2406.17224", "details": "R Wang, S Si, F Yu, D Wiesmann, CJ Hsieh, I Dhillon - arXiv preprint arXiv \u2026, 2024", "abstract": "The trade-off between expressiveness and interpretability remains a core challenge when building human-centric predictive models for classification and decision- making. While symbolic rules offer interpretability, they often lack expressiveness \u2026"}, {"title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs", "link": "https://arxiv.org/pdf/2407.00653", "details": "Y Zhang, X Wang, J Liang, S Xia, L Chen, Y Xiao - arXiv preprint arXiv:2407.00653, 2024", "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various natural language processing (NLP) tasks, which involve increasingly complex reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving new \u2026"}, {"title": "Rethinking Entity-level Unlearning for Large Language Models", "link": "https://arxiv.org/pdf/2406.15796", "details": "W Ma, X Feng, W Zhong, L Huang, Y Ye, B Qin - arXiv preprint arXiv:2406.15796, 2024", "abstract": "Large language model unlearning has gained increasing attention due to its potential to mitigate security and privacy concerns. Current research predominantly focuses on Instance-level unlearning, specifically aiming at forgetting predefined \u2026"}, {"title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models", "link": "https://arxiv.org/pdf/2407.03181", "details": "H Puerto, T Chubakov, X Zhu, HT Madabushi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Requiring a Large Language Model to generate intermediary reasoning steps has been shown to be an effective way of boosting performance. In fact, it has been found that instruction tuning on these intermediary reasoning steps improves model \u2026"}, {"title": "DKPROMPT: Domain Knowledge Prompting Vision-Language Models for Open-World Planning", "link": "https://arxiv.org/pdf/2406.17659", "details": "X Zhang, Z Altaweel, Y Hayamizu, Y Ding, S Amiri\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models (VLMs) have been applied to robot task planning problems, where the robot receives a task in natural language and generates plans based on visual inputs. While current VLMs have demonstrated strong vision-language \u2026"}]
