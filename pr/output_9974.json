[{"title": "Enhancing vision-language models for medical imaging: bridging the 3D gap with innovative slice selection", "link": "https://openreview.net/pdf%3Fid%3DJrJW21IP9p", "details": "Y Wang, Y Dai, C Jones, HI Sair, J Shen, N Loizou\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent approaches to vision-language tasks are built on the remarkable capabilities of large vision-language models (VLMs). These models excel in zero-shot and few- shot learning, enabling them to learn new tasks without parameter updates \u2026"}, {"title": "SciInstruct: a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models", "link": "https://openreview.net/pdf%3Fid%3DLC1QAqhePv", "details": "D Zhang, Z Hu, S Zhoubian, Z Du, K Yang, Z Wang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving \u2026"}, {"title": "Integrating advanced vision-language models for context recognition in risks assessment", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224019027", "details": "J Rodriguez-Juan, D Ortiz-Perez, J Garcia-Rodriguez\u2026 - Neurocomputing, 2024", "abstract": "This study proposes an open-environment, multi-label human risk classification framework, capable of identifying possible risks to which individuals appearing on input video data are exposed. The framework consists of an ensemble of models \u2026"}, {"title": "Micro-Bench: A Microscopy Benchmark for Vision-Language Understanding", "link": "https://openreview.net/pdf%3Fid%3DeRleg6vy0Y", "details": "A Lozano, JJ Nirschl, J Burgess, SR Gupte, Y Zhang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent advances in microscopy have enabled the rapid generation of terabytes of image data in cell biology and biomedical research. Vision-language models (VLMs) offer a promising solution for large-scale biological image analysis, enhancing \u2026"}, {"title": "Chain of Thought Prompting in Vision-Language Model for Vision Reasoning Tasks", "link": "https://link.springer.com/chapter/10.1007/978-981-96-0351-0_22", "details": "J Ou, J Zhou, Y Dong, F Chen - Australasian Joint Conference on Artificial Intelligence, 2024", "abstract": "The large language model has demonstrated its ability to reason and interpret in text- to-text applications. Current Chain of Thought (CoT) research focuses on either explaining reasoning steps or improving prediction results. This paper proposes a \u2026"}, {"title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality", "link": "https://arxiv.org/pdf/2411.11531", "details": "V Chekalina, A Razzigaev, E Goncharova, A Kuznetsov - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper we present an approach to reduce hallucinations in Large Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional modality. Our method involves transforming input text into a set of KG embeddings and using \u2026"}, {"title": "Multi-Stage Vision Token Dropping: Towards Efficient Multimodal Large Language Model", "link": "https://arxiv.org/pdf/2411.10803", "details": "T Liu, L Shi, R Hong, Y Hu, Q Yin, L Zhang - arXiv preprint arXiv:2411.10803, 2024", "abstract": "The vision tokens in multimodal large language models usually exhibit significant spatial and temporal redundancy and take up most of the input tokens, which harms their inference efficiency. To solve this problem, some recent works were introduced \u2026"}, {"title": "An entity and relation extraction model based on context query and axial attention towards patent texts", "link": "https://www.tandfonline.com/doi/pdf/10.1080/09540091.2024.2426816", "details": "T Wang, Y Zhao, G Zhu, Y Liu, H Li, S Zhang, M Hsieh - Connection Science, 2024", "abstract": "Patent Entity and Relation Extraction (PERE) aims to extract entities and entity- relation triples from unstructured patent texts. PERE is one of the fundamental tasks in patent text mining, providing crucial technical support for patent retrieval and \u2026"}]
