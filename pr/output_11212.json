[{"title": "HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding", "link": "https://arxiv.org/pdf/2412.16158%3F", "details": "C Tao, S Su, X Zhu, C Zhang, Z Chen, J Liu, W Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advance of Large Language Models (LLMs) has catalyzed the development of Vision-Language Models (VLMs). Monolithic VLMs, which avoid modality-specific encoders, offer a promising alternative to the compositional ones \u2026"}, {"title": "Dual-path neural network extracts tumor microenvironment information from whole slide images to predict molecular typing and prognosis of Glioma", "link": "https://www.sciencedirect.com/science/article/pii/S016926072400573X", "details": "Z Ning, B Yang, Y Wang, Z Shi, J Yu, G Wu - Computer Methods and Programs in \u2026, 2025", "abstract": "Abstract Background and Objective: Utilizing AI to mine tumor microenvironment information in whole slide images (WSIs) for glioma molecular subtype and prognosis prediction is significant for treatment. Existing weakly-supervised learning \u2026"}, {"title": "Biased or Flawed? Mitigating Stereotypes in Generative Language Models by Addressing Task-Specific Flaws", "link": "https://arxiv.org/pdf/2412.11414%3F", "details": "A Jha, S Kabra, CK Reddy - arXiv preprint arXiv:2412.11414, 2024", "abstract": "Recent studies have shown that generative language models often reflect and amplify societal biases in their outputs. However, these studies frequently conflate observed biases with other task-specific shortcomings, such as comprehension \u2026"}, {"title": "HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models", "link": "https://arxiv.org/pdf/2412.08378", "details": "S Zhu, W Dong, J Song, Y Guo, B Zheng - arXiv preprint arXiv:2412.08378, 2024", "abstract": "Recently, there has been growing interest in the capability of multimodal large language models (MLLMs) to process high-resolution images. A common approach currently involves dynamically cropping the original high-resolution image into \u2026"}, {"title": "Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual Language Models from Southeast Asia", "link": "https://arxiv.org/pdf/2412.07303", "details": "LCL Gamboa, M Lee - arXiv preprint arXiv:2412.07303, 2024", "abstract": "Bias studies on multilingual models confirm the presence of gender-related stereotypes in masked models processing languages with high NLP resources. We expand on this line of research by introducing Filipino CrowS-Pairs and Filipino \u2026"}, {"title": "OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions", "link": "https://arxiv.org/pdf/2412.06693%3F", "details": "YK Zhang, XX Zhong, S Lu, QG Chen, DC Zhan, HJ Ye - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancements in Large Language Models (LLMs) have significantly expanded their applications, ranging from multilingual support to domain-specific tasks and multimodal integration. In this paper, we present OmniEvalKit, a novel \u2026"}, {"title": "Improving Generative Pre-Training: An In-depth Study of Masked Image Modeling and Denoising Models", "link": "https://arxiv.org/pdf/2412.19104", "details": "H Choi, D Kim, S Cha, KM Yi, D Min - arXiv preprint arXiv:2412.19104, 2024", "abstract": "In this work, we dive deep into the impact of additive noise in pre-training deep networks. While various methods have attempted to use additive noise inspired by the success of latent denoising diffusion models, when used in combination with \u2026"}, {"title": "ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models", "link": "https://arxiv.org/pdf/2412.07012", "details": "J Zhang, L Xue, L Song, J Wang, W Huang, M Shu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the rise of multimodal applications, instruction data has become critical for training multimodal language models capable of understanding complex image- based queries. Existing practices rely on powerful but costly large language models \u2026"}, {"title": "ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models", "link": "https://arxiv.org/pdf/2412.12848", "details": "Y Sun, W Gao, J Ma, H Lin, Z Luo, W Zhang - arXiv preprint arXiv:2412.12848, 2024", "abstract": "With the rise and widespread use of Large Language Models (LLMs), ensuring their safety is crucial to prevent harm to humans and promote ethical behaviors. However, directly assessing value valence (ie, support or oppose) by leveraging large-scale \u2026"}]
