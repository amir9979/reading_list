[{"title": "HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models", "link": "https://arxiv.org/pdf/2504.17449", "details": "J Zhang, J Wang, H Li, L Shou, K Chen, G Chen, Q Xie\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The significant computational demands of pretrained language models (PLMs), which often require dedicated hardware, present a substantial challenge in serving them efficiently, especially in multi-tenant environments. To address this, we \u2026"}, {"title": "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models", "link": "https://arxiv.org/pdf/2505.00551%3F", "details": "C Zhang, Y Deng, X Lin, B Wang, D Ng, H Ye, X Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The recent development of reasoning language models (RLMs) represents a novel evolution in large language models. In particular, the recent release of DeepSeek-R1 has generated widespread social impact and sparked enthusiasm in the research \u2026"}, {"title": "Identifying Asthma-Related Symptoms From Electronic Health Records Using a Hybrid Natural Language Processing Approach Within a Large Integrated Health Care \u2026", "link": "https://ai.jmir.org/2025/1/e69132", "details": "F Xie, RS Zeiger, MM Saparudin, S Al-Salman\u2026 - JMIR AI, 2025", "abstract": "Background Asthma-related symptoms are significant predictors of asthma exacerbation. Most of these symptoms are documented in clinical notes in a free-text format, and effective methods for capturing asthma-related symptoms from \u2026"}, {"title": "SAS-Prompt: Large Language Models as Numerical Optimizers for Robot Self-Improvement", "link": "https://arxiv.org/pdf/2504.20459", "details": "HB Amor, L Graesser, A Iscen, D D'Ambrosio\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We demonstrate the ability of large language models (LLMs) to perform iterative self- improvement of robot policies. An important insight of this paper is that LLMs have a built-in ability to perform (stochastic) numerical optimization and that this property \u2026"}, {"title": "Unleashing the potential of prompt engineering for large language models", "link": "https://www.cell.com/patterns/fulltext/S2666-3899\\(25\\)00108-4", "details": "B Chen, Z Zhang, N Langren\u00e9, S Zhu - Patterns, 2025", "abstract": "This review explores the role of prompt engineering in unleashing the capabilities of large language models (LLMs). Prompt engineering is the process of structuring inputs, and it has emerged as a crucial technique for maximizing the utility and \u2026"}, {"title": "Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation", "link": "https://arxiv.org/pdf/2504.12108", "details": "S Cai, L Ding, D Tao - arXiv preprint arXiv:2504.12108, 2025", "abstract": "The rapid development of Large Language Models (LLMs) has intensified concerns about content traceability and potential misuse. Existing watermarking schemes for sampled text often face trade-offs between maintaining text quality and ensuring \u2026"}, {"title": "The framework and implementation of using large language models to answer questions about building codes and standards", "link": "https://ascelibrary.org/doi/abs/10.1061/JCCEE5.CPENG-6037", "details": "I Joffe, G Felobes, Y Elgouhari, M Talebi Kalaleh, Q Mei\u2026 - Journal of Computing in \u2026, 2025", "abstract": "Civil and structural engineering design projects are subject to strict regulations of relevant codes and standards to guarantee that certain standards of safety, reliability, and efficiency are met. However, ensuring that all engineering designs comply with \u2026"}, {"title": "Benchmark for Measuring Intersectional Bias in Race and Gender of Large Language Models Using Synthetic Data", "link": "https://koreascience.kr/article/JAKO202511236003787.pdf", "details": "H Bae - The Transactions of the Korea Information Processing \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) are generative AI systems trained on vast datasets, capable of producing human-like text and widely used across industries. However, LLMs risk generating biased outputs by internalizing stereotypes related to \u2026"}]
