[{"title": "Attention Head Purification: A New Perspective to Harness CLIP for Domain Generalization", "link": "https://arxiv.org/pdf/2412.07226", "details": "Y Wang, G Kang - arXiv preprint arXiv:2412.07226, 2024", "abstract": "Domain Generalization (DG) aims to learn a model from multiple source domains to achieve satisfactory performance on unseen target domains. Recent works introduce CLIP to DG tasks due to its superior image-text alignment and zeros-shot \u2026"}, {"title": "The Pitfalls of Memorization: When Memorization Hurts Generalization", "link": "https://arxiv.org/pdf/2412.07684", "details": "R Bayat, M Pezeshki, E Dohmatob, D Lopez-Paz\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Neural networks often learn simple explanations that fit the majority of the data while memorizing exceptions that deviate from these explanations. This behavior leads to poor generalization when the learned explanations rely on spurious correlations. In \u2026"}, {"title": "FlexLLM: Exploring LLM Customization for Moving Target Defense on Black-Box LLMs Against Jailbreak Attacks", "link": "https://arxiv.org/pdf/2412.07672", "details": "B Chen, H Guo, Q Yan - arXiv preprint arXiv:2412.07672, 2024", "abstract": "Defense in large language models (LLMs) is crucial to counter the numerous attackers exploiting these systems to generate harmful content through manipulated prompts, known as jailbreak attacks. Although many defense strategies have been \u2026"}, {"title": "SpecFuse: Ensembling Large Language Models via Next-Segment Prediction", "link": "https://arxiv.org/pdf/2412.07380", "details": "B Lv, C Tang, Y Zhang, X Liu, Y Yu, P Luo - arXiv preprint arXiv:2412.07380, 2024", "abstract": "Ensembles of generative large language models (LLMs) can integrate the strengths of different LLMs to compensate for the limitations of individual models. However, recent work has focused on training an additional fusion model to combine complete \u2026"}]
