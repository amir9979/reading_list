[{"title": "White-box Multimodal Jailbreaks Against Large Vision-Language Models", "link": "https://arxiv.org/pdf/2405.17894", "details": "R Wang, X Ma, H Zhou, C Ji, G Ye, YG Jiang - arXiv preprint arXiv:2405.17894, 2024", "abstract": "Recent advancements in Large Vision-Language Models (VLMs) have underscored their superiority in various multimodal tasks. However, the adversarial robustness of VLMs has not been fully explored. Existing methods mainly assess robustness \u2026"}, {"title": "Super Tiny Language Models", "link": "https://arxiv.org/pdf/2405.14159", "details": "D Hillier, L Guertler, C Tan, P Agrawal, C Ruirui\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large language models (LLMs) has led to significant improvements in natural language processing but also poses challenges due to their high computational and energy demands. This paper introduces a series of research \u2026"}, {"title": "CoLoR-Filter: Conditional Loss Reduction Filtering for Targeted Language Model Pre-training", "link": "https://arxiv.org/pdf/2406.10670", "details": "D Brandfonbrener, H Zhang, A Kirsch, JR Schwarz\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Selecting high-quality data for pre-training is crucial in shaping the downstream task performance of language models. A major challenge lies in identifying this optimal subset, a problem generally considered intractable, thus necessitating scalable and \u2026"}, {"title": "Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for Electronic Health Records", "link": "https://aclanthology.org/2024.cl4health-1.23.pdf", "details": "J Lov\u00f3n-Melgarejo, T Ben-Haddi, J Di Scala\u2026 - Proceedings of the First \u2026, 2024", "abstract": "The lack of standardized evaluation benchmarks in the medical domain for text inputs can be a barrier to widely adopting and leveraging the potential of natural language models for health-related downstream tasks. This paper revisited an \u2026"}, {"title": "Representing Animatable Avatar via Factorized Neural Fields", "link": "https://arxiv.org/pdf/2406.00637", "details": "C Song, Z Wu, B Wandt, L Sigal, H Rhodin - arXiv preprint arXiv:2406.00637, 2024", "abstract": "For reconstructing high-fidelity human 3D models from monocular videos, it is crucial to maintain consistent large-scale body shapes along with finely matched subtle wrinkles. This paper explores the observation that the per-frame rendering results \u2026"}, {"title": "Unified Editing of Panorama, 3D Scenes, and Videos Through Disentangled Self-Attention Injection", "link": "https://arxiv.org/pdf/2405.16823", "details": "G Kwon, J Park, JC Ye - arXiv preprint arXiv:2405.16823, 2024", "abstract": "While text-to-image models have achieved impressive capabilities in image generation and editing, their application across various modalities often necessitates training separate models. Inspired by existing method of single image editing with \u2026"}, {"title": "Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding", "link": "https://arxiv.org/pdf/2405.19763", "details": "K Liao, S Li, M Zhao, L Liu, M Xue, Z Hu, H Han, C Yin - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent strides in large language models (LLMs) have yielded remarkable performance, leveraging reinforcement learning from human feedback (RLHF) to significantly enhance generation and alignment capabilities. However, RLHF \u2026"}, {"title": "PLUG: Revisiting Amodal Segmentation with Foundation Model and Hierarchical Focus", "link": "https://arxiv.org/pdf/2405.16094", "details": "Z Liu, L Qiao, X Chu, T Jiang - arXiv preprint arXiv:2405.16094, 2024", "abstract": "Aiming to predict the complete shapes of partially occluded objects, amodal segmentation is an important step towards visual intelligence. With crucial significance, practical prior knowledge derives from sufficient training, while limited \u2026"}, {"title": "Query-based Semantic Gaussian Field for Scene Representation in Reinforcement Learning", "link": "https://arxiv.org/pdf/2406.02370", "details": "J Wang, Z Zhang, Q Zhang, J Li, J Sun, M Sun, J He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Latent scene representation plays a significant role in training reinforcement learning (RL) agents. To obtain good latent vectors describing the scenes, recent works incorporate the 3D-aware latent-conditioned NeRF pipeline into scene \u2026"}]
