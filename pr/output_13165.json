[{"title": "NAVIG: Natural Language-guided Analysis with Vision Language Models for Image Geo-localization", "link": "https://arxiv.org/pdf/2502.14638", "details": "Z Zhang, R Li, T Kabir, J Boyd-Graber - arXiv preprint arXiv:2502.14638, 2025", "abstract": "Image geo-localization is the task of predicting the specific location of an image and requires complex reasoning across visual, geographical, and cultural contexts. While prior Vision Language Models (VLMs) have the best accuracy at this task, there is a \u2026"}, {"title": "Explicitly unbiased large language models still form biased associations", "link": "https://www.pnas.org/doi/full/10.1073/pnas.2416228122", "details": "X Bai, A Wang, I Sucholutsky, TL Griffiths - Proceedings of the National Academy of \u2026, 2025", "abstract": "Large language models (LLMs) can pass explicit social bias tests but still harbor implicit biases, similar to humans who endorse egalitarian beliefs yet exhibit subtle biases. Measuring such implicit biases can be a challenge: As LLMs become \u2026"}, {"title": "Asymmetric Co-Training for Source-Free Few-Shot Domain Adaptation", "link": "https://arxiv.org/pdf/2502.14214", "details": "G Li, Y Wu - arXiv preprint arXiv:2502.14214, 2025", "abstract": "Source-free unsupervised domain adaptation (SFUDA) has gained significant attention as an alternative to traditional unsupervised domain adaptation (UDA), which relies on the constant availability of labeled source data. However, SFUDA \u2026"}, {"title": "Fact or Guesswork? Evaluating Large Language Model's Medical Knowledge with Structured One-Hop Judgment", "link": "https://arxiv.org/pdf/2502.14275", "details": "J Li, Y Wang, K Zhang, Y Cai, B Hooi, N Peng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have been widely adopted in various downstream task domains. However, their ability to directly recall and apply factual medical knowledge remains under-explored. Most existing medical QA benchmarks assess \u2026"}, {"title": "On the Query Complexity of Verifier-Assisted Language Generation", "link": "https://arxiv.org/pdf/2502.12123", "details": "E Botta, Y Li, A Mehta, JT Ash, C Zhang, A Risteski - arXiv preprint arXiv:2502.12123, 2025", "abstract": "Recently, a plethora of works have proposed inference-time algorithms (eg best-of- n), which incorporate verifiers to assist the generation process. Their quality- efficiency trade-offs have been empirically benchmarked on a variety of constrained \u2026"}, {"title": "Effectiveness of Transformer-Based Large Language Models in Identifying Adverse Drug Reaction Relations from Unstructured Discharge Summaries in Singapore", "link": "https://link.springer.com/article/10.1007/s40264-025-01525-w", "details": "YL Koon, YT Lam, HX Tan, DHC Teo, JW Neo\u2026 - Drug Safety, 2025", "abstract": "Introduction Transformer-based large language models (LLMs) have transformed the field of natural language processing and led to significant advancements in various text processing tasks. However, the applicability of these LLMs in identifying related \u2026"}, {"title": "Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder", "link": "https://arxiv.org/pdf/2502.14050", "details": "X Yang, S Nie, L Liu, S Gururangan, U Karn, R Hou\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Current pre-trained large language models typically need instruction tuning to align with human preferences. However, instruction tuning data is often quantity-saturated due to the large volume of data collection and fast model iteration, leaving coreset \u2026"}, {"title": "Large Language Models and Mathematical Reasoning Failures", "link": "https://arxiv.org/pdf/2502.11574", "details": "J Boye, B Moell - arXiv preprint arXiv:2502.11574, 2025", "abstract": "This paper investigates the mathematical reasoning capabilities of large language models (LLMs) using 50 newly constructed high-school-level word problems. Unlike prior studies that focus solely on answer correctness, we rigorously analyze both \u2026"}, {"title": "Reasoning-as-Logic-Units: Scaling Test-Time Reasoning in Large Language Models Through Logic Unit Alignment", "link": "https://arxiv.org/pdf/2502.07803", "details": "C Li, T Xu, Y Guo - arXiv preprint arXiv:2502.07803, 2025", "abstract": "Chain-of-Thought (CoT) prompting has shown promise in enhancing the reasoning capabilities of large language models (LLMs) by generating natural language (NL) rationales that lead to the final answer. However, it struggles with numerical \u2026"}]
