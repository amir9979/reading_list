[{"title": "SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding", "link": "https://arxiv.org/pdf/2410.11761", "details": "Y Chen, G Wang, Y Ji, Y Li, J Ye, T Li, B Zhang, N Pei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the progress made by multimodal large language models (MLLMs) in computational pathology, they remain limited by a predominant focus on patch-level analysis, missing essential contextual information at the whole-slide level. The lack \u2026"}, {"title": "When Attention Sink Emerges in Language Models: An Empirical View", "link": "https://arxiv.org/pdf/2410.10781", "details": "X Gu, T Pang, C Du, Q Liu, F Zhang, C Du, Y Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language Models (LMs) assign significant attention to the first token, even if it is not semantically important, which is known as attention sink. This phenomenon has been widely adopted in applications such as streaming/long context generation, KV \u2026"}, {"title": "MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding", "link": "https://arxiv.org/pdf/2410.11829%3F", "details": "Y Cao, Y Liu, Z Chen, G Shi, W Wang, D Zhao, T Lu - arXiv preprint arXiv:2410.11829, 2024", "abstract": "Despite significant advancements in Multimodal Large Language Models (MLLMs) for understanding complex human intentions through cross-modal interactions, capturing intricate image details remains challenging. Previous methods integrating \u2026"}, {"title": "Beyond Labels: A Self-Supervised Framework with Masked Autoencoders and Random Cropping for Breast Cancer Subtype Classification", "link": "https://arxiv.org/pdf/2410.12006", "details": "A Chiocchetti, M Dossena, C Irwin, L Portinale - arXiv preprint arXiv:2410.12006, 2024", "abstract": "This work contributes to breast cancer sub-type classification using histopathological images. We utilize masked autoencoders (MAEs) to learn a self-supervised embedding tailored for computer vision tasks in this domain. This embedding \u2026"}, {"title": "PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for Enhanced Survival Prediction from Histopathology Images", "link": "https://arxiv.org/pdf/2411.00749", "details": "A Krishna, NC Kurian, A Patil, A Parulekar, A Sethi - arXiv preprint arXiv:2411.00749, 2024", "abstract": "Accurate survival prediction is essential for personalized cancer treatment. However, genomic data-often a more powerful predictor than pathology data-is costly and inaccessible. We present the cross-modal genomic feature translation and alignment \u2026"}, {"title": "Exploring the Impact of Backbone Architecture on Explainable CNNs' Interpretability", "link": "https://www.researchgate.net/profile/Zalan-Bodo/publication/384925487_Exploring_the_Impact_of_Backbone_Architecture_on_Explainable_CNNs%27_Interpretability/links/670e3ccf77bab74415a19534/Exploring-the-Impact-of-Backbone-Architecture-on-Explainable-CNNs-Interpretability.pdf", "details": "\u00c1 PORTIK, A BAJCSI, A SZENKOVITS, Z BOD\u00d3 - Acta Univ. Sapientiae, 2024", "abstract": "The growing demand for interpretable models in machine learning underscores the importance of transparency in decision-making processes for building trust and ensuring accountability in AI systems. Unlike complex black-box models \u2026"}, {"title": "Slide-based Graph Collaborative Training for Histopathology Whole Slide Image Analysis", "link": "https://arxiv.org/pdf/2410.10260", "details": "J Shi, T Shu, Z Jiang, W Wang, H Wu, Y Zheng - arXiv preprint arXiv:2410.10260, 2024", "abstract": "The development of computational pathology lies in the consensus that pathological characteristics of tumors are significant guidance for cancer diagnostics. Most existing research focuses on the inner-contextual information within each WSI yet \u2026"}, {"title": "Distributionally robust self-supervised learning for tabular data", "link": "https://arxiv.org/pdf/2410.08511", "details": "S Ghosh, T Xie, M Kuznetsov - arXiv preprint arXiv:2410.08511, 2024", "abstract": "Machine learning (ML) models trained using Empirical Risk Minimization (ERM) often exhibit systematic errors on specific subpopulations of tabular data, known as error slices. Learning robust representation in presence of error slices is challenging \u2026"}, {"title": "Learnable Context in Multiple Instance Learning for Whole Slide Image Classification and Segmentation", "link": "https://link.springer.com/article/10.1007/s10278-024-01302-8", "details": "YY Huang, WT Chu - Journal of Imaging Informatics in Medicine, 2024", "abstract": "Multiple instance learning (MIL) has become a cornerstone in whole slide image (WSI) analysis. In this paradigm, a WSI is conceptualized as a bag of instances. Instance features are extracted by a feature extractor, and then a feature aggregator \u2026"}]
