[{"title": "Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models", "link": "https://arxiv.org/pdf/2503.20492", "details": "F Zeng, Z Cheng, F Zhu, XY Zhang - arXiv preprint arXiv:2503.20492, 2025", "abstract": "Reliable prediction by classifiers is crucial for their deployment in high security and dynamically changing situations. However, modern neural networks often exhibit overconfidence for misclassified predictions, highlighting the need for confidence \u2026"}, {"title": "Generality-aware self-supervised transformer for multivariate time series anomaly detection", "link": "https://link.springer.com/article/10.1007/s10489-025-06481-7", "details": "Y Cho, JH Lee, G Ham, D Jang, D Kim - Applied Intelligence, 2025", "abstract": "Efficient identification of anomalies within multivariate time series data holds significant relevance in contemporary industrial settings. The challenge lies in swiftly and accurately pinpointing anomalous data points. This challenge is further \u2026"}, {"title": "TiTAD: Time-Invariant Transformer for Multivariate Time Series Anomaly Detection", "link": "https://www.mdpi.com/2079-9292/14/7/1401", "details": "Y Liu, W Wang, Y Wu - Electronics, 2025", "abstract": "Anomaly detection in multivariate time series data is critical for industrial sectors such as manufacturing and aerospace. While existing methods have achieved notable success in specific scenarios, they often narrowly focus on either the temporal or \u2026"}, {"title": "Language Model Uncertainty Quantification with Attention Chain", "link": "https://arxiv.org/pdf/2503.19168", "details": "Y Li, R Qiang, L Moukheiber, C Zhang - arXiv preprint arXiv:2503.19168, 2025", "abstract": "Accurately quantifying a large language model's (LLM) predictive uncertainty is crucial for judging the reliability of its answers. While most existing research focuses on short, directly answerable questions with closed-form outputs (eg, multiple \u2026"}, {"title": "InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse Problems", "link": "https://arxiv.org/pdf/2504.01689", "details": "N Elata, H Chung, JC Ye, T Michaeli, M Elad - arXiv preprint arXiv:2504.01689, 2025", "abstract": "Diffusion Models have demonstrated remarkable capabilities in handling inverse problems, offering high-quality posterior-sampling-based solutions. Despite significant advances, a fundamental trade-off persists, regarding the way the \u2026"}, {"title": "Teacher privileged distillation: How to deal with imperfect teachers?", "link": "https://www.sciencedirect.com/science/article/pii/S0950705125003855", "details": "M Mart\u00ednez-Garc\u00eda, I Inza, JA Lozano - Knowledge-Based Systems, 2025", "abstract": "The paradigm of learning using privileged information leverages privileged features present at training time, but not at prediction, as additional training information. The privileged learning process is addressed through a knowledge distillation \u2026"}, {"title": "Random Conditioning with Distillation for Data-Efficient Diffusion Model Compression", "link": "https://arxiv.org/pdf/2504.02011", "details": "D Kim, S Park, G Han, SW Kim, PH Seo - arXiv preprint arXiv:2504.02011, 2025", "abstract": "Diffusion models generate high-quality images through progressive denoising but are computationally intensive due to large model sizes and repeated sampling. Knowledge distillation, which transfers knowledge from a complex teacher to a \u2026"}, {"title": "High Quality Diffusion Distillation on a Single GPU with Relative and Absolute Position Matching", "link": "https://arxiv.org/pdf/2503.20744%3F", "details": "G Zhang, K Niwa, JP Lewis, C Mesnage, WB Kleijn - arXiv preprint arXiv:2503.20744, 2025", "abstract": "We introduce relative and absolute position matching (RAPM), a diffusion distillation method resulting in high quality generation that can be trained efficiently on a single GPU. Recent diffusion distillation research has achieved excellent results for high \u2026"}, {"title": "Doubly Contrastive Learning for Source-Free Domain Adaptive Person Search", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32413/34568", "details": "Y Jia, R Quan, Y Feng, H Chen, J Qin - Proceedings of the AAAI Conference on \u2026, 2025", "abstract": "Abstract Domain Adaptive Person Search (DAPS) aims to improve the generalization capability of person search models by training on both labeled source data and unlabeled target data, which is not that practical in real-world applications \u2026"}]
