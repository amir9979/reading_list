[{"title": "Deep Learning-Based Noninvasive Screening of Type 2 Diabetes with Chest X-ray Images and Electronic Health Records", "link": "https://arxiv.org/pdf/2412.10955", "details": "S Gundapaneni, Z Zhi, M Rodrigues - arXiv preprint arXiv:2412.10955, 2024", "abstract": "The imperative for early detection of type 2 diabetes mellitus (T2DM) is challenged by its asymptomatic onset and dependence on suboptimal clinical diagnostic tests, contributing to its widespread global prevalence. While research into noninvasive \u2026"}, {"title": "A Multi-task Learning Approach for Predicting Spatio-temporal Patient Variables", "link": "https://dl.acm.org/doi/pdf/10.1145/3698587.3701340", "details": "KF Madhobi, E Lofgren, A Kalyanaraman - Proceedings of the 15th ACM International \u2026, 2024", "abstract": "Predicting a patient's length of stay (LOS) or the units they are likely to visit during the course of the stay can be a vital source of information for healthcare administrators towards effective resource planning. However, predicting these parameters can be \u2026"}, {"title": "Why AI Is Good for Our Health but May Hurt Our Wallets", "link": "https://hmpi.org/2024/11/17/why-ai-is-good-for-our-health-but-may-hurt-our-wallets/", "details": "SS Jain, M Cheatham, MA Pfeffer, L Hoff, NH Shah - HMPI: Health Management \u2026, 2024", "abstract": "What is the message? Current regulatory frameworks, reimbursement structures, and business models for AI in healthcare are decoupled, which has created an environment in which AI may significantly increase costs without necessarily \u2026"}, {"title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2412.09827", "details": "C Li, C Ding, K Luan, X Di - arXiv preprint arXiv:2412.09827, 2024", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. LoRA is one of the most widely used methods, which assumes that the optimization process is essentially low \u2026"}, {"title": "Can Language Models Rival Mathematics Students? Evaluating Mathematical Reasoning through Textual Manipulation and Human Experiments", "link": "https://arxiv.org/pdf/2412.11908", "details": "A Nikolaiev, Y Stathopoulos, S Teufel - arXiv preprint arXiv:2412.11908, 2024", "abstract": "In this paper we look at the ability of recent large language models (LLMs) at solving mathematical problems in combinatorics. We compare models LLaMA-2, LLaMA-3.1, GPT-4, and Mixtral against each other and against human pupils and \u2026"}, {"title": "Autonomous medical evaluation for guideline adherence of large language models", "link": "https://www.nature.com/articles/s41746-024-01356-6", "details": "D Fast, LC Adams, F Busch, C Fallon, M Huppertz\u2026 - npj Digital Medicine, 2024", "abstract": "Abstract Autonomous Medical Evaluation for Guideline Adherence (AMEGA) is a comprehensive benchmark designed to evaluate large language models' adherence to medical guidelines across 20 diagnostic scenarios spanning 13 specialties. It \u2026"}, {"title": "Towards a Speech Foundation Model for Singapore and Beyond", "link": "https://arxiv.org/pdf/2412.11538", "details": "M Huzaifah, T Liu, HB Sailor, KM Tan, TK Vangani\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This technical report describes the MERaLiON Speech Encoder, a foundation model designed to support a wide range of downstream speech applications. Developed as part of Singapore's National Multimodal Large Language Model Programme, the \u2026"}]
