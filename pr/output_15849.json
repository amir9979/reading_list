[{"title": "Reinforcement Learning for Reasoning in Large Language Models with One Training Example", "link": "https://arxiv.org/pdf/2504.20571", "details": "Y Wang, Q Yang, Z Zeng, L Ren, L Liu, B Peng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We show that reinforcement learning with verifiable reward using one training example (1-shot RLVR) is effective in incentivizing the math reasoning capabilities of large language models (LLMs). Applying RLVR to the base model Qwen2. 5-Math \u2026"}, {"title": "Window Token Concatenation for Efficient Visual Large Language Models", "link": "https://arxiv.org/pdf/2504.04024", "details": "Y Li, W Bao, B Ye, Z Tan, T Chen, H Liu, Y Kong - arXiv preprint arXiv:2504.04024, 2025", "abstract": "To effectively reduce the visual tokens in Visual Large Language Models (VLLMs), we propose a novel approach called Window Token Concatenation (WiCo). Specifically, we employ a sliding window to concatenate spatially adjacent visual \u2026"}, {"title": "Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large Language Models", "link": "https://arxiv.org/pdf/2504.20469", "details": "E Fane, M Surdeanu, E Blanco, SR Corman - arXiv preprint arXiv:2504.20469, 2025", "abstract": "Understanding how news narratives frame entities is crucial for studying media's impact on societal perceptions of events. In this paper, we evaluate the zero-shot capabilities of large language models (LLMs) in classifying framing roles. Through \u2026"}, {"title": "Few-shot biomedical NER empowered by LLMs-assisted data augmentation and multi-scale feature extraction", "link": "https://link.springer.com/article/10.1186/s13040-025-00443-y", "details": "D Zhao, W Mu, X Jia, S Liu, Y Chu, J Meng, H Lin - BioData Mining, 2025", "abstract": "Abstract Named Entity Recognition (NER) is a fundamental task in processing biomedical text. Due to the limited availability of labeled data, researchers have investigated few-shot learning methods to tackle this challenge. However, replicating \u2026"}, {"title": "Emerging Data Practices: Data Work in the Era of Large Language Models", "link": "https://dl.acm.org/doi/abs/10.1145/3706598.3714069", "details": "A Alvarado Garcia, H Candello, K Badillo-Urquiola\u2026 - Proceedings of the 2025 \u2026, 2025", "abstract": "Data is one of the foundational aspects of making Artificial Intelligence (AI) work as intended. As large language models (LLMs) become the epicenter of AI, it is crucial to understand better how the datasets that maintain such models are created. The \u2026"}]
