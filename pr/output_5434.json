[{"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models", "link": "https://aclanthology.org/2024.acl-long.765.pdf", "details": "S Li, R Lin, S Pei - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Multi-modal large language models (MLLMs) are expected to support multi-turn queries of interchanging image and text modalities in production. However, the current MLLMs trained with visual-question-answering (VQA) datasets could suffer \u2026"}, {"title": "Cognitive Assessment of Language Models", "link": "https://openreview.net/pdf%3Fid%3DpxRh1meUvN", "details": "D McDuff, D Munday, X Liu, I Galatzer-Levy - ICML 2024 Workshop on LLMs and Cognition", "abstract": "Large language models (LLMs) are a subclass of generative artificial intelligence that can interpret language inputs to generate novel responses. These capabilities are conceptualized as a significant step forward in artificial intelligence because the \u2026"}, {"title": "KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models", "link": "https://arxiv.org/pdf/2408.03297", "details": "R Zhang, Y Xu, Y Xiao, R Zhu, X Jiang, X Chu, J Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "By integrating external knowledge, Retrieval-Augmented Generation (RAG) has become an effective strategy for mitigating the hallucination problems that large language models (LLMs) encounter when dealing with knowledge-intensive tasks \u2026"}, {"title": "Making Long-Context Language Models Better Multi-Hop Reasoners", "link": "https://arxiv.org/pdf/2408.03246", "details": "Y Li, S Liang, MR Lyu, L Wang - arXiv preprint arXiv:2408.03246, 2024", "abstract": "Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased \u2026"}, {"title": "Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs", "link": "https://aclanthology.org/2024.findings-acl.938.pdf", "details": "D Wang, J Zhao, H Pei, S Tan, S Zha - Findings of the Association for Computational \u2026, 2024", "abstract": "Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs \u2026"}, {"title": "Tad: A plug-and-play task-aware decoding method to better adapt llms on downstream tasks", "link": "https://www.ijcai.org/proceedings/2024/0728.pdf", "details": "X Xu, H Chen, Z Lin, J Han, L Gong, G Wang, Y Bao\u2026 - Proceedings of the Thirty \u2026, 2024", "abstract": "Fine-tuning pre-trained models on downstream tasks is a common practice in leveraging large language models (LLMs) today. A critical issue is how to adapt pre- trained models to downstream tasks better, thereby enhancing their performance \u2026"}, {"title": "BEnQA: A Question Answering Benchmark for Bengali and English", "link": "https://aclanthology.org/2024.findings-acl.68.pdf", "details": "S Shafayat, H Hasan, M Mahim, R Putri, J Thorne, A Oh - Findings of the Association \u2026, 2024", "abstract": "In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with \u2026"}]
