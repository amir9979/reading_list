[{"title": "Watermarks in the Sand: Impossibility of Strong Watermarking for Language Models", "link": "https://openreview.net/pdf%3Fid%3DbM2s12t4hR", "details": "H Zhang, BL Edelman, D Francati, D Venturi\u2026 - Forty-first International Conference \u2026", "abstract": "Watermarking generative models consists of planting a statistical signal (watermark) in a model's output so that it can be later verified that the output was generated by the given model. A strong watermarking scheme satisfies the property that a \u2026"}, {"title": "Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses", "link": "https://arxiv.org/pdf/2406.01288", "details": "X Zheng, T Pang, C Du, Q Liu, J Jiang, M Lin - arXiv preprint arXiv:2406.01288, 2024", "abstract": "Recently, Anil et al.(2024) show that many-shot (up to hundreds of) demonstrations can jailbreak state-of-the-art LLMs by exploiting their long-context capability. Nevertheless, is it possible to use few-shot demonstrations to efficiently jailbreak \u2026"}, {"title": "Calibrating Reasoning in Language Models with Internal Consistency", "link": "https://arxiv.org/pdf/2405.18711", "details": "Z Xie, J Guo, T Yu, S Li - arXiv preprint arXiv:2405.18711, 2024", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various reasoning tasks, aided by techniques like chain-of-thought (CoT) prompting that elicits verbalized reasoning. However, LLMs often generate text with obvious \u2026"}, {"title": "Identifying erroneous height and weight values from adult electronic health records in the All of Us research program", "link": "https://www.sciencedirect.com/science/article/pii/S1532046424000789", "details": "A Guide, L Sulieman, S Garbett, RM Cronin, M Spotnitz\u2026 - Journal of Biomedical \u2026, 2024", "abstract": "Abstract Introduction Electronic Health Records (EHR) are a useful data source for research, but their usability is hindered by measurement errors. This study investigated an automatic error detection algorithm for adult height and weight \u2026"}, {"title": "Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective", "link": "https://arxiv.org/pdf/2405.16747", "details": "A Tomihari, I Sato - arXiv preprint arXiv:2405.16747, 2024", "abstract": "The two-stage fine-tuning (FT) method, linear probing then fine-tuning (LP-FT), consistently outperforms linear probing (LP) and FT alone in terms of accuracy for both in-distribution (ID) and out-of-distribution (OOD) data. This success is largely \u2026"}, {"title": "Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "link": "https://arxiv.org/pdf/2405.10431", "details": "S Furniturewala, S Jandial, A Java, P Banerjee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing debiasing techniques are typically training-based or require access to the model's internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine \u2026"}, {"title": "X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions", "link": "https://arxiv.org/pdf/2405.19744", "details": "C Li, W Yang, J Zhang, J Lu, S Wang, C Zong - arXiv preprint arXiv:2405.19744, 2024", "abstract": "Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples \u2026"}, {"title": "IT5: Text-to-text Pretraining for Italian Language Understanding and Generation", "link": "https://aclanthology.org/2024.lrec-main.823.pdf", "details": "G Sarti, M Nissim - Proceedings of the 2024 Joint International Conference \u2026, 2024", "abstract": "We introduce IT5, the first family of encoder-decoder transformer models pretrained specifically on Italian. We document and perform a thorough cleaning procedure for a large Italian corpus and use it to pretrain four IT5 model sizes. We then introduce \u2026"}, {"title": "Probe Then Retrieve and Reason: Distilling Probing and Reasoning Capabilities into Smaller Language Models", "link": "https://aclanthology.org/2024.lrec-main.1140.pdf", "details": "Y Zhao, S Zhou, H Zhu - Proceedings of the 2024 Joint International Conference \u2026, 2024", "abstract": "Step-by-step reasoning methods, such as the Chain-of-Thought (CoT), have been demonstrated to be highly effective in harnessing the reasoning capabilities of Large Language Models (LLMs). Recent research efforts have sought to distill LLMs into \u2026"}]
