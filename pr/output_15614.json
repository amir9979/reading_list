[{"title": "Evaluating and mitigating bias in AI-based medical text generation", "link": "https://www.nature.com/articles/s43588-025-00789-7", "details": "X Chen, T Wang, J Zhou, Z Song, X Gao, X Zhang - Nature Computational Science, 2025", "abstract": "Artificial intelligence (AI) systems, particularly those based on deep learning models, have increasingly achieved expert-level performance in medical applications. However, there is growing concern that such AI systems may reflect and amplify \u2026"}, {"title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation", "link": "https://arxiv.org/pdf/2504.02438", "details": "C Cheng, J Guan, W Wu, R Yan - arXiv preprint arXiv:2504.02438, 2025", "abstract": "Long-form video processing fundamentally challenges vision-language models (VLMs) due to the high computational costs of handling extended temporal sequences. Existing token pruning and feature merging methods often sacrifice \u2026"}, {"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}, {"title": "Large Language Models for Thematic Summarization in Qualitative Health Care Research: Comparative Analysis of Model and Human Performance", "link": "https://ai.jmir.org/2025/1/e64447", "details": "A Castellanos, H Jiang, P Gomes, D Vander Meer\u2026 - JMIR AI, 2025", "abstract": "Background The application of large language models (LLMs) in analyzing expert textual online data is a topic of growing importance in computational linguistics and qualitative research within health care settings. Objective The objective of this study \u2026"}, {"title": "EIDT-V: Exploiting Intersections in Diffusion Trajectories for Model-Agnostic, Zero-Shot, Training-Free Text-to-Video Generation", "link": "https://arxiv.org/pdf/2504.06861%3F", "details": "D Jagpal, X Chen, VP Namboodiri - arXiv preprint arXiv:2504.06861, 2025", "abstract": "Zero-shot, training-free, image-based text-to-video generation is an emerging area that aims to generate videos using existing image-based diffusion models. Current methods in this space require specific architectural changes to image generation \u2026"}, {"title": "Advancing reliability in self-supervised transformer models through hierarchical mask attention heads", "link": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13406/134060N/Advancing-reliability-in-self-supervised-transformer-models-through-hierarchical-mask/10.1117/12.3047444.short", "details": "S Baur, A Vahidi, M Wang, N Zebardast, T Elze\u2026 - Medical Imaging 2025 \u2026, 2025", "abstract": "Self-supervised learning (SSL) has proven to be a powerful technique across various domains, including computer vision, natural language processing, and, more recently, medical image analysis. In critical applications such as medical diagnosis \u2026"}, {"title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions", "link": "https://arxiv.org/pdf/2504.05571", "details": "O Ovadia, M Brief, R Lemberg, E Sheetrit - arXiv preprint arXiv:2504.05571, 2025", "abstract": "While Large Language Models (LLMs) acquire vast knowledge during pre-training, they often lack domain-specific, new, or niche information. Continual pre-training (CPT) attempts to address this gap but suffers from catastrophic forgetting and \u2026"}, {"title": "ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection", "link": "https://arxiv.org/pdf/2504.00695", "details": "X Zhu, Z Gu, S Zheng, T Wang, T Li, H Feng, Y Xiao - arXiv preprint arXiv:2504.00695, 2025", "abstract": "Pre-training large language models (LLMs) necessitates enormous diverse textual corpora, making effective data selection a key challenge for balancing computational resources and model performance. Current methodologies primarily emphasize data \u2026"}, {"title": "Slow-fast architecture for video multi-modal large language models", "link": "https://arxiv.org/pdf/2504.01328%3F", "details": "M Shi, S Wang, CY Chen, J Jain, K Wang, J Xiong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Balancing temporal resolution and spatial detail under limited compute budget remains a key challenge for video-based multi-modal large language models (MLLMs). Existing methods typically compress video representations using \u2026"}]
