[{"title": "AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset", "link": "https://arxiv.org/pdf/2411.15640", "details": "T Olatunji, C Nimo, A Owodunni, T Abdullahi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in large language model (LLM) performance on medical multiple choice question (MCQ) benchmarks have stimulated interest from healthcare providers and patients globally. Particularly in low-and middle-income \u2026"}, {"title": "QUEST-AI: A System for Question Generation, Verification, and Refinement using AI for USMLE-Style Exams", "link": "https://www.worldscientific.com/doi/pdf/10.1142/9789819807024_0005", "details": "S Bedi, SL Fleming, CC Chiang, K Morse, A Kumar\u2026 - \u2026 2025: Proceedings of the \u2026, 2024", "abstract": "The United States Medical Licensing Examination (USMLE) is a critical step in assessing the competence of future physicians, yet the process of creating exam questions and study materials is both time-consuming and costly. While Large \u2026"}]
