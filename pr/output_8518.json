[{"title": "Using a natural language processing toolkit to classify electronic health records by psychiatric diagnosis", "link": "https://journals.sagepub.com/doi/pdf/10.1177/14604582241296411", "details": "A Hutto, TM Zikry, B Bohac, T Rose, J Staebler, J Slay\u2026 - Health Informatics Journal, 2024", "abstract": "Objective: We analyzed a natural language processing (NLP) toolkit's ability to classify unstructured EHR data by psychiatric diagnosis. Expertise can be a barrier to using NLP. We employed an NLP toolkit (CLARK) created to support studies led by \u2026"}, {"title": "Calibrated Cache Model for Few-Shot Vision-Language Model Adaptation", "link": "https://arxiv.org/pdf/2410.08895", "details": "K Ding, Q Yu, H Zhang, G Meng, S Xiang - arXiv preprint arXiv:2410.08895, 2024", "abstract": "Cache-based approaches stand out as both effective and efficient for adapting vision- language models (VLMs). Nonetheless, the existing cache model overlooks three crucial aspects. 1) Pre-trained VLMs are mainly optimized for image-text similarity \u2026"}, {"title": "RuleRAG: Rule-guided retrieval-augmented generation with language models for question answering", "link": "https://arxiv.org/pdf/2410.22353", "details": "Z Chen, C Xu, D Wang, Z Huang, Y Dou, J Guo - arXiv preprint arXiv:2410.22353, 2024", "abstract": "Retrieval-augmented generation (RAG) framework has shown promising potential in knowledge-intensive question answering (QA) by retrieving external corpus and generating based on augmented context. However, existing approaches only \u2026"}, {"title": "EchoPrime: A Multi-Video View-Informed Vision-Language Model for Comprehensive Echocardiography Interpretation", "link": "https://arxiv.org/pdf/2410.09704", "details": "M Vukadinovic, X Tang, N Yuan, P Cheng, D Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Echocardiography is the most widely used cardiac imaging modality, capturing ultrasound video data to assess cardiac structure and function. Artificial intelligence (AI) in echocardiography has the potential to streamline manual tasks and improve \u2026"}, {"title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe", "link": "https://arxiv.org/pdf/2410.05248", "details": "Y Xiao, S Zhang, W Zhou, M Ghassemi, S Zhao - arXiv preprint arXiv:2410.05248, 2024", "abstract": "To induce desired behaviors in large language models (LLMs) for interaction-driven tasks, the instruction-tuning stage typically trains LLMs on instruction-response pairs using the next-token prediction (NTP) loss. Previous work aiming to improve \u2026"}, {"title": "TabMedBERT: A Tabular Knowledge Enhanced Biomedical Pretrained Language Model", "link": "https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA240674", "details": "X Yan, L Geng, Z Cao, J Li, W Li, S Li, X Zhou, Y Yang\u2026 - ECAI 2024, 2024", "abstract": "Most existing biomedical language models are trained on plain text with general learning goals such as random word infilling, failing to capture the knowledge in the biomedical corpus sufficiently. Since biomedical articles usually contain many tables \u2026"}, {"title": "Multimodal Large Language Models and Tunings: Vision, Language, Sensors, Audio, and Beyond", "link": "https://arxiv.org/pdf/2410.05608", "details": "SC Han, F Cao, J Poon, R Navigli - arXiv preprint arXiv:2410.05608, 2024", "abstract": "This tutorial explores recent advancements in multimodal pretrained and large models, capable of integrating and processing diverse data forms such as text, images, audio, and video. Participants will gain an understanding of the foundational \u2026"}, {"title": "Integrating Natural Language Models with Bayesian Networks for Explainable Machine Learning", "link": "https://www.sba.org.br/cba2024/papers/paper_9497.pdf", "details": "VB de Oliveira Barth, CD Maciel", "abstract": "The advancements brought by machine learning algorithms have significantly contributed to society, notably natural language models based on transformers, which have the capability to interpret user requests and respond in natural language \u2026"}, {"title": "VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis", "link": "https://arxiv.org/pdf/2410.08397", "details": "A Hoopes, VI Butoi, JV Guttag, AV Dalca - arXiv preprint arXiv:2410.08397, 2024", "abstract": "We present VoxelPrompt, an agent-driven vision-language framework that tackles diverse radiological tasks through joint modeling of natural language, image volumes, and analytical metrics. VoxelPrompt is multi-modal and versatile \u2026"}]
