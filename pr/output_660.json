'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [A Comparison of Parameter-Efficient ASR Domain Adaptation Me'
[{"title": "Understanding emergent abilities of language models from the loss perspective", "link": "https://arxiv.org/pdf/2403.15796", "details": "Z Du, A Zeng, Y Dong, J Tang - arXiv preprint arXiv:2403.15796, 2024", "abstract": "Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) \u2026"}, {"title": "Grounding and Enhancing Grid-based Models for Neural Fields", "link": "https://arxiv.org/pdf/2403.20002", "details": "Z Zhao, F Fan, W Liao, J Yan - arXiv preprint arXiv:2403.20002, 2024", "abstract": "Many contemporary studies utilize grid-based models for neural field representation, but a systematic analysis of grid-based models is still missing, hindering the improvement of those models. Therefore, this paper introduces a theoretical \u2026"}, {"title": "Generative Language Models for Personalized Information Understanding", "link": "https://scholarworks.umass.edu/cgi/viewcontent.cgi%3Farticle%3D4123%26context%3Ddissertations_2", "details": "P Cai - 2024", "abstract": "A major challenge in information understanding stems from the diverse nature of the audience, where individuals possess varying preferences, experiences, educational and cultural backgrounds. Consequently, adopting a one-size-fits-all approach to \u2026"}, {"title": "A Diffusion Model with State Estimation for Degradation-Blind Inverse Imaging", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/28023/28060", "details": "L Ji, Z Rao, SJ Pan, C Lei, Q Chen - Proceedings of the AAAI Conference on Artificial \u2026, 2024", "abstract": "Solving the task of inverse imaging problems can restore unknown clean images from input measurements that have incomplete information. Utilizing powerful generative models, such as denoising diffusion models, could better tackle the ill \u2026"}, {"title": "Africa-Centric Self-Supervised Pre-Training for Multilingual Speech Representation in a Sub-Saharan Context", "link": "https://arxiv.org/pdf/2404.02000", "details": "A Caubri\u00e8re, E Gauthier - arXiv preprint arXiv:2404.02000, 2024", "abstract": "We present the first self-supervised multilingual speech model trained exclusively on African speech. The model learned from nearly 60 000 hours of unlabeled speech segments in 21 languages and dialects spoken in sub-Saharan Africa. On the SSA \u2026"}, {"title": "Invertible Diffusion Models for Compressed Sensing", "link": "https://arxiv.org/pdf/2403.17006", "details": "B Chen, Z Zhang, W Li, C Zhao, J Yu, S Zhao, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While deep neural networks (NN) significantly advance image compressed sensing (CS) by improving reconstruction quality, the necessity of training current CS NNs from scratch constrains their effectiveness and hampers rapid deployment. Although \u2026"}, {"title": "Boosting Self-Supervision for Single-View Scene Completion via Knowledge Distillation", "link": "https://arxiv.org/pdf/2404.07933", "details": "K Han, D Muhle, F Wimbauer, D Cremers - arXiv preprint arXiv:2404.07933, 2024", "abstract": "Inferring scene geometry from images via Structure from Motion is a long-standing and fundamental problem in computer vision. While classical approaches and, more recently, depth map predictions only focus on the visible parts of a scene, the task of \u2026"}, {"title": "NeRF-MAE: Masked AutoEncoders for Self Supervised 3D representation Learning for Neural Radiance Fields", "link": "https://arxiv.org/pdf/2404.01300", "details": "MZ Irshad, S Zakahrov, V Guizilini, A Gaidon, Z Kira\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Neural fields excel in computer vision and robotics due to their ability to understand the 3D visual world such as inferring semantics, geometry, and dynamics. Given the capabilities of neural fields in densely representing a 3D scene from 2D images, we \u2026"}, {"title": "MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts", "link": "https://arxiv.org/pdf/2404.09027", "details": "Y Liao, S Jiang, Y Wang, Y Wang - arXiv preprint arXiv:2404.09027, 2024", "abstract": "Large language models like ChatGPT have shown substantial progress in natural language understanding and generation, proving valuable across various disciplines, including the medical field. Despite advancements, challenges persist \u2026"}]
