[{"title": "Verifiable Summarization of Electronic Health Records Using Large Language Models to Support Chart Review", "link": "https://www.medrxiv.org/content/10.1101/2025.06.02.25328807.full.pdf", "details": "R Verma, E Alsentzer, Z Strasser, L Chang, K Roman\u2026 - medRxiv, 2025", "abstract": "Information overload in electronic health records (EHRs) hampers clinicians' ability to efficiently extract and synthesize critical information from a patient's longitudinal health record, leading to increased cognitive burden and delays in care. This study \u2026"}, {"title": "EuroGEST: Investigating gender stereotypes in multilingual language models", "link": "https://arxiv.org/pdf/2506.03867", "details": "J Rowe, M Klimaszewski, L Guillou, S Vallor, A Birch - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models increasingly support multiple languages, yet most benchmarks for gender bias remain English-centric. We introduce EuroGEST, a dataset designed to measure gender-stereotypical reasoning in LLMs across English \u2026", "entry_id": "http://arxiv.org/abs/2506.03867v1", "updated": "2025-06-04 11:58:18", "published": "2025-06-04 11:58:18", "authors": "Jacqueline Rowe;Mateusz Klimaszewski;Liane Guillou;Shannon Vallor;Alexandra Birch", "summary": "Large language models increasingly support multiple languages, yet most\nbenchmarks for gender bias remain English-centric. We introduce EuroGEST, a\ndataset designed to measure gender-stereotypical reasoning in LLMs across\nEnglish and 29 European languages. EuroGEST builds on an existing\nexpert-informed benchmark covering 16 gender stereotypes, expanded in this work\nusing translation tools, quality estimation metrics, and morphological\nheuristics. Human evaluations confirm that our data generation method results\nin high accuracy of both translations and gender labels across languages. We\nuse EuroGEST to evaluate 24 multilingual language models from six model\nfamilies, demonstrating that the strongest stereotypes in all models across all\nlanguages are that women are 'beautiful', 'empathetic' and 'neat' and men are\n'leaders', 'strong, tough' and 'professional'. We also show that larger models\nencode gendered stereotypes more strongly and that instruction finetuning does\nnot consistently reduce gendered stereotypes. Our work highlights the need for\nmore multilingual studies of fairness in LLMs and offers scalable methods and\nresources to audit gender bias across languages.", "comment": "8 pages, 6 figures, 1 table", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2506.03867v1;http://arxiv.org/pdf/2506.03867v1", "pdf_url": "http://arxiv.org/pdf/2506.03867v1"}, {"title": "ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations", "link": "https://arxiv.org/pdf/2506.03763", "details": "QH Pham, TD Nguyen, T Pham, AT Luu, DQ Nguyen - arXiv preprint arXiv \u2026, 2025", "abstract": "The capabilities of large language models (LLMs) have been enhanced by training on data that reflects human thought processes, such as the Chain-of-Thought format. However, evidence suggests that the conventional scheme of next-word prediction \u2026", "entry_id": "http://arxiv.org/abs/2506.03763v1", "updated": "2025-06-04 09:27:21", "published": "2025-06-04 09:27:21", "authors": "Quang Hieu Pham;Thuy Duong Nguyen;Tung Pham;Anh Tuan Luu;Dat Quoc Nguyen", "summary": "The capabilities of large language models (LLMs) have been enhanced by\ntraining on data that reflects human thought processes, such as the\nChain-of-Thought format. However, evidence suggests that the conventional\nscheme of next-word prediction may not fully capture how humans learn to think.\nInspired by how humans generalize mathematical reasoning, we propose a new\napproach named ClozeMath to fine-tune LLMs for mathematical reasoning. Our\nClozeMath involves a text-infilling task that predicts masked equations from a\ngiven solution, analogous to cloze exercises used in human learning.\nExperiments on GSM8K, MATH, and GSM-Symbolic show that ClozeMath surpasses the\nstrong baseline Masked Thought in performance and robustness, with two\ntest-time scaling decoding algorithms, Beam Search and Chain-of-Thought\ndecoding. Additionally, we conduct an ablation study to analyze the effects of\nvarious architectural and implementation choices on our approach.", "comment": "Accepted to ACL 2025 Findings", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2506.03763v1;http://arxiv.org/pdf/2506.03763v1", "pdf_url": "http://arxiv.org/pdf/2506.03763v1"}, {"title": "Vocabulary-free few-shot learning for Vision-Language Models", "link": "https://arxiv.org/pdf/2506.04005", "details": "M Zanella, C Fuchs, IB Ayed, C De Vleeschouwer - arXiv preprint arXiv:2506.04005, 2025", "abstract": "Recent advances in few-shot adaptation for Vision-Language Models (VLMs) have greatly expanded their ability to generalize across tasks using only a few labeled examples. However, existing approaches primarily build upon the strong zero-shot \u2026", "entry_id": "http://arxiv.org/abs/2506.04005v1", "updated": "2025-06-04 14:32:32", "published": "2025-06-04 14:32:32", "authors": "Maxime Zanella;Cl\u00e9ment Fuchs;Ismail Ben Ayed;Christophe De Vleeschouwer", "summary": "Recent advances in few-shot adaptation for Vision-Language Models (VLMs) have\ngreatly expanded their ability to generalize across tasks using only a few\nlabeled examples. However, existing approaches primarily build upon the strong\nzero-shot priors of these models by leveraging carefully designed,\ntask-specific prompts. This dependence on predefined class names can restrict\ntheir applicability, especially in scenarios where exact class names are\nunavailable or difficult to specify. To address this limitation, we introduce\nvocabulary-free few-shot learning for VLMs, a setting where target class\ninstances - that is, images - are available but their corresponding names are\nnot. We propose Similarity Mapping (SiM), a simple yet effective baseline that\nclassifies target instances solely based on similarity scores with a set of\ngeneric prompts (textual or visual), eliminating the need for carefully\nhandcrafted prompts. Although conceptually straightforward, SiM demonstrates\nstrong performance, operates with high computational efficiency (learning the\nmapping typically takes less than one second), and provides interpretability by\nlinking target classes to generic prompts. We believe that our approach could\nserve as an important baseline for future research in vocabulary-free few-shot\nlearning. Code is available at\nhttps://github.com/MaxZanella/vocabulary-free-FSL.", "comment": "Accepted at CVPR Workshops 2025", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2506.04005v1;http://arxiv.org/pdf/2506.04005v1", "pdf_url": "http://arxiv.org/pdf/2506.04005v1"}, {"title": "Iterative refinement and goal articulation to optimize large language models for clinical information extraction", "link": "https://www.nature.com/articles/s41746-025-01686-z", "details": "D Hein, A Christie, M Holcomb, B Xie, AJ Jain, J Vento\u2026 - npj Digital Medicine, 2025", "abstract": "Extracting structured data from free-text medical records at scale is laborious, and traditional approaches struggle in complex clinical domains. We present a novel, end- to-end pipeline leveraging large language models (LLMs) for highly accurate \u2026"}]
