[{"title": "OT-DETECTOR: Delving into Optimal Transport for Zero-shot Out-of-Distribution Detection", "link": "https://arxiv.org/pdf/2503.06442", "details": "Y Liu, H Tang, H Zhang, J Qin, Z Li - arXiv preprint arXiv:2503.06442, 2025", "abstract": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability and safety of machine learning models in real-world applications. While zero-shot OOD detection, which requires no training on in-distribution (ID) data, has become feasible with the \u2026"}, {"title": "Federated Koopman-Reservoir Learning for Large-Scale Multivariate Time-Series Anomaly Detection", "link": "https://arxiv.org/pdf/2503.11255", "details": "LT Le, TA Nguyen, H Shu, S Seneviratne, CS Hong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The proliferation of edge devices has dramatically increased the generation of multivariate time-series (MVTS) data, essential for applications from healthcare to smart cities. Such data streams, however, are vulnerable to anomalies that signal \u2026"}, {"title": "Fusionformer: A Novel Adversarial Transformer Utilizing Fusion Attention for Multivariate Anomaly Detection", "link": "https://ieeexplore.ieee.org/abstract/document/10922726/", "details": "C Wang, Z Wang, H Dong, S Lauria, W Liu, Y Wang\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "Multivariate time series forecasting (MTSF) is of significant importance in the enhancement and optimization of real-world applications. The task of MTSF poses substantial challenges due to the unpredictability of temporal patterns and the \u2026"}, {"title": "Series clustering and dynamic periodic patching-based transformer for multivariate time series forecasting", "link": "https://www.sciencedirect.com/science/article/pii/S1568494625002911", "details": "Y Wang, X Wu, J Zhang, W Wang, L Zheng, J Shang - Applied Soft Computing, 2025", "abstract": "Multivariate time series forecasting (MTSF) is widely employed in research-intensive domains, such as weather forecasting. Recently, Transformer-based models have outstanding ability to achieve SOTA performance, benefiting from its self-attention \u2026"}, {"title": "Tinyr1-32b-preview: Boosting accuracy with branch-merge distillation", "link": "https://arxiv.org/pdf/2503.04872", "details": "L Sun, G Zhao, X Jian, Y Wu, W Lin, Y Zhu, L Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The challenge of reducing the size of Large Language Models (LLMs) while maintaining their performance has gained significant attention. However, existing methods, such as model distillation and transfer learning, often fail to achieve high \u2026"}, {"title": "InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse Problems", "link": "https://arxiv.org/pdf/2504.01689", "details": "N Elata, H Chung, JC Ye, T Michaeli, M Elad - arXiv preprint arXiv:2504.01689, 2025", "abstract": "Diffusion Models have demonstrated remarkable capabilities in handling inverse problems, offering high-quality posterior-sampling-based solutions. Despite significant advances, a fundamental trade-off persists, regarding the way the \u2026"}, {"title": "Contrastive Learning via Randomly Generated Deep Supervision", "link": "https://ieeexplore.ieee.org/abstract/document/10890867/", "details": "S Wang, Z Ma, KH Chan, Y Liu, T Tong, Q Gao, G Zhai\u2026 - ICASSP 2025-2025 IEEE \u2026, 2025", "abstract": "Unsupervised visual representation learning has gained significant attention in the computer vision community, driven by recent advancements in contrastive learning. Most existing contrastive learning frameworks rely on instance discrimination as a \u2026"}, {"title": "[TINY] Vision language models can implicitly quantify aleatoric uncertainty", "link": "https://openreview.net/pdf%3Fid%3DBkWVcXevTs", "details": "X Wang, E Nalisnick - \u2026 Workshop: Quantify Uncertainty and Hallucination in \u2026", "abstract": "Recent advances in vision language models (VLMs), such as GPT-4o, have revolutionized visual reasoning by enabling zero-shot task completion through natural language instructions. In this paper, we study VLMs' ability to detect input \u2026"}, {"title": "TLAC: Two-stage LMM Augmented CLIP for Zero-Shot Classification", "link": "https://arxiv.org/pdf/2503.12206", "details": "A Munir, FZ Qureshi, MH Khan, M Ali - arXiv preprint arXiv:2503.12206, 2025", "abstract": "Contrastive Language-Image Pretraining (CLIP) has shown impressive zero-shot performance on image classification. However, state-of-the-art methods often rely on fine-tuning techniques like prompt learning and adapter-based tuning to optimize \u2026"}]
