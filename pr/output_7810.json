[{"title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models", "link": "https://arxiv.org/pdf/2410.05639", "details": "R Zhao, ZL Thai, Y Zhang, S Hu, Y Ba, J Zhou, J Cai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The performance of Large Language Models (LLMs) is substantially influenced by the pretraining corpus, which consists of vast quantities of unsupervised data processed by the models. Despite its critical role in model performance, ensuring the \u2026"}, {"title": "Efficient Transfer Learning with Sequential and Multi-Modal Approaches for Electronic Health Records", "link": "https://aaltodoc.aalto.fi/bitstreams/a482ee97-2ad4-444a-895a-e43c89af1fc4/download", "details": "Y Kumar - 2024", "abstract": "The digital transformation in healthcare has dramatically increased data availability, yet the potential for data-driven insights is frequently constrained by the quality of data. Securing high-quality data is particularly challenging in fields like healthcare \u2026"}, {"title": "Advancing Medical Radiograph Representation Learning: A Hybrid Pre-training Paradigm with Multilevel Semantic Granularity", "link": "https://arxiv.org/pdf/2410.00448", "details": "H Jiang, X Hao, Y Huang, C Ma, J Zhang, Y Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces an innovative approach to Medical Vision-Language Pre- training (Med-VLP) area in the specialized context of radiograph representation learning. While conventional methods frequently merge textual annotations into \u2026"}, {"title": "TiC-LM: A Multi-Year Benchmark for Continual Pretraining of Language Models", "link": "https://openreview.net/pdf%3Fid%3DPpSDVE5rAy", "details": "J Li, M Armandpour, SI Mirzadeh, S Mehta, V Shankar\u2026 - NeurIPS 2024 Workshop on \u2026", "abstract": "Large language models (LLMs) are trained on data crawled over many years from the web. We investigate how quickly LLMs become outdated as the world evolves with time and how to best update them with newer data. Specifically, we simulate a \u2026"}, {"title": "An Efficient Contrastive Unimodal Pretraining Method for EHR Time Series Data", "link": "https://arxiv.org/pdf/2410.09199", "details": "R King, S Kodali, C Krueger, T Yang, BJ Mortazavi - arXiv preprint arXiv:2410.09199, 2024", "abstract": "Machine learning has revolutionized the modeling of clinical timeseries data. Using machine learning, a Deep Neural Network (DNN) can be automatically trained to learn a complex mapping of its input features for a desired task. This is particularly \u2026"}, {"title": "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "link": "https://arxiv.org/pdf/2410.05077", "details": "FM Molfese, S Conia, R Orlando, R Navigli - arXiv preprint arXiv:2410.05077, 2024", "abstract": "Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have \u2026"}, {"title": "Optimized biomedical entity relation extraction method with data augmentation and classification using GPT-4 and Gemini", "link": "https://academic.oup.com/database/article/doi/10.1093/database/baae104/7816180", "details": "CP Phan, B Phan, JH Chiang - Database, 2024", "abstract": "Despite numerous research efforts by teams participating in the BioCreative VIII Track 01 employing various techniques to achieve the high accuracy of biomedical relation tasks, the overall performance in this area still has substantial room for \u2026"}, {"title": "Assessments of Generative AI as Clinical Decision Support Ought to be Incorporated into Randomised Controlled Trials of Electronic Alerts for Acute Kidney Injury", "link": "https://www.mcpdigitalhealth.org/article/S2949-7612\\(24\\)00101-9/fulltext", "details": "DJ Sexton, C Judge - Mayo Clinic Proceedings: Digital Health", "abstract": "Acute Kidney Injury (AKI), characterised by an acute deterioration in kidney function occurs in approximately 25% of hospitalised individuals and is associated with prolonged stay, higher cost and increased morbidity and mortality. 1 Clinical \u2026"}, {"title": "Aligning Language Models Using Follow-up Likelihood as Reward Signal", "link": "https://arxiv.org/pdf/2409.13948", "details": "C Zhang, D Chong, F Jiang, C Tang, A Gao, G Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In natural human-to-human conversations, participants often receive feedback signals from one another based on their follow-up reactions. These reactions can include verbal responses, facial expressions, changes in emotional state, and other \u2026"}]
