[{"title": "Scalable information extraction from free text electronic health records using large language models", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/08/10/2024.08.08.24311237.full.pdf", "details": "B Gu, V Shao, Z Liao, V Carducci, S Romero-Brufau\u2026 - medRxiv, 2024", "abstract": "Background: A vast amount of potentially useful information such as description of patient symptoms, family, and social history is recorded as free-text notes in electronic health records (EHRs) but is difficult to reliably extract at scale, limiting \u2026"}, {"title": "Steering Language Models with Game-Theoretic Solvers", "link": "https://openreview.net/pdf%3Fid%3D5QLtIodDmu", "details": "I Gemp, R Patel, Y Bachrach, M Lanctot, V Dasagi\u2026 - Agentic Markets Workshop at ICML \u2026", "abstract": "Mathematical models of strategic interactions among rational agents have long been studied in game theory. However the interactions studied are often over a small set of discrete actions which is very different from how humans communicate in natural \u2026"}, {"title": "Order-Agnostic Data Augmentation for Few-Shot Named Entity Recognition", "link": "https://aclanthology.org/2024.acl-long.421/", "details": "H Wang, L Cheng, W Zhang, L Bing - Proceedings of the 62nd Annual Meeting of \u2026, 2024", "abstract": "Data augmentation (DA) methods have been proven to be effective for pre-trained language models (PLMs) in low-resource settings, including few-shot named entity recognition (NER). However, existing NER DA techniques either perform rule-based \u2026"}, {"title": "E5-V: Universal Embeddings with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2407.12580", "details": "T Jiang, M Song, Z Zhang, H Huang, W Deng, F Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal large language models (MLLMs) have shown promising advancements in general visual and language understanding. However, the representation of multimodal information using MLLMs remains largely unexplored. In this work, we \u2026"}, {"title": "MIBench: Evaluating Multimodal Large Language Models over Multiple Images", "link": "https://arxiv.org/pdf/2407.15272", "details": "H Liu, X Zhang, H Xu, Y Shi, C Jiang, M Yan, J Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Built on the power of LLMs, numerous multimodal large language models (MLLMs) have recently achieved remarkable performance on various vision-language tasks across multiple benchmarks. However, most existing MLLMs and benchmarks \u2026"}, {"title": "Knowledge Injected Multimodal Irregular EHRs Model for Medical Prediction", "link": "https://link.springer.com/chapter/10.1007/978-3-031-67751-9_3", "details": "S Liu, H Chen - \u2026 Workshop on Trustworthy Artificial Intelligence for \u2026, 2024", "abstract": "The health conditions among patients in intensive care units (ICUs) are essential for providing optimal care and improving patient outcomes. Electronic health records (EHRs) serve as a valuable source of information in ICUs, capturing numerical time \u2026"}, {"title": "Enhanced Fine-Tuning of Lightweight Domain-Specific Q&A model Based on Large Language Models", "link": "https://nkcs.iops.ai/wp-content/uploads/2024/08/ISSRE24-Self-Evolution.pdf", "details": "S Zhang, P Zhu, M Ma, J Wang, Y Sun, D Li, J Wang\u2026 - training", "abstract": "Large language models (LLMs) excel at general question-answering (Q&A) but often fall short in specialized domains due to a lack of domain-specific knowledge. Commercial companies face the dual challenges of privacy protection and resource \u2026"}, {"title": "RadGraph-XL: A Large-Scale Expert-Annotated Dataset for Entity and Relation Extraction from Radiology Reports", "link": "https://aclanthology.org/2024.findings-acl.765/", "details": "JB Delbrouck, P Chambon, Z Chen, M Varma\u2026 - Findings of the Association \u2026, 2024", "abstract": "In order to enable extraction of structured clinical data from unstructured radiology reports, we introduce RadGraph-XL, a large-scale, expert-annotated dataset for clinical entity and relation extraction. RadGraph-XL consists of 2,300 radiology \u2026"}]
