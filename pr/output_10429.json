[{"title": "Guiding Generative Protein Language Models with Reinforcement Learning", "link": "https://arxiv.org/pdf/2412.12979", "details": "F Stocco, M Artigues-Lleixa, A Hunklinger, T Widatalla\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Autoregressive protein language models (pLMs) have emerged as powerful tools to efficiently design functional proteins with extraordinary diversity, as evidenced by the successful generation of diverse enzyme families, including lysozymes or carbonic \u2026"}, {"title": "ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models", "link": "https://arxiv.org/pdf/2412.12848", "details": "Y Sun, W Gao, J Ma, H Lin, Z Luo, W Zhang - arXiv preprint arXiv:2412.12848, 2024", "abstract": "With the rise and widespread use of Large Language Models (LLMs), ensuring their safety is crucial to prevent harm to humans and promote ethical behaviors. However, directly assessing value valence (ie, support or oppose) by leveraging large-scale \u2026"}, {"title": "Interpretable LLM-based Table Question Answering", "link": "https://arxiv.org/pdf/2412.12386", "details": "I Brugere, S Sharma, S Kariyappa, AT Nguyen, F Lecue - arXiv preprint arXiv \u2026, 2024", "abstract": "Interpretability for Table Question Answering (Table QA) is critical, particularly in high- stakes industries like finance or healthcare. Although recent approaches using Large Language Models (LLMs) have significantly improved Table QA performance, their \u2026"}, {"title": "Linear Calibration Approach to Knowledge-free Group Robust Classification", "link": "https://bmva-archive.org.uk/bmvc/2024/papers/Paper_38/paper.pdf", "details": "R Ishizaki, S Yamagami, Y Goto, G Irie - 2024", "abstract": "Large-scale pre-trained vision-language models such as CLIP have shown remarkable performance on various downstream tasks. However, such a model often learns not only the information that is truly useful for classification, but also group \u2026"}, {"title": "Data Mining and Machine Learning for Healthcare Fraud Identification", "link": "https://www.researchgate.net/profile/Freeman-Paul/publication/387137084_Data_Mining_and_Machine_Learning_for_Healthcare_Fraud_Identification/links/6761f388e9b25e24af5ddc23/Data-Mining-and-Machine-Learning-for-Healthcare-Fraud-Identification.pdf", "details": "M Herland, TM Khoshgoftaar, RA Bauder", "abstract": "Healthcare fraud is a pervasive issue that significantly impacts the healthcare industry, driving up costs and compromising patient care. Detecting and preventing such fraudulent activities requires sophisticated approaches, and data mining and \u2026"}, {"title": "Leveraging Machine Learning for Healthcare Compliance and Fraud Detect", "link": "https://www.researchgate.net/profile/Freeman-Paul/publication/387137335_Leveraging_Machine_Learning_for_Healthcare_Compliance_and_Fraud_Detect/links/6761f49a1da39f14957f4da6/Leveraging-Machine-Learning-for-Healthcare-Compliance-and-Fraud-Detect.pdf", "details": "MS Alam, P Rai, RK Tiwari", "abstract": "The integration of machine learning (ML) into healthcare compliance and fraud detection has revolutionized the way healthcare organizations approach regulatory adherence and fraudulent activity prevention. This article explores the role of ML in \u2026"}, {"title": "Assessing the Limitations of Large Language Models in Clinical Fact Decomposition", "link": "https://arxiv.org/pdf/2412.12422", "details": "M Munnangi, A Swaminathan, JA Fries, J Jindal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Verifying factual claims is critical for using large language models (LLMs) in healthcare. Recent work has proposed fact decomposition, which uses LLMs to rewrite source text into concise sentences conveying a single piece of information, as \u2026"}, {"title": "Boosting Test Performance with Importance Sampling--a Subpopulation Perspective", "link": "https://arxiv.org/pdf/2412.13003", "details": "H Shen, Z Zhao - arXiv preprint arXiv:2412.13003, 2024", "abstract": "Despite empirical risk minimization (ERM) is widely applied in the machine learning community, its performance is limited on data with spurious correlation or subpopulation that is introduced by hidden attributes. Existing literature proposed \u2026"}]
