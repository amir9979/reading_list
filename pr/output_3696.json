[{"title": "INFusion: Diffusion Regularized Implicit Neural Representations for 2D and 3D accelerated MRI reconstruction", "link": "https://arxiv.org/pdf/2406.13895", "details": "Y Arefeen, B Levac, Z Stoebner, J Tamir - arXiv preprint arXiv:2406.13895, 2024", "abstract": "Implicit Neural Representations (INRs) are a learning-based approach to accelerate Magnetic Resonance Imaging (MRI) acquisitions, particularly in scan-specific settings when only data from the under-sampled scan itself are available. Previous \u2026"}, {"title": "Neural Fields as Distributions: Signal Processing Beyond Euclidean Space", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Rebain_Neural_Fields_as_Distributions_Signal_Processing_Beyond_Euclidean_Space_CVPR_2024_paper.pdf", "details": "D Rebain, S Yazdani, KM Yi, A Tagliasacchi - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "Neural fields have emerged as a powerful and broadly applicable method for representing signals. However in contrast to classical discrete digital signal processing the portfolio of tools to process such representations is still severely \u2026"}, {"title": "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models", "link": "https://arxiv.org/pdf/2407.05131", "details": "P Xia, K Zhu, H Li, H Zhu, Y Li, G Li, L Zhang, H Yao - arXiv preprint arXiv:2407.05131, 2024", "abstract": "The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has enhanced medical diagnosis. However, current Med-LVLMs frequently encounter factual issues, often generating responses that do not align with established medical \u2026"}, {"title": "Dude: Dual Distribution-Aware Context Prompt Learning For Large Vision-Language Model", "link": "https://arxiv.org/pdf/2407.04489", "details": "DMH Nguyen, AT Le, TQ Nguyen, NT Diep, T Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Prompt learning methods are gaining increasing attention due to their ability to customize large vision-language models to new domains using pre-trained contextual knowledge and minimal training data. However, existing works typically \u2026"}, {"title": "CryoViT: Efficient Segmentation of Cryogenic Electron Tomograms with Vision Foundation Models", "link": "https://www.biorxiv.org/content/10.1101/2024.06.26.600701.full.pdf", "details": "SR Gupte, C Hou, GH Wu, JG Galaz-Montoya, W Chiu\u2026 - bioRxiv, 2024", "abstract": "Cryogenic electron tomography (cryoET) directly visualizes subcellular structures in 3D at the nanometer scale. Quantitative analyses of cryoET data can reveal structural biomarkers of diseases, provide novel mechanistic insights, and inform the effects of \u2026"}, {"title": "Low-Rank Adaptation for Multilingual Summarization: An Empirical Study", "link": "https://aclanthology.org/2024.findings-naacl.77.pdf", "details": "C Whitehouse, F Huot, J Bastings, M Dehghani, CC Lin\u2026 - Findings of the Association \u2026, 2024", "abstract": "Although the advancements of pre-trained Large Language Models have significantly accelerated recent progress in NLP, their ever-increasing size poses significant challenges for conventional fine-tuning, especially in memory-intensive \u2026"}, {"title": "Scaling Laws for Linear Complexity Language Models", "link": "https://arxiv.org/pdf/2406.16690", "details": "X Shen, D Li, R Leng, Z Qin, W Sun, Y Zhong - arXiv preprint arXiv:2406.16690, 2024", "abstract": "The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their \u2026"}, {"title": "Speculative Speech Recognition by Audio-Prefixed Low-Rank Adaptation of Language Models", "link": "https://arxiv.org/pdf/2407.04641", "details": "B Yusuf, MK Baskar, A Rosenberg, B Ramabhadran - arXiv preprint arXiv:2407.04641, 2024", "abstract": "This paper explores speculative speech recognition (SSR), where we empower conventional automatic speech recognition (ASR) with speculation capabilities, allowing the recognizer to run ahead of audio. We introduce a metric for measuring \u2026"}, {"title": "Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation", "link": "https://arxiv.org/pdf/2407.05890", "details": "J Chen, B Lin, X Liu, X Liang, KYK Wong - arXiv preprint arXiv:2407.05890, 2024", "abstract": "LLM-based agents have demonstrated impressive zero-shot performance in the vision-language navigation (VLN) task. However, these zero-shot methods focus only on solving high-level task planning by selecting nodes in predefined navigation \u2026"}]
