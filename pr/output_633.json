'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Can 3D Vision-Language Models Truly Understand Natural'
[{"title": "Adaptive Prompt Routing for Arbitrary Text Style Transfer with Pre-trained Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29832/31446", "details": "Q Liu, J Qin, W Ye, H Mou, Y He, K Wang - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Recently, arbitrary text style transfer (TST) has made significant progress with the paradigm of prompt learning. In this paradigm, researchers often design or search for a fixed prompt for any input. However, existing evidence shows that large language \u2026"}, {"title": "COVID-19 outbreaks surveillance through text mining applied to electronic health records", "link": "https://link.springer.com/article/10.1186/s12879-024-09250-y", "details": "HAL Rocha, EZM Solha, V Furtado, FL Justino\u2026 - BMC infectious diseases, 2024", "abstract": "Background The COVID-19 pandemic has caused significant disruptions to everyday life and has had social, political, and financial consequences that will persist for years. Several initiatives with intensive use of technology were quickly developed in \u2026"}, {"title": "Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language Models", "link": "https://arxiv.org/pdf/2403.13588", "details": "C Feng, Y Sun, K Li, P Zhou, J Lv, A Lu - arXiv preprint arXiv:2403.13588, 2024", "abstract": "As Pre-trained Language Models (PLMs), a popular approach for code intelligence, continue to grow in size, the computational cost of their usage has become prohibitively expensive. Prompt learning, a recent development in the field of natural \u2026"}, {"title": "Impact of Preference Noise on the Alignment Performance of Generative Language Models", "link": "https://arxiv.org/pdf/2404.09824", "details": "Y Gao, D Alon, D Metzler - arXiv preprint arXiv:2404.09824, 2024", "abstract": "A key requirement in developing Generative Language Models (GLMs) is to have their values aligned with human values. Preference-based alignment is a widely used paradigm for this purpose, in which preferences over generation pairs are first \u2026"}, {"title": "PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid Domain Generalization", "link": "https://arxiv.org/pdf/2404.09011", "details": "Z Chen, W Wang, Z Zhao, F Su, A Men, H Meng - arXiv preprint arXiv:2404.09011, 2024", "abstract": "Domain Generalization (DG) aims to resolve distribution shifts between source and target domains, and current DG methods are default to the setting that data from source and target domains share identical categories. Nevertheless, there exists \u2026"}, {"title": "BAITSAO: Building A Foundation Model for Drug Synergy Analysis Powered by Language Models", "link": "https://www.biorxiv.org/content/10.1101/2024.04.08.588634.full.pdf", "details": "T Liu, T Chu, X Luo, H Zhao - bioRxiv, 2024", "abstract": "Drug synergy prediction is a challenging and important task in the treatment of complex diseases including cancer. In this manuscript, we present a novel Foundation Model, known as BAITSAO, for tasks related to drug synergy prediction \u2026"}, {"title": "Large Scale Self-Supervised Pretraining for Active Speaker Detection", "link": "https://ieeexplore.ieee.org/abstract/document/10447899/", "details": "O Braga, W Xia, K Johnson, A Chuang, Y Ye, O Siohan\u2026 - ICASSP 2024-2024 IEEE \u2026, 2024", "abstract": "In this work we investigate the impact of a large-scale self-supervised pretraining strategy for active speaker detection (ASD) on an unlabeled dataset consisting of over 125k hours of YouTube videos. When compared to a baseline trained from \u2026"}, {"title": "XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception", "link": "https://arxiv.org/pdf/2403.14402", "details": "HJ Han, M Anwar, J Pino, WN Hsu, M Carpuat, B Shi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is \u2026"}, {"title": "Self-Supervised Pulse-Aware Interpretable Disentangled ECG Representation Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10447945/", "details": "CT Chou, VS Tseng - ICASSP 2024-2024 IEEE International Conference on \u2026, 2024", "abstract": "Electrocardiography (ECG) is a widely used cardiac measurement for detecting cardiovascular conditions, while self-supervised learning leverages unlabeled data for model pre-training. However, current self-supervised frameworks for ECG signals \u2026"}]
