[{"title": "Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework", "link": "https://arxiv.org/pdf/2409.16146", "details": "L Chen, R Zhang, J Guo, Y Fan, X Cheng - arXiv preprint arXiv:2409.16146, 2024", "abstract": "Retrieval-augmented generation (RAG) has emerged as a popular solution to mitigate the hallucination issues of large language models. However, existing studies on RAG seldom address the issue of predictive uncertainty, ie, how likely it is \u2026"}, {"title": "The Matrix Reloaded: Towards Counterfactual Group Fairness in Machine Learning", "link": "https://openreview.net/pdf%3Fid%3DwqDiPP8Xm7", "details": "M Pinto, AV Carreiro, P Madeira, A Lopez, H Gamboa - Journal of Data-centric \u2026, 2024", "abstract": "In today's data-driven world, addressing bias is essential to minimize discriminatory outcomes and work toward fairness in machine learning models. This paper presents a novel data-centric framework for bias analysis, harnessing the power of \u2026"}, {"title": "Explainable Diagnosis Prediction through Neuro-Symbolic Integration", "link": "https://arxiv.org/pdf/2410.01855%3F", "details": "Q Lu, R Li, E Sagheb, A Wen, J Wang, L Wang, JW Fan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Diagnosis prediction is a critical task in healthcare, where timely and accurate identification of medical conditions can significantly impact patient outcomes. Traditional machine learning and deep learning models have achieved notable \u2026"}, {"title": "Harnessing Diversity for Important Data Selection in Pretraining Large Language Models", "link": "https://arxiv.org/pdf/2409.16986", "details": "C Zhang, H Zhong, K Zhang, C Chai, R Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Data selection is of great significance in pre-training large language models, given the variation in quality within the large-scale available training corpora. To achieve this, researchers are currently investigating the use of data influence to measure the \u2026"}, {"title": "Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE", "link": "https://arxiv.org/pdf/2409.17508", "details": "X Zhu, Y Hu, F Mo, M Li, J Wu - arXiv preprint arXiv:2409.17508, 2024", "abstract": "Multi-modal large language models (MLLMs) have shown impressive capabilities as a general-purpose interface for various visual and linguistic tasks. However, building a unified MLLM for multi-task learning in the medical field remains a thorny \u2026"}, {"title": "T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data", "link": "https://arxiv.org/pdf/2410.05016", "details": "H Thimonier, JLDM Costa, F Popineau, A Rimmel\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-supervision is often used for pre-training to foster performance on a downstream task by constructing meaningful representations of samples. Self-supervised learning (SSL) generally involves generating different views of the same sample and thus \u2026"}, {"title": "Cycle-GANs Generated Difference Maps to Interpret Race Prediction from Medical Images", "link": "https://link.springer.com/content/pdf/10.1007/978-3-031-72787-0.pdf%23page%3D143", "details": "A Gupta, SR Ahmed, J Patel, C Clark, YA Veturi\u2026 - Ethics and Fairness in Medical \u2026", "abstract": "Recent research has revealed the remarkable ability of artificial intelligence (AI) to identify features related to an individual's selfreported race in medical images, but what such features may be remains an unanswered question. In this work, we aim to \u2026"}, {"title": "Inference-time language model alignment via integrated value guidance", "link": "https://arxiv.org/pdf/2409.17819%3F", "details": "Z Liu, Z Zhou, Y Wang, C Yang, Y Qiao - arXiv preprint arXiv:2409.17819, 2024", "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce $\\textit {Integrated Value Guidance} $(IVG), a method that uses implicit and \u2026"}, {"title": "FaithEval: Can Your Language Model Stay Faithful to Context, Even If\" The Moon is Made of Marshmallows\"", "link": "https://arxiv.org/pdf/2410.03727", "details": "Y Ming, S Purushwalkam, S Pandit, Z Ke, XP Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Ensuring faithfulness to context in large language models (LLMs) and retrieval- augmented generation (RAG) systems is crucial for reliable deployment in real-world applications, as incorrect or unsupported information can erode user trust. Despite \u2026"}]
