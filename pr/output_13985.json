[{"title": "MOAT: Evaluating LMMs for Capability Integration and Instruction Grounding", "link": "https://arxiv.org/pdf/2503.09348", "details": "Z Ye, M Sun, H Gao, C Yu, Y Shi - arXiv preprint arXiv:2503.09348, 2025", "abstract": "Large multimodal models (LMMs) have demonstrated significant potential as generalists in vision-language (VL) tasks. However, there remains a significant gap between state-of-the-art LMMs and human performance when it comes to complex \u2026"}, {"title": "Inference Retrieval-Augmented Multi-Modal Chain-of-Thoughts Reasoning for Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10888701/", "details": "Q He, S Qian, J Zhang, C Wang - ICASSP 2025-2025 IEEE International Conference \u2026, 2025", "abstract": "Recent advancements in Large Language Models (LLMs) have catalyzed the exploration of Chain of Thought (CoT) approaches, particularly in extending their application to multimodal tasks to enhance reasoning capabilities. However, current \u2026"}, {"title": "Language Models as Knowledge Bases?", "link": "https://scispace.com/pdf/language-models-as-knowledge-bases-2bs7zawas9.pdf", "details": "FPT Rockt\u00e4schel, P Lewis, A Bakhtin, Y Wu\u2026", "abstract": "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the \u2026"}, {"title": "DiffPO: Diffusion-styled Preference Optimization for Efficient Inference-Time Alignment of Large Language Models", "link": "https://arxiv.org/pdf/2503.04240", "details": "R Chen, W Chai, Z Yang, X Zhang, JT Zhou, T Quek\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inference-time alignment provides an efficient alternative for aligning LLMs with humans. However, these approaches still face challenges, such as limited scalability due to policy-specific value functions and latency during the inference phase. In this \u2026"}, {"title": "Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2503.06749", "details": "W Huang, B Jia, Z Zhai, S Cao, Z Ye, F Zhao, Y Hu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning capabilities in LLMs purely through Reinforcement Learning (RL). Inspired by this breakthrough, we explore how RL can be utilized to enhance the reasoning \u2026"}, {"title": "EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees", "link": "https://arxiv.org/pdf/2503.08893", "details": "Z Zeng, Y Wang, H Hajishirzi, PW Koh - arXiv preprint arXiv:2503.08893, 2025", "abstract": "An ideal model evaluation should achieve two goals: identifying where the model fails and providing actionable improvement guidance. Toward these goals for Language Model (LM) evaluations, we formulate the problem of generating a \u2026"}, {"title": "QA-Calibration of language model confidence scores", "link": "https://www.amazon.science/publications/qa-calibration-of-language-model-confidence-scores", "details": "A Mastakouri, E Kirschbaum, S Kasiviswanathan\u2026 - 2025", "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim \u2026"}, {"title": "LLM-PS: Empowering Large Language Models for Time Series Forecasting with Temporal Patterns and Semantics", "link": "https://arxiv.org/pdf/2503.09656", "details": "J Tang, S Chen, C Gong, J Zhang, D Tao - arXiv preprint arXiv:2503.09656, 2025", "abstract": "Time Series Forecasting (TSF) is critical in many real-world domains like financial planning and health monitoring. Recent studies have revealed that Large Language Models (LLMs), with their powerful in-contextual modeling capabilities, hold \u2026"}, {"title": "XIFBench: Evaluating Large Language Models on Multilingual Instruction Following", "link": "https://arxiv.org/pdf/2503.07539%3F", "details": "Z Li, K Chen, Y Long, X Bai, Y Zhang, X Wei, J Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable instruction-following capabilities across various applications. However, their performance in multilingual settings remains poorly understood, as existing evaluations lack fine-grained \u2026"}]
