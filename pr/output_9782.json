[{"title": "Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising", "link": "https://arxiv.org/pdf/2411.03053%3F", "details": "T Huang, J Meng, H Chen, G Zheng, X Yang, X Yi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We investigate the construction of gradient-guided conditional diffusion models for reconstructing private images, focusing on the adversarial interplay between differential privacy noise and the denoising capabilities of diffusion models. While \u2026"}, {"title": "Content-Style Learning from Unaligned Domains: Identifiability under Unknown Latent Dimensions", "link": "https://arxiv.org/pdf/2411.03755", "details": "S Shrestha, X Fu - arXiv preprint arXiv:2411.03755, 2024", "abstract": "Understanding identifiability of latent content and style variables from unaligned multi- domain data is essential for tasks such as domain translation and data generation. Existing works on content-style identification were often developed under somewhat \u2026"}, {"title": "DRESS: Disentangled Representation-based Self-Supervised Meta-Learning for Diverse Tasks", "link": "https://openreview.net/pdf%3Fid%3DAguQIV9CeN", "details": "W Cui, Y Sui, JC Cresswell, K Golestan - NeurIPS 2024 Workshop: Self-Supervised Learning \u2026", "abstract": "Meta-learning represents a strong class of approaches for solving few-shot learning tasks. Nonetheless, recent research suggests that simply pre-training a generic encoder can potentially surpass meta-learning algorithms. In this paper, we first \u2026"}, {"title": "Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc Explainability in Image Classification", "link": "https://arxiv.org/pdf/2411.05698%3F", "details": "A De Santis, R Campi, M Bianchi, M Brambilla - arXiv preprint arXiv:2411.05698, 2024", "abstract": "Convolutional Neural Networks (CNNs) have seen significant performance improvements in recent years. However, due to their size and complexity, they function as black-boxes, leading to transparency concerns. State-of-the-art saliency \u2026"}, {"title": "Pretrained Reversible Generation as Unsupervised Visual Representation Learning", "link": "https://arxiv.org/pdf/2412.01787", "details": "R Xue, J Zhang, Y Niu, D Shen, B Ma, Y Liu, J Yang - arXiv preprint arXiv:2412.01787, 2024", "abstract": "Recent generative models based on score matching and flow matching have significantly advanced generation tasks, but their potential in discriminative tasks remains underexplored. Previous approaches, such as generative classifiers, have \u2026"}, {"title": "Fast Sampling via Discrete Non-Markov Diffusion Models with Predetermined Transition Time", "link": "https://openreview.net/pdf%3Fid%3DKkYZmepjHn", "details": "Z Chen, H Yuan, Y Li, Y Kou, J Zhang, Q Gu - The Thirty-eighth Annual Conference \u2026, 2024", "abstract": "Discrete diffusion models have emerged as powerful tools for high-quality data generation. Despite their success in discrete spaces, such as text generation tasks, the acceleration of discrete diffusion models remains under-explored. In this paper \u2026"}, {"title": "On Domain Generalization Datasets as Proxy Benchmarks for Causal Representation Learning", "link": "https://openreview.net/pdf%3Fid%3DLbFK9pUlA5", "details": "OE Salaudeen, N Chiou, S Koyejo - NeurIPS 2024 Causal Representation Learning \u2026", "abstract": "Benchmarking causal representation learning for real-world high-dimensional settings where most relevant causal variables are not directly observed remains a challenge. Notably, one promise of causal representations is their robustness to \u2026"}, {"title": "Contrastive Learning using Synthetic Images Generated from Real Images", "link": "https://openaccess.thecvf.com/content/ACCV2024/papers/Sasaya_Contrastive_Learning_using_Synthetic_Images_Generated_from_Real_Images_ACCV_2024_paper.pdf", "details": "T Sasaya, S Yamamoto, T Ida, T Takimoto - Proceedings of the Asian Conference on \u2026, 2024", "abstract": "The effectiveness of pre-training using large-scale natural image datasets has been demonstrated for situations in which there are limited available real images. However, some research has shown that models pre-trained using natural images \u2026"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2411.03313%3F", "details": "H Zilong, Y Qinghao, K Bingyi, F Jiashi, F Haoqi - arXiv preprint arXiv:2411.03313, 2024", "abstract": "We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised \u2026"}]
