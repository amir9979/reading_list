'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Phi-3 technical report: A highly capable language mode'
[{"title": "Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?", "link": "https://arxiv.org/pdf/2404.12728", "details": "C Qin, W Xia, T Wang, F Jiao, Y Hu, B Ding, R Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Analogical reasoning is a unique ability of humans to address unfamiliar challenges by transferring strategies from relevant past experiences. One key finding in psychology is that compared with irrelevant past experiences, recalling relevant ones \u2026"}, {"title": "Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs", "link": "https://arxiv.org/pdf/2404.13033", "details": "B Guo, H Wang, W Xiao, H Chen, Z Lee, S Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the burgeoning field of Large Language Models (LLMs) like ChatGPT and LLaMA, Prompt Engineering (PE) is renowned for boosting zero-shot or in-context learning (ICL) through prompt modifications. Yet, the realm of the sample design for \u2026"}, {"title": "AlpaPICO: Extraction of PICO Frames from Clinical Trial Documents Using LLMs", "link": "https://www.sciencedirect.com/science/article/pii/S1046202324000896", "details": "M Ghosh, S Mukherjee, A Ganguly, P Basuchowdhuri\u2026 - Methods, 2024", "abstract": "In recent years, there has been a surge in the publication of clinical trial reports, making it challenging to conduct systematic reviews. Automatically extracting Population, Intervention, Comparator, and Outcome (PICO) from clinical trial studies \u2026"}, {"title": "WorldValuesBench: A Large-Scale Benchmark Dataset for Multi-Cultural Value Awareness of Language Models", "link": "https://arxiv.org/pdf/2404.16308", "details": "W Zhao, D Mondal, N Tandon, D Dillion, K Gray, Y Gu - arXiv preprint arXiv \u2026, 2024", "abstract": "The awareness of multi-cultural human values is critical to the ability of language models (LMs) to generate safe and personalized responses. However, this awareness of LMs has been insufficiently studied, since the computer science \u2026"}, {"title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning", "link": "https://proceedings.mlr.press/v238/e-ildiz24a/e-ildiz24a.pdf", "details": "ME Ildiz, Z Zhao, S Oymak - International Conference on Artificial Intelligence and \u2026, 2024", "abstract": "Large language models exhibit strong multitasking capabilities, however, their learning dynamics as a function of task characteristics, sample size, and model complexity remain mysterious. For instance, it is known that, as the model size grows \u2026"}, {"title": "Stronger Random Baselines for In-Context Learning", "link": "https://arxiv.org/pdf/2404.13020", "details": "G Yauney, D Mimno - arXiv preprint arXiv:2404.13020, 2024", "abstract": "Evaluating the in-context learning classification performance of language models poses challenges due to small dataset sizes, extensive prompt-selection using the validation set, and intentionally difficult tasks that lead to near-random performance \u2026"}, {"title": "Eyes Can Deceive: Benchmarking Counterfactual Reasoning Abilities of Multi-modal Large Language Models", "link": "https://arxiv.org/pdf/2404.12966", "details": "Y Li, W Tian, Y Jiao, J Chen, YG Jiang - arXiv preprint arXiv:2404.12966, 2024", "abstract": "Counterfactual reasoning, as a crucial manifestation of human intelligence, refers to making presuppositions based on established facts and extrapolating potential outcomes. Existing multimodal large language models (MLLMs) have exhibited \u2026"}, {"title": "FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom", "link": "https://arxiv.org/pdf/2404.12273", "details": "Y He, Y Kang, L Fan, Q Yang - arXiv preprint arXiv:2404.12273, 2024", "abstract": "Federated Learning (FL) has emerged as a promising solution for collaborative training of large language models (LLMs). However, the integration of LLMs into FL introduces new challenges, particularly concerning the evaluation of LLMs \u2026"}, {"title": "SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension", "link": "https://arxiv.org/pdf/2404.16790", "details": "B Li, Y Ge, Y Chen, Y Ge, R Zhang, Y Shan - arXiv preprint arXiv:2404.16790, 2024", "abstract": "Comprehending text-rich visual content is paramount for the practical application of Multimodal Large Language Models (MLLMs), since text-rich scenarios are ubiquitous in the real world, which are characterized by the presence of extensive \u2026"}]
