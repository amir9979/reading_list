[{"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "Making Long-Context Language Models Better Multi-Hop Reasoners", "link": "https://arxiv.org/pdf/2408.03246", "details": "Y Li, S Liang, MR Lyu, L Wang - arXiv preprint arXiv:2408.03246, 2024", "abstract": "Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Zero\u2010and few\u2010shot prompting of generative large language models provides weak assessment of risk of bias in clinical trials", "link": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/jrsm.1749", "details": "S \u0160uster, T Baldwin, K Verspoor - Research Synthesis Methods", "abstract": "Existing systems for automating the assessment of risk\u2010of\u2010bias (RoB) in medical studies are supervised approaches that require substantial training data to work well. However, recent revisions to RoB guidelines have resulted in a scarcity of available \u2026"}, {"title": "RuMedSpellchecker: A new approach for advanced spelling error correction in Russian electronic health records", "link": "https://www.sciencedirect.com/science/article/pii/S1877750324001868", "details": "D Pogrebnoi, A Funkner, S Kovalchuk - Journal of Computational Science, 2024", "abstract": "In healthcare, a remarkable progress in machine learning has given rise to a diverse range of predictive and decision-making medical models, significantly enhancing treatment efficacy and overall quality of care. These models often rely on electronic \u2026"}, {"title": "Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement", "link": "https://arxiv.org/pdf/2408.03092", "details": "L Yu, B Yu, H Yu, F Huang, Y Li - arXiv preprint arXiv:2408.03092, 2024", "abstract": "Merging Large Language Models (LLMs) aims to amalgamate multiple homologous LLMs into one with all the capabilities. Ideally, any LLMs sharing the same backbone should be mergeable, irrespective of whether they are Fine-Tuned (FT) with minor \u2026"}, {"title": "Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning", "link": "https://arxiv.org/pdf/2408.08651", "details": "K Moore, J Roberts, T Pham, D Fisher - arXiv preprint arXiv:2408.08651, 2024", "abstract": "Language models are known to absorb biases from their training data, leading to predictions driven by statistical regularities rather than semantic relevance. We investigate the impact of these biases on answer choice preferences in the Massive \u2026"}, {"title": "LoRAMoE: Alleviating World Knowledge Forgetting in Large Language Models via MoE-Style Plugin", "link": "https://aclanthology.org/2024.acl-long.106.pdf", "details": "S Dou, E Zhou, Y Liu, S Gao, W Shen, L Xiong, Y Zhou\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Supervised fine-tuning (SFT) is a crucial step for large language models (LLMs), enabling them to align with human instructions and enhance their capabilities in downstream tasks. Substantially increasing instruction data is a direct solution to \u2026"}, {"title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "link": "https://arxiv.org/pdf/2408.01380", "details": "P Mangal, C Mak, T Kanakis, T Donovan, D Braines\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence of Large Language Models (LLMs) have fundamentally altered the way we interact with digital systems and have led to the pursuit of LLM powered AI agents to assist in daily workflows. LLMs, whilst powerful and capable of \u2026"}]
