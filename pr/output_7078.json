[{"title": "Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models", "link": "https://arxiv.org/pdf/2409.14247", "details": "J Chiyah-Garcia, A Suglia, A Eshghi - arXiv preprint arXiv:2409.14247, 2024", "abstract": "In dialogue, the addressee may initially misunderstand the speaker and respond erroneously, often prompting the speaker to correct the misunderstanding in the next turn with a Third Position Repair (TPR). The ability to process and respond \u2026"}, {"title": "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction", "link": "https://arxiv.org/pdf/2409.16783", "details": "J Zhang, Y Zhou, Y Liu, Z Li, S Hu - arXiv preprint arXiv:2409.16783, 2024", "abstract": "Automated red teaming is an effective method for identifying misaligned behaviors in large language models (LLMs). Existing approaches, however, often focus primarily on improving attack success rates while overlooking the need for comprehensive test \u2026"}, {"title": "Analyzing Probabilistic Methods for Evaluating Agent Capabilities", "link": "https://arxiv.org/pdf/2409.16125", "details": "A H\u00f8jmark, G Pimpale, A Panickssery, M Hobbhahn\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To mitigate risks from AI systems, we need to assess their capabilities accurately. This is especially difficult in cases where capabilities are only rarely displayed. Phuong et al. propose two methods that aim to obtain better estimates of the \u2026"}, {"title": "RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code", "link": "https://arxiv.org/pdf/2409.15154", "details": "J Chen, Q Zhong, Y Wang, K Ning, Y Liu, Z Xu, Z Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence of Large Language Models (LLMs) has significantly influenced various aspects of software development activities. Despite their benefits, LLMs also pose notable risks, including the potential to generate harmful content and being \u2026"}, {"title": "HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2409.16191", "details": "H Que, F Duan, L He, Y Mou, W Zhou, J Liu, W Rong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks (eg, long-context understanding), and many benchmarks have been proposed. However, we observe that long text generation capabilities are \u2026"}, {"title": "Investigating Layer Importance in Large Language Models", "link": "https://arxiv.org/pdf/2409.14381", "details": "Y Zhang, Y Dong, K Kawaguchi - arXiv preprint arXiv:2409.14381, 2024", "abstract": "Large language models (LLMs) have gained increasing attention due to their prominent ability to understand and process texts. Nevertheless, LLMs largely remain opaque. The lack of understanding of LLMs has obstructed the deployment in \u2026"}, {"title": "RAD-Bench: Evaluating Large Language Models Capabilities in Retrieval Augmented Dialogues", "link": "https://arxiv.org/pdf/2409.12558", "details": "TL Kuo, FT Liao, MW Hsieh, FC Chang, PC Hsu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In real-world applications with Large Language Models (LLMs), external retrieval mechanisms-such as Search-Augmented Generation (SAG), tool utilization, and Retrieval-Augmented Generation (RAG)-are often employed to enhance the quality \u2026"}, {"title": "Clusters Emerge in Transformer-based Causal Language Models", "link": "https://openreview.net/pdf%3Fid%3DHKnV74Azat", "details": "X Wu, LR Varshney - The 7th BlackboxNLP Workshop", "abstract": "Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still an area of active development. Recent works\\citep {RLHF \u2026"}, {"title": "Harnessing Diversity for Important Data Selection in Pretraining Large Language Models", "link": "https://arxiv.org/pdf/2409.16986", "details": "C Zhang, H Zhong, K Zhang, C Chai, R Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Data selection is of great significance in pre-training large language models, given the variation in quality within the large-scale available training corpora. To achieve this, researchers are currently investigating the use of data influence to measure the \u2026"}]
