[{"title": "Unlocking Continual Learning Abilities in Language Models", "link": "https://arxiv.org/pdf/2406.17245", "details": "W Du, S Cheng, T Luo, Z Qiu, Z Huang, KC Cheung\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) exhibit impressive performance and generalization capabilities. However, LMs struggle with the persistent challenge of catastrophic forgetting, which undermines their long-term sustainability in continual learning (CL) \u2026"}, {"title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?", "link": "https://arxiv.org/pdf/2406.16316", "details": "Y Jinnai - arXiv preprint arXiv:2406.16316, 2024", "abstract": "Alignment of the language model with human preferences is a common approach to making a language model useful to end users. However, most alignment work is done in English, and human preference datasets are dominated by English \u2026"}, {"title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization", "link": "https://arxiv.org/pdf/2406.16743", "details": "Z Zhao, X Zhang, K Xu, X Hu, R Zhang, Z Du, Q Guo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the widespread application of Large Language Models (LLMs), it has become a significant concern to ensure their safety and prevent harmful responses. While current safe-alignment methods based on instruction fine-tuning and Reinforcement \u2026"}, {"title": "Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation", "link": "https://arxiv.org/pdf/2406.16356", "details": "R Hida, J Ohmura, T Sekiya - arXiv preprint arXiv:2406.16356, 2024", "abstract": "Instruction-tuned Large Language Models (LLMs) have achieved remarkable performance across various benchmark tasks. While providing instructions to LLMs for guiding their generations is user-friendly, assessing their instruction-following \u2026"}, {"title": "Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors", "link": "https://arxiv.org/pdf/2406.17163", "details": "V Yadav, Z Tang, V Srinivasan - arXiv preprint arXiv:2406.17163, 2024", "abstract": "Large language models (LLM) have achieved remarkable success in natural language generation but lesser focus has been given to their applicability in decision making tasks such as classification. We show that LLMs like LLaMa can achieve high \u2026"}, {"title": "Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation", "link": "https://arxiv.org/pdf/2406.18460", "details": "A Njifenjou, V Sucal, B Jabaian, F Lef\u00e8vre - arXiv preprint arXiv:2406.18460, 2024", "abstract": "Recently, various methods have been proposed to create open-domain conversational agents with Large Language Models (LLMs). These models are able to answer user queries, but in a one-way Q&A format rather than a true conversation \u2026"}, {"title": "DemoRank: Selecting Effective Demonstrations for Large Language Models in Ranking Task", "link": "https://arxiv.org/pdf/2406.16332", "details": "W Liu, Y Zhu, Z Dou - arXiv preprint arXiv:2406.16332, 2024", "abstract": "Recently, there has been increasing interest in applying large language models (LLMs) as zero-shot passage rankers. However, few studies have explored how to select appropriate in-context demonstrations for the passage ranking task, which is \u2026"}, {"title": "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation", "link": "https://arxiv.org/pdf/2406.14979", "details": "Y Lyu, Z Niu, Z Xie, C Zhang, T Xu, Y Wang, E Chen - arXiv preprint arXiv:2406.14979, 2024", "abstract": "Despite the significant progress of large language models (LLMs) in various tasks, they often produce factual errors due to their limited internal knowledge. Retrieval- Augmented Generation (RAG), which enhances LLMs with external knowledge \u2026"}, {"title": "Adversarial attacks and defenses for large language models (LLMs): methods, frameworks & challenges", "link": "https://link.springer.com/article/10.1007/s13735-024-00334-8", "details": "P Kumar - International Journal of Multimedia Information \u2026, 2024", "abstract": "Large language models (LLMs) have exhibited remarkable efficacy and proficiency in a wide array of NLP endeavors. Nevertheless, concerns are growing rapidly regarding the security and vulnerabilities linked to the adoption and incorporation of \u2026"}]
