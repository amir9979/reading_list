[{"title": "MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification", "link": "https://arxiv.org/pdf/2502.04515", "details": "W Fan, J Fei, D Guo, K Yi, X Song, H Xiang, H Ye, M Li - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical time series has been playing a vital role in real-world healthcare systems as valuable information in monitoring health conditions of patients. Accurate classification for medical time series, eg, Electrocardiography (ECG) signals, can \u2026"}, {"title": "InstrucTime: Advancing Time Series Classification with Multimodal Language Modeling", "link": "https://dl.acm.org/doi/abs/10.1145/3701551.3703499", "details": "M Cheng, Y Chen, Q Liu, Z Liu, Y Luo, E Chen - \u2026 Conference on Web Search and Data \u2026, 2025", "abstract": "For the advancement of time series classification, we can summarize that most existing methods adopt a common learning-to-classify paradigm-a classifier model tries to learn the relation between sequence inputs and target label encoded by one \u2026"}, {"title": "Double Distillation Network for Multi-Agent Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.03125", "details": "Y Zhou, S Wang, W Chen, R Zhang, Z Zhao, Z Zhang - arXiv preprint arXiv \u2026, 2025", "abstract": "Multi-agent reinforcement learning typically employs a centralized training- decentralized execution (CTDE) framework to alleviate the non-stationarity in environment. However, the partial observability during execution may lead to \u2026"}, {"title": "CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation", "link": "https://arxiv.org/pdf/2502.21074", "details": "Z Shen, H Yan, L Zhang, Z Hu, Y Du, Y He - arXiv preprint arXiv:2502.21074, 2025", "abstract": "Chain-of-Thought (CoT) enhances Large Language Models (LLMs) by enabling step- by-step reasoning in natural language. However, the language space may be suboptimal for reasoning. While implicit CoT methods attempt to enable reasoning \u2026"}, {"title": "TopoCL: Topological Contrastive Learning for Time Series", "link": "https://arxiv.org/pdf/2502.02924", "details": "N Kim, H Baik, Y Yoon - arXiv preprint arXiv:2502.02924, 2025", "abstract": "Universal time series representation learning is challenging but valuable in real- world applications such as classification, anomaly detection, and forecasting. Recently, contrastive learning (CL) has been actively explored to tackle time series \u2026"}]
