[{"title": "Enhancing vision-language models for medical imaging: bridging the 3D gap with innovative slice selection", "link": "https://openreview.net/pdf%3Fid%3DJrJW21IP9p", "details": "Y Wang, Y Dai, C Jones, HI Sair, J Shen, N Loizou\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent approaches to vision-language tasks are built on the remarkable capabilities of large vision-language models (VLMs). These models excel in zero-shot and few- shot learning, enabling them to learn new tasks without parameter updates \u2026"}, {"title": "Mixed Distillation Helps Smaller Language Models Reason Better", "link": "https://aclanthology.org/2024.findings-emnlp.91.pdf", "details": "L Chenglin, Q Chen, L Li, C Wang, F Tao, Y Li, Z Chen\u2026 - Findings of the Association \u2026, 2024", "abstract": "As large language models (LLMs) have demonstrated impressive multiple step-by- step reasoning capabilities in recent natural language processing (NLP) reasoning tasks, many studies are interested in distilling reasoning abilities into smaller \u2026"}, {"title": "Frozen Large-scale Pretrained Vision-Language Models are the Effective Foundational Backbone for Multimodal Breast Cancer Prediction", "link": "https://ieeexplore.ieee.org/iel8/6221020/6363502/10769012.pdf", "details": "HQ Vo, L Wang, KK Wong, CF Ezeana, X Yu, W Yang\u2026 - IEEE Journal of Biomedical \u2026, 2024", "abstract": "Breast cancer is a pervasive global health concern among women. Leveraging multimodal data from enterprise patient databases-including Picture Archiving and Communication Systems (PACS) and Electronic Health Records (EHRs)-holds \u2026"}, {"title": "SciInstruct: a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models", "link": "https://openreview.net/pdf%3Fid%3DLC1QAqhePv", "details": "D Zhang, Z Hu, S Zhoubian, Z Du, K Yang, Z Wang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving \u2026"}, {"title": "Learning predictable and robust neural representations by straightening image sequences", "link": "https://arxiv.org/pdf/2411.01777", "details": "X Niu, C Savin, EP Simoncelli - arXiv preprint arXiv:2411.01777, 2024", "abstract": "Prediction is a fundamental capability of all living organisms, and has been proposed as an objective for learning sensory representations. Recent work demonstrates that in primate visual systems, prediction is facilitated by neural representations that \u2026"}, {"title": "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "link": "https://aclanthology.org/2024.findings-emnlp.61.pdf", "details": "X Wei, H Chen, H Yu, H Fei, Q Liu - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) have achieved notable success in commonsense reasoning tasks, benefiting from their extensive world knowledge acquired through extensive pretraining. While approaches like Chain-of-Thought \u2026"}, {"title": "Micro-Bench: A Microscopy Benchmark for Vision-Language Understanding", "link": "https://openreview.net/pdf%3Fid%3DeRleg6vy0Y", "details": "A Lozano, JJ Nirschl, J Burgess, SR Gupte, Y Zhang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent advances in microscopy have enabled the rapid generation of terabytes of image data in cell biology and biomedical research. Vision-language models (VLMs) offer a promising solution for large-scale biological image analysis, enhancing \u2026"}, {"title": "Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset", "link": "https://arxiv.org/pdf/2411.03554", "details": "Y Ma, J Wang, F Wang, S Ma, J Li, X Li, F Huang, L Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Machine unlearning has emerged as an effective strategy for forgetting specific information in the training data. However, with the increasing integration of visual data, privacy concerns in Vision Language Models (VLMs) remain underexplored. To \u2026"}, {"title": "Mathematical Reasoning via Multi-step Self Questioning and Answering for Small Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9440-9_7", "details": "K Chen, J Wang, X Zhang - CCF International Conference on Natural Language \u2026, 2024", "abstract": "Mathematical reasoning is challenging for large language models (LLMs), while the scaling relationship concerning LLM capacity is under-explored. Existing works have tried to leverage the rationales of LLMs to train small language models (SLMs) for \u2026"}]
