[{"title": "Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models", "link": "https://arxiv.org/pdf/2407.20271", "details": "H Tang, Y Liu, X Liu, K Zhang, Y Zhang, Q Liu, E Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in machine learning, especially in Natural Language Processing (NLP), have led to the development of sophisticated models trained on vast datasets, but this progress has raised concerns about potential sensitive \u2026"}, {"title": "Improving Context-Aware Preference Modeling for Language Models", "link": "https://arxiv.org/pdf/2407.14916", "details": "S Pitis, Z Xiao, NL Roux, A Sordoni - arXiv preprint arXiv:2407.14916, 2024", "abstract": "While finetuning language models from pairwise preferences has proven remarkably effective, the underspecified nature of natural language presents critical challenges. Direct preference feedback is uninterpretable, difficult to provide where \u2026"}, {"title": "Retrieve, Generate, Evaluate: A Case Study for Medical Paraphrases Generation with Small Language Models", "link": "https://arxiv.org/pdf/2407.16565", "details": "I Buhnila, A Sinha, M Constant - arXiv preprint arXiv:2407.16565, 2024", "abstract": "Recent surge in the accessibility of large language models (LLMs) to the general population can lead to untrackable use of such models for medical-related recommendations. Language generation via LLMs models has two key problems \u2026"}, {"title": "Explainable Stock Price Movement Prediction using Contrastive Learning", "link": "https://sentic.net/explainable-stock-price-movement-prediction.pdf", "details": "K Du, R Mao, F Xing, E Cambria - 2024", "abstract": "Predicting stock price movements is a high-stakes task that demands explainability for human decision-makers. A key shortcoming in current methods is treating sub- predictions independently, without learning from accumulated experiences. We \u2026"}, {"title": "AbdomenAtlas: A large-scale, detailed-annotated, & multi-center dataset for efficient transfer learning and open algorithmic benchmarking", "link": "https://arxiv.org/pdf/2407.16697", "details": "W Li, C Qu, X Chen, PRAS Bassi, Y Shi, Y Lai, Q Yu\u2026 - Medical Image Analysis, 2024", "abstract": "We introduce the largest abdominal CT dataset (termed AbdomenAtlas) of 20,460 three-dimensional CT volumes sourced from 112 hospitals across diverse populations, geographies, and facilities. AbdomenAtlas provides 673 K high-quality \u2026"}, {"title": "UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models", "link": "https://arxiv.org/pdf/2407.16160", "details": "L Qi, H Yongyi, L Defu, Z Zhi, X Tong, L Che, C Enhong - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Entity Linking (MEL) is a crucial task that aims at linking ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on using \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}, {"title": "Multi-group Uncertainty Quantification for Long-form Text Generation", "link": "https://arxiv.org/pdf/2407.21057", "details": "T Liu, ZS Wu - arXiv preprint arXiv:2407.21057, 2024", "abstract": "While large language models are rapidly moving towards consumer-facing applications, they are often still prone to factual errors and hallucinations. In order to reduce the potential harms that may come from these errors, it is important for users \u2026"}, {"title": "The Art of Refusal: A Survey of Abstention in Large Language Models", "link": "https://arxiv.org/pdf/2407.18418", "details": "B Wen, J Yao, S Feng, C Xu, Y Tsvetkov, B Howe\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Abstention, the refusal of large language models (LLMs) to provide an answer, is increasingly recognized for its potential to mitigate hallucinations and enhance safety in building LLM systems. In this survey, we introduce a framework to examine \u2026"}]
