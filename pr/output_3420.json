[{"title": "Abstraction-of-Thought Makes Language Models Better Reasoners", "link": "https://arxiv.org/pdf/2406.12442", "details": "R Hong, H Zhang, X Pan, D Yu, C Zhang - arXiv preprint arXiv:2406.12442, 2024", "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks \u2026"}, {"title": "Language Models can be Deductive Solvers", "link": "https://aclanthology.org/2024.findings-naacl.254.pdf", "details": "J Feng, R Xu, J Hao, H Sharma, Y Shen, D Zhao\u2026 - Findings of the Association \u2026, 2024", "abstract": "Logical reasoning is a fundamental aspect of human intelligence and a key component of tasks like problem-solving and decision-making. Recent advancements have enabled Large Language Models (LLMs) to potentially exhibit \u2026"}, {"title": "ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models", "link": "https://aclanthology.org/2024.findings-naacl.261.pdf", "details": "MN Tran, PV Nguyen, L Nguyen, D Dien - Findings of the Association for \u2026, 2024", "abstract": "As the number of language models has increased, various benchmarks have been suggested to assess the proficiency of the models in natural language understanding. However, there is a lack of such a benchmark in Vietnamese due to \u2026"}, {"title": "Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations", "link": "https://arxiv.org/pdf/2406.11801", "details": "R Hazra, S Layek, S Banerjee, S Poria - arXiv preprint arXiv:2406.11801, 2024", "abstract": "Ensuring the safe alignment of large language models (LLMs) with human values is critical as they become integral to applications like translation and question answering. Current alignment methods struggle with dynamic user intentions and \u2026"}, {"title": "AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2406.13233", "details": "Z Zeng, Y Miao, H Gao, H Zhang, Z Deng - arXiv preprint arXiv:2406.13233, 2024", "abstract": "Mixture of experts (MoE) has become the standard for constructing production-level large language models (LLMs) due to its promise to boost model capacity without causing significant overheads. Nevertheless, existing MoE methods usually enforce \u2026"}, {"title": "Is A Picture Worth A Thousand Words? Delving Into Spatial Reasoning for Vision Language Models", "link": "https://arxiv.org/pdf/2406.14852", "details": "J Wang, Y Ming, Z Shi, V Vineet, X Wang, N Joshi - arXiv preprint arXiv:2406.14852, 2024", "abstract": "Large language models (LLMs) and vision-language models (VLMs) have demonstrated remarkable performance across a wide range of tasks and domains. Despite this promise, spatial understanding and reasoning--a fundamental \u2026"}, {"title": "Aligning Language Models with the Human World", "link": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi%3Farticle%3D1241%26context%3Ddissertations", "details": "R LIU - 2024", "abstract": "Abstract The field of Natural Language Processing (NLP) has undergone a significant transformation with the emergence of large language models (LMs). These models have enabled the development of human-like conversational \u2026"}, {"title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought", "link": "https://arxiv.org/pdf/2406.13940", "details": "Y Zhang, Q Chen, M Li, W Che, L Qin - arXiv preprint arXiv:2406.13940, 2024", "abstract": "Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention. Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning \u2026"}, {"title": "Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications", "link": "https://aclanthology.org/2024.naacl-long.198.pdf", "details": "Y Liu, S Gautam, J Ma, H Lakkaraju - Proceedings of the 2024 Conference of the \u2026, 2024", "abstract": "Recent literature has suggested the potential of using large language models (LLMs) to make classifications for tabular tasks. However, LLMs have been shown to exhibit harmful social biases that reflect the stereotypes and inequalities present in society \u2026"}]
