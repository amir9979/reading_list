[{"title": "Vision-Language Models under Cultural and Inclusive Considerations", "link": "https://arxiv.org/pdf/2407.06177", "details": "A Karamolegkou, P Rust, Y Cao, R Cui, A S\u00f8gaard\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large vision-language models (VLMs) can assist visually impaired people by describing images from their daily lives. Current evaluation datasets may not reflect diverse cultural user backgrounds or the situational context of this use case. To \u2026"}, {"title": "AI Safety in Generative AI Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2407.18369", "details": "J Chua, Y Li, S Yang, C Wang, L Yao - arXiv preprint arXiv:2407.18369, 2024", "abstract": "Large Language Model (LLMs) such as ChatGPT that exhibit generative AI capabilities are facing accelerated adoption and innovation. The increased presence of Generative AI (GAI) inevitably raises concerns about the risks and safety \u2026"}, {"title": "AWT: Transferring Vision-Language Models via Augmentation, Weighting, and Transportation", "link": "https://arxiv.org/pdf/2407.04603", "details": "Y Zhu, Y Ji, Z Zhao, G Wu, L Wang - arXiv preprint arXiv:2407.04603, 2024", "abstract": "Pre-trained vision-language models (VLMs) have shown impressive results in various visual classification tasks. However, we often fail to fully unleash their potential when adapting them for new concept understanding due to limited \u2026"}, {"title": "LiteGPT: Large Vision-Language Model for Joint Chest X-ray Localization and Classification Task", "link": "https://arxiv.org/pdf/2407.12064", "details": "K Le-Duc, R Zhang, NS Nguyen, TH Pham, A Dao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models have been extensively explored across a wide range of tasks, achieving satisfactory performance; however, their application in medical imaging remains underexplored. In this work, we propose a unified framework \u2026"}, {"title": "Neural Fields for Continuous Periodic Motion Estimation in 4D Cardiovascular Imaging", "link": "https://arxiv.org/pdf/2407.20728", "details": "S Garzia, P Rygiel, S Dummer, F Cademartiri, S Celi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Time-resolved three-dimensional flow MRI (4D flow MRI) provides a unique non- invasive solution to visualize and quantify hemodynamics in blood vessels such as the aortic arch. However, most current analysis methods for arterial 4D flow MRI use \u2026"}, {"title": "Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models", "link": "https://arxiv.org/pdf/2407.11717", "details": "C Ju, H Wang, H Cheng, X Chen, Z Zhai, W Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Large Models (VLMs) recently become primary backbone of AI, due to the impressive performance. However, their expensive computation costs, ie, throughput and delay, impede potentials in the real-world scenarios. To achieve \u2026"}, {"title": "XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training", "link": "https://arxiv.org/pdf/2407.19546", "details": "B Wu, Y Xie, Z Zhang, MH Phan, Q Chen, L Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-and-language pretraining (VLP) in the medical field utilizes contrastive learning on image-text pairs to achieve effective transfer across tasks. Yet, current VLP approaches with the masked modelling strategy face two challenges when \u2026"}, {"title": "LLMBox: A Comprehensive Library for Large Language Models", "link": "https://arxiv.org/pdf/2407.05563", "details": "T Tang, Y Hu, B Li, W Luo, Z Qin, H Sun, J Wang, S Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To facilitate the research on large language models (LLMs), this paper presents a comprehensive and unified library, LLMBox, to ease the development, use, and evaluation of LLMs. This library is featured with three main merits:(1) a unified data \u2026"}]
