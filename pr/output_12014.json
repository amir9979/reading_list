[{"title": "In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review", "link": "https://arxiv.org/pdf/2501.10727", "details": "A Jim\u00e9nez-S\u00e1nchez, NR Avlona, S de Boer\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Datasets play a critical role in medical imaging research, yet issues such as label quality, shortcuts, and metadata are often overlooked. This lack of attention may harm the generalizability of algorithms and, consequently, negatively impact patient \u2026"}, {"title": "Double Visual Defense: Adversarial Pre-training and Instruction Tuning for Improving Vision-Language Model Robustness", "link": "https://arxiv.org/pdf/2501.09446", "details": "Z Wang, C Xie, B Bartoldson, B Kailkhura - arXiv preprint arXiv:2501.09446, 2025", "abstract": "This paper investigates the robustness of vision-language models against adversarial visual perturbations and introduces a novel``double visual defense\" to enhance this robustness. Unlike previous approaches that resort to lightweight \u2026"}, {"title": "Context-aware prompt learning for test-time vision recognition with frozen vision-language model", "link": "https://www.sciencedirect.com/science/article/pii/S0031320325000196", "details": "J Yin, X Zhang, L Wu, X Wang - Pattern Recognition, 2025", "abstract": "Current pre-trained vision-language models, such as CLIP, have demonstrated remarkable zero-shot generalization capabilities across various downstream tasks. However, their performance significantly degrades when test inputs exhibit different \u2026"}, {"title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "link": "https://arxiv.org/pdf/2501.12266", "details": "C Patr\u00edcio, I Rio-Torto, JS Cardoso, LF Teixeira\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The main challenges limiting the adoption of deep learning-based solutions in medical workflows are the availability of annotated data and the lack of interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the latter \u2026"}, {"title": "ChartAdapter: Large Vision-Language Model for Chart Summarization", "link": "https://arxiv.org/pdf/2412.20715", "details": "P Xu, Y Ding, W Fan - arXiv preprint arXiv:2412.20715, 2024", "abstract": "Chart summarization, which focuses on extracting key information from charts and interpreting it in natural language, is crucial for generating and delivering insights through effective and accessible data analysis. Traditional methods for chart \u2026"}, {"title": "Vision-language representation learning with breadth and depth attention pre-training", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124015752", "details": "Y Liu, B Zhang, CC Wang, G Yan, K Zhou, Z Li\u2026 - Knowledge-Based Systems, 2025", "abstract": "The rapid advances in computer vision and natural language processing have led to increased attention toward the challenge of understanding vision and language together across multiple domains. Representation learning has become a major \u2026"}, {"title": "Generating with Fairness: A Modality-Diffused Counterfactual Framework for Incomplete Multimodal Recommendations", "link": "https://arxiv.org/pdf/2501.11916", "details": "J Li, S Wang, Q Zhang, S Yu, F Chen - arXiv preprint arXiv:2501.11916, 2025", "abstract": "Incomplete scenario is a prevalent, practical, yet challenging setting in Multimodal Recommendations (MMRec), where some item modalities are missing due to various factors. Recently, a few efforts have sought to improve the recommendation accuracy \u2026"}, {"title": "Med-R $^ 2$: Crafting Trustworthy LLM Physicians through Retrieval and Reasoning of Evidence-Based Medicine", "link": "https://arxiv.org/pdf/2501.11885", "details": "K Lu, Z Liang, D Pan, S Zhang, X Wu, W Chen, Z Zhou\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In recent years, Large Language Models (LLMs) have exhibited remarkable capabilities in clinical scenarios. However, despite their potential, existing works face challenges when applying LLMs to medical settings. Strategies relying on training \u2026"}, {"title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement", "link": "https://arxiv.org/pdf/2501.12273", "details": "M Cao, T Zhang, M Li, C Zhang, Y Liu, H Duan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs). However, as LLMs become more advanced, the availability of high-quality human-annotated SFT \u2026"}]
