[{"title": "KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models", "link": "https://arxiv.org/pdf/2408.03297", "details": "R Zhang, Y Xu, Y Xiao, R Zhu, X Jiang, X Chu, J Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "By integrating external knowledge, Retrieval-Augmented Generation (RAG) has become an effective strategy for mitigating the hallucination problems that large language models (LLMs) encounter when dealing with knowledge-intensive tasks \u2026"}, {"title": "Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Trustworthy Response Generation in Chinese", "link": "https://dl.acm.org/doi/pdf/10.1145/3686807", "details": "H Wang, S Zhao, Z Qiang, Z Li, C Liu, N Xi, Y Du, B Qin\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the hallucination about medical facts due to \u2026"}, {"title": "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.03560", "details": "AS Joaquin, B Wang, Z Liu, N Asher, B Lim, P Muller\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite advancements, fine-tuning Large Language Models (LLMs) remains costly due to the extensive parameter count and substantial data requirements for model generalization. Accessibility to computing resources remains a barrier for the open \u2026"}, {"title": "Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.06663", "details": "K Sun, M Dredze - arXiv preprint arXiv:2408.06663, 2024", "abstract": "The development of large language models leads to the formation of a pre-train-then- align paradigm, in which the model is typically pre-trained on a large text corpus and undergoes a tuning stage to align the model with human preference or downstream \u2026"}, {"title": "EXAONE 3.0 7.8 B Instruction Tuned Language Model", "link": "https://arxiv.org/pdf/2408.03541", "details": "LG Research, S An, K Bae, E Choi, SJ Choi, Y Choi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce EXAONE 3.0 instruction-tuned language model, the first open model in the family of Large Language Models (LLMs) developed by LG AI Research. Among different model sizes, we publicly release the 7.8 B instruction-tuned model to \u2026"}, {"title": "Fine-tuning Language Models for Triple Extraction with Data Augmentation", "link": "https://aclanthology.org/2024.kallm-1.12.pdf", "details": "Y Zhang, T Sadler, MR Taesiri, W Xu, M Reformat - Proceedings of the 1st Workshop \u2026, 2024", "abstract": "Advanced language models with impressive capabilities to process textual information can more effectively extract high-quality triples, which are the building blocks of knowledge graphs. Our work examines language models' abilities to extract \u2026"}, {"title": "Hw-tsc at textgraphs-17 shared task: Enhancing inference capabilities of llms with knowledge graphs", "link": "https://aclanthology.org/2024.textgraphs-1.11.pdf", "details": "W Tang, X Qiao, X Zhao, M Zhang, C Su, Y Li, Y Li\u2026 - Proceedings of TextGraphs \u2026, 2024", "abstract": "In this paper, we present an effective method for TextGraphs-17 Shared Task. This task requires selecting an entity from the candidate entities that is relevant to the given question and answer. The selection process is aided by utilizing the shortest \u2026"}, {"title": "Controllable Citation Sentence Generation with Language Models", "link": "https://aclanthology.org/2024.sdp-1.4.pdf", "details": "N Gu, R Hahnloser - Proceedings of the Fourth Workshop on Scholarly \u2026, 2024", "abstract": "Citation generation aims to generate a citation sentence that refers to a chosen paper in the context of a manuscript. However, a rigid citation generation process is at odds with an author's desire to control specific attributes, such as 1) the citation \u2026"}, {"title": "Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models", "link": "https://arxiv.org/pdf/2408.06621", "details": "S Cha, S Cho, D Hwang, M Lee - arXiv preprint arXiv:2408.06621, 2024", "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning and memorization capabilities via pretraining on massive textual corpora. However, training LLMs on human-written text entails significant risk of privacy and copyright \u2026"}]
