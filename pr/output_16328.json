[{"title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation", "link": "https://arxiv.org/pdf/2504.20859", "details": "G Hadad, H Roitman, Y Eshel, B Shapira, L Rokach - arXiv preprint arXiv:2504.20859, 2025", "abstract": "As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents``X-Cross''--a novel cross-domain sequential-recommendation model \u2026"}, {"title": "DeepCritic: Deliberate Critique with Large Language Models", "link": "https://arxiv.org/pdf/2505.00662%3F", "details": "W Yang, J Chen, Y Lin, JR Wen - arXiv preprint arXiv:2505.00662, 2025", "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem. Leveraging LLMs as critique models to achieve automated supervision is a \u2026"}, {"title": "Unleashing the potential of prompt engineering for large language models", "link": "https://www.cell.com/patterns/fulltext/S2666-3899\\(25\\)00108-4", "details": "B Chen, Z Zhang, N Langren\u00e9, S Zhu - Patterns, 2025", "abstract": "This review explores the role of prompt engineering in unleashing the capabilities of large language models (LLMs). Prompt engineering is the process of structuring inputs, and it has emerged as a crucial technique for maximizing the utility and \u2026"}, {"title": "Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers", "link": "https://arxiv.org/pdf/2505.04842", "details": "K Sareen, MM Moss, A Sordoni, R Agarwal, A Hosseini - arXiv preprint arXiv \u2026, 2025", "abstract": "Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners, such as GRPO or Leave-one-out PPO, abandon the learned value function in favor of empirically estimated returns. This hinders test-time compute scaling that relies on \u2026"}, {"title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems", "link": "https://arxiv.org/pdf/2505.00212", "details": "S Zhang, M Yin, J Zhang, J Liu, Z Han, J Zhang, B Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Failure attribution in LLM multi-agent systems-identifying the agent and step responsible for task failures-provides crucial clues for systems debugging but remains underexplored and labor-intensive. In this paper, we propose and formulate \u2026"}, {"title": "Racing Thoughts: Explaining Contextualization Errors in Large Language Models", "link": "https://aclanthology.org/2025.naacl-long.155.pdf", "details": "MA Lepori, MC Mozer, A Ghandeharioun - Proceedings of the 2025 Conference of the \u2026, 2025", "abstract": "The profound success of transformer-based language models can largely be attributed to their ability to integrate relevant contextual information from an input sequence in order to generate a response or complete a task. However, we know \u2026"}, {"title": "Sailing AI by the Stars: A Survey of Learning from Rewards in Post-Training and Test-Time Scaling of Large Language Models", "link": "https://arxiv.org/pdf/2505.02686%3F", "details": "X Wu - arXiv preprint arXiv:2505.02686, 2025", "abstract": "Recent developments in Large Language Models (LLMs) have shifted from pre- training scaling to post-training and test-time scaling. Across these developments, a key unified paradigm has arisen: Learning from Rewards, where reward signals act \u2026"}, {"title": "Automatic Calibration for Membership Inference Attack on Large Language Models", "link": "https://arxiv.org/pdf/2505.03392", "details": "SZ Zade, Y Qiang, X Zhou, H Zhu, MA Roshani\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Membership Inference Attacks (MIAs) have recently been employed to determine whether a specific text was part of the pre-training data of Large Language Models (LLMs). However, existing methods often misinfer non-members as members \u2026"}, {"title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models", "link": "https://arxiv.org/pdf/2505.02847", "details": "B Zhang, R Ma, Q Jiang, P Wang, J Chen, Z Xie\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Assessing how well a large language model (LLM) understands human, rather than merely text, remains an open challenge. To bridge the gap, we introduce Sentient Agent as a Judge (SAGE), an automated evaluation framework that measures an \u2026"}]
