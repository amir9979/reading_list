[{"title": "RealMath: A Continuous Benchmark for Evaluating Language Models on Research-Level Mathematics", "link": "https://arxiv.org/pdf/2505.12575", "details": "J Zhang, C Petrui, K Nikoli\u0107, F Tram\u00e8r - arXiv preprint arXiv:2505.12575, 2025", "abstract": "Existing benchmarks for evaluating mathematical reasoning in large language models (LLMs) rely primarily on competition problems, formal proofs, or artificially challenging questions--failing to capture the nature of mathematics encountered in \u2026", "entry_id": "http://arxiv.org/abs/2505.12575v1", "updated": "2025-05-18 23:32:46", "published": "2025-05-18 23:32:46", "authors": "Jie Zhang;Cezara Petrui;Kristina Nikoli\u0107;Florian Tram\u00e8r", "summary": "Existing benchmarks for evaluating mathematical reasoning in large language\nmodels (LLMs) rely primarily on competition problems, formal proofs, or\nartificially challenging questions -- failing to capture the nature of\nmathematics encountered in actual research environments. We introduce RealMath,\na novel benchmark derived directly from research papers and mathematical forums\nthat assesses LLMs' abilities on authentic mathematical tasks. Our approach\naddresses three critical challenges: sourcing diverse research-level content,\nenabling reliable automated evaluation through verifiable statements, and\ndesigning a continually refreshable dataset to mitigate contamination risks.\nExperimental results across multiple LLMs reveal surprising capabilities in\nhandling research mathematics compared to competition problems, suggesting\ncurrent models may already serve as valuable assistants for working\nmathematicians despite limitations on highly challenging problems. The code and\ndataset for RealMath are publicly available.", "comment": null, "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI", "links": "http://arxiv.org/abs/2505.12575v1;http://arxiv.org/pdf/2505.12575v1", "pdf_url": "http://arxiv.org/pdf/2505.12575v1"}, {"title": "dKV-Cache: The Cache for Diffusion Language Models", "link": "https://arxiv.org/pdf/2505.15781", "details": "X Ma, R Yu, G Fang, X Wang - arXiv preprint arXiv:2505.15781, 2025", "abstract": "Diffusion Language Models (DLMs) have been seen as a promising competitor for autoregressive language models. However, diffusion language models have long been constrained by slow inference. A core challenge is that their non \u2026", "entry_id": "http://arxiv.org/abs/2505.15781v1", "updated": "2025-05-21 17:32:10", "published": "2025-05-21 17:32:10", "authors": "Xinyin Ma;Runpeng Yu;Gongfan Fang;Xinchao Wang", "summary": "Diffusion Language Models (DLMs) have been seen as a promising competitor for\nautoregressive language models. However, diffusion language models have long\nbeen constrained by slow inference. A core challenge is that their\nnon-autoregressive architecture and bidirectional attention preclude the\nkey-value cache that accelerates decoding. We address this bottleneck by\nproposing a KV-cache-like mechanism, delayed KV-Cache, for the denoising\nprocess of DLMs. Our approach is motivated by the observation that different\ntokens have distinct representation dynamics throughout the diffusion process.\nAccordingly, we propose a delayed and conditioned caching strategy for key and\nvalue states. We design two complementary variants to cache key and value\nstep-by-step: (1) dKV-Cache-Decode, which provides almost lossless\nacceleration, and even improves performance on long sequences, suggesting that\nexisting DLMs may under-utilise contextual information during inference. (2)\ndKV-Cache-Greedy, which has aggressive caching with reduced lifespan, achieving\nhigher speed-ups with quadratic time complexity at the cost of some performance\ndegradation. dKV-Cache, in final, achieves from 2-10x speedup in inference,\nlargely narrowing the gap between ARs and DLMs. We evaluate our dKV-Cache on\nseveral benchmarks, delivering acceleration across general language\nunderstanding, mathematical, and code-generation benchmarks. Experiments\ndemonstrate that cache can also be used in DLMs, even in a training-free manner\nfrom current DLMs.", "comment": "The code is available at https://github.com/horseee/dKV-Cache", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.15781v1;http://arxiv.org/pdf/2505.15781v1", "pdf_url": "http://arxiv.org/pdf/2505.15781v1"}, {"title": "MMaDA: Multimodal Large Diffusion Language Models", "link": "https://arxiv.org/pdf/2505.15809", "details": "L Yang, Y Tian, B Li, X Zhang, K Shen, Y Tong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce MMaDA, a novel class of multimodal diffusion foundation models designed to achieve superior performance across diverse domains such as textual reasoning, multimodal understanding, and text-to-image generation. The approach is \u2026", "entry_id": "http://arxiv.org/abs/2505.15809v1", "updated": "2025-05-21 17:59:05", "published": "2025-05-21 17:59:05", "authors": "Ling Yang;Ye Tian;Bowen Li;Xinchen Zhang;Ke Shen;Yunhai Tong;Mengdi Wang", "summary": "We introduce MMaDA, a novel class of multimodal diffusion foundation models\ndesigned to achieve superior performance across diverse domains such as textual\nreasoning, multimodal understanding, and text-to-image generation. The approach\nis distinguished by three key innovations: (i) MMaDA adopts a unified diffusion\narchitecture with a shared probabilistic formulation and a modality-agnostic\ndesign, eliminating the need for modality-specific components. This\narchitecture ensures seamless integration and processing across different data\ntypes. (ii) We implement a mixed long chain-of-thought (CoT) fine-tuning\nstrategy that curates a unified CoT format across modalities. By aligning\nreasoning processes between textual and visual domains, this strategy\nfacilitates cold-start training for the final reinforcement learning (RL)\nstage, thereby enhancing the model's ability to handle complex tasks from the\noutset. (iii) We propose UniGRPO, a unified policy-gradient-based RL algorithm\nspecifically tailored for diffusion foundation models. Utilizing diversified\nreward modeling, UniGRPO unifies post-training across both reasoning and\ngeneration tasks, ensuring consistent performance improvements. Experimental\nresults demonstrate that MMaDA-8B exhibits strong generalization capabilities\nas a unified multimodal foundation model. It surpasses powerful models like\nLLaMA-3-7B and Qwen2-7B in textual reasoning, outperforms Show-o and SEED-X in\nmultimodal understanding, and excels over SDXL and Janus in text-to-image\ngeneration. These achievements highlight MMaDA's effectiveness in bridging the\ngap between pretraining and post-training within unified diffusion\narchitectures, providing a comprehensive framework for future research and\ndevelopment. We open-source our code and trained models at:\nhttps://github.com/Gen-Verse/MMaDA", "comment": "Project: https://github.com/Gen-Verse/MMaDA", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.15809v1;http://arxiv.org/pdf/2505.15809v1", "pdf_url": "http://arxiv.org/pdf/2505.15809v1"}, {"title": "Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models", "link": "https://arxiv.org/pdf/2505.15634", "details": "Z Li, X Wang, Y Yang, Z Yao, H Xiong, M Du - arXiv preprint arXiv:2505.15634, 2025", "abstract": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and mathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT length, as seen in models such as DeepSeek-R1, significantly enhances this \u2026", "entry_id": "http://arxiv.org/abs/2505.15634v1", "updated": "2025-05-21 15:17:59", "published": "2025-05-21 15:17:59", "authors": "Zihao Li;Xu Wang;Yuzhe Yang;Ziyu Yao;Haoyi Xiong;Mengnan Du", "summary": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and\nmathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT\nlength, as seen in models such as DeepSeek-R1, significantly enhances this\nreasoning for complex problems, but requires costly and high-quality long CoT\ndata and fine-tuning. This work, inspired by the deep thinking paradigm of\nDeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of\nan LLM without external datasets. Our method first employs Sparse Autoencoders\n(SAEs) to extract interpretable features from vanilla CoT. These features are\nthen used to steer the LLM's internal states during generation. Recognizing\nthat many LLMs do not have corresponding pre-trained SAEs, we further introduce\na novel SAE-free steering algorithm, which directly computes steering\ndirections from the residual activations of an LLM, obviating the need for an\nexplicit SAE. Experimental results demonstrate that both our SAE-based and\nsubsequent SAE-free steering algorithms significantly enhance the reasoning\ncapabilities of LLMs.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.LG", "links": "http://arxiv.org/abs/2505.15634v1;http://arxiv.org/pdf/2505.15634v1", "pdf_url": "http://arxiv.org/pdf/2505.15634v1"}, {"title": "Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models", "link": "https://arxiv.org/pdf/2505.15406", "details": "Z Song, Q Jiang, M Cui, M Li, L Gao, Z Zhang, Z Xu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The rise of Large Audio Language Models (LAMs) brings both potential and risks, as their audio outputs may contain harmful or unethical content. However, current research lacks a systematic, quantitative evaluation of LAM safety especially against \u2026", "entry_id": "http://arxiv.org/abs/2505.15406v1", "updated": "2025-05-21 11:47:47", "published": "2025-05-21 11:47:47", "authors": "Zirui Song;Qian Jiang;Mingxuan Cui;Mingzhe Li;Lang Gao;Zeyu Zhang;Zixiang Xu;Yanbo Wang;Chenxi Wang;Guangxian Ouyang;Zhenhao Chen;Xiuying Chen", "summary": "The rise of Large Audio Language Models (LAMs) brings both potential and\nrisks, as their audio outputs may contain harmful or unethical content.\nHowever, current research lacks a systematic, quantitative evaluation of LAM\nsafety especially against jailbreak attacks, which are challenging due to the\ntemporal and semantic nature of speech. To bridge this gap, we introduce\nAJailBench, the first benchmark specifically designed to evaluate jailbreak\nvulnerabilities in LAMs. We begin by constructing AJailBench-Base, a dataset of\n1,495 adversarial audio prompts spanning 10 policy-violating categories,\nconverted from textual jailbreak attacks using realistic text to speech\nsynthesis. Using this dataset, we evaluate several state-of-the-art LAMs and\nreveal that none exhibit consistent robustness across attacks. To further\nstrengthen jailbreak testing and simulate more realistic attack conditions, we\npropose a method to generate dynamic adversarial variants. Our Audio\nPerturbation Toolkit (APT) applies targeted distortions across time, frequency,\nand amplitude domains. To preserve the original jailbreak intent, we enforce a\nsemantic consistency constraint and employ Bayesian optimization to efficiently\nsearch for perturbations that are both subtle and highly effective. This\nresults in AJailBench-APT, an extended dataset of optimized adversarial audio\nsamples. Our findings demonstrate that even small, semantically preserved\nperturbations can significantly reduce the safety performance of leading LAMs,\nunderscoring the need for more robust and semantically aware defense\nmechanisms.", "comment": "We release AJailBench, including both static and optimized\n  adversarial data, to facilitate future research:\n  https://github.com/mbzuai-nlp/AudioJailbreak", "journal_ref": null, "primary_category": "cs.SD", "categories": "cs.SD;cs.AI;eess.AS", "links": "http://arxiv.org/abs/2505.15406v1;http://arxiv.org/pdf/2505.15406v1", "pdf_url": "http://arxiv.org/pdf/2505.15406v1"}, {"title": "Utilizing Large language models to select literature for meta-analysis shows workload reduction while maintaining a similar recall level as manual curation", "link": "https://link.springer.com/article/10.1186/s12874-025-02569-3", "details": "X Cai, Y Geng, Y Du, B Westerman, D Wang, C Ma\u2026 - BMC Medical Research \u2026, 2025", "abstract": "Large language models (LLMs) like ChatGPT showed great potential in aiding medical research. A heavy workload in filtering records is needed during the research process of evidence-based medicine, especially meta-analysis. However \u2026"}, {"title": "FisherSFT: Data-Efficient Supervised Fine-Tuning of Language Models Using Information Gain", "link": "https://arxiv.org/pdf/2505.14826", "details": "R Deb, K Thekumparampil, K Kalantari, G Hiranandani\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Supervised fine-tuning (SFT) is a standard approach to adapting large language models (LLMs) to new domains. In this work, we improve the statistical efficiency of SFT by selecting an informative subset of training examples. Specifically, for a fixed \u2026", "entry_id": "http://arxiv.org/abs/2505.14826v1", "updated": "2025-05-20 18:41:34", "published": "2025-05-20 18:41:34", "authors": "Rohan Deb;Kiran Thekumparampil;Kousha Kalantari;Gaurush Hiranandani;Shoham Sabach;Branislav Kveton", "summary": "Supervised fine-tuning (SFT) is a standard approach to adapting large\nlanguage models (LLMs) to new domains. In this work, we improve the statistical\nefficiency of SFT by selecting an informative subset of training examples.\nSpecifically, for a fixed budget of training examples, which determines the\ncomputational cost of fine-tuning, we determine the most informative ones. The\nkey idea in our method is to select examples that maximize information gain,\nmeasured by the Hessian of the log-likelihood of the LLM. We approximate it\nefficiently by linearizing the LLM at the last layer using multinomial logistic\nregression models. Our approach is computationally efficient, analyzable, and\nperforms well empirically. We demonstrate this on several problems, and back\nour claims with both quantitative results and an LLM evaluation.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.CL;stat.ML", "links": "http://arxiv.org/abs/2505.14826v1;http://arxiv.org/pdf/2505.14826v1", "pdf_url": "http://arxiv.org/pdf/2505.14826v1"}, {"title": "Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory", "link": "https://arxiv.org/pdf/2505.15055", "details": "H Zhou, H Huang, Z Zhao, L Han, H Wang, K Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The evaluation of large language models (LLMs) via benchmarks is widespread, yet inconsistencies between different leaderboards and poor separability among top models raise concerns about their ability to accurately reflect authentic model \u2026", "entry_id": "http://arxiv.org/abs/2505.15055v1", "updated": "2025-05-21 03:24:11", "published": "2025-05-21 03:24:11", "authors": "Hongli Zhou;Hui Huang;Ziqing Zhao;Lvyuan Han;Huicheng Wang;Kehai Chen;Muyun Yang;Wei Bao;Jian Dong;Bing Xu;Conghui Zhu;Hailong Cao;Tiejun Zhao", "summary": "The evaluation of large language models (LLMs) via benchmarks is widespread,\nyet inconsistencies between different leaderboards and poor separability among\ntop models raise concerns about their ability to accurately reflect authentic\nmodel capabilities. This paper provides a critical analysis of benchmark\neffectiveness, examining main-stream prominent LLM benchmarks using results\nfrom diverse models. We first propose a new framework for accurate and reliable\nestimations of item characteristics and model abilities. Specifically, we\npropose Pseudo-Siamese Network for Item Response Theory (PSN-IRT), an enhanced\nItem Response Theory framework that incorporates a rich set of item parameters\nwithin an IRT-grounded architecture. Based on PSN-IRT, we conduct extensive\nanalysis which reveals significant and varied shortcomings in the measurement\nquality of current benchmarks. Furthermore, we demonstrate that leveraging\nPSN-IRT is able to construct smaller benchmarks while maintaining stronger\nalignment with human preference.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.15055v1;http://arxiv.org/pdf/2505.15055v1", "pdf_url": "http://arxiv.org/pdf/2505.15055v1"}, {"title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "link": "https://arxiv.org/pdf/2505.15323", "details": "S Cappelletti, T Poppi, S Poppi, ZX Yong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) are increasingly evaluated on multiple-choice question answering (MCQA) tasks using* first-token probability*(FTP), which selects the answer option whose initial token has the highest likelihood. While efficient, FTP \u2026", "entry_id": "http://arxiv.org/abs/2505.15323v1", "updated": "2025-05-21 09:58:38", "published": "2025-05-21 09:58:38", "authors": "Silvia Cappelletti;Tobia Poppi;Samuele Poppi;Zheng-Xin Yong;Diego Garcia-Olano;Marcella Cornia;Lorenzo Baraldi;Rita Cucchiara", "summary": "Large Language Models (LLMs) are increasingly evaluated on multiple-choice\nquestion answering (MCQA) tasks using *first-token probability* (FTP), which\nselects the answer option whose initial token has the highest likelihood. While\nefficient, FTP can be fragile: models may assign high probability to unrelated\ntokens (*misalignment*) or use a valid token merely as part of a generic\npreamble rather than as a clear answer choice (*misinterpretation*),\nundermining the reliability of symbolic evaluation. We propose a simple\nsolution: the *prefilling attack*, a structured natural-language prefix (e.g.,\n\"*The correct option is:*\") prepended to the model output. Originally explored\nin AI safety, we repurpose prefilling to steer the model to respond with a\nclean, valid option, without modifying its parameters. Empirically, the FTP\nwith prefilling strategy substantially improves accuracy, calibration, and\noutput consistency across a broad set of LLMs and MCQA benchmarks. It\noutperforms standard FTP and often matches the performance of open-ended\ngeneration approaches that require full decoding and external classifiers,\nwhile being significantly more efficient. Our findings suggest that prefilling\nis a simple, robust, and low-cost method to enhance the reliability of\nFTP-based evaluation in multiple-choice settings.", "comment": "13 pages, 5 figures, 7 tables", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.15323v1;http://arxiv.org/pdf/2505.15323v1", "pdf_url": "http://arxiv.org/pdf/2505.15323v1"}]
