[{"title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "link": "https://arxiv.org/pdf/2503.01743%3F", "details": "A Abouelenin, A Ashfaq, A Atkinson, H Awadalla\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality web and synthetic data, significantly outperforming recent \u2026"}, {"title": "VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary", "link": "https://arxiv.org/pdf/2503.09402", "details": "KQ Lin, MZ Shou - arXiv preprint arXiv:2503.09402, 2025", "abstract": "Human daily activities can be concisely narrated as sequences of routine events (eg, turning off an alarm) in video streams, forming an event vocabulary. Motivated by this, we introduce VLog, a novel video understanding framework that define video \u2026"}, {"title": "Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge", "link": "https://arxiv.org/pdf/2503.04036", "details": "X Cui, JTZ Wei, S Swayamdipta, R Jia - arXiv preprint arXiv:2503.04036, 2025", "abstract": "Data watermarking in language models injects traceable signals, such as specific token sequences or stylistic patterns, into copyrighted text, allowing copyright holders to track and verify training data ownership. Previous data watermarking techniques \u2026"}, {"title": "Multidimensional Consistency Improves Reasoning in Language Models", "link": "https://arxiv.org/pdf/2503.02670", "details": "H Lai, X Zhang, M Nissim - arXiv preprint arXiv:2503.02670, 2025", "abstract": "While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across \u2026"}, {"title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models", "link": "https://arxiv.org/pdf/2503.01464", "details": "B Nazarov, D Frolova, Y Lubarsky, A Gaissinski\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed on domain-specific data has shown significant promise. However, commercial use of such LLMs is limited by the high computational cost required for their deployment at \u2026"}, {"title": "Audio-reasoner: Improving reasoning capability in large audio language models", "link": "https://arxiv.org/pdf/2503.02318", "details": "Z Xie, M Lin, Z Liu, P Wu, S Yan, C Miao - arXiv preprint arXiv:2503.02318, 2025", "abstract": "Recent advancements in multimodal reasoning have largely overlooked the audio modality. We introduce Audio-Reasoner, a large-scale audio language model for deep reasoning in audio tasks. We meticulously curated a large-scale and diverse \u2026"}, {"title": "AdvFusion: Adapter-based Knowledge Transfer for Code Summarization on Code Language Models", "link": "https://figshare.le.ac.uk/articles/conference_contribution/AdvFusion_Adapter-based_Knowledge_Transfer_for_Code_Summarization_on_Code_Language_Models/28658645/1/files/53208368.pdf", "details": "F Chen, I Saberi, A Esmaeili, F Fard - 2025", "abstract": "Programming languages can benefit from one an-other by utilizing a pre-trained model for software engineeringtasks such as code summarization and method name prediction. While full fine-tuning of Code Language Models (Code-LMs) hasbeen \u2026"}, {"title": "Autoregressive Language Model with Historical Context Re-encoding", "link": "https://ieeexplore.ieee.org/abstract/document/10890165/", "details": "Y Zhuang - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "The foundation of current large language model applications lies in the generative language model, which typically employs an autoregressive token generation approach. However, this model faces two key limitations: its unidirectional causal \u2026"}, {"title": "X2CT-CLIP: Enable Multi-Abnormality Detection in Computed Tomography from Chest Radiography via Tri-Modal Contrastive Learning", "link": "https://arxiv.org/pdf/2503.02162", "details": "J You, Y Gao, S Kim, C Mcintosh - arXiv preprint arXiv:2503.02162, 2025", "abstract": "Computed tomography (CT) is a key imaging modality for diagnosis, yet its clinical utility is marred by high radiation exposure and long turnaround times, restricting its use for larger-scale screening. Although chest radiography (CXR) is more accessible \u2026"}]
