[{"title": "Optimizing Fine-Tuning in Quantized Language Models: An In-Depth Analysis of Key Variables.", "link": "https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D15462218%26AN%3D182195836%26h%3DDkM7H%252BNd4BEWKjE7TEkwhwLcnO19xZgFOBIOwZt8r9Fzq0LyL73eEmZznOSwUtStliyGVMcyE3esDPWIq7NApw%253D%253D%26crl%3Dc", "details": "A Shen, Z Lai, D Li, X Hu - Computers, Materials & Continua, 2025", "abstract": "Abstract Large-scale Language Models (LLMs) have achieved significant breakthroughs in Natural Language Processing (NLP), driven by the pre-training and fine-tuning paradigm. While this approach allows models to specialize in specific \u2026"}, {"title": "A dataset and benchmark for hospital course summarization with adapted large language models", "link": "https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae312/7934937", "details": "A Aali, D Van Veen, YI Arefeen, J Hom, C Bluethgen\u2026 - Journal of the American \u2026, 2024", "abstract": "Objective Brief hospital course (BHC) summaries are clinical documents that summarize a patient's hospital stay. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for \u2026"}, {"title": "Instruction-Following Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2501.02086", "details": "B Hou, Q Chen, J Wang, G Yin, C Wang, N Du, R Pang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "With the rapid scaling of large language models (LLMs), structured pruning has become a widely used technique to learn efficient, smaller models from larger ones, delivering superior performance compared to training similarly sized models from \u2026"}, {"title": "Towards Compatible Fine-tuning for Vision-Language Model Updates", "link": "https://arxiv.org/pdf/2412.20895", "details": "Z Wang, J Liang, L Sheng, R He, Z Wang, T Tan - arXiv preprint arXiv:2412.20895, 2024", "abstract": "So far, efficient fine-tuning has become a popular strategy for enhancing the capabilities of foundation models on downstream tasks by learning plug-and-play modules. However, existing methods overlook a crucial issue: if the underlying \u2026"}, {"title": "Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization", "link": "https://arxiv.org/pdf/2501.13573", "details": "L Huang, X Feng, W Ma, Y Fan, X Feng, Y Ye, W Zhong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Ensuring contextual faithfulness in retrieval-augmented large language models (LLMs) is crucial for building trustworthy information-seeking systems, particularly in long-form question-answering (LFQA) scenarios. In this work, we identify a salient \u2026"}]
