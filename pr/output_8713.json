[{"title": "Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset", "link": "https://arxiv.org/pdf/2411.03554", "details": "Y Ma, J Wang, F Wang, S Ma, J Li, X Li, F Huang, L Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Machine unlearning has emerged as an effective strategy for forgetting specific information in the training data. However, with the increasing integration of visual data, privacy concerns in Vision Language Models (VLMs) remain underexplored. To \u2026"}, {"title": "Language-Inspired Relation Transfer for Few-Shot Class-Incremental Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10746343/", "details": "Y Zhao, J Li, Z Song, Y Tian - IEEE Transactions on Pattern Analysis and Machine \u2026, 2024", "abstract": "Depicting novel classes with language descriptions by observing few-shot samples is inherent in human-learning systems. This lifelong learning capability helps to distinguish new knowledge from old ones through the increase of open-world \u2026"}]
