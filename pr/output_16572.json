[{"title": "The DRAGON benchmark for clinical NLP", "link": "https://www.nature.com/articles/s41746-025-01626-x", "details": "JS Bosma, K Dercksen, L Builtjes, R Andr\u00e9, C Roest\u2026 - npj Digital Medicine, 2025", "abstract": "Artificial Intelligence can mitigate the global shortage of medical diagnostic personnel but requires large-scale annotated datasets to train clinical algorithms. Natural Language Processing (NLP), including Large Language Models (LLMs) \u2026"}, {"title": "What Makes Large Language Models Reason In (Multi-Turn) Code Generation?", "link": "https://hal.science/hal-05070997/document", "details": "Z Kunhao, D Juliette, G Jonas, C Taco, B Negrevergne\u2026 - ICLR, 2025", "abstract": "Prompting techniques such as chain-of-thought have established themselves as a popular vehicle for improving the outputs of large language models (LLMs). For code generation, however, their exact mechanics and efficacy are under-explored. We \u2026"}, {"title": "Aligning large language models with human preferences using historical text edits", "link": "https://www.sciencedirect.com/science/article/pii/S0950705125006124", "details": "J Majkutewicz, J Szyma\u0144ski - Knowledge-Based Systems, 2025", "abstract": "Aligning large language models with human values (to be helpful, harmless, honest) requires high-quality, comprehensive human preference datasets. However, the substantial cost of creating such datasets often limits their size and scope, hindering \u2026"}, {"title": "Calibration of Large Language Models on Code Summarization", "link": "https://research.ibm.com/publications/calibration-of-large-language-models-on-code-summarization", "details": "YS Virk, P Devanbu, T Ahmed - International Symposium on Foundations of Software \u2026, 2025", "abstract": "A good summary can often be very useful during program comprehension. While a brief, fluent, and relevant summary can be helpful, it does require significant human effort to produce. Often, good summaries are unavailable in software projects, thus \u2026"}]
