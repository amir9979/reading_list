[{"title": "Lifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models", "link": "https://arxiv.org/pdf/2406.18746", "details": "G Tziafas, H Kasaei - arXiv preprint arXiv:2406.18746, 2024", "abstract": "Large Language Models (LLMs) have emerged as a new paradigm for embodied reasoning and control, most recently by generating robot policy code that utilizes a custom library of vision and control primitive skills. However, prior arts fix their skills \u2026"}, {"title": "Waterfall: Framework for Robust and Scalable Text Watermarking", "link": "https://arxiv.org/pdf/2407.04411", "details": "GKR Lau, X Niu, H Dao, J Chen, CS Foo, BKH Low - arXiv preprint arXiv:2407.04411, 2024", "abstract": "Protecting intellectual property (IP) of text such as articles and code is increasingly important, especially as sophisticated attacks become possible, such as paraphrasing by large language models (LLMs) or even unauthorized training of \u2026"}, {"title": "Efficient Training of Language Models with Compact and Consistent Next Token Distributions", "link": "https://arxiv.org/pdf/2407.02819", "details": "A Sathe, S Sarawagi - arXiv preprint arXiv:2407.02819, 2024", "abstract": "Maximizing the likelihood of the next token is an established, statistically sound objective for pre-training language models. In this paper we show that we can train better models faster by pre-aggregating the corpus with a collapsed $ n $-gram \u2026"}, {"title": "Collaborative Performance Prediction for Large Language Models", "link": "https://arxiv.org/pdf/2407.01300", "details": "Q Zhang, F Lyu, X Liu, C Ma - arXiv preprint arXiv:2407.01300, 2024", "abstract": "Comprehensively understanding and accurately predicting the performance of large language models across diverse downstream tasks has emerged as a pivotal challenge in NLP research. The pioneering scaling law on downstream works \u2026"}, {"title": "Universal Approximation Theory: The basic theory for large language models", "link": "https://arxiv.org/pdf/2407.00958", "details": "W Wang, Q Li - arXiv preprint arXiv:2407.00958, 2024", "abstract": "Language models have emerged as a critical area of focus in artificial intelligence, particularly with the introduction of groundbreaking innovations like ChatGPT. Large- scale Transformer networks have quickly become the leading approach for \u2026"}, {"title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs", "link": "https://arxiv.org/pdf/2407.00653", "details": "Y Zhang, X Wang, J Liang, S Xia, L Chen, Y Xiao - arXiv preprint arXiv:2407.00653, 2024", "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various natural language processing (NLP) tasks, which involve increasingly complex reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving new \u2026"}, {"title": "Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement", "link": "https://arxiv.org/pdf/2407.01461", "details": "Z Huang, X Wang, F Zhang, Z Xu, C Zhang, X Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The capacity of large language models (LLMs) to generate honest, harmless, and helpful responses heavily relies on the quality of user prompts. However, these prompts often tend to be brief and vague, thereby significantly limiting the full \u2026"}, {"title": "Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation", "link": "https://arxiv.org/pdf/2406.18460", "details": "A Njifenjou, V Sucal, B Jabaian, F Lef\u00e8vre - arXiv preprint arXiv:2406.18460, 2024", "abstract": "Recently, various methods have been proposed to create open-domain conversational agents with Large Language Models (LLMs). These models are able to answer user queries, but in a one-way Q&A format rather than a true conversation \u2026"}, {"title": "DART: Deep Adversarial Automated Red Teaming for LLM Safety", "link": "https://arxiv.org/pdf/2407.03876", "details": "B Jiang, Y Jing, T Shen, Q Yang, D Xiong - arXiv preprint arXiv:2407.03876, 2024", "abstract": "Manual Red teaming is a commonly-used method to identify vulnerabilities in large language models (LLMs), which, is costly and unscalable. In contrast, automated red teaming uses a Red LLM to automatically generate adversarial prompts to the Target \u2026"}]
