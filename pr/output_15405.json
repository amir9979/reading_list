[{"title": "MOM: Memory-Efficient Offloaded Mini-Sequence Inference for Long Context Language Models", "link": "https://arxiv.org/pdf/2504.12526", "details": "J Zhang, T Zhu, C Luo, A Anandkumar - arXiv preprint arXiv:2504.12526, 2025", "abstract": "Long-context language models exhibit impressive performance but remain challenging to deploy due to high GPU memory demands during inference. We propose Memory-efficient Offloaded Mini-sequence Inference (MOM), a method that \u2026"}, {"title": "CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training", "link": "https://arxiv.org/pdf/2504.13161", "details": "S Diao, Y Yang, Y Fu, X Dong, D Su, M Kliegl, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Pre-training datasets are typically collected from web content and lack inherent domain divisions. For instance, widely used datasets like Common Crawl do not include explicit domain labels, while manually curating labeled datasets such as The \u2026"}, {"title": "Capybara-OMNI: An Efficient Paradigm for Building Omni-Modal Language Models", "link": "https://arxiv.org/pdf/2504.12315", "details": "X Ji, J Wang, H Zhang, J Zhang, H Zhou, C Sun, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "With the development of Multimodal Large Language Models (MLLMs), numerous outstanding accomplishments have emerged within the open-source community. Due to the complexity of creating and training multimodal data pairs, it is still a \u2026"}, {"title": "Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model", "link": "https://arxiv.org/pdf/2503.21782", "details": "A Shaker, M Maaz, C Gou, H Rezatofighi, S Khan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Video understanding models often struggle with high computational requirements, extensive parameter counts, and slow inference speed, making them inefficient for practical use. To tackle these challenges, we propose Mobile-VideoGPT, an efficient \u2026"}, {"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2504.00869%3F", "details": "X Huang, J Wu, H Liu, X Tang, Y Zhou - arXiv preprint arXiv:2504.00869, 2025", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from \u2026"}, {"title": "Summarization Metrics for Spanish and Basque: Do Automatic Scores and LLM-Judges Correlate with Humans?", "link": "https://arxiv.org/pdf/2503.17039", "details": "J Barnes, N Perez, A Bonet-Jover, B Altuna - arXiv preprint arXiv:2503.17039, 2025", "abstract": "Studies on evaluation metrics and LLM-as-a-Judge models for automatic text summarization have largely been focused on English, limiting our understanding of their effectiveness in other languages. Through our new dataset BASSE (BAsque \u2026"}, {"title": "Automated Radiology Report Labeling in Chest X-Ray Pathologies: Development and Evaluation of a Large Language Model Framework", "link": "https://medinform.jmir.org/2025/1/e68618/", "details": "A Abdullah, ST Kim - JMIR Medical Informatics, 2025", "abstract": "Background: Labeling unstructured radiology reports is crucial for creating structured datasets that facilitate downstream tasks, such as training large-scale medical imaging models. Current approaches typically rely on Bidirectional Encoder \u2026"}, {"title": "Foundation Model for Predicting Prognosis and Adjuvant Therapy Benefit From Digital Pathology in GI Cancers", "link": "https://ascopubs.org/doi/abs/10.1200/JCO-24-01501", "details": "X Wang, Y Jiang, S Yang, F Wang, X Zhang, W Wang\u2026 - Journal of Clinical Oncology, 2025", "abstract": "PURPOSE Artificial intelligence (AI) holds significant promise for improving cancer diagnosis and treatment. Here, we present a foundation AI model for prognosis prediction on the basis of standard hematoxylin and eosin\u2013stained histopathology \u2026"}, {"title": "A large-scale vision-language dataset derived from open scientific literature to advance biomedical generalist ai", "link": "https://arxiv.org/pdf/2503.22727", "details": "A Lozano, MW Sun, J Burgess, JJ Nirschl, C Polzak\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite the excitement behind biomedical artificial intelligence (AI), access to high- quality, diverse, and large-scale data-the foundation for modern AI systems-is still a bottleneck to unlocking its full potential. To address this gap, we introduce \u2026"}]
