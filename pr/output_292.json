'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [CL&CD: Contrastive Learning and Cluster Description for Zero'
[{"title": "Contrastive Learning on Multimodal Analysis of Electronic Health Records", "link": "https://arxiv.org/html/2403.14926v1", "details": "T Cai, F Huang, R Nakada, L Zhang, D Zhou - arXiv preprint arXiv:2403.14926, 2024", "abstract": "Electronic health record (EHR) systems contain a wealth of multimodal clinical data including structured data like clinical codes and unstructured data such as clinical notes. However, many existing EHR-focused studies has traditionally either \u2026"}, {"title": "Bootstrapping Large Language Models for Radiology Report Generation", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/29826/31434", "details": "C Liu, Y Tian, W Chen, Y Song, Y Zhang - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Radiology report generation (RRG) aims to automatically generate a free-text description from a specific clinical radiograph, eg, chest X-Ray images. Existing approaches tend to perform RRG with specific models trained on the public yet \u2026"}, {"title": "A Diffusion-Based Pre-training Framework for Crystal Property Prediction", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/28748/29440", "details": "Z Song, Z Meng, I King - Proceedings of the AAAI Conference on Artificial \u2026, 2024", "abstract": "Many significant problems involving crystal property prediction from 3D structures have limited labeled data due to expensive and time-consuming physical simulations or lab experiments. To overcome this challenge, we propose a pretrain-finetune \u2026"}, {"title": "Dia-LLaMA: Towards Large Language Model-driven CT Report Generation", "link": "https://arxiv.org/html/2403.16386v1", "details": "Z Chen, L Luo, Y Bie, H Chen - arXiv preprint arXiv:2403.16386, 2024", "abstract": "Medical report generation has achieved remarkable advancements yet has still been faced with several challenges. First, the inherent imbalance in the distribution of normal and abnormal cases may lead models to exhibit a biased focus on normal \u2026"}, {"title": "Few-Shot Adversarial Prompt Learning on Vision-Language Models", "link": "https://arxiv.org/html/2403.14774v1", "details": "Y Zhou, X Xia, Z Lin, B Han, T Liu - arXiv preprint arXiv:2403.14774, 2024", "abstract": "The vulnerability of deep neural networks to imperceptible adversarial perturbations has attracted widespread attention. Inspired by the success of vision-language foundation models, previous efforts achieved zero-shot adversarial robustness by \u2026"}, {"title": "Distilling Named Entity Recognition Models for Endangered Species from Large Language Models", "link": "https://arxiv.org/pdf/2403.15430", "details": "J Atuhurra, SC Dujohn, H Kamigaito, H Shindo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Natural language processing (NLP) practitioners are leveraging large language models (LLM) to create structured datasets from semi-structured and unstructured data sources such as patents, papers, and theses, without having domain-specific \u2026"}, {"title": "Adaptive Prompt Routing for Arbitrary Text Style Transfer with Pre-trained Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29832/31446", "details": "Q Liu, J Qin, W Ye, H Mou, Y He, K Wang - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Recently, arbitrary text style transfer (TST) has made significant progress with the paradigm of prompt learning. In this paradigm, researchers often design or search for a fixed prompt for any input. However, existing evidence shows that large language \u2026"}, {"title": "Construction of a Japanese Financial Benchmark for Large Language Models", "link": "https://arxiv.org/pdf/2403.15062", "details": "M Hirano - arXiv preprint arXiv:2403.15062, 2024", "abstract": "With the recent development of large language models (LLMs), models that focus on certain domains and languages have been discussed for their necessity. There is also a growing need for benchmarks to evaluate the performance of current LLMs in \u2026"}, {"title": "Towards Multi-Intent Spoken Language Understanding via Hierarchical Attention and Optimal Transport", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29738/31270", "details": "X Cheng, Z Zhu, H Li, Y Li, X Zhuang, Y Zou - \u2026 of the AAAI Conference on Artificial \u2026, 2024", "abstract": "Multi-Intent spoken language understanding (SLU) can handle complicated utterances expressing multiple intents, which has attracted increasing attention from researchers. Although existing models have obtained promising performance, most \u2026"}]
