[{"title": "Tinylvlm-ehub: Towards comprehensive and efficient evaluation for large vision-language models", "link": "https://ieeexplore.ieee.org/abstract/document/10858438/", "details": "W Shao, M Lei, Y Hu, P Gao, P Xu, K Zhang, F Meng\u2026 - IEEE Transactions on Big \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) have made significant strides in various multimodal tasks. Notably, GPT4V, Claude, Gemini, and others showcase exceptional multimodal capabilities, marked by profound comprehension and \u2026"}, {"title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "link": "https://arxiv.org/pdf/2501.16961%3F", "details": "M Raza, N Milic-Frayling - arXiv preprint arXiv:2501.16961, 2025", "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that \u2026"}, {"title": "Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models", "link": "https://arxiv.org/pdf/2501.18533%3F", "details": "Y Ding, L Li, B Cao, J Shao - arXiv preprint arXiv:2501.18533, 2025", "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable performance across a wide range of tasks. However, their deployment in safety-critical domains poses significant challenges. Existing safety fine-tuning methods, which focus on \u2026"}, {"title": "Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration", "link": "https://arxiv.org/pdf/2502.01969", "details": "Y Zhu, L Tao, M Dong, C Xu - arXiv preprint arXiv:2502.01969, 2025", "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning capabilities but remain highly susceptible to object hallucination, where models generate responses that are not factually aligned with the visual content. Recent \u2026"}, {"title": "SKIntern: Internalizing Symbolic Knowledge for Distilling Better CoT Capabilities into Small Language Models", "link": "https://aclanthology.org/2025.coling-main.215.pdf", "details": "H Liao, S He, Y Hao, X Li, Y Zhang, J Zhao, K Liu - Proceedings of the 31st \u2026, 2025", "abstract": "Abstract Small Language Models (SLMs) are attracting attention due to the high computational demands and privacy concerns of Large Language Models (LLMs). Some studies fine-tune SLMs using Chains of Thought (CoT) data distilled from \u2026"}, {"title": "Exploring Primitive Visual Measurement Understanding and the Role of Output Format in Learning in Vision-Language Models", "link": "https://arxiv.org/pdf/2501.15144", "details": "A Yadav, L Liu, Y Qi - arXiv preprint arXiv:2501.15144, 2025", "abstract": "This work investigates the capabilities of current vision-language models (VLMs) in visual understanding and attribute measurement of primitive shapes using a benchmark focused on controlled 2D shape configurations with variations in spatial \u2026"}, {"title": "MedEx: Enhancing Medical Question-Answering with First-Order Logic based Reasoning and Knowledge Injection", "link": "https://aclanthology.org/2025.coling-main.649.pdf", "details": "A Zafar, K Mishra, A Ekbal - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "In medical question-answering, traditional knowledge triples often fail due to superfluous data and their inability to capture complex relationships between symptoms and treatments across diseases. This limits models' ability to provide \u2026"}, {"title": "Advancing Vision-Language Models with Generative AI", "link": "https://www.preprints.org/frontend/manuscript/10b5ed95bd23954c58eef830d9d74bfa/download_pub", "details": "A Vats, R Raja - 2025", "abstract": "Generative AI within large vision-language models (LVLMs) has revolutionized multimodal learning, enabling machines to understand and generate visual content from textual descriptions with unprecedented accuracy. This paper explores state-of \u2026"}, {"title": "Addressing the Training-Inference Discrepancy in Discrete Diffusion for Text Generation", "link": "https://aclanthology.org/2025.coling-main.477.pdf", "details": "M Asada, M Miwa - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "This study addresses the discrepancy between training and inference in discrete diffusion models for text generation. We propose two novel strategies:(1) a training schema that considers two-step diffusion processes, allowing the model to use its \u2026"}]
