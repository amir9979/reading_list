[{"title": "Verifying Cross-modal Entity Consistency in News using Vision-language Models", "link": "https://arxiv.org/pdf/2501.11403", "details": "S Tahmasebi, E M\u00fcller-Budack, R Ewerth - arXiv preprint arXiv:2501.11403, 2025", "abstract": "The web has become a crucial source of information, but it is also used to spread disinformation, often conveyed through multiple modalities like images and text. The identification of inconsistent cross-modal information, in particular entities such as \u2026"}, {"title": "Benchmarking Large Language Models via Random Variables", "link": "https://arxiv.org/pdf/2501.11790", "details": "Z Hong, H Wu, S Dong, J Dong, Y Xiao, Y Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "With the continuous advancement of large language models (LLMs) in mathematical reasoning, evaluating their performance in this domain has become a prominent research focus. Recent studies have raised concerns about the reliability of current \u2026"}, {"title": "Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization", "link": "https://arxiv.org/pdf/2501.13573", "details": "L Huang, X Feng, W Ma, Y Fan, X Feng, Y Ye, W Zhong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Ensuring contextual faithfulness in retrieval-augmented large language models (LLMs) is crucial for building trustworthy information-seeking systems, particularly in long-form question-answering (LFQA) scenarios. In this work, we identify a salient \u2026"}]
