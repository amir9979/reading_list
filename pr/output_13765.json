[{"title": "Multidimensional Consistency Improves Reasoning in Language Models", "link": "https://arxiv.org/pdf/2503.02670", "details": "H Lai, X Zhang, M Nissim - arXiv preprint arXiv:2503.02670, 2025", "abstract": "While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across \u2026"}, {"title": "Adding Alignment Control to Language Models", "link": "https://arxiv.org/pdf/2503.04346", "details": "W Zhu, W Zhang, R Wang - arXiv preprint arXiv:2503.04346, 2025", "abstract": "Post-training alignment has increasingly become a crucial factor in enhancing the usability of language models (LMs). However, the strength of alignment varies depending on individual preferences. This paper proposes a method to incorporate \u2026"}, {"title": "Audio-Reasoner: Improving Reasoning Capability in Large Audio Language Models", "link": "https://arxiv.org/pdf/2503.02318", "details": "Z Xie, M Lin, Z Liu, P Wu, S Yan, C Miao - arXiv preprint arXiv:2503.02318, 2025", "abstract": "Recent advancements in multimodal reasoning have largely overlooked the audio modality. We introduce Audio-Reasoner, a large-scale audio language model for deep reasoning in audio tasks. We meticulously curated a large-scale and diverse \u2026"}, {"title": "GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation", "link": "https://arxiv.org/pdf/2502.18990", "details": "J He, J Neville, M Wan, L Yang, H Liu, X Xu, X Song\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) can enhance their capabilities as AI assistants by integrating external tools, allowing them to access a wider range of information. While recent LLMs are typically fine-tuned with tool usage examples during \u2026"}, {"title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation", "link": "https://arxiv.org/pdf/2502.19414", "details": "S Sinha, S Goel, P Kumaraguru, J Geiping, M Bethge\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery. Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time. This process requires significant \u2026"}, {"title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment", "link": "https://arxiv.org/pdf/2503.04647", "details": "W Yang, J Wu, C Wang, C Zong, J Zhang - arXiv preprint arXiv:2503.04647, 2025", "abstract": "Direct Preference Optimization (DPO) has become a prominent method for aligning Large Language Models (LLMs) with human preferences. While DPO has enabled significant progress in aligning English LLMs, multilingual preference alignment is \u2026"}, {"title": "DiffPO: Diffusion-styled Preference Optimization for Efficient Inference-Time Alignment of Large Language Models", "link": "https://arxiv.org/pdf/2503.04240", "details": "R Chen, W Chai, Z Yang, X Zhang, JT Zhou, T Quek\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inference-time alignment provides an efficient alternative for aligning LLMs with humans. However, these approaches still face challenges, such as limited scalability due to policy-specific value functions and latency during the inference phase. In this \u2026"}, {"title": "CROWDSELECT: Synthetic Instruction Data Selection with Multi-LLM Wisdom", "link": "https://arxiv.org/pdf/2503.01836%3F", "details": "Y Li, L Yang, W Shen, P Zhou, Y Wan, W Lin, D Chen - arXiv preprint arXiv \u2026, 2025", "abstract": "Distilling advanced Large Language Models' instruction-following capabilities into smaller models using a selected subset has become a mainstream approach in model training. While existing synthetic instruction data selection strategies rely \u2026"}, {"title": "Nature-Inspired Population-Based Evolution of Large Language Models", "link": "https://arxiv.org/pdf/2503.01155", "details": "Y Zhang, P Ye, X Yang, S Feng, S Zhang, L Bai\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Evolution, the engine behind the survival and growth of life on Earth, operates through the population-based process of reproduction. Inspired by this principle, this paper formally defines a newly emerging problem--the population-based evolution of \u2026"}]
