[{"title": "Using a natural language processing toolkit to classify electronic health records by psychiatric diagnosis", "link": "https://journals.sagepub.com/doi/pdf/10.1177/14604582241296411", "details": "A Hutto, TM Zikry, B Bohac, T Rose, J Staebler, J Slay\u2026 - Health Informatics Journal, 2024", "abstract": "Objective: We analyzed a natural language processing (NLP) toolkit's ability to classify unstructured EHR data by psychiatric diagnosis. Expertise can be a barrier to using NLP. We employed an NLP toolkit (CLARK) created to support studies led by \u2026"}, {"title": "TLDR: Token-Level Detective Reward Model for Large Vision Language Models", "link": "https://arxiv.org/pdf/2410.04734", "details": "D Fu, T Xiao, R Wang, W Zhu, P Zhang, G Pang, R Jia\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Although reward models have been successful in improving multimodal large language models, the reward models themselves remain brutal and contain minimal information. Notably, existing reward models only mimic human annotations by \u2026"}, {"title": "Design and development of a machine-learning-driven opioid overdose risk prediction tool integrated in electronic health records in primary care settings", "link": "https://link.springer.com/article/10.1186/s42234-024-00156-3", "details": "K Nguyen, DL Wilson, J Diiulio, B Hall, L Militello\u2026 - Bioelectronic Medicine, 2024", "abstract": "Background Integrating advanced machine-learning (ML) algorithms into clinical practice is challenging and requires interdisciplinary collaboration to develop transparent, interpretable, and ethically sound clinical decision support (CDS) tools \u2026"}, {"title": "EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679582", "details": "Y Zhu, C Ren, Z Wang, X Zheng, S Xie, J Feng, X Zhu\u2026 - Proceedings of the 33rd \u2026, 2024", "abstract": "The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary \u2026"}, {"title": "Preserving Generalization of Language models in Few-shot Continual Relation Extraction", "link": "https://arxiv.org/pdf/2410.00334", "details": "Q Tran, NX Thanh, NH Anh, NL Hai, T Le, L Van Ngo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic area of study where models can sequentially integrate knowledge from new relations with limited labeled data while circumventing catastrophic forgetting and preserving prior \u2026"}, {"title": "E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model", "link": "https://arxiv.org/pdf/2410.14200", "details": "H Lai, Z Jiang, Q Yao, R Wang, Z He, X Tao, W Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The development of 3D medical vision-language models holds significant potential for disease diagnosis and patient treatment. However, compared to 2D medical images, 3D medical images, such as CT scans, face challenges related to limited \u2026"}, {"title": "Calibrated Cache Model for Few-Shot Vision-Language Model Adaptation", "link": "https://arxiv.org/pdf/2410.08895", "details": "K Ding, Q Yu, H Zhang, G Meng, S Xiang - arXiv preprint arXiv:2410.08895, 2024", "abstract": "Cache-based approaches stand out as both effective and efficient for adapting vision- language models (VLMs). Nonetheless, the existing cache model overlooks three crucial aspects. 1) Pre-trained VLMs are mainly optimized for image-text similarity \u2026"}, {"title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe", "link": "https://arxiv.org/pdf/2410.05248", "details": "Y Xiao, S Zhang, W Zhou, M Ghassemi, S Zhao - arXiv preprint arXiv:2410.05248, 2024", "abstract": "To induce desired behaviors in large language models (LLMs) for interaction-driven tasks, the instruction-tuning stage typically trains LLMs on instruction-response pairs using the next-token prediction (NTP) loss. Previous work aiming to improve \u2026"}, {"title": "SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning", "link": "https://arxiv.org/pdf/2410.11200", "details": "R Kotoge, Z Chen, T Kimura, Y Matsubara\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While end-to-end multi-channel electroencephalography (EEG) learning approaches have shown significant promise, their applicability is often constrained in neurological diagnostics, such as intracranial EEG resources. When provided with a \u2026"}]
