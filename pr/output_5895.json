[{"title": "Estimating ECG Intervals from Lead-I Alone: External Validation of Supervised Models", "link": "https://www.medrxiv.org/content/10.1101/2024.08.12.24311879.full.pdf", "details": "R Alam, C Stultz - medRxiv, 2024", "abstract": "The diagnosis, prognosis, and treatment of a number of cardiovascular disorders rely on ECG interval measurements, including the PR, QRS, and QT intervals. These quantities are measured from the 12-lead ECG, either manually or using automated \u2026"}, {"title": "Enhancing Audio-Language Models through Self-Supervised Post-Training with Text-Audio Pairs", "link": "https://arxiv.org/pdf/2408.09269", "details": "A Sinha, C Migozzi, A Rey, C Zhang - arXiv preprint arXiv:2408.09269, 2024", "abstract": "Research on multi-modal contrastive learning strategies for audio and text has rapidly gained interest. Contrastively trained Audio-Language Models (ALMs), such as CLAP, which establish a unified representation across audio and language \u2026"}, {"title": "Multi-task heterogeneous graph learning on electronic health records", "link": "https://arxiv.org/pdf/2408.07569", "details": "TH Chan, G Yin, K Bae, L Yu - Neural Networks, 2024", "abstract": "Learning electronic health records (EHRs) has received emerging attention because of its capability to facilitate accurate medical diagnosis. Since the EHRs contain enriched information specifying complex interactions between entities, modeling \u2026"}, {"title": "MindLLM: Lightweight large language model pre-training, evaluation and domain application", "link": "https://www.sciencedirect.com/science/article/pii/S2666651024000111", "details": "Y Yang, H Sun, J Li, R Liu, Y Li, Y Liu, Y Gao, H Huang - AI Open, 2024", "abstract": "Abstract Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is \u2026"}, {"title": "PCLmed: Champion Solution for ImageCLEFmedical 2024 Caption Prediction Challenge via Medical Vision-Language Foundation Models", "link": "https://ceur-ws.org/Vol-3740/paper-164.pdf", "details": "B Yang, Y Yu, Y Zou, T Zhang - \u2026 Working Notes, CEUR Workshop Proceedings, CEUR \u2026, 2024", "abstract": "Automatically generating captions and reports for medical images has become increasingly important due to the growing workload of radiologists in hospitals. To tackle this challenging task with limited annotation data, there is a rising interest in \u2026"}]
