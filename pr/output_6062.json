[{"title": "Making Long-Context Language Models Better Multi-Hop Reasoners", "link": "https://arxiv.org/pdf/2408.03246", "details": "Y Li, S Liang, MR Lyu, L Wang - arXiv preprint arXiv:2408.03246, 2024", "abstract": "Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased \u2026"}, {"title": "Efficient Test-Time Prompt Tuning for Vision-Language Models", "link": "https://arxiv.org/pdf/2408.05775", "details": "Y Zhu, G Zhang, C Xu, H Shen, X Chen, G Wu, L Wang - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models have showcased impressive zero-shot classification capabilities when equipped with suitable text prompts. Previous studies have shown the effectiveness of test-time prompt tuning; however, these methods typically require \u2026"}, {"title": "Self-Supervised Position Debiasing for Large Language Models", "link": "https://aclanthology.org/2024.findings-acl.170.pdf", "details": "Z Liu, Z Chen, M Zhang, Z Ren, P Ren, Z Chen - Findings of the Association for \u2026, 2024", "abstract": "Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Previous \u2026"}, {"title": "Studying Veteran food insecurity longitudinally using electronic health record data and natural language processing", "link": "https://www.medrxiv.org/content/10.1101/2024.08.30.24312861.full.pdf", "details": "AB Chapman, T Panadero, R Dalrymple, A Cohen\u2026 - medRxiv, 2024", "abstract": "Food insecurity is an important social risk factor that is directly linked to patient health and well-being. The Department of Veterans Affairs (VA) aims to identify and resolve food insecurity through social and clinical interventions. However, evaluating the \u2026"}, {"title": "Multi-modal Concept Alignment Pre-training for Generative Medical Visual Question Answering", "link": "https://aclanthology.org/2024.findings-acl.319.pdf", "details": "Q Yan, J Duan, J Wang - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Medical Visual Question Answering (Med-VQA) seeks to accurately respond to queries regarding medical images, a task particularly challenging for open-ended questions. This study unveils the Multi-modal Concept Alignment Pre-training \u2026"}, {"title": "Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios", "link": "https://aclanthology.org/2024.findings-acl.230.pdf", "details": "L Lin, J Fu, P Liu, Q Li, Y Gong, J Wan, F Zhang\u2026 - Findings of the Association \u2026, 2024", "abstract": "Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local \u2026"}, {"title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models By admin No Comments", "link": "https://your-ai-staff.com/self-consistency-improves-chain-of-thought/", "details": "X Wang, J Wei, D Schuurmans, Q Le, H Chi, S Narang\u2026", "abstract": "Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding \u2026"}, {"title": "Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Trustworthy Response Generation in Chinese", "link": "https://dl.acm.org/doi/pdf/10.1145/3686807", "details": "H Wang, S Zhao, Z Qiang, Z Li, C Liu, N Xi, Y Du, B Qin\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the hallucination about medical facts due to \u2026"}, {"title": "Llama2Vec: Unsupervised Adaptation of Large Language Models for Dense Retrieval", "link": "https://aclanthology.org/2024.acl-long.191.pdf", "details": "C Li, Z Liu, S Xiao, Y Shao, D Lian - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Dense retrieval calls for discriminative embeddings to represent the semantic relationship between query and document. It may benefit from the using of large language models (LLMs), given LLMs' strong capability on semantic understanding \u2026"}]
