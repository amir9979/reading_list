'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Learning Transferable Time Series Classifier with Cros'
[{"title": "CL4DIV: A Contrastive Learning Framework for Search Result Diversification", "link": "https://dl.acm.org/doi/abs/10.1145/3616855.3635851", "details": "Z Deng, Z Dou, Y Zhu, JR Wen - Proceedings of the 17th ACM International \u2026, 2024", "abstract": "Search result diversification aims to provide a diversified document ranking list so as to cover as many intents as possible and satisfy the various information needs of different users. Existing approaches usually represented documents by pretrained \u2026"}, {"title": "ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models", "link": "https://arxiv.org/pdf/2403.11103", "details": "Y Heng, C Deng, Y Li, Y Yu, Y Li, R Zhang, C Zhang - arXiv preprint arXiv:2403.11103, 2024", "abstract": "Although Large Language Models (LLMs) exhibit remarkable adaptability across domains, these models often fall short in structured knowledge extraction tasks such as named entity recognition (NER). This paper explores an innovative, cost-efficient \u2026"}, {"title": "Ensemble pretrained language models to extract biomedical knowledge from literature", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae061/7634192", "details": "Z Li, Q Wei, LC Huang, J Li, Y Hu, YS Chuang, J He\u2026 - Journal of the American \u2026, 2024", "abstract": "Objectives The rapid expansion of biomedical literature necessitates automated techniques to discern relationships between biomedical concepts from extensive free text. Such techniques facilitate the development of detailed knowledge bases and \u2026"}, {"title": "From Noise to Clarity: Unraveling the Adversarial Suffix of Large Language Model Attacks via Translation of Text Embeddings", "link": "https://arxiv.org/html/2402.16006v1", "details": "H Wang, H Li, M Huang, L Sha - arXiv preprint arXiv:2402.16006, 2024", "abstract": "The safety defense methods of Large language models (LLMs) stays limited because the dangerous prompts are manually curated to just few known attack types, which fails to keep pace with emerging varieties. Recent studies found that attaching \u2026"}, {"title": "MSLM-S2ST: A Multitask Speech Language Model for Textless Speech-to-Speech Translation with Speaker Style Preservation", "link": "https://arxiv.org/pdf/2403.12408", "details": "Y Peng, I Kulikov, Y Yang, S Popuri, H Lu, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "There have been emerging research interest and advances in speech-to-speech translation (S2ST), translating utterances from one language to another. This work proposes Multitask Speech Language Model (MSLM), which is a decoder-only \u2026"}, {"title": "Large Model driven Radiology Report Generation with Clinical Quality Reinforcement Learning", "link": "https://arxiv.org/html/2403.06728v1", "details": "Z Zhou, M Shi, M Wei, O Alabi, Z Yue, T Vercauteren - arXiv preprint arXiv \u2026, 2024", "abstract": "Radiology report generation (RRG) has attracted significant attention due to its potential to reduce the workload of radiologists. Current RRG approaches are still unsatisfactory against clinical standards. This paper introduces a novel RRG \u2026"}, {"title": "Drug\u2013target interaction prediction using knowledge graph embedding", "link": "https://www.cell.com/iscience/pdf/S2589-0042\\(24\\)00614-X.pdf", "details": "N Li, Z Yang, J Wang, H Lin - iScience, 2024", "abstract": "The prediction of drug-target interactions (DTIs) is a critical phase in the sustainable drug development process, especially when the research focus is to capitalize on the repositioning of existing drugs. Computational approaches to predicting DTIs can \u2026"}]
