'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [Text-to-OverpassQL: A Natural Language Interface for '
[{"title": "Transformers Can Represent $ n $-gram Language Models", "link": "https://arxiv.org/pdf/2404.14994", "details": "A Svete, R Cotterell - arXiv preprint arXiv:2404.14994, 2024", "abstract": "Plenty of existing work has analyzed the abilities of the transformer architecture by describing its representational capacity with formal models of computation. However, the focus so far has been on analyzing the architecture in terms of language\\emph \u2026"}, {"title": "An in-depth evaluation of federated learning on biomedical natural language processing for information extraction", "link": "https://www.nature.com/articles/s41746-024-01126-4", "details": "L Peng, G Luo, S Zhou, J Chen, Z Xu, J Sun, R Zhang - npj Digital Medicine, 2024", "abstract": "Abstract Language models (LMs) such as BERT and GPT have revolutionized natural language processing (NLP). However, the medical field faces challenges in training LMs due to limited data access and privacy constraints imposed by \u2026"}, {"title": "Federated Document Visual Question Answering: A Pilot Study", "link": "https://arxiv.org/pdf/2405.06636", "details": "K Nguyen, D Karatzas - arXiv preprint arXiv:2405.06636, 2024", "abstract": "An important handicap of document analysis research is that documents tend to be copyrighted or contain private information, which prohibits their open publication and the creation of centralised, large-scale document datasets. Instead, documents are \u2026"}, {"title": "Heterogeneous Knowledge Grounding for Medical Question Answering with Retrieval Augmented Large Language Model", "link": "https://dl.acm.org/doi/abs/10.1145/3589335.3651941", "details": "W Zhao, Z Deng, S Yadav, PS Yu - Companion Proceedings of the ACM on Web \u2026, 2024", "abstract": "The Large Language Model (LLM) is renowned for its ability to encode a vast amount of general domain knowledge, enabling it to excel in question-answering, dialogue systems, and summarization tasks. However, the medical domain presents a unique \u2026"}, {"title": "Eyes Can Deceive: Benchmarking Counterfactual Reasoning Abilities of Multi-modal Large Language Models", "link": "https://arxiv.org/pdf/2404.12966", "details": "Y Li, W Tian, Y Jiao, J Chen, YG Jiang - arXiv preprint arXiv:2404.12966, 2024", "abstract": "Counterfactual reasoning, as a crucial manifestation of human intelligence, refers to making presuppositions based on established facts and extrapolating potential outcomes. Existing multimodal large language models (MLLMs) have exhibited \u2026"}, {"title": "Compositional Text-to-Image Generation with Dense Blob Representations", "link": "https://arxiv.org/pdf/2405.08246", "details": "W Nie, S Liu, M Mardani, C Liu, B Eckart, A Vahdat - arXiv preprint arXiv:2405.08246, 2024", "abstract": "Existing text-to-image models struggle to follow complex text prompts, raising the need for extra grounding inputs for better controllability. In this work, we propose to decompose a scene into visual primitives-denoted as dense blob representations \u2026"}, {"title": "Graph learning with label attention and hyperbolic embedding for temporal event prediction in healthcare", "link": "https://napier-repository.worktribe.com/preview/3635477/1-s2.0-S0925231224005071-main.pdf", "details": "U Naseem, S Thapa, Q Zhang, S Wang, J Rashid, L Hu\u2026 - Neurocomputing, 2024", "abstract": "The digitization of healthcare systems has led to the proliferation of electronic health records (EHRs), serving as comprehensive repositories of patient information. However, the vast volume and complexity of EHR data present challenges in \u2026"}, {"title": "MedDr: Diagnosis-Guided Bootstrapping for Large-Scale Medical Vision-Language Learning", "link": "https://arxiv.org/pdf/2404.15127", "details": "S He, Y Nie, Z Chen, Z Cai, H Wang, S Yang, H Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large-scale vision-language models has showcased remarkable capabilities across various tasks. However, the lack of extensive and high-quality image-text data in medicine has greatly hindered the development of \u2026"}, {"title": "A Progressive Framework of Vision-language Knowledge Distillation and Alignment for Multilingual Scene", "link": "https://arxiv.org/pdf/2404.11249", "details": "W Zhang, Y Zhang, J Lin, B Huang, J Zhang, W Yu - arXiv preprint arXiv:2404.11249, 2024", "abstract": "Pre-trained vision-language (VL) models such as CLIP have shown excellent performance in many downstream cross-modal tasks. However, most of them are only applicable to the English context. Subsequent research has focused on this \u2026"}]
