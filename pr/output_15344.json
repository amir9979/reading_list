[{"title": "Language Models May Verbatim Complete TextThey Were Not Explicitly Trained On", "link": "https://arxiv.org/pdf/2503.17514%3F", "details": "KZ Liu, CA Choquette-Choo, M Jagielski, P Kairouz\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "An important question today is whether a given text was used to train a large language model (LLM). A\\emph {completion} test is often employed: check if the LLM completes a sufficiently complex text. This, however, requires a ground-truth \u2026"}, {"title": "Fine-Tuning Language Models with Collaborative and Semantic Experts", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/34753/36908", "details": "J Yang, B Hui, M Yang, J Yang, L Zhang, Q Qu, J Lin - Proceedings of the AAAI \u2026, 2025", "abstract": "Recent advancements in large language models (LLMs) have broadened their application scope but revealed challenges in balancing capabilities across general knowledge, coding, and mathematics. To address this, we introduce a Collaborative \u2026"}, {"title": "FATE: Feature-Adapted Parameter Tuning for Vision-Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32975/35130", "details": "Z Xu, Z Peng, X Yang, W Shen - Proceedings of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Following the recent popularity of vision language models, several attempts, eg, parameter-efficient fine-tuning (PEFT), have been made to extend them to different downstream tasks. Previous PEFT works motivate their methods from the view of \u2026"}, {"title": "DICE: A Framework for Dimensional and Contextual Evaluation of Language Models", "link": "https://arxiv.org/pdf/2504.10359", "details": "A Shrivastava, PA Aoyagui - arXiv preprint arXiv:2504.10359, 2025", "abstract": "Language models (LMs) are increasingly being integrated into a wide range of applications, yet the modern evaluation paradigm does not sufficiently reflect how they are actually being used. Current evaluations rely on benchmarks that often lack \u2026"}, {"title": "Unified Knowledge Maintenance Pruning and Progressive Recovery with Weight Recalling for Large Vision-Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/32923/35078", "details": "Z Wu, J Chen, Y Wang - Proceedings of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Abstract Large Vision-Language Model (LVLM), leveraging Large Language Model (LLM) as the cognitive core, has recently become one of the most representative multimodal model paradigms. However, with the expansion of unimodal \u2026"}, {"title": "Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data", "link": "https://arxiv.org/pdf/2504.04740", "details": "S Mishra, K Saenko, V Saligrama - arXiv preprint arXiv:2504.04740, 2025", "abstract": "Compositionality, or correctly recognizing scenes as compositions of atomic visual concepts, remains difficult for multimodal large language models (MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in distinguishing \u2026"}, {"title": "Skip-Vision: A Comprehensive Framework for Accelerating Vision-Language Models", "link": "https://arxiv.org/pdf/2503.21817%3F", "details": "W Zeng, Z Huang, K Ji, Y Yan - arXiv preprint arXiv:2503.21817, 2025", "abstract": "Transformer-based models have driven significant advancements in Multimodal Large Language Models (MLLMs), yet their computational costs surge drastically when scaling resolution, training data, and model parameters. A key bottleneck \u2026"}, {"title": "CARE: Aligning Language Models for Regional Cultural Awareness", "link": "https://arxiv.org/pdf/2504.05154%3F", "details": "G Guo, T Naous, H Wakaki, Y Nishimura, Y Mitsufuji\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing language models (LMs) often exhibit a Western-centric bias and struggle to represent diverse cultural knowledge. Previous attempts to address this rely on synthetic data and express cultural knowledge only in English. In this work, we study \u2026"}, {"title": "Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models", "link": "https://arxiv.org/pdf/2504.04264", "details": "M Wang, H Adel, L Lange, Y Liu, E Nie, J Str\u00f6tgen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multilingual language models (MLMs) store factual knowledge across languages but often struggle to provide consistent responses to semantically equivalent prompts in different languages. While previous studies point out this cross-lingual inconsistency \u2026"}]
