[{"title": "REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability", "link": "https://arxiv.org/pdf/2412.08513", "details": "KK Wickstr\u00f8m, T Br\u00fcsch, MC Kampffmeyer, R Jenssen - arXiv preprint arXiv \u2026, 2024", "abstract": "Incorporating uncertainty is crucial to provide trustworthy explanations of deep learning models. Recent works have demonstrated how uncertainty modeling can be particularly important in the unsupervised field of representation learning explainable \u2026"}, {"title": "Explaining and Mitigating the Modality Gap in Contrastive Multimodal Learning", "link": "https://arxiv.org/pdf/2412.07909", "details": "C Yaras, S Chen, P Wang, Q Qu - arXiv preprint arXiv:2412.07909, 2024", "abstract": "Multimodal learning has recently gained significant popularity, demonstrating impressive performance across various zero-shot classification tasks and a range of perceptive and generative applications. Models such as Contrastive Language \u2026"}, {"title": "SPI2I: Structure-Preserved Image-to-Image Translation with Diffusion Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-78305-0_10", "details": "B Dong, B Peng, J Dong - International Conference on Pattern Recognition, 2025", "abstract": "Large-scale text-to-image generative models are already proficient at producing high- quality results that closely match the intended prompts. Nevertheless, the pivotal challenge in image editing tasks lies in the difficulty of confining alterations within the \u2026"}, {"title": "Generative Models for Robot Learning", "link": "https://openreview.net/pdf%3Fid%3DbYCIdcBpEm", "details": "Z Wang, C Deng, C Liu, Z Jiang, H Geng, H Xu, Y Tang\u2026 - ICLR 2025 Workshop Proposals", "abstract": "Next generation of robots should combine ideas from other fields such as computer vision, natural language processing, machine learning and many others, because the close-loop system is required to deal with complex tasks based on multimodal \u2026"}]
