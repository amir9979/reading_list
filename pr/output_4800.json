[{"title": "Soft Prompts Go Hard: Steering Visual Language Models with Hidden Meta-Instructions", "link": "https://arxiv.org/pdf/2407.08970", "details": "T Zhang, C Zhang, JX Morris, E Bagdasaryan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce a new type of indirect injection vulnerabilities in language models that operate on images: hidden\" meta-instructions\" that influence how the model interprets the image and steer the model's outputs to express an adversary-chosen \u2026"}, {"title": "Pretrained Language Models for Semantics-Aware Data Harmonisation of Observational Clinical Studies in the Era of Big Data", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/07/12/2024.07.12.24310136.full.pdf", "details": "JJ Dylag, Z Zlatev, M Boniface - medRxiv, 2024", "abstract": "In clinical research, there is a strong drive to leverage big data from population cohort studies and routine electronic healthcare records to design new interventions, improve health outcomes and increase efficiency of healthcare delivery. Yet \u2026"}]
