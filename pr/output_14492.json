[{"title": "Optimizing generative AI by backpropagating language model feedback", "link": "https://www.nature.com/articles/s41586-025-08661-4", "details": "M Yuksekgonul, F Bianchi, J Boen, S Liu, P Lu\u2026 - Nature, 2025", "abstract": "Recent breakthroughs in artificial intelligence (AI) are increasingly driven by systems orchestrating multiple large language models (LLMs) and other specialized tools, such as search engines and simulators. So far, these systems are primarily \u2026"}, {"title": "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models", "link": "https://arxiv.org/pdf/2503.09573%3F", "details": "M Arriola, A Gokaslan, JT Chiu, Z Yang, Z Qi, J Han\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Diffusion language models offer unique benefits over autoregressive models due to their potential for parallelized generation and controllability, yet they lag in likelihood modeling and are limited to fixed-length generation. In this work, we introduce a \u2026"}, {"title": "Auditing language models for hidden objectives", "link": "https://arxiv.org/pdf/2503.10965%3F", "details": "S Marks, J Treutlein, T Bricken, J Lindsey, J Marcus\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We study the feasibility of conducting alignment audits: investigations into whether models have undesired objectives. As a testbed, we train a language model with a hidden objective. Our training pipeline first teaches the model about exploitable \u2026"}, {"title": "Towards reasoning era: A survey of long chain-of-thought for reasoning large language models", "link": "https://arxiv.org/pdf/2503.09567%3F", "details": "Q Chen, L Qin, J Liu, D Peng, J Guan, P Wang, M Hu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in reasoning with large language models (RLLMs), such as OpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in complex domains like mathematics and coding. A central factor in their success lies \u2026"}, {"title": "DAST: Difficulty-Aware Self-Training on Large Language Models", "link": "https://arxiv.org/pdf/2503.09029", "details": "B Xue, Q Zhu, H Wang, R Wang, S Wang, H Xu, F Mi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Present Large Language Models (LLM) self-training methods always under-sample on challenging queries, leading to inadequate learning on difficult problems which limits LLMs' ability. Therefore, this work proposes a difficulty-aware self-training \u2026"}, {"title": "GRU: Mitigating the Trade-off between Unlearning and Retention for Large Language Models", "link": "https://arxiv.org/pdf/2503.09117", "details": "Y Wang, Q Wang, F Liu, W Huang, Y Du, X Du, B Han - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language model (LLM) unlearning has demonstrated its essential role in removing privacy and copyright-related responses, crucial for their legal and safe applications. However, the pursuit of complete unlearning often comes with \u2026"}, {"title": "Learning Human Feedback from Large Language Models for Content Quality-aware Recommendation", "link": "https://dl.acm.org/doi/pdf/10.1145/3727144", "details": "H Wang, C Wu, Y Huang, T Qi - ACM Transactions on Information Systems, 2025", "abstract": "Recommender systems are widely employed to mitigate information overload by tailoring online content to individual preferences. Existing recommendation methods typically focus on optimizing the relevance between candidate item content and user \u2026"}, {"title": "Efficient and explainable sequential recommendation with language model", "link": "https://drive.google.com/file/d/11rlrXoCrYwH9mIJCDfw2gHwD8PCImjoK/view", "details": "Z Li, L Zou, C Ma, C Li - Information Processing & Management, 2025", "abstract": "Motivated by the outstanding success of large language models (LLMs) in a broad spectrum of NLP tasks, applying them for explainable recommendation become a cutting-edge recently. However, due to the inherent inconsistency in the information \u2026"}, {"title": "CEFW: A Comprehensive Evaluation Framework for Watermark in Large Language Models", "link": "https://arxiv.org/pdf/2503.20802", "details": "S Zhang, B Cheng, J Han, Y Chen, Z Wu, C Li, P Gu - arXiv preprint arXiv:2503.20802, 2025", "abstract": "Text watermarking provides an effective solution for identifying synthetic text generated by large language models. However, existing techniques often focus on satisfying specific criteria while ignoring other key aspects, lacking a unified \u2026"}]
