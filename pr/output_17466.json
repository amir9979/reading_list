[{"title": "A probabilistic approach for building disease phenotypes across electronic health records", "link": "https://link.springer.com/article/10.1186/s13040-025-00454-9", "details": "D Vidmar, J De Freitas, W Thompson, JM Pfeifer\u2026 - BioData Mining, 2025", "abstract": "Identifying the set of patients with a particular disease diagnosis across electronic health records (EHRs), referred to as a phenotype, is an important step in clinical research and applications. However, this task is often challenging, where incomplete \u2026"}, {"title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models", "link": "https://arxiv.org/pdf/2506.04689", "details": "T Nguyen, Y Li, O Golovneva, L Zettlemoyer, S Oh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet \u2026", "entry_id": "http://arxiv.org/abs/2506.04689v1", "updated": "2025-06-05 07:12:12", "published": "2025-06-05 07:12:12", "authors": "Thao Nguyen;Yang Li;Olga Golovneva;Luke Zettlemoyer;Sewoong Oh;Ludwig Schmidt;Xian Li", "summary": "Scaling laws predict that the performance of large language models improves\nwith increasing model size and data size. In practice, pre-training has been\nrelying on massive web crawls, using almost all data sources publicly available\non the internet so far. However, this pool of natural data does not grow at the\nsame rate as the compute supply. Furthermore, the availability of high-quality\ntexts is even more limited: data filtering pipelines often remove up to 99% of\nthe initial web scrapes to achieve state-of-the-art. To address the \"data wall\"\nof pre-training scaling, our work explores ways to transform and recycle data\ndiscarded in existing filtering processes. We propose REWIRE, REcycling the Web\nwith guIded REwrite, a method to enrich low-quality documents so that they\ncould become useful for training. This in turn allows us to increase the\nrepresentation of synthetic data in the final pre-training set. Experiments at\n1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw\ntexts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points\nimprovement respectively across 22 diverse tasks, compared to training on only\nfiltered web data. Training on the raw-synthetic data mix is also more\neffective than having access to 2x web data. Through further analysis, we\ndemonstrate that about 82% of the mixed in texts come from transforming\nlower-quality documents that would otherwise be discarded. REWIRE also\noutperforms related approaches of generating synthetic data, including\nWikipedia-style paraphrasing, question-answer synthesizing and knowledge\nextraction. These results suggest that recycling web texts holds the potential\nfor being a simple and effective approach for scaling pre-training data.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.LG", "links": "http://arxiv.org/abs/2506.04689v1;http://arxiv.org/pdf/2506.04689v1", "pdf_url": "http://arxiv.org/pdf/2506.04689v1"}, {"title": "An Implemented Real-World-Data Pipeline for Standardization of Electronic Health Records in Precision Oncology", "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12150718/", "details": "K Kreimeyer, D Barasa, M Sherief, X Shi, M Borja\u2026 - AMIA Summits on \u2026, 2025", "abstract": "Several use cases in precision oncology require accurately extracting and standardizing Real-World Data from Electronic Health Records (EHRs). We developed the infrastructure and a toolset incorporating data mining and natural \u2026"}, {"title": "When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment", "link": "https://arxiv.org/pdf/2506.07452", "details": "Y Xiao, S Tonekaboni, W Gerych, V Suriyakumar\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) can be prompted with specific styles (eg, formatting responses as lists), including in jailbreak queries. Although these style patterns are semantically unrelated to the malicious intents behind jailbreak queries, their safety \u2026", "entry_id": "http://arxiv.org/abs/2506.07452v1", "updated": "2025-06-09 05:57:39", "published": "2025-06-09 05:57:39", "authors": "Yuxin Xiao;Sana Tonekaboni;Walter Gerych;Vinith Suriyakumar;Marzyeh Ghassemi", "summary": "Large language models (LLMs) can be prompted with specific styles (e.g.,\nformatting responses as lists), including in jailbreak queries. Although these\nstyle patterns are semantically unrelated to the malicious intents behind\njailbreak queries, their safety impact remains unclear. In this work, we seek\nto understand whether style patterns compromise LLM safety, how superficial\nstyle alignment increases model vulnerability, and how best to mitigate these\nrisks during alignment. We evaluate 32 LLMs across seven jailbreak benchmarks,\nand find that malicious queries with style patterns inflate the attack success\nrate (ASR) for nearly all models. Notably, ASR inflation correlates with both\nthe length of style patterns and the relative attention an LLM exhibits on\nthem. We then investigate superficial style alignment, and find that\nfine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of\nthose same styles. Finally, we propose SafeStyle, a defense strategy that\nincorporates a small amount of safety training data augmented to match the\ndistribution of style patterns in the fine-tuning data. Across three LLMs and\nfive fine-tuning style settings, SafeStyle consistently outperforms baselines\nin maintaining LLM safety.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.AI;cs.CL;cs.CY", "links": "http://arxiv.org/abs/2506.07452v1;http://arxiv.org/pdf/2506.07452v1", "pdf_url": "http://arxiv.org/pdf/2506.07452v1"}]
