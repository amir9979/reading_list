[{"title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge", "link": "https://arxiv.org/pdf/2407.19594", "details": "T Wu, W Yuan, O Golovneva, J Xu, Y Tian, J Jiao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains. While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can \u2026"}, {"title": "Enhancing Explainable Rating Prediction through Annotated Macro Concepts", "link": "https://aclanthology.org/2024.acl-long.631.pdf", "details": "H Zhou, S Zhou, H Chen, N Liu, F Yang, X Huang - \u2026 of the 62nd Annual Meeting of \u2026, 2024", "abstract": "Generating recommendation reasons for recommendation results is a long-standing problem because it is challenging to explain the underlying reasons for recommending an item based on user and item IDs. Existing models usually learn \u2026"}, {"title": "DOSSIER: Fact checking in electronic health records while preserving patient privacy", "link": "https://www.amazon.science/publications/dossier-fact-checking-in-electronic-health-records-while-preserving-patient-privacy", "details": "H Zhang, S Nagesh, M Shyani, N Mishra - 2024", "abstract": "Given a particular claim about a specific document, the fact checking problem is to determine if the claim is true and, if so, provide corroborating evidence. The problem is motivated by contexts where a document is too lengthy to quickly read and find an \u2026"}, {"title": "Modelling Patient Longitudinal Data for Clinical Decision Support: A Case Study on Emerging AI Healthcare Technologies", "link": "https://link.springer.com/article/10.1007/s10796-024-10513-x", "details": "S Niu, J Ma, Q Yin, Z Wang, L Bai, X Yang - Information Systems Frontiers, 2024", "abstract": "The COVID-19 pandemic has highlighted the critical need for advanced technology in healthcare. Clinical Decision Support Systems (CDSS) utilizing Artificial Intelligence (AI) have emerged as one of the most promising technologies for \u2026"}, {"title": "EVLM: An Efficient Vision-Language Model for Visual Understanding", "link": "https://arxiv.org/pdf/2407.14177", "details": "K Chen, D Shen, H Zhong, H Zhong, K Xia, D Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the field of multi-modal language models, the majority of methods are built on an architecture similar to LLaVA. These models use a single-layer ViT feature as a visual prompt, directly feeding it into the language models alongside textual tokens \u2026"}, {"title": "Continual Learning with Semi-supervised Contrastive Distillation for Incremental Neural Machine Translation", "link": "https://aclanthology.org/2024.acl-long.588.pdf", "details": "Y Liang, F Meng, J Wang, J Xu, Y Chen, J Zhou - \u2026 of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Incrementally expanding the capability of an existing translation model to solve new domain tasks over time is a fundamental and practical problem, which usually suffers from catastrophic forgetting. Generally, multi-domain learning can be seen as a good \u2026"}, {"title": "Evaluating the necessity of the multiple metrics for assessing explainable AI: A critical examination", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224010531", "details": "M Pawlicki, A Pawlicka, F Uccello, S Szelest\u2026 - Neurocomputing, 2024", "abstract": "This paper investigates the specific properties of Explainable Artificial Intelligence (xAI), particularly when implemented in AI/ML models across high-stakes sectors, in this case cybersecurity. The authors execute a comprehensive systematic review of \u2026"}, {"title": "MixPrompt: Enhancing Generalizability and Adversarial Robustness for Vision-Language Models via Prompt Fusion", "link": "https://link.springer.com/chapter/10.1007/978-981-97-5606-3_28", "details": "H Fan, Z Ma, Y Li, R Tian, Y Chen, C Gao - International Conference on Intelligent \u2026, 2024", "abstract": "Abstract Pretrained Vision-Language Models (VLMs) like CLIP have exhibited remarkable capacities across downstream tasks, while their image encoders are vulnerable to adversarial examples. A recently introduced lightweight approach \u2026"}, {"title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education", "link": "https://arxiv.org/pdf/2407.17022", "details": "S Kim, S Kim - arXiv preprint arXiv:2407.17022, 2024", "abstract": "Large language model (LLM)-based evaluation pipelines have demonstrated their capability to robustly evaluate machine-generated text. Extending this methodology to assess human-written text could significantly benefit educational settings by \u2026"}]
