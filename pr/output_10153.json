[{"title": "Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions", "link": "https://arxiv.org/pdf/2412.02621%3F", "details": "K Sun, S Xue, F Sun, H Sun, Y Luo, L Wang, S Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in deep learning have significantly revolutionized the field of clinical diagnosis and treatment, offering novel approaches to improve diagnostic precision and treatment efficacy across diverse clinical domains, thus driving the \u2026"}, {"title": "Template Matters: Understanding the Role of Instruction Templates in Multimodal Language Model Evaluation and Training", "link": "https://arxiv.org/pdf/2412.08307", "details": "S Wang, L Song, J Zhang, R Shimizu, A Luo, L Yao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Current multimodal language models (MLMs) evaluation and training approaches overlook the influence of instruction format, presenting an elephant-in-the-room problem. Previous research deals with this problem by manually crafting instructions \u2026"}, {"title": "Efficient Transfer Learning for Video-language Foundation Models", "link": "https://arxiv.org/pdf/2411.11223", "details": "H Chen, Z Huang, Y Hong, Y Wang, Z Lyu, Z Xu, J Lan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained vision-language models provide a robust foundation for efficient transfer learning across various downstream tasks. In the field of video action recognition, mainstream approaches often introduce additional parameter modules to capture \u2026"}, {"title": "MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement", "link": "https://arxiv.org/pdf/2411.18309", "details": "X Deng, X He, Y Zhou, S Cai, C Cai, Z Chen - arXiv preprint arXiv:2411.18309, 2024", "abstract": "CT report generation (CTRG) aims to automatically generate diagnostic reports for 3D volumes, relieving clinicians' workload and improving patient care. Despite clinical value, existing works fail to effectively incorporate diagnostic information from \u2026"}, {"title": "Multimodal Autoregressive Pre-training of Large Vision Encoders", "link": "https://arxiv.org/pdf/2411.14402%3F", "details": "E Fini, M Shukor, X Li, P Dufter, M Klein, D Haldimann\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce a novel method for pre-training of large-scale vision encoders. Building on recent advancements in autoregressive pre-training of vision models, we extend this framework to a multimodal setting, ie, images and text. In this paper, we present \u2026"}, {"title": "Group Robust Best-of-K Decoding of Language Models for Pluralistic Alignment", "link": "https://openreview.net/pdf%3Fid%3DJI6j4NUGHv", "details": "S Yoon, W Bankes, S Son, A Petrovic, SS Ramesh\u2026 - Pluralistic Alignment Workshop at \u2026", "abstract": "The desirable behaviour of a chat agent can be described with multiple criteria, such as harmlessness, helpfulness, and conciseness, each of which can be scored by a reward model. While each user, or a group of users, may perceive each criterion with \u2026"}, {"title": "Enhancing the reasoning ability of multimodal large language models via mixed preference optimization", "link": "https://arxiv.org/pdf/2411.10442", "details": "W Wang, Z Chen, W Wang, Y Cao, Y Liu, Z Gao, J Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing open-source multimodal large language models (MLLMs) generally follow a training process involving pre-training and supervised fine-tuning. However, these models suffer from distribution shifts, which limit their multimodal reasoning \u2026"}, {"title": "Dynamic data summarization for hierarchical spatial clustering", "link": "https://arxiv.org/pdf/2412.07789", "details": "K Abduaziz, MS Kim, JS Shin - arXiv preprint arXiv:2412.07789, 2024", "abstract": "Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) finds meaningful patterns in spatial data by considering density and spatial proximity. As the clustering algorithm is inherently designed for static \u2026"}, {"title": "BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices", "link": "https://arxiv.org/pdf/2411.10640", "details": "X Lu, Y Chen, C Chen, H Tan, B Chen, Y Xie, R Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence and growing popularity of multimodal large language models (MLLMs) have significant potential to enhance various aspects of daily life, from improving communication to facilitating learning and problem-solving. Mobile \u2026"}]
