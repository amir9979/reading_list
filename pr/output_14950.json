[{"title": "Do Larger Language Models Imply Better Reasoning? A Pretraining Scaling Law for Reasoning", "link": "https://arxiv.org/pdf/2504.03635", "details": "X Wang, S Tan, M Jin, WY Wang, R Panda, Y Shen - arXiv preprint arXiv:2504.03635, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks requiring complex reasoning. However, the effects of scaling on their reasoning abilities remain insufficiently understood. In this paper, we \u2026"}, {"title": "Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models", "link": "https://arxiv.org/pdf/2504.04264", "details": "M Wang, H Adel, L Lange, Y Liu, E Nie, J Str\u00f6tgen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multilingual language models (MLMs) store factual knowledge across languages but often struggle to provide consistent responses to semantically equivalent prompts in different languages. While previous studies point out this cross-lingual inconsistency \u2026"}, {"title": "VALIDATION OF NATURAL LANGUAGE PROCESSING FOR SURGICAL COMPLICATION SURVEILLANCE: DETECTING ELEVEN POSTOPERATIVE \u2026", "link": "https://www.medrxiv.org/content/10.1101/2025.04.07.25325367.full.pdf", "details": "EE Dencker, A Bonde, A Troelsen, M Sillesen - medRxiv, 2025", "abstract": "Background Postoperative complications (PCs) rates are crucial quality metrics in surgery, as they reflect both patient outcomes, perioperative care effectiveness and healthcare resource strain. Despite their importance, efficient, accurate, and \u2026"}, {"title": "DeCAP: Context-Adaptive Prompt Generation for Debiasing Zero-shot Question Answering in Large Language Models", "link": "https://arxiv.org/pdf/2503.19426%3F", "details": "S Bae, YS Choi, JH Lee - arXiv preprint arXiv:2503.19426, 2025", "abstract": "While Large Language Models (LLMs) excel in zero-shot Question Answering (QA), they tend to expose biases in their internal knowledge when faced with socially sensitive questions, leading to a degradation in performance. Existing zero-shot \u2026"}, {"title": "AD-GPT: Large Language Models in Alzheimer's Disease", "link": "https://arxiv.org/pdf/2504.03071", "details": "Z Liu, L Tang, Z Sun, Z Liu, Y Lyu, W Ruan, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have emerged as powerful tools for medical information retrieval, yet their accuracy and depth remain limited in specialized domains such as Alzheimer's disease (AD), a growing global health challenge. To \u2026"}]
