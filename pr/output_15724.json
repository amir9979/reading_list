[{"title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis", "link": "https://arxiv.org/pdf/2504.10352", "details": "Y Yang, S Liu, J Li, Y Hu, H Wu, H Wang, J Yu, L Meng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent zero-shot text-to-speech (TTS) systems face a common dilemma: autoregressive (AR) models suffer from slow generation and lack duration controllability, while non-autoregressive (NAR) models lack temporal modeling and \u2026"}, {"title": "Prejudge-Before-Think: Enhancing Large Language Models at Test-Time by Process Prejudge Reasoning", "link": "https://arxiv.org/pdf/2504.13500%3F", "details": "J Wang, J Jiang, Y Liu, M Zhang, X Cai - arXiv preprint arXiv:2504.13500, 2025", "abstract": "In this paper, we introduce a new\\emph {process prejudge} strategy in LLM reasoning to demonstrate that bootstrapping with process prejudge allows the LLM to adaptively anticipate the errors encountered when advancing the subsequent \u2026"}, {"title": "Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?", "link": "https://arxiv.org/pdf/2504.10000", "details": "Y Wang, J Guan, J Liang, R He - arXiv preprint arXiv:2504.10000, 2025", "abstract": "Multi-modal large language models (MLLMs) have made significant progress, yet their safety alignment remains limited. Typically, current open-source MLLMs rely on the alignment inherited from their language module to avoid harmful generations \u2026"}, {"title": "A Dual-Space Framework for General Knowledge Distillation of Large Language Models", "link": "https://arxiv.org/pdf/2504.11426", "details": "X Zhang, S Zhang, Y Liang, F Meng, Y Chen, J Xu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Knowledge distillation (KD) is a promising solution to compress large language models (LLMs) by transferring their knowledge to smaller models. During this process, white-box KD methods usually minimize the distance between the output \u2026"}, {"title": "Learning from Reference Answers: Versatile Language Model Alignment without Binary Human Preference Data", "link": "https://arxiv.org/pdf/2504.09895%3F", "details": "S Zhao, L Zhu, Y Yang - arXiv preprint arXiv:2504.09895, 2025", "abstract": "Large language models~(LLMs) are expected to be helpful, harmless, and honest. In various alignment scenarios, such as general human preference, safety, and confidence alignment, binary preference data collection and reward modeling are \u2026"}, {"title": "SaRO: Enhancing LLM Safety through Reasoning-based Alignment", "link": "https://arxiv.org/pdf/2504.09420", "details": "Y Mou, Y Luo, S Zhang, W Ye - arXiv preprint arXiv:2504.09420, 2025", "abstract": "Current safety alignment techniques for large language models (LLMs) face two key challenges:(1) under-generalization, which leaves models vulnerable to novel jailbreak attacks, and (2) over-alignment, which leads to the excessive refusal of \u2026"}, {"title": "InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning", "link": "https://arxiv.org/pdf/2504.13032", "details": "Z Wang, SX Teo, JJ Chew, W Shi - arXiv preprint arXiv:2504.13032, 2025", "abstract": "Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought- action-observation (TAO) process to enhance LLM performance, but these \u2026"}, {"title": "d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning", "link": "https://arxiv.org/pdf/2504.12216", "details": "S Zhao, D Gupta, Q Zheng, A Grover - arXiv preprint arXiv:2504.12216, 2025", "abstract": "Recent large language models (LLMs) have demonstrated strong reasoning capabilities that benefits from online reinforcement learning (RL). These capabilities have primarily been demonstrated within the left-to-right autoregressive (AR) \u2026"}, {"title": "Teaching Large Language Models to Reason through Learning and Forgetting", "link": "https://arxiv.org/pdf/2504.11364", "details": "T Ni, A Nie, S Chaudhary, Y Liu, H Rangwala, R Fakoor - arXiv preprint arXiv \u2026, 2025", "abstract": "Leveraging inference-time search in large language models has proven effective in further enhancing a trained model's capability to solve complex mathematical and reasoning problems. However, this approach significantly increases computational \u2026"}]
