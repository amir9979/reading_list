[{"title": "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "link": "https://aclanthology.org/2024.findings-emnlp.61.pdf", "details": "X Wei, H Chen, H Yu, H Fei, Q Liu - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) have achieved notable success in commonsense reasoning tasks, benefiting from their extensive world knowledge acquired through extensive pretraining. While approaches like Chain-of-Thought \u2026"}, {"title": "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.884.pdf", "details": "P Gao, T Yamasaki, K Imoto - Findings of the Association for Computational \u2026, 2024", "abstract": "We propose VE-KD, a novel method that balances knowledge distillation and vocabulary expansion with the aim of training efficient domain-specific language models. Compared with traditional pre-training approaches, VE-KD exhibits \u2026"}, {"title": "SEAVER: Attention Reallocation for Mitigating Distractions in Language Models for Conditional Semantic Textual Similarity Measurement", "link": "https://aclanthology.org/2024.findings-emnlp.5.pdf", "details": "B Li, Y Fan, Z Gao - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Conditional Semantic Textual Similarity (C-STS) introduces specific limiting conditions to the traditional Semantic Textual Similarity (STS) task, posing challenges for STS models. Language models employing cross-encoding \u2026"}, {"title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "link": "https://aclanthology.org/2024.emnlp-main.1220.pdf", "details": "S Singla, Z Wang, T Liu, A Ashfaq, Z Hu, E Xing - \u2026 of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Abstract Aligning Large Language Models (LLMs) traditionally relies on complex and costly training processes like supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF). To address the challenge of achieving \u2026"}, {"title": "Improving Referring Ability for Biomedical Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.375.pdf", "details": "J Jiang, F Cheng, A Aizawa - Findings of the Association for Computational \u2026, 2024", "abstract": "Existing auto-regressive large language models (LLMs) are primarily trained using documents from general domains. In the biomedical domain, continual pre-training is a prevalent method for domain adaptation to inject professional knowledge into \u2026"}, {"title": "Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models", "link": "https://aclanthology.org/2024.emnlp-main.566.pdf", "details": "XH Feng, C Chen, Y Li, Z Lin - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Pre-trained language models acquire knowledge from vast amounts of text data, which can inadvertently contain sensitive information. To mitigate the presence of undesirable knowledge, the task of knowledge unlearning becomes crucial for \u2026"}, {"title": "Mitigate Extrinsic Social Bias in Pre-trained Language Models via Continuous Prompts Adjustment", "link": "https://aclanthology.org/2024.emnlp-main.620.pdf", "details": "Y Dai, H Gu, Y Wang, X Wang - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Although pre-trained language models (PLMs) have been widely used in natural language understandings (NLU), they are still exposed to fairness issues. Most existing extrinsic debiasing methods rely on manually curated word lists for each \u2026"}, {"title": "Empowering Multi-step Reasoning across Languages via Program-Aided Language Models", "link": "https://aclanthology.org/2024.emnlp-main.678.pdf", "details": "L Ranaldi, G Pucci, B Haddow, A Birch - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "In-context learning methods are popular inference strategies where Large Language Models (LLMs) are elicited to solve a task using provided demonstrations without parameter updates. Among these approaches are the reasoning methods, best \u2026"}, {"title": "Scalable Data Ablation Approximations for Language Models through Modular Training and Merging", "link": "https://arxiv.org/pdf/2410.15661", "details": "C Na, I Magnusson, AH Jha, T Sherborne, E Strubell\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Training data compositions for Large Language Models (LLMs) can significantly affect their downstream performance. However, a thorough data ablation study exploring large sets of candidate data mixtures is typically prohibitively expensive \u2026"}]
