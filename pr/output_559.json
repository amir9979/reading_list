'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [FairPair: A Robust Evaluation of Biases in Language Mo'
[{"title": "JDocQA: Japanese Document Question Answering Dataset for Generative Language Models", "link": "https://arxiv.org/pdf/2403.19454", "details": "E Onami, S Kurita, T Miyanishi, T Watanabe - arXiv preprint arXiv:2403.19454, 2024", "abstract": "Document question answering is a task of question answering on given documents such as reports, slides, pamphlets, and websites, and it is a truly demanding task as paper and electronic forms of documents are so common in our society. This is \u2026"}, {"title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies", "link": "https://arxiv.org/pdf/2404.06395", "details": "S Hu, Y Tu, X Han, C He, G Cui, X Long, Z Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This \u2026"}, {"title": "CodecLM: Aligning Language Models with Tailored Synthetic Data", "link": "https://arxiv.org/pdf/2404.05875", "details": "Z Wang, CL Li, V Perot, LT Le, J Miao, Z Zhang, CY Lee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next- token prediction objective and users' actual goals. To reduce the labor and time cost \u2026"}, {"title": "2 Unlocking information in electronic health records using natural language processing: a case study in medication information extraction", "link": "https://www.degruyter.com/document/doi/10.1515/9781614513902.33/pdf%3FlicenseType%3Drestricted", "details": "H Xu, JC Denny", "abstract": "Clinical natural language processing (NLP), which can unlock detailed patient information from clinical narratives stored in electronic health records, has been frequently used to support clinical research and operations. This chapter introduces \u2026"}, {"title": "Consprompt: Exploiting Contrastive Samples for Few-Shot Prompt Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10448403/", "details": "J Weng, Y Deng, D Li, H You, Y Hu, H Huang - ICASSP 2024-2024 IEEE International \u2026, 2024", "abstract": "Prompt has become an effective linguistic tool for utilizing pre-trained language models. However, in few-shot scenarios, subtle changes of prompt's design always make the result widely different, and the prompt learning methods are also easy to \u2026"}, {"title": "Few-Shot Data Synthesis for Open Domain Multi-Hop Question Answering", "link": "https://aclanthology.org/2024.eacl-long.12.pdf", "details": "M Chen, X Chen, W Yih - Proceedings of the 18th Conference of the European \u2026, 2024", "abstract": "Few-shot learning for open domain multi-hop question answering typically relies on the in-context learning capability of large language models (LLMs). While powerful, these LLMs usually contain tens or hundreds of billions of parameters, making them \u2026"}, {"title": "Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models", "link": "https://arxiv.org/pdf/2404.06209", "details": "S Bordt, H Nori, V Rodrigues, B Nushi, R Caruana - arXiv preprint arXiv:2404.06209, 2024", "abstract": "While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over. In this work, we address this concern for tabular data \u2026"}, {"title": "Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models", "link": "https://arxiv.org/pdf/2403.13590", "details": "A Liusie, Y Fathullah, MJF Gales - arXiv preprint arXiv:2403.13590, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities and versatility in NLP tasks, however they sometimes fail to maintain crucial invariances for specific tasks. One example is permutation sensitivity, where \u2026"}, {"title": "The Hallucinations Leaderboard--An Open Effort to Measure Hallucinations in Large Language Models", "link": "https://arxiv.org/pdf/2404.05904", "details": "G Hong, AP Gema, R Saxena, X Du, P Nie, Y Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have transformed the Natural Language Processing (NLP) landscape with their remarkable ability to understand and generate human- like text. However, these models are prone to``hallucinations''--outputs that do not \u2026"}]
