[{"title": "Position: Participatory Assessment of Large Language Model Applications in an Academic Medical Center", "link": "https://openreview.net/pdf%3Fid%3DJixmrZF2wM", "details": "G Carra, B Kulynych, F Bastardot, DE Kaufmann\u2026 - GenAI for Health: Potential, Trust \u2026", "abstract": "Although Large Language Models (LLMs) have shown promising performance in healthcare-related applications, their deployment in the medical domain poses unique challenges of ethical, regulatory, and technical nature. In this study, we \u2026"}, {"title": "Uni-Mlip: Unified Self-supervision for Medical Vision Language Pre-training", "link": "https://arxiv.org/pdf/2411.15207", "details": "A Bawazir, K Wu, W Li - arXiv preprint arXiv:2411.15207, 2024", "abstract": "Recent advancements in vision-language pre-training via contrastive learning have significantly improved performance across computer vision tasks. However, in the medical domain, obtaining multimodal data is often costly and challenging due to \u2026"}, {"title": "Med-2E3: A 2D-Enhanced 3D Medical Multimodal Large Language Model", "link": "https://arxiv.org/pdf/2411.12783", "details": "Y Shi, X Zhu, Y Hu, C Guo, M Li, J Wu - arXiv preprint arXiv:2411.12783, 2024", "abstract": "The analysis of 3D medical images is crucial for modern healthcare, yet traditional task-specific models are becoming increasingly inadequate due to limited generalizability across diverse clinical scenarios. Multimodal large language models \u2026"}]
