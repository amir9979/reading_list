[{"title": "Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.06663", "details": "K Sun, M Dredze - arXiv preprint arXiv:2408.06663, 2024", "abstract": "The development of large language models leads to the formation of a pre-train-then- align paradigm, in which the model is typically pre-trained on a large text corpus and undergoes a tuning stage to align the model with human preference or downstream \u2026"}, {"title": "Matching tasks to objectives: Fine-tuning and prompt-tuning strategies for encoder-decoder pre-trained language models", "link": "https://link.springer.com/article/10.1007/s10489-024-05660-2", "details": "A Pouramini, H Faili - Applied Intelligence, 2024", "abstract": "Prompt-based learning has emerged as a dominant paradigm in natural language processing. This study explores the impact of diverse pre-training objectives on the performance of encoder-decoder pre-trained language models across generation \u2026"}, {"title": "Exploring Universal Intrinsic Task Subspace for Few-shot Learning via Prompt Tuning", "link": "https://ieeexplore.ieee.org/iel8/6570655/6633080/10603438.pdf", "details": "Y Qin, X Wang, Y Su, Y Lin, N Ding, J Yi, W Chen, Z Liu\u2026 - IEEE/ACM Transactions on \u2026, 2024", "abstract": "Why can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidence indicating that the adaptations of PLMs to various fewshot \u2026"}, {"title": "Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning", "link": "https://arxiv.org/pdf/2407.18248", "details": "T Wang, S Li, W Lu - arXiv preprint arXiv:2407.18248, 2024", "abstract": "Effective training of language models (LMs) for mathematical reasoning tasks demands high-quality supervised fine-tuning data. Besides obtaining annotations from human experts, a common alternative is sampling from larger and more \u2026"}, {"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "Leveraging LLM Reasoning Enhances Personalized Recommender Systems", "link": "https://arxiv.org/pdf/2408.00802", "details": "AY Tsai, A Kraft, L Jin, C Cai, A Hosseini, T Xu, Z Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements have showcased the potential of Large Language Models (LLMs) in executing reasoning tasks, particularly facilitated by Chain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve clear, definitive \u2026"}, {"title": "Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.02032", "details": "F Huo, W Xu, Z Zhang, H Wang, Z Chen, P Zhao - arXiv preprint arXiv:2408.02032, 2024", "abstract": "While Large Vision-Language Models (LVLMs) have rapidly advanced in recent years, the prevalent issue known as thehallucination'problem has emerged as a significant bottleneck, hindering their real-world deployments. Existing methods \u2026"}, {"title": "Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models", "link": "https://arxiv.org/pdf/2408.06518", "details": "H Gonen, T Blevins, A Liu, L Zettlemoyer, NA Smith - arXiv preprint arXiv:2408.06518, 2024", "abstract": "Despite their wide adoption, the biases and unintended behaviors of language models remain poorly understood. In this paper, we identify and characterize a phenomenon never discussed before, which we call semantic leakage, where \u2026"}, {"title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability", "link": "https://arxiv.org/pdf/2407.19842", "details": "J Garc\u00eda-Carrasco, A Mat\u00e9, J Trujillo - arXiv preprint arXiv:2407.19842, 2024", "abstract": "Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the \u2026"}]
