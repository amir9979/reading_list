[{"title": "Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models", "link": "https://arxiv.org/pdf/2501.18533%3F", "details": "Y Ding, L Li, B Cao, J Shao - arXiv preprint arXiv:2501.18533, 2025", "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable performance across a wide range of tasks. However, their deployment in safety-critical domains poses significant challenges. Existing safety fine-tuning methods, which focus on \u2026"}, {"title": "Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration", "link": "https://arxiv.org/pdf/2502.01969", "details": "Y Zhu, L Tao, M Dong, C Xu - arXiv preprint arXiv:2502.01969, 2025", "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning capabilities but remain highly susceptible to object hallucination, where models generate responses that are not factually aligned with the visual content. Recent \u2026"}, {"title": "SKIntern: Internalizing Symbolic Knowledge for Distilling Better CoT Capabilities into Small Language Models", "link": "https://aclanthology.org/2025.coling-main.215.pdf", "details": "H Liao, S He, Y Hao, X Li, Y Zhang, J Zhao, K Liu - Proceedings of the 31st \u2026, 2025", "abstract": "Abstract Small Language Models (SLMs) are attracting attention due to the high computational demands and privacy concerns of Large Language Models (LLMs). Some studies fine-tune SLMs using Chains of Thought (CoT) data distilled from \u2026"}, {"title": "Exploring Primitive Visual Measurement Understanding and the Role of Output Format in Learning in Vision-Language Models", "link": "https://arxiv.org/pdf/2501.15144", "details": "A Yadav, L Liu, Y Qi - arXiv preprint arXiv:2501.15144, 2025", "abstract": "This work investigates the capabilities of current vision-language models (VLMs) in visual understanding and attribute measurement of primitive shapes using a benchmark focused on controlled 2D shape configurations with variations in spatial \u2026"}, {"title": "MedEx: Enhancing Medical Question-Answering with First-Order Logic based Reasoning and Knowledge Injection", "link": "https://aclanthology.org/2025.coling-main.649.pdf", "details": "A Zafar, K Mishra, A Ekbal - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "In medical question-answering, traditional knowledge triples often fail due to superfluous data and their inability to capture complex relationships between symptoms and treatments across diseases. This limits models' ability to provide \u2026"}, {"title": "Advancing Vision-Language Models with Generative AI", "link": "https://www.preprints.org/frontend/manuscript/10b5ed95bd23954c58eef830d9d74bfa/download_pub", "details": "A Vats, R Raja - 2025", "abstract": "Generative AI within large vision-language models (LVLMs) has revolutionized multimodal learning, enabling machines to understand and generate visual content from textual descriptions with unprecedented accuracy. This paper explores state-of \u2026"}, {"title": "Addressing the Training-Inference Discrepancy in Discrete Diffusion for Text Generation", "link": "https://aclanthology.org/2025.coling-main.477.pdf", "details": "M Asada, M Miwa - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "This study addresses the discrepancy between training and inference in discrete diffusion models for text generation. We propose two novel strategies:(1) a training schema that considers two-step diffusion processes, allowing the model to use its \u2026"}, {"title": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2501.12370", "details": "S Abnar, H Shah, D Busbridge, AME Ali, J Susskind\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Scaling the capacity of language models has consistently proven to be a reliable approach for improving performance and unlocking new capabilities. Capacity can be primarily defined by two dimensions: the number of model parameters and the \u2026"}, {"title": "Scaling Laws for Upcycling Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2502.03009", "details": "SP Liew, T Kato, S Takase - arXiv preprint arXiv:2502.03009, 2025", "abstract": "Pretraining large language models (LLMs) is resource-intensive, often requiring months of training time even with high-end GPU clusters. There are two approaches of mitigating such computational demands: reusing smaller models to train larger \u2026"}]
