[{"title": "CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training", "link": "https://arxiv.org/pdf/2504.13161", "details": "S Diao, Y Yang, Y Fu, X Dong, D Su, M Kliegl, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Pre-training datasets are typically collected from web content and lack inherent domain divisions. For instance, widely used datasets like Common Crawl do not include explicit domain labels, while manually curating labeled datasets such as The \u2026"}, {"title": "HF4Rec: Human-Like Feedback-Driven Optimization Framework for Explainable Recommendation", "link": "https://arxiv.org/pdf/2504.14147", "details": "J Tang, J Zhang, Z Tian, X Feng, L Wang, X Chen - arXiv preprint arXiv:2504.14147, 2025", "abstract": "Recent advancements in explainable recommendation have greatly bolstered user experience by elucidating the decision-making rationale. However, the existing methods actually fail to provide effective feedback signals for potentially better or \u2026"}, {"title": "d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning", "link": "https://arxiv.org/pdf/2504.12216", "details": "S Zhao, D Gupta, Q Zheng, A Grover - arXiv preprint arXiv:2504.12216, 2025", "abstract": "Recent large language models (LLMs) have demonstrated strong reasoning capabilities that benefits from online reinforcement learning (RL). These capabilities have primarily been demonstrated within the left-to-right autoregressive (AR) \u2026"}, {"title": "HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs", "link": "https://arxiv.org/pdf/2504.09482%3F", "details": "S Dasgupta, S Nath, A Basu, P Shamsolmoali, S Das - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have recently garnered widespread attention due to their adeptness at generating innovative responses to the given prompts across a multitude of domains. However, LLMs often suffer from the inherent limitation of \u2026"}, {"title": "Improving Sequential Recommenders through Counterfactual Augmentation of System Exposure", "link": "https://arxiv.org/pdf/2504.13482", "details": "Z Zhao, Z Ren, J Yang, Z Yan, Z Wang, L Yang, P Ren\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In sequential recommendation (SR), system exposure refers to items that are exposed to the user. Typically, only a few of the exposed items would be interacted with by the user. Although SR has achieved great success in predicting future user \u2026"}, {"title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning", "link": "https://arxiv.org/pdf/2504.09772%3F", "details": "C Jin, H Peng, Q Zhang, Y Tang, DN Metaxas, T Che - arXiv preprint arXiv \u2026, 2025", "abstract": "Multi-agent systems (MAS) built on large language models (LLMs) offer a promising path toward solving complex, real-world tasks that single-agent systems often struggle to manage. While recent advancements in test-time scaling (TTS) have \u2026"}, {"title": "Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection", "link": "https://arxiv.org/pdf/2504.09440", "details": "MS Liu, S Bo, J Fang - arXiv preprint arXiv:2504.09440, 2025", "abstract": "Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical \u2026"}]
