[{"title": "Are Expert-Level Language Models Expert-Level Annotators?", "link": "https://arxiv.org/pdf/2410.03254", "details": "YM Tseng, WL Chen, CC Chen, HH Chen - arXiv preprint arXiv:2410.03254, 2024", "abstract": "Data annotation refers to the labeling or tagging of textual data with relevant information. A large body of works have reported positive results on leveraging LLMs as an alternative to human annotators. However, existing studies focus on classic \u2026"}, {"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning", "link": "https://arxiv.org/pdf/2410.14375", "details": "J Yu, Y Zhou, Y He, NL Zhang, R Silva - arXiv preprint arXiv:2410.14375, 2024", "abstract": "The fine-tuning of pre-trained language models (PLMs) has been shown to be effective across various domains. By using domain-specific supervised data, the general-purpose representation derived from PLMs can be transformed into a \u2026"}, {"title": "From Imitation to Introspection: Probing Self-Consciousness in Language Models", "link": "https://arxiv.org/pdf/2410.18819", "details": "S Chen, S Yu, S Zhao, C Lu - arXiv preprint arXiv:2410.18819, 2024", "abstract": "Self-consciousness, the introspection of one's existence and thoughts, represents a high-level cognitive process. As language models advance at an unprecedented pace, a critical question arises: Are these models becoming self-conscious? Drawing \u2026"}, {"title": "Taipan: Efficient and Expressive State Space Language Models with Selective Attention", "link": "https://arxiv.org/pdf/2410.18572", "details": "C Van Nguyen, HH Nguyen, TM Pham, R Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Efficient long-context language modeling remains a significant challenge in Natural Language Processing (NLP). While Transformers dominate language tasks, they struggle with long sequences due to quadratic computational complexity in training \u2026"}, {"title": "LoGra-Med: Long context multi-graph alignment for medical vision-language model", "link": "https://arxiv.org/pdf/2410.02615%3F", "details": "DMH Nguyen, NT Diep, TQ Nguyen, HB Le, T Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "State-of-the-art medical multi-modal large language models (med-MLLM), like LLaVA-Med or BioMedGPT, leverage instruction-following data in pre-training. However, those models primarily focus on scaling the model size and data volume to \u2026"}, {"title": "Explainable Diagnosis Prediction through Neuro-Symbolic Integration", "link": "https://arxiv.org/pdf/2410.01855%3F", "details": "Q Lu, R Li, E Sagheb, A Wen, J Wang, L Wang, JW Fan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Diagnosis prediction is a critical task in healthcare, where timely and accurate identification of medical conditions can significantly impact patient outcomes. Traditional machine learning and deep learning models have achieved notable \u2026"}, {"title": "ConceptDrift: Uncovering Biases through the Lens of Foundational Models", "link": "https://arxiv.org/pdf/2410.18970", "details": "CD P\u0103duraru, A B\u0103rb\u0103lau, R Filipescu, AL Nicolicioiu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Datasets and pre-trained models come with intrinsic biases. Most methods rely on spotting them by analysing misclassified samples, in a semi-automated human- computer validation. In contrast, we propose ConceptDrift, a method which analyzes \u2026"}, {"title": "Advancing Medical Radiograph Representation Learning: A Hybrid Pre-training Paradigm with Multilevel Semantic Granularity", "link": "https://arxiv.org/pdf/2410.00448", "details": "H Jiang, X Hao, Y Huang, C Ma, J Zhang, Y Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces an innovative approach to Medical Vision-Language Pre- training (Med-VLP) area in the specialized context of radiograph representation learning. While conventional methods frequently merge textual annotations into \u2026"}]
