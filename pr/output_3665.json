[{"title": "Memory Augmented Language Models through Mixture of Word Experts", "link": "https://aclanthology.org/2024.naacl-long.249.pdf", "details": "C dos Santos, J Lee-Thorp, I Noble, CC Chang\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Scaling up the number of parameters of language models has proven to be an effective approach to improve performance. For dense models, increasing their size proportionally increases their computational footprint. In this work, we seek to \u2026"}, {"title": "Refusal in Language Models Is Mediated by a Single Direction", "link": "https://arxiv.org/pdf/2406.11717", "details": "A Arditi, O Obeso, A Syed, D Paleka, N Rimsky\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Conversational large language models are fine-tuned for both instruction-following and safety, resulting in models that obey benign requests but refuse harmful ones. While this refusal behavior is widespread across chat models, its underlying \u2026"}, {"title": "Automated Identification of Patients' Unmet Social Needs in Clinical Text Using Natural Language Processing", "link": "https://www.mcpdigitalhealth.org/article/S2949-7612\\(24\\)00069-5/pdf", "details": "S Moon, Y Wu, JB Doughty, ML Wieland, LM Philpot\u2026 - Mayo Clinic Proceedings \u2026, 2024", "abstract": "Objective To develop natural language processing (NLP) solutions for identifying patients' unmet social needs to enable timely intervention. Patients and Methods: Design Retrospective cohort study with review and annotation of clinical notes to \u2026"}, {"title": "Risk Prediction of Heart Diseases in Breast Cancer Patients: A Deep Learning Approach with Longitudinal Electronic Health Records Data", "link": "https://www.sciencedirect.com/science/article/pii/S2589004224015542/pdf%3Fmd5%3D37c71c6825b3040cbf3cbd88afb5955b%26pid%3D1-s2.0-S2589004224015542-main.pdf", "details": "S Zhou, A Blaes, C Shenoy, J Sun, R Zhang - iScience, 2024", "abstract": "Accurately predicting heart disease risks in breast cancer patients is crucial for clinical decision support and patient safety. This study developed and evaluated predictive models for six heart diseases using real-world electronic health records \u2026"}, {"title": "A Critical Look At Tokenwise Reward-Guided Text Generation", "link": "https://arxiv.org/pdf/2406.07780", "details": "A Rashid, R Wu, J Grosse, A Kristiadi, P Poupart - arXiv preprint arXiv:2406.07780, 2024", "abstract": "Large language models (LLMs) can significantly be improved by aligning to human preferences--the so-called reinforcement learning from human feedback (RLHF). However, the cost of fine-tuning an LLM is prohibitive for many users. Due to their \u2026"}, {"title": "Evaluating $ n $-Gram Novelty of Language Models Using Rusty-DAWG", "link": "https://arxiv.org/pdf/2406.13069", "details": "W Merrill, NA Smith, Y Elazar - arXiv preprint arXiv:2406.13069, 2024", "abstract": "How novel are texts generated by language models (LMs) relative to their training corpora? In this work, we investigate the extent to which modern LMs generate $ n $- grams from their training data, evaluating both (i) the probability LMs assign to \u2026"}, {"title": "ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models", "link": "https://aclanthology.org/2024.findings-naacl.261.pdf", "details": "MN Tran, PV Nguyen, L Nguyen, D Dien - Findings of the Association for \u2026, 2024", "abstract": "As the number of language models has increased, various benchmarks have been suggested to assess the proficiency of the models in natural language understanding. However, there is a lack of such a benchmark in Vietnamese due to \u2026"}, {"title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models", "link": "https://arxiv.org/pdf/2406.19146", "details": "T Porian, M Wortsman, J Jitsev, L Schmidt, Y Carmon - arXiv preprint arXiv \u2026, 2024", "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the optimal model size as a function of the compute budget, but these laws yield substantially different predictions. We explain the discrepancy by reproducing the Kaplan scaling \u2026"}, {"title": "Abstraction-of-Thought Makes Language Models Better Reasoners", "link": "https://arxiv.org/pdf/2406.12442", "details": "R Hong, H Zhang, X Pan, D Yu, C Zhang - arXiv preprint arXiv:2406.12442, 2024", "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks \u2026"}]
