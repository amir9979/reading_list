[{"title": "Self-training elicits concise reasoning in large language models", "link": "https://arxiv.org/pdf/2502.20122", "details": "T Munkhbat, N Ho, S Kim, Y Yang, Y Kim, SY Yun - arXiv preprint arXiv:2502.20122, 2025", "abstract": "Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens \u2026"}, {"title": "A survey on feedback-based multi-step reasoning for large language models on mathematics", "link": "https://arxiv.org/pdf/2502.14333", "details": "TR Wei, H Liu, X Wu, Y Fang - arXiv preprint arXiv:2502.14333, 2025", "abstract": "Recent progress in large language models (LLM) found chain-of-thought prompting strategies to improve the reasoning ability of LLMs by encouraging problem solving through multiple steps. Therefore, subsequent research aimed to integrate the multi \u2026"}, {"title": "Probench: Benchmarking large language models in competitive programming", "link": "https://arxiv.org/pdf/2502.20868", "details": "L Yang, R Jin, L Shi, J Peng, Y Chen, D Xiong - arXiv preprint arXiv:2502.20868, 2025", "abstract": "With reasoning language models such as OpenAI-o3 and DeepSeek-R1 emerging, large language models (LLMs) have entered a new phase of development. However, existing benchmarks for coding evaluation are gradually inadequate to assess the \u2026"}, {"title": "Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA", "link": "https://arxiv.org/pdf/2503.02034", "details": "Z Zhong, Y Wang, L Bi, Z Ma, SH Ahn, CJ Mullin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical imaging plays a pivotal role in modern healthcare, with computed tomography pulmonary angiography (CTPA) being a critical tool for diagnosing pulmonary embolism and other thoracic conditions. However, the complexity of \u2026"}, {"title": "QA-Calibration of language model confidence scores", "link": "https://www.amazon.science/publications/qa-calibration-of-language-model-confidence-scores", "details": "A Mastakouri, E Kirschbaum, S Kasiviswanathan\u2026 - 2025", "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim \u2026"}]
