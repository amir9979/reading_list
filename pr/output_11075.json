[{"title": "Enhancing LLMs for Physics Problem-Solving using Reinforcement Learning with Human-AI Feedback", "link": "https://arxiv.org/pdf/2412.06827", "details": "A Anand, K Prasad, C Kirtani, AR Nair, M Gupta\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in text-based tasks but struggle with the complex reasoning required for physics problems, particularly in advanced arithmetic and conceptual understanding. While some \u2026"}, {"title": "PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning", "link": "https://arxiv.org/pdf/2412.04975%3F", "details": "J Rieger, M Ruckdeschel, G Wiedemann - arXiv preprint arXiv:2412.04975, 2024", "abstract": "Few-shot learning and parameter-efficient fine-tuning (PEFT) are crucial to overcome the challenges of data scarcity and ever growing language model sizes. This applies in particular to specialized scientific domains, where researchers might lack \u2026"}, {"title": "EXAONE 3.5: Series of Large Language Models for Real-world Use Cases", "link": "https://arxiv.org/pdf/2412.04862", "details": "LG Research, S An, K Bae, E Choi, K Choi, SJ Choi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This technical report introduces the EXAONE 3.5 instruction-tuned language models, developed and released by LG AI Research. The EXAONE 3.5 language models are offered in three configurations: 32B, 7.8 B, and 2.4 B. These models feature several \u2026"}, {"title": "AutoReason: Automatic Few-Shot Reasoning Decomposition", "link": "https://arxiv.org/pdf/2412.06975", "details": "A Sevinc, A Gumus - arXiv preprint arXiv:2412.06975, 2024", "abstract": "Chain of Thought (CoT) was introduced in recent research as a method for improving step-by-step reasoning in Large Language Models. However, CoT has limited applications such as its need for hand-crafted few-shot exemplar prompts and no \u2026"}, {"title": "Dynamic Ensemble Reasoning for LLM Experts", "link": "https://arxiv.org/pdf/2412.07448", "details": "J Hu, Y Wang, S Zhang, K Zhou, G Chen, Y Hu, B Xiao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Ensemble reasoning for the strengths of different LLM experts is critical to achieving consistent and satisfactory performance on diverse inputs across a wide range of tasks. However, existing LLM ensemble methods are either computationally \u2026"}, {"title": "Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt", "link": "https://arxiv.org/pdf/2412.05967", "details": "D de Mijolla, W Yang, P Duckett, C Frye, M Worrall - arXiv preprint arXiv:2412.05967, 2024", "abstract": "Prompting and fine-tuning have emerged as two competing paradigms for augmenting language models with new capabilities, such as the use of tools. Prompting approaches are quick to set up but rely on providing explicit \u2026"}, {"title": "SpecFuse: Ensembling Large Language Models via Next-Segment Prediction", "link": "https://arxiv.org/pdf/2412.07380%3F", "details": "B Lv, C Tang, Y Zhang, X Liu, Y Yu, P Luo - arXiv preprint arXiv:2412.07380, 2024", "abstract": "Ensembles of generative large language models (LLMs) can integrate the strengths of different LLMs to compensate for the limitations of individual models. However, recent work has focused on training an additional fusion model to combine complete \u2026"}]
