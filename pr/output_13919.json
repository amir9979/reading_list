[{"title": "LightGen: Efficient Image Generation through Knowledge Distillation and Direct Preference Optimization", "link": "https://arxiv.org/pdf/2503.08619", "details": "X Wu, Y Bai, H Zheng, HH Chen, Y Liu, Z Wang, X Ma\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in text-to-image generation have primarily relied on extensive datasets and parameter-heavy architectures. These requirements severely limit accessibility for researchers and practitioners who lack substantial computational \u2026"}, {"title": "Dynamic Soft Contrastive Learning for Time Series Anomaly Detection", "link": "https://ieeexplore.ieee.org/iel8/10887540/10887541/10889377.pdf", "details": "Y Song, Y Liu, S Shu - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Multivariate time series anomaly detection has been extensively studied in diverse domains. Within the horizon of unsupervised methods, density estimation is regarded as a promising direction. However, the anomalies that distribute closely with normal \u2026"}, {"title": "BiasEdit: Debiasing Stereotyped Language Models via Model Editing", "link": "https://arxiv.org/pdf/2503.08588", "details": "X Xu, W Xu, N Zhang, J McAuley - arXiv preprint arXiv:2503.08588, 2025", "abstract": "Previous studies have established that language models manifest stereotyped biases. Existing debiasing strategies, such as retraining a model with counterfactual data, representation projection, and prompting often fail to efficiently eliminate bias or \u2026"}, {"title": "LatentPS: Image Editing Using Latent Representations in Diffusion Models", "link": "https://openaccess.thecvf.com/content/WACV2025W/ImageQuality/papers/Wu_LatentPS_Image_Editing_Using_Latent_Representations_in_Diffusion_Models_WACVW_2025_paper.pdf", "details": "Z Wu, H Murata, N Takahashi, Q Wu, Y Tsuruoka - Proceedings of the Winter \u2026, 2025", "abstract": "Generative image models have significantly advanced recently enabling detailed image generation from textual prompts. However accurately describing complex image with textual prompts alone is often challenging. To address this we propose \u2026"}, {"title": "CAD-VAE: Leveraging Correlation-Aware Latents for Comprehensive Fair Disentanglement", "link": "https://arxiv.org/pdf/2503.07938", "details": "C Ma, R Zhao, X Xiao, H Xie, T Wang, X Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "While deep generative models have significantly advanced representation learning, they may inherit or amplify biases and fairness issues by encoding sensitive attributes alongside predictive features. Enforcing strict independence in \u2026"}, {"title": "The future of action recognition: are multi-modal visual language models the key?", "link": "https://link.springer.com/article/10.1007/s11760-025-03951-w", "details": "E G\u00fcm\u00fc\u015fkaynak, S Eken - Signal, Image and Video Processing, 2025", "abstract": "This study investigates the potential of Visual Language Models for action recognition, a critical task in video analysis. Traditional action recognition methods predominantly rely on visual features, often struggling with challenges such as \u2026"}]
