[{"title": "Self-prompting large language models for zero-shot open-domain QA", "link": "https://aclanthology.org/2024.naacl-long.17.pdf", "details": "J Li, J Wang, Z Zhang, H Zhao - Proceedings of the 2024 Conference of the North \u2026, 2024", "abstract": "Abstract Open-Domain Question Answering (ODQA) aims to answer questions without explicitly providing specific background documents. This task becomes notably challenging in a zero-shot setting where no data is available to train tailored \u2026"}, {"title": "Memory augmented language models through mixture of word experts", "link": "https://aclanthology.org/2024.naacl-long.249.pdf", "details": "C dos Santos, J Lee-Thorp, I Noble, CC Chang\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Scaling up the number of parameters of language models has proven to be an effective approach to improve performance. For dense models, increasing their size proportionally increases their computational footprint. In this work, we seek to \u2026"}, {"title": "MaCSC: Towards Multimodal-augmented Pre-trained Language Models via Conceptual Prototypes and Self-balancing Calibration", "link": "https://aclanthology.org/2024.naacl-long.446.pdf", "details": "X Zhuang, Z Wang, X Cheng, Y Xie, L Liang, Y Zou - \u2026 of the 2024 Conference of the \u2026, 2024", "abstract": "Pre-trained language models (PLMs) that rely solely on textual data may exhibit limitations in multimodal semantics comprehension. Existing solutions attempt to alleviate this issue by incorporating explicit image retrieval or generation techniques \u2026"}, {"title": "mDPO: Conditional Preference Optimization for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2406.11839", "details": "F Wang, W Zhou, JY Huang, N Xu, S Zhang, H Poon\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Direct preference optimization (DPO) has shown to be an effective method for large language model (LLM) alignment. Recent works have attempted to apply DPO to multimodal scenarios but have found it challenging to achieve consistent \u2026"}, {"title": "Large Language Models for Text Style Transfer: Exploratory Analysis of Prompting and Knowledge Augmentation Techniques", "link": "https://ebooks.iospress.nl/pdf/doi/10.3233/AISE240025", "details": "M Toshevska, S Gievska - \u2026 2024: Combined Proceedings of Workshops and \u2026, 2024", "abstract": "Large language models have gained extensive research interest in the past few years. They have demonstrated remarkable ability to process and generate human- like text, and have improved performances on various natural language processing \u2026"}, {"title": "Towards improved breast cancer detection on digital mammograms using local self-attention-based transformer", "link": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13174/131741T/Towards-improved-breast-cancer-detection-on-digital-mammograms-using-local/10.1117/12.3025375.short", "details": "H Chen, AL Martel - 17th International Workshop on Breast Imaging (IWBI \u2026, 2024", "abstract": "Deep-learning-based models have been proposed as an automated second reader for mammograms that might help reduce radiologists' workload and improve screening accuracy. However, the inherent traits of mammograms, characterized by \u2026"}, {"title": "Demonstration Augmentation for Zero-shot In-context Learning", "link": "https://arxiv.org/pdf/2406.01224", "details": "Y Su, Y Tai, Y Ji, J Li, B Yan, M Zhang - arXiv preprint arXiv:2406.01224, 2024", "abstract": "Large Language Models (LLMs) have demonstrated an impressive capability known as In-context Learning (ICL), which enables them to acquire knowledge from textual demonstrations without the need for parameter updates. However, many studies \u2026"}, {"title": "Beyond Imitation: Learning Key Reasoning Steps from Dual Chain-of-Thoughts in Reasoning Distillation", "link": "https://arxiv.org/pdf/2405.19737", "details": "C Dai, K Li, W Zhou, S Hu - arXiv preprint arXiv:2405.19737, 2024", "abstract": "As Large Language Models (LLMs) scale up and gain powerful Chain-of-Thoughts (CoTs) reasoning abilities, practical resource constraints drive efforts to distill these capabilities into more compact Smaller Language Models (SLMs). We find that CoTs \u2026"}]
