[{"title": "VU Research Portal", "link": "https://research.vu.nl/ws/portalfiles/portal/355675396/d1ab2185232d59b73/docs/_source/tutorials/notebooks/deploying-textclassification-colab-activelearning.ipynb", "details": "M Laurer", "abstract": "From millions of social media posts, to decades of legal text-more and more relevant information is hidden in digital text corpora that are too large for manual analyses. The key promise of machine learning is to automate parts of the manual analysis \u2026"}, {"title": "Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards", "link": "https://arxiv.org/pdf/2409.17472", "details": "H Do, S Ryu, GG Lee - arXiv preprint arXiv:2409.17472, 2024", "abstract": "Recent advances in automated essay scoring (AES) have shifted towards evaluating multiple traits to provide enriched feedback. Like typical AES systems, multi-trait AES employs the quadratic weighted kappa (QWK) to measure agreement with human \u2026"}, {"title": "Language Models Benefit from Preparation with Elicited Knowledge", "link": "https://arxiv.org/pdf/2409.01345", "details": "J Yu, H An, LK Schubert - arXiv preprint arXiv:2409.01345, 2024", "abstract": "The zero-shot chain of thought (CoT) approach is often used in question answering (QA) by language models (LMs) for tasks that require multiple reasoning steps, typically enhanced by the prompt\" Let's think step by step.\" However, some QA tasks \u2026"}, {"title": "How Does Diverse Interpretability of Textual Prompts Impact Medical Vision-Language Zero-Shot Tasks?", "link": "https://arxiv.org/pdf/2409.00543", "details": "S Wang, C Liu, R Arcucci - arXiv preprint arXiv:2409.00543, 2024", "abstract": "Recent advancements in medical vision-language pre-training (MedVLP) have significantly enhanced zero-shot medical vision tasks such as image classification by leveraging large-scale medical image-text pair pre-training. However, the \u2026"}]
