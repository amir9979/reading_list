[{"title": "GEOBench-VLM: Benchmarking Vision-Language Models for Geospatial Tasks", "link": "https://arxiv.org/pdf/2411.19325", "details": "MS Danish, MA Munir, SRA Shah, K Kuckreja, FS Khan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While numerous recent benchmarks focus on evaluating generic Vision-Language Models (VLMs), they fall short in addressing the unique demands of geospatial applications. Generic VLM benchmarks are not designed to handle the complexities \u2026"}, {"title": "Evaluating Vision-Language Models as Evaluators in Path Planning", "link": "https://arxiv.org/pdf/2411.18711", "details": "M Aghzal, X Yue, E Plaku, Z Yao - arXiv preprint arXiv:2411.18711, 2024", "abstract": "Despite their promise to perform complex reasoning, large language models (LLMs) have been shown to have limited effectiveness in end-to-end planning. This has inspired an intriguing question: if these models cannot plan well, can they still \u2026"}, {"title": "VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models", "link": "https://arxiv.org/pdf/2412.01822", "details": "BK Lee, R Hachiuma, YCF Wang, YM Ro, YH Wu - arXiv preprint arXiv:2412.01822, 2024", "abstract": "The recent surge in high-quality visual instruction tuning samples from closed-source vision-language models (VLMs) such as GPT-4V has accelerated the release of open-source VLMs across various model sizes. However, scaling VLMs to improve \u2026"}, {"title": "Domain Aware Multi-Task Pre-Training of 3D Swin Transformer for Brain MRI", "link": "https://openaccess.thecvf.com/content/ACCV2024/papers/Kim_Domain_Aware_Multi-Task_Pre-Training_of_3D_Swin_Transformer_for_Brain_ACCV_2024_paper.pdf", "details": "J Kim, M Kim, H Park - Proceedings of the Asian Conference on Computer \u2026, 2024", "abstract": "The scarcity of annotated medical images is a major bottleneck in developing learning models for medical image analysis. Hence, recent studies have focused on pretrained models with fewer annotation requirements that can be fine-tuned for \u2026"}, {"title": "ConvBench: A Multi-Turn Conversation Evaluation Benchmark with Hierarchical Ablation Capability for Large Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3DPyTf2jj0SH", "details": "S Liu, K Ying, H Zhang, Y Yang, Y Lin, T Zhang, C Li\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Multi-turn visual conversation is an important ability of real-world AI assistants. However, the related evaluation benchmark is missed. This paper presents ConvBench, a multi-turn conversation benchmark with hierarchical capabilities \u2026"}, {"title": "Micro-Bench: A Microscopy Benchmark for Vision-Language Understanding", "link": "https://openreview.net/pdf%3Fid%3DeRleg6vy0Y", "details": "A Lozano, JJ Nirschl, J Burgess, SR Gupte, Y Zhang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent advances in microscopy have enabled the rapid generation of terabytes of image data in cell biology and biomedical research. Vision-language models (VLMs) offer a promising solution for large-scale biological image analysis, enhancing \u2026"}, {"title": "Sparse Attention Vectors: Generative Multimodal Model Features Are Discriminative Vision-Language Classifiers", "link": "https://arxiv.org/pdf/2412.00142", "details": "C Mitra, B Huang, T Chai, Z Lin, A Arbelle, R Feris\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generative Large Multimodal Models (LMMs) like LLaVA and Qwen-VL excel at a wide variety of vision-language (VL) tasks such as image captioning or visual question answering. Despite strong performance, LMMs are not directly suited for \u2026"}, {"title": "SciInstruct: a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models", "link": "https://openreview.net/pdf%3Fid%3DLC1QAqhePv", "details": "D Zhang, Z Hu, S Zhoubian, Z Du, K Yang, Z Wang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving \u2026"}, {"title": "Efficient Aspect-Based Summarization of Climate Change Reports with Small Language Models", "link": "https://arxiv.org/pdf/2411.14272", "details": "I Ghinassi, L Catalano, T Colella - arXiv preprint arXiv:2411.14272, 2024", "abstract": "The use of Natural Language Processing (NLP) for helping decision-makers with Climate Change action has recently been highlighted as a use case aligning with a broader drive towards NLP technologies for social good. In this context, Aspect \u2026"}]
