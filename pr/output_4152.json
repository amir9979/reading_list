[{"title": "SOMONITOR: Explainable Marketing Data Processing and Analysis with Large Language Models", "link": "https://arxiv.org/pdf/2407.13117", "details": "Q Yang, S Nikolenko, M Ongpin, I Gossoudarev\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Online marketing faces formidable challenges in managing and interpreting immense volumes of data necessary for competitor analysis, content research, and strategic branding. It is impossible to review hundreds to thousands of transient \u2026"}, {"title": "Meta-learning and Data Augmentation for Stress Testing Forecasting Models", "link": "https://arxiv.org/pdf/2406.17008", "details": "R In\u00e1cio, V Cerqueira, M Barandas, C Soares - arXiv preprint arXiv:2406.17008, 2024", "abstract": "The effectiveness of univariate forecasting models is often hampered by conditions that cause them stress. A model is considered to be under stress if it shows a negative behaviour, such as higher-than-usual errors or increased uncertainty \u2026"}, {"title": "Hybrid Explanatory Interactive Machine Learning for Medical Diagnosis", "link": "https://link.springer.com/chapter/10.1007/978-3-031-63211-2_9", "details": "E Slany, S Scheele, U Schmid - IFIP International Conference on Artificial Intelligence \u2026, 2024", "abstract": "Abstract Machine learning (ML) models can be an effective assistance in medical diagnosis if they allow physicians to project their knowledge into model's internal mechanism. Using model-agnostic explanatory interactive ML (XIML), physicians \u2026"}, {"title": "LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models", "link": "https://arxiv.org/pdf/2406.19486", "details": "S Guo, S Damani, K Chang - arXiv preprint arXiv:2406.19486, 2024", "abstract": "In prompt tuning, a prefix or suffix text is added to the prompt, and the embeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix are optimized to gain more control over language models for specific tasks. This approach eliminates the \u2026"}, {"title": "IRIT-Berger-Levrault at SemEval-2024: How Sensitive Sentence Embeddings are to Hallucinations?", "link": "https://aclanthology.org/2024.semeval-1.86.pdf", "details": "N Bendahman, K Pinel-Sauvagnat, G Hubert, M Billami - Proceedings of the 18th \u2026, 2024", "abstract": "This article presents our participation to Task 6 of SemEval-2024, named SHROOM (a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes), which aims at detecting hallucinations. We propose two types of approaches for the \u2026"}, {"title": "Task Oriented In-Domain Data Augmentation", "link": "https://arxiv.org/pdf/2406.16694", "details": "X Liang, X Hu, S Zuo, Y Gong, Q Lou, Y Liu, SL Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have shown superior performance in various applications and fields. To achieve better performance on specialized domains such as law and advertisement, LLMs are often continue pre-trained on in-domain data \u2026"}, {"title": "Evaluating Large Language Models with fmeval", "link": "https://arxiv.org/pdf/2407.12872", "details": "P Schw\u00f6bel, L Franceschi, MB Zafar, K Vasist\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "fmeval is an open source library to evaluate large language models (LLMs) in a range of tasks. It helps practitioners evaluate their model for task performance and along multiple responsible AI dimensions. This paper presents the library and \u2026"}, {"title": "VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation", "link": "https://arxiv.org/pdf/2406.19276", "details": "Y Song, Y Kim, M Iyyer - arXiv preprint arXiv:2406.19276, 2024", "abstract": "Existing metrics for evaluating the factuality of long-form text, such as FACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input text into\" atomic claims\" and verify each against a knowledge base like Wikipedia. These metrics are \u2026"}, {"title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation", "link": "https://arxiv.org/pdf/2406.19371", "details": "CM Pham, S Sun, M Iyyer - arXiv preprint arXiv:2406.19371, 2024", "abstract": "Existing research on instruction following largely focuses on tasks with simple instructions and short responses. In this work, we explore multi-constraint instruction following for generating long-form text. We create Suri, a dataset with 20K human \u2026"}]
