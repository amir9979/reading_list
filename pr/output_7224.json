[{"title": "RAG-Modulo: Solving Sequential Tasks using Experience, Critics, and Language Models", "link": "https://arxiv.org/pdf/2409.12294", "details": "A Jain, C Jermaine, V Unhelkar - arXiv preprint arXiv:2409.12294, 2024", "abstract": "Large language models (LLMs) have recently emerged as promising tools for solving challenging robotic tasks, even in the presence of action and observation uncertainties. Recent LLM-based decision-making methods (also referred to as LLM \u2026"}, {"title": "Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data", "link": "https://arxiv.org/pdf/2409.12437", "details": "J Zhou, A Ghaddar, G Zhang, L Ma, Y Hu, S Pal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite recent advances in training and prompting strategies for Large Language Models (LLMs), these models continue to face challenges with complex logical reasoning tasks that involve long reasoning chains. In this work, we explore the \u2026"}, {"title": "Inference-Time Language Model Alignment via Integrated Value Guidance", "link": "https://arxiv.org/pdf/2409.17819", "details": "Z Liu, Z Zhou, Y Wang, C Yang, Y Qiao - arXiv preprint arXiv:2409.17819, 2024", "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce $\\textit {Integrated Value Guidance} $(IVG), a method that uses implicit and \u2026"}, {"title": "Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness", "link": "https://arxiv.org/pdf/2409.17791", "details": "J Li, H Huang, Y Zhang, P Xu, X Chen, R Song, L Shi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, there has been significant interest in replacing the reward model in Reinforcement Learning with Human Feedback (RLHF) methods for Large Language Models (LLMs), such as Direct Preference Optimization (DPO) and its \u2026"}, {"title": "SpecEval: Evaluating Code Comprehension in Large Language Models via Program Specifications", "link": "https://arxiv.org/pdf/2409.12866", "details": "L Ma, S Liu, L Bu, S Li, Y Wang, Y Liu - arXiv preprint arXiv:2409.12866, 2024", "abstract": "Large Language models have achieved impressive performance in automated software engineering. Extensive efforts have been made to evaluate the abilities of code LLMs in various aspects, with an increasing number of benchmarks and \u2026"}, {"title": "A Comprehensive Evaluation of Quantized Instruction-Tuned Large Language Models: An Experimental Analysis up to 405B", "link": "https://arxiv.org/pdf/2409.11055", "details": "J Lee, S Park, J Kwon, J Oh, Y Kwon - arXiv preprint arXiv:2409.11055, 2024", "abstract": "Prior research works have evaluated quantized LLMs using limited metrics such as perplexity or a few basic knowledge tasks and old datasets. Additionally, recent large- scale models such as Llama 3.1 with up to 405B have not been thoroughly \u2026"}, {"title": "Self-Evolutionary Large Language Models through Uncertainty-Enhanced Preference Optimization", "link": "https://arxiv.org/pdf/2409.11212", "details": "J Wang, Y Zhou, X Zhang, M Bao, P Yan - arXiv preprint arXiv:2409.11212, 2024", "abstract": "Iterative preference optimization has recently become one of the de-facto training paradigms for large language models (LLMs), but the performance is still underwhelming due to too much noisy preference data yielded in the loop. To \u2026"}, {"title": "Towards Data Contamination Detection for Modern Large Language Models: Limitations, Inconsistencies, and Oracle Challenges", "link": "https://arxiv.org/pdf/2409.09927", "details": "V Samuel, Y Zhou, HP Zou - arXiv preprint arXiv:2409.09927, 2024", "abstract": "As large language models achieve increasingly impressive results, questions arise about whether such performance is from generalizability or mere data memorization. Thus, numerous data contamination detection methods have been proposed \u2026"}, {"title": "Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models", "link": "https://arxiv.org/pdf/2409.06277", "details": "Y Shu, W Hu, SK Ng, BKH Low, FR Yu - arXiv preprint arXiv:2409.06277, 2024", "abstract": "Large Language Models (LLMs) have become indispensable in numerous real- world applications. Unfortunately, fine-tuning these models at scale, especially in federated settings where data privacy and communication efficiency are critical \u2026"}]
