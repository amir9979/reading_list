[{"title": "Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization", "link": "https://arxiv.org/pdf/2410.09302", "details": "G Liu, K Ji, R Zheng, Z Wu, C Dun, Q Gu, L Yan - arXiv preprint arXiv:2410.09302, 2024", "abstract": "Reinforcement Learning (RL) plays a crucial role in aligning large language models (LLMs) with human preferences and improving their ability to perform complex tasks. However, current approaches either require significant computational resources due \u2026"}, {"title": "Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?", "link": "https://arxiv.org/pdf/2410.23856", "details": "Z Zhou, R Tao, J Zhu, Y Luo, Z Wang, B Han - arXiv preprint arXiv:2410.23856, 2024", "abstract": "This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We \u2026"}, {"title": "MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation", "link": "https://arxiv.org/pdf/2410.12916", "details": "SK Gorti, I Gofman, Z Liu, J Wu, N Vouitsis, G Yu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Text-to-SQL generation enables non-experts to interact with databases via natural language. Recent advances rely on large closed-source models like GPT-4 that present challenges in accessibility, privacy, and latency. To address these issues, we \u2026"}, {"title": "Transformer-based Language Models for Reasoning in the Description Logic ALCQ", "link": "https://arxiv.org/pdf/2410.09613", "details": "A Poulis, E Tsalapati, M Koubarakis - arXiv preprint arXiv:2410.09613, 2024", "abstract": "Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order \u2026"}, {"title": "Measuring Human-AI Value Alignment in Large Language Models", "link": "https://ojs.aaai.org/index.php/AIES/article/download/31703/33870", "details": "H Norhashim, J Hahn - Proceedings of the AAAI/ACM Conference on AI, Ethics \u2026, 2024", "abstract": "This paper seeks to quantify the human-AI value alignment in large language models. Alignment between humans and AI has become a critical area of research to mitigate potential harm posed by AI. In tandem with this need, developers have \u2026"}, {"title": "Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning", "link": "https://arxiv.org/pdf/2410.19290", "details": "Y Liu, S Chang, T Jaakkola, Y Zhang - arXiv preprint arXiv:2410.19290, 2024", "abstract": "Recent studies have identified one aggravating factor of LLM hallucinations as the knowledge inconsistency between pre-training and fine-tuning, where unfamiliar fine- tuning data mislead the LLM to fabricate plausible but wrong outputs. In this paper \u2026"}, {"title": "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models", "link": "https://arxiv.org/pdf/2410.12011", "details": "K Tatariya, V Araujo, T Bauwens, M de Lhoneux - arXiv preprint arXiv:2410.12011, 2024", "abstract": "Pixel-based language models have emerged as a compelling alternative to subword- based language modelling, particularly because they can represent virtually any script. PIXEL, a canonical example of such a model, is a vision transformer that has \u2026"}, {"title": "TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles", "link": "https://arxiv.org/pdf/2410.05262", "details": "Q Yu, S Song, K Fang, Y Shi, Z Zheng, H Wang, S Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the application of Large Language Models (LLMs) expands, the demand for reliable evaluations increases. Existing LLM evaluation benchmarks primarily rely on static datasets, making it challenging to assess model performance in dynamic \u2026"}, {"title": "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "link": "https://arxiv.org/pdf/2410.20008", "details": "Z Zhao, Y Ziser, SB Cohen - arXiv preprint arXiv:2410.20008, 2024", "abstract": "Fine-tuning pre-trained large language models (LLMs) on a diverse array of tasks has become a common approach for building models that can solve various natural language processing (NLP) tasks. However, where and to what extent these models \u2026"}]
