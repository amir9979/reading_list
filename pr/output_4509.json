[{"title": "MLKD-BERT: Multi-level Knowledge Distillation for Pre-trained Language Models", "link": "https://arxiv.org/pdf/2407.02775", "details": "Y Zhang, Z Yang, S Ji - arXiv preprint arXiv:2407.02775, 2024", "abstract": "Knowledge distillation is an effective technique for pre-trained language model compression. Although existing knowledge distillation methods perform well for the most typical model BERT, they could be further improved in two aspects: the relation \u2026"}, {"title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application", "link": "https://arxiv.org/pdf/2407.01885", "details": "C Yang, W Lu, Y Zhu, Y Wang, Q Chen, C Gao, B Yan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in various domains, attracting significant interest from both academia and industry. Despite their impressive performance, the substantial size and computational demands of LLMs \u2026"}, {"title": "Heterogeneous-Graph Reasoning with Context Paraphrase for Commonsense Question Answering", "link": "https://ieeexplore.ieee.org/abstract/document/10612243/", "details": "Y Wang, H Zhang, J Liang, R Li - IEEE/ACM Transactions on Audio, Speech, and \u2026, 2024", "abstract": "Commonsense question answering (CQA) generally means that the machine uses its mastered commonsense to answer questions without relevant background material, which is a challenging task in natural language processing. Existing \u2026"}, {"title": "BFLN: A Blockchain-based Federated Learning Model for Non-IID Data", "link": "https://arxiv.org/pdf/2407.05276", "details": "Y Li, C Xia, D Huang, L Sun, T Wang - arXiv preprint arXiv:2407.05276, 2024", "abstract": "As the application of federated learning becomes increasingly widespread, the issue of imbalanced training data distribution has emerged as a significant challenge. Federated learning utilizes local data stored on different training clients for model \u2026"}, {"title": "TagOOD: A Novel Approach to Out-of-Distribution Detection via Vision-Language Representations and Class Center Learning", "link": "https://openreview.net/pdf%3Fid%3Ds9WLhE2c75", "details": "J Li, X Zhou, K Jiang, L Hong, P Guo, Z Chen, W Ge\u2026 - ACM Multimedia 2024", "abstract": "Multimodal fusion, leveraging data like vision and language, is rapidly gaining traction. This enriched data representation improves performance across various tasks. Existing methods for out-of-distribution (OOD) detection, a critical area where \u2026"}, {"title": "Large Language Models for Tabular Data: Progresses and Future Directions", "link": "https://dl.acm.org/doi/pdf/10.1145/3626772.3661384", "details": "H Dong, Z Wang - Proceedings of the 47th International ACM SIGIR \u2026, 2024", "abstract": "Tables contain a significant portion of the world's structured information. The ability to efficiently and accurately understand, process, reason about, analyze, and generate tabular data is critical for achieving Artificial General Intelligence (AGI) systems \u2026"}, {"title": "Causal-driven Large Language Models with Faithful Reasoning for Knowledge Question Answering", "link": "https://openreview.net/pdf%3Fid%3DcuWUx0RzgC", "details": "J Wang, D Cao, S Lu, Z Ma, J Xiao, TS Chua - ACM Multimedia 2024", "abstract": "In Large Language Models (LLMs), text generation that involves knowledge representation is often fraught with the risk of''hallucinations'', where models confidently produce erroneous or fabricated content. These inaccuracies often stem \u2026"}, {"title": "Advancing Faithfulness of Large Language Models in Goal-Oriented Dialogue Question Answering", "link": "https://dl.acm.org/doi/abs/10.1145/3640794.3665573", "details": "A Sticha, N Braunschweiler, RS Doddipatla, KM Knill - \u2026 of the 6th ACM Conference on \u2026, 2024", "abstract": "Goal-oriented dialogue systems, such as assistant chatbots and conversational AI systems, have gained prominence for their question-answering capabilities, often utilizing large language models (LLMs) as knowledge bases. However, these \u2026"}, {"title": "3D Question Answering with Scene Graph Reasoning", "link": "https://openreview.net/pdf%3Fid%3DqmyPQ3XbBZ", "details": "Z Wu, H Li, G Chen, Z Yu, X Gu, Y Wang - ACM Multimedia 2024", "abstract": "3DQA has gained considerable attention due to its enhanced spatial understanding capabilities compared to image-based VQA. However, existing 3DQA methods have explicitly focused on integrating text and color-coded point cloud features, thereby \u2026"}]
