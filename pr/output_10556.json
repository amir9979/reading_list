[{"title": "Why language models collapse when trained on recursively generated text", "link": "https://arxiv.org/pdf/2412.14872", "details": "L Wang, X Shi, G Li, J Li, Y Dong, X Zhang, W Jiao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) have been widely used to generate text on the Internet. The generated text is often collected into the training corpus of the next generations of LMs. Previous work has experimentally found that LMs collapse when trained on \u2026"}, {"title": "Assessing and Learning Alignment of Unimodal Vision and Language Models", "link": "https://arxiv.org/pdf/2412.04616", "details": "L Zhang, Q Yang, A Agrawal - arXiv preprint arXiv:2412.04616, 2024", "abstract": "How well are unimodal vision and language models aligned? Although prior work have approached answering this question, their assessment methods do not directly translate to how these models are used in practical vision-language tasks. In this \u2026"}, {"title": "ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?", "link": "https://arxiv.org/pdf/2412.02368", "details": "L Zhang, S Eger, Y Cheng, W Zhai, J Belouadi, C Leiter\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal large language models (LLMs) have demonstrated impressive capabilities in generating high-quality images from textual instructions. However, their performance in generating scientific images--a critical application for \u2026"}, {"title": "Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning", "link": "https://arxiv.org/pdf/2412.14780", "details": "Z Ye, Z Zhang, Y Zhang, J Ma, J Lin, F Feng - arXiv preprint arXiv:2412.14780, 2024", "abstract": "When using agent-task datasets to enhance agent capabilities for Large Language Models (LLMs), current methodologies often treat all tokens within a sample equally. However, we argue that tokens serving different roles-specifically, reasoning tokens \u2026"}, {"title": "Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over Aligned Large Language Models", "link": "https://arxiv.org/pdf/2412.12865", "details": "Y Fan, Y Hong, Q Wang, J Bao, H Jiang, Y Song - arXiv preprint arXiv:2412.12865, 2024", "abstract": "Alignment, endowing a pre-trained Large language model (LLM) with the ability to follow instructions, is crucial for its real-world applications. Conventional supervised fine-tuning (SFT) methods formalize it as causal language modeling typically with a \u2026"}, {"title": "GeoTool-GPT: a trainable method for facilitating Large Language Models to master GIS tools", "link": "https://www.tandfonline.com/doi/abs/10.1080/13658816.2024.2438937", "details": "C Wei, Y Zhang, X Zhao, Z Zeng, Z Wang, J Lin\u2026 - International Journal of \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) excel in natural language-relevant tasks like text generation and question answering Q&A. To further expand their application, efforts focus on enabling LLMs to utilize real-world tools. However, their tool-use \u2026"}, {"title": "Training Large Language Models to Reason in a Continuous Latent Space", "link": "https://arxiv.org/pdf/2412.06769%3F", "details": "S Hao, S Sukhbaatar, DJ Su, X Li, Z Hu, J Weston\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) are restricted to reason in the\" language space\", where they typically express the reasoning process with a chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue that language space may \u2026"}, {"title": "XTransplant: A Probe into the Upper Bound Performance of Multilingual Capability and Culture Adaptability in LLMs via Mutual Cross-lingual Feed-forward \u2026", "link": "https://arxiv.org/pdf/2412.12686", "details": "Y Ye, X Feng, X Feng, L Qin, Y Huang, L Huang, W Ma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Current large language models (LLMs) often exhibit imbalances in multilingual capabilities and cultural adaptability, largely due to their English-centric pretraining data. To address this imbalance, we propose a probing method named XTransplant \u2026"}, {"title": "Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models", "link": "https://arxiv.org/pdf/2412.08615", "details": "J Li, Y Hao, H Xu, X Wang, Y Hong - arXiv preprint arXiv:2412.08615, 2024", "abstract": "Despite the advancements in training Large Language Models (LLMs) with alignment techniques to enhance the safety of generated content, these models remain susceptible to jailbreak, an adversarial attack method that exposes security \u2026"}]
