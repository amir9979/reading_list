[{"title": "Understanding and Modeling Job Marketplace with Pretrained Language Models", "link": "https://arxiv.org/pdf/2408.04381", "details": "Y Zhu, L Wu, B Zhang, S Wang, Q Guo, L Hong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Job marketplace is a heterogeneous graph composed of interactions among members (job-seekers), companies, and jobs. Understanding and modeling job marketplace can benefit both job seekers and employers, ultimately contributing to \u2026"}, {"title": "Differentially Private and Heterogeneity-Robust Federated Learning with Theoretical Guarantee", "link": "https://ieeexplore.ieee.org/abstract/document/10643038/", "details": "X Wang, S Wang, Y Li, F Fan, S Li, X Lin - IEEE Transactions on Artificial Intelligence, 2024", "abstract": "Federated learning (FL) is a popular distributed paradigm where enormous clients collaboratively train a machine learning (ML) model under the orchestration of a central server without knowing the clients' private raw data. The development of \u2026"}, {"title": "Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank", "link": "https://arxiv.org/pdf/2407.19943", "details": "S Gupta, H Oosterhuis, M de Rijke - arXiv preprint arXiv:2407.19943, 2024", "abstract": "Counterfactual learning to rank (CLTR) can be risky; various circumstances can cause it to produce sub-optimal models that hurt performance when deployed. Safe CLTR was introduced to mitigate these risks when using inverse propensity scoring \u2026"}, {"title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "link": "https://arxiv.org/pdf/2408.02103", "details": "P Wang, X Wang, C Lou, S Mao, P Xie, Y Jiang - arXiv preprint arXiv:2408.02103, 2024", "abstract": "In-context learning (ICL) is a few-shot learning paradigm that involves learning mappings through input-output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language \u2026"}, {"title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models", "link": "https://arxiv.org/pdf/2408.02632", "details": "M Diao, R Li, S Liu, G Liao, J Wang, X Cai, W Xu - arXiv preprint arXiv:2408.02632, 2024", "abstract": "As large language models (LLMs) continue to advance in capability and influence, ensuring their security and preventing harmful outputs has become crucial. A promising approach to address these concerns involves training models to \u2026"}, {"title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework", "link": "https://arxiv.org/pdf/2408.02056", "details": "G Kumichev, P Blinov, Y Kuzkina, V Goncharov\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generating synthetic text addresses the challenge of data availability in privacy- sensitive domains such as healthcare. This study explores the applicability of synthetic data in real-world medical settings. We introduce MedSyn, a novel medical \u2026"}, {"title": "Progressively Selective Label Enhancement for Language Model Alignment", "link": "https://arxiv.org/pdf/2408.02599", "details": "B Liu, N Xu, X Geng - arXiv preprint arXiv:2408.02599, 2024", "abstract": "Large Language Models have demonstrated impressive capabilities in various language tasks but may produce content that misaligns with human expectations, raising ethical and legal concerns. Therefore, it is important to explore the limitations \u2026"}, {"title": "SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain", "link": "https://arxiv.org/pdf/2407.19584", "details": "P Colombo, T Pires, M Boudiaf, R Melo, D Culver\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper, we introduce SaulLM-54B and SaulLM-141B, two large language models (LLMs) tailored for the legal sector. These models, which feature architectures of 54 billion and 141 billion parameters, respectively, are based on the \u2026"}, {"title": "CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion", "link": "https://aclanthology.org/2024.findings-acl.679.pdf", "details": "Q Ren, C Gao, J Shao, J Yan, X Tan, W Lam, L Ma - Findings of the Association for \u2026, 2024", "abstract": "The rapid advancement of Large Language Models (LLMs) has brought about remarkable generative capabilities but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from \u2026"}]
