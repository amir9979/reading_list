[{"title": "RuleRAG: Rule-guided retrieval-augmented generation with language models for question answering", "link": "https://arxiv.org/pdf/2410.22353", "details": "Z Chen, C Xu, D Wang, Z Huang, Y Dou, J Guo - arXiv preprint arXiv:2410.22353, 2024", "abstract": "Retrieval-augmented generation (RAG) framework has shown promising potential in knowledge-intensive question answering (QA) by retrieving external corpus and generating based on augmented context. However, existing approaches only \u2026"}, {"title": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models", "link": "https://openreview.net/pdf%3Fid%3DHOLs697aIx", "details": "A Dutta, YC Hsiao - NeurIPS 2024 Workshop on Open-World Agents", "abstract": "We propose a novel in-context learning algorithm for building autonomous decision- making language agents. The language agent continuously attempts to solve the same task by reasoning, acting, observing and then self-correcting each time the task \u2026"}, {"title": "CLR-Bench: Evaluating Large Language Models in College-level Reasoning", "link": "https://arxiv.org/pdf/2410.17558", "details": "J Dong, Z Hong, Y Bei, F Huang, X Wang, X Huang - arXiv preprint arXiv:2410.17558, 2024", "abstract": "Large language models (LLMs) have demonstrated their remarkable performance across various language understanding tasks. While emerging benchmarks have been proposed to evaluate LLMs in various domains such as mathematics and \u2026"}, {"title": "Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models", "link": "https://arxiv.org/pdf/2410.20745", "details": "Y Jin, Z Li, C Zhang, T Cao, Y Gao, P Jayarao, M Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Online shopping is a complex multi-task, few-shot learning problem with a wide and evolving range of entities, relations, and tasks. However, existing models and benchmarks are commonly tailored to specific tasks, falling short of capturing the full \u2026"}, {"title": "SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models", "link": "https://arxiv.org/pdf/2410.19503", "details": "J Koo, Y Hwang, Y Kim, T Kang, H Bae, K Jung - arXiv preprint arXiv:2410.19503, 2024", "abstract": "Despite the success of Large Language Models (LLMs), they still face challenges related to high inference costs and memory requirements. To address these issues, Knowledge Distillation (KD) has emerged as a popular method for model \u2026"}, {"title": "Flaming-hot Initiation with Regular Execution Sampling for Large Language Models", "link": "https://arxiv.org/pdf/2410.21236", "details": "W Chen, Z Zhang, G Liu, R Zheng, W Shi, C Dun, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains. A key challenge in developing these general capabilities is efficiently sourcing diverse, high-quality data. This \u2026"}, {"title": "Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Generator-Validator Fine-tuning", "link": "https://arxiv.org/pdf/2410.12164", "details": "J Xing, Y He, M Zhou, H Dong, S Han, D Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this work, we propose Table-LLM-Specialist, or Table-Specialist for short, as a new self-trained fine-tuning paradigm specifically designed for table tasks. Our insight is that for each table task, there often exist two dual versions of the same task, one \u2026"}, {"title": "Aligning Large Language Models via Self-Steering Optimization", "link": "https://arxiv.org/pdf/2410.17131", "details": "H Xiang, B Yu, H Lin, K Lu, Y Lu, X Han, L Sun, J Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Automated alignment develops alignment systems with minimal human intervention. The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation. In this paper, we introduce \u2026"}, {"title": "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models", "link": "https://arxiv.org/pdf/2410.20008", "details": "Z Zhao, Y Ziser, SB Cohen - arXiv preprint arXiv:2410.20008, 2024", "abstract": "Fine-tuning pre-trained large language models (LLMs) on a diverse array of tasks has become a common approach for building models that can solve various natural language processing (NLP) tasks. However, where and to what extent these models \u2026"}]
