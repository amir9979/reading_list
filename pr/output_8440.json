[{"title": "Vascular endothelial growth factor/connective tissue growth factor and proteomic analysis of aqueous humor after intravitreal conbercept for proliferative diabetes \u2026", "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11422360/", "details": "HS Li, X Lyu, A Rong, YL Bi, W Xu, HP Cui - International Journal of Ophthalmology, 2024", "abstract": "AIM To investigate the role of connective tissue growth factor (CTGF) and vascular endothelial growth factor (VEGF) in the protein profile of the aqueous humor in patients with proliferative diabetic retinopathy (PDR) following intravitreal injection of \u2026"}, {"title": "On Instruction-Finetuning Neural Machine Translation Models", "link": "https://arxiv.org/pdf/2410.05553", "details": "V Raunak, R Grundkiewicz, M Junczys-Dowmunt - arXiv preprint arXiv:2410.05553, 2024", "abstract": "In this work, we introduce instruction finetuning for Neural Machine Translation (NMT) models, which distills instruction following capabilities from Large Language Models (LLMs) into orders-of-magnitude smaller NMT models. Our instruction \u2026"}, {"title": "Optimising Region of Interest Registration for Multiple-Tissue Whole Slide Images", "link": "https://link.springer.com/chapter/10.1007/978-3-031-73480-9_26", "details": "A Fiorin, L Adalid Llansa, E Goyda, V Della Mea\u2026 - International Workshop on \u2026, 2024", "abstract": "Digital pathology transforms clinical workflows by enabling the analysis of whole slide images (WSIs) on computers. While most methods focus on haematoxylin and eosin (H&E) stained WSIs, immunohistochemistry (IHC) is crucial for biomarker \u2026"}, {"title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models", "link": "https://arxiv.org/pdf/2410.05639", "details": "R Zhao, ZL Thai, Y Zhang, S Hu, Y Ba, J Zhou, J Cai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The performance of Large Language Models (LLMs) is substantially influenced by the pretraining corpus, which consists of vast quantities of unsupervised data processed by the models. Despite its critical role in model performance, ensuring the \u2026"}, {"title": "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "link": "https://arxiv.org/pdf/2410.05077", "details": "FM Molfese, S Conia, R Orlando, R Navigli - arXiv preprint arXiv:2410.05077, 2024", "abstract": "Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have \u2026"}]
