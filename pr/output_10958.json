[{"title": "Detecting Online Sexism: Integrating Sentiment Analysis with Contextual Language Models", "link": "https://www.mdpi.com/2673-2688/5/4/137", "details": "F Belbachir, T Roustan, A Soukane - AI, 2024", "abstract": "In the digital era, social media platforms have seen a substantial increase in the volume of online comments. While these platforms provide users with a space to express their opinions, they also serve as fertile ground for the proliferation of hate \u2026"}, {"title": "Unifying KV Cache Compression for Large Language Models with LeanKV", "link": "https://arxiv.org/pdf/2412.03131", "details": "Y Zhang, Y Hu, R Zhao, J Lui, H Chen - arXiv preprint arXiv:2412.03131, 2024", "abstract": "Large language models (LLMs) demonstrate exceptional performance but incur high serving costs due to substantial memory demands, with the key-value (KV) cache being a primary bottleneck. Existing KV cache compression methods, including \u2026"}, {"title": "C $^ 2$ LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation", "link": "https://arxiv.org/pdf/2412.04947", "details": "Y Li, TL Wong, CT Hung, J Zhao, D Zheng, KW Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in large language models (LLMs) have shown significant promise, yet their evaluation raises concerns, particularly regarding data contamination due to the lack of access to proprietary training data. To address this issue, we present C \u2026"}, {"title": "Prompting Large Language Models for Automatic Question Tagging", "link": "https://mi-research.net/article/doi/10.1007/s11633-024-1509-1", "details": "N Xu, D Xue, S Qian, Q Fang, J Hu - Machine Intelligence Research, 2025", "abstract": "Automatic question tagging (AQT) represents a crucial task in community question answering (CQA) websites. Its pivotal role lies in substantially augmenting user experience through the optimization of question-answering efficiency. Existing \u2026"}, {"title": "Composing Smart Data Services in Shop Floors Through Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-96-0808-9_21", "details": "JG Mathew, F Monti, D Firmani, F Leotta, F Mandreoli\u2026 - International Conference on \u2026, 2024", "abstract": "Recent years have witnessed an ever-growing use of Large Language Models (LLMs) to lower the technical barrier for several tasks, ranging from coding to querying relational databases to composing services. In this work, we focus on using \u2026"}, {"title": "Operating Conversational Large Language Models (LLMs) in the Presenceof Errors", "link": "https://ieeexplore.ieee.org/abstract/document/10812917/", "details": "Z Gao, J Deng, P Reviriego, S Liu, A Pozo, F Lombardi - IEEE Nanotechnology \u2026, 2024", "abstract": "Conversational Large Language Models have taken the center stage of the artificial intelligence landscape. As they are pervasive, there is a need to evaluate their dependability, ie, performance when errors appear due to the underlying hardware \u2026"}, {"title": "Structured Contexts For Large Language Models", "link": "https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-218.pdf", "details": "K Lin - 2024", "abstract": "Large language models (LLMs) are as capable as the context that they are given. Given a task, how well LLMs perform on it is determined by how the task is represented in the input context of the LLM and how well the LLM is trained to handle \u2026"}, {"title": "Stability Evaluation of Large Language Models via Distributional Perturbation Analysis", "link": "https://ljsthu.github.io/assets/neurips-workshop.pdf", "details": "J Liu, J Li, P Cui, J Blanchet", "abstract": "Abstract The performance of Large Language Models (LLMs) can degrade when exposed to shifts such as changes in language style or domain-specific knowledge that is underrepresented in the training data. To ensure robust deployment, we \u2026"}]
