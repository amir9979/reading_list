[{"title": "MaxCutPool: differentiable feature-aware Maxcut for pooling in graph neural networks", "link": "https://arxiv.org/pdf/2409.05100", "details": "C Abate, FM Bianchi - arXiv preprint arXiv:2409.05100, 2024", "abstract": "We propose a novel approach to compute the\\texttt {MAXCUT} in attributed graphs,\\textit {ie}, graphs with features associated with nodes and edges. Our approach is robust to the underlying graph topology and is fully differentiable \u2026"}, {"title": "Annealed Sinkhorn for Optimal Transport: convergence, regularization path and debiasing", "link": "https://arxiv.org/pdf/2408.11620", "details": "L Chizat - arXiv preprint arXiv:2408.11620, 2024", "abstract": "Sinkhorn's algorithm is a method of choice to solve large-scale optimal transport (OT) problems. In this context, it involves an inverse temperature parameter $\\beta $ that determines the speed-accuracy trade-off. To improve this trade-off, practitioners often \u2026"}, {"title": "Contrastive Learning with Transformer initialization and clustering prior for text representation", "link": "https://www.sciencedirect.com/science/article/pii/S1568494624009360", "details": "C Liu, X Chen, P Hu, J Lin, J Wang, X Geng - Applied Soft Computing, 2024", "abstract": "Acquiring labeled data for learning sentence embeddings in Natural Language Processing poses challenges due to limited availability and high costs. In order to tackle this issue, we introduce a novel method called Contrastive Learning with \u2026"}, {"title": "On the Convergence Analysis of Over-Parameterized Variational Autoencoders: A Neural Tangent Kernel Perspective", "link": "https://arxiv.org/pdf/2409.05349", "details": "L Wang, W Huang - arXiv preprint arXiv:2409.05349, 2024", "abstract": "Variational Auto-Encoders (VAEs) have emerged as powerful probabilistic models for generative tasks. However, their convergence properties have not been rigorously proven. The challenge of proving convergence is inherently difficult due to \u2026"}, {"title": "AFFECTIVEFUSIONNET: A MULTIMODAL EMOTION RECOGNITION USING COMBINATION OF VISUAL TRANSFORMERS AND VARIATIONAL AUTOENCODERS", "link": "https://researchportal.northumbria.ac.uk/files/169891361/ICMLC_AffectiveFusionNet_CameraReady.pdf", "details": "EK BABU, K MISTRY, N ANWAR, LI ZHANG", "abstract": "AffectiveFusionNet showcases a new era in multimodal emotion recognition, ingeniously integrating the strengths of Visual Transformers (ViTs) and Variational Autoencoders (VAEs) with the advanced principles of COGMEN and V2EM. This \u2026"}, {"title": "Reward-Directed Score-Based Diffusion Models via q-Learning", "link": "https://arxiv.org/pdf/2409.04832", "details": "X Gao, J Zha, XY Zhou - arXiv preprint arXiv:2409.04832, 2024", "abstract": "We propose a new reinforcement learning (RL) formulation for training continuous- time score-based diffusion models for generative AI to generate samples that maximize reward functions while keeping the generated distributions close to the \u2026"}]
