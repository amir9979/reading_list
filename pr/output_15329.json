[{"title": "How to Enhance Downstream Adversarial Robustness (almost) without Touching the Pre-Trained Foundation Model?", "link": "https://arxiv.org/pdf/2504.10850", "details": "M Liu, Z Huang, Y Xing - arXiv preprint arXiv:2504.10850, 2025", "abstract": "With the rise of powerful foundation models, a pre-training-fine-tuning paradigm becomes increasingly popular these days: A foundation model is pre-trained using a huge amount of data from various sources, and then the downstream users only \u2026"}, {"title": "Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations", "link": "https://arxiv.org/pdf/2504.10833", "details": "S Kumar, D Dalal, N Ahuja - arXiv preprint arXiv:2504.10833, 2025", "abstract": "Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a promising tool for generating semantic explanations of the decision-making processes in deep neural networks, having applications in both model improvement \u2026"}]
