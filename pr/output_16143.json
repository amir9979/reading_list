[{"title": "Exploring Grounding Abilities in Vision-Language Models through Contextual Perception", "link": "https://ieeexplore.ieee.org/iel8/7274989/7422051/10985830.pdf", "details": "W Xu, T Zhou, T Zhang, J Li, P Chen, J Pan, X Liu - IEEE Transactions on Cognitive \u2026, 2025", "abstract": "Vision language models (VLMs) have demonstrated strong general capabilities and achieved great success in areas such as image understanding and reasoning. Visual prompts enhance the focus of VLMs on designated areas, but their fine \u2026"}, {"title": "Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models", "link": "https://arxiv.org/pdf/2504.14395", "details": "B Jalaian, ND Bastian - arXiv preprint arXiv:2504.14395, 2025", "abstract": "To develop trustworthy Vision-Language Models (VLMs), it is essential to address adversarial robustness and hallucination mitigation, both of which impact factual accuracy in high-stakes applications such as defense and healthcare. Existing \u2026"}, {"title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models", "link": "https://arxiv.org/pdf/2504.14194", "details": "X Zhuang, J Peng, R Ma, Y Wang, T Bai, X Wei, J Qiu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality, a critical driver of model performance. Current data selection methods, such as natural \u2026"}, {"title": "Adversarial Robustness Analysis of Vision-Language Models in Medical Image Segmentation", "link": "https://arxiv.org/pdf/2505.02971", "details": "A Budathoki, M Dhakal - arXiv preprint arXiv:2505.02971, 2025", "abstract": "Adversarial attacks have been fairly explored for computer vision and vision- language models. However, the avenue of adversarial attack for the vision language segmentation models (VLSMs) is still under-explored, especially for medical image \u2026"}, {"title": "Exploring Multimodal Language Models for Sustainability Disclosure Extraction: A Comparative Study", "link": "https://aclanthology.org/2025.insights-1.13.pdf", "details": "T Gupta, T Goel, I Verma - The Sixth Workshop on Insights from Negative Results \u2026, 2025", "abstract": "Sustainability metrics have increasingly become a crucial non-financial criterion in investment decision-making. Organizations worldwide are recognizing the importance of sustainability and are proactively highlighting their efforts through \u2026"}, {"title": "Empirical Evaluation of Knowledge Distillation from Transformers to Subquadratic Language Models", "link": "https://arxiv.org/pdf/2504.14366", "details": "P Haller, J Golde, A Akbik - arXiv preprint arXiv:2504.14366, 2025", "abstract": "Knowledge distillation is a widely used technique for compressing large language models (LLMs) by training a smaller student model to mimic a larger teacher model. Typically, both the teacher and student are Transformer-based architectures \u2026"}, {"title": "CLONE: Synthetic Guideline-based Clinical Reasoning with Large Language Models for Early Diagnosis of Mild Cognitive Impairment", "link": "https://dl.acm.org/doi/abs/10.1145/3706599.3720111", "details": "S Cha, J Park, H Choi, H Ryu, K Seo - Proceedings of the Extended Abstracts of the \u2026, 2025", "abstract": "Early diagnosis of mild cognitive impairment (MCI) is essential to prevent its progression to Alzheimer's disease. Human expert-driven diagnosis provides interpretable rationales but is time-consuming, while machine learning-based \u2026"}, {"title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2504.07887", "details": "R Cantini, A Orsino, M Ruggiero, D Talia - arXiv preprint arXiv:2504.07887, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, driving advancements in machine translation, summarization, and conversational agents. However, their increasing integration into critical societal domains has raised \u2026"}, {"title": "The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer", "link": "https://arxiv.org/pdf/2504.10462", "details": "W Lei, J Wang, H Wang, X Li, JH Liew, J Feng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces SAIL, a single transformer unified multimodal large language model (MLLM) that integrates raw pixel encoding and language decoding within a singular architecture. Unlike existing modular MLLMs, which rely on a pre-trained \u2026"}]
