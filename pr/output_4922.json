[{"title": "Scaling Retrieval-Based Language Models with a Trillion-Token Datastore", "link": "https://arxiv.org/pdf/2407.12854", "details": "R Shao, J He, A Asai, W Shi, T Dettmers, S Min\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Scaling laws with respect to the amount of training data and the number of parameters allow us to predict the cost-benefit trade-offs of pretraining language models (LMs) in different configurations. In this paper, we consider another \u2026"}, {"title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer", "link": "https://arxiv.org/pdf/2408.01402", "details": "Y Yang, P Xu - arXiv preprint arXiv:2408.01402, 2024", "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in offline reinforcement learning (RL) tasks, leveraging pre-collected datasets and Transformer's capability to model long sequences. Recent works have demonstrated \u2026"}, {"title": "Strong Copyright Protection for Language Models via Adaptive Model Fusion", "link": "https://arxiv.org/pdf/2407.20105", "details": "J Abad, K Donhauser, F Pinto, F Yang - arXiv preprint arXiv:2407.20105, 2024", "abstract": "The risk of language models unintentionally reproducing copyrighted material from their training data has led to the development of various protective measures. In this paper, we propose model fusion as an effective solution to safeguard against \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}, {"title": "Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation", "link": "https://arxiv.org/pdf/2408.01363", "details": "JH Yang, J Lin - arXiv preprint arXiv:2408.01363, 2024", "abstract": "Vision--Language Models (VLMs) have demonstrated success across diverse applications, yet their potential to assist in relevance judgments remains uncertain. This paper assesses the relevance estimation capabilities of VLMs, including CLIP \u2026"}, {"title": "High-Throughput Phenotyping of Clinical Text Using Large Language Models", "link": "https://arxiv.org/pdf/2408.01214", "details": "DB Hier, SI Munzir, A Stahlfeld, T Obafemi-Ajayi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "High-throughput phenotyping automates the mapping of patient signs to standardized ontology concepts and is essential for precision medicine. This study evaluates the automation of phenotyping of clinical summaries from the Online \u2026"}, {"title": "Improving the quality of Persian clinical text with a novel spelling correction system", "link": "https://link.springer.com/article/10.1186/s12911-024-02613-0", "details": "SMS Dashti, SF Dashti - BMC Medical Informatics and Decision Making, 2024", "abstract": "Background The accuracy of spelling in Electronic Health Records (EHRs) is a critical factor for efficient clinical care, research, and ensuring patient safety. The Persian language, with its abundant vocabulary and complex characteristics, poses \u2026"}, {"title": "Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian", "link": "https://arxiv.org/pdf/2407.06011", "details": "TM Buonocore, S Rancati, E Parimbelli - arXiv preprint arXiv:2407.06011, 2024", "abstract": "The development of domain-specific language models has significantly advanced natural language processing applications in various specialized fields, particularly in biomedicine. However, the focus has largely been on English-language models \u2026"}, {"title": "Pseudo-triplet Guided Few-shot Composed Image Retrieval", "link": "https://arxiv.org/pdf/2407.06001", "details": "B Hou, H Lin, H Wen, M Liu, X Song - arXiv preprint arXiv:2407.06001, 2024", "abstract": "Composed Image Retrieval (CIR) is a challenging task that aims to retrieve the target image based on a multimodal query, ie, a reference image and its corresponding modification text. While previous supervised or zero-shot learning paradigms all fail \u2026"}]
