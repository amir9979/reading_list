[{"title": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models", "link": "https://arxiv.org/pdf/2503.18923", "details": "M Cao, P Hu, Y Wang, J Gu, H Tang, H Zhao, J Dong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we \u2026"}, {"title": "CoMP: Continual Multimodal Pre-training for Vision Foundation Models", "link": "https://arxiv.org/pdf/2503.18931", "details": "Y Chen, L Meng, W Peng, Z Wu, YG Jiang - arXiv preprint arXiv:2503.18931, 2025", "abstract": "Pre-trained Vision Foundation Models (VFMs) provide strong visual representations for a wide range of applications. In this paper, we continually pre-train prevailing VFMs in a multimodal manner such that they can effortlessly process visual inputs of \u2026"}, {"title": "Breaking the Encoder Barrier for Seamless Video-Language Understanding", "link": "https://arxiv.org/pdf/2503.18422", "details": "H Li, Y Zhang, L Guo, X Yue, J Liu - arXiv preprint arXiv:2503.18422, 2025", "abstract": "Most Video-Large Language Models (Video-LLMs) adopt an encoder-decoder framework, where a vision encoder extracts frame-wise features for processing by a language model. However, this approach incurs high computational costs \u2026"}, {"title": "SRG-Net: A Self-supervised 3D Scene Representation Method via Graph Contrastive Learning for Novel View Synthesis", "link": "https://www.jstage.jst.go.jp/article/transfun/advpub/0/advpub_2024EAL2091/_pdf", "details": "Q Qi, Z Liu, Y Guo - IEICE Transactions on Fundamentals of Electronics \u2026, 2025", "abstract": "SUMMARYAccurate scene representation holds practical significance for autonomous driving and virtual reality. This letter proposes a network to optimize images encoding and features learning for better scene representations \u2026"}, {"title": "Map: Evaluation and multi-agent enhancement of large language models for inpatient pathways", "link": "https://arxiv.org/pdf/2503.13205%3F", "details": "Z Chen, Z Peng, X Liang, C Wang, P Liang, L Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited \u2026"}, {"title": "Multimodal artificial intelligence approaches using large language models for expert\u2010level landslide image analysis", "link": "https://onlinelibrary.wiley.com/doi/pdf/10.1111/mice.13482", "details": "K Areerob, VQ Nguyen, X Li, S Inadomi, T Shimada\u2026 - Computer\u2010Aided Civil and \u2026, 2025", "abstract": "Climate change exacerbates natural disasters, demanding rapid damage and risk assessment. However, expert\u2010reliant analyses delay responses despite drone\u2010aided data collection. This study develops and compares multimodal AI approaches using \u2026"}, {"title": "May the Memory Be With You: Efficient and Infinitely Updatable State for Large Language Models", "link": "https://dl.acm.org/doi/pdf/10.1145/3721146.3721951", "details": "E Chukwu, L Bindschaedler - Proceedings of the 5th Workshop on Machine Learning \u2026, 2025", "abstract": "Large language models (LLMs) excel at natural language tasks but lack persistent state management for personalized and adaptive interactions. We propose a framework that endows these models with stateful capabilities by combining retrieval \u2026"}, {"title": "ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection", "link": "https://arxiv.org/pdf/2504.00695", "details": "X Zhu, Z Gu, S Zheng, T Wang, T Li, H Feng, Y Xiao - arXiv preprint arXiv:2504.00695, 2025", "abstract": "Pre-training large language models (LLMs) necessitates enormous diverse textual corpora, making effective data selection a key challenge for balancing computational resources and model performance. Current methodologies primarily emphasize data \u2026"}, {"title": "SWAN-GPT: An Efficient and Scalable Approach for Long-Context Language Modeling", "link": "https://arxiv.org/pdf/2504.08719", "details": "KC Puvvada, F Ladhak, SA Serrano, CP Hsieh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present a decoder-only Transformer architecture that robustly generalizes to sequence lengths substantially longer than those seen during training. Our model, SWAN-GPT, interleaves layers without positional encodings (NoPE) and sliding \u2026"}]
