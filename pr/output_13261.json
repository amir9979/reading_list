[{"title": "Learning with Enriched Inductive Biases for Vision-Language Models", "link": "https://ruyuanzhang.github.io/files/2501_indctbiasVisLangModel_IJCV.pdf", "details": "L Yang, RY Zhang, Q Chen, X Xie - International Journal of Computer Vision, 2025", "abstract": "Abstract Vision-Language Models, pre-trained on large-scale image-text pairs, serve as strong foundation models for transfer learning across a variety of downstream tasks. For few-shot generalization tasks, ie., when the model is trained on few-shot \u2026"}, {"title": "Distilling foundation models for robust and efficient models in digital pathology", "link": "https://arxiv.org/pdf/2501.16239%3F", "details": "A Filiot, N Dop, O Tchita, A Riou, R Dubois, T Peeters\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In recent years, the advent of foundation models (FM) for digital pathology has relied heavily on scaling the pre-training datasets and the model size, yielding large and powerful models. While it resulted in improving the performance on diverse \u2026"}, {"title": "Optimizing Singular Spectrum for Large Language Model Compression", "link": "https://arxiv.org/pdf/2502.15092", "details": "D Li, T Shen, Y Zhou, B Yang, Z Liu, M Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, yet prohibitive parameter complexity often hinders their deployment. Existing singular value decomposition (SVD) based compression methods simply deem singular \u2026"}, {"title": "MCG-Net: Medical Chief Complaint-guided Multi-modal Masked Content Pre-training for chest image classification", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002829", "details": "L Zou, J Li, H Chen, M Liang, J Ke, Y Zhong, J Chen - Expert Systems with \u2026, 2025", "abstract": "Medical image classification plays a crucial role in disease diagnosis, personalized treatment, and clinical decision-making, with significant progress driven by deep learning (DL). However, DL's performance heavily relies on large-scale, accurately \u2026"}]
