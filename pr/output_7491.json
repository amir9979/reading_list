[{"title": "Unraveling Cross-Modality Knowledge Conflict in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.03659", "details": "T Zhu, Q Liu, F Wang, Z Tu, M Chen - arXiv preprint arXiv:2410.03659, 2024", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities for capturing and reasoning over multimodal inputs. However, these models are prone to parametric knowledge conflicts, which arise from inconsistencies of \u2026"}, {"title": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models", "link": "https://arxiv.org/pdf/2409.19375", "details": "Z Han, J Yang, J Li, Q Hu, Q Xu, MZ Shou, C Zhang - arXiv preprint arXiv:2409.19375, 2024", "abstract": "Vision-language foundation models (eg, CLIP) have shown remarkable performance across a wide range of tasks. However, deploying these models may be unreliable when significant distribution gaps exist between the training and test data. The \u2026"}, {"title": "VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks", "link": "https://arxiv.org/pdf/2410.05160", "details": "Z Jiang, R Meng, X Yang, S Yavuz, Y Zhou, W Chen - arXiv preprint arXiv:2410.05160, 2024", "abstract": "Embedding models have been crucial in enabling various downstream tasks such as semantic similarity, information retrieval, and clustering. Recently, there has been a surge of interest in developing universal text embedding models that can generalize \u2026"}, {"title": "KalmanHD: Robust On-Device Time Series Forecasting with Hyperdimensional Computing", "link": "https://repositorio.cetys.mx/handle/60000/1845", "details": "I Gomez Moreno, X Yu, T Rosing - 2024", "abstract": "Time series forecasting is shifting towards Edge AI, where models are trained and executed on edge devices instead of in the cloud. However, training forecasting models at the edge faces two challenges concurrently:(1) dealing with streaming \u2026"}, {"title": "Patch-Based Contrastive Learning and Memory Consolidation for Online Unsupervised Continual Learning", "link": "https://arxiv.org/pdf/2409.16391", "details": "C Taylor, V Vassiliades, C Dovrolis - arXiv preprint arXiv:2409.16391, 2024", "abstract": "We focus on a relatively unexplored learning paradigm known as {\\em Online Unsupervised Continual Learning}(O-UCL), where an agent receives a non- stationary, unlabeled data stream and progressively learns to identify an increasing \u2026"}, {"title": "Clinical-grade Multi-Organ Pathology Report Generation for Multi-scale Whole Slide Images via a Semantically Guided Medical Text Foundation Model", "link": "https://arxiv.org/pdf/2409.15574", "details": "JW Tan, SK Kim, E Kim, SH Lee, S Ahn, WK Jeong - arXiv preprint arXiv:2409.15574, 2024", "abstract": "Vision language models (VLM) have achieved success in both natural language comprehension and image recognition tasks. However, their use in pathology report generation for whole slide images (WSIs) is still limited due to the huge size of multi \u2026"}, {"title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe", "link": "https://arxiv.org/pdf/2410.05248", "details": "Y Xiao, S Zhang, W Zhou, M Ghassemi, S Zhao - arXiv preprint arXiv:2410.05248, 2024", "abstract": "To induce desired behaviors in large language models (LLMs) for interaction-driven tasks, the instruction-tuning stage typically trains LLMs on instruction-response pairs using the next-token prediction (NTP) loss. Previous work aiming to improve \u2026"}, {"title": "Leveraging Coarse-to-Fine Grained Representations in Contrastive Learning for Differential Medical Visual Question Answering", "link": "https://papers.miccai.org/miccai-2024/paper/1957_paper.pdf", "details": "X Liang, Y Wang, D Wang, Z Jiao, H Zhong, M Yang\u2026 - International Conference on \u2026, 2024", "abstract": "Abstract Chest X-ray Differential Medical Visual Question Answering (Diff-MedVQA) is a novel multi-modal task designed to answer questions about diseases, especially their differences, based on a main image and a reference image. Compared to the \u2026"}, {"title": "From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings", "link": "https://arxiv.org/pdf/2410.04133", "details": "J Li, A Aguirre, J Moura, C Liu, L Zhong, C Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Artificial Intelligence (AI) has shown great promise in electrocardiogram (ECG) analysis and cardiovascular disease detection. However, developing a general AI- ECG model has been challenging due to inter-individual variability and the diversity \u2026"}]
