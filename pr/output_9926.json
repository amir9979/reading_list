[{"title": "Free $^ 2$ Guide: Gradient-Free Path Integral Control for Enhancing Text-to-Video Generation with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2411.17041", "details": "J Kim, BS Kim, JC Ye - arXiv preprint arXiv:2411.17041, 2024", "abstract": "Diffusion models have achieved impressive results in generative tasks like text-to- image (T2I) and text-to-video (T2V) synthesis. However, achieving accurate text alignment in T2V generation remains challenging due to the complex temporal \u2026"}, {"title": "VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge", "link": "https://arxiv.org/pdf/2411.12915", "details": "V Nath, W Li, D Yang, A Myronenko, M Zheng, Y Lu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generalist vision language models (VLMs) have made significant strides in computer vision, but they fall short in specialized fields like healthcare, where expert knowledge is essential. In traditional computer vision tasks, creative or approximate \u2026"}, {"title": "GEOBench-VLM: Benchmarking Vision-Language Models for Geospatial Tasks", "link": "https://arxiv.org/pdf/2411.19325", "details": "MS Danish, MA Munir, SRA Shah, K Kuckreja, FS Khan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While numerous recent benchmarks focus on evaluating generic Vision-Language Models (VLMs), they fall short in addressing the unique demands of geospatial applications. Generic VLM benchmarks are not designed to handle the complexities \u2026"}, {"title": "Evaluating Vision-Language Models as Evaluators in Path Planning", "link": "https://arxiv.org/pdf/2411.18711", "details": "M Aghzal, X Yue, E Plaku, Z Yao - arXiv preprint arXiv:2411.18711, 2024", "abstract": "Despite their promise to perform complex reasoning, large language models (LLMs) have been shown to have limited effectiveness in end-to-end planning. This has inspired an intriguing question: if these models cannot plan well, can they still \u2026"}, {"title": "Devils in Middle Layers of Large Vision-Language Models: Interpreting, Detecting and Mitigating Object Hallucinations via Attention Lens", "link": "https://arxiv.org/pdf/2411.16724", "details": "Z Jiang, J Chen, B Zhu, T Luo, Y Shen, X Yang - arXiv preprint arXiv:2411.16724, 2024", "abstract": "Hallucinations in Large Vision-Language Models (LVLMs) significantly undermine their reliability, motivating researchers to explore the causes of hallucination. However, most studies primarily focus on the language aspect rather than the visual \u2026"}, {"title": "Adversarial Prompt Distillation for Vision-Language Models", "link": "https://arxiv.org/pdf/2411.15244", "details": "L Luo, X Wang, B Zi, S Zhao, X Ma - arXiv preprint arXiv:2411.15244, 2024", "abstract": "Large pre-trained Vision-Language Models (VLMs) such as Contrastive Language- Image Pre-Training (CLIP) have been shown to be susceptible to adversarial attacks, raising concerns about their deployment in safety-critical scenarios like autonomous \u2026"}, {"title": "From language models over tokens to language models over characters", "link": "https://arxiv.org/pdf/2412.03719", "details": "T Vieira, B LeBrun, M Giulianelli, JL Gastaldi, B DuSell\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models are internally--and mathematically--distributions over token strings rather than\\emph {character} strings, posing numerous challenges for programmers building user applications on top of them. For example, if a prompt is \u2026"}, {"title": "Spider 2.0: Evaluating language models on real-world enterprise text-to-sql workflows", "link": "https://arxiv.org/pdf/2411.07763", "details": "F Lei, J Chen, Y Ye, R Cao, D Shin, H Su, Z Suo, H Gao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Real-world enterprise text-to-SQL workflows often involve complex cloud or local data across various database systems, multiple SQL queries in various dialects, and diverse operations from data transformation to analytics. We introduce Spider 2.0, an \u2026"}, {"title": "Incorporating Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3D1fpjV6xQ6Q", "details": "C Zhang, Z Wan, Z Kan, MQ Ma, S Stepputtis\u2026 - Workshop on Responsibly \u2026", "abstract": "While recent Large Vision-Language Models (LVLMs) have shown remarkable performance in multi-modal tasks, they are prone to generating hallucinatory text responses that do not align with the given visual input, which restricts their practical \u2026"}]
