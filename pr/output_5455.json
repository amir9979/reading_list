[{"title": "EZSR: Event-based Zero-Shot Recognition", "link": "https://arxiv.org/pdf/2407.21616", "details": "Y Yang, L Pan, D Li, L Liu - arXiv preprint arXiv:2407.21616, 2024", "abstract": "This paper studies zero-shot object recognition using event camera data. Guided by CLIP, which is pre-trained on RGB images, existing approaches achieve zero-shot object recognition by maximizing embedding similarities between event data \u2026"}, {"title": "Learning Adaptive Parameter Representation for Event-based Video Reconstruction", "link": "https://ieeexplore.ieee.org/abstract/document/10609501/", "details": "D Gu, J Li, L Zhu - IEEE Signal Processing Letters, 2024", "abstract": "Event-based video reconstruction aims to generate images from asynchronous event streams, which record the intensity changes exceeding specific contrast thresholds. However, the contrast thresholds are varied among pixels with manufacturing \u2026"}, {"title": "SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training", "link": "https://arxiv.org/pdf/2408.08295", "details": "G Zhang, L Wang, G Kang, L Chen, Y Wei - arXiv preprint arXiv:2408.08295, 2024", "abstract": "In recent years, continual learning with pre-training (CLPT) has received widespread interest, instead of its traditional focus of training from scratch. The use of strong pre- trained models (PTMs) can greatly facilitate knowledge transfer and alleviate \u2026"}, {"title": "IgnitionInnovators at\" Discharge Me!\": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries", "link": "https://arxiv.org/pdf/2407.17636", "details": "AQ Tang, X Zhang, MN Dinh - arXiv preprint arXiv:2407.17636, 2024", "abstract": "This paper presents our proposed approach to the Discharge Me! shared task, collocated with the 23th Workshop on Biomedical Natural Language Processing (BioNLP). In this work, we develop an LLM-based framework for solving the \u2026"}, {"title": "Rescue: Ranking llm responses with partial ordering to improve response generation", "link": "https://aclanthology.org/2024.acl-srw.32.pdf", "details": "Y Wang, R Zheng, H Li, Q Zhang, T Gui, F Liu - \u2026 of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Customizing LLMs for a specific task involves separating high-quality responses from lower-quality ones. This skill can be developed using supervised fine-tuning with extensive human preference data. However, obtaining a large volume of expert \u2026"}]
