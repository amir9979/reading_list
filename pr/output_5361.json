[{"title": "Language models as models of language", "link": "https://arxiv.org/pdf/2408.07144", "details": "R Milli\u00e8re - arXiv preprint arXiv:2408.07144, 2024", "abstract": "This chapter critically examines the potential contributions of modern language models to theoretical linguistics. Despite their focus on engineering goals, these models' ability to acquire sophisticated linguistic knowledge from mere exposure to \u2026"}, {"title": "T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step", "link": "https://aclanthology.org/2024.acl-long.515.pdf", "details": "Z Chen, W Du, W Zhang, K Liu, J Liu, M Zheng, J Zhuo\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Large language models (LLMs) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool utilization capability of LLMs is still under-explored. In contrast \u2026"}, {"title": "InstructCoder: Instruction Tuning Large Language Models for Code Editing", "link": "https://aclanthology.org/2024.acl-srw.6.pdf", "details": "K Li, Q Hu, J Zhao, H Chen, Y Xie, T Liu, M Shieh, J He - Proceedings of the 62nd \u2026, 2024", "abstract": "Code editing encompasses a variety of pragmatic tasks that developers deal with daily. Despite its relevance and practical usefulness, automatic code editing remains an underexplored area in the evolution of deep learning models, partly due to data \u2026"}, {"title": "RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models", "link": "https://aclanthology.org/2024.acl-long.140.pdf", "details": "J Wang, J Wu, M Chen, Y Vorobeychik, C Xiao - \u2026 of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Abstract Reinforcement Learning with Human Feedback (RLHF) is a methodology designed to align Large Language Models (LLMs) with human preferences, playing an important role in LLMs alignment. Despite its advantages, RLHF relies on human \u2026"}, {"title": "Large Language Models Prompting With Episodic Memory", "link": "https://arxiv.org/pdf/2408.07465", "details": "D Do, Q Tran, S Venkatesh, H Le - arXiv preprint arXiv:2408.07465, 2024", "abstract": "Prompt optimization is essential for enhancing the performance of Large Language Models (LLMs) in a range of Natural Language Processing (NLP) tasks, particularly in scenarios of few-shot learning where training examples are incorporated directly \u2026"}, {"title": "KoCommonGEN v2: A Benchmark for Navigating Korean Commonsense Reasoning Challenges in Large Language Models", "link": "https://aclanthology.org/2024.findings-acl.141.pdf", "details": "J Seo, J Lee, C Park, ST Hong, S Lee, HS Lim - Findings of the Association for \u2026, 2024", "abstract": "The evolution of large language models (LLMs) has culminated in a multitask model paradigm where prompts drive the generation of user-specific outputs. However, this advancement has revealed a critical challenge: LLMs frequently produce outputs \u2026"}, {"title": "Relation labeling in product knowledge graphs with large language models for e-commerce", "link": "https://link.springer.com/article/10.1007/s13042-024-02274-5", "details": "J Chen, L Ma, X Li, J Xu, JHD Cho, K Nag, E Korpeoglu\u2026 - International Journal of \u2026, 2024", "abstract": "Abstract Product Knowledge Graphs (PKGs) play a crucial role in enhancing e- commerce system performance by providing structured information about entities and their relationships, such as complementary or substitutable relations between \u2026"}, {"title": "Mitigating Privacy Seesaw in Large Language Models: Augmented Privacy Neuron Editing via Activation Patching", "link": "https://aclanthology.org/2024.findings-acl.315.pdf", "details": "X Wu, W Dong, S Xu, D Xiong - Findings of the Association for Computational \u2026, 2024", "abstract": "Protecting privacy leakage in large language models remains a paramount challenge. In this paper, we reveal Privacy Seesaw in LLM privacy safeguarding, a phenomenon where measures to secure specific private information inadvertently \u2026"}, {"title": "IAPT: Instance-Aware Prompt Tuning for Large Language Models", "link": "https://aclanthology.org/2024.acl-long.771.pdf", "details": "W Zhu, A Tian, C Yin, Y Ni, X Wang, G Xie - Proceedings of the 62nd Annual Meeting \u2026, 2024", "abstract": "Soft prompt tuning is a widely studied parameter-efficient fine-tuning method. However, it has a clear drawback: many soft tokens must be inserted into the input sequences to guarantee downstream performance. As a result, soft prompt tuning is \u2026"}]
