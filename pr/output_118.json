'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Anatomical Structure-Guided Medical Vision-Language Pr'
[{"title": "Counterfactual contrastive learning: robust representations via causal image synthesis", "link": "https://arxiv.org/pdf/2403.09605", "details": "M Roschewitz, FDS Ribeiro, T Xia, G Khara, B Glocker - arXiv preprint arXiv \u2026, 2024", "abstract": "Contrastive pretraining is well-known to improve downstream task performance and model generalisation, especially in limited label settings. However, it is sensitive to the choice of augmentation pipeline. Positive pairs should preserve semantic \u2026"}, {"title": "ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding", "link": "https://arxiv.org/pdf/2402.11889", "details": "Q Zhong, L Ding, J Liu, B Du, D Tao - arXiv preprint arXiv:2402.11889, 2024", "abstract": "With the development of instruction-tuned large language models (LLMs), improving the safety of LLMs has become more critical. However, the current approaches for aligning the LLMs output with expected safety usually require substantial training \u2026"}, {"title": "Transformer-based Causal Language Models Perform Clustering", "link": "https://arxiv.org/pdf/2402.12151", "details": "X Wu, LR Varshney - arXiv preprint arXiv:2402.12151, 2024", "abstract": "Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still a concern. Recent works have shown great improvements \u2026"}, {"title": "CARZero: Cross-Attention Alignment for Radiology Zero-Shot Classification", "link": "https://arxiv.org/pdf/2402.17417", "details": "H Lai, Q Yao, Z Jiang, R Wang, Z He, X Tao, SK Zhou - arXiv preprint arXiv \u2026, 2024", "abstract": "The advancement of Zero-Shot Learning in the medical domain has been driven forward by using pre-trained models on large-scale image-text pairs, focusing on image-text alignment. However, existing methods primarily rely on cosine similarity \u2026"}, {"title": "Retrieval augmented text-to-SQL generation for epidemiological question answering using electronic health records", "link": "https://arxiv.org/pdf/2403.09226", "details": "A Ziletti, L D'Ambrosi - arXiv preprint arXiv:2403.09226, 2024", "abstract": "Electronic health records (EHR) and claims data are rich sources of real-world data that reflect patient health status and healthcare utilization. Querying these databases to answer epidemiological questions is challenging due to the intricacy of medical \u2026"}, {"title": "Evaluation of Effectiveness of Self-Supervised Learning in Chest X-Ray Imaging to Reduce Annotated Images", "link": "https://link.springer.com/article/10.1007/s10278-024-00975-5", "details": "K Imagawa, K Shiomoto - Journal of Imaging Informatics in Medicine, 2024", "abstract": "A significant challenge in machine learning-based medical image analysis is the scarcity of medical images. Obtaining a large number of labeled medical images is difficult because annotating medical images is a time-consuming process that \u2026"}]
