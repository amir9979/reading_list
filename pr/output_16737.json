[{"title": "KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance", "link": "https://arxiv.org/pdf/2505.15480", "details": "Q Zhong, L Ding, X Cai, J Liu, B Du, D Tao - arXiv preprint arXiv:2505.15480, 2025", "abstract": "\u2026 Supervised fine-tuning (SFT) is a common approach to improve the domain-specific **question** - **answering** (QA) performance of **large** **language** **models** (LLMs). However, recent literature reveals that due to the conflicts between LLMs\u2019 internal knowledge \u2026", "entry_id": "http://arxiv.org/abs/2505.15480v1", "updated": "2025-05-21 12:55:28", "published": "2025-05-21 12:55:28", "authors": "Qihuang Zhong;Liang Ding;Xiantao Cai;Juhua Liu;Bo Du;Dacheng Tao", "summary": "Supervised fine-tuning (SFT) is a common approach to improve the\ndomain-specific question-answering (QA) performance of large language models\n(LLMs). However, recent literature reveals that due to the conflicts between\nLLMs' internal knowledge and the context knowledge of training data, vanilla\nSFT using the full QA training set is usually suboptimal. In this paper, we\nfirst design a query diversification strategy for robust conflict detection and\nthen conduct a series of experiments to analyze the impact of knowledge\nconflict. We find that 1) training samples with varied conflicts contribute\ndifferently, where SFT on the data with large conflicts leads to catastrophic\nperformance drops; 2) compared to directly filtering out the conflict data,\nappropriately applying the conflict data would be more beneficial. Motivated by\nthis, we propose a simple-yet-effective Knowledge-aware Fine-tuning (namely\nKaFT) approach to effectively boost LLMs' performance. The core of KaFT is to\nadapt the training weight by assigning different rewards for different training\nsamples according to conflict level. Extensive experiments show that KaFT\nbrings consistent and significant improvements across four LLMs. More analyses\nprove that KaFT effectively improves the model generalization and alleviates\nthe hallucination.", "comment": "Accepted to ACL2025 Findings", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.15480v1;http://arxiv.org/pdf/2505.15480v1", "pdf_url": "http://arxiv.org/pdf/2505.15480v1"}, {"title": "MedBrowseComp: Benchmarking Medical Deep Research and Computer Use", "link": "https://arxiv.org/pdf/2505.14963", "details": "S Chen, P Moreira, Y Xiao, S Schmidgall, J Warner\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 **Large** **language** **models** (LLMs) are increasingly envisioned as decision-support tools in **clinical** practice, yet safe **clinical** reasoning demands the integration of \u2026 We hope it will accelerate progress toward efficient, high-accuracy **medical** **question** \u2026", "entry_id": "http://arxiv.org/abs/2505.14963v1", "updated": "2025-05-20 22:42:33", "published": "2025-05-20 22:42:33", "authors": "Shan Chen;Pedro Moreira;Yuxin Xiao;Sam Schmidgall;Jeremy Warner;Hugo Aerts;Thomas Hartvigsen;Jack Gallifant;Danielle S. Bitterman", "summary": "Large language models (LLMs) are increasingly envisioned as decision-support\ntools in clinical practice, yet safe clinical reasoning demands integrating\nheterogeneous knowledge bases -- trials, primary studies, regulatory documents,\nand cost data -- under strict accuracy constraints. Existing evaluations often\nrely on synthetic prompts, reduce the task to single-hop factoid queries, or\nconflate reasoning with open-ended generation, leaving their real-world utility\nunclear. To close this gap, we present MedBrowseComp, the first benchmark that\nsystematically tests an agent's ability to reliably retrieve and synthesize\nmulti-hop medical facts from live, domain-specific knowledge bases.\nMedBrowseComp contains more than 1,000 human-curated questions that mirror\nclinical scenarios where practitioners must reconcile fragmented or conflicting\ninformation to reach an up-to-date conclusion. Applying MedBrowseComp to\nfrontier agentic systems reveals performance shortfalls as low as ten percent,\nexposing a critical gap between current LLM capabilities and the rigor demanded\nin clinical settings. MedBrowseComp therefore offers a clear testbed for\nreliable medical information seeking and sets concrete goals for future model\nand toolchain upgrades. You can visit our project page at:\nhttps://moreirap12.github.io/mbc-browse-app/", "comment": "You can visit our project page at:\n  https://moreirap12.github.io/mbc-browse-app/", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.14963v1;http://arxiv.org/pdf/2505.14963v1", "pdf_url": "http://arxiv.org/pdf/2505.14963v1"}, {"title": "Comparative Analysis Study on Automated Dataset Generation Frameworks for RAG System Performance Evaluation", "link": "https://koreascience.kr/article/JAKO202514154005683.pdf", "details": "B Kim, J Yang - The Journal of Korea Institute of Information \u2026, 2025", "abstract": "\u2026 It explains the necessity and importance of RAG technology in overcoming the limitations of **large** **language** **models** (LLMs) and \u2026 were selected, and for each, 100 **question** \u2013 **answer** pairs were generated using documents from the **medical** , financial \u2026"}, {"title": "Nested Named Entity Recognition: A Survey of Latest Research", "link": "https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.70052", "details": "L Ji, Y Dang, Y Du, W Gao, H Zhang - Expert Systems, 2025", "abstract": "\u2026 As a key technology in NLP, NER lays the foundation for information extraction, knowledge **question** **answering** system, text summary, knowledge \u2026 However, a common observation is that many **large** **language** **models** perform below baseline \u2026"}]
