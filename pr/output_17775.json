[{"title": "Conformal Prediction for Zero-Shot Models", "link": "https://openaccess.thecvf.com/content/CVPR2025/papers/Silva-Rodriguez_Conformal_Prediction_for_Zero-Shot_Models_CVPR_2025_paper.pdf", "details": "J Silva-Rodr\u00edguez, I Ben Ayed, J Dolz - Proceedings of the Computer Vision and \u2026, 2025", "abstract": "Vision-language models pre-trained at large scale have shown unprecedented adaptability and generalization to downstream tasks. Although its discriminative potential has been widely explored, its reliability and uncertainty are still overlooked \u2026"}, {"title": "Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning", "link": "https://link.springer.com/chapter/10.1007/978-981-96-8295-9_12", "details": "K Obata, T Murayama, Z Chen, Y Matsubara, Y Sakurai - Pacific-Asia Conference on \u2026, 2025", "abstract": "Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities \u2026"}, {"title": "MTAD-Kanformer: multivariate time-series anomaly detection via kan and transformer", "link": "https://link.springer.com/article/10.1007/s10489-025-06650-8", "details": "X Xie, W Zheng, S Xiong, T Wan - Applied Intelligence, 2025", "abstract": "In numerous real-world IoT systems, sensing devices produce vast volumes of multivariate time series data. These infrastructures frequently become targets for cyber-attacks, underscoring the critical importance of anomaly detection in \u2026"}, {"title": "Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models", "link": "https://arxiv.org/pdf/2506.00457", "details": "J Park, H Lee, D Lee, D Gwak, J Choo - arXiv preprint arXiv:2506.00457, 2025", "abstract": "Large Language Models (LLMs) have shown remarkable performance across diverse tasks without domain-specific training, fueling interest in their potential for time-series forecasting. While LLMs have shown potential in zero-shot forecasting \u2026", "entry_id": "http://arxiv.org/abs/2506.00457v1", "updated": "2025-05-31 08:24:01", "published": "2025-05-31 08:24:01", "authors": "Junwoo Park;Hyuck Lee;Dohyun Lee;Daehoon Gwak;Jaegul Choo", "summary": "Large Language Models (LLMs) have shown remarkable performance across diverse\ntasks without domain-specific training, fueling interest in their potential for\ntime-series forecasting. While LLMs have shown potential in zero-shot\nforecasting through prompting alone, recent studies suggest that LLMs lack\ninherent effectiveness in forecasting. Given these conflicting findings, a\nrigorous validation is essential for drawing reliable conclusions. In this\npaper, we evaluate the effectiveness of LLMs as zero-shot forecasters compared\nto state-of-the-art domain-specific models. Our experiments show that LLM-based\nzero-shot forecasters often struggle to achieve high accuracy due to their\nsensitivity to noise, underperforming even simple domain-specific models. We\nhave explored solutions to reduce LLMs' sensitivity to noise in the zero-shot\nsetting, but improving their robustness remains a significant challenge. Our\nfindings suggest that rather than emphasizing zero-shot forecasting, a more\npromising direction would be to focus on fine-tuning LLMs to better process\nnumerical sequences. Our experimental code is available at\nhttps://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster.", "comment": "Annual Meeting of the Association for Computational Linguistics\n  (ACL), 2025, Accepted as Short Paper", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2506.00457v1;http://arxiv.org/pdf/2506.00457v1", "pdf_url": "http://arxiv.org/pdf/2506.00457v1"}, {"title": "Optimizing Data Augmentation through Bayesian Model Selection", "link": "https://arxiv.org/pdf/2505.21813", "details": "M Matymov, BH Tran, M Kampffmeyer, M Heinonen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Data Augmentation (DA) has become an essential tool to improve robustness and generalization of modern machine learning. However, when deciding on DA strategies it is critical to choose parameters carefully, and this can be a daunting task \u2026", "entry_id": "http://arxiv.org/abs/2505.21813v1", "updated": "2025-05-27 22:44:36", "published": "2025-05-27 22:44:36", "authors": "Madi Matymov;Ba-Hien Tran;Michael Kampffmeyer;Markus Heinonen;Maurizio Filippone", "summary": "Data Augmentation (DA) has become an essential tool to improve robustness and\ngeneralization of modern machine learning. However, when deciding on DA\nstrategies it is critical to choose parameters carefully, and this can be a\ndaunting task which is traditionally left to trial-and-error or expensive\noptimization based on validation performance. In this paper, we counter these\nlimitations by proposing a novel framework for optimizing DA. In particular, we\ntake a probabilistic view of DA, which leads to the interpretation of\naugmentation parameters as model (hyper)-parameters, and the optimization of\nthe marginal likelihood with respect to these parameters as a Bayesian model\nselection problem. Due to its intractability, we derive a tractable Evidence\nLower BOund (ELBO), which allows us to optimize augmentation parameters jointly\nwith model parameters. We provide extensive theoretical results on variational\napproximation quality, generalization guarantees, invariance properties, and\nconnections to empirical Bayes. Through experiments on computer vision tasks,\nwe show that our approach improves calibration and yields robust performance\nover fixed or no augmentation. Our work provides a rigorous foundation for\noptimizing DA through Bayesian principles with significant potential for robust\nmachine learning.", "comment": "26 pages, 3 figures", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;stat.ML;62F15, 68T07 (Primary) 62M45, 62C10, 65C60 (Secondary)", "links": "http://arxiv.org/abs/2505.21813v1;http://arxiv.org/pdf/2505.21813v1", "pdf_url": "http://arxiv.org/pdf/2505.21813v1"}, {"title": "A Hybrid Spiking Model for Anomaly Detection in Multivariate Time Series", "link": "https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.70086", "details": "W Zhang, P He, S Wang, F Yang, Y Liu - Expert Systems, 2025", "abstract": "Deep neural networks have exhibited preeminent performance in anomaly detection, but they struggle to effectively capture changes over time in multivariate time\u2010series data and suffer from resource consumption issues. Spiking neural networks address \u2026"}, {"title": "Cluster-Aware Causal Mixer for Online Anomaly Detection in Multivariate Time Series", "link": "https://arxiv.org/pdf/2506.00188", "details": "MMN Murad, Y Yilmaz - arXiv preprint arXiv:2506.00188, 2025", "abstract": "Early and accurate detection of anomalies in time series data is critical, given the significant risks associated with false or missed detections. While MLP-based mixer models have shown promise in time series analysis, they lack a causality mechanism \u2026", "entry_id": "http://arxiv.org/abs/2506.00188v1", "updated": "2025-05-30 19:56:54", "published": "2025-05-30 19:56:54", "authors": "Md Mahmuddun Nabi Murad;Yasin Yilmaz", "summary": "Early and accurate detection of anomalies in time series data is critical,\ngiven the significant risks associated with false or missed detections. While\nMLP-based mixer models have shown promise in time series analysis, they lack a\ncausality mechanism to preserve temporal dependencies inherent in the system.\nMoreover, real-world multivariate time series often contain numerous channels\nwith diverse inter-channel correlations. A single embedding mechanism for all\nchannels does not effectively capture these complex relationships. To address\nthese challenges, we propose a novel cluster-aware causal mixer to effectively\ndetect anomalies in multivariate time series. Our model groups channels into\nclusters based on their correlations, with each cluster processed through a\ndedicated embedding layer. In addition, we introduce a causal mixer in our\nmodel, which mixes the information while maintaining causality. Furthermore, we\npresent an anomaly detection framework that accumulates the anomaly evidence\nover time to prevent false positives due to nominal outliers. Our proposed\nmodel operates in an online fashion, making it suitable for real-time\ntime-series anomaly detection tasks. Experimental evaluations across six public\nbenchmark datasets demonstrate that our model consistently achieves superior F1\nscores.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;stat.ML", "links": "http://arxiv.org/abs/2506.00188v1;http://arxiv.org/pdf/2506.00188v1", "pdf_url": "http://arxiv.org/pdf/2506.00188v1"}, {"title": "Robust Few-Shot Vision-Language Model Adaptation", "link": "https://arxiv.org/pdf/2506.04713", "details": "H Wang, T Liu, S Kong - arXiv preprint arXiv:2506.04713, 2025", "abstract": "Pretrained VLMs achieve strong performance on downstream tasks when adapted with just a few labeled examples. As the adapted models inevitably encounter out-of- distribution (OOD) test data that deviates from the in-distribution (ID) task-specific \u2026", "entry_id": "http://arxiv.org/abs/2506.04713v1", "updated": "2025-06-05 07:37:15", "published": "2025-06-05 07:37:15", "authors": "Hanxin Wang;Tian Liu;Shu Kong", "summary": "Pretrained VLMs achieve strong performance on downstream tasks when adapted\nwith just a few labeled examples. As the adapted models inevitably encounter\nout-of-distribution (OOD) test data that deviates from the in-distribution (ID)\ntask-specific training data, enhancing OOD generalization in few-shot\nadaptation is critically important. We study robust few-shot VLM adaptation,\naiming to increase both ID and OOD accuracy. By comparing different adaptation\nmethods (e.g., prompt tuning, linear probing, contrastive finetuning, and full\nfinetuning), we uncover three key findings: (1) finetuning with proper\nhyperparameters significantly outperforms the popular VLM adaptation methods\nprompt tuning and linear probing; (2) visual encoder-only finetuning achieves\nbetter efficiency and accuracy than contrastively finetuning both visual and\ntextual encoders; (3) finetuning the top layers of the visual encoder provides\nthe best balance between ID and OOD accuracy. Building on these findings, we\npropose partial finetuning of the visual encoder empowered with two simple\naugmentation techniques: (1) retrieval augmentation which retrieves\ntask-relevant data from the VLM's pretraining dataset to enhance adaptation,\nand (2) adversarial perturbation which promotes robustness during finetuning.\nResults show that the former/latter boosts OOD/ID accuracy while slightly\nsacrificing the ID/OOD accuracy. Yet, perhaps understandably, naively combining\nthe two does not maintain their best OOD/ID accuracy. We address this dilemma\nwith the developed SRAPF, Stage-wise Retrieval Augmentation-based Adversarial\nPartial Finetuning. SRAPF consists of two stages: (1) partial finetuning the\nvisual encoder using both ID and retrieved data, and (2) adversarial partial\nfinetuning with few-shot ID data. Extensive experiments demonstrate that SRAPF\nachieves the state-of-the-art ID and OOD accuracy on the ImageNet OOD\nbenchmarks.", "comment": "Project website: https://hannawang09.github.io/projects/srapf/", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2506.04713v1;http://arxiv.org/pdf/2506.04713v1", "pdf_url": "http://arxiv.org/pdf/2506.04713v1"}]
