[{"title": "Optimizing generative AI by backpropagating language model feedback", "link": "https://www.nature.com/articles/s41586-025-08661-4", "details": "M Yuksekgonul, F Bianchi, J Boen, S Liu, P Lu\u2026 - Nature, 2025", "abstract": "Recent breakthroughs in artificial intelligence (AI) are increasingly driven by systems orchestrating multiple large language models (LLMs) and other specialized tools, such as search engines and simulators. So far, these systems are primarily \u2026"}, {"title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation", "link": "https://arxiv.org/pdf/2502.19414%3F", "details": "S Sinha, S Goel, P Kumaraguru, J Geiping, M Bethge\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery. Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time. This process requires significant \u2026"}, {"title": "Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models", "link": "https://arxiv.org/pdf/2502.15639", "details": "A Sundar, S Williamson, K Metcalf, BJ Theobald\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Aligned representations across languages is a desired property in multilingual large language models (mLLMs), as alignment can improve performance in cross-lingual tasks. Typically alignment requires fine-tuning a model, which is computationally \u2026"}, {"title": "DiffPO: Diffusion-styled Preference Optimization for Efficient Inference-Time Alignment of Large Language Models", "link": "https://arxiv.org/pdf/2503.04240", "details": "R Chen, W Chai, Z Yang, X Zhang, JT Zhou, T Quek\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inference-time alignment provides an efficient alternative for aligning LLMs with humans. However, these approaches still face challenges, such as limited scalability due to policy-specific value functions and latency during the inference phase. In this \u2026"}, {"title": "Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs", "link": "https://arxiv.org/pdf/2503.05139", "details": "L Team, B Zeng, C Huang, C Zhang, C Tian, C Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In this technical report, we tackle the challenges of training large-scale Mixture of Experts (MoE) models, focusing on overcoming cost inefficiency and resource limitations prevalent in such systems. To address these issues, we present two \u2026"}, {"title": "Alignment for Efficient Tool Calling of Large Language Models", "link": "https://arxiv.org/pdf/2503.06708", "details": "H Xu, Z Wang, Z Zhu, L Pan, X Chen, L Chen, K Yu - arXiv preprint arXiv:2503.06708, 2025", "abstract": "Recent advancements in tool learning have enabled large language models (LLMs) to integrate external tools, enhancing their task performance by expanding their knowledge boundaries. However, relying on tools often introduces tradeoffs between \u2026"}, {"title": "Benchmarking Reasoning Robustness in Large Language Models", "link": "https://arxiv.org/pdf/2503.04550", "details": "T Yu, Y Jing, X Zhang, W Jiang, W Wu, Y Wang, W Hu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite the recent success of large language models (LLMs) in reasoning such as DeepSeek, we for the first time identify a key dilemma in reasoning robustness and generalization: significant performance degradation on novel or incomplete data \u2026"}, {"title": "InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2503.06692", "details": "Y Yan, Y Shen, Y Liu, J Jiang, M Zhang, J Shao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Advanced reasoning in large language models has achieved remarkable performance on challenging tasks, but the prevailing long-context reasoning paradigm faces critical limitations: quadratic computational scaling with sequence \u2026"}, {"title": "Enhancing Large Language Models on Domain-specific Tasks: A Novel Training Strategy via Domain Adaptation and Preference Alignment", "link": "https://ieeexplore.ieee.org/abstract/document/10890050/", "details": "J Deng, Z Zhang, JK Cheng, J Ma - \u2026 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "In handling complex, domain-specific tasks, particularly in the context of state-owned assets and enterprises (SOAEs), general LLMs suffer from the knowledge gap due to insufficient exposure to domain-specific corpora, and the value disagreement, as \u2026"}]
