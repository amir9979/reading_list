[{"title": "Unveiling the linguistic capabilities of a self-supervised speech model through cross-lingual benchmark and layer-wise similarity analysis", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10597571.pdf", "details": "T Ashihara, M Delcroix, Y Ijima, M Kashino - IEEE Access, 2024", "abstract": "Self-supervised learning (SSL), an unsupervised representation learning technique, has received widespread attention across various modalities. Speech, with its inherent complexity encompassing acoustic (eg, speaker, phoneme, and \u2026"}, {"title": "Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs", "link": "https://arxiv.org/pdf/2407.15431", "details": "H Zhao, B Yang, Y Cen, J Ren, C Zhang, Y Dong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The text-attributed graph (TAG) is one kind of important real-world graph-structured data with each node associated with raw texts. For TAGs, traditional few-shot node classification methods directly conduct training on the pre-processed node features \u2026"}, {"title": "Two Stacks Are Better Than One: A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives", "link": "https://arxiv.org/pdf/2407.15489", "details": "Z Li, S Ji, T Mickus, V Segonne, J Tiedemann - arXiv preprint arXiv:2407.15489, 2024", "abstract": "Pretrained language models (PLMs) display impressive performances and have captured the attention of the NLP community. Establishing the best practices in pretraining has therefore become a major point of focus for much of NLP research \u2026"}, {"title": "Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation", "link": "https://arxiv.org/pdf/2407.15268", "details": "L Sun, J Zhao, M Han, C Xiong - arXiv preprint arXiv:2407.15268, 2024", "abstract": "Multimodal foundation models hold significant potential for automating radiology report generation, thereby assisting clinicians in diagnosing cardiac diseases. However, generated reports often suffer from serious factual inaccuracy. In this \u2026"}, {"title": "Entropy-Based Decoding for Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2406.17519", "details": "Z Qiu, Z Ou, B Wu, J Li, A Liu, I King - arXiv preprint arXiv:2406.17519, 2024", "abstract": "Augmenting Large Language Models (LLMs) with retrieved external knowledge has proven effective for improving the factual accuracy of generated responses. Despite their success, retrieval-augmented LLMs still face the distractibility issue, where the \u2026"}, {"title": "Slice-Consistent Lymph Nodes Detection Transformer in CT Scans via Cross-slice Query Contrastive Learning", "link": "https://www.cs.jhu.edu/~lelu/publication/MICCAI2024-0362.pdf", "details": "Q Yu, Y Wang, K Yan, L Lu, N Shen, X Ye, X Ding\u2026", "abstract": "Lymph node (LN) assessment is an indispensable yet very challenging task in the daily clinical workload of radiology and oncology offering valuable insights for cancer staging and treatment planning. Finding scatteredly distributed, low-contrast clinically \u2026"}]
