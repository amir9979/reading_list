[{"title": "EchoFM: Foundation Model for Generalizable Echocardiogram Analysis", "link": "https://arxiv.org/pdf/2410.23413", "details": "S Kim, P Jin, S Song, C Chen, Y Li, H Ren, X Li, T Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Foundation models have recently gained significant attention because of their generalizability and adaptability across multiple tasks and data distributions. Although medical foundation models have emerged, solutions for cardiac imaging \u2026"}, {"title": "PLDR-LLM: Large Language Model from Power Law Decoder Representations", "link": "https://arxiv.org/pdf/2410.16703", "details": "B Gokden - arXiv preprint arXiv:2410.16703, 2024", "abstract": "We present the Large Language Model from Power Law Decoder Representations (PLDR-LLM), a language model that leverages non-linear and linear transformations through Power Law Graph Attention mechanism to generate well-defined deductive \u2026"}, {"title": "Learning predictable and robust neural representations by straightening image sequences", "link": "https://arxiv.org/pdf/2411.01777", "details": "X Niu, C Savin, EP Simoncelli - arXiv preprint arXiv:2411.01777, 2024", "abstract": "Prediction is a fundamental capability of all living organisms, and has been proposed as an objective for learning sensory representations. Recent work demonstrates that in primate visual systems, prediction is facilitated by neural representations that \u2026"}, {"title": "A foundation model for generalizable disease diagnosis in chest X-ray images", "link": "https://arxiv.org/pdf/2410.08861", "details": "L Xu, Z Ni, H Sun, H Li, S Zhang - arXiv preprint arXiv:2410.08861, 2024", "abstract": "Medical artificial intelligence (AI) is revolutionizing the interpretation of chest X-ray (CXR) images by providing robust tools for disease diagnosis. However, the effectiveness of these AI models is often limited by their reliance on large amounts of \u2026"}, {"title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding", "link": "https://arxiv.org/pdf/2410.21311", "details": "F Zhu, Z Liu, XY Ng, H Wu, W Wang, F Feng, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable performance in many vision-language tasks, yet their capabilities in fine-grained visual understanding remain insufficiently evaluated. Existing benchmarks either contain \u2026"}, {"title": "RoRA-VLM: Robust Retrieval-Augmented Vision Language Models", "link": "https://arxiv.org/pdf/2410.08876", "details": "J Qi, Z Xu, R Shao, Y Chen, J Di, Y Cheng, Q Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Current vision-language models (VLMs) still exhibit inferior performance on knowledge-intensive tasks, primarily due to the challenge of accurately encoding all the associations between visual objects and scenes to their corresponding entities \u2026"}, {"title": "VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis", "link": "https://arxiv.org/pdf/2410.08397", "details": "A Hoopes, VI Butoi, JV Guttag, AV Dalca - arXiv preprint arXiv:2410.08397, 2024", "abstract": "We present VoxelPrompt, an agent-driven vision-language framework that tackles diverse radiological tasks through joint modeling of natural language, image volumes, and analytical metrics. VoxelPrompt is multi-modal and versatile \u2026"}, {"title": "Vision-Language Models Can Self-Improve Reasoning via Reflection", "link": "https://arxiv.org/pdf/2411.00855", "details": "K Cheng, Y Li, F Xu, J Zhang, H Zhou, Y Liu - arXiv preprint arXiv:2411.00855, 2024", "abstract": "Chain-of-thought (CoT) has proven to improve the reasoning capability of large language models (LLMs). However, due to the complexity of multimodal scenarios and the difficulty in collecting high-quality CoT data, CoT reasoning in multimodal \u2026"}, {"title": "Automated anonymization of radiology reports: comparison of publicly available natural language processing and large language models", "link": "https://link.springer.com/article/10.1007/s00330-024-11148-x", "details": "MC Langenbach, B Foldyna, I Hadzic, IL Langenbach\u2026 - European Radiology, 2024", "abstract": "Purpose Medical reports, governed by HIPAA regulations, contain personal health information (PHI), restricting secondary data use. Utilizing natural language processing (NLP) and large language models (LLM), we sought to employ publicly \u2026"}]
