[{"title": "Semantic-aware contrastive learning via multi-prompt alignment", "link": "https://link.springer.com/article/10.1007/s10994-024-06665-1", "details": "Z Zhao, H Qin, M Kong, L Chen, D Xie, J Zhu, Q Zhu - Machine Learning, 2025", "abstract": "The role of the sample generation mechanism in contrastive learning is pivotal. It not only determines the pairings of positive and negative samples but also enriches the diversity of the sample pool, thereby substantially affecting the quality of the learned \u2026"}, {"title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "link": "https://arxiv.org/pdf/2502.05142", "details": "Z Yang, X Xu, J Zhang, G Wang, MK Kalra, P Yan - arXiv preprint arXiv:2502.05142, 2025", "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data \u2026"}, {"title": "An effective multi-step feature selection framework for clinical outcome prediction using electronic medical records", "link": "https://link.springer.com/article/10.1186/s12911-025-02922-y", "details": "H Wang, M Zhang, L Mai, X Li, A Bellou, L Wu - BMC Medical Informatics and \u2026, 2025", "abstract": "Identifying key variables is essential for developing clinical outcome prediction models based on high-dimensional electronic medical records (EMR). However, despite the abundance of feature selection (FS) methods available, challenges \u2026"}, {"title": "Prediction of Intensive Care Length of Stay for Surviving and Nonsurviving Patients Using Deep Learning", "link": "https://journals.lww.com/ccmjournal/fulltext/9900/prediction_of_intensive_care_length_of_stay_for.456.aspx", "details": "L Brochini, X Liu, L Atallah, P Amelung, R French\u2026 - Critical Care Medicine, 2025", "abstract": "Objectives: Length of stay (LOS) models support evaluating ICU care; however, current benchmarking models fail to consider differences in LOS between surviving and nonsurviving patients, which can lead to biased predictions toward the surviving \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis", "link": "https://arxiv.org/pdf/2502.14807", "details": "F Maani, N Saeed, T Saleem, Z Farooq, H Alasmawi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Foundation models are becoming increasingly effective in the medical domain, offering pre-trained models on large datasets that can be readily adapted for downstream tasks. Despite progress, fetal ultrasound images remain a challenging \u2026"}, {"title": "The Sharpness Disparity Principle in Transformers for Accelerating Language Model Pre-Training", "link": "https://arxiv.org/pdf/2502.19002", "details": "J Wang, M Wang, Z Zhou, J Yan, L Wu - arXiv preprint arXiv:2502.19002, 2025", "abstract": "Transformers consist of diverse building blocks, such as embedding layers, normalization layers, self-attention mechanisms, and point-wise feedforward networks. Thus, understanding the differences and interactions among these blocks \u2026"}, {"title": "Conformal Uncertainty Indicator for Continual Test-Time Adaptation", "link": "https://arxiv.org/pdf/2502.02998", "details": "F Lyu, H Zhao, Z Shi, Y Liu, F Hu, Z Zhang, L Wang - arXiv preprint arXiv:2502.02998, 2025", "abstract": "Continual Test-Time Adaptation (CTTA) aims to adapt models to sequentially changing domains during testing, relying on pseudo-labels for self-adaptation. However, incorrect pseudo-labels can accumulate, leading to performance \u2026"}, {"title": "GPT-4 assistance for improvement of physician performance on patient care tasks: a randomized controlled trial", "link": "https://www.nature.com/articles/s41591-024-03456-y", "details": "E Goh, RJ Gallo, E Strong, Y Weng, H Kerman\u2026 - Nature Medicine, 2025", "abstract": "While large language models (LLMs) have shown promise in diagnostic reasoning, their impact on management reasoning, which involves balancing treatment decisions and testing strategies while managing risk, is unknown. This prospective \u2026"}]
