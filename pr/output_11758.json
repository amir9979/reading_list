[{"title": "Harnessing Language Models and Machine Learning for Rancorous URL Classification", "link": "https://www.taylorfrancis.com/chapters/edit/10.1201/9781032711300-19/harnessing-language-models-machine-learning-rancorous-url-classification-prabhuta-chaudhary-ayush-verma-manju-khari", "details": "P Chaudhary, A Verma, M Khari - Cybersecurity and Data Science Innovations for \u2026", "abstract": "As the internet expands exponentially, the need for robust network security has become increasingly critical. This increase in online activity has led to a rise in cyber threats, making individuals and organizations more vulnerable to security breaches \u2026"}, {"title": "19 Harnessing Language Models", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DXEs5EQAAQBAJ%26oi%3Dfnd%26pg%3DPA273%26ots%3DSqjepXVpTb%26sig%3D3kK9SFw2Fwpjt6GmOYFBbzCtAGU", "details": "P Chaudhary, A Verma, M Khari - Cybersecurity and Data Science Innovations for \u2026, 2025", "abstract": "The internet nowadays is full of potential dangers due to the increased use of URLs all over the world. Over 90% of all hacking attempts target WordPress, the content management system (CMS) that has been compromised the most. WordPress is a \u2026"}, {"title": "Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack", "link": "https://arxiv.org/pdf/2501.08454", "details": "S Antebi, E Habler, A Shabtai, Y Elovici - arXiv preprint arXiv:2501.08454, 2025", "abstract": "Large language models (LLMs) have become essential digital task assistance tools. Their training relies heavily on the collection of vast amounts of data, which may include copyright-protected or sensitive information. Recent studies on the detection \u2026"}, {"title": "Fake news detection: comparative evaluation of BERT-like models and large language models with generative AI-annotated data", "link": "https://link.springer.com/article/10.1007/s10115-024-02321-1", "details": "S Raza, D Paulen-Patterson, C Ding - Knowledge and Information Systems, 2025", "abstract": "Fake news poses a significant threat to public opinion and social stability in modern society. This study presents a comparative evaluation of BERT-like encoder-only models and autoregressive decoder-only large language models (LLMs) for fake \u2026"}, {"title": "Disentangling Exploration of Large Language Models by Optimal Exploitation", "link": "https://arxiv.org/pdf/2501.08925", "details": "T Grams, P Betz, C Bartelt - arXiv preprint arXiv:2501.08925, 2025", "abstract": "Exploration is a crucial skill for self-improvement and open-ended problem-solving. However, it remains uncertain whether large language models can effectively explore the state-space. Existing evaluations predominantly focus on the trade-off \u2026"}, {"title": "Curriculum Learning for Cross-Lingual Data-to-Text Generation With Noisy Data", "link": "https://ui.adsabs.harvard.edu/abs/2024arXiv241213484A/abstract", "details": "K Aditya Hari, M Gupta, V Varma - arXiv e-prints, 2024", "abstract": "Curriculum learning has been used to improve the quality of text generation systems by ordering the training samples according to a particular schedule in various tasks. In the context of data-to-text generation (DTG), previous studies used various \u2026"}]
