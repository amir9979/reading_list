'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [A Dataset for Evaluating Contextualized Representatio'
[{"title": "Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation", "link": "https://arxiv.org/pdf/2404.17489", "details": "W Cui, R Hosseinzadeh, J Ma, T Wu, Y Sui, K Golestan - arXiv preprint arXiv \u2026, 2024", "abstract": "Contrastive learning is a model pre-training technique by first creating similar views of the original data, and then encouraging the data and its corresponding views to be close in the embedding space. Contrastive learning has witnessed success in image \u2026"}, {"title": "The Hallucinations Leaderboard--An Open Effort to Measure Hallucinations in Large Language Models", "link": "https://arxiv.org/pdf/2404.05904", "details": "G Hong, AP Gema, R Saxena, X Du, P Nie, Y Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have transformed the Natural Language Processing (NLP) landscape with their remarkable ability to understand and generate human- like text. However, these models are prone to``hallucinations''--outputs that do not \u2026"}]
