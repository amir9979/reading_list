[{"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization", "link": "https://arxiv.org/pdf/2410.09302", "details": "G Liu, K Ji, R Zheng, Z Wu, C Dun, Q Gu, L Yan - arXiv preprint arXiv:2410.09302, 2024", "abstract": "Reinforcement Learning (RL) plays a crucial role in aligning large language models (LLMs) with human preferences and improving their ability to perform complex tasks. However, current approaches either require significant computational resources due \u2026"}, {"title": "LoGra-Med: Long context multi-graph alignment for medical vision-language model", "link": "https://arxiv.org/pdf/2410.02615%3F", "details": "DMH Nguyen, NT Diep, TQ Nguyen, HB Le, T Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "State-of-the-art medical multi-modal large language models (med-MLLM), like LLaVA-Med or BioMedGPT, leverage instruction-following data in pre-training. However, those models primarily focus on scaling the model size and data volume to \u2026"}, {"title": "Category-guided multi-interest collaborative metric learning with representation uniformity constraints", "link": "https://www.sciencedirect.com/science/article/pii/S0306457324002966", "details": "L Wang, T Lian - Information Processing & Management, 2025", "abstract": "Multi-interest collaborative metric learning has recently emerged as an effective approach to modeling the multifaceted interests of a user in recommender systems. However, two issues remain unexplored.(1) There is no explicit guidance for the \u2026"}, {"title": "Advancing Medical Radiograph Representation Learning: A Hybrid Pre-training Paradigm with Multilevel Semantic Granularity", "link": "https://arxiv.org/pdf/2410.00448", "details": "H Jiang, X Hao, Y Huang, C Ma, J Zhang, Y Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces an innovative approach to Medical Vision-Language Pre- training (Med-VLP) area in the specialized context of radiograph representation learning. While conventional methods frequently merge textual annotations into \u2026"}, {"title": "Self-eXplainable AI for Medical Image Analysis: A Survey and New Outlooks", "link": "https://arxiv.org/pdf/2410.02331", "details": "J Hou, S Liu, Y Bie, H Wang, A Tan, L Luo, H Chen - arXiv preprint arXiv:2410.02331, 2024", "abstract": "The increasing demand for transparent and reliable models, particularly in high- stakes decision-making areas such as medical image analysis, has led to the emergence of eXplainable Artificial Intelligence (XAI). Post-hoc XAI techniques \u2026"}, {"title": "Medqa-cs: Benchmarking large language models clinical skills using an ai-sce framework", "link": "https://arxiv.org/pdf/2410.01553%3F", "details": "Z Yao, Z Zhang, C Tang, X Bian, Y Zhao, Z Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Artificial intelligence (AI) and large language models (LLMs) in healthcare require advanced clinical skills (CS), yet current benchmarks fail to evaluate these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by \u2026"}, {"title": "The Role of Deductive and Inductive Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2410.02892", "details": "C Cai, X Zhao, H Liu, Z Jiang, T Zhang, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have achieved substantial progress in artificial intelligence, particularly in reasoning tasks. However, their reliance on static prompt structures, coupled with limited dynamic reasoning capabilities, often constrains their \u2026"}, {"title": "LUCIDA: Low-Dose Universal-Tissue CT Image Domain Adaptation for Medical Segmentation", "link": "https://papers.miccai.org/miccai-2024/paper/0562_paper.pdf", "details": "Y Chen, X Meng, Y Wang, S Zeng, X Liu, Z Xie - International Conference on Medical \u2026, 2024", "abstract": "Accurate segmentation in low-dose CT scans remains a challenge in medical imaging, primarily due to the high annotation costs. This study introduces LUCIDA, a Low-dose Universal-tissue CT Image Domain Adaptation model. LUCIDA operates \u2026"}]
