[{"title": "LLM Compiler: Foundation Language Models for Compiler Optimization", "link": "https://dl.acm.org/doi/pdf/10.1145/3708493.3712691", "details": "C Cummins, V Seeker, D Grubisic, B Roziere\u2026 - Proceedings of the 34th \u2026, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a variety of software engineering and coding tasks. However, their application in the domain of code and compiler optimization remains underexplored. Training LLMs is \u2026"}, {"title": "SPARC: Score Prompting and Adaptive Fusion for Zero-Shot Multi-Label Recognition in Vision-Language Models", "link": "https://arxiv.org/pdf/2502.16911", "details": "K Miller, S Mishra, A Gangrade, K Saenko, V Saligrama - arXiv preprint arXiv \u2026, 2025", "abstract": "Zero-shot multi-label recognition (MLR) with Vision-Language Models (VLMs) faces significant challenges without training data, model tuning, or architectural modifications. Existing approaches require prompt tuning or architectural \u2026"}, {"title": "Towards Conditioning Clinical Text Generation for User Control", "link": "https://arxiv.org/pdf/2502.17571", "details": "OA Kora\u015f, R Bahnan, J Kleesiek, A Dada - arXiv preprint arXiv:2502.17571, 2025", "abstract": "Deploying natural language generation systems in clinical settings remains challenging despite advances in Large Language Models (LLMs), which continue to exhibit hallucinations and factual inconsistencies, necessitating human oversight \u2026"}, {"title": "Teaching Large Language Models Number-Focused Headline Generation With Key Element Rationales", "link": "https://arxiv.org/pdf/2502.03129", "details": "Z Qian, X Zhang, X Xu, F Xia - arXiv preprint arXiv:2502.03129, 2025", "abstract": "Number-focused headline generation is a summarization task requiring both high textual quality and precise numerical accuracy, which poses a unique challenge for Large Language Models (LLMs). Existing studies in the literature focus only on either \u2026"}, {"title": "RAPID: Reliable and efficient Automatic generation of submission rePortIng checklists with large language moDels", "link": "https://www.biorxiv.org/content/10.1101/2025.02.13.638015.full.pdf", "details": "Z Li, X Luo, Z Yang, H Zhang, B Wang, L Ge, Z Bian\u2026 - bioRxiv, 2025", "abstract": "Importance Medical reporting guidelines are significant in improving the transparency, quality, and integrity of medical research, particularly in randomized clinical trials; adherence to these guidelines supports research interpretability and \u2026"}, {"title": "Towards Principled Training and Serving of Large Language Models", "link": "https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-6.pdf", "details": "B Zhu - 2025", "abstract": "Large Language Models (LLMs) have emerged as a transformative technology in artificial intelligence (AI), demonstrating unprecedented capabilities in tasks ranging from translation and summarization to code generation, complex reasoning, and \u2026"}, {"title": "Hierarchical Prompting Taxonomy: A Universal Evaluation Framework for Large Language Models Aligned with Human Cognitive Principles", "link": "https://www.researchgate.net/profile/Devichand-Budagam/publication/381517001_Hierarchical_Prompting_Taxonomy_A_Universal_Evaluation_Framework_for_Large_Language_Models_Aligned_with_Human_Cognitive_Principles/links/67b88a29207c0c20fa9109be/Hierarchical-Prompting-Taxonomy-A-Universal-Evaluation-Framework-for-Large-Language-Models-Aligned-with-Human-Cognitive-Principles.pdf", "details": "D Budagam, A Kumar, M Khoshnoodi, S KJ, V Jain\u2026 - 2025", "abstract": "Assessing the effectiveness of large language models (LLMs) in performing different tasks is crucial for understanding their strengths and weaknesses. This paper presents Hierarchical Prompting Taxonomy (HPT), grounded on human cognitive \u2026"}]
