[{"title": "Enhancing One-shot Pruned Pre-trained Language Models through Sparse-Dense-Sparse Mechanism", "link": "https://arxiv.org/pdf/2408.10473", "details": "G Li, X Zhao, L Liu, Z Li, D Li, L Tian, J He, A Sirasao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained language models (PLMs) are engineered to be robust in contextual understanding and exhibit outstanding performance in various natural language processing tasks. However, their considerable size incurs significant computational \u2026"}, {"title": "Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios", "link": "https://aclanthology.org/2024.findings-acl.230.pdf", "details": "L Lin, J Fu, P Liu, Q Li, Y Gong, J Wan, F Zhang\u2026 - Findings of the Association \u2026, 2024", "abstract": "Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local \u2026"}, {"title": "Exploiting Pre-trained Language Models for Black-box Attack against Knowledge Graph Embeddings", "link": "https://dl.acm.org/doi/pdf/10.1145/3688850", "details": "G Yang, L Zhang, Y Liu, H Xie, Z Mao - ACM Transactions on Knowledge Discovery \u2026, 2024", "abstract": "Despite the emerging research on adversarial attacks against Knowledge Graph Embedding (KGE) models, most of them focus on white-box attack settings. However, white-box attacks are difficult to apply in practice compared to black-box attacks \u2026"}, {"title": "Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models", "link": "https://aclanthology.org/2024.acl-long.765.pdf", "details": "S Li, R Lin, S Pei - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Multi-modal large language models (MLLMs) are expected to support multi-turn queries of interchanging image and text modalities in production. However, the current MLLMs trained with visual-question-answering (VQA) datasets could suffer \u2026"}, {"title": "KoCommonGEN v2: A Benchmark for Navigating Korean Commonsense Reasoning Challenges in Large Language Models", "link": "https://aclanthology.org/2024.findings-acl.141.pdf", "details": "J Seo, J Lee, C Park, ST Hong, S Lee, HS Lim - Findings of the Association for \u2026, 2024", "abstract": "The evolution of large language models (LLMs) has culminated in a multitask model paradigm where prompts drive the generation of user-specific outputs. However, this advancement has revealed a critical challenge: LLMs frequently produce outputs \u2026"}, {"title": "Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.06663", "details": "K Sun, M Dredze - arXiv preprint arXiv:2408.06663, 2024", "abstract": "The development of large language models leads to the formation of a pre-train-then- align paradigm, in which the model is typically pre-trained on a large text corpus and undergoes a tuning stage to align the model with human preference or downstream \u2026"}, {"title": "Language Models Pre-training", "link": "https://link.springer.com/content/pdf/10.1007/978-3-031-65647-7_2.pdf", "details": "U Kamath, K Keenan, G Somers, S Sorenson - Large Language Models: A Deep Dive \u2026, 2024", "abstract": "Pre-training forms the foundation for LLMs' capabilities. LLMs gain vital language comprehension and generative language skills by using large-scale datasets. The size and quality of these datasets are essential for maximizing LLMs' potential. It is \u2026"}, {"title": "Llama2Vec: Unsupervised Adaptation of Large Language Models for Dense Retrieval", "link": "https://aclanthology.org/2024.acl-long.191.pdf", "details": "C Li, Z Liu, S Xiao, Y Shao, D Lian - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Dense retrieval calls for discriminative embeddings to represent the semantic relationship between query and document. It may benefit from the using of large language models (LLMs), given LLMs' strong capability on semantic understanding \u2026"}, {"title": "Analysis of Plan-based Retrieval for Grounded Text Generation", "link": "https://arxiv.org/pdf/2408.10490", "details": "A Godbole, N Monath, S Kim, AS Rawat, A McCallum\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In text generation, hallucinations refer to the generation of seemingly coherent text that contradicts established knowledge. One compelling hypothesis is that hallucinations occur when a language model is given a generation task outside its \u2026"}]
