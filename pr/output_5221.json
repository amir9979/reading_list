[{"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.02032", "details": "F Huo, W Xu, Z Zhang, H Wang, Z Chen, P Zhao - arXiv preprint arXiv:2408.02032, 2024", "abstract": "While Large Vision-Language Models (LVLMs) have rapidly advanced in recent years, the prevalent issue known as thehallucination'problem has emerged as a significant bottleneck, hindering their real-world deployments. Existing methods \u2026"}, {"title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability", "link": "https://arxiv.org/pdf/2407.19842", "details": "J Garc\u00eda-Carrasco, A Mat\u00e9, J Trujillo - arXiv preprint arXiv:2407.19842, 2024", "abstract": "Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the \u2026"}, {"title": "Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models", "link": "https://arxiv.org/pdf/2408.03907", "details": "SH Kumar, S Sahay, S Mazumder, E Okur\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have excelled at language understanding and generating human-level text. However, even with supervised training and human alignment, these LLMs are susceptible to adversarial attacks where malicious users \u2026"}, {"title": "Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation", "link": "https://arxiv.org/pdf/2408.00555", "details": "X Qu, Q Chen, W Wei, J Sun, J Dong - arXiv preprint arXiv:2408.00555, 2024", "abstract": "Despite the remarkable ability of large vision-language models (LVLMs) in image comprehension, these models frequently generate plausible yet factually incorrect responses, a phenomenon known as hallucination. Recently, in large language \u2026"}, {"title": "Is Child-Directed Speech Effective Training Data for Language Models?", "link": "https://arxiv.org/pdf/2408.03617", "details": "SY Feng, ND Goodman, MC Frank - arXiv preprint arXiv:2408.03617, 2024", "abstract": "While high-performing language models are typically trained on hundreds of billions of words, human children become fluent language users with a much smaller amount of data. What are the features of the data they receive, and how do these features \u2026"}, {"title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "link": "https://arxiv.org/pdf/2408.02103", "details": "P Wang, X Wang, C Lou, S Mao, P Xie, Y Jiang - arXiv preprint arXiv:2408.02103, 2024", "abstract": "In-context learning (ICL) is a few-shot learning paradigm that involves learning mappings through input-output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language \u2026"}, {"title": "Open-Domain Question Answering over Tables with Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-97-5615-5_28", "details": "X Liang, R Hu, Y Liu, K Zhu - International Conference on Intelligent Computing, 2024", "abstract": "Open-domain question answering (ODQA) over tables has received attention in recent years. This task requires retrieving evidence from huge amounts of semi- structured tabular data to answer natural language questions. Previous open-domain \u2026"}, {"title": "Mitigating Multilingual Hallucination in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.00550", "details": "X Qu, M Song, W Wei, J Dong, Y Cheng - arXiv preprint arXiv:2408.00550, 2024", "abstract": "While Large Vision-Language Models (LVLMs) have exhibited remarkable capabilities across a wide range of tasks, they suffer from hallucination problems, where models generate plausible yet incorrect answers given the input image-query \u2026"}]
