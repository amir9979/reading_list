[{"title": "RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records", "link": "https://arxiv.org/html/2403.00815v1", "details": "R Xu, W Shi, Y Yu, Y Zhuang, B Jin, MD Wang, JC Ho\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain \u2026"}, {"title": "Set the Clock: Temporal Alignment of Pretrained Language Models", "link": "https://arxiv.org/pdf/2402.16797", "details": "B Zhao, Z Brumbaugh, Y Wang, H Hajishirzi, NA Smith - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) are trained on web text originating from many points in time and, in general, without any explicit temporal grounding. This work investigates the temporal chaos of pretrained LMs and explores various methods to align their \u2026"}, {"title": "QuRating: Selecting High-Quality Data for Training Language Models", "link": "https://arxiv.org/pdf/2402.09739", "details": "A Wettig, A Gupta, S Malik, D Chen - arXiv preprint arXiv:2402.09739, 2024", "abstract": "Selecting high-quality pre-training data is important for creating capable language models, but existing methods rely on simple heuristics. We introduce QuRating, a method for selecting pre-training data that captures the abstract qualities of texts \u2026"}, {"title": "Reliable, Adaptable, and Attributable Language Models with Retrieval", "link": "https://arxiv.org/pdf/2403.03187", "details": "A Asai, Z Zhong, D Chen, PW Koh, L Zettlemoyer\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Parametric language models (LMs), which are trained on vast amounts of web data, exhibit remarkable flexibility and capability. However, they still face practical challenges such as hallucinations, difficulty in adapting to new data distributions, and \u2026"}, {"title": "How does Architecture Influence the Base Capabilities of Pre-trained Language Models? A Case Study Based on FFN-Wider Transformer Models", "link": "https://arxiv.org/pdf/2403.02436", "details": "X Lu, Y Zhao, B Qin - arXiv preprint arXiv:2403.02436, 2024", "abstract": "Pre-trained language models have been proven to possess strong base capabilities, which not only excel in in-distribution language modeling but also show powerful abilities in out-of-distribution language modeling, transfer learning and few-shot \u2026"}, {"title": "RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models", "link": "https://arxiv.org/html/2403.02271v1", "details": "S Najafi, A Fyshe - arXiv preprint arXiv:2403.02271, 2024", "abstract": "Pre-trained Language Models (PLMs) can be accurately fine-tuned for downstream text processing tasks. Recently, researchers have introduced several parameter- efficient fine-tuning methods that optimize input prompts or adjust a small number of \u2026"}, {"title": "TOO-BERT: A Trajectory Order Objective BERT for self-supervised representation learning of temporal healthcare data", "link": "https://www.researchsquare.com/article/rs-3959125/latest.pdf", "details": "A Amirahmadi, F Etminani, J Bjork, O Melander\u2026 - 2024", "abstract": "Healthcare data accumulation over time, particularly in Electronic Health Records (EHRs), plays a pivotal role by offering a vast repository of patient data with the potential to enhance patient care and predict health outcomes. While Bert-inspired \u2026"}, {"title": "Grounding Language Models for Visual Entity Recognition", "link": "https://arxiv.org/pdf/2402.18695", "details": "Z Xiao, M Gong, P Cascante-Bonilla, X Zhang, J Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce AutoVER, an Autoregressive model for Visual Entity Recognition. Our model extends an autoregressive Multi-modal Large Language Model by employing retrieval augmented constrained generation. It mitigates low performance on out-of \u2026"}, {"title": "Natural language processing of multi-hospital electronic health records for public health surveillance of suicidality", "link": "https://www.nature.com/articles/s44184-023-00046-7", "details": "R Bey, A Cohen, V Trebossen, B Dura, PA Geoffroy\u2026 - npj Mental Health Research, 2024", "abstract": "There is an urgent need to monitor the mental health of large populations, especially during crises such as the COVID-19 pandemic, to timely identify the most at-risk subgroups and to design targeted prevention campaigns. We therefore developed \u2026"}, {"title": "Machine Learning Models for the Prediction of Early-Onset Bipolar Using Electronic Health Records", "link": "https://www.medrxiv.org/content/10.1101/2024.02.19.24302919.full.pdf", "details": "B Wang, Y Sheu, H Lee, RG Mealer, VM Castro\u2026 - medRxiv, 2024", "abstract": "Objective Early identification of bipolar disorder (BD) provides an important opportunity for timely intervention. In this study, we aimed to develop machine learning models using large-scale electronic health record (EHR) data including \u2026"}]
