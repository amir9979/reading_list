[{"title": "THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2405.05256", "details": "P Kaul, Z Li, H Yang, Y Dukler, A Swaminathan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Mitigating hallucinations in large vision-language models (LVLMs) remains an open problem. Recent benchmarks do not address hallucinations in open-ended free-form responses, which we term\" Type I hallucinations\". Instead, they focus on \u2026"}, {"title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision", "link": "https://arxiv.org/pdf/2405.04086", "details": "Y Tong, S Wang, D Li, Y Wang, S Han, Z Lin, C Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While Large Language Models (LLMs) have demonstrated proficiency in handling complex queries, much of the past work has depended on extensively annotated datasets by human experts. However, this reliance on fully-supervised annotations \u2026"}, {"title": "Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding", "link": "https://arxiv.org/pdf/2405.19763", "details": "K Liao, S Li, M Zhao, L Liu, M Xue, Z Hu, H Han, C Yin - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent strides in large language models (LLMs) have yielded remarkable performance, leveraging reinforcement learning from human feedback (RLHF) to significantly enhance generation and alignment capabilities. However, RLHF \u2026"}, {"title": "TAeKD: Teacher Assistant Enhanced Knowledge Distillation for Closed-Source Multilingual Neural Machine Translation", "link": "https://aclanthology.org/2024.lrec-main.1350.pdf", "details": "B Lv, X Liu, K Wei, P Luo, Y Yu - Proceedings of the 2024 Joint International \u2026, 2024", "abstract": "Abstract Knowledge Distillation (KD) serves as an efficient method for transferring language knowledge from open-source large language models (LLMs) to more computationally efficient models. However, challenges arise when attempting to \u2026"}, {"title": "Interpretable Multi-task Learning with Shared Variable Embeddings", "link": "https://arxiv.org/pdf/2405.06330", "details": "M \u017belaszczyk, J Ma\u0144dziuk - arXiv preprint arXiv:2405.06330, 2024", "abstract": "This paper proposes a general interpretable predictive system with shared information. The system is able to perform predictions in a multi-task setting where distinct tasks are not bound to have the same input/output structure. Embeddings of \u2026"}, {"title": "Exploring and Mitigating Shortcut Learning for Generative Large Language Models", "link": "https://aclanthology.org/2024.lrec-main.602.pdf", "details": "Z Sun, Y Xiao, J Li, Y Ji, W Chen, M Zhang - Proceedings of the 2024 Joint \u2026, 2024", "abstract": "Recent generative large language models (LLMs) have exhibited incredible instruction-following capabilities while keeping strong task completion ability, even without task-specific fine-tuning. Some works attribute this to the bonus of the new \u2026"}, {"title": "Towards Better Vision-Inspired Vision-Language Models", "link": "https://www.lamda.nju.edu.cn/caoyh/files/VIVL.pdf", "details": "YH Cao, K Ji, Z Huang, C Zheng, J Liu, J Wang, J Chen\u2026", "abstract": "Vision-language (VL) models have achieved unprecedented success recently, in which the connection module is the key to bridge the modality gap. Nevertheless, the abundant visual clues are not sufficiently exploited in most existing methods. On the \u2026"}, {"title": "Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning", "link": "https://arxiv.org/pdf/2405.05615", "details": "S Jie, Y Tang, N Ding, ZH Deng, K Han, Y Wang - arXiv preprint arXiv:2405.05615, 2024", "abstract": "Current solutions for efficiently constructing large vision-language (VL) models follow a two-step paradigm: projecting the output of pre-trained vision encoders to the input space of pre-trained language models as visual prompts; and then transferring the \u2026"}, {"title": "Probe Then Retrieve and Reason: Distilling Probing and Reasoning Capabilities into Smaller Language Models", "link": "https://aclanthology.org/2024.lrec-main.1140.pdf", "details": "Y Zhao, S Zhou, H Zhu - Proceedings of the 2024 Joint International Conference \u2026, 2024", "abstract": "Step-by-step reasoning methods, such as the Chain-of-Thought (CoT), have been demonstrated to be highly effective in harnessing the reasoning capabilities of Large Language Models (LLMs). Recent research efforts have sought to distill LLMs into \u2026"}]
