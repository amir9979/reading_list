[{"title": "Language Models Don't Learn the Physical Manifestation of Language", "link": "https://aclanthology.org/2024.acl-long.195.pdf", "details": "B Lee, J Lim - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "We argue that language-only models don't learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test. These tasks highlight a \u2026"}, {"title": "MindLLM: Lightweight large language model pre-training, evaluation and domain application", "link": "https://www.sciencedirect.com/science/article/pii/S2666651024000111", "details": "Y Yang, H Sun, J Li, R Liu, Y Li, Y Liu, Y Gao, H Huang - AI Open, 2024", "abstract": "Abstract Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is \u2026"}, {"title": "DOSSIER: Fact checking in electronic health records while preserving patient privacy", "link": "https://www.amazon.science/publications/dossier-fact-checking-in-electronic-health-records-while-preserving-patient-privacy", "details": "H Zhang, S Nagesh, M Shyani, N Mishra - 2024", "abstract": "Given a particular claim about a specific document, the fact checking problem is to determine if the claim is true and, if so, provide corroborating evidence. The problem is motivated by contexts where a document is too lengthy to quickly read and find an \u2026"}, {"title": "RuMedSpellchecker: A new approach for advanced spelling error correction in Russian electronic health records", "link": "https://www.sciencedirect.com/science/article/pii/S1877750324001868", "details": "D Pogrebnoi, A Funkner, S Kovalchuk - Journal of Computational Science, 2024", "abstract": "In healthcare, a remarkable progress in machine learning has given rise to a diverse range of predictive and decision-making medical models, significantly enhancing treatment efficacy and overall quality of care. These models often rely on electronic \u2026"}, {"title": "Prompt Learning with Extended Kalman Filter for Pre-trained Language Models", "link": "https://www.ijcai.org/proceedings/2024/0492.pdf", "details": "Q Li, X Xie, C Wang, SK Zhou", "abstract": "Prompt learning has gained popularity as a means to leverage the knowledge embedded in pre-trained language models (PLMs) for NLP tasks while using a limited number of trainable parameters. While it has shown promise in tasks like \u2026"}, {"title": "Boosting entity recognition by leveraging cross-task domain models for weak supervision", "link": "https://www.amazon.science/publications/boosting-entity-recognition-by-leveraging-cross-task-domain-models-for-weak-supervision", "details": "S Agrawal, S Merugu, V Sembium - 2024", "abstract": "Entity Recognition (ER) is a common natural language processing task encountered in a number of real-world applications. For common domains and named entities such as places and organisations, there exists sufficient high quality annotated data \u2026"}, {"title": "Pre-training data selection for biomedical domain adaptation using journal impact metrics", "link": "https://aclanthology.org/2024.bionlp-1.27.pdf", "details": "M Lai-king, P Paroubek - Proceedings of the 23rd Workshop on Biomedical \u2026, 2024", "abstract": "Abstract Domain adaptation is a widely used method in natural language processing (NLP) to improve the performance of a language model within a specific domain. This method is particularly common in the biomedical domain, which sees regular \u2026"}, {"title": "Accuracy and transportability of machine learning models for adolescent suicide prediction with longitudinal clinical records", "link": "https://www.nature.com/articles/s41398-024-03034-3", "details": "C Zang, Y Hou, D Lyu, J Jin, S Sacco, K Chen\u2026 - Translational psychiatry, 2024", "abstract": "Abstract Machine Learning models trained from real-world data have demonstrated promise in predicting suicide attempts in adolescents. However, their transportability, namely the performance of a model trained on one dataset and applied to different \u2026"}, {"title": "XrayGPT: Chest Radiographs Summarization using Large Medical Vision-Language Models", "link": "https://aclanthology.org/2024.bionlp-1.35.pdf", "details": "OC Thawakar, AM Shaker, SS Mullappilly, H Cholakkal\u2026 - Proceedings of the 23rd \u2026, 2024", "abstract": "The latest breakthroughs in large language models (LLMs) and vision-language models (VLMs) have showcased promising capabilities toward performing a wide range of tasks. Such models are typically trained on massive datasets comprising \u2026"}]
