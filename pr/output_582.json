'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Smaller Language Models are Better Zero-shot Machine-G'
[{"title": "Pretraining a foundation model for generalizable fluorescence microscopy-based image restoration", "link": "https://www.nature.com/articles/s41592-024-02244-3", "details": "C Ma, W Tan, R He, B Yan - Nature Methods, 2024", "abstract": "Fluorescence microscopy-based image restoration has received widespread attention in the life sciences and has led to significant progress, benefiting from deep learning technology. However, most current task-specific methods have limited \u2026"}, {"title": "Can 3D Vision-Language Models Truly Understand Natural Language?", "link": "https://arxiv.org/pdf/2403.14760", "details": "W Deng, R Ding, J Yang, J Liu, Y Li, X Qi, E Ngai - arXiv preprint arXiv:2403.14760, 2024", "abstract": "Rapid advancements in 3D vision-language (3D-VL) tasks have opened up new avenues for human interaction with embodied agents or robots using natural language. Despite this progress, we find a notable limitation: existing 3D-VL models \u2026"}, {"title": "Adaptive Prompt Routing for Arbitrary Text Style Transfer with Pre-trained Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29832/31446", "details": "Q Liu, J Qin, W Ye, H Mou, Y He, K Wang - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Recently, arbitrary text style transfer (TST) has made significant progress with the paradigm of prompt learning. In this paradigm, researchers often design or search for a fixed prompt for any input. However, existing evidence shows that large language \u2026"}, {"title": "Emergent Abilities in Reduced-Scale Generative Language Models", "link": "https://arxiv.org/pdf/2404.02204", "details": "S Muckatira, V Deshpande, V Lialin, A Rumshisky - arXiv preprint arXiv:2404.02204, 2024", "abstract": "Large language models can solve new tasks without task-specific fine-tuning. This ability, also known as in-context learning (ICL), is considered an emergent ability and is primarily seen in large language models with billions of parameters. This study \u2026"}, {"title": "Prevalence and risk factors for long COVID among adults in Scotland using electronic health records: a national, retrospective, observational cohort study", "link": "https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370\\(24\\)00169-X/fulltext", "details": "K Jeffrey, L Woolford, R Maini, S Basetti, A Batchelor\u2026 - eClinicalMedicine, 2024", "abstract": "Background Long COVID is a debilitating multisystem condition. The objective of this study was to estimate the prevalence of long COVID in the adult population of Scotland, and to identify risk factors associated with its development. Methods In this \u2026"}, {"title": "Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language Models", "link": "https://arxiv.org/pdf/2403.13588", "details": "C Feng, Y Sun, K Li, P Zhou, J Lv, A Lu - arXiv preprint arXiv:2403.13588, 2024", "abstract": "As Pre-trained Language Models (PLMs), a popular approach for code intelligence, continue to grow in size, the computational cost of their usage has become prohibitively expensive. Prompt learning, a recent development in the field of natural \u2026"}, {"title": "Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models", "link": "https://arxiv.org/pdf/2403.11838", "details": "Y Luo, Z Lin, Y Zhang, J Sun, C Lin, C Xu, X Su, Y Shen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) exhibit impressive capabilities but also present risks such as biased content generation and privacy issues. One of the current alignment techniques includes principle-driven integration, but it faces challenges arising from \u2026"}, {"title": "mPLM-Sim: Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models", "link": "https://aclanthology.org/2024.findings-eacl.20.pdf", "details": "P Lin, C Hu, Z Zhang, AFT Martins, H Sch\u00fctze - Findings of the Association for \u2026, 2024", "abstract": "Recent multilingual pretrained language models (mPLMs) have been shown to encode strong language-specific signals, which are not explicitly provided during pretraining. It remains an open question whether it is feasible to employ mPLMs to \u2026"}, {"title": "XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception", "link": "https://arxiv.org/pdf/2403.14402", "details": "HJ Han, M Anwar, J Pino, WN Hsu, M Carpuat, B Shi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Speech recognition and translation systems perform poorly on noisy inputs, which are frequent in realistic environments. Augmenting these systems with visual signals has the potential to improve robustness to noise. However, audio-visual (AV) data is \u2026"}]
