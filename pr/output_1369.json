'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Impact of Preference Noise on the Alignment Performanc'
[{"title": "Infusing internalized knowledge of language models into hybrid prompts for knowledgeable dialogue generation", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124005082", "details": "J Bai, Z Yan, S Zhang, J Yang, H Guo, Z Li - Knowledge-Based Systems, 2024", "abstract": "Existing knowledge-grounded dialogue (KGD) systems access the knowledge from an external knowledge base, then generate the context-coherent response accordingly. However, the knowledge access capability is constrained to the scale of \u2026"}, {"title": "More Room for Language: Investigating the Effect of Retrieval on Language Models", "link": "https://arxiv.org/pdf/2404.10939", "details": "D Samuel, LGG Charpentier, S Wold - arXiv preprint arXiv:2404.10939, 2024", "abstract": "Retrieval-augmented language models pose a promising alternative to standard language modeling. During pretraining, these models search in a corpus of documents for contextually relevant information that could aid the language \u2026"}, {"title": "Special Section on Efficiency in Neural Information Retrieval", "link": "https://dl.acm.org/doi/full/10.1145/3641203", "details": "S Bruch, C Lucchese, M Maistro, FM Nardini - ACM Transactions on Information \u2026, 2024", "abstract": "The rise of deep neural networks and self-supervised learning in recent years have brought about a paradigm shift in Information Retrieval. From retrieval to ranking, question answering to recommendation, search to conversational agents, models \u2026"}, {"title": "Assessing readiness to use electronic health record data for outcome ascertainment in clinical trials\u2013A case study", "link": "https://www.sciencedirect.com/science/article/pii/S1551714424001551", "details": "D Esserman, EJ Greene, NK Latham, M Kane, C Lu\u2026 - Contemporary Clinical Trials, 2024", "abstract": "Background Variable data quality poses a challenge to using electronic health record (EHR) data to ascertain acute clinical outcomes in multi-site clinical trials. Differing EHR platforms and data comprehensiveness across clinical trial sites \u2026"}, {"title": "Speech Recognition for Indigenous Language Using Self-Supervised Learning and Natural Language Processing", "link": "https://www.scitepress.org/Papers/2024/123963/123963.pdf", "details": "S Tamura, T Hattori, Y Kato, N Noguchi", "abstract": "This paper proposes a new concept to build a speech recognition system for an indigenous under-resourced language, by using another speech recognizer for a major language as well as neural machine translation and text autoencoder \u2026"}, {"title": "A Primer on the Inner Workings of Transformer-based Language Models", "link": "https://arxiv.org/pdf/2405.00208", "details": "J Ferrando, G Sarti, A Bisazza, MR Costa-juss\u00e0 - arXiv preprint arXiv:2405.00208, 2024", "abstract": "The rapid progress of research aimed at interpreting the inner workings of advanced language models has highlighted a need for contextualizing the insights gained from years of work in this area. This primer provides a concise technical introduction to the \u2026"}, {"title": "Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation", "link": "https://arxiv.org/pdf/2404.11160", "details": "JL Espejel, MSY Alassan, M Bouhandi, W Dahhane\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have become the go-to solution for many Natural Language Processing (NLP) tasks due to their ability to tackle various problems and produce high-quality results. Specifically, they are increasingly used to automatically \u2026"}, {"title": "Construction of Domain-specified Japanese Large Language Model for Finance through Continual Pre-training", "link": "https://arxiv.org/pdf/2404.10555", "details": "M Hirano, K Imajo - arXiv preprint arXiv:2404.10555, 2024", "abstract": "Large language models (LLMs) are now widely used in various fields, including finance. However, Japanese financial-specific LLMs have not been proposed yet. Hence, this study aims to construct a Japanese financial-specific LLM through \u2026"}, {"title": "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval", "link": "https://arxiv.org/pdf/2404.18424", "details": "S Zhuang, X Ma, B Koopman, J Lin, G Zuccon - arXiv preprint arXiv:2404.18424, 2024", "abstract": "The current use of large language models (LLMs) for zero-shot document ranking follows one of two ways: 1) prompt-based re-ranking methods, which require no further training but are feasible for only re-ranking a handful of candidate documents \u2026"}]
