[{"title": "Exploration of Plan-Guided Summarization for Narrative Texts: the Case of Small Language Models", "link": "https://arxiv.org/pdf/2504.09071", "details": "M Grenander, S Varia, P Czarnowska, Y Vyas\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Plan-guided summarization attempts to reduce hallucinations in small language models (SLMs) by grounding generated summaries to the source text, typically by targeting fine-grained details such as dates or named entities. In this work, we \u2026"}, {"title": "The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer", "link": "https://arxiv.org/pdf/2504.10462", "details": "W Lei, J Wang, H Wang, X Li, JH Liew, J Feng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces SAIL, a single transformer unified multimodal large language model (MLLM) that integrates raw pixel encoding and language decoding within a singular architecture. Unlike existing modular MLLMs, which rely on a pre-trained \u2026"}, {"title": "Don't Deceive Me: Mitigating Gaslighting through Attention Reallocation in LMMs", "link": "https://arxiv.org/pdf/2504.09456", "details": "P Jiao, B Zhu, J Chen, CW Ngo, YG Jiang - arXiv preprint arXiv:2504.09456, 2025", "abstract": "Large Multimodal Models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks. However, their vulnerability to user gaslighting-the deliberate use of misleading or contradictory inputs-raises critical concerns about their reliability \u2026"}, {"title": "COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts", "link": "https://arxiv.org/pdf/2504.10158", "details": "J Li, X Zhang, H Zou, Y Guo, R Xu, Y Liu, C Zhu, Y He\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Current object detectors often suffer significant perfor-mance degradation in real- world applications when encountering distributional shifts. Consequently, the out-of- distribution (OOD) generalization capability of object detectors has garnered \u2026"}, {"title": "AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening", "link": "https://arxiv.org/pdf/2504.02870", "details": "FPW Lo, J Qiu, Z Wang, H Yu, Y Chen, G Zhang, B Lo - arXiv preprint arXiv \u2026, 2025", "abstract": "Resume screening is a critical yet time-intensive process in talent acquisition, requiring recruiters to analyze vast volume of job applications while remaining objective, accurate, and fair. With the advancements in Large Language Models \u2026"}, {"title": "HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs", "link": "https://arxiv.org/pdf/2504.09482", "details": "S Dasgupta, S Nath, A Basu, P Shamsolmoali, S Das - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have recently garnered widespread attention due to their adeptness at generating innovative responses to the given prompts across a multitude of domains. However, LLMs often suffer from the inherent limitation of \u2026"}, {"title": "Continual Multimodal Contrastive Learning", "link": "https://arxiv.org/pdf/2503.14963%3F", "details": "X Liu, X Xia, SK Ng, TS Chua - arXiv preprint arXiv:2503.14963, 2025", "abstract": "Multimodal contrastive learning (MCL) advances in aligning different modalities and generating multimodal representations in a joint space. By leveraging contrastive learning across diverse modalities, large-scale multimodal data enhances \u2026"}, {"title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning", "link": "https://arxiv.org/pdf/2504.09772", "details": "C Jin, H Peng, Q Zhang, Y Tang, DN Metaxas, T Che - arXiv preprint arXiv \u2026, 2025", "abstract": "Multi-agent systems (MAS) built on large language models (LLMs) offer a promising path toward solving complex, real-world tasks that single-agent systems often struggle to manage. While recent advancements in test-time scaling (TTS) have \u2026"}, {"title": "ELOQUENT CLEF Shared Tasks for Evaluation of Generative Language Model Quality, 2025 Edition", "link": "https://dl.acm.org/doi/abs/10.1007/978-3-031-88720-8_56", "details": "J Karlgren, E Artemova, O Bojar, V Mikhailov\u2026 - European Conference on \u2026, 2025", "abstract": "The ELOQUENT lab for evaluation of generative language model quality and usefulness addresses high-level quality criteria through a set of open-ended shared tasks implemented, where possible, to leverage the ability of systems built on \u2026"}]
