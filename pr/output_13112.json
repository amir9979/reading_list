[{"title": "A Chain-of-Thought Subspace Meta-Learning for Few-shot Image Captioning with Large Vision and Language Models", "link": "https://arxiv.org/pdf/2502.13942", "details": "H Huang, S Yuan, Y Hao, C Wen, Y Fang - arXiv preprint arXiv:2502.13942, 2025", "abstract": "A large-scale vision and language model that has been pretrained on massive data encodes visual and linguistic prior, which makes it easier to generate images and language that are more natural and realistic. Despite this, there is still a significant \u2026"}, {"title": "MCG-Net: Medical Chief Complaint-guided Multi-modal Masked Content Pre-training for chest image classification", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002829", "details": "L Zou, J Li, H Chen, M Liang, J Ke, Y Zhong, J Chen - Expert Systems with \u2026, 2025", "abstract": "Medical image classification plays a crucial role in disease diagnosis, personalized treatment, and clinical decision-making, with significant progress driven by deep learning (DL). However, DL's performance heavily relies on large-scale, accurately \u2026"}, {"title": "Language Models Can Predict Their Own Behavior", "link": "https://arxiv.org/pdf/2502.13329", "details": "D Ashok, J May - arXiv preprint arXiv:2502.13329, 2025", "abstract": "Autoregressive Language Models output text by sequentially predicting the next token to generate, with modern methods like Chain-of-Thought (CoT) prompting achieving state-of-the-art reasoning capabilities by scaling the number of generated \u2026"}, {"title": "Cross-space topological contrastive learning for knowledge graph-aware issue recommendation", "link": "https://link.springer.com/article/10.1007/s10115-025-02355-z", "details": "L Zhang, Y Shi, K Qi, D Wu, X Wang, Z Yan, Z Chen - Knowledge and Information \u2026, 2025", "abstract": "Opensource communities utilize issues to promote knowledge sharing and discussions among developers. However, as the community scales, the number of issues increases dramatically. To ensure efficient circulation of issues and improve \u2026"}, {"title": "ConceptCLIP: Towards Trustworthy Medical AI via Concept-Enhanced Contrastive Langauge-Image Pre-training", "link": "https://arxiv.org/pdf/2501.15579", "details": "Y Nie, S He, Y Bie, Y Wang, Z Chen, S Yang, H Chen - arXiv preprint arXiv \u2026, 2025", "abstract": "Trustworthiness is essential for the precise and interpretable application of artificial intelligence (AI) in medical imaging. Traditionally, precision and interpretability have been addressed as separate tasks, namely medical image analysis and explainable \u2026"}, {"title": "Engaging Preference Optimization Alignment in Large Language Model for Continual Radiology Report Generation: A Hybrid Approach", "link": "https://link.springer.com/article/10.1007/s12559-025-10404-6", "details": "A Izhar, N Idris, N Japar - Cognitive Computation, 2025", "abstract": "Large language models (LLMs) remain relatively underutilized in medical imaging, particularly in radiology, which is essential for disease diagnosis and management. Nonetheless, radiology report generation (RRG) is a time-consuming task that can \u2026"}, {"title": "Cross-modal Augmented Transformer for Automated Medical Report Generation", "link": "https://ieeexplore.ieee.org/iel8/6221039/6563131/10857391.pdf", "details": "Y Tang, Y Yuan, F Tao, M Tang - IEEE Journal of Translational Engineering in Health \u2026, 2025", "abstract": "In clinical practice, interpreting medical images and composing diagnostic reports typically involve significant manual workload. Therefore, an automated report generation framework that mimics a doctor's diagnosis better meets the requirements \u2026"}, {"title": "Large Language Model Approach for Zero-Shot Information Extraction and Clustering of Japanese Radiology Reports: Algorithm Development and Validation", "link": "https://cancer.jmir.org/2025/1/e57275/", "details": "Y Yamagishi, Y Nakamura, S Hanaoka, O Abe - JMIR cancer, 2025", "abstract": "Background: The application of natural language processing in medicine has increased significantly, including tasks such as information extraction and classification. Natural language processing plays a crucial role in structuring free \u2026"}, {"title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models", "link": "https://arxiv.org/pdf/2502.10250", "details": "GK Kumar, I Chaabane, K Wu - arXiv preprint arXiv:2502.10250, 2025", "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved \u2026"}]
