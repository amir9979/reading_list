[{"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "Bilingual Evaluation of Language Models on General Knowledge in University Entrance Exams with Minimal Contamination", "link": "https://arxiv.org/pdf/2409.12746", "details": "ES Salido, R Morante, J Gonzalo, G Marco\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this article we present UNED-ACCESS 2024, a bilingual dataset that consists of 1003 multiple-choice questions of university entrance level exams in Spanish and English. Questions are originally formulated in Spanish and translated manually into \u2026"}, {"title": "Effective prompt extraction from language models", "link": "https://openreview.net/pdf%3Fid%3D0o95CVdNuz", "details": "Y Zhang, N Carlini, D Ippolito - First Conference on Language Modeling, 2024", "abstract": "The text generated by large language models is commonly controlled by prompting, where a prompt prepended to a user's query guides the model's output. The prompts used by companies to guide their models are often treated as secrets, to be hidden \u2026"}, {"title": "Exploring and Enhancing the Transfer of Distribution in Knowledge Distillation for Autoregressive Language Models", "link": "https://arxiv.org/pdf/2409.12512", "details": "J Rao, X Liu, Z Lin, L Ding, J Li, D Tao - arXiv preprint arXiv:2409.12512, 2024", "abstract": "Knowledge distillation (KD) is a technique that compresses large teacher models by training smaller student models to mimic them. The success of KD in auto-regressive language models mainly relies on Reverse KL for mode-seeking and student \u2026"}, {"title": "SPARK: Multi-Vision Sensor Perception and Reasoning Benchmark for Large-scale Vision-Language Models", "link": "https://arxiv.org/pdf/2408.12114", "details": "Y Yu, S Chung, BK Lee, YM Ro - arXiv preprint arXiv:2408.12114, 2024", "abstract": "Large-scale Vision-Language Models (LVLMs) have significantly advanced with text- aligned vision inputs. They have made remarkable progress in computer vision tasks by aligning text modality with vision inputs. There are also endeavors to incorporate \u2026"}, {"title": "Evaluating Attribute Comprehension in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.13898", "details": "H Zhang, Z Yang, Y Liu, X Wang, Z He, K Liang, Z Ma - arXiv preprint arXiv \u2026, 2024", "abstract": "Currently, large vision-language models have gained promising progress on many downstream tasks. However, they still suffer many challenges in fine-grained visual understanding tasks, such as object attribute comprehension. Besides, there have \u2026"}, {"title": "Training Language Models to Self-Correct via Reinforcement Learning", "link": "https://arxiv.org/pdf/2409.12917", "details": "A Kumar, V Zhuang, R Agarwal, Y Su, JD Co-Reyes\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-correction is a highly desirable capability of large language models (LLMs), yet it has consistently been found to be largely ineffective in modern LLMs. Existing approaches for training self-correction either require multiple models or rely on a \u2026"}, {"title": "Understanding Defects in Generated Codes by Language Models", "link": "https://arxiv.org/pdf/2408.13372", "details": "AM Esfahani, N Kahani, SA Ajila - arXiv preprint arXiv:2408.13372, 2024", "abstract": "This study investigates the reliability of code generation by Large Language Models (LLMs), focusing on identifying and analyzing defects in the generated code. Despite the advanced capabilities of LLMs in automating code generation, ensuring the \u2026"}, {"title": "Poly-Visual-Expert Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3D7QaEO9WYMa", "details": "X Fan, T Ji, S Li, S Jin, S Song, J Wang, B Hong\u2026 - First Conference on Language \u2026", "abstract": "Current large vision-language models (VLMs) frequently face challenges such as the limited capabilities of a single visual component and the excessive length of visual tokens. These issues can limit the model's ability to interpret complex visual \u2026"}]
