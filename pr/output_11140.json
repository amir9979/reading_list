[{"title": "Distilling Large Language Models for Efficient Clinical Information Extraction", "link": "https://arxiv.org/pdf/2501.00031", "details": "KS Vedula, A Gupta, A Swaminathan, I Lopez, S Bedi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) excel at clinical information extraction but their computational demands limit practical deployment. Knowledge distillation--the process of transferring knowledge from larger to smaller models--offers a potential \u2026"}, {"title": "Contextualized race and ethnicity annotations for clinical text from MIMIC-III", "link": "https://search.proquest.com/openview/6bc23dba101d21a98bf23c696190c1cb/1%3Fpq-origsite%3Dgscholar%26cbl%3D2041912", "details": "J Li, J Joseph, S Kinberg, LR Richter, S Crusco\u2026", "abstract": "Observational health research often relies on accurate and complete race and ethnicity (RE) patient information, such as characterizing cohorts, assessing quality/performance metrics of hospitals and health systems, and identifying health \u2026"}, {"title": "Improving How Caregivers of People Living With Dementia Are Identified in the Electronic Health Record: Qualitative Study and Exploratory Chart Review", "link": "https://aging.jmir.org/2024/1/e59584", "details": "AR Green, CM Boyd, RQ Rosado, AE Daddato\u2026 - JMIR aging, 2024", "abstract": "Background Family and unpaid caregivers play a crucial role in supporting people living with dementia; yet, they are not systematically identified and documented by health systems. Objective The aims of the study are to determine the extent to which \u2026"}]
