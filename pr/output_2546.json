[{"title": "In-Context Learning of Physical Properties: Few-Shot Adaptation to Out-of-Distribution Molecular Graphs", "link": "https://arxiv.org/pdf/2406.01808", "details": "G Kaszuba, AD Naghdi, D Massa, S Papanikolaou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models manifest the ability of few-shot adaptation to a sequence of provided examples. This behavior, known as in-context learning, allows for performing nontrivial machine learning tasks during inference only. In this work, we \u2026"}, {"title": "LIDAO: Towards Limited Interventions for Debiasing (Large) Language Models", "link": "https://arxiv.org/pdf/2406.00548", "details": "T Liu, H Wang, S Wang, Y Cheng, J Gao - arXiv preprint arXiv:2406.00548, 2024", "abstract": "Large language models (LLMs) have achieved impressive performance on various natural language generation tasks. Nonetheless, they suffer from generating negative and harmful contents that are biased against certain demographic groups \u2026"}]
