[{"title": "MFC-Bench: Benchmarking Multimodal Fact-Checking with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2406.11288", "details": "S Wang, H Lin, Z Luo, Z Ye, G Chen, J Ma - arXiv preprint arXiv:2406.11288, 2024", "abstract": "Large vision-language models (LVLMs) have significantly improved multimodal reasoning tasks, such as visual question answering and image captioning. These models embed multimodal facts within their parameters, rather than relying on \u2026"}, {"title": "X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions", "link": "https://arxiv.org/pdf/2405.19744", "details": "C Li, W Yang, J Zhang, J Lu, S Wang, C Zong - arXiv preprint arXiv:2405.19744, 2024", "abstract": "Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples \u2026"}, {"title": "Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to Searching for the Most Promising Intermediate Thought", "link": "https://openreview.net/pdf%3Fid%3DCpcaL75UgY", "details": "ZY Zhang, S Han, H Yao, G Niu, M Sugiyama - Forty-first International Conference on \u2026", "abstract": "To improve the ability of the large language model (LLMs) to tackle complex reasoning problems, chain-of-thoughts (CoT) methods were proposed to guide LLMs to reason step-by-step, enabling problem solving from simple to complex. State-of \u2026"}, {"title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment", "link": "https://arxiv.org/pdf/2405.19332", "details": "S Zhang, D Yu, H Sharma, Z Yang, S Wang, H Hassan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed \u2026"}, {"title": "Does your data spark joy? Performance gains from domain upsampling at the end of training", "link": "https://arxiv.org/pdf/2406.03476", "details": "C Blakeney, M Paul, BW Larsen, S Owen, J Frankle - arXiv preprint arXiv:2406.03476, 2024", "abstract": "Pretraining datasets for large language models (LLMs) have grown to trillions of tokens composed of large amounts of CommonCrawl (CC) web scrape along with smaller, domain-specific datasets. It is expensive to understand the impact of these \u2026"}, {"title": "Privacy-Aware Visual Language Models", "link": "https://arxiv.org/pdf/2405.17423", "details": "L Samson, N Barazani, S Ghebreab, YM Asano - arXiv preprint arXiv:2405.17423, 2024", "abstract": "This paper aims to advance our understanding of how Visual Language Models (VLMs) handle privacy-sensitive information, a crucial concern as these technologies become integral to everyday life. To this end, we introduce a new benchmark \u2026"}, {"title": "Self-Hint Prompting Improves Zero-shot Reasoning in Large Language Models via Reflective Cycle", "link": "https://escholarship.org/content/qt5ht3f0dt/qt5ht3f0dt_noSplash_508be8c9920e4bd796bec268a73a6b1a.pdf", "details": "J Chen, J Tian, Y Jin - Proceedings of the Annual Meeting of the Cognitive \u2026, 2024", "abstract": "Chain-of-Thought (CoT) has brought a fresh perspective to improve the reasoning ability of large language models (LLMs). To relieve the burden of manual design in CoT, Zero-shot CoT has pioneered a direct interaction with LLMs. Based on it \u2026"}, {"title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2405.18218", "details": "Y Zhang, Y Li, X Wang, Q Shen, B Plank, B Bischl\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Overparametrized transformer networks are the state-of-the-art architecture for Large Language Models (LLMs). However, such models contain billions of parameters making large compute a necessity, while raising environmental concerns. To \u2026"}, {"title": "Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts", "link": "https://arxiv.org/pdf/2406.12034", "details": "J Kang, L Karlinsky, H Luo, Z Wang, J Hansen, J Glass\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present Self-MoE, an approach that transforms a monolithic LLM into a compositional, modular system of self-specialized experts, named MiXSE (MiXture of Self-specialized Experts). Our approach leverages self-specialization, which \u2026"}]
