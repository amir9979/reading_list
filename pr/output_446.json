'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [On the Multilingual Ability of Decoder-based Pre-trai'
[{"title": "Emergent Abilities in Reduced-Scale Generative Language Models", "link": "https://arxiv.org/html/2404.02204v1", "details": "S Muckatira, V Deshpande, V Lialin, A Rumshisky - arXiv preprint arXiv:2404.02204, 2024", "abstract": "Large language models can solve new tasks without task-specific fine-tuning. This ability, also known as in-context learning (ICL), is considered an emergent ability and is primarily seen in large language models with billions of parameters. This study \u2026"}, {"title": "Sailor: Open Language Models for South-East Asia", "link": "https://arxiv.org/pdf/2404.03608", "details": "L Dou, Q Liu, G Zeng, J Guo, J Zhou, W Lu, M Lin - arXiv preprint arXiv:2404.03608, 2024", "abstract": "We present Sailor, a family of open language models ranging from 0.5 B to 7B parameters, tailored for South-East Asian (SEA) languages. These models are continually pre-trained from Qwen1. 5, a great language model for multilingual use \u2026"}, {"title": "Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models", "link": "https://arxiv.org/pdf/2404.02575", "details": "H Chae, Y Kim, S Kim, KT Ong, B Kwak, M Kim, S Kim\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Algorithmic reasoning refers to the ability to understand the complex patterns behind the problem and decompose them into a sequence of reasoning steps towards the solution. Such nature of algorithmic reasoning makes it a challenge for large \u2026"}, {"title": "$\\texttt {LM}^\\texttt {2} $: A Simple Society of Language Models Solves Complex Reasoning", "link": "https://arxiv.org/html/2404.02255v1", "details": "G Juneja, S Dutta, T Chakraborty - arXiv preprint arXiv:2404.02255, 2024", "abstract": "Despite demonstrating emergent reasoning abilities, Large Language Models (LLMS) often lose track of complex, multi-step reasoning. Existing studies show that providing guidance via decomposing the original question into multiple subproblems \u2026"}, {"title": "Identifying prognostic factors for survival in intensive care unit patients with SIRS or sepsis by machine learning analysis on electronic health records", "link": "https://journals.plos.org/digitalhealth/article%3Fid%3D10.1371/journal.pdig.0000459", "details": "M Mollura, D Chicco, A Paglialonga, R Barbieri - PLOS Digital Health, 2024", "abstract": "Background Systemic inflammatory response syndrome (SIRS) and sepsis are the most common causes of in-hospital death. However, the characteristics associated with the improvement in the patient conditions during the ICU stay were not fully \u2026"}, {"title": "Identifying data-driven subtypes of major depressive disorder with electronic health records", "link": "https://www.sciencedirect.com/science/article/pii/S0165032724005858", "details": "A Sharma, PF Verhaak, TH McCoy, RH Perlis\u2026 - Journal of Affective \u2026, 2024", "abstract": "Background Efforts to reduce the heterogeneity of major depressive disorder (MDD) by identifying subtypes have not yet facilitated treatment personalization or investigation of biology, so novel approaches merit consideration. Methods We \u2026"}, {"title": "An Incomplete Loop: Deductive, Inductive, and Abductive Learning in Large Language Models", "link": "https://arxiv.org/pdf/2404.03028", "details": "E Liu, G Neubig, J Andreas - arXiv preprint arXiv:2404.03028, 2024", "abstract": "Modern language models (LMs) can learn to perform new tasks in different ways: in instruction following, the target task is described explicitly in natural language; in few- shot prompting, the task is specified implicitly with a small number of examples; in \u2026"}, {"title": "Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra", "link": "https://arxiv.org/pdf/2404.03647", "details": "D Kevian, U Syed, X Guo, A Havens, G Dullerud\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra in solving undergraduate-level control problems. Controls provides an interesting case study \u2026"}, {"title": "Automatic Prompt Selection for Large Language Models", "link": "https://arxiv.org/html/2404.02717v1", "details": "VT Do, VK Hoang, DH Nguyen, S Sabahi, J Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) can perform various natural language processing tasks with suitable instruction prompts. However, designing effective prompts manually is challenging and time-consuming. Existing methods for automatic prompt \u2026"}]
