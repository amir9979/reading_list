[{"title": "ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data", "link": "https://arxiv.org/pdf/2505.10083", "details": "C Wang, Q Qi, Z Rao, L Pan, J Wang, J Liao - arXiv preprint arXiv:2505.10083, 2025", "abstract": "Conventional forecasting methods rely on unimodal time series data, limiting their ability to exploit rich textual information. Recently, large language models (LLMs) and time series foundation models (TSFMs) have demonstrated powerful capability \u2026"}, {"title": "DiffODE: Neural ODE with Differentiable Hidden State for Irregular Time Series Analysis", "link": "https://www.computer.org/csdl/proceedings-article/icde/2025/360300c107/26FZAEab0hq", "details": "Y Zhang, X Wang, X Yu, Z Zhou, X Xu, L Bai, Y Wang - 2025 IEEE 41st International \u2026, 2025", "abstract": "Irregular time series analysis is increasingly essential in data management due to the proliferation of complex data irregularly sampled by real-world systems. Traditional time series models, including RNN-based models and transformer \u2026"}, {"title": "Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis", "link": "https://arxiv.org/pdf/2505.10046", "details": "B Tang, B Zheng, X Pan, S Paul, S Xie - arXiv preprint arXiv:2505.10046, 2025", "abstract": "This paper does not describe a new method; instead, it provides a thorough exploration of an important yet understudied design space related to recent advances in text-to-image synthesis--specifically, the deep fusion of large language \u2026"}]
