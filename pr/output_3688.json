[{"title": "The Epistemic Uncertainty Hole: an issue of Bayesian Neural Networks", "link": "https://arxiv.org/pdf/2407.01985", "details": "M Fellaji, F Pennerath - arXiv preprint arXiv:2407.01985, 2024", "abstract": "Bayesian Deep Learning (BDL) gives access not only to aleatoric uncertainty, as standard neural networks already do, but also to epistemic uncertainty, a measure of confidence a model has in its own predictions. In this article, we show through \u2026"}, {"title": "Improving Zero-shot Generalization of Learned Prompts via Unsupervised Knowledge Distillation", "link": "https://arxiv.org/pdf/2407.03056", "details": "M Mistretta, A Baldrati, M Bertini, AD Bagdanov - arXiv preprint arXiv:2407.03056, 2024", "abstract": "Vision-Language Models (VLMs) demonstrate remarkable zero-shot generalization to unseen tasks, but fall short of the performance of supervised methods in generalizing to downstream tasks with limited data. Prompt learning is emerging as a \u2026"}, {"title": "Improving the Evaluation and Actionability of Explanation Methods for Multivariate Time Series Classification", "link": "https://ui.adsabs.harvard.edu/abs/2024arXiv240612507I/abstract", "details": "D Italo Serramazza, T Le Nguyen, G Ifrim - arXiv e-prints, 2024", "abstract": "Abstract Explanation for Multivariate Time Series Classification (MTSC) is an important topic that is under explored. There are very few quantitative evaluation methodologies and even fewer examples of actionable explanation, where the \u2026"}]
