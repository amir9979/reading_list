[{"title": "Comparing step counting algorithms for high-resolution wrist accelerometry data in older adults in the ARIC study", "link": "https://academic.oup.com/biomedgerontology/advance-article/doi/10.1093/gerona/glaf034/8019831", "details": "S Gao, X Zhou, L Koffman, AA Wanigatunga\u2026 - The Journals of Gerontology \u2026, 2025", "abstract": "Background Step counting from wrist accelerometry data is widely used in physical activity research and practice. While several open-source algorithms can estimate steps from high-resolution accelerometry data, there is a critical need to compare \u2026"}, {"title": "MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification", "link": "https://arxiv.org/pdf/2502.04515", "details": "W Fan, J Fei, D Guo, K Yi, X Song, H Xiang, H Ye, M Li - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical time series has been playing a vital role in real-world healthcare systems as valuable information in monitoring health conditions of patients. Accurate classification for medical time series, eg, Electrocardiography (ECG) signals, can \u2026"}, {"title": "GL-MCM: Global and Local Maximum Concept Matching for Zero-Shot Out-of-Distribution Detection", "link": "https://link.springer.com/article/10.1007/s11263-025-02356-z", "details": "A Miyai, Q Yu, G Irie, K Aizawa - International Journal of Computer Vision, 2025", "abstract": "Zero-shot OOD detection is a task that detects OOD images during inference with only in-distribution (ID) class names. Existing methods assume ID images contain a single, centered object, and do not consider the more realistic multi-object scenarios \u2026"}, {"title": "IMTS-Mixer: Mixer-Networks for Irregular Multivariate Time Series Forecasting", "link": "https://arxiv.org/pdf/2502.11816", "details": "C Kl\u00f6tergens, T Dernedde, L Schmidt-Thieme - arXiv preprint arXiv:2502.11816, 2025", "abstract": "Forecasting Irregular Multivariate Time Series (IMTS) has recently emerged as a distinct research field, necessitating specialized models to address its unique challenges. While most forecasting literature assumes regularly spaced observations \u2026"}, {"title": "From Deep Additive Kernel Learning to Last-Layer Bayesian Neural Networks via Induced Prior Approximation", "link": "https://arxiv.org/pdf/2502.10540", "details": "W Zhao, H Chen, T Liu, R Tuo, C Tian - arXiv preprint arXiv:2502.10540, 2025", "abstract": "With the strengths of both deep learning and kernel methods like Gaussian Processes (GPs), Deep Kernel Learning (DKL) has gained considerable attention in recent years. From the computational perspective, however, DKL becomes \u2026"}, {"title": "Efficient Few-Shot Continual Learning in Vision-Language Models", "link": "https://arxiv.org/pdf/2502.04098", "details": "A Panos, R Aljundi, DO Reino, RE Turner - arXiv preprint arXiv:2502.04098, 2025", "abstract": "Vision-language models (VLMs) excel in tasks such as visual question answering and image captioning. However, VLMs are often limited by their use of pretrained image encoders, like CLIP, leading to image understanding errors that hinder overall \u2026"}, {"title": "A transformer-based dual contrastive learning approach for zero-shot learning", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225002024", "details": "Y Lei, R Jing, F Li, Q Gao, C Deng - Neurocomputing, 2025", "abstract": "The goal of zero-shot learning is to utilize attribute information for seen classes so as to generalize the learned knowledge to unseen classes. However, current algorithms often overlook the fact that the same attribute may exhibit different visual features \u2026"}, {"title": "DISD-Net: A Dynamic Interactive Network with Self-distillation for Cross-subject Multi-modal Emotion Recognition", "link": "https://ieeexplore.ieee.org/abstract/document/10857425/", "details": "C Cheng, W Liu, X Wang, L Feng, Z Jia - IEEE Transactions on Multimedia, 2025", "abstract": "Multi-modal Emotion Recognition (MER) has demonstrated competitive performance in affective computing, owing to synthesizing information from diverse modalities. However, many existing approaches still face unresolved challenges, such as:(i) how \u2026"}, {"title": "NoRD: A framework for noise-resilient self-distillation through relative supervision", "link": "https://link.springer.com/article/10.1007/s10489-025-06355-y", "details": "S Sharma, SS Lodhi, V Srivastava, J Chandra - Applied Intelligence, 2025", "abstract": "Abstract Knowledge distillation (KD) has become a pivotal technique in deep learning, facilitating model compression and regularization by transferring knowledge from one neural network to another, enhancing its capabilities for \u2026"}]
