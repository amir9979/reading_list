[{"title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer", "link": "https://arxiv.org/pdf/2408.01402", "details": "Y Yang, P Xu - arXiv preprint arXiv:2408.01402, 2024", "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in offline reinforcement learning (RL) tasks, leveraging pre-collected datasets and Transformer's capability to model long sequences. Recent works have demonstrated \u2026"}, {"title": "Exploring Universal Intrinsic Task Subspace for Few-shot Learning via Prompt Tuning", "link": "https://ieeexplore.ieee.org/iel8/6570655/6633080/10603438.pdf", "details": "Y Qin, X Wang, Y Su, Y Lin, N Ding, J Yi, W Chen, Z Liu\u2026 - IEEE/ACM Transactions on \u2026, 2024", "abstract": "Why can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidence indicating that the adaptations of PLMs to various fewshot \u2026"}, {"title": "An Empirical Evaluation of the Zero-shot, Few-shot, and Traditional Fine-tuning Based Pretrained Language Models for Sentiment Analysis in Software Engineering", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10623654.pdf", "details": "M Shafikuzzaman, MR Islam, AC Rolli, S Akhter\u2026 - IEEE Access, 2024", "abstract": "Recent advances in natural language processing (NLP) have led to the development of revolutionized pretrained language models (PLMs) impacting various NLP tasks, including sentiment analysis in software engineering. Choosing the right PLMs is \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}, {"title": "Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement", "link": "https://arxiv.org/pdf/2408.03092", "details": "L Yu, B Yu, H Yu, F Huang, Y Li - arXiv preprint arXiv:2408.03092, 2024", "abstract": "Merging Large Language Models (LLMs) aims to amalgamate multiple homologous LLMs into one with all the capabilities. Ideally, any LLMs sharing the same backbone should be mergeable, irrespective of whether they are Fine-Tuned (FT) with minor \u2026"}, {"title": "Mitigating Entity-Level Hallucination in Large Language Models", "link": "https://arxiv.org/pdf/2407.09417%3Ftrk%3Dpublic_post_comment-text", "details": "W Su, Y Tang, Q Ai, C Wang, Z Wu, Y Liu - arXiv preprint arXiv:2407.09417, 2024", "abstract": "The emergence of Large Language Models (LLMs) has revolutionized how users access information, shifting from traditional search engines to direct question-and- answer interactions with LLMs. However, the widespread adoption of LLMs has \u2026"}, {"title": "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching", "link": "https://arxiv.org/pdf/2407.17349", "details": "Y Ding, H Hu, J Zhou, Q Chen, B Jiang, L He - arXiv preprint arXiv:2407.17349, 2024", "abstract": "With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem \u2026"}, {"title": "Counterfactual Explanations for Medical Image Classification and Regression using Diffusion Autoencoder", "link": "https://arxiv.org/pdf/2408.01571", "details": "M Atad, D Schinz, H Moeller, R Graf, B Wiestler\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Counterfactual explanations (CEs) aim to enhance the interpretability of machine learning models by illustrating how alterations in input features would affect the resulting predictions. Common CE approaches require an additional model and are \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}]
