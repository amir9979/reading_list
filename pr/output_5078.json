[{"title": "Skip\\n: A simple method to reduce hallucination in large vision-language models", "link": "https://oar.a-star.edu.sg/storage/d/d66g61dkp7/nn-bias-in-visual-language-models-camera-ready.pdf", "details": "Z Han, Z Bai, H Mei, Q Xu, C Zhang, MZ Shou - arXiv preprint arXiv:2402.01345, 2024", "abstract": "Recent advancements in large vision-language models (LVLMs) have demonstrated impressive capability in visual information understanding with human language. Despite these advances, LVLMs still face challenges with multimodal hallucination \u2026"}, {"title": "Re-Envisioning Electronic Health Records to Optimize Patient-Centered Cancer Care, Quality, Surveillance, and Research", "link": "https://ascopubs.org/doi/pdfdirect/10.1200/OP.24.00260", "details": "AP Singh, EP Balogh, RW Carlson, MM Huizinga\u2026 - JCO Oncology Practice, 2024", "abstract": "Electronic health records (EHRs) are a significant advancement over paper records. However, the full potential of EHRs for improving care quality, patient outcomes, surveillance, and research in cancer care is yet to be realized. The organic evolution \u2026"}, {"title": "Accuracy and transportability of machine learning models for adolescent suicide prediction with longitudinal clinical records", "link": "https://www.nature.com/articles/s41398-024-03034-3", "details": "C Zang, Y Hou, D Lyu, J Jin, S Sacco, K Chen\u2026 - Translational psychiatry, 2024", "abstract": "Abstract Machine Learning models trained from real-world data have demonstrated promise in predicting suicide attempts in adolescents. However, their transportability, namely the performance of a model trained on one dataset and applied to different \u2026"}, {"title": "Solving Robotics Problems in Zero-Shot with Vision-Language Models", "link": "https://arxiv.org/pdf/2407.19094", "details": "Z Wang, R Shen, B Stadie - arXiv preprint arXiv:2407.19094, 2024", "abstract": "We introduce Wonderful Team, a multi-agent visual LLM (VLLM) framework for solving robotics problems in the zero-shot regime. By zero-shot we mean that, for a novel environment, we feed a VLLM an image of the robot's environment and a \u2026"}, {"title": "Pre-training data selection for biomedical domain adaptation using journal impact metrics", "link": "https://aclanthology.org/2024.bionlp-1.27.pdf", "details": "M Lai-king, P Paroubek - Proceedings of the 23rd Workshop on Biomedical \u2026, 2024", "abstract": "Abstract Domain adaptation is a widely used method in natural language processing (NLP) to improve the performance of a language model within a specific domain. This method is particularly common in the biomedical domain, which sees regular \u2026"}, {"title": "Overview of the First Shared Task on Clinical Text Generation: RRG24 and \u201cDischarge Me!\u201d", "link": "https://aclanthology.org/2024.bionlp-1.7.pdf", "details": "J Xu, Z Chen, A Johnston, L Blankemeier, M Varma\u2026 - Proceedings of the 23rd \u2026, 2024", "abstract": "Recent developments in natural language generation have tremendous implications for healthcare. For instance, state-of-the-art systems could automate the generation of sections in clinical reports to alleviate physician workload and streamline hospital \u2026"}, {"title": "Exploring Universal Intrinsic Task Subspace for Few-shot Learning via Prompt Tuning", "link": "https://ieeexplore.ieee.org/iel8/6570655/6633080/10603438.pdf", "details": "Y Qin, X Wang, Y Su, Y Lin, N Ding, J Yi, W Chen, Z Liu\u2026 - IEEE/ACM Transactions on \u2026, 2024", "abstract": "Why can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidence indicating that the adaptations of PLMs to various fewshot \u2026"}]
