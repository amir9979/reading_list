[{"title": "Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation", "link": "https://arxiv.org/pdf/2504.12108", "details": "S Cai, L Ding, D Tao - arXiv preprint arXiv:2504.12108, 2025", "abstract": "The rapid development of Large Language Models (LLMs) has intensified concerns about content traceability and potential misuse. Existing watermarking schemes for sampled text often face trade-offs between maintaining text quality and ensuring \u2026"}, {"title": "Multilingual Contextualization of Large Language Models for Document-Level Machine Translation", "link": "https://arxiv.org/pdf/2504.12140", "details": "MM Ramos, P Fernandes, S Agrawal, AFT Martins - arXiv preprint arXiv:2504.12140, 2025", "abstract": "Large language models (LLMs) have demonstrated strong performance in sentence- level machine translation, but scaling to document-level translation remains challenging, particularly in modeling long-range dependencies and discourse \u2026"}]
