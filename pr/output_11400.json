[{"title": "Language Models as Continuous Self-Evolving Data Engineers", "link": "https://arxiv.org/pdf/2412.15151%3F", "details": "P Wang, M Wang, Z Ma, X Yang, S Feng, D Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert \u2026"}, {"title": "MetaRuleGPT: Recursive Numerical Reasoning of Language Models Trained with Simple Rules", "link": "https://arxiv.org/pdf/2412.13536", "details": "K Chen, L Wang, Q Zhang, R Xu - arXiv preprint arXiv:2412.13536, 2024", "abstract": "Recent studies have highlighted the limitations of large language models in mathematical reasoning, particularly their inability to capture the underlying logic. Inspired by meta-learning, we propose that models should acquire not only task \u2026"}, {"title": "FastVLM: Efficient Vision Encoding for Vision Language Models", "link": "https://arxiv.org/pdf/2412.13303", "details": "PKA Vasu, F Faghri, CL Li, C Koc, N True, A Antony\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Scaling the input image resolution is essential for enhancing the performance of Vision Language Models (VLMs), particularly in text-rich image understanding tasks. However, popular visual encoders such as ViTs become inefficient at high \u2026"}, {"title": "Are Vision-Language Models Truly Understanding Multi-vision Sensor?", "link": "https://arxiv.org/pdf/2412.20750", "details": "S Chung, Y Yu, Y Chee, SY Kim, BK Lee, YM Ro - arXiv preprint arXiv:2412.20750, 2024", "abstract": "Large-scale Vision-Language Models (VLMs) have advanced by aligning vision inputs with text, significantly improving performance in computer vision tasks. Moreover, for VLMs to be effectively utilized in real-world applications, an \u2026"}, {"title": "Unveiling Visual Perception in Language Models: An Attention Head Analysis Approach", "link": "https://arxiv.org/pdf/2412.18108", "details": "J Bi, J Guo, Y Tang, LB Wen, Z Liu, C Xu - arXiv preprint arXiv:2412.18108, 2024", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated remarkable progress in visual understanding. This impressive leap raises a compelling question: how can language models, initially trained solely on \u2026"}, {"title": "From Models to Microtheories: Distilling a Model's Topical Knowledge for Grounded Question Answering", "link": "https://arxiv.org/pdf/2412.17701", "details": "N Weir, BD Mishra, O Weller, O Tafjord, S Hornstein\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent reasoning methods (eg, chain-of-thought, entailment reasoning) help users understand how language models (LMs) answer a single question, but they do little to reveal the LM's overall understanding, or\" theory,\" about the question's $\\textit \u2026"}, {"title": "B-AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Black-box Adversarial Visual-Instructions", "link": "https://ieeexplore.ieee.org/abstract/document/10816024/", "details": "H Zhang, W Shao, H Liu, Y Ma, P Luo, Y Qiao, N Zheng\u2026 - IEEE Transactions on \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have shown significant progress in responding well to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent \u2026"}, {"title": "Aligning Crowd-Sourced Human Feedback for Reinforcement Learning on Code Generation by Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10818581/", "details": "MF Wong, CW Tan - IEEE Transactions on Big Data, 2024", "abstract": "This paper studies how AI-assisted programming and large language models (LLM) improve software developers' ability via AI tools (LLM agents) like Github Copilot and Amazon CodeWhisperer, while integrating human feedback to enhance \u2026"}, {"title": "Adaptive Pruning for Large Language Models with Structural Importance Awareness", "link": "https://arxiv.org/pdf/2412.15127", "details": "H Zheng, J Ren, Y Sun, R Zhang, W Zhang, Z Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The recent advancements in large language models (LLMs) have significantly improved language understanding and generation capabilities. However, it is difficult to deploy LLMs on resource-constrained edge devices due to their high \u2026"}]
