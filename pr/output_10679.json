[{"title": "The potential of Generative Pre-trained Transformer 4 (GPT-4) to analyse medical notes in three different languages: a retrospective model-evaluation study", "link": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500\\(24\\)00246-2/fulltext", "details": "MCS Menezes, AF Hoffmann, ALM Tan, M Nalbandyan\u2026 - The Lancet Digital Health, 2025", "abstract": "Background Patient notes contain substantial information but are difficult for computers to analyse due to their unstructured format. Large-language models (LLMs), such as Generative Pre-trained Transformer 4 (GPT-4), have changed our \u2026"}, {"title": "Differentially Private Federated Learning of Diffusion Models for Synthetic Tabular Data Generation", "link": "https://arxiv.org/pdf/2412.16083", "details": "T Sattarov, M Schreyer, D Borth - arXiv preprint arXiv:2412.16083, 2024", "abstract": "The increasing demand for privacy-preserving data analytics in finance necessitates solutions for synthetic data generation that rigorously uphold privacy standards. We introduce DP-Fed-FinDiff framework, a novel integration of Differential Privacy \u2026"}, {"title": "Offline Reinforcement Learning for LLM Multi-Step Reasoning", "link": "https://arxiv.org/pdf/2412.16145", "details": "H Wang, S Hao, H Dong, S Zhang, Y Bao, Z Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Improving the multi-step reasoning ability of large language models (LLMs) with offline reinforcement learning (RL) is essential for quickly adapting them to complex tasks. While Direct Preference Optimization (DPO) has shown promise in aligning \u2026"}, {"title": "Re-evaluating Group Robustness via Adaptive Class-Specific Scaling", "link": "https://arxiv.org/pdf/2412.15311", "details": "S Seo, B Han - arXiv preprint arXiv:2412.15311, 2024", "abstract": "Group distributionally robust optimization, which aims to improve robust accuracies-- worst-group and unbiased accuracies--is a prominent algorithm used to mitigate spurious correlations and address dataset bias. Although existing approaches have \u2026"}, {"title": "Towards Efficient and Explainable Hate Speech Detection via Model Distillation", "link": "https://arxiv.org/pdf/2412.13698", "details": "P Piot, J Parapar - arXiv preprint arXiv:2412.13698, 2024", "abstract": "Automatic detection of hate and abusive language is essential to combat its online spread. Moreover, recognising and explaining hate speech serves to educate people about its negative effects. However, most current detection models operate as black \u2026"}, {"title": "The Role of Artificial Intelligence and Machine Learning in Healthcare", "link": "https://www.researchgate.net/profile/Richard-Aggrey/publication/387298355_The_Role_of_Artificial_Intelligence_and_Machine_Learning_in_Healthcare/links/6766ce47c1b0135465ee0c42/The-Role-of-Artificial-Intelligence-and-Machine-Learning-in-Healthcare.pdf", "details": "R Aggrey, BA Adjei, NAK Dsane, KO Afoduo\u2026", "abstract": "Abstract Artificial Intelligence (AI) and Machine Learning (ML) can potentially revolutionise healthcare systems by improving diagnostic and treatment procedures, thereby enhancing patients' health. Based on big data, these technologies can find \u2026"}, {"title": "OG-RAG: Ontology-Grounded Retrieval-Augmented Generation For Large Language Models", "link": "https://arxiv.org/pdf/2412.15235", "details": "K Sharma, P Kumar, Y Li - arXiv preprint arXiv:2412.15235, 2024", "abstract": "This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented Generation method designed to enhance LLM-generated responses by anchoring retrieval processes in domain-specific ontologies. While LLMs are widely used for \u2026"}, {"title": "Does VLM Classification Benefit from LLM Description Semantics?", "link": "https://arxiv.org/pdf/2412.11917%3F", "details": "P Ma, L Rietdorf, D Kotovenko, VT Hu, B Ommer - arXiv preprint arXiv:2412.11917, 2024", "abstract": "Accurately describing images via text is a foundation of explainable AI. Vision- Language Models (VLMs) like CLIP have recently addressed this by aligning images and texts in a shared embedding space, expressing semantic similarities between \u2026"}, {"title": "Confidence in the Reasoning of Large Language Models", "link": "https://assets.pubpub.org/8ahvoupt/Pawitan%2520%26%2520Holmes%2520\\(2024\\)_Just%2520Accepted-21734387493774.pdf", "details": "Y Pawitan, C Holmes - arXiv preprint arXiv:2412.15296, 2024", "abstract": "There is a growing literature on reasoning by large language models (LLMs), but the discussion on the uncertainty in their responses is still lacking. Our aim is to assess the extent of confidence that LLMs have in their answers and how it correlates with \u2026"}]
