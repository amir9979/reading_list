[{"title": "Mental Modeling of Reinforcement Learning Agents by Language Models", "link": "https://arxiv.org/pdf/2406.18505", "details": "W Lu, X Zhao, J Spisak, JH Lee, S Wermter - arXiv preprint arXiv:2406.18505, 2024", "abstract": "Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it \u2026"}, {"title": "OEHR: An Orthopedic Electronic Health Record Dataset", "link": "https://dl.acm.org/doi/abs/10.1145/3626772.3657885", "details": "Y Xie, K Wang, J Zheng, F Liu, X Wang, G Huang - Proceedings of the 47th \u2026, 2024", "abstract": "During the past decades, healthcare institutions continually amassed clinical data that is not intended to support research. Despite the increasing number of publicly available electronic health record (EHR) datasets, it is difficult to find publicly \u2026"}, {"title": "Fuzzy Multi-view Graph Learning on Sparse Electronic Health Records", "link": "https://ieeexplore.ieee.org/abstract/document/10572354/", "details": "T Tang, Z Han, S Yu, A Bagirov, Q Zhang - IEEE Transactions on Fuzzy Systems, 2024", "abstract": "Extracting latent disease patterns from electronic health records (EHRs) is a crucial solution for disease analysis, significantly facilitating healthcare decision-making. Multiview learning presents itself as a promising approach that offers a \u2026"}, {"title": "Language models, like humans, show content effects on reasoning tasks", "link": "https://academic.oup.com/pnasnexus/article/3/7/pgae233/7712372", "details": "AK Lampinen, I Dasgupta, SCY Chan, HR Sheahan\u2026 - PNAS nexus, 2024", "abstract": "Abstract reasoning is a key ability for an intelligent system. Large language models (LMs) achieve above-chance performance on abstract reasoning tasks but exhibit many imperfections. However, human abstract reasoning is also imperfect. Human \u2026"}, {"title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation", "link": "https://arxiv.org/pdf/2406.19371", "details": "CM Pham, S Sun, M Iyyer - arXiv preprint arXiv:2406.19371, 2024", "abstract": "Existing research on instruction following largely focuses on tasks with simple instructions and short responses. In this work, we explore multi-constraint instruction following for generating long-form text. We create Suri, a dataset with 20K human \u2026"}, {"title": "Aligning Language Models with the Human World", "link": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi%3Farticle%3D1241%26context%3Ddissertations", "details": "R LIU - 2024", "abstract": "Abstract The field of Natural Language Processing (NLP) has undergone a significant transformation with the emergence of large language models (LMs). These models have enabled the development of human-like conversational \u2026"}, {"title": "Rgat at semeval-2024 task 2: Biomedical natural language inference using graph attention network", "link": "https://aclanthology.org/2024.semeval-1.19.pdf", "details": "A Chakraborty - Proceedings of the 18th International Workshop on \u2026, 2024", "abstract": "In this work, we (team RGAT) describe our approaches for the SemEval 2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials (NLI4CT). The objective of this task is multi-evidence natural language inference based on different \u2026"}, {"title": "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation", "link": "https://arxiv.org/pdf/2406.17681", "details": "K Qian, S Wan, C Tang, Y Wang, X Zhang, M Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models achieve impressive scores on traditional benchmarks, an increasing number of researchers are becoming concerned about benchmark data leakage during pre-training, commonly known as the data contamination problem. To \u2026"}, {"title": "Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation", "link": "https://arxiv.org/pdf/2407.01948", "details": "P Messina, R Vidal, D Parra, \u00c1 Soto, V Araujo - arXiv preprint arXiv:2407.01948, 2024", "abstract": "Advancing representation learning in specialized fields like medicine remains challenging due to the scarcity of expert annotations for text and images. To tackle this issue, we present a novel two-stage framework designed to extract high-quality \u2026"}]
