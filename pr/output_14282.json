[{"title": "HaploVL: A Single-Transformer Baseline for Multi-Modal Understanding", "link": "https://arxiv.org/pdf/2503.14694", "details": "R Yang, L Song, Y Xiao, R Huang, Y Ge, Y Shan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in large language models (LLMs) have significantly propelled the development of large multi-modal models (LMMs), highlighting the potential for general and intelligent assistants. However, most LMMs model visual and textual \u2026"}, {"title": "QA-Calibration of language model confidence scores", "link": "https://www.amazon.science/publications/qa-calibration-of-language-model-confidence-scores", "details": "A Mastakouri, E Kirschbaum, S Kasiviswanathan\u2026 - 2025", "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim \u2026"}, {"title": "R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization", "link": "https://arxiv.org/pdf/2503.12937", "details": "J Zhang, J Huang, H Yao, S Liu, X Zhang, S Lu, D Tao - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent studies generally enhance MLLMs' reasoning capabilities via supervised fine- tuning on high-quality chain-of-thought reasoning data, which often leads models to merely imitate successful reasoning paths without understanding what the wrong \u2026"}, {"title": "DAST: Difficulty-Aware Self-Training on Large Language Models", "link": "https://arxiv.org/pdf/2503.09029", "details": "B Xue, Q Zhu, H Wang, R Wang, S Wang, H Xu, F Mi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Present Large Language Models (LLM) self-training methods always under-sample on challenging queries, leading to inadequate learning on difficult problems which limits LLMs' ability. Therefore, this work proposes a difficulty-aware self-training \u2026"}, {"title": "Towards reasoning era: A survey of long chain-of-thought for reasoning large language models", "link": "https://arxiv.org/pdf/2503.09567", "details": "Q Chen, L Qin, J Liu, D Peng, J Guan, P Wang, M Hu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in reasoning with large language models (RLLMs), such as OpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in complex domains like mathematics and coding. A central factor in their success lies \u2026"}, {"title": "XIFBench: Evaluating Large Language Models on Multilingual Instruction Following", "link": "https://arxiv.org/pdf/2503.07539%3F", "details": "Z Li, K Chen, Y Long, X Bai, Y Zhang, X Wei, J Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable instruction-following capabilities across various applications. However, their performance in multilingual settings remains poorly understood, as existing evaluations lack fine-grained \u2026"}, {"title": "Corrective In-Context Learning: Evaluating Self-Correction in Large Language Models", "link": "https://arxiv.org/pdf/2503.16022", "details": "M Sanz-Guerrero, K von der Wense - arXiv preprint arXiv:2503.16022, 2025", "abstract": "In-context learning (ICL) has transformed the use of large language models (LLMs) for NLP tasks, enabling few-shot learning by conditioning on labeled examples without finetuning. Despite its effectiveness, ICL is prone to errors, especially for \u2026"}, {"title": "No LLM is Free From Bias: A Comprehensive Study of Bias Evaluation in Large Language models", "link": "https://arxiv.org/pdf/2503.11985", "details": "CV Kumar, A Urlana, G Kanumolu, BM Garlapati\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Advancements in Large Language Models (LLMs) have increased the performance of different natural language understanding as well as generation tasks. Although LLMs have breached the state-of-the-art performance in various tasks, they often \u2026"}, {"title": "From Chaos to Order: The Atomic Reasoner Framework for Fine-grained Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2503.15944", "details": "J Liu, Y Zheng, R Cheng, Q Wu, W Guo, F Ni, H Liang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in large language models (LLMs) have shown remarkable progress, yet their capacity for logical``slow-thinking''reasoning persists as a critical research frontier. Current inference scaling paradigms suffer from two fundamental \u2026"}]
