[{"title": "Learning local discrete features in explainable-by-design convolutional neural networks", "link": "https://arxiv.org/pdf/2411.00139", "details": "PI Kaplanoglou, K Diamantaras - arXiv preprint arXiv:2411.00139, 2024", "abstract": "Our proposed framework attempts to break the trade-off between performance and explainability by introducing an explainable-by-design convolutional neural network (CNN) based on the lateral inhibition mechanism. The ExplaiNet model consists of \u2026"}, {"title": "A lightweight and explainable model for driver abnormal behavior recognition", "link": "https://www.sciencedirect.com/science/article/pii/S0952197624017172", "details": "J Hao, X Sun, X Liu, D Hua, J Hu - Engineering Applications of Artificial Intelligence, 2025", "abstract": "With the advancement of intelligent transportation systems, accurate identification of driver abnormal behavior is crucial for enhancing road safety. However, the limited computing power of vehicular systems poses a challenge for running efficient and \u2026"}, {"title": "Adversarial Masked Autoencoders Are Robust Vision Learners", "link": "https://ieeexplore.ieee.org/abstract/document/10755032/", "details": "Y Yao, N Desai, M Palaniswami - IEEE Transactions on Artificial Intelligence, 2024", "abstract": "Self-supervised learning, specifically masked image modeling, has achieved significant success, surpassing earlier contrastive learning methods. However, the robustness of these methods against adversarial attacks, which subtly manipulate \u2026"}, {"title": "Cervical OCT image classification using contrastive masked autoencoders with Swin Transformer", "link": "https://www.sciencedirect.com/science/article/pii/S0895611124001460", "details": "Q Wang, Y Xiong, H Zhu, X Mu, Y Zhang, Y Ma - Computerized Medical Imaging and \u2026, 2024", "abstract": "Abstract Background and Objective: Cervical cancer poses a major health threat to women globally. Optical coherence tomography (OCT) imaging has recently shown promise for non-invasive cervical lesion diagnosis. However, obtaining high-quality \u2026"}, {"title": "Generative Example-Based Explanations: Bridging the Gap between Generative Modeling and Explainability", "link": "https://arxiv.org/pdf/2410.20890", "details": "P Vaeth, AM Fruehwald, B Paassen, M Gregorova - arXiv preprint arXiv:2410.20890, 2024", "abstract": "Recently, several methods have leveraged deep generative modeling to produce example-based explanations of decision algorithms for high-dimensional input data. Despite promising results, a disconnect exists between these methods and the \u2026"}, {"title": "Efficient Vision-Language pre-training via domain-specific learning for human activities", "link": "https://aclanthology.org/2024.emnlp-main.454.pdf", "details": "A Bulat, Y Ouali, R Guerrero, B Martinez\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Current Vision-Language (VL) models owe their success to large-scale pre- training on web-collected data, which in turn requires high-capacity architectures and large compute resources for training. We posit that when the downstream tasks are \u2026"}, {"title": "CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense", "link": "https://arxiv.org/pdf/2410.23091", "details": "M Zhang, K Bi, W Chen, Q Chen, J Guo, X Cheng - arXiv preprint arXiv:2410.23091, 2024", "abstract": "Despite ongoing efforts to defend neural classifiers from adversarial attacks, they remain vulnerable, especially to unseen attacks. In contrast, humans are difficult to be cheated by subtle manipulations, since we make judgments only based on \u2026"}, {"title": "Enhancing Vision-Language Model Safety through Progressive Concept-Bottleneck-Driven Alignment", "link": "https://arxiv.org/pdf/2411.11543", "details": "Z Liu, Y Nie, Y Tan, X Yue, Q Cui, C Wang, X Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Benefiting from the powerful capabilities of Large Language Models (LLMs), pre- trained visual encoder models connected to LLMs form Vision Language Models (VLMs). However, recent research shows that the visual modality in VLMs is highly \u2026"}, {"title": "VAE-SIMCA\u2014data-driven method for building one class classifiers with variational autoencoders", "link": "https://www.sciencedirect.com/science/article/pii/S0169743924002168", "details": "A Petersen, S Kucheryavskiy - Chemometrics and Intelligent Laboratory Systems, 2024", "abstract": "The paper proposes a new method for building one class classifiers based on variational autoencoders (VAE). The classification decision is built on a linear combination of two squared distances: computed for the original and the \u2026"}]
