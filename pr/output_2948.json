[{"title": "X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions", "link": "https://arxiv.org/pdf/2405.19744", "details": "C Li, W Yang, J Zhang, J Lu, S Wang, C Zong - arXiv preprint arXiv:2405.19744, 2024", "abstract": "Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples \u2026"}, {"title": "TopViewRS: Vision-Language Models as Top-View Spatial Reasoners", "link": "https://arxiv.org/pdf/2406.02537", "details": "C Li, C Zhang, H Zhou, N Collier, A Korhonen, I Vuli\u0107 - arXiv preprint arXiv \u2026, 2024", "abstract": "Top-view perspective denotes a typical way in which humans read and reason over different types of maps, and it is vital for localization and navigation of humans as well as ofnon-human'agents, such as the ones backed by large Vision-Language \u2026"}, {"title": "Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt", "link": "https://arxiv.org/pdf/2406.04031", "details": "Z Ying, A Liu, T Zhang, Z Yu, S Liang, X Liu, D Tao - arXiv preprint arXiv:2406.04031, 2024", "abstract": "In the realm of large vision language models (LVLMs), jailbreak attacks serve as a red-teaming approach to bypass guardrails and uncover safety implications. Existing jailbreaks predominantly focus on the visual modality, perturbing solely visual inputs \u2026"}, {"title": "White-box Multimodal Jailbreaks Against Large Vision-Language Models", "link": "https://arxiv.org/pdf/2405.17894", "details": "R Wang, X Ma, H Zhou, C Ji, G Ye, YG Jiang - arXiv preprint arXiv:2405.17894, 2024", "abstract": "Recent advancements in Large Vision-Language Models (VLMs) have underscored their superiority in various multimodal tasks. However, the adversarial robustness of VLMs has not been fully explored. Existing methods mainly assess robustness \u2026"}, {"title": "Super Tiny Language Models", "link": "https://arxiv.org/pdf/2405.14159", "details": "D Hillier, L Guertler, C Tan, P Agrawal, C Ruirui\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large language models (LLMs) has led to significant improvements in natural language processing but also poses challenges due to their high computational and energy demands. This paper introduces a series of research \u2026"}, {"title": "Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for Electronic Health Records", "link": "https://aclanthology.org/2024.cl4health-1.23.pdf", "details": "J Lov\u00f3n-Melgarejo, T Ben-Haddi, J Di Scala\u2026 - Proceedings of the First \u2026, 2024", "abstract": "The lack of standardized evaluation benchmarks in the medical domain for text inputs can be a barrier to widely adopting and leveraging the potential of natural language models for health-related downstream tasks. This paper revisited an \u2026"}, {"title": "Representing Animatable Avatar via Factorized Neural Fields", "link": "https://arxiv.org/pdf/2406.00637", "details": "C Song, Z Wu, B Wandt, L Sigal, H Rhodin - arXiv preprint arXiv:2406.00637, 2024", "abstract": "For reconstructing high-fidelity human 3D models from monocular videos, it is crucial to maintain consistent large-scale body shapes along with finely matched subtle wrinkles. This paper explores the observation that the per-frame rendering results \u2026"}, {"title": "Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding", "link": "https://arxiv.org/pdf/2405.19763", "details": "K Liao, S Li, M Zhao, L Liu, M Xue, Z Hu, H Han, C Yin - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent strides in large language models (LLMs) have yielded remarkable performance, leveraging reinforcement learning from human feedback (RLHF) to significantly enhance generation and alignment capabilities. However, RLHF \u2026"}, {"title": "Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional Chaining", "link": "https://arxiv.org/pdf/2406.06586", "details": "S Liu, B He, L Song - arXiv preprint arXiv:2406.06586, 2024", "abstract": "Large Language Models (LLMs) have shown human-like reasoning abilities but still face challenges in solving complex logical problems. Existing unidirectional chaining methods, such as forward chaining and backward chaining, suffer from issues like \u2026"}]
