[{"title": "Large Language Model with Region-guided Referring and Grounding for CT Report Generation", "link": "https://arxiv.org/pdf/2411.15539", "details": "Z Chen, Y Bie, H Jin, H Chen - arXiv preprint arXiv:2411.15539, 2024", "abstract": "Computed tomography (CT) report generation is crucial to assist radiologists in interpreting CT volumes, which can be time-consuming and labor-intensive. Existing methods primarily only consider the global features of the entire volume, making it \u2026"}, {"title": "Generalized Deep Learning for Histopathology Image Classification Using Supervised Contrastive Learning", "link": "https://www.sciencedirect.com/science/article/pii/S2090123224005320", "details": "MM Rahaman, EKA Millar, E Meijering - Journal of Advanced Research, 2024", "abstract": "Introduction: Cancer is a leading cause of death worldwide, necessitating effective diagnostic tools for early detection and treatment. Histopathological image analysis is crucial for cancer diagnosis but is often hindered by human error and variability \u2026"}, {"title": "Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "link": "https://aclanthology.org/2024.emnlp-main.852.pdf", "details": "L Chen, R Zheng, B Wang, S Jin, C Huang, J Ye\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Reinforcement Learning from Human Feedback (RLHF) is a crucial approach to aligning language models with human values and intentions. A fundamental challenge in this method lies in ensuring that the reward model \u2026"}, {"title": "Multi-scale graph harmonies: Unleashing U-Net's potential for medical image segmentation through contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024008438", "details": "J Wu, J Ma, H Xi, J Li, J Zhu - Neural Networks, 2024", "abstract": "Medical image segmentation is essential for accurately representing tissues and organs in scans, improving diagnosis, guiding treatment, enabling quantitative analysis, and advancing AI-assisted healthcare. Organs and lesion areas in medical \u2026"}, {"title": "Metaaligner: Towards generalizable multi-objective alignment of language models", "link": "https://openreview.net/pdf%3Fid%3DdIVb5C0QFf", "details": "K Yang, Z Liu, Q Xie, J Huang, T Zhang, S Ananiadou - The Thirty-eighth Annual \u2026, 2024", "abstract": "Recent advancements in large language models (LLMs) focus on aligning to heterogeneous human expectations and values via multi-objective preference alignment. However, existing methods are dependent on the policy model \u2026"}, {"title": "Micro-Bench: A Microscopy Benchmark for Vision-Language Understanding", "link": "https://openreview.net/pdf%3Fid%3DeRleg6vy0Y", "details": "A Lozano, JJ Nirschl, J Burgess, SR Gupte, Y Zhang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent advances in microscopy have enabled the rapid generation of terabytes of image data in cell biology and biomedical research. Vision-language models (VLMs) offer a promising solution for large-scale biological image analysis, enhancing \u2026"}, {"title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "link": "https://arxiv.org/pdf/2411.08733%3F", "details": "S Singla, Z Wang, T Liu, A Ashfaq, Z Hu, EP Xing - arXiv preprint arXiv:2411.08733, 2024", "abstract": "Aligning Large Language Models (LLMs) traditionally relies on costly training and human preference annotations. Self-alignment seeks to reduce these expenses by enabling models to align themselves. To further lower costs and achieve alignment \u2026"}, {"title": "Self-Training Large Language and Vision Assistant for Medical Question Answering", "link": "https://aclanthology.org/2024.emnlp-main.1119.pdf", "details": "G Sun, C Qin, H Fu, L Wang, Z Tao - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "Abstract Large Vision-Language Models (LVLMs) have shown significant potential in assisting medical diagnosis by leveraging extensive biomedical datasets. However, the advancement of medical image understanding and reasoning critically depends \u2026"}, {"title": "Gradient Localization Improves Lifelong Pretraining of Language Models", "link": "https://arxiv.org/pdf/2411.04448", "details": "J Fernandez, Y Bisk, E Strubell - arXiv preprint arXiv:2411.04448, 2024", "abstract": "Large Language Models (LLMs) trained on web-scale text corpora have been shown to capture world knowledge in their parameters. However, the mechanism by which language models store different types of knowledge is poorly understood. In this \u2026"}]
