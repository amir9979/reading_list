[{"title": "Explainable Emotion Decoding for Human and Computer Vision", "link": "https://link.springer.com/chapter/10.1007/978-3-031-63797-1_10", "details": "A Borriero, M Milazzo, M Diano, D Orsenigo, MC Villa\u2026 - World Conference on \u2026, 2024", "abstract": "Abstract Modern Machine Learning (ML) has significantly advanced various research fields, but the opaque nature of ML models hinders their adoption in several domains. Explainable AI (XAI) addresses this challenge by providing additional \u2026"}, {"title": "A Closer Look at Benchmarking Self-Supervised Pre-training with Image Classification", "link": "https://arxiv.org/pdf/2407.12210", "details": "M Marks, M Knott, N Kondapaneni, E Cole, T Defraeye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-supervised learning (SSL) is a machine learning approach where the data itself provides supervision, eliminating the need for external labels. The model is forced to learn about the data structure or context by solving a pretext task. With SSL, models \u2026"}, {"title": "Let Me Show You Step by Step: An Interpretable Graph Routing Network for Knowledge-based Visual Question Answering", "link": "https://dl.acm.org/doi/abs/10.1145/3626772.3657790", "details": "D Wang, L Hu, R Hao, Y Shao, X Lv, L Nie, J Li - \u2026 of the 47th International ACM SIGIR \u2026, 2024", "abstract": "Visual Question Answering based on external Knowledge Bases (KB-VQA) requires a model to incorporate knowledge beyond the content of given image and question for answer prediction. Most existing works made efforts on using graph neural \u2026"}, {"title": "Coincident Learning for Unsupervised Anomaly Detection of Scientific Instruments", "link": "https://iopscience.iop.org/article/10.1088/2632-2153/ad64a6/pdf", "details": "R Humble, Z Zhang, FH O'Shea, E Darve, D Ratner - Machine Learning: Science and \u2026, 2024", "abstract": "Anomaly detection is an important task for complex scientific experiments and other complex systems (eg, industrial facilities, manufacturing), where failures in a sub- system can lead to lost data, poor performance, or even damage to components \u2026"}, {"title": "IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning", "link": "https://ui.adsabs.harvard.edu/abs/2024arXiv240613683S/abstract", "details": "S Suvra Ghosal, S Basu, S Feizi, D Manocha - arXiv e-prints, 2024", "abstract": "Image-text contrastive models such as CLIP learn transferable and robust representations for zero-shot transfer to a variety of downstream tasks. However, to obtain strong downstream performances, prompts need to be carefully curated \u2026"}, {"title": "$\\mathbb {X} $-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs", "link": "https://openreview.net/pdf%3Fid%3DXdMUx9rhl9", "details": "V Sobal, M Ibrahim, R Balestriero, V Cabannes\u2026 - \u2026 on Foundation Models in the Wild", "abstract": "Learning good representations involves capturing the diverse ways in which data samples relate. Contrastive loss\u2014an objective matching related samples\u2014underlies methods from self-supervised to multimodal learning. Contrastive losses, however \u2026"}, {"title": "In Search of Forgotten Domain Generalization", "link": "https://openreview.net/pdf%3Fid%3DBc2p8T4V32", "details": "P Mayilvahanan, RS Zimmermann, T Wiedemer\u2026 - \u2026 on Foundation Models in the Wild", "abstract": "Out-of-Domain (OOD) generalization is the ability of a model trained on one or more domains to generalize to unseen domains. In the ImageNet era of computer vision, evaluation sets for measuring a model's OOD performance were designed to be \u2026"}]
