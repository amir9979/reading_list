[{"title": "BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation", "link": "https://arxiv.org/pdf/2502.03860", "details": "B Pang, H Dong, J Xu, S Savarese, Y Zhou, C Xiong - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs), such as o1 from OpenAI, have demonstrated remarkable reasoning capabilities. o1 generates a long chain-of-thought (LongCoT) before answering a question. LongCoT allows LLMs to analyze problems, devise \u2026"}, {"title": "Controllable Sequence Editing for Counterfactual Generation", "link": "https://arxiv.org/pdf/2502.03569", "details": "MM Li, K Li, Y Ektefaie, S Messica, M Zitnik - arXiv preprint arXiv:2502.03569, 2025", "abstract": "Sequence models generate counterfactuals by modifying parts of a sequence based on a given condition, enabling reasoning about\" what if\" scenarios. While these models excel at conditional generation, they lack fine-grained control over when and \u2026"}, {"title": "LLM Alignment as Retriever Optimization: An Information Retrieval Perspective", "link": "https://arxiv.org/pdf/2502.03699", "details": "B Jin, J Yoon, Z Qin, Z Wang, W Xiong, Y Meng, J Han\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence with capabilities in reasoning, coding, and communication, driving innovation across industries. Their true potential depends on effective alignment to ensure correct \u2026"}, {"title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization", "link": "https://arxiv.org/pdf/2502.04306", "details": "Y Wang, L Yang, G Li, M Wang, B Aragam - arXiv preprint arXiv:2502.04306, 2025", "abstract": "Recent research has leveraged large language model multi-agent systems for complex problem-solving while trying to reduce the manual effort required to build them, driving the development of automated agent workflow optimization methods \u2026"}]
