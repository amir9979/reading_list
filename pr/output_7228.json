[{"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task Specific Expert Pruning", "link": "https://arxiv.org/pdf/2409.01483", "details": "S Sarkar, L Lausen, V Cevher, S Zha, T Brox, G Karypis - arXiv preprint arXiv \u2026, 2024", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative to dense models in language modeling. These models use conditionally activated feedforward subnetworks in transformer blocks, allowing for a separation between \u2026"}, {"title": "Skipformer: Evolving Beyond Blocks for Extensively Searching On-Device Language Models with Learnable Attention Window", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10666862.pdf", "details": "M Bodenham, J Kung - IEEE Access, 2024", "abstract": "Deployment of language models to resource-constrained edge devices is an uphill battle against their ever-increasing size. The task transferability of language models makes deployment to the edge an attractive application. Prior neural architecture \u2026"}, {"title": "Prediction of short-term adverse clinical outcomes of acute pulmonary embolism using conventional machine learning and deep Learning based on CTPA images", "link": "https://link.springer.com/article/10.1007/s11239-024-03044-4", "details": "D Wang, R Chen, W Wang, Y Yang, Y Yu, L Liu, F Yang\u2026 - Journal of Thrombosis and \u2026, 2024", "abstract": "To explore the predictive value of traditional machine learning (ML) and deep learning (DL) algorithms based on computed tomography pulmonary angiography (CTPA) images for short-term adverse outcomes in patients with acute pulmonary \u2026"}, {"title": "A Case Demonstration of the Open Health Natural Language Processing Toolkit From the National COVID-19 Cohort Collaborative and the Researching COVID to \u2026", "link": "https://medinform.jmir.org/2024/1/e49997", "details": "A Wen, L Wang, H He, S Fu, S Liu, DA Hanauer\u2026 - JMIR Medical Informatics, 2024", "abstract": "Background A wealth of clinically relevant information is only obtainable within unstructured clinical narratives, leading to great interest in clinical natural language processing (NLP). While a multitude of approaches to NLP exist, current algorithm \u2026"}, {"title": "An Efficient Contrastive Unimodal Pretraining Method for EHR Time Series Data", "link": "https://openreview.net/pdf%3Fid%3DZN5vbwMpgX", "details": "R King, S Kodali, C Krueger, T Yang, BJ Mortazavi - IEEE-EMBS International Conference on \u2026", "abstract": "Machine learning has revolutionized the modeling of clinical timeseries data. Using machine learning, a Deep Neural Network (DNN) can be automatically trained to learn a complex mapping of its input features for a desired task. This is particularly \u2026"}, {"title": "Language Models Benefit from Preparation with Elicited Knowledge", "link": "https://arxiv.org/pdf/2409.01345", "details": "J Yu, H An, LK Schubert - arXiv preprint arXiv:2409.01345, 2024", "abstract": "The zero-shot chain of thought (CoT) approach is often used in question answering (QA) by language models (LMs) for tasks that require multiple reasoning steps, typically enhanced by the prompt\" Let's think step by step.\" However, some QA tasks \u2026"}, {"title": "Fine-Tuned Transformers and Large Language Models for Entity Recognition in Complex Eligibility Criteria for Clinical Trials", "link": "https://aisel.aisnet.org/isd2014/proceedings2024/datascience/19/", "details": "K Kantor, M Morzy - 2024", "abstract": "This paper evaluates the\\texttt {gpt-4-turbo} model's proficiency in recognizing named entities within the clinical trial eligibility criteria. We employ prompt learning to a dataset comprising $49\\, 903$ criteria from $3\\, 314$ trials, with $120\\, 906 \u2026"}]
