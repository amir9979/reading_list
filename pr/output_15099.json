[{"title": "Efficient Tuning of Large Language Models for Knowledge-Grounded Dialogue Generation", "link": "https://arxiv.org/pdf/2504.07754", "details": "B Zhang, H Ma, D Li, J Ding, J Wang, B Xu, HF Lin - arXiv preprint arXiv:2504.07754, 2025", "abstract": "Large language models (LLMs) demonstrate remarkable text comprehension and generation capabilities but often lack the ability to utilize up-to-date or domain- specific knowledge not included in their training data. To address this gap, we \u2026"}]
