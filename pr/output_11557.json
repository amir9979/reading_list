[{"title": "Enhancing radiology report generation through pre-trained language models", "link": "https://link.springer.com/article/10.1007/s13748-024-00358-5", "details": "G Leonardi, L Portinale, A Santomauro - Progress in Artificial Intelligence, 2024", "abstract": "In the healthcare field, the ability to integrate and process data from various modalities, such as medical images, clinical notes, and patient records, plays a central role in enabling Artificial Intelligence models to provide more informed \u2026"}, {"title": "Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models", "link": "https://arxiv.org/pdf/2412.18609%3F", "details": "J Yi, ST Wasim, Y Luo, M Naseer, J Gall - arXiv preprint arXiv:2412.18609, 2024", "abstract": "We present an efficient encoder-free approach for video-language understanding that achieves competitive performance while significantly reducing computational overhead. Current video-language models typically rely on heavyweight image \u2026"}, {"title": "MiniGPT-Pancreas: Multimodal Large Language Model for Pancreas Cancer Classification and Detection", "link": "https://arxiv.org/pdf/2412.15925", "details": "A Moglia, EC Nastasio, L Mainardi, P Cerveri - arXiv preprint arXiv:2412.15925, 2024", "abstract": "Problem: Pancreas radiological imaging is challenging due to the small size, blurred boundaries, and variability of shape and position of the organ among patients. Goal: In this work we present MiniGPT-Pancreas, a Multimodal Large Language Model \u2026"}, {"title": "Biased or Flawed? Mitigating Stereotypes in Generative Language Models by Addressing Task-Specific Flaws", "link": "https://arxiv.org/pdf/2412.11414%3F", "details": "A Jha, S Kabra, CK Reddy - arXiv preprint arXiv:2412.11414, 2024", "abstract": "Recent studies have shown that generative language models often reflect and amplify societal biases in their outputs. However, these studies frequently conflate observed biases with other task-specific shortcomings, such as comprehension \u2026"}, {"title": "Technical Report: Small Language Model for Japanese Clinical and Medicine", "link": "https://arxiv.org/pdf/2412.16423", "details": "S Watanabe - arXiv preprint arXiv:2412.16423, 2024", "abstract": "This report presents a small language model (SLM) for Japanese clinical and medicine, named NCVC-slm-1. This 1B parameters model was trained using Japanese text classified to be of high-quality. Moreover, NCVC-slm-1 was \u2026"}, {"title": "CaseSumm: A Large-Scale Dataset for Long-Context Summarization from US Supreme Court Opinions", "link": "https://arxiv.org/pdf/2501.00097", "details": "M Heddaya, K MacMillan, A Malani, H Mei, C Tan - arXiv preprint arXiv:2501.00097, 2024", "abstract": "This paper introduces CaseSumm, a novel dataset for long-context summarization in the legal domain that addresses the need for longer and more complex datasets for summarization evaluation. We collect 25.6 K US Supreme Court (SCOTUS) opinions \u2026"}, {"title": "An Empirical Study of Autoregressive Pre-training from Videos", "link": "https://arxiv.org/pdf/2501.05453", "details": "J Rajasegaran, I Radosavovic, R Ravishankar\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We empirically study autoregressive pre-training from videos. To perform our study, we construct a series of autoregressive video models, called Toto. We treat videos as sequences of visual tokens and train transformer models to autoregressively predict \u2026"}]
