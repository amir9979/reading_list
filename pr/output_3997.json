[{"title": "Open (Clinical) LLMs are Sensitive to Instruction Phrasings", "link": "https://arxiv.org/pdf/2407.09429", "details": "AMC Arroyo, M Munnangi, J Sun, KYC Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as \u2026"}, {"title": "Applicability of large language models and generative models for legal case judgement summarization", "link": "https://www.researchgate.net/profile/Aniket-Deroy-2/publication/382148784_Applicability_of_Large_Language_Models_and_Generative_Models_for_Legal_Case_Judgement_Summarization/links/668f956c3e0edb1e0fdb87f3/Applicability-of-Large-Language-Models-and-Generative-Models-for-Legal-Case-Judgement-Summarization.pdf", "details": "A Deroy, K Ghosh, S Ghosh - Artificial Intelligence and Law, 2024", "abstract": "Automatic summarization of legal case judgements, which are known to be long and complex, has traditionally been tried via extractive summarization models. In recent years, generative models including abstractive summarization models and Large \u2026"}, {"title": "Exploring Hybrid Contrastive Learning and Scene-to-Label Information for Multilabel Remote Sensing Image Classification", "link": "https://ieeexplore.ieee.org/abstract/document/10580951/", "details": "T Song, S Bai, F Yang, C Gao, H Chen, J Li - IEEE Transactions on Geoscience and \u2026, 2024", "abstract": "Multilabel remote sensing (RS) image classification aims to predict multiple semantic labels from an RS image. Previous methods [eg, graph convolution networks (GCNs)] focus on mining the relationships of multiple labels, neglecting that the \u2026"}, {"title": "Unicoder: Scaling code large language model via universal code", "link": "https://arxiv.org/pdf/2406.16441", "details": "T Sun, L Chai, J Yang, Y Yin, H Guo, J Liu, B Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various downstream natural language processing (NLP) tasks. When applying LLMs for code generation, recent works mainly focus on \u2026"}, {"title": "InternLM-Law: An Open Source Chinese Legal Large Language Model", "link": "https://arxiv.org/pdf/2406.14887", "details": "Z Fei, S Zhang, X Shen, D Zhu, X Wang, M Cao, F Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While large language models (LLMs) have showcased impressive capabilities, they struggle with addressing legal queries due to the intricate complexities and specialized expertise required in the legal field. In this paper, we introduce InternLM \u2026"}, {"title": "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors", "link": "https://arxiv.org/pdf/2407.09136", "details": "N Daheim, J Macina, M Kapur, I Gurevych, M Sachan - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) present an opportunity to scale high-quality personalized education to all. A promising approach towards this means is to build dialog tutoring models that scaffold students' problem-solving. However, even though \u2026"}, {"title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference", "link": "https://arxiv.org/pdf/2406.17626", "details": "E Yu, J Li, M Liao, S Wang, Z Gao, F Mi, L Hong - arXiv preprint arXiv:2406.17626, 2024", "abstract": "As large language models (LLMs) constantly evolve, ensuring their safety remains a critical research problem. Previous red-teaming approaches for LLM safety have primarily focused on single prompt attacks or goal hijacking. To the best of our \u2026"}]
