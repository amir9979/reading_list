[{"title": "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets", "link": "https://arxiv.org/pdf/2410.15096", "details": "OJ Kwon, DE Matsunaga, KE Kim - arXiv preprint arXiv:2410.15096, 2024", "abstract": "A critical component of the current generation of language models is preference alignment, which aims to precisely control the model's behavior to meet human needs and values. The most notable among such methods is Reinforcement \u2026"}, {"title": "Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679722", "details": "Y Shi, Q Tan, X Wu, S Zhong, K Zhou, N Liu - Proceedings of the 33rd ACM \u2026, 2024", "abstract": "Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging \u2026"}, {"title": "Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes", "link": "https://arxiv.org/pdf/2410.16930", "details": "BR Christ, Z Gottesman, J Kropko, T Hartvigsen - arXiv preprint arXiv:2410.16930, 2024", "abstract": "Math reasoning is a highly active area of Large Language Model (LLM) research because it is a hallmark of artificial intelligence. However, few works have explored how math reasoning is encoded within LLM parameters and if it is a skill that can be \u2026"}, {"title": "Language Models-enhanced Semantic Topology Representation Learning For Temporal Knowledge Graph Extrapolation", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679602", "details": "T Zhang, T Zheng, Z Xiao, Z Chen, L Li, Z Feng\u2026 - Proceedings of the 33rd \u2026, 2024", "abstract": "Temporal Knowledge Graph (TKG) extrapolation aims to predict future missing facts based on historical information, which has exhibited both semantics and topology of events. The mainstream methods have advanced the prediction performance by \u2026"}, {"title": "Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Models Alignment", "link": "https://arxiv.org/pdf/2410.16714", "details": "M Wang, C Ma, Q Chen, L Meng, Y Han, J Xiao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-play methods have demonstrated remarkable success in enhancing model capabilities across various domains. In the context of Reinforcement Learning from Human Feedback (RLHF), self-play not only boosts Large Language Model (LLM) \u2026"}, {"title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models", "link": "https://arxiv.org/pdf/2410.18252", "details": "M Noukhovitch, S Huang, S Xhonneux, A Hosseini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously generating from the large language model (LLM) policy, labelling with a reward model, and learning using feedback on the LLM's own outputs. While performant, this \u2026"}, {"title": "Vision Language Model is NOT All You Need: Augmentation Strategies for Molecule Language Models", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679607", "details": "N Lee, S Laghuvarapu, C Park, J Sun - Proceedings of the 33rd ACM International \u2026, 2024", "abstract": "Recently, there has been a growing interest among researchers in understanding molecules and their textual descriptions through molecule language models (MoLM). However, despite some early promising developments, the advancement of MoLM \u2026"}, {"title": "Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning", "link": "https://arxiv.org/pdf/2410.12608%3F", "details": "VYH Toh, D Ghosal, S Poria - arXiv preprint arXiv:2410.12608, 2024", "abstract": "Large language models (LLMs) have shown increasing proficiency in solving mathematical reasoning problems. However, many current open-source LLMs often still make calculation and semantic understanding errors in their intermediate \u2026"}, {"title": "SafeBench: A Safety Evaluation Framework for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2410.18927", "details": "Z Ying, A Liu, S Liang, L Huang, J Guo, W Zhou, X Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Large Language Models (MLLMs) are showing strong safety concerns (eg, generating harmful outputs for users), which motivates the development of safety evaluation benchmarks. However, we observe that existing safety benchmarks for \u2026"}]
