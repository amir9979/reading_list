[{"title": "A generalist vision\u2013language foundation model for diverse biomedical tasks", "link": "https://www.nature.com/articles/s41591-024-03185-2", "details": "K Zhang, R Zhou, E Adhikarla, Z Yan, Y Liu, J Yu, Z Liu\u2026 - Nature Medicine, 2024", "abstract": "Traditional biomedical artificial intelligence (AI) models, designed for specific tasks or modalities, often exhibit limited flexibility in real-world deployment and struggle to utilize holistic information. Generalist AI holds the potential to address these \u2026"}, {"title": "Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment", "link": "https://arxiv.org/pdf/2407.10804", "details": "J Jiang, J Li, WX Zhao, Y Song, T Zhang, JR Wen - arXiv preprint arXiv:2407.10804, 2024", "abstract": "Adapting general large language models (LLMs) to specialized domains presents great challenges due to varied data distributions. This adaptation typically requires continual pre-training on massive domain-specific corpora to facilitate knowledge \u2026"}, {"title": "A Knowledge Graph Embedding Model for Answering Factoid Entity Questions", "link": "https://dl.acm.org/doi/pdf/10.1145/3678003", "details": "P Jafarzadeh, F Ensan, M Ali Akbar Alavi\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Factoid entity questions (FEQ), which seek answers in the form of a single entity from knowledge sources such as DBpedia and Wikidata, constitute a substantial portion of user queries in search engines. This paper introduces the Knowledge Graph \u2026"}, {"title": "Entity Retrieval for Answering Entity-Centric Questions", "link": "https://arxiv.org/pdf/2408.02795", "details": "HS Shavarani, A Sarkar - arXiv preprint arXiv:2408.02795, 2024", "abstract": "The similarity between the question and indexed documents is a crucial factor in document retrieval for retrieval-augmented question answering. Although this is typically the only method for obtaining the relevant documents, it is not the sole \u2026"}, {"title": "A knowledge graph completion model based on triple level interaction and contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S003132032400534X", "details": "J Hu, H Yang, F Teng, S Du, T Li - Pattern Recognition, 2024", "abstract": "Abstract Knowledge graphs provide credible and structured knowledge for downstream tasks such as information retrieval. Nevertheless, the ubiquitous incompleteness of knowledge graphs often limits the performance of applications. To \u2026"}, {"title": "Open (Clinical) LLMs are Sensitive to Instruction Phrasings", "link": "https://arxiv.org/pdf/2407.09429", "details": "AMC Arroyo, M Munnangi, J Sun, KYC Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as \u2026"}, {"title": "A Systematic Evaluation of GPT-4V's Multimodal Capability for Chest X-ray Image Analysis", "link": "https://www.sciencedirect.com/science/article/pii/S2950162824000535", "details": "Y Liu, Y Li, Z Wang, X Liang, L Liu, L Wang, L Cui, Z Tu\u2026 - Meta-Radiology, 2024", "abstract": "This work evaluates GPT-4V's multimodal capability for medical image analysis, focusing on three representative tasks radiology report generation, medical visual question answering, and medical visual grounding. For the evaluation, a set of \u2026"}, {"title": "Making Long-Context Language Models Better Multi-Hop Reasoners", "link": "https://arxiv.org/pdf/2408.03246", "details": "Y Li, S Liang, MR Lyu, L Wang - arXiv preprint arXiv:2408.03246, 2024", "abstract": "Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}]
