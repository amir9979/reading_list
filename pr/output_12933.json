[{"title": "Hybrid cross-modality fusion network for medical image segmentation with contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0952197625000739", "details": "X Zhou, Q Song, J Nie, Y Feng, H Liu, F Liang, L Chen\u2026 - Engineering Applications of \u2026, 2025", "abstract": "Medical image segmentation has been widely adopted in artificial intelligence-based clinical applications. The integration of medical texts into image segmentation models has significantly improved the segmentation performance. It is crucial to \u2026"}, {"title": "Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger vision learners for medical image segmentation", "link": "https://arxiv.org/pdf/2502.08347", "details": "F Tang, Q Yao, W Ma, C Wu, Z Jiang, SK Zhou - arXiv preprint arXiv:2502.08347, 2025", "abstract": "Medical image segmentation remains a formidable challenge due to the label scarcity. Pre-training Vision Transformer (ViT) through masked image modeling (MIM) on large-scale unlabeled medical datasets presents a promising solution \u2026"}, {"title": "Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning", "link": "https://arxiv.org/pdf/2502.05282", "details": "Y He, B Wang, R Ge, Y Chen, G Yang, S Li - IEEE Transactions on Pattern Analysis \u2026, 2025", "abstract": "Dense contrastive representation learning (DCRL) has greatly improved the learning efficiency for image dense prediction tasks, showing its great potential to reduce the large costs of medical image collection and dense annotation. However, the \u2026"}, {"title": "Tuning Vision Foundation Model via Test-Time Prompt-Guided Training for VFSS Segmentations", "link": "https://arxiv.org/pdf/2501.18474", "details": "C Zeng, D Smithard, AM Gambaruto, T Burghardt - arXiv preprint arXiv:2501.18474, 2025", "abstract": "Vision foundation models have demonstrated exceptional generalization capabilities in segmentation tasks for both generic and specialized images. However, a performance gap persists between foundation models and task-specific, specialized \u2026"}]
