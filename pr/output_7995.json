[{"title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models", "link": "https://arxiv.org/pdf/2410.05639", "details": "R Zhao, ZL Thai, Y Zhang, S Hu, Y Ba, J Zhou, J Cai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The performance of Large Language Models (LLMs) is substantially influenced by the pretraining corpus, which consists of vast quantities of unsupervised data processed by the models. Despite its critical role in model performance, ensuring the \u2026"}, {"title": "An Efficient Contrastive Unimodal Pretraining Method for EHR Time Series Data", "link": "https://arxiv.org/pdf/2410.09199", "details": "R King, S Kodali, C Krueger, T Yang, BJ Mortazavi - arXiv preprint arXiv:2410.09199, 2024", "abstract": "Machine learning has revolutionized the modeling of clinical timeseries data. Using machine learning, a Deep Neural Network (DNN) can be automatically trained to learn a complex mapping of its input features for a desired task. This is particularly \u2026"}, {"title": "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "link": "https://arxiv.org/pdf/2410.05077", "details": "FM Molfese, S Conia, R Orlando, R Navigli - arXiv preprint arXiv:2410.05077, 2024", "abstract": "Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have \u2026"}, {"title": "Assessments of Generative AI as Clinical Decision Support Ought to be Incorporated into Randomised Controlled Trials of Electronic Alerts for Acute Kidney Injury", "link": "https://www.mcpdigitalhealth.org/article/S2949-7612\\(24\\)00101-9/fulltext", "details": "DJ Sexton, C Judge - Mayo Clinic Proceedings: Digital Health", "abstract": "Acute Kidney Injury (AKI), characterised by an acute deterioration in kidney function occurs in approximately 25% of hospitalised individuals and is associated with prolonged stay, higher cost and increased morbidity and mortality. 1 Clinical \u2026"}, {"title": "Addition is All You Need for Energy-efficient Language Models", "link": "https://arxiv.org/pdf/2410.00907%3F", "details": "H Luo, W Sun - arXiv preprint arXiv:2410.00907, 2024", "abstract": "Large neural networks spend most computation on floating point tensor multiplications. In this work, we find that a floating point multiplier can be approximated by one integer adder with high precision. We propose the linear \u2026"}, {"title": "Advancing Medical Radiograph Representation Learning: A Hybrid Pre-training Paradigm with Multilevel Semantic Granularity", "link": "https://arxiv.org/pdf/2410.00448", "details": "H Jiang, X Hao, Y Huang, C Ma, J Zhang, Y Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces an innovative approach to Medical Vision-Language Pre- training (Med-VLP) area in the specialized context of radiograph representation learning. While conventional methods frequently merge textual annotations into \u2026"}, {"title": "Efficient Long-range Language Modeling with Self-supervised Causal Retrieval", "link": "https://arxiv.org/pdf/2410.01651", "details": "X Hu, Z Teng, W Wu, K Tu - arXiv preprint arXiv:2410.01651, 2024", "abstract": "Recently, retrieval-based language models (RLMs) have received much attention. However, most of them leverage a pre-trained retriever with fixed parameters, which may not adapt well to causal language models. In this work, we propose Grouped \u2026"}, {"title": "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs", "link": "https://arxiv.org/pdf/2409.14988", "details": "C Christophe, T Raha, S Maslenkova, MU Salman\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated significant potential in transforming clinical applications. In this study, we investigate the efficacy of four techniques in adapting LLMs for clinical use-cases: continuous pretraining, instruct \u2026"}, {"title": "A foundation model for generalizable disease diagnosis in chest X-ray images", "link": "https://arxiv.org/pdf/2410.08861", "details": "L Xu, Z Ni, H Sun, H Li, S Zhang - arXiv preprint arXiv:2410.08861, 2024", "abstract": "Medical artificial intelligence (AI) is revolutionizing the interpretation of chest X-ray (CXR) images by providing robust tools for disease diagnosis. However, the effectiveness of these AI models is often limited by their reliance on large amounts of \u2026"}]
