[{"title": "LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models", "link": "https://arxiv.org/pdf/2406.19486", "details": "S Guo, S Damani, K Chang - arXiv preprint arXiv:2406.19486, 2024", "abstract": "In prompt tuning, a prefix or suffix text is added to the prompt, and the embeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix are optimized to gain more control over language models for specific tasks. This approach eliminates the \u2026"}, {"title": "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2406.12050", "details": "Z Zhang, Z Liang, W Yu, D Yu, M Jia, D Yu, M Jiang - arXiv preprint arXiv:2406.12050, 2024", "abstract": "Supervised fine-tuning enhances the problem-solving abilities of language models across various mathematical reasoning tasks. To maximize such benefits, existing research focuses on broadening the training set with various data augmentation \u2026"}, {"title": "Abstraction-of-Thought Makes Language Models Better Reasoners", "link": "https://arxiv.org/pdf/2406.12442", "details": "R Hong, H Zhang, X Pan, D Yu, C Zhang - arXiv preprint arXiv:2406.12442, 2024", "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks \u2026"}, {"title": "Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding", "link": "https://arxiv.org/pdf/2406.12295", "details": "K Zhang, J Wang, N Ding, B Qi, E Hua, X Lv, B Zhou - arXiv preprint arXiv:2406.12295, 2024", "abstract": "Large Language Models (LLMs) demonstrate impressive performance in diverse applications, yet they face significant drawbacks, including high inference latency, expensive training cost, and generation of hallucination. Collaborative decoding \u2026"}, {"title": "Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models", "link": "https://arxiv.org/pdf/2406.12182", "details": "L Zhao, W Zeng, X Shi, H Zhou, D Hao, Y Lin - arXiv preprint arXiv:2406.12182, 2024", "abstract": "Recently, both closed-source LLMs and open-source communities have made significant strides, outperforming humans in various general domains. However, their performance in specific professional fields such as medicine, especially within the \u2026"}, {"title": "Just read twice: closing the recall gap for recurrent language models", "link": "https://arxiv.org/pdf/2407.05483", "details": "S Arora, A Timalsina, A Singhal, B Spector, S Eyuboglu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recurrent large language models that compete with Transformers in language modeling perplexity are emerging at a rapid rate (eg, Mamba, RWKV). Excitingly, these architectures use a constant amount of memory during inference. However \u2026"}, {"title": "Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?", "link": "https://arxiv.org/pdf/2406.13121", "details": "J Lee, A Chen, Z Dai, D Dua, DS Sachan, M Boratko\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Long-context language models (LCLMs) have the potential to revolutionize our approach to tasks traditionally reliant on external tools like retrieval systems or databases. Leveraging LCLMs' ability to natively ingest and process entire corpora of \u2026"}, {"title": "AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for Vision-Language Models", "link": "https://arxiv.org/pdf/2406.10900", "details": "X Wu, T Guan, D Li, S Huang, X Liu, X Wang, R Xian\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large vision-language models (LVLMs) hallucinate: certain context cues in an image may trigger the language module's overconfident and incorrect reasoning on abnormal or hypothetical objects. Though a few benchmarks have been developed \u2026"}, {"title": "Dialogue Action Tokens: Steering Language Models in Goal-Directed Dialogue with a Multi-Turn Planner", "link": "https://arxiv.org/pdf/2406.11978", "details": "K Li, Y Wang, F Vi\u00e9gas, M Wattenberg - arXiv preprint arXiv:2406.11978, 2024", "abstract": "We present an approach called Dialogue Action Tokens (DAT) that adapts language model agents to plan goal-directed dialogues. The core idea is to treat each utterance as an action, thereby converting dialogues into games where existing \u2026"}]
