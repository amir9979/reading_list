[{"title": "Improving the quality of positive and negative samples based on topological analysis and counterfactual reasoning for graph contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425007183", "details": "X Wang, Q Zhang, G Liu, Z Zhao - Expert Systems with Applications, 2025", "abstract": "Abstract Graph Contrastive Learning (GCL), as one of the most popular self- supervised paradigms, has achieved significant success in graph representation learning. However, its performance heavily depends on the quality of positive and \u2026"}, {"title": "CTVAE: Contrastive Tabular Variational Autoencoder for imbalance data", "link": "https://link.springer.com/article/10.1007/s10115-025-02377-7", "details": "AX Wang, MQ Le, HT Duong, BN Van, BP Nguyen - Knowledge and Information \u2026, 2025", "abstract": "Class imbalance, where datasets often lack sufficient samples for minority classes, is a persistent challenge in machine learning. Existing solutions often generate synthetic data to mitigate this issue, but they typically struggle with complex data \u2026"}, {"title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "link": "https://arxiv.org/pdf/2503.01743%3F", "details": "A Abouelenin, A Ashfaq, A Atkinson, H Awadalla\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality web and synthetic data, significantly outperforming recent \u2026"}]
