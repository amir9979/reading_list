[{"title": "Cross-biased Contrastive Learning for Answer Selection with Dual-Tower Structure", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224014127", "details": "X Jin, Y Du, B Wang, Q Zhang - Neurocomputing, 2024", "abstract": "A large number of unanswered products-related questions appear in the E- commerce platforms, necessitating the deployment of question-answering models to automatically provide precise responses for the user. However, the substantial \u2026"}, {"title": "Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models", "link": "https://arxiv.org/pdf/2409.06277", "details": "Y Shu, W Hu, SK Ng, BKH Low, FR Yu - arXiv preprint arXiv:2409.06277, 2024", "abstract": "Large Language Models (LLMs) have become indispensable in numerous real- world applications. Unfortunately, fine-tuning these models at scale, especially in federated settings where data privacy and communication efficiency are critical \u2026"}, {"title": "Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style", "link": "https://arxiv.org/pdf/2409.10955", "details": "Y Li, K Zhou, Q Qiao, B Nguyen, Q Wang, Q Li - arXiv preprint arXiv:2409.10955, 2024", "abstract": "Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by incorporating external information into the response generation process. However, how context-faithful LLMs are and what factors influence LLMs' context \u2026"}]
