[{"title": "Are Retrials All You Need? Enhancing Large Language Model Reasoning Without Verbalized Feedback", "link": "https://arxiv.org/pdf/2504.12951", "details": "N Potamitis, A Arora - arXiv preprint arXiv:2504.12951, 2025", "abstract": "Recent advancements in large language models (LLMs) have catalyzed the development of general-purpose autonomous agents, demonstrating remarkable performance in complex reasoning tasks across various domains. This surge has \u2026"}, {"title": "MAIN: Mutual Alignment Is Necessary for instruction tuning", "link": "https://arxiv.org/pdf/2504.12913", "details": "F Yang, J Liu, X Zhang, H Liu, X Cao, Y Zhan, H Sun\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Instruction tuning has enabled large language models (LLMs) to achieve remarkable performance, but its success heavily depends on the availability of large-scale, high- quality instruction-response pairs. However, current methods for scaling up data \u2026"}, {"title": "Bayesian Teaching Enables Probabilistic Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2503.17523", "details": "L Qiu, F Sha, K Allen, Y Kim, T Linzen, S van Steenkiste - arXiv preprint arXiv \u2026, 2025", "abstract": "Artificial intelligence systems based on large language models (LLMs) are increasingly used as agents that interact with users and with the world. To do so successfully, LLMs need to construct internal representations of the world and form \u2026"}, {"title": "From Chaos to Order: The Atomic Reasoner Framework for Fine-grained Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2503.15944", "details": "J Liu, Y Zheng, R Cheng, Q Wu, W Guo, F Ni, H Liang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in large language models (LLMs) have shown remarkable progress, yet their capacity for logical``slow-thinking''reasoning persists as a critical research frontier. Current inference scaling paradigms suffer from two fundamental \u2026"}, {"title": "A Survey on Personalized Alignment--The Missing Piece for Large Language Models in Real-World Applications", "link": "https://arxiv.org/pdf/2503.17003%3F", "details": "J Guan, J Wu, JN Li, C Cheng, W Wu - arXiv preprint arXiv:2503.17003, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities, yet their transition to real-world applications reveals a critical limitation: the inability to adapt to individual preferences while maintaining alignment with universal human \u2026"}, {"title": "Persona-judge: Personalized Alignment of Large Language Models via Token-level Self-judgment", "link": "https://arxiv.org/pdf/2504.12663", "details": "X Zhang, R Chen, Y Feng, Z Liu - arXiv preprint arXiv:2504.12663, 2025", "abstract": "Aligning language models with human preferences presents significant challenges, particularly in achieving personalization without incurring excessive computational costs. Existing methods rely on reward signals and additional annotated data \u2026"}]
