[{"title": "Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks", "link": "https://arxiv.org/pdf/2405.10548", "details": "A Chatterjee, E Tanwar, S Dutta, T Chakraborty - arXiv preprint arXiv:2405.10548, 2024", "abstract": "Large Language Models (LLMs) have transformed NLP with their remarkable In- context Learning (ICL) capabilities. Automated assistants based on LLMs are gaining popularity; however, adapting them to novel tasks is still challenging. While colossal \u2026"}, {"title": "FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models", "link": "https://arxiv.org/pdf/2405.10286", "details": "A Bulat, Y Ouali, G Tzimiropoulos - arXiv preprint arXiv:2405.10286, 2024", "abstract": "Despite noise and caption quality having been acknowledged as important factors impacting vision-language contrastive pre-training, in this paper, we show that the full potential of improving the training process by addressing such issues is yet to be \u2026"}, {"title": "TopViewRS: Vision-Language Models as Top-View Spatial Reasoners", "link": "https://arxiv.org/pdf/2406.02537", "details": "C Li, C Zhang, H Zhou, N Collier, A Korhonen, I Vuli\u0107 - arXiv preprint arXiv \u2026, 2024", "abstract": "Top-view perspective denotes a typical way in which humans read and reason over different types of maps, and it is vital for localization and navigation of humans as well as ofnon-human'agents, such as the ones backed by large Vision-Language \u2026"}, {"title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models", "link": "https://arxiv.org/pdf/2406.02224", "details": "T Fan, G Ma, Y Kang, H Gu, L Fan, Q Yang - arXiv preprint arXiv:2406.02224, 2024", "abstract": "Recent research in federated large language models (LLMs) has primarily focused on enabling clients to fine-tune their locally deployed homogeneous LLMs collaboratively or on transferring knowledge from server-based LLMs to small \u2026"}, {"title": "Pseudo-Prompt Generating in Pre-trained Vision-Language Models for Multi-Label Medical Image Classification", "link": "https://arxiv.org/pdf/2405.06468", "details": "Y Ye, J Zhang, H Shi - arXiv preprint arXiv:2405.06468, 2024", "abstract": "The task of medical image recognition is notably complicated by the presence of varied and multiple pathological indications, presenting a unique challenge in multi- label classification with unseen labels. This complexity underlines the need for \u2026"}, {"title": "Observational Scaling Laws and the Predictability of Language Model Performance", "link": "https://arxiv.org/pdf/2405.10938", "details": "Y Ruan, CJ Maddison, T Hashimoto - arXiv preprint arXiv:2405.10938, 2024", "abstract": "Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different \u2026"}, {"title": "UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models", "link": "https://arxiv.org/pdf/2406.02110", "details": "Z Li, L Deng, H Liu, Q Liu, J Du - arXiv preprint arXiv:2406.02110, 2024", "abstract": "OwnThink stands as the most extensive Chinese open-domain knowledge graph introduced in recent times. Despite prior attempts in question answering over OwnThink (OQA), existing studies have faced limitations in model representation \u2026"}, {"title": "LA-UCL: LLM-Augmented Unsupervised Contrastive Learning Framework for Few-Shot Text Classification", "link": "https://aclanthology.org/2024.lrec-main.890.pdf", "details": "J Zhang, H Gao, P Zhang, B Feng, W Deng, Y Hou - Proceedings of the 2024 Joint \u2026, 2024", "abstract": "The few-shot tasks require the model to have the ability to generalize from a few samples. However, due to the lack of cognitive ability, the current works cannot fully utilize limited samples to expand the sample space and still suffer from overfitting \u2026"}, {"title": "Zero-shot LLM-guided Counterfactual Generation for Text", "link": "https://arxiv.org/pdf/2405.04793", "details": "A Bhattacharjee, R Moraffah, J Garland, H Liu - arXiv preprint arXiv:2405.04793, 2024", "abstract": "Counterfactual examples are frequently used for model development and evaluation in many natural language processing (NLP) tasks. Although methods for automated counterfactual generation have been explored, such methods depend on models \u2026"}]
