[{"title": "Explainable and Interpretable Model for the Early Detection of Brain Stroke Using Optimized Boosting Algorithms", "link": "https://www.mdpi.com/2075-4418/14/22/2514", "details": "Y Dubey, Y Tarte, N Talatule, K Damahe, P Palsodkar\u2026 - Diagnostics, 2024", "abstract": "Stroke stands as a prominent global health issue, causing considerable mortality and debilitation. It arises when cerebral blood flow is compromised, leading to irreversible brain cell damage or death. Leveraging the power of machine learning \u2026"}, {"title": "Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising", "link": "https://arxiv.org/pdf/2411.03053%3F", "details": "T Huang, J Meng, H Chen, G Zheng, X Yang, X Yi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We investigate the construction of gradient-guided conditional diffusion models for reconstructing private images, focusing on the adversarial interplay between differential privacy noise and the denoising capabilities of diffusion models. While \u2026"}, {"title": "A lightweight and explainable model for driver abnormal behavior recognition", "link": "https://www.sciencedirect.com/science/article/pii/S0952197624017172", "details": "J Hao, X Sun, X Liu, D Hua, J Hu - Engineering Applications of Artificial Intelligence, 2025", "abstract": "With the advancement of intelligent transportation systems, accurate identification of driver abnormal behavior is crucial for enhancing road safety. However, the limited computing power of vehicular systems poses a challenge for running efficient and \u2026"}, {"title": "Interpretability as Approximation: Understanding Black-Box Models by Decision Boundary", "link": "https://www.mdpi.com/2079-9292/13/22/4339", "details": "H Dong, B Liu, D Ye, G Liu - Electronics, 2024", "abstract": "Currently, interpretability methods focus more on less objective human- understandable semantics. To objectify and standardize interpretability research, in this study, we provide notions of interpretability based on approximation theory. We \u2026"}, {"title": "Efficient Vision-Language pre-training via domain-specific learning for human activities", "link": "https://aclanthology.org/2024.emnlp-main.454.pdf", "details": "A Bulat, Y Ouali, R Guerrero, B Martinez\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Current Vision-Language (VL) models owe their success to large-scale pre- training on web-collected data, which in turn requires high-capacity architectures and large compute resources for training. We posit that when the downstream tasks are \u2026"}, {"title": "A Proposal for Explainable Fruit Quality Recognition Using Multimodal Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-76607-7_9", "details": "F Nu\u00f1ez, B Peralta, O Nicolis, L Caro, M Mora - Iberoamerican Congress on Pattern \u2026, 2024", "abstract": "The fruit industry in Chile has achieved global recognition for its productivity and leadership in fruit exportation, being the main exporter in the Southern Hemisphere, especially of cherries, grapes, and blueberries. Agricultural automation is a growing \u2026"}, {"title": "Evolved Hierarchical Masking for Self-Supervised Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10742293/", "details": "Z Feng, S Zhang - IEEE Transactions on Pattern Analysis and Machine \u2026, 2024", "abstract": "Existing Masked Image Modeling methods apply fixed mask patterns to guide the self- supervised training. As those mask patterns resort to different criteria to depict image contents, sticking to a fixed pattern leads to a limited vision cues modeling capability \u2026"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2411.03313%3F", "details": "H Zilong, Y Qinghao, K Bingyi, F Jiashi, F Haoqi - arXiv preprint arXiv:2411.03313, 2024", "abstract": "We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised \u2026"}]
