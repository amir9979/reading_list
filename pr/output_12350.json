[{"title": "M $^ 2$-VLP: Enhancing Multilingual Vision-Language Pre-Training via Multi-Grained Alignment", "link": "https://openreview.net/pdf%3Fid%3DAegCFewVum", "details": "A Ahmat, L Wang, Y Yang, B Ma, R Dong, K Lu, R Ma\u2026 - THE WEB CONFERENCE 2025", "abstract": "Recently, multilingual Vision-Language Pre-training (mVLP) has shown remarkable progress in learning joint representations across different modalities and languages. However, most existing methods learn semantic alignment at a coarse-grained level \u2026"}, {"title": "Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach", "link": "https://arxiv.org/pdf/2501.18320", "details": "T Pan, W Pu, L Zhao, R Zhou - arXiv preprint arXiv:2501.18320, 2025", "abstract": "Automated optimization modeling (AOM) has evoked considerable interest with the rapid evolution of large language models (LLMs). Existing approaches predominantly rely on prompt engineering, utilizing meticulously designed expert \u2026"}]
