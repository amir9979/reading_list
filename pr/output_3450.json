[{"title": "Self-Supervised Time-Series Anomaly Detection Using Learnable Data Augmentation", "link": "https://arxiv.org/pdf/2406.12260", "details": "K Choi, J Yi, J Mok, S Yoon - arXiv preprint arXiv:2406.12260, 2024", "abstract": "Continuous efforts are being made to advance anomaly detection in various manufacturing processes to increase the productivity and safety of industrial sites. Deep learning replaced rule-based methods and recently emerged as a promising \u2026"}, {"title": "Federated Distillation for Medical Image Classification: Towards Trustworthy Computer-Aided Diagnosis", "link": "https://arxiv.org/pdf/2407.02261", "details": "S Ren, Y Hu, S Chen, G Wang - arXiv preprint arXiv:2407.02261, 2024", "abstract": "Medical image classification plays a crucial role in computer-aided clinical diagnosis. While deep learning techniques have significantly enhanced efficiency and reduced costs, the privacy-sensitive nature of medical imaging data complicates centralized \u2026"}, {"title": "Improving Generalization in Offline Reinforcement Learning via Adversarial Data Splitting", "link": "https://openreview.net/pdf%3Fid%3DCV9PiQGt0i", "details": "D Wang, L Li, W Wei, Q Yu, HAO Jianye, J Liang - Forty-first International Conference on \u2026", "abstract": "Offline Reinforcement Learning (RL) commonly suffers from the out-of-distribution (OOD) overestimation issue due to the distribution shift. Prior work gradually shifts their focus from suppressing OOD overestimation to avoiding overly conservative \u2026"}, {"title": "Motion Consistency Model: Accelerating Video Diffusion with Disentangled Motion-Appearance Distillation", "link": "https://arxiv.org/pdf/2406.06890", "details": "Y Zhai, K Lin, Z Yang, L Li, J Wang, CC Lin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Image diffusion distillation achieves high-fidelity generation with very few sampling steps. However, applying these techniques directly to video diffusion often results in unsatisfactory frame quality due to the limited visual quality in public video datasets \u2026"}, {"title": "LLM-based Knowledge Pruning for Time Series Data Analytics on Edge-computing Devices", "link": "https://arxiv.org/pdf/2406.08765", "details": "R Jin, Q Xu, M Wu, Y Xu, D Li, X Li, Z Chen - arXiv preprint arXiv:2406.08765, 2024", "abstract": "Limited by the scale and diversity of time series data, the neural networks trained on time series data often overfit and show unsatisfacotry performances. In comparison, large language models (LLMs) recently exhibit impressive generalization in diverse \u2026"}]
