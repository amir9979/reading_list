[{"title": "Tinylvlm-ehub: Towards comprehensive and efficient evaluation for large vision-language models", "link": "https://ieeexplore.ieee.org/abstract/document/10858438/", "details": "W Shao, M Lei, Y Hu, P Gao, P Xu, K Zhang, F Meng\u2026 - IEEE Transactions on Big \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) have made significant strides in various multimodal tasks. Notably, GPT4V, Claude, Gemini, and others showcase exceptional multimodal capabilities, marked by profound comprehension and \u2026"}, {"title": "Efficient Architectures for High Resolution Vision-Language Models", "link": "https://arxiv.org/pdf/2501.02584", "details": "M Carvalho, B Martins - arXiv preprint arXiv:2501.02584, 2025", "abstract": "Vision-Language Models (VLMs) have recently experienced significant advancements. However, challenges persist in the accurate recognition of fine details within high resolution images, which limits performance in multiple tasks. This \u2026"}, {"title": "From My View to Yours: Ego-Augmented Learning in Large Vision Language Models for Understanding Exocentric Daily Living Activities", "link": "https://arxiv.org/pdf/2501.05711", "details": "D Reilly, MK Govind, S Das - arXiv preprint arXiv:2501.05711, 2025", "abstract": "Large Vision Language Models (LVLMs) have demonstrated impressive capabilities in video understanding, yet their adoption for Activities of Daily Living (ADL) remains limited by their inability to capture fine-grained interactions and spatial relationships \u2026"}, {"title": "Guiding Medical Vision-Language Models with Explicit Visual Prompts: Framework Design and Comprehensive Exploration of Prompt Variations", "link": "https://arxiv.org/pdf/2501.02385", "details": "K Zhu, Z Qin, H Yi, Z Jiang, Q Lao, S Zhang, K Li - arXiv preprint arXiv:2501.02385, 2025", "abstract": "With the recent advancements in vision-language models (VLMs) driven by large language models (LLMs), many researchers have focused on models that comprised of an image encoder, an image-to-language projection layer, and a text decoder \u2026"}, {"title": "Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation", "link": "https://arxiv.org/pdf/2501.03545%3F", "details": "C Samarinas, A Krubner, A Salemi, Y Kim, H Zamani - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper presents ICAT, an evaluation framework for measuring coverage of diverse factual information in long-form text generation. ICAT breaks down a long output text into a list of atomic claims and not only verifies each claim through \u2026"}, {"title": "Recalibrated cross-modal alignment network for radiology report generation with weakly supervised contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425000168", "details": "X Hou, X Li, Z Liu, S Sang, M Lu, Y Zhang - Expert Systems with Applications, 2025", "abstract": "Automatic radiology report generation is rapidly becoming an essential method for medical diagnosis and precision medicine, which will help clinical doctors make more informed decisions and achieve better results. Most previous studies mainly \u2026"}, {"title": "Denoising Multi-Level Cross-Attention and Contrastive Learning for Chest Radiology Report Generation", "link": "https://link.springer.com/article/10.1007/s10278-025-01422-9", "details": "D Zhu, L Liu, X Yang, L Liu, W Peng - Journal of Imaging Informatics in Medicine, 2025", "abstract": "Chest radiology report generation plays a vital role in supporting diagnosis, alleviating physician workload, and reducing the risk of misdiagnosis. However, significant challenges persist:(1) Data bias and background noise in chest images \u2026"}, {"title": "MiniMedGPT: Efficient Large Vision-Language Model for medical Visual Question Answering", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525000017", "details": "AR Alsabbagh, T Mansour, M Al-Kharabsheh\u2026 - Pattern Recognition Letters, 2025", "abstract": "Abstract While Large Vision-Language Models (LVLMs) like GPT-4 and Gemini demonstrate significant potential, their utilization in the medical domain remains largely unexplored. This is due to challenges attributed to prolonged training and \u2026"}, {"title": "Expert evaluation of large language models for clinical dialogue summarization", "link": "https://www.nature.com/articles/s41598-024-84850-x", "details": "D Fraile Navarro, E Coiera, TW Hambly, Z Triplett\u2026 - Scientific Reports, 2025", "abstract": "We assessed the performance of large language models' summarizing clinical dialogues using computational metrics and human evaluations. The comparison was done between automatically generated and human-produced summaries. We \u2026"}]
