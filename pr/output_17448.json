[{"title": "Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving", "link": "https://arxiv.org/pdf/2506.08349", "details": "Y Zhou, X Liu, C Yan, C Ning, X Zhang, B Li, X Fu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 Based on these findings, we offer the following insights for applying and developing **large** **language** **models** to address real-world **clinical** challenges: (1) Model Selection: For low-level **medical** tasks such as knowledge-based **question** \u2026", "entry_id": "http://arxiv.org/abs/2506.08349v1", "updated": "2025-06-10 02:07:33", "published": "2025-06-10 02:07:33", "authors": "Yuxuan Zhou;Xien Liu;Chenwei Yan;Chen Ning;Xiao Zhang;Boxun Li;Xiangling Fu;Shijin Wang;Guoping Hu;Yu Wang;Ji Wu", "summary": "Large language models (LLMs) have demonstrated remarkable performance on\nvarious medical benchmarks, but their capabilities across different cognitive\nlevels remain underexplored. Inspired by Bloom's Taxonomy, we propose a\nmulti-cognitive-level evaluation framework for assessing LLMs in the medical\ndomain in this study. The framework integrates existing medical datasets and\nintroduces tasks targeting three cognitive levels: preliminary knowledge grasp,\ncomprehensive knowledge application, and scenario-based problem solving. Using\nthis framework, we systematically evaluate state-of-the-art general and medical\nLLMs from six prominent families: Llama, Qwen, Gemma, Phi, GPT, and DeepSeek.\nOur findings reveal a significant performance decline as cognitive complexity\nincreases across evaluated models, with model size playing a more critical role\nin performance at higher cognitive levels. Our study highlights the need to\nenhance LLMs' medical capabilities at higher cognitive levels and provides\ninsights for developing LLMs suited to real-world medical applications.", "comment": "20 pages, 11 figures. Accepted by ICML 2025", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2506.08349v1;http://arxiv.org/pdf/2506.08349v1", "pdf_url": "http://arxiv.org/pdf/2506.08349v1"}, {"title": "Causal Discovery through Synergizing Large Language Model and Data-Driven Reasoning", "link": "https://www.cs.emory.edu/~jyang71/files/llmcd.pdf", "details": "H Du, Y Zheng, B Jing, Y Zhao, G Kou, G Liu, T Gu\u2026 - 2025", "abstract": "\u2026 To address this issue, this paper proposes a novel causal modeling framework, LLM-CD, which integrates the metadata-based reasoning capabilities of **large** **language** **models** (LLMs) with the data-driven modeling abilities of TCDA for causal \u2026"}, {"title": "Application of Gemini in Public Health Amid the Artificial Intelligence Era", "link": "https://ieeexplore.ieee.org/abstract/document/11028593/", "details": "M Tatar, S Farokhi, AA Foumani, E Uzunlar, OM Araz - IEEE Engineering \u2026, 2025", "abstract": "\u2026 , Gemini can **answer** complex **medical** **questions** in an easy-to-understand context, creating smooth communication between **clinicians** and \u2026 Zhang, Y., et al., Potenfial of mulfimodal **large** **language** **models** for data mining of **medical** images and free-text \u2026"}, {"title": "How do the Available LLM Platforms Fare as On-the-Go Orthopaedic Referencing Source? A Comparative Analysis", "link": "https://link.springer.com/article/10.1007/s43465-025-01430-5", "details": "G Chellamuthu, S Muthu, S Siddamanickam\u2026 - Indian Journal of \u2026, 2025", "abstract": "\u2026 BioBERT had superior scores when compared to BERT in functions like named entity recognition, **question** **answering** and relation \u2026 **Clinicians** can effectively utilize **large** **language** **models** (LLMs) to access a broad range of references for \u2026"}, {"title": "Generative AI and Foundation Models", "link": "https://www.ulopenaccess.com/papers/ULIRS_V02I02/ULIRS20250202_002.pdf", "details": "VSR Narapareddy - Universal Library of Innovative Research and Studies, 2025", "abstract": "\u2026 For instance, Reinforcement Learning with Human Feedback (RLHF) has become a popular technique to align **large** **language** **models** with \u2026 Integration with **large** **language** **models** enables robots to follow high-level natural language \u2026"}, {"title": "Hybrid AI for Process Management-Improving Similarity Assessment in Process-Oriented Case-Based Reasoning via Deep Learning", "link": "https://ubt.opus.hbz-nrw.de/opus45-ubtr/files/2518/Dissertation_Hoffmann.pdf", "details": "M Hoffmann", "abstract": "\u2026 raw data to solve complex AI problems such as object detection, **question** **answering** , and machine translation. While DL minimizes manual \u2026 domain of argumentation [93] extends the initial approach and includes **Large** **Language** \u2026"}, {"title": "Agentic AI: Theories and Practices", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DsKNkEQAAQBAJ%26oi%3Dfnd%26pg%3DPR7%26dq%3Dclinical%2Bquestion%2Banswering%2B%2B%2522large%2Blanguage%2Bmodels%2522%26ots%3DgHegqTEQvw%26sig%3DOvnNc5-5ch_nZWvp8PRt8mET538", "details": "K Huang - 2025", "abstract": "\u2026 The advent of **large** **language** **models** and transformer architectures has enabled agents with unprecedented language understanding and \u2026 Recent **large** **language** **models** like GPT-4, Claud 3, and Gemini and their successors have pushed the \u2026"}]
