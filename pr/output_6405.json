[{"title": "MixIR: Mixing Input and Representations for Contrastive Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10636233/", "details": "T Zhao, X Guo, Y Lin, B Du - IEEE Transactions on Neural Networks and Learning \u2026, 2024", "abstract": "Recently, contrastive learning has shown significant progress in learning visual representations from unlabeled data. The core idea is training the backbone to be invariant to different augmentations of an instance. While most methods only \u2026"}, {"title": "Enhancing Contrastive Learning on Graphs with Node Similarity", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671898", "details": "H Chi, Y Ma - Proceedings of the 30th ACM SIGKDD Conference on \u2026, 2024", "abstract": "Graph Neural Networks (GNN) have proven successful for graph-related tasks. However, many GNNs methods require labeled data, which is challenging to obtain. To tackle this, graph contrastive learning (GCL) have gained attention. GCL learns by \u2026"}, {"title": "TriCI: Triple Cross-Intra Branch Contrastive Learning for Point Cloud Analysis", "link": "https://ieeexplore.ieee.org/abstract/document/10640279/", "details": "D Shao, X Lu, W Wang, X Liu, AS Mian - IEEE Transactions on Visualization and \u2026, 2024", "abstract": "Whereas contrastive learning eliminates the need for labeled data, existing methods may suffer from inadequate features due to the conventional single shared encoder structure and struggle to fully harness the rich spectrum of 3D augmentations. In this \u2026"}, {"title": "Self-Supervised Contrastive Learning for Videos using Differentiable Local Alignment", "link": "https://arxiv.org/pdf/2409.04607", "details": "K Oei, A Gomaa, AM Feit, J Belo - arXiv preprint arXiv:2409.04607, 2024", "abstract": "Robust frame-wise embeddings are essential to perform video analysis and understanding tasks. We present a self-supervised method for representation learning based on aligning temporal video sequences. Our framework uses a \u2026"}, {"title": "Self-supervised Anomaly Detection Pretraining Enhances Long-tail ECG Diagnosis", "link": "https://arxiv.org/pdf/2408.17154", "details": "A Jiang, C Huang, Q Cao, Y Xu, Z Zeng, K Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Current computer-aided ECG diagnostic systems struggle with the underdetection of rare but critical cardiac anomalies due to the imbalanced nature of ECG datasets. This study introduces a novel approach using self-supervised anomaly detection \u2026"}, {"title": "MSCPT: Few-shot Whole Slide Image Classification with Multi-scale and Context-focused Prompt Tuning", "link": "https://arxiv.org/pdf/2408.11505", "details": "M Han, L Qu, D Yang, X Zhang, X Wang, L Zhang - arXiv preprint arXiv:2408.11505, 2024", "abstract": "Multiple instance learning (MIL) has become a standard paradigm for weakly supervised classification of whole slide images (WSI). However, this paradigm relies on the use of a large number of labelled WSIs for training. The lack of training data \u2026"}, {"title": "Clinical Context-aware Radiology Report Generation from Medical Images using Transformers", "link": "https://arxiv.org/pdf/2408.11344", "details": "S Singh - arXiv preprint arXiv:2408.11344, 2024", "abstract": "Recent developments in the field of Natural Language Processing, especially language models such as the transformer have brought state-of-the-art results in language understanding and language generation. In this work, we investigate the \u2026"}, {"title": "DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised Vector-LoRA of the Foundation Model", "link": "https://arxiv.org/pdf/2408.17433", "details": "MS Zeinoddin, C Lena, J Qu, L Carlini, M Magro, S Kim\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Robotic-assisted surgery (RAS) relies on accurate depth estimation for 3D reconstruction and visualization. While foundation models like Depth Anything Models (DAM) show promise, directly applying them to surgery often yields \u2026"}, {"title": "Cross-Domain Foundation Model Adaptation: Pioneering Computer Vision Models for Geophysical Data Analysis", "link": "https://arxiv.org/pdf/2408.12396", "details": "Z Guo, X Wu, L Liang, H Sheng, N Chen, Z Bi - arXiv preprint arXiv:2408.12396, 2024", "abstract": "We explore adapting foundation models (FMs) from the computer vision domain to geoscience. FMs, large neural networks trained on massive datasets, excel in diverse tasks with remarkable adaptability and generality. However, geoscience \u2026"}]
