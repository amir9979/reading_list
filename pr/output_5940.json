[{"title": "On Robustness-Accuracy Characterization of Language Models using Synthetic Datasets", "link": "https://openreview.net/pdf%3Fid%3DC0j44uRPcl", "details": "CY Ko, PY Chen, P Das, YS Chuang, L Daniel - First Conference on Language Modeling", "abstract": "In recent years, language models (LMs) that were pretrained at scale on diverse data have proven to be a successful approach for solving different downstream tasks. However, new concerns about proper performance evaluation have been raised \u2026"}, {"title": "A large-scale audit of dataset licensing and attribution in AI", "link": "https://www.nature.com/articles/s42256-024-00878-8", "details": "S Longpre, R Mahari, A Chen, N Obeng-Marnu, D Sileo\u2026 - Nature Machine Intelligence, 2024", "abstract": "The race to train language models on vast, diverse and inconsistently documented datasets raises pressing legal and ethical concerns. To improve data transparency and understanding, we convene a multi-disciplinary effort between legal and \u2026"}, {"title": "A Gradient Analysis Framework for Rewarding Good and Penalizing Bad Examples in Language Models", "link": "https://arxiv.org/pdf/2408.16751", "details": "YL Tuan, WY Wang - arXiv preprint arXiv:2408.16751, 2024", "abstract": "Beyond maximum likelihood estimation (MLE), the standard objective of a language model (LM) that optimizes good examples probabilities, many studies have explored ways that also penalize bad examples for enhancing the quality of output distribution \u2026"}, {"title": "Unleash The Power of Pre-Trained Language Models for Irregularly Sampled Time Series", "link": "https://arxiv.org/pdf/2408.08328", "details": "W Zhang, C Yin, H Liu, H Xiong - arXiv preprint arXiv:2408.08328, 2024", "abstract": "Pre-trained Language Models (PLMs), such as ChatGPT, have significantly advanced the field of natural language processing. This progress has inspired a series of innovative studies that explore the adaptation of PLMs to time series \u2026"}, {"title": "BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems", "link": "https://arxiv.org/pdf/2408.15971", "details": "W Wang, D Zhang, T Feng, B Wang, J Tang - arXiv preprint arXiv:2408.15971, 2024", "abstract": "Large Language Models (LLMs) are becoming increasingly powerful and capable of handling complex tasks, eg, building single agents and multi-agent systems. Compared to single agents, multi-agent systems have higher requirements for the \u2026"}, {"title": "BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models", "link": "https://arxiv.org/pdf/2408.12798", "details": "Y Li, H Huang, Y Zhao, X Ma, J Sun - arXiv preprint arXiv:2408.12798, 2024", "abstract": "Generative Large Language Models (LLMs) have made significant strides across various tasks, but they remain vulnerable to backdoor attacks, where specific triggers in the prompt cause the LLM to generate adversary-desired responses. While most \u2026"}, {"title": "Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models", "link": "https://arxiv.org/pdf/2408.14866", "details": "H Liu, Y Xie, Y Wang, M Shieh - arXiv preprint arXiv:2408.14866, 2024", "abstract": "Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy \u2026"}, {"title": "A Law of Next-Token Prediction in Large Language Models", "link": "https://arxiv.org/pdf/2408.13442", "details": "H He, WJ Su - arXiv preprint arXiv:2408.13442, 2024", "abstract": "Large language models (LLMs) have been widely employed across various application domains, yet their black-box nature poses significant challenges to understanding how these models process input data internally to make predictions \u2026"}, {"title": "Measuring and Controlling Instruction (In) Stability in Language Model Dialogs", "link": "https://openreview.net/pdf%3Fid%3D60a1SAtH4e", "details": "K Li, T Liu, N Bashkansky, D Bau, F Vi\u00e9gas, H Pfister\u2026 - First Conference on \u2026, 2024", "abstract": "System-prompting is a standard tool for customizing language-model chatbots, enabling them to follow a specific instruction. An implicit assumption in the use of system prompts is that they will be _stable_, so the chatbot will continue to generate \u2026"}]
