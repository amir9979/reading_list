[{"title": "Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification", "link": "https://arxiv.org/pdf/2410.18686", "details": "X Tao, T Pan, M Cheng, Y Luo - arXiv preprint arXiv:2410.18686, 2024", "abstract": "Leveraging large language models (LLMs) has garnered increasing attention and introduced novel perspectives in time series classification. However, existing approaches often overlook the crucial dynamic temporal information inherent in time \u2026"}, {"title": "DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting", "link": "https://arxiv.org/pdf/2410.22981", "details": "Z Liu, J Yang, Q Mao, Y Zhao, M Cheng, Z Li, Q Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multivariate time series forecasting plays a crucial role in various real-world applications. Significant efforts have been made to integrate advanced network architectures and training strategies that enhance the capture of temporal \u2026"}, {"title": "Approximate attention with MLP: a pruning strategy for attention-based model in multivariate time series forecasting", "link": "https://arxiv.org/pdf/2410.24023", "details": "S Guo, J Deng, Y Wei, H Dou, F Shen, J Zhao - arXiv preprint arXiv:2410.24023, 2024", "abstract": "Attention-based architectures have become ubiquitous in time series forecasting tasks, including spatio-temporal (STF) and long-term time series forecasting (LTSF). Yet, our understanding of the reasons for their effectiveness remains limited. This \u2026"}, {"title": "VPformer: Multivariate Time Series Forecasting with Variable Correlation and Triple Patch Correlation Transformer", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9434-8_13", "details": "Z Wang, Y Huang, C Zhao, C Zhou - \u2026 on Natural Language Processing and Chinese \u2026, 2024", "abstract": "Time series forecasting is vital in industries like weather and transportation. However, Transformer models may face challenges capturing both variable and temporal correlations in multivariate forecasting, potentially hindering their \u2026"}, {"title": "Enhancing Zero-Shot Vision Models by Label-Free Prompt Distribution Learning and Bias Correcting", "link": "https://arxiv.org/pdf/2410.19294", "details": "X Zhu, B Zhu, Y Tan, S Wang, Y Hao, H Zhang - arXiv preprint arXiv:2410.19294, 2024", "abstract": "Vision-language models, such as CLIP, have shown impressive generalization capacities when using appropriate text descriptions. While optimizing prompts on downstream labeled data has proven effective in improving performance, these \u2026"}]
