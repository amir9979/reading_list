'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [AsCL: An Asymmetry-sensitive Contrastive Learning Meth'
[{"title": "TransMI: A Framework to Create Strong Baselines from Multilingual Pretrained Language Models for Transliterated Data", "link": "https://arxiv.org/pdf/2405.09913", "details": "Y Liu, C Ma, H Ye, H Sch\u00fctze - arXiv preprint arXiv:2405.09913, 2024", "abstract": "Transliterating related languages that use different scripts into a common script shows effectiveness in improving crosslingual transfer in downstream tasks. However, this methodology often makes pretraining a model from scratch \u2026"}, {"title": "DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for Unconventional Reasoning", "link": "https://arxiv.org/pdf/2405.11559", "details": "SV Mathur, AR Jindal, M Shrivastava - arXiv preprint arXiv:2405.11559, 2024", "abstract": "While significant work has been done in the field of NLP on vertical thinking, which involves primarily logical thinking, little work has been done towards lateral thinking, which involves looking at problems from an unconventional perspective and defying \u2026"}, {"title": "Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization", "link": "https://arxiv.org/pdf/2405.10616", "details": "Y Ji, Y Xiang, J Li, W Chen, Z Liu, K Chen, M Zhang - arXiv preprint arXiv:2405.10616, 2024", "abstract": "In recent years, large language models (LLMs) have driven advances in natural language processing. Still, their growing scale has increased the computational burden, necessitating a balance between efficiency and performance. Low-rank \u2026"}, {"title": "Factual Serialization Enhancement: A Key Innovation for Chest X-ray Report Generation", "link": "https://arxiv.org/pdf/2405.09586", "details": "K Liu, Z Ma, M Liu, Z Jiao, X Kang, Q Miao, K Xie - arXiv preprint arXiv:2405.09586, 2024", "abstract": "The automation of writing imaging reports is a valuable tool for alleviating the workload of radiologists. Crucial steps in this process involve the cross-modal alignment between medical images and reports, as well as the retrieval of similar \u2026"}, {"title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2405.07551", "details": "S Yin, W You, Z Ji, G Zhong, J Bai - arXiv preprint arXiv:2405.07551, 2024", "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math \u2026"}, {"title": "CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios", "link": "https://arxiv.org/pdf/2404.15272", "details": "J Lin, Y Xia, J Zhang, K Yan, L Lu, J Luo, L Zhang - arXiv preprint arXiv:2404.15272, 2024", "abstract": "Medical Vision-Language Pretraining (Med-VLP) establishes a connection between visual content from medical images and the relevant textual descriptions. Existing Med-VLP methods primarily focus on 2D images depicting a single body part \u2026"}, {"title": "FDT\u2212 Dr2T: a unified Dense Radiology Report Generation Transformer framework for X-ray images", "link": "https://link.springer.com/article/10.1007/s00138-024-01544-0", "details": "D Sharma, C Dhiman, D Kumar - Machine Vision and Applications, 2024", "abstract": "Abstract Medical Image Captioning (MIC), is a developing area of artificial intelligence that combines two main research areas, computer vision and natural language processing. In order to support clinical workflows and decision-making \u2026"}, {"title": "Observational Scaling Laws and the Predictability of Language Model Performance", "link": "https://arxiv.org/pdf/2405.10938", "details": "Y Ruan, CJ Maddison, T Hashimoto - arXiv preprint arXiv:2405.10938, 2024", "abstract": "Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different \u2026"}, {"title": "Detection of Korean Phishing Messages Using Biased Discriminant Analysis under Extreme Class Imbalance Problem", "link": "https://www.mdpi.com/2078-2489/15/5/265/pdf", "details": "S Kim, J Park, H Ahn, Y Lee - Information, 2024", "abstract": "In South Korea, the rapid proliferation of smartphones has led to an uptick in messenger phishing attacks associated with electronic communication financial scams. In response to this, various phishing detection algorithms have been \u2026"}]
