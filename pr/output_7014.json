[{"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Pushing the Limits of Vision-Language Models in Remote Sensing without Human Annotations", "link": "https://arxiv.org/pdf/2409.07048", "details": "K Cha, D Yu, J Seo - arXiv preprint arXiv:2409.07048, 2024", "abstract": "The prominence of generalized foundation models in vision-language integration has witnessed a surge, given their multifarious applications. Within the natural domain, the procurement of vision-language datasets to construct these foundation \u2026"}, {"title": "Small Language Models: Survey, Measurements, and Insights", "link": "https://arxiv.org/pdf/2409.15790", "details": "Z Lu, X Li, D Cai, R Yi, F Liu, X Zhang, ND Lane, M Xu - arXiv preprint arXiv \u2026, 2024", "abstract": "Small language models (SLMs), despite their widespread adoption in modern smart devices, have received significantly less academic attention compared to their large language model (LLM) counterparts, which are predominantly deployed in data \u2026"}, {"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "Generative Chain-of-Thought for Zero-Shot Cognitive Reasoning", "link": "https://link.springer.com/chapter/10.1007/978-3-031-72344-5_22", "details": "L Liu, D Zhang, S Zhu, S Li - International Conference on Artificial Neural Networks, 2024", "abstract": "Cognitive reasoning holds a significant place within the field of Natural Language Processing (NLP). Yet, the exploration of zero-shot scenarios, which align more closely with real-life situations than supervised scenarios, has been relatively limited \u2026"}, {"title": "ControlMath: Controllable Data Generation Promotes Math Generalist Models", "link": "https://arxiv.org/pdf/2409.15376", "details": "N Chen, N Wu, J Chang, J Li - arXiv preprint arXiv:2409.15376, 2024", "abstract": "Utilizing large language models (LLMs) for data augmentation has yielded encouraging results in mathematical reasoning. However, these approaches face constraints in problem diversity, potentially restricting them to in-domain/distribution \u2026"}, {"title": "On the Relationship between Truth and Political Bias in Language Models", "link": "https://arxiv.org/pdf/2409.05283", "details": "S Fulay, W Brannon, S Mohanty, C Overney\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model alignment research often attempts to ensure that models are not only helpful and harmless, but also truthful and unbiased. However, optimizing these objectives simultaneously can obscure how improving one aspect might impact the \u2026"}, {"title": "PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions", "link": "https://arxiv.org/pdf/2409.05076", "details": "Y Zhang, R Xie, J Chen, X Sun, Y Wang - arXiv preprint arXiv:2409.05076, 2024", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated their powerful multimodal capabilities. However, they also face serious safety problems, as adversaries can induce robustness issues in LVLMs through the use of well \u2026"}, {"title": "Building A Coding Assistant via the Retrieval-Augmented Language Model", "link": "https://dl.acm.org/doi/abs/10.1145/3695868", "details": "X Li, H Wang, Z Liu, S Yu, S Wang, Y Yan, Y Fu, Y Gu\u2026 - ACM Transactions on Information \u2026", "abstract": "Pretrained language models have shown strong effectiveness in code-related tasks, such as code retrieval, code generation, code summarization, and code completion tasks. In this paper, we propose CO de assista N t vi A retrieval-augme N ted \u2026"}]
