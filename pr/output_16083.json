[{"title": "SilVar-Med: A Speech-Driven Visual Language Model for Explainable Abnormality Detection in Medical Imaging", "link": "https://arxiv.org/pdf/2504.10642", "details": "TH Pham, C Ngo, TD Bui, ML Quang, TH Pham, TS Hy - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical Visual Language Models have shown great potential in various healthcare applications, including medical image captioning and diagnostic assistance. However, most existing models rely on text-based instructions, limiting their usability \u2026"}, {"title": "Self-alignment of Large Video Language Models with Refined Regularized Preference Optimization", "link": "https://arxiv.org/pdf/2504.12083", "details": "P Sarkar, A Etemad - arXiv preprint arXiv:2504.12083, 2025", "abstract": "Despite recent advances in Large Video Language Models (LVLMs), they still struggle with fine-grained temporal understanding, hallucinate, and often make simple mistakes on even simple video question-answering tasks, all of which pose \u2026"}, {"title": "MOM: Memory-Efficient Offloaded Mini-Sequence Inference for Long Context Language Models", "link": "https://arxiv.org/pdf/2504.12526%3F", "details": "J Zhang, T Zhu, C Luo, A Anandkumar - arXiv preprint arXiv:2504.12526, 2025", "abstract": "Long-context language models exhibit impressive performance but remain challenging to deploy due to high GPU memory demands during inference. We propose Memory-efficient Offloaded Mini-sequence Inference (MOM), a method that \u2026"}, {"title": "PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models", "link": "https://arxiv.org/pdf/2504.08966", "details": "M Dhouib, D Buscaldi, S Vanier, A Shabou - arXiv preprint arXiv:2504.08966, 2025", "abstract": "Visual Language Models require substantial computational resources for inference due to the additional input tokens needed to represent visual information. However, these visual tokens often contain redundant and unimportant information, resulting in \u2026"}, {"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}, {"title": "NNTile: a machine learning framework capable of training extremely large GPT language models on a single node", "link": "https://arxiv.org/pdf/2504.13236", "details": "A Mikhalev, A Katrutsa, K Sozykin, I Oseledets - arXiv preprint arXiv:2504.13236, 2025", "abstract": "This study presents an NNTile framework for training large deep neural networks in heterogeneous clusters. The NNTile is based on a StarPU library, which implements task-based parallelism and schedules all provided tasks onto all available \u2026"}, {"title": "Knowledge-augmented Pre-trained Language Models for Biomedical Relation Extraction", "link": "https://arxiv.org/pdf/2505.00814", "details": "M S\u00e4nger, U Leser - arXiv preprint arXiv:2505.00814, 2025", "abstract": "Automatic relationship extraction (RE) from biomedical literature is critical for managing the vast amount of scientific knowledge produced each year. In recent years, utilizing pre-trained language models (PLMs) has become the prevalent \u2026"}, {"title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data", "link": "https://arxiv.org/pdf/2504.09967", "details": "X Zhu, F Mo, Z Zhang, J Wang, Y Shi, M Wu, C Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The emergence of medical generalist foundation models has revolutionized conventional task-specific model development paradigms, aiming to better handle multiple tasks through joint training on large-scale medical datasets. However, recent \u2026"}, {"title": "AOR: Anatomical Ontology-Guided Reasoning for Medical Large Multimodal Model in Chest X-Ray Interpretation", "link": "https://arxiv.org/pdf/2505.02830", "details": "Q Li, Z Cui, S Bae, J Xu, R Yuan, Y Zhang, R Feng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Chest X-rays (CXRs) are the most frequently performed imaging examinations in clinical settings. Recent advancements in Large Multimodal Models (LMMs) have enabled automated CXR interpretation, enhancing diagnostic accuracy and \u2026"}]
