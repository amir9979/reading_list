[{"title": "Twofold Debiasing Enhances Fine-Grained Learning with Coarse Labels", "link": "https://arxiv.org/pdf/2502.19816", "details": "X Zhao, J Jin, Y Li, Y Yao - arXiv preprint arXiv:2502.19816, 2025", "abstract": "The Coarse-to-Fine Few-Shot (C2FS) task is designed to train models using only coarse labels, then leverages a limited number of subclass samples to achieve fine- grained recognition capabilities. This task presents two main challenges: coarse \u2026"}, {"title": "Cross-Modal Alignment Regularization: Enhancing Language Models with Vision Model Representations", "link": "https://openreview.net/pdf%3Fid%3D4Yag8mHVtc", "details": "Y Gan, KI Zhao, P Isola - Second Workshop on Representational Alignment at \u2026", "abstract": "Cross-modal distillation has emerged as a critical technique for leveraging the complementary strengths of different modalities. However, existing work has not enabled direct benefits between models trained on data from different modalities. In \u2026"}, {"title": "OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction", "link": "https://arxiv.org/pdf/2503.03734", "details": "H Huang, F Liu, L Fu, T Wu, M Mukadam, J Malik\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-Language-Action (VLA) models aim to predict robotic actions based on visual observations and language instructions. Existing approaches require fine-tuning pre- trained visionlanguage models (VLMs) as visual and language features are \u2026"}, {"title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "link": "https://arxiv.org/pdf/2503.01743", "details": "A Abouelenin, A Ashfaq, A Atkinson, H Awadalla\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality web and synthetic data, significantly outperforming recent \u2026"}]
