[{"title": "Leveraging explainable artificial intelligence for early prediction of bloodstream infections using historical electronic health records", "link": "https://journals.plos.org/digitalhealth/article%3Fid%3D10.1371/journal.pdig.0000506", "details": "R Bopche, LT Gustad, JE Afset, B Ehrnstr\u00f6m\u2026 - PLOS Digital Health, 2024", "abstract": "Bloodstream infections (BSIs) are a severe public health threat due to their rapid progression into critical conditions like sepsis. This study presents a novel eXplainable Artificial Intelligence (XAI) framework to predict BSIs using historical \u2026"}, {"title": "SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers", "link": "https://arxiv.org/pdf/2411.13428%3F", "details": "H Karami, D Atienza, A Ionescu - arXiv preprint arXiv:2411.13428, 2024", "abstract": "Generating synthetic Electronic Health Records (EHRs) offers significant potential for data augmentation, privacy-preserving data sharing, and improving machine learning model training. We propose a novel tokenization strategy tailored for \u2026"}, {"title": "Leveraging Self Weak-supervision for Improved VLM Performance", "link": "https://openreview.net/pdf%3Fid%3DksjzXcHdle", "details": "S Roy, A Etemad - Adaptive Foundation Models: Evolving AI for \u2026", "abstract": "In this work, we present SelfPrompt, a novel semi-supervised prompt-tuning approach for tuning vision-language models (VLMs) in a semi-supervised learning setup. Existing methods for tuning VLMs in semi-supervised setup struggle with the \u2026"}, {"title": "Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning", "link": "https://arxiv.org/pdf/2411.13623", "details": "T Lenz, P Neidlinger, M Ligero, G W\u00f6lflein\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Representation learning of pathology whole-slide images (WSIs) has primarily relied on weak supervision with Multiple Instance Learning (MIL). This approach leads to slide representations highly tailored to a specific clinical task. Self-supervised \u2026"}, {"title": "General Geospatial Inference with a Population Dynamics Foundation Model", "link": "https://arxiv.org/pdf/2411.07207%3F", "details": "M Agarwal, M Sun, C Kamath, A Muslim, P Sarker\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Supporting the health and well-being of dynamic populations around the world requires governmental agencies, organizations and researchers to understand and reason over complex relationships between human behavior and local contexts in \u2026"}, {"title": "Text as Images: Can Multimodal Large Language Models Follow Printed Instructions in Pixels?", "link": "https://openreview.net/pdf%3Fid%3DdC9kEMBchM", "details": "X Li, Y Lu, WY Wang, Y Choi - Adaptive Foundation Models: Evolving AI for \u2026, 2024", "abstract": "Recent multimodal large language models (MLLMs) have shown promising instruction following capabilities on vision-language tasks. In this work, we introduce VISUAL MODALITY INSTRUCTION (VIM) 1, and investigate how well multimodal \u2026"}]
