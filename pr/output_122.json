'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [K2: A foundation language model for geoscience knowledge und'
[{"title": "Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations", "link": "https://arxiv.org/pdf/2402.12038", "details": "M Bhan, JN Vittaut, N Chesneau, MJ Lesot - arXiv preprint arXiv:2402.12038, 2024", "abstract": "Incorporating natural language rationales in the prompt and In-Context Learning (ICL) has led to a significant improvement of Large Language Models (LLMs) performance. However, rationales currently require human-annotation or the use of \u2026"}, {"title": "Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization", "link": "https://arxiv.org/pdf/2403.00067", "details": "MTR Laskar, E Khasanova, XY Fu, C Chen, SB TN - arXiv preprint arXiv:2403.00067, 2024", "abstract": "This work focuses on the task of query-based meeting summarization in which the summary of a context (meeting transcript) is generated in response to a specific query. When using Large Language Models (LLMs) for this task, a new call to the \u2026"}, {"title": "RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models", "link": "https://arxiv.org/html/2403.02271v1", "details": "S Najafi, A Fyshe - arXiv preprint arXiv:2403.02271, 2024", "abstract": "Pre-trained Language Models (PLMs) can be accurately fine-tuned for downstream text processing tasks. Recently, researchers have introduced several parameter- efficient fine-tuning methods that optimize input prompts or adjust a small number of \u2026"}, {"title": "Anatomical Structure-Guided Medical Vision-Language Pre-training", "link": "https://arxiv.org/pdf/2403.09294", "details": "Q Li, X Yan, J Xu, R Yuan, Y Zhang, R Feng, Q Shen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Learning medical visual representations through vision-language pre-training has reached remarkable progress. Despite the promising performance, it still faces challenges, ie, local alignment lacks interpretability and clinical relevance, and the \u2026"}, {"title": "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods", "link": "https://arxiv.org/pdf/2403.00998", "details": "P Tsvilodub, H Wang, S Grosch, M Franke - arXiv preprint arXiv:2403.00998, 2024", "abstract": "This paper systematically compares different methods of deriving item-level predictions of language models for multiple-choice tasks. It compares scoring methods for answer options based on free generation of responses, various \u2026"}, {"title": "Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds", "link": "https://arxiv.org/pdf/2403.06609", "details": "J Wu, X Wu, J Yang - arXiv preprint arXiv:2403.06609, 2024", "abstract": "Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients. This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate \u2026"}, {"title": "CLIPping the Deception: Adapting Vision-Language Models for Universal Deepfake Detection", "link": "https://arxiv.org/pdf/2402.12927", "details": "SA Khan, DT Dang-Nguyen - arXiv preprint arXiv:2402.12927, 2024", "abstract": "The recent advancements in Generative Adversarial Networks (GANs) and the emergence of Diffusion models have significantly streamlined the production of highly realistic and widely accessible synthetic content. As a result, there is a \u2026"}, {"title": "AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions", "link": "https://arxiv.org/pdf/2403.09346", "details": "H Zhang, W Shao, H Liu, Y Ma, P Luo, Y Qiao, K Zhang - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have shown significant progress in well responding to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent \u2026"}, {"title": "Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale", "link": "https://arxiv.org/html/2403.08293v1", "details": "X Hu, P Ji, Q Zhu, W Wu, K Tu - arXiv preprint arXiv:2403.08293, 2024", "abstract": "A syntactic language model (SLM) incrementally generates a sentence with its syntactic tree in a left-to-right manner. We present Generative Pretrained Structured Transformers (GPST), an unsupervised SLM at scale capable of being pre-trained \u2026"}]
