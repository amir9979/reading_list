[{"title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality", "link": "https://arxiv.org/pdf/2411.11531", "details": "V Chekalina, A Razzigaev, E Goncharova, A Kuznetsov - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper we present an approach to reduce hallucinations in Large Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional modality. Our method involves transforming input text into a set of KG embeddings and using \u2026"}, {"title": "MegaCOIN: Enhancing Medium-Grained Color Perception for Vision-Language Models", "link": "https://arxiv.org/pdf/2412.03927", "details": "MC Chiu, S Wen, PY Chen, X Ma - arXiv preprint arXiv:2412.03927, 2024", "abstract": "In vision-language models (VLMs), the ability to perceive and interpret color and physical environment is crucial for achieving contextually accurate understanding and interaction. However, despite advances in multimodal modeling, there remains a \u2026"}, {"title": "DHCP: Detecting Hallucinations by Cross-modal Attention Pattern in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2411.18659", "details": "Y Zhang, R Xie, J Chen, X Sun, Y Wang - arXiv preprint arXiv:2411.18659, 2024", "abstract": "Large vision-language models (LVLMs) have demonstrated exceptional performance on complex multimodal tasks. However, they continue to suffer from significant hallucination issues, including object, attribute, and relational \u2026"}, {"title": "Safe+ Safe= Unsafe? Exploring How Safe Images Can Be Exploited to Jailbreak Large Vision-Language Models", "link": "https://arxiv.org/pdf/2411.11496", "details": "C Cui, G Deng, A Zhang, J Zheng, Y Li, L Gao, T Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in Large Vision-Language Models (LVLMs) have showcased strong reasoning abilities across multiple modalities, achieving significant breakthroughs in various real-world applications. Despite this great success, the \u2026"}, {"title": "Self-Generated Critiques Boost Reward Modeling for Language Models", "link": "https://arxiv.org/pdf/2411.16646%3F", "details": "Y Yu, Z Chen, A Zhang, L Tan, C Zhu, RY Pang, Y Qian\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reward modeling is crucial for aligning large language models (LLMs) with human preferences, especially in reinforcement learning from human feedback (RLHF). However, current reward models mainly produce scalar scores and struggle to \u2026"}, {"title": "NLPrompt: Noise-Label Prompt Learning for Vision-Language Models", "link": "https://arxiv.org/pdf/2412.01256", "details": "B Pan, Q Li, X Tang, W Huang, Z Fang, F Liu, J Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence of vision-language foundation models, such as CLIP, has revolutionized image-text representation, enabling a broad range of applications via prompt learning. Despite its promise, real-world datasets often contain noisy labels \u2026"}, {"title": "metaTextGrad: Learning to learn with language models as optimizers", "link": "https://openreview.net/pdf%3Fid%3DyzieYIT9hu", "details": "G Xu, M Yuksekgonul, C Guestrin, J Zou - Adaptive Foundation Models: Evolving AI for \u2026", "abstract": "Large language models (LLMs) are increasingly used in learning algorithms, evaluations, and optimization tasks. Recent studies have shown that incorporating self-criticism into LLMs can significantly enhance model performance, with \u2026"}, {"title": "LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models", "link": "https://arxiv.org/pdf/2411.06839", "details": "R Yang, T Wu, J Wang, P Hu, N Wong, Y Yang - arXiv preprint arXiv:2411.06839, 2024", "abstract": "In this paper, we propose a novel LLM-Neo framework that efficiently transfers knowledge from a large language model (LLM) teacher to a compact student. Initially, we revisit the knowledge distillation (KD) and low-rank adaption (LoRA), and \u2026"}, {"title": "\\textsc {Neon}: News Entity-Interaction Extraction for Enhanced Question Answering", "link": "https://arxiv.org/pdf/2411.12449", "details": "S Singhania, S Cucerzan, A Herring, SK Jauhar - arXiv preprint arXiv:2411.12449, 2024", "abstract": "Capturing fresh information in near real-time and using it to augment existing large language models (LLMs) is essential to generate up-to-date, grounded, and reliable output. This problem becomes particularly challenging when LLMs are used for \u2026"}]
