[{"title": "$ S^ 3$: Synonymous Semantic Space for Improving Zero-Shot Generalization of Vision-Language Models", "link": "https://arxiv.org/pdf/2412.04925", "details": "X Yin, Q Wang, B Cao, Q Hu - arXiv preprint arXiv:2412.04925, 2024", "abstract": "Recently, many studies have been conducted to enhance the zero-shot generalization ability of vision-language models (eg, CLIP) by addressing the semantic misalignment between image and text embeddings in downstream tasks \u2026"}, {"title": "Domain knowledge boosted adaptation: Leveraging vision-language models for multi-source domain adaptation", "link": "https://www.sciencedirect.com/science/article/pii/S092523122401885X", "details": "Y He, J Feng, G Ding, Y Guo, T He - Neurocomputing, 2024", "abstract": "Multi-source domain adaptation (MSDA) aims to adapt a model trained on multiple labeled source domains to an unlabeled target domain. Existing MSDA methods primarily focus on reducing domain gaps by aligning the source domains with the \u2026"}, {"title": "Copyright-Protected Language Generation via Adaptive Model Fusion", "link": "https://arxiv.org/pdf/2412.06619", "details": "J Abad, K Donhauser, F Pinto, F Yang - arXiv preprint arXiv:2412.06619, 2024", "abstract": "The risk of language models reproducing copyrighted material from their training data has led to the development of various protective measures. Among these, inference-time strategies that impose constraints via post-processing have shown \u2026"}, {"title": "PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning", "link": "https://arxiv.org/pdf/2412.04975", "details": "J Rieger, M Ruckdeschel, G Wiedemann - arXiv preprint arXiv:2412.04975, 2024", "abstract": "Few-shot learning and parameter-efficient fine-tuning (PEFT) are crucial to overcome the challenges of data scarcity and ever growing language model sizes. This applies in particular to specialized scientific domains, where researchers might lack \u2026"}, {"title": "Training Large Language Models to Reason in a Continuous Latent Space", "link": "https://arxiv.org/pdf/2412.06769", "details": "S Hao, S Sukhbaatar, DJ Su, X Li, Z Hu, J Weston\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) are restricted to reason in the\" language space\", where they typically express the reasoning process with a chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue that language space may \u2026"}, {"title": "Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt", "link": "https://arxiv.org/pdf/2412.05967", "details": "D de Mijolla, W Yang, P Duckett, C Frye, M Worrall - arXiv preprint arXiv:2412.05967, 2024", "abstract": "Prompting and fine-tuning have emerged as two competing paradigms for augmenting language models with new capabilities, such as the use of tools. Prompting approaches are quick to set up but rely on providing explicit \u2026"}]
