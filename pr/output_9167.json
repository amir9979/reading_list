[{"title": "Metaaligner: Towards generalizable multi-objective alignment of language models", "link": "https://openreview.net/pdf%3Fid%3DdIVb5C0QFf", "details": "K Yang, Z Liu, Q Xie, J Huang, T Zhang, S Ananiadou - The Thirty-eighth Annual \u2026, 2024", "abstract": "Recent advancements in large language models (LLMs) focus on aligning to heterogeneous human expectations and values via multi-objective preference alignment. However, existing methods are dependent on the policy model \u2026"}, {"title": "Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?", "link": "https://arxiv.org/pdf/2410.23856", "details": "Z Zhou, R Tao, J Zhu, Y Luo, Z Wang, B Han - arXiv preprint arXiv:2410.23856, 2024", "abstract": "This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We \u2026"}, {"title": "Mia-dpo: Multi-image augmented direct preference optimization for large vision-language models", "link": "https://arxiv.org/pdf/2410.17637", "details": "Z Liu, Y Zang, X Dong, P Zhang, Y Cao, H Duan, C He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing \u2026"}, {"title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality", "link": "https://arxiv.org/pdf/2411.11531", "details": "V Chekalina, A Razzigaev, E Goncharova, A Kuznetsov - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper we present an approach to reduce hallucinations in Large Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional modality. Our method involves transforming input text into a set of KG embeddings and using \u2026"}, {"title": "Foundation models in healthcare require rethinking reliability", "link": "https://www.nature.com/articles/s42256-024-00924-5", "details": "T Grote, T Freiesleben, P Berens - Nature Machine Intelligence, 2024", "abstract": "A new class of AI models, called foundation models, has entered healthcare. Foundation models violate several basic principles of the standard machine learning paradigm for assessing reliability, making it necessary to rethink what guarantees \u2026"}, {"title": "Multifaceted Natural Language Processing Task\u2013Based Evaluation of Bidirectional Encoder Representations From Transformers Models for Bilingual (Korean and \u2026", "link": "https://medinform.jmir.org/2024/1/e52897/", "details": "K Kim, S Park, J Min, S Park, JY Kim, J Eun, K Jung\u2026 - JMIR Medical Informatics, 2024", "abstract": "Background: The bidirectional encoder representations from transformers (BERT) model has attracted considerable attention in clinical applications, such as patient classification and disease prediction. However, current studies have typically \u2026"}, {"title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding", "link": "https://arxiv.org/pdf/2410.21311", "details": "F Zhu, Z Liu, XY Ng, H Wu, W Wang, F Feng, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable performance in many vision-language tasks, yet their capabilities in fine-grained visual understanding remain insufficiently evaluated. Existing benchmarks either contain \u2026"}, {"title": "Outperforming Larger Models on Text Classification Through Continued Pre-training", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9431-7_24", "details": "Y Zheng, M Liu, Z Ao, W Hao, H Zhang, Y Sun - CCF International Conference on \u2026, 2024", "abstract": "Generative large language models (LLMs), such as GPT-4, have demonstrated remarkable performance across a wide range of NLP tasks. The increased number of LLMs' parameters enhances their generalization capabilities, but it also results in a \u2026"}, {"title": "Evaluation of a task specific self-supervised learning framework in digital pathology relative to transfer learning approaches and existing foundation models", "link": "https://www.modernpathology.org/article/S0893-3952\\(24\\)00216-3/fulltext", "details": "T Rahman, AS Baras, R Chellappa - Modern Pathology, 2024", "abstract": "An integral stage in typical digital pathology workflows involves deriving specific features from tiles extracted from a tessellated whole slide image. Notably, various computer vision neural network architectures, particularly the ImageNet pre-trained \u2026"}]
