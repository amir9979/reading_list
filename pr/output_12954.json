[{"title": "Hierarchical Autoregressive Transformers: Combining Byte-and Word-Level Processing for Robust, Adaptable Language Models", "link": "https://arxiv.org/pdf/2501.10322", "details": "P Neitemeier, B Deiseroth, C Eichenberg, L Balles - arXiv preprint arXiv:2501.10322, 2025", "abstract": "Tokenization is a fundamental step in natural language processing, breaking text into units that computational models can process. While learned subword tokenizers have become the de-facto standard, they present challenges such as large \u2026"}, {"title": "From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models", "link": "https://www.biorxiv.org/content/biorxiv/early/2025/02/08/2025.02.06.636901.full.pdf", "details": "E Adams, L Bai, M Lee, Y Yu, M AlQuraishi - bioRxiv, 2025", "abstract": "Protein language models (pLMs) are powerful predictors of protein structure and function, learning through unsupervised training on millions of protein sequences. pLMs are thought to capture common motifs in protein sequences, but the specifics of \u2026"}, {"title": "DuCo-Net: Dual-Contrastive Learning Network for Medical Report Retrieval Leveraging Enhanced Encoders and Augmentations", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10870249.pdf", "details": "ZU Rahman, JH Lee, DT Vu, I Murtza, JY Kim - IEEE Access, 2025", "abstract": "The conventional process of generating medical radiology reports is labor-intensive and time-consuming, requiring radiologists to describe findings meticulously from imaging studies. This manual approach often causes undesirable delays in patient \u2026"}, {"title": "A Differentiable Rank-Based Objective For Better Feature Learning", "link": "https://arxiv.org/pdf/2502.09445", "details": "KL Pavasovic, D Lopez-Paz, G Biroli, L Sagun - arXiv preprint arXiv:2502.09445, 2025", "abstract": "In this paper, we leverage existing statistical methods to better understand feature learning from data. We tackle this by modifying the model-free variable selection method, Feature Ordering by Conditional Independence (FOCI), which is introduced \u2026"}, {"title": "AIDE: Agentically Improve Visual Language Model with Domain Experts", "link": "https://arxiv.org/pdf/2502.09051", "details": "MC Chiu, F Liu, K Sapra, A Tao, Y Jacoob, X Ma, Z Yu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The enhancement of Visual Language Models (VLMs) has traditionally relied on knowledge distillation from larger, more capable models. This dependence creates a fundamental bottleneck for improving state-of-the-art systems, particularly when no \u2026"}]
