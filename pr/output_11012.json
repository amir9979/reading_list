[{"title": "Liquid: Language Models are Scalable Multi-modal Generators", "link": "https://arxiv.org/pdf/2412.04332", "details": "J Wu, Y Jiang, C Ma, Y Liu, H Zhao, Z Yuan, S Bai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present Liquid, an auto-regressive generation paradigm that seamlessly integrates visual comprehension and generation by tokenizing images into discrete codes and learning these code embeddings alongside text tokens within a shared \u2026"}, {"title": "Delve into Visual Contrastive Decoding for Hallucination Mitigation of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.06775", "details": "YL Lee, YH Tsai, WC Chiu - arXiv preprint arXiv:2412.06775, 2024", "abstract": "While large vision-language models (LVLMs) have shown impressive capabilities in generating plausible responses correlated with input visual contents, they still suffer from hallucinations, where the generated text inaccurately reflects visual contents. To \u2026"}, {"title": "Why AI Is Good for Our Health but May Hurt Our Wallets", "link": "https://hmpi.org/2024/11/17/why-ai-is-good-for-our-health-but-may-hurt-our-wallets/", "details": "SS Jain, M Cheatham, MA Pfeffer, L Hoff, NH Shah - HMPI: Health Management \u2026, 2024", "abstract": "What is the message? Current regulatory frameworks, reimbursement structures, and business models for AI in healthcare are decoupled, which has created an environment in which AI may significantly increase costs without necessarily \u2026"}, {"title": "Contrastive concept-phrase pre-training for generating clinically accurate and interpretable chest X-ray reports", "link": "https://link.springer.com/article/10.1007/s00521-024-10640-1", "details": "A Tubaishat, T Zia, D Windridge, M Nawaz, S Razzaq - Neural Computing and \u2026, 2024", "abstract": "Automated radiology report generation is an emerging field for improving patient care and alleviating radiologist workload. However, existing methods face a range of challenges such as limited data availability, clinical metric performance, and \u2026"}, {"title": "Do Large Language Models have Shared Weaknesses in Medical Question Answering?", "link": "https://openreview.net/pdf%3Fid%3DZjQ04tsRQl", "details": "AM Bean, K Korgul, F Krones, R McCraith, A Mahdi - Advancements In Medical \u2026, 2024", "abstract": "Large language models (LLMs) have made rapid improvement on medical benchmarks, but their unreliability remains a persistent challenge for safe real-world uses. To design for the use LLMs as a category, rather than for specific models \u2026"}, {"title": "SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator", "link": "https://arxiv.org/pdf/2412.12094", "details": "G Chen, H Shi, J Li, Y Gao, X Ren, Y Chen, X Jiang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have exhibited exceptional performance across a spectrum of natural language processing tasks. However, their substantial sizes pose considerable challenges, particularly in computational demands and inference \u2026"}, {"title": "Autonomous medical evaluation for guideline adherence of large language models", "link": "https://www.nature.com/articles/s41746-024-01356-6", "details": "D Fast, LC Adams, F Busch, C Fallon, M Huppertz\u2026 - NPJ Digital Medicine, 2024", "abstract": "Abstract Autonomous Medical Evaluation for Guideline Adherence (AMEGA) is a comprehensive benchmark designed to evaluate large language models' adherence to medical guidelines across 20 diagnostic scenarios spanning 13 specialties. It \u2026"}]
