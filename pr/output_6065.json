[{"title": "Customizing Language Models with Instance-wise LoRA for Sequential Recommendation", "link": "https://arxiv.org/pdf/2408.10159", "details": "X Kong, J Wu, A Zhang, L Sheng, H Lin, X Wang, X He - arXiv preprint arXiv \u2026, 2024", "abstract": "Sequential recommendation systems predict a user's next item of interest by analyzing past interactions, aligning recommendations with individual preferences. Leveraging the strengths of Large Language Models (LLMs) in knowledge \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "Enhancing One-shot Pruned Pre-trained Language Models through Sparse-Dense-Sparse Mechanism", "link": "https://arxiv.org/pdf/2408.10473", "details": "G Li, X Zhao, L Liu, Z Li, D Li, L Tian, J He, A Sirasao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained language models (PLMs) are engineered to be robust in contextual understanding and exhibit outstanding performance in various natural language processing tasks. However, their considerable size incurs significant computational \u2026"}, {"title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models By admin No Comments", "link": "https://your-ai-staff.com/self-consistency-improves-chain-of-thought/", "details": "X Wang, J Wei, D Schuurmans, Q Le, H Chi, S Narang\u2026", "abstract": "Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding \u2026"}, {"title": "Unleash the power of pre-trained language models for irregularly sampled time series", "link": "https://arxiv.org/pdf/2408.08328", "details": "W Zhang, C Yin, H Liu, H Xiong - arXiv preprint arXiv:2408.08328, 2024", "abstract": "Pre-trained Language Models (PLMs), such as ChatGPT, have significantly advanced the field of natural language processing. This progress has inspired a series of innovative studies that explore the adaptation of PLMs to time series \u2026"}, {"title": "GraphWiz: An Instruction-Following Language Model for Graph Computational Problems", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3672010", "details": "N Chen, Y Li, J Tang, J Li - Proceedings of the 30th ACM SIGKDD Conference on \u2026, 2024", "abstract": "Large language models (LLMs) have achieved impressive success across various domains, but their capability in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel \u2026"}, {"title": "Importance Weighting Can Help Large Language Models Self-Improve", "link": "https://arxiv.org/pdf/2408.09849", "details": "C Jiang, C Chan, W Xue, Q Liu, Y Guo - arXiv preprint arXiv:2408.09849, 2024", "abstract": "Large language models (LLMs) have shown remarkable capability in numerous tasks and applications. However, fine-tuning LLMs using high-quality datasets under external supervision remains prohibitively expensive. In response, LLM self \u2026"}, {"title": "Reasoning and Planning with Large Language Models in Code Development", "link": "https://dl.acm.org/doi/pdf/10.1145/3637528.3671452", "details": "H Ding, Z Fan, I Guehring, G Gupta, W Ha, J Huan\u2026 - Proceedings of the 30th \u2026, 2024", "abstract": "Large Language Models (LLMs) are revolutionizing the field of code development by leveraging their deep understanding of code patterns, syntax, and semantics to assist developers in various tasks, from code generation and testing to code \u2026"}, {"title": "Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models", "link": "https://arxiv.org/pdf/2408.10682", "details": "H Yuan, Z Jin, P Cao, Y Chen, K Liu, J Zhao - arXiv preprint arXiv:2408.10682, 2024", "abstract": "LLM have achieved success in many fields but still troubled by problematic content in the training corpora. LLM unlearning aims at reducing their influence and avoid undesirable behaviours. However, existing unlearning methods remain vulnerable to \u2026"}]
