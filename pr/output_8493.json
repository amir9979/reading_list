[{"title": "Unsupervised multi-source domain adaptation via contrastive learning for EEG classification", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424023194", "details": "C Xu, Y Song, Q Zheng, Q Wang, PA Heng - Expert Systems with Applications, 2024", "abstract": "Individual differences in electroencephalography (EEG) present significant challenges for subject-independent EEG classification in brain-computer interfaces (BCIs). Existing domain adaptation methods often address individual differences by \u2026"}, {"title": "PathMoCo: A Novel Framework to Improve Feature Embedding in Self-supervised Contrastive Learning for Histopathological Images", "link": "https://arxiv.org/pdf/2410.17514", "details": "H Manoochehri, B Zhang, BS Knudsen, T Tasdizen - arXiv preprint arXiv:2410.17514, 2024", "abstract": "Self-supervised contrastive learning has become a cornerstone in various areas, particularly histopathological image analysis. Image augmentation plays a crucial role in self-supervised contrastive learning, as it generates variations in image \u2026"}, {"title": "Self-Supervised Contrastive Learning for Consistent Few-Shot Image Representations", "link": "https://link.springer.com/chapter/10.1007/978-3-031-74561-4_15", "details": "S Karimijafarbigloo, R Azad, D Merhof - International Workshop on PRedictive \u2026, 2024", "abstract": "The central challenge in few-shot learning involves (1) acquiring object proposals through the support representation,(2) ensuring consistent representations for images in both support and query sets, and (3) achieving effective metric learning for \u2026"}, {"title": "Positive-Augmented Contrastive Learning for Vision-and-Language Evaluation and Training", "link": "https://arxiv.org/pdf/2410.07336", "details": "S Sarto, N Moratelli, M Cornia, L Baraldi, R Cucchiara - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite significant advancements in caption generation, existing evaluation metrics often fail to capture the full quality or fine-grained details of captions. This is mainly due to their reliance on non-specific human-written references or noisy pre-training \u2026"}, {"title": "Enhancing Multimodal Medical Image Classification using Cross-Graph Modal Contrastive Learning", "link": "https://arxiv.org/pdf/2410.17494", "details": "JE Ding, CC Hsu, F Liu - arXiv preprint arXiv:2410.17494, 2024", "abstract": "The classification of medical images is a pivotal aspect of disease diagnosis, often enhanced by deep learning techniques. However, traditional approaches typically focus on unimodal medical image data, neglecting the integration of diverse non \u2026"}, {"title": "A General-Purpose Multimodal Foundation Model for Dermatology", "link": "https://arxiv.org/pdf/2410.15038", "details": "S Yan, Z Yu, C Primiero, C Vico-Alonso, Z Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Diagnosing and treating skin diseases require advanced visual skills across multiple domains and the ability to synthesize information from various imaging modalities. Current deep learning models, while effective at specific tasks such as diagnosing \u2026"}, {"title": "Evaluation of a task specific self-supervised learning framework in digital pathology relative to transfer learning approaches and existing foundation models", "link": "https://www.modernpathology.org/article/S0893-3952\\(24\\)00216-3/fulltext", "details": "T Rahman, AS Baras, R Chellappa - Modern Pathology, 2024", "abstract": "An integral stage in typical digital pathology workflows involves deriving specific features from tiles extracted from a tessellated whole slide image. Notably, various computer vision neural network architectures, particularly the ImageNet pre-trained \u2026"}, {"title": "SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding", "link": "https://arxiv.org/pdf/2410.11761", "details": "Y Chen, G Wang, Y Ji, Y Li, J Ye, T Li, B Zhang, N Pei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the progress made by multimodal large language models (MLLMs) in computational pathology, they remain limited by a predominant focus on patch-level analysis, missing essential contextual information at the whole-slide level. The lack \u2026"}, {"title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models", "link": "https://arxiv.org/pdf/2410.18252", "details": "M Noukhovitch, S Huang, S Xhonneux, A Hosseini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously generating from the large language model (LLM) policy, labelling with a reward model, and learning using feedback on the LLM's own outputs. While performant, this \u2026"}]
