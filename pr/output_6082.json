[{"title": "Stacked Reflective Reasoning in Large Neural Language Models", "link": "https://ceur-ws.org/Vol-3740/paper-121.pdf", "details": "K Villarreal-Haro, F S\u00e1nchez-Vega, A Rosales-P\u00e9rez\u2026 - Working Notes of CLEF, 2024", "abstract": "Sexism, far from being merely a conceptual issue, is a concerning and pervasive social health problem that negatively impacts individuals' well-being and perception. In today's digital era, as sexism permeates online platforms, the creation of systems \u2026"}, {"title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models By admin No Comments", "link": "https://your-ai-staff.com/self-consistency-improves-chain-of-thought/", "details": "X Wang, J Wei, D Schuurmans, Q Le, H Chi, S Narang\u2026", "abstract": "Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding \u2026"}]
