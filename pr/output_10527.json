[{"title": "Sneaking Syntax into Transformer Language Models with Tree Regularization", "link": "https://arxiv.org/pdf/2411.18885", "details": "A Nandi, CD Manning, S Murty - arXiv preprint arXiv:2411.18885, 2024", "abstract": "While compositional accounts of human language understanding are based on a hierarchical tree-like process, neural models like transformers lack a direct inductive bias for such tree structures. Introducing syntactic inductive biases could unlock more \u2026"}, {"title": "LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation", "link": "https://arxiv.org/pdf/2412.15188", "details": "W Shi, X Han, C Zhou, W Liang, XV Lin, L Zettlemoyer\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present LlamaFusion, a framework for empowering pretrained text-only large language models (LLMs) with multimodal generative capabilities, enabling them to understand and generate both text and images in arbitrary sequences. LlamaFusion \u2026"}, {"title": "Language Models as Continuous Self-Evolving Data Engineers", "link": "https://arxiv.org/pdf/2412.15151", "details": "P Wang, M Wang, Z Ma, X Yang, S Feng, D Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert \u2026"}, {"title": "Detection of Patient-Level Immunotherapy-Related Adverse Events (irAEs) from Clinical Narratives of Electronic Health Records: A High-Sensitivity Artificial \u2026", "link": "https://www.tandfonline.com/doi/pdf/10.2147/POR.S468253", "details": "MM Zitu, ME Gatti-Mays, KC Johnson, S Zhang\u2026 - Pragmatic and \u2026, 2024", "abstract": "Purpose We developed an artificial intelligence (AI) model to detect immunotherapy- related adverse events (irAEs) from clinical narratives of electronic health records (EHRs) at the patient level. Patients and Methods Training data, used for internal \u2026"}, {"title": "VLM-AD: End-to-End Autonomous Driving through Vision-Language Model Supervision", "link": "https://arxiv.org/pdf/2412.14446", "details": "Y Xu, Y Hu, Z Zhang, GP Meyer, SK Mustikovela\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Human drivers rely on commonsense reasoning to navigate diverse and dynamic real-world scenarios. Existing end-to-end (E2E) autonomous driving (AD) models are typically optimized to mimic driving patterns observed in data, without capturing the \u2026"}, {"title": "HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model", "link": "https://arxiv.org/pdf/2412.14613", "details": "M Ohi, M Kaneko, N Okazaki, N Inoue - arXiv preprint arXiv:2412.14613, 2024", "abstract": "Vision-language models (VLMs) have shown impressive abilities in text and image understanding. However, existing metrics for evaluating the text generated by VLMs focus exclusively on overall quality, leading to two limitations: 1) it is challenging to \u2026"}, {"title": "Label-template based Few-Shot Text Classification with Contrastive Learning", "link": "https://arxiv.org/pdf/2412.10110%3F", "details": "G Hou, S Cao, D Ouyang, N Wang - arXiv preprint arXiv:2412.10110, 2024", "abstract": "As an algorithmic framework for learning to learn, meta-learning provides a promising solution for few-shot text classification. However, most existing research fail to give enough attention to class labels. Traditional basic framework building \u2026"}]
