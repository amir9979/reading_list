[{"title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization", "link": "https://arxiv.org/pdf/2411.10442", "details": "W Wang, Z Chen, W Wang, Y Cao, Y Liu, Z Gao, J Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing open-source multimodal large language models (MLLMs) generally follow a training process involving pre-training and supervised fine-tuning. However, these models suffer from distribution shifts, which limit their multimodal reasoning \u2026"}, {"title": "DriveMLLM: A Benchmark for Spatial Understanding with Multimodal Large Language Models in Autonomous Driving", "link": "https://arxiv.org/pdf/2411.13112", "details": "X Guo, R Zhang, Y Duan, Y He, C Zhang, S Liu, L Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "Autonomous driving requires a comprehensive understanding of 3D environments to facilitate high-level tasks such as motion prediction, planning, and mapping. In this paper, we introduce DriveMLLM, a benchmark specifically designed to evaluate the \u2026"}, {"title": "Large Language Models Can Self-Improve in Long-context Reasoning", "link": "https://arxiv.org/pdf/2411.08147", "details": "S Li, C Yang, Z Cheng, L Liu, M Yu, Y Yang, W Lam - arXiv preprint arXiv:2411.08147, 2024", "abstract": "Large language models (LLMs) have achieved substantial progress in processing long contexts but still struggle with long-context reasoning. Existing approaches typically involve fine-tuning LLMs with synthetic data, which depends on annotations \u2026"}, {"title": "Measuring Non-Adversarial Reproduction of Training Data in Large Language Models", "link": "https://arxiv.org/pdf/2411.10242%3F", "details": "M Aerni, J Rando, E Debenedetti, N Carlini, D Ippolito\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models memorize parts of their training data. Memorizing short snippets and facts is required to answer questions about the world and to be fluent in any language. But models have also been shown to reproduce long verbatim \u2026"}, {"title": "Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training", "link": "https://arxiv.org/pdf/2411.14318", "details": "Z Luo, X Zhang, X Liu, H Li, Y Gong, C Qi, P Cheng - arXiv preprint arXiv:2411.14318, 2024", "abstract": "It is well-known that a diverse corpus is critical for training large language models, which are typically constructed from a mixture of various domains. In general, previous efforts resort to sampling training data from different domains with static \u2026"}, {"title": "Lost in Inference: Rediscovering the Role of Natural Language Inference for Large Language Models", "link": "https://arxiv.org/pdf/2411.14103", "details": "L Madaan, D Esiobu, P Stenetorp, B Plank, D Hupkes - arXiv preprint arXiv \u2026, 2024", "abstract": "In the recent past, a popular way of evaluating natural language understanding (NLU), was to consider a model's ability to perform natural language inference (NLI) tasks. In this paper, we investigate if NLI tasks, that are rarely used for LLM \u2026"}, {"title": "Text-to-SQL Systems in the Era of Advanced Large Language Models", "link": "https://era.library.ualberta.ca/items/3db9c207-9248-4760-8f82-0f6f308ff3ff/download/d817de66-5fe8-47fb-b065-1e5cf7644244", "details": "M Pourreza - 2024", "abstract": "Text-to-SQL conversion, the process of transforming natural language queries into executable SQL commands, stands at the forefront of bridging human linguistic capabilities with the structured logic of databases. This dissertation embarks on a \u2026"}, {"title": "Membership Inference Attacks against Large Language Models via Self-prompt Calibration", "link": "https://fi.ee.tsinghua.edu.cn/~gaochen/papers/NeurIPS2024-SPV-MIA.pdf", "details": "W Fu, H Wang, G Liu, Y Li, T Jiang", "abstract": "Abstract Membership Inference Attacks (MIA) aim to infer whether a target data record has been utilized for model training or not. Existing MIAs designed for large language models (LLMs) can be bifurcated into two types: reference-free and \u2026"}, {"title": "Reinforcement Learning for Aligning Large Language Models Agents with Interactive Environments: Quantifying and Mitigating Prompt Overfitting", "link": "https://ui.adsabs.harvard.edu/abs/2024arXiv241019920S/abstract", "details": "M Salim Aissi, C Romac, T Carta, S Lamprier\u2026 - arXiv e-prints, 2024", "abstract": "Reinforcement learning (RL) is a promising approach for aligning large language models (LLMs) knowledge with sequential decision-making tasks. However, few studies have thoroughly investigated the impact on LLM agents capabilities of fine \u2026"}]
