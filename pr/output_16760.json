[{"title": "SemiT-SAM: Building A Visual Foundation Model for Tooth Instance Segmentation on Panoramic Radiographs", "link": "https://link.springer.com/chapter/10.1007/978-3-031-88977-6_11", "details": "J Hao, M Liu, L He, L Yao, JKH Tsoi, KF Hung - International Conference on Medical \u2026, 2025", "abstract": "Automated tooth instance segmentation on dental radiographs is a crucial step in establishing digital dental workflows. However, unlike the realm of natural images, there is currently no visual foundation model that can implement tooth instance \u2026"}, {"title": "Contrastive prototype federated learning against noisy labels in fetal standard plane detection", "link": "https://link.springer.com/article/10.1007/s11548-025-03400-6", "details": "MC Fiorentino, G Migliorelli, FP Villani, E Frontoni\u2026 - International Journal of \u2026, 2025", "abstract": "Purpose This study aims to improve federated learning (FL) for ultrasound fetal standard plane detection by addressing noisy labels and data size variability across decentralized clients. We propose a federated denoising framework leveraging \u2026"}, {"title": "Improved Multiclass Lung Disease Classification Using Segmentation and Deep Learning from Chest X-Ray Images", "link": "https://www.tandfonline.com/doi/abs/10.1080/02564602.2025.2501936", "details": "VK Yadav, J Singhai - IETE Technical Review, 2025", "abstract": "Chest X-Ray (CXR) imaging has developed as an important technique for identifying lung diseases, especially in low-and middle-income nations where tuberculosis and pneumonia are serious health problems. With the onset of the COVID-19 pandemic \u2026"}, {"title": "Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models", "link": "https://arxiv.org/pdf/2505.15057", "details": "F Wang, JI Tamir - arXiv preprint arXiv:2505.15057, 2025", "abstract": "Magnetic Resonance Imaging (MRI) is highly susceptible to motion artifacts due to the extended acquisition times required for k-space sampling. These artifacts can compromise diagnostic utility, particularly for dynamic imaging. We propose a novel \u2026", "entry_id": "http://arxiv.org/abs/2505.15057v1", "updated": "2025-05-21 03:27:21", "published": "2025-05-21 03:27:21", "authors": "Frederic Wang;Jonathan I. Tamir", "summary": "Magnetic Resonance Imaging (MRI) is highly susceptible to motion artifacts\ndue to the extended acquisition times required for k-space sampling. These\nartifacts can compromise diagnostic utility, particularly for dynamic imaging.\nWe propose a novel alternating minimization framework that leverages a bespoke\ndiffusion model to jointly reconstruct and correct non-rigid motion-corrupted\nk-space data. The diffusion model uses a coarse-to-fine denoising strategy to\ncapture large overall motion and reconstruct the lower frequencies of the image\nfirst, providing a better inductive bias for motion estimation than that of\nstandard diffusion models. We demonstrate the performance of our approach on\nboth real-world cine cardiac MRI datasets and complex simulated rigid and\nnon-rigid deformations, even when each motion state is undersampled by a factor\nof 64x. Additionally, our method is agnostic to sampling patterns, anatomical\nvariations, and MRI scanning protocols, as long as some low frequency\ncomponents are sampled during each motion state.", "comment": "ICIP 2025", "journal_ref": null, "primary_category": "eess.IV", "categories": "eess.IV;cs.CV", "links": "http://arxiv.org/abs/2505.15057v1;http://arxiv.org/pdf/2505.15057v1", "pdf_url": "http://arxiv.org/pdf/2505.15057v1"}, {"title": "MedSG-Bench: A Benchmark for Medical Image Sequences Grounding", "link": "https://arxiv.org/pdf/2505.11852", "details": "J Yue, S Zhang, Z Jia, H Xu, Z Han, X Liu, G Wang - arXiv preprint arXiv:2505.11852, 2025", "abstract": "Visual grounding is essential for precise perception and reasoning in multimodal large language models (MLLMs), especially in medical imaging domains. While existing medical visual grounding benchmarks primarily focus on single-image \u2026", "entry_id": "http://arxiv.org/abs/2505.11852v1", "updated": "2025-05-17 05:31:17", "published": "2025-05-17 05:31:17", "authors": "Jingkun Yue;Siqi Zhang;Zinan Jia;Huihuan Xu;Zongbo Han;Xiaohong Liu;Guangyu Wang", "summary": "Visual grounding is essential for precise perception and reasoning in\nmultimodal large language models (MLLMs), especially in medical imaging\ndomains. While existing medical visual grounding benchmarks primarily focus on\nsingle-image scenarios, real-world clinical applications often involve\nsequential images, where accurate lesion localization across different\nmodalities and temporal tracking of disease progression (e.g., pre- vs.\npost-treatment comparison) require fine-grained cross-image semantic alignment\nand context-aware reasoning. To remedy the underrepresentation of image\nsequences in existing medical visual grounding benchmarks, we propose\nMedSG-Bench, the first benchmark tailored for Medical Image Sequences\nGrounding. It comprises eight VQA-style tasks, formulated into two paradigms of\nthe grounding tasks, including 1) Image Difference Grounding, which focuses on\ndetecting change regions across images, and 2) Image Consistency Grounding,\nwhich emphasizes detection of consistent or shared semantics across sequential\nimages. MedSG-Bench covers 76 public datasets, 10 medical imaging modalities,\nand a wide spectrum of anatomical structures and diseases, totaling 9,630\nquestion-answer pairs. We benchmark both general-purpose MLLMs (e.g.,\nQwen2.5-VL) and medical-domain specialized MLLMs (e.g., HuatuoGPT-vision),\nobserving that even the advanced models exhibit substantial limitations in\nmedical sequential grounding tasks. To advance this field, we construct\nMedSG-188K, a large-scale instruction-tuning dataset tailored for sequential\nvisual grounding, and further develop MedSeq-Grounder, an MLLM designed to\nfacilitate future research on fine-grained understanding across medical\nsequential images. The benchmark, dataset, and model are available at\nhttps://huggingface.co/MedSG-Bench", "comment": null, "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.11852v1;http://arxiv.org/pdf/2505.11852v1", "pdf_url": "http://arxiv.org/pdf/2505.11852v1"}]
