[{"title": "Mental Modeling of Reinforcement Learning Agents by Language Models", "link": "https://arxiv.org/pdf/2406.18505", "details": "W Lu, X Zhao, J Spisak, JH Lee, S Wermter - arXiv preprint arXiv:2406.18505, 2024", "abstract": "Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it \u2026"}, {"title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models", "link": "https://aclanthology.org/2024.findings-naacl.18.pdf", "details": "Z Su, Z Lin, B Baixue, H Chen, S Hu, W Zhou, G Ding\u2026 - Findings of the Association \u2026, 2024", "abstract": "Generative language models are usually pre-trained on large text corpus via predicting the next token (ie, sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language \u2026"}, {"title": "EHRmonize: A Framework for Medical Concept Abstraction from Electronic Health Records using Large Language Models", "link": "https://arxiv.org/pdf/2407.00242", "details": "J Matos, J Gallifant, J Pei, AI Wong - arXiv preprint arXiv:2407.00242, 2024", "abstract": "Electronic health records (EHRs) contain vast amounts of complex data, but harmonizing and processing this information remains a challenging and costly task requiring significant clinical expertise. While large language models (LLMs) have \u2026"}, {"title": "SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation", "link": "https://arxiv.org/pdf/2406.12975", "details": "X Liu, T Sun, T Xu, F Wu, C Wang, X Wang, J Gao - arXiv preprint arXiv:2406.12975, 2024", "abstract": "Large Language Models (LLMs) have transformed machine learning but raised significant legal concerns due to their potential to produce text that infringes on copyrights, resulting in several high-profile lawsuits. The legal landscape is \u2026"}, {"title": "Adaptive Rank Selections for Low-Rank Approximation of Language Models", "link": "https://aclanthology.org/2024.naacl-long.13.pdf", "details": "S Gao, T Hua, YC Hsu, Y Shen, H Jin - Proceedings of the 2024 Conference of the \u2026, 2024", "abstract": "Abstract Singular Value Decomposition (SVD) or its weighted variants has significantly progressed in compressing language models. Previous works assume the same importance for all operations and assign the same number of ranks for \u2026"}, {"title": "This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes", "link": "https://aclanthology.org/2024.naacl-long.213.pdf", "details": "B Li, S Haider, C Callison-Burch - Proceedings of the 2024 Conference of the North \u2026, 2024", "abstract": "Abstract Do the Spratly Islands belong to China, the Philippines, or Vietnam? A pretrained large language model (LLM) may answer differently if asked in the languages of each claimant country: Chinese, Tagalog, or Vietnamese. This \u2026"}, {"title": "Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding", "link": "https://arxiv.org/pdf/2406.12295", "details": "K Zhang, J Wang, N Ding, B Qi, E Hua, X Lv, B Zhou - arXiv preprint arXiv:2406.12295, 2024", "abstract": "Large Language Models (LLMs) demonstrate impressive performance in diverse applications, yet they face significant drawbacks, including high inference latency, expensive training cost, and generation of hallucination. Collaborative decoding \u2026"}, {"title": "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2406.12050", "details": "Z Zhang, Z Liang, W Yu, D Yu, M Jia, D Yu, M Jiang - arXiv preprint arXiv:2406.12050, 2024", "abstract": "Supervised fine-tuning enhances the problem-solving abilities of language models across various mathematical reasoning tasks. To maximize such benefits, existing research focuses on broadening the training set with various data augmentation \u2026"}, {"title": "Information Guided Regularization for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2406.14005", "details": "M Sharma, N Muralidhar, S Xu, RB Yosuf\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The pretraining-fine-tuning paradigm has been the de facto strategy for transfer learning in modern language modeling. With the understanding that task adaptation in LMs is often a function of parameters shared across tasks, we argue that a more \u2026"}]
