[{"title": "RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics", "link": "https://arxiv.org/pdf/2411.16537", "details": "CH Song, V Blukis, J Tremblay, S Tyree, Y Su\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Spatial understanding is a crucial capability for robots to make grounded decisions based on their environment. This foundational skill enables robots not only to perceive their surroundings but also to reason about and interact meaningfully within \u2026"}, {"title": "Chain of Attack: On the Robustness of Vision-Language Models Against Transfer-Based Adversarial Attacks", "link": "https://arxiv.org/pdf/2411.15720", "details": "P Xie, Y Bie, J Mao, Y Song, Y Wang, H Chen, K Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained vision-language models (VLMs) have showcased remarkable performance in image and natural language understanding, such as image captioning and response generation. As the practical applications of vision-language \u2026"}, {"title": "On-Board Vision-Language Models for Personalized Autonomous Vehicle Motion Control: System Design and Real-World Validation", "link": "https://arxiv.org/pdf/2411.11913%3F", "details": "C Cui, Z Yang, Y Zhou, J Peng, SY Park, C Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Personalized driving refers to an autonomous vehicle's ability to adapt its driving behavior or control strategies to match individual users' preferences and driving styles while maintaining safety and comfort standards. However, existing works \u2026"}, {"title": "Adversarial Prompt Distillation for Vision-Language Models", "link": "https://arxiv.org/pdf/2411.15244", "details": "L Luo, X Wang, B Zi, S Zhao, X Ma - arXiv preprint arXiv:2411.15244, 2024", "abstract": "Large pre-trained Vision-Language Models (VLMs) such as Contrastive Language- Image Pre-Training (CLIP) have been shown to be susceptible to adversarial attacks, raising concerns about their deployment in safety-critical scenarios like autonomous \u2026"}, {"title": "Learning predictable and robust neural representations by straightening image sequences", "link": "https://arxiv.org/pdf/2411.01777", "details": "X Niu, C Savin, EP Simoncelli - arXiv preprint arXiv:2411.01777, 2024", "abstract": "Prediction is a fundamental capability of all living organisms, and has been proposed as an objective for learning sensory representations. Recent work demonstrates that in primate visual systems, prediction is facilitated by neural representations that \u2026"}, {"title": "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "link": "https://aclanthology.org/2024.findings-emnlp.61.pdf", "details": "X Wei, H Chen, H Yu, H Fei, Q Liu - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) have achieved notable success in commonsense reasoning tasks, benefiting from their extensive world knowledge acquired through extensive pretraining. While approaches like Chain-of-Thought \u2026"}, {"title": "Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?", "link": "https://arxiv.org/pdf/2410.23856", "details": "Z Zhou, R Tao, J Zhu, Y Luo, Z Wang, B Han - arXiv preprint arXiv:2410.23856, 2024", "abstract": "This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We \u2026"}, {"title": "Mathematical Reasoning via Multi-step Self Questioning and Answering for Small Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9440-9_7", "details": "K Chen, J Wang, X Zhang - CCF International Conference on Natural Language \u2026, 2024", "abstract": "Mathematical reasoning is challenging for large language models (LLMs), while the scaling relationship concerning LLM capacity is under-explored. Existing works have tried to leverage the rationales of LLMs to train small language models (SLMs) for \u2026"}, {"title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality", "link": "https://arxiv.org/pdf/2411.11531", "details": "V Chekalina, A Razzigaev, E Goncharova, A Kuznetsov - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper we present an approach to reduce hallucinations in Large Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional modality. Our method involves transforming input text into a set of KG embeddings and using \u2026"}]
