[{"title": "FoPru: Focal Pruning for Efficient Large Vision-Language Models", "link": "https://arxiv.org/pdf/2411.14164", "details": "L Jiang, W Huang, T Liu, Y Zeng, J Li, L Cheng, X Xu - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) represent a significant advancement toward achieving superior multimodal capabilities by enabling powerful Large Language Models (LLMs) to understand visual input. Typically, LVLMs utilize visual \u2026"}, {"title": "LLaVA-o1: Let Vision Language Models Reason Step-by-Step", "link": "https://arxiv.org/pdf/2411.10440%3F", "details": "G Xu, P Jin, L Hao, Y Song, L Sun, L Yuan - arXiv preprint arXiv:2411.10440, 2024", "abstract": "Large language models have demonstrated substantial advancements in reasoning capabilities, particularly through inference-time scaling, as illustrated by models such as OpenAI's o1. However, current Vision-Language Models (VLMs) often struggle to \u2026"}, {"title": "VisionZip: Longer is Better but Not Necessary in Vision Language Models", "link": "https://arxiv.org/pdf/2412.04467", "details": "S Yang, Y Chen, Z Tian, C Wang, J Li, B Yu, J Jia - arXiv preprint arXiv:2412.04467, 2024", "abstract": "Recent advancements in vision-language models have enhanced performance by increasing the length of visual tokens, making them much longer than text tokens and significantly raising computational costs. However, we observe that the visual tokens \u2026"}, {"title": "AdvDreamer Unveils: Are Vision-Language Models Truly Ready for Real-World 3D Variations?", "link": "https://arxiv.org/pdf/2412.03002", "details": "S Ruan, H Liu, Y Huang, X Wang, C Kang, H Su\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision Language Models (VLMs) have exhibited remarkable generalization capabilities, yet their robustness in dynamic real-world scenarios remains largely unexplored. To systematically evaluate VLMs' robustness to real-world 3D variations \u2026"}, {"title": "Lifelong Knowledge Editing for Vision Language Models with Low-Rank Mixture-of-Experts", "link": "https://arxiv.org/pdf/2411.15432", "details": "Q Chen, C Wang, D Wang, T Zhang, W Li, X He - arXiv preprint arXiv:2411.15432, 2024", "abstract": "Model editing aims to correct inaccurate knowledge, update outdated information, and incorporate new data into Large Language Models (LLMs) without the need for retraining. This task poses challenges in lifelong scenarios where edits must be \u2026"}, {"title": "An Approach to Complex Visual Data Interpretation with Vision-Language Models", "link": "https://openaccess.thecvf.com/content/ACCV2024W/LAVA/papers/Nguyen_An_Approach_to_Complex_Visual_Data_Interpretation_with_Vision-Language_Models_ACCVW_2024_paper.pdf", "details": "TS Nguyen, VT Huynh, VL Nguyen, MT Tran - \u2026 of the Asian Conference on Computer \u2026, 2024", "abstract": "The LAVA Workshop 2024 challenge aimed to assess the capability of Large Vision- Language Models (VLMs) to interpret and understand complex visual data accurately. This includes intricate visual formats such as data flow diagrams, class \u2026"}, {"title": "A cascaded retrieval-while-reasoning multi-document comprehension framework with incremental attention for medical question answering", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424025685", "details": "J Liu, J Ren, R Bai, Z Zhang, Z Lu - Expert Systems with Applications, 2024", "abstract": "Abstract Clinical Machine Reading Comprehension (MRC) is challenging due to the need for medical expertise and comprehensive reasoning chains for diagnosis. This paper introduces a novel cascade retrieval-while-reasoning framework for clinical \u2026"}, {"title": "PreAdapter: Pre-training Language Models on Knowledge Graphs", "link": "https://link.springer.com/chapter/10.1007/978-3-031-77850-6_12", "details": "J Omeliyanenko, A Hotho, D Schl\u00f6r - International Semantic Web Conference, 2024", "abstract": "Pre-trained language models have demonstrated state-of-the-art performance in various downstream tasks such as summarization, sentiment classification, and question answering. Leveraging vast amounts of textual data during training, these \u2026"}, {"title": "Task Arithmetic Through The Lens Of One-Shot Federated Learning", "link": "https://arxiv.org/pdf/2411.18607%3F", "details": "Z Tao, I Mason, S Kulkarni, X Boix - arXiv preprint arXiv:2411.18607, 2024", "abstract": "Task Arithmetic is a model merging technique that enables the combination of multiple models' capabilities into a single model through simple arithmetic in the weight space, without the need for additional fine-tuning or access to the original \u2026"}]
