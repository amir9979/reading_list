[{"title": "Can Language Models Reason about Individualistic Human Values and Preferences?", "link": "https://arxiv.org/pdf/2410.03868", "details": "L Jiang, T Sorensen, S Levine, Y Choi - arXiv preprint arXiv:2410.03868, 2024", "abstract": "Recent calls for pluralistic alignment emphasize that AI systems should address the diverse needs of all people. Yet, efforts in this space often require sorting people into fixed buckets of pre-specified diversity-defining dimensions (eg, demographics \u2026"}, {"title": "General Preference Modeling with Preference Representations for Aligning Language Models", "link": "https://arxiv.org/pdf/2410.02197%3F", "details": "Y Zhang, G Zhang, Y Wu, K Xu, Q Gu - arXiv preprint arXiv:2410.02197, 2024", "abstract": "Modeling human preferences is crucial for aligning foundation models with human values. Traditional reward modeling methods, such as the Bradley-Terry (BT) reward model, fall short in expressiveness, particularly in addressing intransitive \u2026"}, {"title": "Exploring the Learning Capabilities of Language Models using LEVERWORLDS", "link": "https://arxiv.org/pdf/2410.00519%3F", "details": "E Wagner, A Feder, O Abend - arXiv preprint arXiv:2410.00519, 2024", "abstract": "Learning a model of a stochastic setting often involves learning both general structure rules and specific properties of the instance. This paper investigates the interplay between learning the general and the specific in various learning methods \u2026"}, {"title": "POSIX: A Prompt Sensitivity Index For Large Language Models", "link": "https://arxiv.org/pdf/2410.02185", "details": "A Chatterjee, HK Renduchintala, S Bhatia\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) are found to be surprisingly sensitive to minor variations in prompts, often generating significantly divergent outputs in response to minor variations in the prompts, such as spelling \u2026"}, {"title": "Law of the Weakest Link: Cross Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2409.19951", "details": "M Zhong, A Zhang, X Wang, R Hou, W Xiong, C Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The development and evaluation of Large Language Models (LLMs) have largely focused on individual capabilities. However, this overlooks the intersection of multiple abilities across different types of expertise that are often required for real \u2026"}, {"title": "Quantifying Generalization Complexity for Large Language Models", "link": "https://arxiv.org/pdf/2410.01769", "details": "Z Qi, H Luo, X Huang, Z Zhao, Y Jiang, X Fan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While large language models (LLMs) have shown exceptional capabilities in understanding complex queries and performing sophisticated tasks, their generalization abilities are often deeply entangled with memorization, necessitating \u2026"}, {"title": "RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models", "link": "https://arxiv.org/pdf/2409.19886", "details": "S Chen, W Jiang, B Lin, JT Kwok, Y Zhang - arXiv preprint arXiv:2409.19886, 2024", "abstract": "Recent works show that assembling multiple off-the-shelf large language models (LLMs) can harness their complementary abilities. To achieve this, routing is a promising method, which learns a router to select the most suitable LLM for each \u2026"}, {"title": "How Reliable Is Human Feedback For Aligning Large Language Models?", "link": "https://arxiv.org/pdf/2410.01957", "details": "MH Yeh, L Tao, J Wang, X Du, Y Li - arXiv preprint arXiv:2410.01957, 2024", "abstract": "Most alignment research today focuses on designing new learning algorithms using datasets like Anthropic-HH, assuming human feedback data is inherently reliable. However, little attention has been given to the qualitative unreliability of human \u2026"}, {"title": "MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework", "link": "https://arxiv.org/pdf/2410.01553%3F", "details": "Z Yao, Z Zhang, C Tang, X Bian, Y Zhao, Z Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Artificial intelligence (AI) and large language models (LLMs) in healthcare require advanced clinical skills (CS), yet current benchmarks fail to evaluate these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by \u2026"}]
