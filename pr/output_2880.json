[{"title": "Repurposing Language Models into Embedding Models: Finding the Compute-Optimal Recipe", "link": "https://arxiv.org/pdf/2406.04165", "details": "A Ziarko, AQ Jiang, B Piotrowski, W Li, M Jamnik\u2026 - arXiv e-prints, 2024", "abstract": "Text embeddings are essential for many tasks, such as document retrieval, clustering, and semantic similarity assessment. In this paper, we study how to contrastively train text embedding models in a compute-optimal fashion, given a suite \u2026"}, {"title": "Injecting Undetectable Backdoors in Deep Learning and Language Models", "link": "https://arxiv.org/pdf/2406.05660", "details": "A Kalavasis, A Karbasi, A Oikonomou, K Sotiraki\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As ML models become increasingly complex and integral to high-stakes domains such as finance and healthcare, they also become more susceptible to sophisticated adversarial attacks. We investigate the threat posed by undetectable backdoors in \u2026"}, {"title": "Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models", "link": "https://arxiv.org/pdf/2406.04274", "details": "X Ji, S Kulkarni, M Wang, T Xie - arXiv preprint arXiv:2406.04274, 2024", "abstract": "This work studies the challenge of aligning large language models (LLMs) with offline preference data. We focus on alignment by Reinforcement Learning from Human Feedback (RLHF) in particular. While popular preference optimization \u2026"}, {"title": "Reflection-Reinforced Self-Training for Language Agents", "link": "https://arxiv.org/pdf/2406.01495", "details": "ZY Dou, CF Yang, X Wu, KW Chang, N Peng - arXiv preprint arXiv:2406.01495, 2024", "abstract": "Self-training can potentially improve the performance of language agents without relying on demonstrations from humans or stronger models. The general process involves generating samples from a model, evaluating their quality, and updating the \u2026"}, {"title": "Gaussian Process Optimization for Adaptable Multi-Objective Text Generation using Linearly-Weighted Language Models", "link": "https://ssanner.github.io/papers/naacl24_gpllm.pdf", "details": "MMA Pour, A Pesaranghader, E Cohen, S Sanner - Findings of the Association for \u2026, 2024", "abstract": "In multi-objective text generation, we aim to optimize over multiple weighted aspects (eg, toxicity, semantic preservation, fluency) of the generated text. However, multi- objective weighting schemes may change dynamically in practice according to \u2026"}, {"title": "Can Language Models Use Forecasting Strategies?", "link": "https://arxiv.org/abs/2406.04446", "details": "S Pratt, S Blumberg, PK Carolino, MR Morris - arXiv preprint arXiv:2406.04446, 2024", "abstract": "Advances in deep learning systems have allowed large models to match or surpass human accuracy on a number of skills such as image classification, basic programming, and standardized test taking. As the performance of the most capable \u2026"}, {"title": "UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback", "link": "https://arxiv.org/pdf/2406.07739", "details": "J Wu, E Schoop, A Leung, T Barik, JP Bigham\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) struggle to consistently generate UI code that compiles and produces visually relevant designs. Existing approaches to improve generation rely on expensive human feedback or distilling a proprietary model. In \u2026"}, {"title": "Low-Resource Cross-Lingual Summarization through Few-Shot Learning with Large Language Models", "link": "https://arxiv.org/pdf/2406.04630", "details": "G Park, S Hwang, H Lee - arXiv e-prints, 2024", "abstract": "Cross-lingual summarization (XLS) aims to generate a summary in a target language different from the source language document. While large language models (LLMs) have shown promising zero-shot XLS performance, their few-shot capabilities on this \u2026"}, {"title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models", "link": "https://arxiv.org/pdf/2406.05948", "details": "X Li, Y Zhang, R Lou, C Wu, J Wang - arXiv preprint arXiv:2406.05948, 2024", "abstract": "Backdoor attacks present significant threats to Large Language Models (LLMs), particularly with the rise of third-party services that offer API integration and prompt engineering. Untrustworthy third parties can plant backdoors into LLMs and pose \u2026"}]
