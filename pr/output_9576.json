[{"title": "Automatic classification of HEp-2 specimens by explainable deep learning and Jensen-Shannon reliability index", "link": "https://www.sciencedirect.com/science/article/pii/S0933365724002720", "details": "A Mencattini, T Tocci, M Nuccetelli, M Pieri\u2026 - Artificial Intelligence in \u2026, 2024", "abstract": "Abstract The Anti-Nuclear Antibodies (ANA) test using Human Epithelial type 2 (HEp- 2) cells in the Indirect Immuno-Fluorescence (IIF) assay protocol is considered the gold standard for detecting Connective Tissue Diseases. Computer-assisted systems \u2026"}, {"title": "Content-Style Learning from Unaligned Domains: Identifiability under Unknown Latent Dimensions", "link": "https://arxiv.org/pdf/2411.03755", "details": "S Shrestha, X Fu - arXiv preprint arXiv:2411.03755, 2024", "abstract": "Understanding identifiability of latent content and style variables from unaligned multi- domain data is essential for tasks such as domain translation and data generation. Existing works on content-style identification were often developed under somewhat \u2026"}, {"title": "Interpretability as Approximation: Understanding Black-Box Models by Decision Boundary", "link": "https://www.mdpi.com/2079-9292/13/22/4339", "details": "H Dong, B Liu, D Ye, G Liu - Electronics, 2024", "abstract": "Currently, interpretability methods focus more on less objective human- understandable semantics. To objectify and standardize interpretability research, in this study, we provide notions of interpretability based on approximation theory. We \u2026"}, {"title": "MSAttnFlow: Normalizing flow for unsupervised anomaly detection with multi-scale attention", "link": "https://www.sciencedirect.com/science/article/pii/S0031320324009713", "details": "Z Hu, X Zeng, Y Li, Z Yin, E Meng, Z Wei, L Zhu\u2026 - Pattern Recognition, 2024", "abstract": "Unsupervised anomaly detection (UAD) aims to locate anomalies in images without using annotated defective data. Normalizing flow is inherently suitable for the UAD task because it can explicitly model the data distribution and perform accurate \u2026"}, {"title": "Fast Sampling via Discrete Non-Markov Diffusion Models with Predetermined Transition Time", "link": "https://openreview.net/pdf%3Fid%3DKkYZmepjHn", "details": "Z Chen, H Yuan, Y Li, Y Kou, J Zhang, Q Gu - The Thirty-eighth Annual Conference \u2026, 2024", "abstract": "Discrete diffusion models have emerged as powerful tools for high-quality data generation. Despite their success in discrete spaces, such as text generation tasks, the acceleration of discrete diffusion models remains under-explored. In this paper \u2026"}, {"title": "On Domain Generalization Datasets as Proxy Benchmarks for Causal Representation Learning", "link": "https://openreview.net/pdf%3Fid%3DLbFK9pUlA5", "details": "OE Salaudeen, N Chiou, S Koyejo - NeurIPS 2024 Causal Representation Learning \u2026", "abstract": "Benchmarking causal representation learning for real-world high-dimensional settings where most relevant causal variables are not directly observed remains a challenge. Notably, one promise of causal representations is their robustness to \u2026"}, {"title": "Efficient Vision-Language pre-training via domain-specific learning for human activities", "link": "https://aclanthology.org/2024.emnlp-main.454.pdf", "details": "A Bulat, Y Ouali, R Guerrero, B Martinez\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Current Vision-Language (VL) models owe their success to large-scale pre- training on web-collected data, which in turn requires high-capacity architectures and large compute resources for training. We posit that when the downstream tasks are \u2026"}, {"title": "Evolved Hierarchical Masking for Self-Supervised Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10742293/", "details": "Z Feng, S Zhang - IEEE Transactions on Pattern Analysis and Machine \u2026, 2024", "abstract": "Existing Masked Image Modeling methods apply fixed mask patterns to guide the self- supervised training. As those mask patterns resort to different criteria to depict image contents, sticking to a fixed pattern leads to a limited vision cues modeling capability \u2026"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2411.03313%3F", "details": "H Zilong, Y Qinghao, K Bingyi, F Jiashi, F Haoqi - arXiv preprint arXiv:2411.03313, 2024", "abstract": "We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised \u2026"}]
