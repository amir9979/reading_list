[{"title": "Predicting and analyzing memorization within fine-tuned Large Language Models", "link": "https://arxiv.org/pdf/2409.18858", "details": "J Dentan, D Buscaldi, A Shabou, S Vanier - arXiv preprint arXiv:2409.18858, 2024", "abstract": "Large Language Models have received significant attention due to their abilities to solve a wide range of complex tasks. However these models memorize a significant proportion of their training data, posing a serious threat when disclosed at inference \u2026"}, {"title": "Chatbots Are Not Clinicians: Addressing Misconceptions About Large Language Model Use in Psychiatric Care", "link": "https://link.springer.com/article/10.1007/s40596-024-02042-1", "details": "B Bala - Academic Psychiatry, 2024", "abstract": "Of all the reasons people have used to try and dissuade me from entering psychiatry\u2014 financial, cultural, political\u2014this assertion about AI was new. Even more surprising was that this comment came from a fellow medical student. Over the last year \u2026"}, {"title": "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models", "link": "https://arxiv.org/pdf/2409.18943", "details": "J Li, L Zhang, Y Li, Z Liu, R Luo, L Chen, M Yang - arXiv preprint arXiv:2409.18943, 2024", "abstract": "The instruction-following ability of large language models enables humans to interact with AI agents in a natural way. However, when required to generate responses of a specific length, large language models often struggle to meet users' needs due to \u2026"}]
