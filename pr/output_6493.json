[{"title": "Multi-scale multi-instance contrastive learning for whole slide image classification", "link": "https://www.sciencedirect.com/science/article/pii/S0952197624014581", "details": "J Zhang, F Hao, X Liu, S Yao, Y Wu, M Li, W Zheng - Engineering Applications of \u2026, 2024", "abstract": "Multi-instance learning (MIL) has become the mainstream solution for processing super-high resolution whole slide images (WSIs) with the pyramidal structure in digital pathology. Current MIL-based methods usually learn features from WSI at a \u2026"}, {"title": "MSCPT: Few-shot Whole Slide Image Classification with Multi-scale and Context-focused Prompt Tuning", "link": "https://arxiv.org/pdf/2408.11505", "details": "M Han, L Qu, D Yang, X Zhang, X Wang, L Zhang - arXiv preprint arXiv:2408.11505, 2024", "abstract": "Multiple instance learning (MIL) has become a standard paradigm for weakly supervised classification of whole slide images (WSI). However, this paradigm relies on the use of a large number of labelled WSIs for training. The lack of training data \u2026"}, {"title": "Dataset Distillation for Histopathology Image Classification", "link": "https://arxiv.org/pdf/2408.09709", "details": "C Cong, S Xuan, S Liu, M Pagnucco, S Zhang, Y Song - arXiv preprint arXiv \u2026, 2024", "abstract": "Deep neural networks (DNNs) have exhibited remarkable success in the field of histopathology image analysis. On the other hand, the contemporary trend of employing large models and extensive datasets has underscored the significance of \u2026"}, {"title": "FR-MIL: Distribution Re-calibration based Multiple Instance Learning with Transformer for Whole Slide Image Classification", "link": "https://ieeexplore.ieee.org/abstract/document/10640165/", "details": "P Chikontwe, M Kim, J Jeong, HJ Sung, H Go, SJ Nam\u2026 - IEEE Transactions on \u2026, 2024", "abstract": "In digital pathology, whole slide images (WSI) are crucial for cancer prognostication and treatment planning. WSI classification is generally addressed using multiple instance learning (MIL), alleviating the challenge of processing billions of pixels and \u2026"}, {"title": "Attention Is Not What You Need: Revisiting Multi-Instance Learning for Whole Slide Image Classification", "link": "https://arxiv.org/pdf/2408.09449", "details": "X Liu, W Zhang, ML Zhang - arXiv preprint arXiv:2408.09449, 2024", "abstract": "Although attention-based multi-instance learning algorithms have achieved impressive performances on slide-level whole slide image (WSI) classification tasks, they are prone to mistakenly focus on irrelevant patterns such as staining conditions \u2026"}, {"title": "Rectifying self-training with neighborhood consistency and proximity for source-free domain adaptation", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224011962", "details": "B Xing, X Ying, R Wang - Neurocomputing, 2024", "abstract": "Source-free domain adaptation (SFDA) seeks to transfer knowledge from the source domain to the target domain by leveraging only unlabeled target data and pre- trained source model, without accessing source data. Existing approaches for SFDA \u2026"}]
