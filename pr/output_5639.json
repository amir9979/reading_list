[{"title": "Aligning (Medical) LLMs for (Counterfactual) Fairness", "link": "https://arxiv.org/pdf/2408.12055", "details": "R Poulain, H Fayyaz, R Beheshti - arXiv preprint arXiv:2408.12055, 2024", "abstract": "Large Language Models (LLMs) have emerged as promising solutions for a variety of medical and clinical decision support applications. However, LLMs are often subject to different types of biases, which can lead to unfair treatment of individuals \u2026"}, {"title": "TRRG: Towards Truthful Radiology Report Generation With Cross-modal Disease Clue Enhanced Large Language Model", "link": "https://arxiv.org/pdf/2408.12141", "details": "Y Wang, C Hao, Y Cui, X Su, W Xie, T Tan, Z Yu - arXiv preprint arXiv:2408.12141, 2024", "abstract": "The vision-language modeling capability of multi-modal large language models has attracted wide attention from the community. However, in medical domain, radiology report generation using vision-language models still faces significant challenges due \u2026"}, {"title": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference", "link": "https://arxiv.org/pdf/2408.01935", "details": "K Shen, M Kejriwal - arXiv preprint arXiv:2408.01935, 2024", "abstract": "Despite their impressive performance, large language models (LLMs) such as ChatGPT are known to pose important risks. One such set of risks arises from misplaced confidence, whether over-confidence or under-confidence, that the \u2026"}, {"title": "Citekit: A Modular Toolkit for Large Language Model Citation Generation", "link": "https://arxiv.org/pdf/2408.04662", "details": "J Shen, T Zhou, S Zhao, Y Chen, K Liu - arXiv preprint arXiv:2408.04662, 2024", "abstract": "Enabling Large Language Models (LLMs) to generate citations in Question- Answering (QA) tasks is an emerging paradigm aimed at enhancing the verifiability of their responses when LLMs are utilizing external references to generate an \u2026"}, {"title": "MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework for Multimodal Large Language Model", "link": "https://arxiv.org/pdf/2408.12321", "details": "C Jiang, J Hongrui, H Xu, W Ye, M Dong, M Yan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper presents MaVEn, an innovative Multi-granularity Visual Encoding framework designed to enhance the capabilities of Multimodal Large Language Models (MLLMs) in multi-image reasoning. Current MLLMs primarily focus on single \u2026"}, {"title": "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?", "link": "https://arxiv.org/pdf/2408.11854", "details": "Y Gao, S Myers, S Chen, D Dligach, TA Miller\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The introduction of Large Language Models (LLMs) has advanced data representation and analysis, bringing significant progress in their use for medical questions and answering. Despite these advancements, integrating tabular data \u2026"}]
