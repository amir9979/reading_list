[{"title": "Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning", "link": "https://arxiv.org/pdf/2410.14390", "details": "B Zhang, D Liu, O Simeone, G Wang, D Pezaros, G Zhu - arXiv preprint arXiv \u2026, 2024", "abstract": "To support real-world decision-making, it is crucial for models to be well-calibrated, ie, to assign reliable confidence estimates to their predictions. Uncertainty quantification is particularly important in personalized federated learning (PFL), as \u2026"}, {"title": "Time Series Classification with Large Language Models via Linguistic Scaffolding", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10706904.pdf", "details": "H Jang, JY Yang, J Hwang, E Yang - IEEE Access, 2024", "abstract": "Time series classification requires specialized models that can effectively capture temporal structures. Consequently, Large Language Models (LLMs) have emerged as promising candidates due to their proficiency in sequence modeling and semantic \u2026"}, {"title": "Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models", "link": "https://arxiv.org/pdf/2410.09385", "details": "SK Bhethanabhotla, O Swelam, J Siems, D Salinas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces Mamba4Cast, a zero-shot foundation model for time series forecasting. Based on the Mamba architecture and inspired by Prior-data Fitted Networks (PFNs), Mamba4Cast generalizes robustly across diverse time series tasks \u2026"}, {"title": "Self-Supervised Learning of Disentangled Representations for Multivariate Time-Series", "link": "https://arxiv.org/pdf/2410.12606", "details": "C Chang, CT Chan, WY Wang, WC Peng, TF Chen - arXiv preprint arXiv:2410.12606, 2024", "abstract": "Multivariate time-series data in fields like healthcare and industry are informative but challenging due to high dimensionality and lack of labels. Recent self-supervised learning methods excel in learning rich representations without labels but struggle \u2026"}, {"title": "DyGraphformer: Transformer combining dynamic spatio-temporal graph network for multivariate time series forecasting", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024007007", "details": "S Han, Y Xun, J Cai, H Yang, Y Li - Neural Networks, 2024", "abstract": "Transformer-based models demonstrate tremendous potential for Multivariate Time Series (MTS) forecasting due to their ability to capture long-term temporal dependencies by using the self-attention mechanism. However, effectively modeling \u2026"}, {"title": "Dynamic deep graph convolution with enhanced transformer networks for time series anomaly detection in IoT", "link": "https://link.springer.com/article/10.1007/s10586-024-04707-w", "details": "R Gao, Z Chen, X Wu, Y Yu, L Zhang - Cluster Computing, 2025", "abstract": "Anomaly detection of multi-time series data during the working process of Internet of Things systems that utilize sensors is one of the key aspects to prevent accidents in industrial information systems. The key challenge is to discover generalized normal \u2026"}, {"title": "Dynamic Contrastive Learning for Time Series Representation", "link": "https://arxiv.org/pdf/2410.15416", "details": "AK Shamba, K Bach, G Taylor - arXiv preprint arXiv:2410.15416, 2024", "abstract": "Understanding events in time series is an important task in a variety of contexts. However, human analysis and labeling are expensive and time-consuming. Therefore, it is advantageous to learn embeddings for moments in time series in an \u2026"}, {"title": "Posterior Inferred, Now What? Streamlining Prediction in Bayesian Deep Learning", "link": "https://openreview.net/pdf%3Fid%3Dcx9TXPTzt9", "details": "R Li, M Klasson, A Solin, M Trapp - NeurIPS 2024 Workshop on Bayesian Decision \u2026", "abstract": "The rising interest in Bayesian deep learning (BDL) has led to a plethora of methods for estimating the posterior distribution. However, efficient computation of inferences, such as predictions, has been largely overlooked with Monte Carlo integration \u2026"}, {"title": "DEformer: Dual Embedded Transformer for Multivariate Time Series Forecasting", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10710626.pdf", "details": "M Kim, S Lee, SM Choi - IEEE Access, 2024", "abstract": "Deep learning models have significantly addressed the challenges of multivariate time series forecasting. Recently, Transformer-based models which have primarily focused on either temporal or inter-variate (spatial) dependencies have \u2026"}]
