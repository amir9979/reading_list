[{"title": "Low-Rank Few-Shot Adaptation of Vision-Language Models", "link": "https://arxiv.org/pdf/2405.18541", "details": "M Zanella, IB Ayed - arXiv preprint arXiv:2405.18541, 2024", "abstract": "Recent progress in the few-shot adaptation of Vision-Language Models (VLMs) has further pushed their generalization capabilities, at the expense of just a few labeled samples within the target downstream task. However, this promising, already quite \u2026"}, {"title": "Autonomous Data Selection with Language Models for Mathematical Texts", "link": "https://openreview.net/pdf%3Fid%3DbBF077z8LF", "details": "Y Zhang, Y Luo, Y Yuan, AC Yao - ICLR 2024 Workshop on Navigating and \u2026, 2024", "abstract": "To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or \u2026"}, {"title": "Calibrating Reasoning in Language Models with Internal Consistency", "link": "https://arxiv.org/pdf/2405.18711", "details": "Z Xie, J Guo, T Yu, S Li - arXiv preprint arXiv:2405.18711, 2024", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various reasoning tasks, aided by techniques like chain-of-thought (CoT) prompting that elicits verbalized reasoning. However, LLMs often generate text with obvious \u2026"}, {"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment", "link": "https://arxiv.org/pdf/2405.19332", "details": "S Zhang, D Yu, H Sharma, Z Yang, S Wang, H Hassan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed \u2026"}, {"title": "AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data", "link": "https://arxiv.org/pdf/2405.19265", "details": "Z Song, Y Wang, W Zhang, K Liu, C Lyu, D Song\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Open-source Large Language Models (LLMs) and their specialized variants, particularly Code LLMs, have recently delivered impressive performance. However, previous Code LLMs are typically fine-tuned on single-source data with limited \u2026"}, {"title": "A Causal Framework for Evaluating Deferring Systems", "link": "https://arxiv.org/pdf/2405.18902", "details": "F Palomba, A Pugnana, JM Alvarez, S Ruggieri - arXiv preprint arXiv:2405.18902, 2024", "abstract": "Deferring systems extend supervised Machine Learning (ML) models with the possibility to defer predictions to human experts. However, evaluating the impact of a deferring strategy on system accuracy is still an overlooked area. This paper fills this \u2026"}, {"title": "Saliency infused dialogue response generation: Improving task oriented text generation using feature attribution", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424011497", "details": "RK Joshi, A Chatterjee, A Ekbal - Expert Systems with Applications, 2024", "abstract": "Challenges persist in dialogue scenarios, particularly in multi-turn dialogues where response generation often disregards contextual information beyond the last user utterance, resulting in fluent yet inadequate responses. This paper addresses these \u2026"}, {"title": "ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models", "link": "https://arxiv.org/pdf/2405.18638", "details": "A Elangovan, L Liu, L Xu, S Bodapati, D Roth - arXiv preprint arXiv:2405.18638, 2024", "abstract": "In this position paper, we argue that human evaluation of generative large language models (LLMs) should be a multidisciplinary undertaking that draws upon insights from disciplines such as user experience research and human behavioral \u2026"}]
