[{"title": "Linguistic Entity Masking to Improve Cross-Lingual Representation of Multilingual Language Models for Low-Resource Languages", "link": "https://arxiv.org/pdf/2501.05700", "details": "A Fernando, S Ranathunga - arXiv preprint arXiv:2501.05700, 2025", "abstract": "Multilingual Pre-trained Language models (multiPLMs), trained on the Masked Language Modelling (MLM) objective are commonly being used for cross-lingual tasks such as bitext mining. However, the performance of these models is still \u2026"}, {"title": "Federated Learning with Partially Labeled Data: A Conditional Distillation Approach", "link": "https://arxiv.org/pdf/2412.18833", "details": "P Wang, C Shen, M Oda, CS Fuh, K Mori, W Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In medical imaging, developing generalized segmentation models that can handle multiple organs and lesions is crucial. However, the scarcity of fully annotated datasets and strict privacy regulations present significant barriers to data sharing \u2026"}, {"title": "OASIS Uncovers: High-Quality T2I Models, Same Old Stereotypes", "link": "https://arxiv.org/pdf/2501.00962", "details": "S Dehdashtian, G Sreekumar, VN Boddeti - arXiv preprint arXiv:2501.00962, 2025", "abstract": "Images generated by text-to-image (T2I) models often exhibit visual biases and stereotypes of concepts such as culture and profession. Existing quantitative measures of stereotypes are based on statistical parity that does not align with the \u2026"}, {"title": "Large Language Model Federated Learning with Blockchain and Unlearning for Cross-Organizational Collaboration", "link": "https://arxiv.org/pdf/2412.13551", "details": "X Zuo, M Wang, T Zhu, S Yu, W Zhou - arXiv preprint arXiv:2412.13551, 2024", "abstract": "Large language models (LLMs) have transformed the way computers understand and process human language, but using them effectively across different organizations remains still difficult. When organizations work together to improve \u2026"}, {"title": "Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2501.05767", "details": "Y Li, H Huang, C Chen, K Huang, C Huang, Z Guo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The recent advancement of Multimodal Large Language Models (MLLMs) has significantly improved their fine-grained perception of single images and general comprehension across multiple images. However, existing MLLMs still face \u2026"}, {"title": "Cascaded Self-Evaluation Augmented Training for Efficient Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2501.05662", "details": "Z Lv, W Wang, J Wang, S Zhang, F Wu - arXiv preprint arXiv:2501.05662, 2025", "abstract": "Efficient Multimodal Large Language Models (EMLLMs) have rapidly advanced recently. Incorporating Chain-of-Thought (CoT) reasoning and step-by-step self- evaluation has improved their performance. However, limited parameters often \u2026"}]
