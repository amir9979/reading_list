[{"title": "Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models", "link": "https://arxiv.org/pdf/2412.16545", "details": "Z Zhang, Y Wang, X Huang, T Fang, H Zhang, C Deng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models have shown remarkable performance across a wide range of language tasks, owing to their exceptional capabilities in context modeling. The most commonly used method of context modeling is full self-attention, as seen in \u2026"}, {"title": "MAPLE: A Framework for Active Preference Learning Guided by Large Language Models", "link": "https://arxiv.org/pdf/2412.07207", "details": "S Mahmud, M Nakamura, S Zilberstein - arXiv preprint arXiv:2412.07207, 2024", "abstract": "The advent of large language models (LLMs) has sparked significant interest in using natural language for preference learning. However, existing methods often suffer from high computational burdens, taxing human supervision, and lack of \u2026"}, {"title": "Quantifying perturbation impacts for large language models", "link": "https://arxiv.org/pdf/2412.00868", "details": "P Rauba, Q Wei, M van der Schaar - arXiv preprint arXiv:2412.00868, 2024", "abstract": "We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability. A key obstacle in this domain is disentangling the \u2026"}]
