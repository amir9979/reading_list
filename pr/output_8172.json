[{"title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models", "link": "https://arxiv.org/pdf/2410.18785", "details": "Q Li, X Liu, Z Tang, P Dong, Z Li, X Pan, X Chu - arXiv preprint arXiv:2410.18785, 2024", "abstract": "Model editing has become an increasingly popular alternative for efficiently updating knowledge within language models. Current methods mainly focus on reliability, generalization, and locality, with many methods excelling across these criteria. Some \u2026"}, {"title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models", "link": "https://arxiv.org/pdf/2410.18252", "details": "M Noukhovitch, S Huang, S Xhonneux, A Hosseini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously generating from the large language model (LLM) policy, labelling with a reward model, and learning using feedback on the LLM's own outputs. While performant, this \u2026"}, {"title": "CREAM: Consistency Regularized Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2410.12735%3F", "details": "Z Wang, W He, Z Liang, X Zhang, C Bansal, Y Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent self-rewarding large language models (LLM) have successfully applied LLM- as-a-Judge to iteratively improve the alignment performance without the need of human annotations for preference data. These methods commonly utilize the same \u2026"}, {"title": "Large language models enabled multiagent ensemble method for efficient EHR data labeling", "link": "https://arxiv.org/pdf/2410.16543", "details": "J Huang, K Nezafati, I Villanueva-Miranda, Z Gu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This study introduces a novel multiagent ensemble method powered by LLMs to address a key challenge in ML-data labeling, particularly in large-scale EHR datasets. Manual labeling of such datasets requires domain expertise and is labor \u2026"}, {"title": "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "link": "https://arxiv.org/pdf/2410.05077", "details": "FM Molfese, S Conia, R Orlando, R Navigli - arXiv preprint arXiv:2410.05077, 2024", "abstract": "Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have \u2026"}, {"title": "Prompt Learning for Few-Shot Question Answering via Self-Context Data Augmentation", "link": "https://ieeexplore.ieee.org/abstract/document/10723112/", "details": "JQ Qiu, CY Zhang, CLP Chen - IEEE Transactions on Artificial Intelligence, 2024", "abstract": "Pre-trained language models (PLMs) have shown remarkable performance on question answering (QA) tasks, but they usually require fine-tuning that depends on a substantial quantity of QA pairs. Therefore, improving the performance of PLMs in \u2026"}, {"title": "Assessments of Generative AI as Clinical Decision Support Ought to be Incorporated into Randomised Controlled Trials of Electronic Alerts for Acute Kidney Injury", "link": "https://www.mcpdigitalhealth.org/article/S2949-7612\\(24\\)00101-9/fulltext", "details": "DJ Sexton, C Judge - Mayo Clinic Proceedings: Digital Health", "abstract": "Acute Kidney Injury (AKI), characterised by an acute deterioration in kidney function occurs in approximately 25% of hospitalised individuals and is associated with prolonged stay, higher cost and increased morbidity and mortality. 1 Clinical \u2026"}, {"title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models", "link": "https://arxiv.org/pdf/2410.05639", "details": "R Zhao, ZL Thai, Y Zhang, S Hu, Y Ba, J Zhou, J Cai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The performance of Large Language Models (LLMs) is substantially influenced by the pretraining corpus, which consists of vast quantities of unsupervised data processed by the models. Despite its critical role in model performance, ensuring the \u2026"}, {"title": "Probing-RAG: Self-Probing to Guide Language Models in Selective Document Retrieval", "link": "https://arxiv.org/pdf/2410.13339", "details": "I Baek, H Chang, B Kim, J Lee, H Lee - arXiv preprint arXiv:2410.13339, 2024", "abstract": "Retrieval-Augmented Generation (RAG) enhances language models by retrieving and incorporating relevant external knowledge. However, traditional retrieve-and- generate processes may not be optimized for real-world scenarios, where queries \u2026"}]
