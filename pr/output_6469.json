[{"title": "Contrastive Learning Network for Unsupervised Graph Matching", "link": "https://ieeexplore.ieee.org/abstract/document/10671578/", "details": "Y Xie, L Luo, T Cao, B Yu, AK Qin - IEEE Transactions on Circuits and Systems for \u2026, 2024", "abstract": "Graph matching aims to establish node correspondences between graphs, which is a classic combinatorial optimization problem. In recent years,(deep) learning-based methods have emerged as a superior alternative to traditional graph matching \u2026"}, {"title": "Cross-modality interaction reasoning for enhancing vision-language pre-training in image-text retrieval", "link": "https://link.springer.com/article/10.1007/s10489-024-05823-1", "details": "T Yao, S Peng, L Wang, Y Li, Y Sun - Applied Intelligence, 2024", "abstract": "Recent days have seen significant improvements in multi-modal learning made by Vision-Language Pre-training (VLP) models. However, most of them employ the coarse-grained global alignment to overcome semantic gap for generating common \u2026"}, {"title": "Revisiting Prompt Pretraining of Vision-Language Models", "link": "https://arxiv.org/pdf/2409.06166", "details": "Z Chen, L Yang, S Chen, Z Chen, J Liang, X Li - arXiv preprint arXiv:2409.06166, 2024", "abstract": "Prompt learning is an effective method to customize Vision-Language Models (VLMs) for various downstream tasks, involving tuning very few parameters of input prompt tokens. Recently, prompt pretraining in large-scale dataset (eg, ImageNet \u2026"}]
