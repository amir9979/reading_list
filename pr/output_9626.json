[{"title": "ConvBench: A Multi-Turn Conversation Evaluation Benchmark with Hierarchical Ablation Capability for Large Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3DPyTf2jj0SH", "details": "S Liu, K Ying, H Zhang, Y Yang, Y Lin, T Zhang, C Li\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Multi-turn visual conversation is an important ability of real-world AI assistants. However, the related evaluation benchmark is missed. This paper presents ConvBench, a multi-turn conversation benchmark with hierarchical capabilities \u2026"}, {"title": "LONG EXPOSURE: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity", "link": "https://www.computer.org/csdl/proceedings-article/sc/2024/529100b176/21HUWjOHh3q", "details": "T Wang, K Li, Z Hao, D Bai, J Ren, Y Zhang, T Cao\u2026 - 2024 SC24: International \u2026, 2024", "abstract": "The adaptation of pre-trained large language models (LLMs) to diverse downstream tasks via fine-tuning is critical for numerous applications. However, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques presents significant challenges in \u2026"}, {"title": "Label correlated contrastive learning for medical report generation", "link": "https://www.sciencedirect.com/science/article/pii/S0169260724004759", "details": "X Liu, J Xin, B Dai, Q Shen, Z Huang, Z Wang - Computer Methods and Programs in \u2026, 2024", "abstract": "Abstract Background and Objective: Automatic generation of medical reports reduces both the burden on radiologists and the possibility of errors due to the inexperience of radiologists. The model that utilizes attention mechanism and contrastive learning \u2026"}, {"title": "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "link": "https://aclanthology.org/2024.emnlp-main.1249.pdf", "details": "X Lin, M Li, R Zemel, H Ji, SF Chang - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "Recently, enabling pretrained language models (PLMs) to perform zero-shot crossmodal tasks such as video question answering has been extensively studied. A popular approach is to learn a projection network that projects visual features into the \u2026"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2411.03313%3F", "details": "H Zilong, Y Qinghao, K Bingyi, F Jiashi, F Haoqi - arXiv preprint arXiv:2411.03313, 2024", "abstract": "We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised \u2026"}, {"title": "PhoneLM: an Efficient and Capable Small Language Model Family through Principled Pre-training", "link": "https://arxiv.org/pdf/2411.05046", "details": "R Yi, X Li, W Xie, Z Lu, C Wang, A Zhou, S Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The interest in developing small language models (SLM) for on-device deployment is fast growing. However, the existing SLM design hardly considers the device hardware characteristics. Instead, this work presents a simple yet effective principle \u2026"}, {"title": "Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering", "link": "https://aclanthology.org/2024.emnlp-main.110.pdf", "details": "D Hao, Q Wang, L Guo, J Jiang, J Liu - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "While large pre-trained visual-language models have shown promising results on traditional visual question answering benchmarks, it is still challenging for them to answer complex VQA problems which requires diverse world knowledge. Motivated \u2026"}, {"title": "Empowering multi-step reasoning across languages via program-aided language models", "link": "https://aclanthology.org/2024.emnlp-main.678.pdf", "details": "L Ranaldi, G Pucci, B Haddow, A Birch - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "In-context learning methods are popular inference strategies where Large Language Models (LLMs) are elicited to solve a task using provided demonstrations without parameter updates. Among these approaches are the reasoning methods, best \u2026"}, {"title": "Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations", "link": "https://arxiv.org/pdf/2411.05261", "details": "Y Fang, Z Jin, S Guo, J Liu, Y Gao, J Ning, Z Yue, Z Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite significant advancements in report generation methods, a critical limitation remains: the lack of interpretability in the generated text. This paper introduces an innovative approach to enhance the explainability of text generated by report \u2026"}]
