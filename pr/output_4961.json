[{"title": "Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation", "link": "https://arxiv.org/pdf/2407.19619", "details": "M Bhattarai, JE Santos, S Jones, A Biswas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The advent of large language models (LLMs) has significantly advanced the field of code translation, enabling automated translation between programming languages. However, these models often struggle with complex translation tasks due to \u2026"}, {"title": "Report-Concept Textual-Prompt Learning for Enhancing X-ray Diagnosis", "link": "https://openreview.net/pdf%3Fid%3Dfgy59cM8X6", "details": "X Zhao, ZY Liu, F Liu, G Li, Y Dou, S Peng - ACM Multimedia 2024", "abstract": "Despite significant advances in image-text medical visual language modeling, the high cost of fine-grained annotation of images to align radiology reports has led current approaches to focus primarily on semantic alignment between the image and \u2026"}, {"title": "Specialist vision-language models for clinical ophthalmology", "link": "https://arxiv.org/abs/2407.08410", "details": "R Holland, TRP Taylor, C Holmes, S Riedl, J Mai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Clinicians spend a significant amount of time reviewing medical images and transcribing their findings regarding patient diagnosis, referral and treatment in text form. Vision-language models (VLMs), which automatically interpret images and \u2026"}, {"title": "SSAT-Adapter: Enhancing Vision-Language Model Few-shot Learning with Auxiliary Tasks", "link": "https://openreview.net/pdf%3Fid%3DuaKuvzR74K", "details": "B Chen, YS Koh, G Dobbie - ACM Multimedia 2024", "abstract": "Traditional deep learning models often struggle in few-shot learning scenarios, where limited labeled data is available. While the Contrastive Language-Image Pre- training (CLIP) model demonstrates impressive zero-shot capabilities, its \u2026"}, {"title": "Towards Medical Vision-Language Contrastive Pre-training via Study-Oriented Semantic Exploration", "link": "https://openreview.net/pdf%3Fid%3DVIPZtona4Q", "details": "LIU BO, LU ZEXIN, Y Wang - ACM Multimedia 2024", "abstract": "Contrastive vision-language pre-training has shown great promise in representation transfer learning and cross-modality learning in the medical field. However, without fully exploiting the intrinsic properties and correlations of multimodal medical data \u2026"}, {"title": "Exploring Universal Intrinsic Task Subspace for Few-shot Learning via Prompt Tuning", "link": "https://ieeexplore.ieee.org/iel8/6570655/6633080/10603438.pdf", "details": "Y Qin, X Wang, Y Su, Y Lin, N Ding, J Yi, W Chen, Z Liu\u2026 - IEEE/ACM Transactions on \u2026, 2024", "abstract": "Why can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidence indicating that the adaptations of PLMs to various fewshot \u2026"}, {"title": "Cognitive Assessment of Language Models", "link": "https://openreview.net/pdf%3Fid%3DpxRh1meUvN", "details": "D McDuff, D Munday, X Liu, I Galatzer-Levy - ICML 2024 Workshop on LLMs and Cognition", "abstract": "Large language models (LLMs) are a subclass of generative artificial intelligence that can interpret language inputs to generate novel responses. These capabilities are conceptualized as a significant step forward in artificial intelligence because the \u2026"}, {"title": "PCLmed: Champion Solution for ImageCLEFmedical 2024 Caption Prediction Challenge via Medical Vision-Language Foundation Models", "link": "https://ceur-ws.org/Vol-3740/paper-164.pdf", "details": "B Yang, Y Yu, Y Zou, T Zhang - \u2026 Working Notes, CEUR Workshop Proceedings, CEUR \u2026, 2024", "abstract": "Automatically generating captions and reports for medical images has become increasingly important due to the growing workload of radiologists in hospitals. To tackle this challenging task with limited annotation data, there is a rising interest in \u2026"}]
