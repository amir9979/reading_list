'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Autonomous Data Selection with Language Models for Mat'
[{"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "link": "https://arxiv.org/pdf/2405.00402", "details": "L Ranaldi, A Freitas - arXiv preprint arXiv:2405.00402, 2024", "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches \u2026"}, {"title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision", "link": "https://arxiv.org/pdf/2405.04086", "details": "Y Tong, S Wang, D Li, Y Wang, S Han, Z Lin, C Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While Large Language Models (LLMs) have demonstrated proficiency in handling complex queries, much of the past work has depended on extensively annotated datasets by human experts. However, this reliance on fully-supervised annotations \u2026"}, {"title": "RevOnt: Reverse Engineering of Competency Questions from Knowledge Graphs via Language Models", "link": "https://kclpure.kcl.ac.uk/portal/files/257691951/RevOnt_Revisions_Jongmo_3_.pdf", "details": "F Ciroku, J de Berardinis, J Kim, AM Penuela\u2026 - Journal of Web Semantics, 2024", "abstract": "RevOnt: Reverse Engineering of Competency Questions from Knowledge Graphs via Language Models Page 1 King\u2019s Research Portal Link to publication record in King's Research Portal Citation for published version (APA): Ciroku, F., de Berardinis, J., Kim \u2026"}, {"title": "More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness", "link": "https://arxiv.org/pdf/2404.18870", "details": "AJ Li, S Krishna, H Lakkaraju - arXiv preprint arXiv:2404.18870, 2024", "abstract": "The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power. Despite the effectiveness of \u2026"}, {"title": "HFT: Half Fine-Tuning for Large Language Models", "link": "https://arxiv.org/pdf/2404.18466", "details": "T Hui, Z Zhang, S Wang, W Xu, Y Sun, H Wu - arXiv preprint arXiv:2404.18466, 2024", "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of \u2026"}, {"title": "Model & Data Insights using Pre-trained Language Models", "link": "https://openreview.net/pdf%3Fid%3DL5T3ZqsD0j", "details": "S Asgari, A Khani, AH Khasahmadi, A Sanghi\u2026 - ICLR 2024 Workshop on \u2026", "abstract": "We propose TExplain, using language models to interpret pre-trained image classifiers' features. Our approach connects the feature space of image classifiers with language models, generating explanatory sentences during inference. By \u2026"}, {"title": "Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2405.00175", "details": "A Salemi, H Zamani - arXiv preprint arXiv:2405.00175, 2024", "abstract": "This paper introduces uRAG--a framework with a unified retrieval engine that serves multiple downstream retrieval-augmented generation (RAG) systems. Each RAG system consumes the retrieval results for a unique purpose, such as open-domain \u2026"}, {"title": "When Quantization Affects Confidence of Large Language Models?", "link": "https://arxiv.org/pdf/2405.00632", "details": "I Proskurina, L Brun, G Metzler, J Velcin - arXiv preprint arXiv:2405.00632, 2024", "abstract": "Recent studies introduced effective compression techniques for Large Language Models (LLMs) via post-training quantization or low-bit weight representation. Although quantized weights offer storage efficiency and allow for faster inference \u2026"}]
