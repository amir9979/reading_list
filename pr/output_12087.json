[{"title": "Unsupervised Anomaly Detection for Improving Adversarial Robustness of 3D Object Detection Models", "link": "https://www.mdpi.com/2079-9292/14/2/236", "details": "M Cai, X Wang, F Sohel, H Lei - Electronics, 2025", "abstract": "Three-dimensional object detection based on deep neural networks (DNNs) is widely used in safety-related applications, such as autonomous driving. However, existing research has shown that 3D object detection models are vulnerable to \u2026"}, {"title": "Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings", "link": "https://openreview.net/forum%3Fid%3Dpv1D6CWgrY", "details": "G Zheng, MA Jacobs, V Braverman, VS Parekh - Medical Imaging with Deep Learning", "abstract": "Self-supervised learning has revolutionized medical imaging by enabling efficient and generalizable feature extraction from large-scale unlabeled datasets. Recently, self-supervised foundation models have been extended to three-dimensional (3D) \u2026"}, {"title": "An Interpretable Measure for Quantifying Predictive Dependence between Continuous Random Variables--Extended Version", "link": "https://arxiv.org/pdf/2501.10815", "details": "R Assun\u00e7\u00e3o, F Figueiredo, FNT J\u00fanior\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "A fundamental task in statistical learning is quantifying the joint dependence or association between two continuous random variables. We introduce a novel, fully non-parametric measure that assesses the degree of association between \u2026"}, {"title": "Enhancing Automated Interpretability with Output-Centric Feature Descriptions", "link": "https://arxiv.org/pdf/2501.08319", "details": "Y Gur-Arieh, R Mayan, C Agassy, A Geiger, M Geva - arXiv preprint arXiv:2501.08319, 2025", "abstract": "Automated interpretability pipelines generate natural language descriptions for the concepts represented by features in large language models (LLMs), such as plants or the first word in a sentence. These descriptions are derived using inputs that \u2026"}]
