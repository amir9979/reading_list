[{"title": "Exploring the Zero-Shot Capabilities of Vision-Language Models for Improving Gaze Following", "link": "https://openaccess.thecvf.com/content/CVPR2024W/GAZE/papers/Gupta_Exploring_the_Zero-Shot_Capabilities_of_Vision-Language_Models_for_Improving_Gaze_CVPRW_2024_paper.pdf", "details": "A Gupta, P Vuillecard, A Farkhondeh, JM Odobez - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "Contextual cues related to a person's pose and interactions with objects and other people in the scene can provide valuable information for gaze following. While existing methods have focused on dedicated cue extraction methods in this work we \u2026"}, {"title": "EmbSpatial-Bench: Benchmarking Spatial Understanding for Embodied Tasks with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2406.05756", "details": "M Du, B Wu, Z Li, X Huang, Z Wei - arXiv preprint arXiv:2406.05756, 2024", "abstract": "The recent rapid development of Large Vision-Language Models (LVLMs) has indicated their potential for embodied tasks. However, the critical skill of spatial understanding in embodied environments has not been thoroughly evaluated \u2026"}, {"title": "MirrorCheck: Efficient Adversarial Defense for Vision-Language Models", "link": "https://arxiv.org/pdf/2406.09250", "details": "S Fares, K Ziu, T Aremu, N Durasov, M Tak\u00e1\u010d, P Fua\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Models (VLMs) are becoming increasingly vulnerable to adversarial attacks as various novel attack strategies are being proposed against these models. While existing defenses excel in unimodal contexts, they currently fall \u2026"}, {"title": "Towards High-fidelity Artistic Image Vectorization via Texture-Encapsulated Shape Parameterization", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Towards_High-fidelity_Artistic_Image_Vectorization_via_Texture-Encapsulated_Shape_Parameterization_CVPR_2024_paper.pdf", "details": "Y Chen, B Ni, J Liu, X Huang, X Chen - Proceedings of the IEEE/CVF Conference on \u2026, 2024", "abstract": "We develop a novel vectorized image representation scheme accommodating both shape/geometry and texture in a decoupled way particularly tailored for reconstruction and editing tasks of artistic/design images such as Emojis and \u2026"}, {"title": "Bridging Operator Learning and Conditioned Neural Fields: A Unifying Perspective", "link": "https://arxiv.org/pdf/2405.13998", "details": "S Wang, JH Seidman, S Sankaran, H Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Operator learning is an emerging area of machine learning which aims to learn mappings between infinite dimensional function spaces. Here we uncover a connection between operator learning architectures and conditioned neural fields \u2026"}, {"title": "GECKO: Generative Language Model for English, Code and Korean", "link": "https://arxiv.org/pdf/2405.15640", "details": "S Oh, D Kim - arXiv preprint arXiv:2405.15640, 2024", "abstract": "We introduce GECKO, a bilingual large language model (LLM) optimized for Korean and English, along with programming languages. GECKO is pretrained on the balanced, high-quality corpus of Korean and English employing LLaMA architecture \u2026"}, {"title": "Neural Fields as Distributions: Signal Processing Beyond Euclidean Space", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Rebain_Neural_Fields_as_Distributions_Signal_Processing_Beyond_Euclidean_Space_CVPR_2024_paper.pdf", "details": "D Rebain, S Yazdani, KM Yi, A Tagliasacchi - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "Neural fields have emerged as a powerful and broadly applicable method for representing signals. However in contrast to classical discrete digital signal processing the portfolio of tools to process such representations is still severely \u2026"}, {"title": "Exploring the Latest LLMs for Leaderboard Extraction", "link": "https://arxiv.org/pdf/2406.04383", "details": "S Kabongo, J D'Souza, S Auer - arXiv preprint arXiv:2406.04383, 2024", "abstract": "The rapid advancements in Large Language Models (LLMs) have opened new avenues for automating complex tasks in AI research. This paper investigates the efficacy of different LLMs-Mistral 7B, Llama-2, GPT-4-Turbo and GPT-4. o in \u2026"}, {"title": "Inter-slice Super-resolution of Magnetic Resonance Images by Pre-training and Self-supervised Fine-tuning", "link": "https://arxiv.org/pdf/2406.05974", "details": "X Wang, Z Song, Y Zhu, S Wang, L Zhang, D Shen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In clinical practice, 2D magnetic resonance (MR) sequences are widely adopted. While individual 2D slices can be stacked to form a 3D volume, the relatively large slice spacing can pose challenges for both image visualization and subsequent \u2026"}]
