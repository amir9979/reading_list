[{"title": "Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL", "link": "https://arxiv.org/pdf/2410.11371", "details": "Q Zhong, K Chen, L Ding, J Liu, B Du, D Tao - arXiv preprint arXiv:2410.11371, 2024", "abstract": "Large Language Models (LLMs) have shown promising performance in text-to-SQL, which involves translating natural language questions into SQL queries. However, current text-to-SQL LLMs are computationally expensive and challenging to deploy \u2026"}, {"title": "MiniPLM: Knowledge Distillation for Pre-Training Language Models", "link": "https://arxiv.org/pdf/2410.17215%3F", "details": "Y Gu, H Zhou, F Meng, J Zhou, M Huang - arXiv preprint arXiv:2410.17215, 2024", "abstract": "Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness \u2026"}, {"title": "Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning", "link": "https://arxiv.org/pdf/2410.14390", "details": "B Zhang, D Liu, O Simeone, G Wang, D Pezaros, G Zhu - arXiv preprint arXiv \u2026, 2024", "abstract": "To support real-world decision-making, it is crucial for models to be well-calibrated, ie, to assign reliable confidence estimates to their predictions. Uncertainty quantification is particularly important in personalized federated learning (PFL), as \u2026"}, {"title": "Variation in Mentions of Race and Ethnicity in Notes in Intensive Care Units Across a Health Care System", "link": "https://aacnjournals.org/ajcconline/article/33/6/462/32573", "details": "J Cobert, E Espejo, J Boscardin, H Mills, D Ashana\u2026 - American Journal of Critical \u2026, 2024", "abstract": "Background Social constructs like race can affect how patients are perceived and impact care. This study investigated whether mentions of race in notes for critically ill patients differed according to patients' race. Methods This retrospective cohort study \u2026"}, {"title": "ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Guarantee Robustness after Fine-Tuning", "link": "https://arxiv.org/pdf/2410.21582", "details": "J Hwang, B Cheung, ZW Hong, A Boopathy, P Agrawal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Highly performant large-scale pre-trained models promise to also provide a valuable foundation for learning specialized tasks, by fine-tuning the model to the desired task. By starting from a good general-purpose model, the goal is to achieve both \u2026"}, {"title": "Interpretable Mesomorphic Neural Networks For Tabular Data", "link": "https://www.researchgate.net/profile/Arlind-Kadra/publication/385416359_Interpretable_Mesomorphic_Neural_Networks_For_Tabular_Data/links/67238fc25852dd723ca07a20/Interpretable-Mesomorphic-Neural-Networks-For-Tabular-Data.pdf", "details": "A Kadra, SP Arango, J Grabocka", "abstract": "Even though neural networks have been long deployed in applications involving tabular data, still existing neural architectures are not explainable by design. In this work, we propose a new class of interpretable neural networks for tabular data that \u2026"}, {"title": "SeRA: Self-Reviewing and Alignment of Large Language Models using Implicit Reward Margins", "link": "https://arxiv.org/pdf/2410.09362", "details": "J Ko, S Dingliwal, B Ganesh, S Sengupta, S Bodapati\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Direct alignment algorithms (DAAs), such as direct preference optimization (DPO), have become popular alternatives for Reinforcement Learning from Human Feedback (RLHF) due to their simplicity, efficiency, and stability. However, the \u2026"}, {"title": "NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples", "link": "https://arxiv.org/pdf/2410.14669%3F", "details": "B Li, Z Lin, W Peng, JD Nyandwi, D Jiang, Z Ma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models (VLMs) have made significant progress in recent visual- question-answering (VQA) benchmarks that evaluate complex visio-linguistic reasoning. However, are these models truly effective? In this work, we show that \u2026"}, {"title": "LLaVA-KD: A Framework of Distilling Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2410.16236", "details": "Y Cai, J Zhang, H He, X He, A Tong, Z Gan, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The success of Large Language Models (LLM) has led researchers to explore Multimodal Large Language Models (MLLM) for unified visual and linguistic understanding. However, the increasing model size and computational complexity of \u2026"}]
