[{"title": "EvolveDirector: Approaching Advanced Text-to-Image Generation with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.07133", "details": "R Zhao, H Yuan, Y Wei, S Zhang, Y Gu, L Ran, X Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in generation models have showcased remarkable capabilities in generating fantastic content. However, most of them are trained on proprietary high-quality data, and some models withhold their parameters and only \u2026"}, {"title": "AnyAttack: Towards Large-scale Self-supervised Generation of Targeted Adversarial Examples for Vision-Language Models", "link": "https://arxiv.org/pdf/2410.05346", "details": "J Zhang, J Ye, X Ma, Y Li, Y Yang, J Sang, DY Yeung - arXiv preprint arXiv \u2026, 2024", "abstract": "Due to their multimodal capabilities, Vision-Language Models (VLMs) have found numerous impactful applications in real-world scenarios. However, recent studies have revealed that VLMs are vulnerable to image-based adversarial attacks \u2026"}, {"title": "MedImageInsight: An Open-Source Embedding Model for General Domain Medical Imaging", "link": "https://arxiv.org/pdf/2410.06542", "details": "NCF Codella, Y Jin, S Jain, Y Gu, HH Lee, AB Abacha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this work, we present MedImageInsight, an open-source medical imaging embedding model. MedImageInsight is trained on medical images with associated text and labels across a diverse collection of domains, including X-Ray, CT, MRI \u2026"}, {"title": "Deciphering Cross-Modal Alignment in Large Vision-Language Models with Modality Integration Rate", "link": "https://arxiv.org/pdf/2410.07167", "details": "Q Huang, X Dong, P Zhang, Y Zang, Y Cao, J Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present the Modality Integration Rate (MIR), an effective, robust, and generalized metric to indicate the multi-modal pre-training quality of Large Vision Language Models (LVLMs). Large-scale pre-training plays a critical role in building capable \u2026"}, {"title": "To read or not to read\u2013A cross-sectional study of Swedish primary care patients' adoption of patient accessible electronic health records", "link": "https://journals.sagepub.com/doi/full/10.1177/20552076241287636", "details": "I Muli, \u00c5 Cajander, H Hvitfeldt, YT Lagerros\u2026 - Digital health, 2024", "abstract": "Objective Patient-accessible electronic health records (PAEHR) were implemented in the Stockholm region of Sweden seven years ago. This study examines socio- demographic and psychographic factors associated with reading/not reading these \u2026"}, {"title": "CLOSER: Towards Better Representation Learning for Few-Shot Class-Incremental Learning", "link": "https://arxiv.org/pdf/2410.05627", "details": "J Oh, S Baik, KM Lee - arXiv preprint arXiv:2410.05627, 2024", "abstract": "Aiming to incrementally learn new classes with only few samples while preserving the knowledge of base (old) classes, few-shot class-incremental learning (FSCIL) faces several challenges, such as overfitting and catastrophic forgetting. Such a \u2026"}]
