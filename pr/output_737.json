'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Adaptive Prompt Routing for Arbitrary Text Style Trans'
[{"title": "Can only LLMs do Reasoning?: Potential of Small Language Models in Task Planning", "link": "https://arxiv.org/pdf/2404.03891", "details": "G Choi, H Ahn - arXiv preprint arXiv:2404.03891, 2024", "abstract": "In robotics, the use of Large Language Models (LLMs) is becoming prevalent, especially for understanding human commands. In particular, LLMs are utilized as domain-agnostic task planners for high-level human commands. LLMs are capable \u2026"}, {"title": "Emergent Abilities in Reduced-Scale Generative Language Models", "link": "https://arxiv.org/pdf/2404.02204", "details": "S Muckatira, V Deshpande, V Lialin, A Rumshisky - arXiv preprint arXiv:2404.02204, 2024", "abstract": "Large language models can solve new tasks without task-specific fine-tuning. This ability, also known as in-context learning (ICL), is considered an emergent ability and is primarily seen in large language models with billions of parameters. This study \u2026"}, {"title": "Fine-Tuning Language Models with Reward Learning on Policy", "link": "https://arxiv.org/pdf/2403.19279", "details": "H Lang, F Huang, Y Li - arXiv preprint arXiv:2403.19279, 2024", "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as an effective approach to aligning large language models (LLMs) to human preferences. RLHF contains three steps, ie, human preference collecting, reward learning, and policy \u2026"}, {"title": "Investigating Regularization of Self-Play Language Models", "link": "https://arxiv.org/pdf/2404.04291", "details": "R Alami, A Abubaker, M Achab, MEA Seddik, S Lahlou - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper explores the effects of various forms of regularization in the context of language model alignment via self-play. While both reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) require to collect \u2026"}, {"title": "NeRFCodec: Neural Feature Compression Meets Neural Radiance Fields for Memory-Efficient Scene Representation", "link": "https://arxiv.org/pdf/2404.02185", "details": "S Li, H Li, Y Liao, L Yu - arXiv preprint arXiv:2404.02185, 2024", "abstract": "The emergence of Neural Radiance Fields (NeRF) has greatly impacted 3D scene modeling and novel-view synthesis. As a kind of visual media for 3D scene representation, compression with high rate-distortion performance is an eternal \u2026"}, {"title": "Africa-Centric Self-Supervised Pre-Training for Multilingual Speech Representation in a Sub-Saharan Context", "link": "https://arxiv.org/pdf/2404.02000", "details": "A Caubri\u00e8re, E Gauthier - arXiv preprint arXiv:2404.02000, 2024", "abstract": "We present the first self-supervised multilingual speech model trained exclusively on African speech. The model learned from nearly 60 000 hours of unlabeled speech segments in 21 languages and dialects spoken in sub-Saharan Africa. On the SSA \u2026"}, {"title": "Bi-level Guided Diffusion Models for Zero-Shot Medical Imaging Inverse Problems", "link": "https://arxiv.org/pdf/2404.03706", "details": "H Askari, F Roosta, H Sun - arXiv preprint arXiv:2404.03706, 2024", "abstract": "In the realm of medical imaging, inverse problems aim to infer high-quality images from incomplete, noisy measurements, with the objective of minimizing expenses and risks to patients in clinical settings. The Diffusion Models have recently emerged \u2026"}, {"title": "NeRF-MAE: Masked AutoEncoders for Self Supervised 3D representation Learning for Neural Radiance Fields", "link": "https://arxiv.org/pdf/2404.01300", "details": "MZ Irshad, S Zakahrov, V Guizilini, A Gaidon, Z Kira\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Neural fields excel in computer vision and robotics due to their ability to understand the 3D visual world such as inferring semantics, geometry, and dynamics. Given the capabilities of neural fields in densely representing a 3D scene from 2D images, we \u2026"}, {"title": "Harnessing the Power of Large Vision Language Models for Synthetic Image Detection", "link": "https://arxiv.org/pdf/2404.02726", "details": "M Keita, W Hamidouche, H Bougueffa, A Hadid\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In recent years, the emergence of models capable of generating images from text has attracted considerable interest, offering the possibility of creating realistic images from text descriptions. Yet these advances have also raised concerns about the \u2026"}]
