[{"title": "BiasICL: In-Context Learning and Demographic Biases of Vision Language Models", "link": "https://arxiv.org/pdf/2503.02334", "details": "S Xu, J Janizek, Y Jiang, R Daneshjou - arXiv preprint arXiv:2503.02334, 2025", "abstract": "Vision language models (VLMs) show promise in medical diagnosis, but their performance across demographic subgroups when using in-context learning (ICL) remains poorly understood. We examine how the demographic composition of \u2026"}, {"title": "X2CT-CLIP: Enable Multi-Abnormality Detection in Computed Tomography from Chest Radiography via Tri-Modal Contrastive Learning", "link": "https://arxiv.org/pdf/2503.02162", "details": "J You, Y Gao, S Kim, C Mcintosh - arXiv preprint arXiv:2503.02162, 2025", "abstract": "Computed tomography (CT) is a key imaging modality for diagnosis, yet its clinical utility is marred by high radiation exposure and long turnaround times, restricting its use for larger-scale screening. Although chest radiography (CXR) is more accessible \u2026"}, {"title": "Enhancing Multi-hop Reasoning in Vision-Language Models via Self-Distillation with Multi-Prompt Ensembling", "link": "https://arxiv.org/pdf/2503.01754%3F", "details": "G Wu, H Song, Y Wang, Q Yan, Y Tian, LL Cheong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multi-modal large language models have seen rapid advancement alongside large language models. However, while language models can effectively leverage chain- of-thought prompting for zero or few-shot learning, similar prompting strategies are \u2026"}, {"title": "GPT-PPG: A GPT-based Foundation Model for Photoplethysmography Signals", "link": "https://arxiv.org/pdf/2503.08015", "details": "Z Chen, C Ding, S Kataria, R Yan, M Wang, R Lee\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This study introduces a novel application of a Generative Pre-trained Transformer (GPT) model tailored for photoplethysmography (PPG) signals, serving as a foundation model for various downstream tasks. Adapting the standard GPT \u2026"}, {"title": "Automated Radiology Report Labeling in Chest X-Ray Pathologies: Development and Evaluation of a Large Language Model Framework", "link": "https://medinform.jmir.org/2025/1/e68618/", "details": "A Abdullah, ST Kim - JMIR Medical Informatics, 2025", "abstract": "Background: Labeling unstructured radiology reports is crucial for creating structured datasets that facilitate downstream tasks, such as training large-scale medical imaging models. Current approaches typically rely on Bidirectional Encoder \u2026"}, {"title": "DynaGraph: Interpretable Multi-Label Prediction from EHRs via Dynamic Graph Learning and Contrastive Augmentation", "link": "https://arxiv.org/pdf/2503.22257", "details": "M Mesinovic, S Molaei, P Watkinson, T Zhu - arXiv preprint arXiv:2503.22257, 2025", "abstract": "Learning from longitudinal electronic health records is limited if it does not capture the temporal trajectories of the patient's state in a clinical setting. Graph models allow us to capture the hidden dependencies of the multivariate time-series when the \u2026"}, {"title": "RadTextAid: A CNN-Guided Framework Utilizing Lightweight Vision-Language Models for Assistive Radiology Reporting", "link": "https://openreview.net/pdf%3Fid%3DqMf7t1RvWW", "details": "MW Nafee, TR Aanika, T Hasan - Workshop on Large Language Models and \u2026, 2025", "abstract": "Deciphering chest X-rays is crucial for diagnosing thoracic diseases such as pneumonia, lung cancer, and cardiomegaly. Radiologists often work under significant workloads and handle large volumes of data, which can lead to \u2026"}, {"title": "EventMamba: Enhancing Spatio-Temporal Locality with State Space Models for Event-Based Video Reconstruction", "link": "https://arxiv.org/pdf/2503.19721", "details": "C Ge, X Fu, P He, K Wang, C Cao, ZJ Zha - arXiv preprint arXiv:2503.19721, 2025", "abstract": "Leveraging its robust linear global modeling capability, Mamba has notably excelled in computer vision. Despite its success, existing Mamba-based vision models have overlooked the nuances of event-driven tasks, especially in video reconstruction \u2026"}, {"title": "Impact of Glyph Information on Latent Space Diffusion Models for Accurate Handwritten Text Generation", "link": "https://ieeexplore.ieee.org/abstract/document/10890644/", "details": "YL Lin, HC Cheng, CI Huang, CY Wang, JC Wang - ICASSP 2025-2025 IEEE \u2026, 2025", "abstract": "The generation of high-quality stylized handwritten text images is a challenging task in computer vision and artificial intelligence. While advanced approaches using Latent Diffusion Models (LDMs) for generating stylized handwritten text have shown \u2026"}]
