[{"title": "Stackelberg Game Preference Optimization for Data-Efficient Alignment of Language Models", "link": "https://arxiv.org/pdf/2502.18099", "details": "X Chu, Z Zhang, T Jia, Y Jin - arXiv preprint arXiv:2502.18099, 2025", "abstract": "Aligning language models with human preferences is critical for real-world deployment, but existing methods often require large amounts of high-quality human annotations. Aiming at a data-efficient alignment method, we propose Stackelberg \u2026"}, {"title": "Multilingual Language Model Pretraining using Machine-translated Data", "link": "https://arxiv.org/pdf/2502.13252", "details": "J Wang, Y Lu, M Weber, M Ryabinin, D Adelani\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "High-resource languages such as English, enables the pretraining of high-quality large language models (LLMs). The same can not be said for most other languages as LLMs still underperform for non-English languages, likely due to a gap in the \u2026"}, {"title": "Transfer-Prompting: Enhancing Cross-Task Adaptation in Large Language Models via Dual-Stage Prompts Optimization", "link": "https://arxiv.org/pdf/2502.14211", "details": "Y Chang, Y Chang, Y Wu - arXiv preprint arXiv:2502.14211, 2025", "abstract": "Large language models (LLMs) face significant challenges when balancing multiple high-level objectives, such as generating coherent, relevant, and high-quality responses while maintaining efficient task adaptation across diverse tasks. To \u2026"}, {"title": "Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs", "link": "https://arxiv.org/pdf/2502.14645", "details": "Y Wu, L Ding, L Shen, D Tao - arXiv preprint arXiv:2502.14645, 2025", "abstract": "Knowledge editing allows for efficient adaptation of large language models (LLMs) to new information or corrections without requiring full retraining. However, prior methods typically focus on either single-language editing or basic multilingual \u2026"}, {"title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.18439", "details": "C Park, S Han, X Guo, A Ozdaglar, K Zhang, JK Kim - arXiv preprint arXiv:2502.18439, 2025", "abstract": "Leveraging multiple large language models (LLMs) to build collaborative multi- agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability \u2026"}, {"title": "Fact or Guesswork? Evaluating Large Language Model's Medical Knowledge with Structured One-Hop Judgment", "link": "https://arxiv.org/pdf/2502.14275", "details": "J Li, Y Wang, K Zhang, Y Cai, B Hooi, N Peng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have been widely adopted in various downstream task domains. However, their ability to directly recall and apply factual medical knowledge remains under-explored. Most existing medical QA benchmarks assess \u2026"}, {"title": "Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks", "link": "https://openreview.net/pdf%3Fid%3D3YyyiyV4B6", "details": "F Lin, S Mao, E La Malfa, V Hofmann, A de Wynter\u2026 - Workshop on Reasoning and \u2026", "abstract": "Language is not monolithic. While benchmarks, including those designed for multiple languages, are often used as proxies to evaluate the performance of Large Language Models (LLMs), they tend to overlook the nuances of within-language \u2026"}, {"title": "Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval", "link": "https://arxiv.org/pdf/2502.13369", "details": "A Sharma, L Lara, A Zouaq, CJ Pal - arXiv preprint arXiv:2502.13369, 2025", "abstract": "The ability to generate SPARQL queries from natural language questions is crucial for ensuring efficient and accurate retrieval of structured data from knowledge graphs (KG). While large language models (LLMs) have been widely adopted for SPARQL \u2026"}, {"title": "Behavioral Analysis of Information Salience in Large Language Models", "link": "https://arxiv.org/pdf/2502.14613", "details": "J Trienes, J Schl\u00f6tterer, JJ Li, C Seifert - arXiv preprint arXiv:2502.14613, 2025", "abstract": "Large Language Models (LLMs) excel at text summarization, a task that requires models to select content based on its importance. However, the exact notion of salience that LLMs have internalized remains unclear. To bridge this gap, we \u2026"}]
