[{"title": "MOM: Memory-Efficient Offloaded Mini-Sequence Inference for Long Context Language Models", "link": "https://arxiv.org/pdf/2504.12526%3F", "details": "J Zhang, T Zhu, C Luo, A Anandkumar - arXiv preprint arXiv:2504.12526, 2025", "abstract": "Long-context language models exhibit impressive performance but remain challenging to deploy due to high GPU memory demands during inference. We propose Memory-efficient Offloaded Mini-sequence Inference (MOM), a method that \u2026"}, {"title": "NNTile: a machine learning framework capable of training extremely large GPT language models on a single node", "link": "https://arxiv.org/pdf/2504.13236", "details": "A Mikhalev, A Katrutsa, K Sozykin, I Oseledets - arXiv preprint arXiv:2504.13236, 2025", "abstract": "This study presents an NNTile framework for training large deep neural networks in heterogeneous clusters. The NNTile is based on a StarPU library, which implements task-based parallelism and schedules all provided tasks onto all available \u2026"}, {"title": "Detoxifying language model outputs: combining multi-agent debates and reinforcement learning for improved summarization", "link": "https://www.researchgate.net/profile/Bharathi-Mohan-Gurusamy/publication/391274884_Detoxifying_language_model_outputs_combining_multi-agent_debates_and_reinforcement_learning_for_improved_summarization/links/6810f68860241d51401fd6e2/Detoxifying-language-model-outputs-combining-multi-agent-debates-and-reinforcement-learning-for-improved-summarization.pdf", "details": "GB Mohan, M Gayathri, RP Kumar - Language Resources and Evaluation, 2025", "abstract": "The increasing prevalence of online user generated content has raised serious concerns about toxic language, which reinforces societal biases and causes psychological harm. This study introduces a novel approach that combines multi \u2026"}, {"title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data", "link": "https://arxiv.org/pdf/2504.09967", "details": "X Zhu, F Mo, Z Zhang, J Wang, Y Shi, M Wu, C Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The emergence of medical generalist foundation models has revolutionized conventional task-specific model development paradigms, aiming to better handle multiple tasks through joint training on large-scale medical datasets. However, recent \u2026"}, {"title": "Overview of the peranssumm 2025 shared task on perspective-aware healthcare answer summarization", "link": "https://aclanthology.org/2025.cl4health-1.41.pdf", "details": "S Agarwal, MS Akhtar, S Yadav - Proceedings of the Second Workshop on Patient \u2026, 2025", "abstract": "This paper presents an overview of the Perspective-aware Answer Summarization (PerAnsSumm) Shared Task on summarizing healthcare answers in Community Question Answering forums hosted at the CL4Health Workshop at NAACL 2025. In \u2026"}, {"title": "MiMo: Unlocking the Reasoning Potential of Language Model--From Pretraining to Posttraining", "link": "https://arxiv.org/pdf/2505.07608", "details": "B Xia, B Shen, D Zhu, D Zhang, G Wang, H Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing \u2026"}, {"title": "Explainable differential diagnosis with dual-inference large language models", "link": "https://www.nature.com/articles/s44401-025-00015-6", "details": "S Zhou, M Lin, S Ding, J Wang, C Chen, GB Melton\u2026 - npj Health Systems, 2025", "abstract": "Automatic differential diagnosis (DDx) involves identifying potential conditions that could explain a patient's symptoms and its accurate interpretation is of substantial significance. While large language models (LLMs) have demonstrated remarkable \u2026"}, {"title": "A Benchmark for Multi-Task Evaluation of Pretrained Models in Medical Report Generation", "link": "https://www.bio-conferences.org/articles/bioconf/pdf/2025/25/bioconf_icbb2025_03010.pdf", "details": "R Lin, C Li, R Wang - BIO Web of Conferences, 2025", "abstract": "MRG for medical images has become increasingly important due to the growing workload of radiologists in hospitals. However, current studies in the MRG field predominantly focus on specific modal-ities or training foundation models with a \u2026"}, {"title": "Automated generation of discharge summaries: leveraging large language models with clinical data", "link": "https://www.nature.com/articles/s41598-025-01618-7", "details": "M Ganzinger, N Kunz, P Fuchs, CK Lyu, M Loos\u2026 - Scientific Reports, 2025", "abstract": "This study explores the use of open-source large language models (LLMs) to automate generation of German discharge summaries from structured clinical data. The structured data used to produce AI-generated summaries were manually \u2026"}]
