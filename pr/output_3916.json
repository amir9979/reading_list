[{"title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models", "link": "https://arxiv.org/pdf/2406.19146", "details": "T Porian, M Wortsman, J Jitsev, L Schmidt, Y Carmon - arXiv preprint arXiv \u2026, 2024", "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the optimal model size as a function of the compute budget, but these laws yield substantially different predictions. We explain the discrepancy by reproducing the Kaplan scaling \u2026"}, {"title": "Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks", "link": "https://arxiv.org/pdf/2406.12066", "details": "J Gallifant, S Chen, P Moreira, N Munch, M Gao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Medical knowledge is context-dependent and requires consistent reasoning across various natural language expressions of semantically equivalent phrases. This is particularly crucial for drug names, where patients often use brand names like Advil \u2026"}, {"title": "Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations", "link": "https://arxiv.org/pdf/2406.11801", "details": "R Hazra, S Layek, S Banerjee, S Poria - arXiv preprint arXiv:2406.11801, 2024", "abstract": "Ensuring the safe alignment of large language models (LLMs) with human values is critical as they become integral to applications like translation and question answering. Current alignment methods struggle with dynamic user intentions and \u2026"}, {"title": "Automating Weak Label Generation for Data Programming with Clinicians in the Loop", "link": "https://arxiv.org/pdf/2407.07982", "details": "J Park, S Pugh, K Sridhar, M Liu, N Yarna, R Kaur\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Deep Neural Networks (DNNs) are often data hungry and need high-quality labeled data in copious amounts for learning to converge. This is a challenge in the field of medicine since high quality labeled data is often scarce. Data programming \u2026"}, {"title": "Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective", "link": "https://arxiv.org/pdf/2407.06992", "details": "YA Liu, R Zhang, J Guo, M de Rijke, Y Fan, X Cheng - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in neural information retrieval (IR) models have significantly enhanced their effectiveness over various IR tasks. The robustness of these models, essential for ensuring their reliability in practice, has also garnered significant \u2026"}, {"title": "Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models", "link": "https://arxiv.org/pdf/2406.14091", "details": "D Lee, D Rim, M Choi, J Choo - arXiv preprint arXiv:2406.14091, 2024", "abstract": "Although language models (LMs) demonstrate exceptional capabilities on various tasks, they are potentially vulnerable to extraction attacks, which represent a significant privacy risk. To mitigate the privacy concerns of LMs, machine unlearning \u2026"}, {"title": "Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?", "link": "https://arxiv.org/pdf/2406.13121", "details": "J Lee, A Chen, Z Dai, D Dua, DS Sachan, M Boratko\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Long-context language models (LCLMs) have the potential to revolutionize our approach to tasks traditionally reliant on external tools like retrieval systems or databases. Leveraging LCLMs' ability to natively ingest and process entire corpora of \u2026"}, {"title": "Iterative Length-Regularized Direct Preference Optimization: A Case Study on Improving 7B Language Models to GPT-4 Level", "link": "https://arxiv.org/pdf/2406.11817", "details": "J Liu, Z Zhou, J Liu, X Bu, C Yang, HS Zhong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Direct Preference Optimization (DPO), a standard method for aligning language models with human preferences, is traditionally applied to offline preferences. Recent studies show that DPO benefits from iterative training with online preferences \u2026"}, {"title": "MFC-Bench: Benchmarking Multimodal Fact-Checking with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2406.11288", "details": "S Wang, H Lin, Z Luo, Z Ye, G Chen, J Ma - arXiv preprint arXiv:2406.11288, 2024", "abstract": "Large vision-language models (LVLMs) have significantly improved multimodal reasoning tasks, such as visual question answering and image captioning. These models embed multimodal facts within their parameters, rather than relying on \u2026"}]
