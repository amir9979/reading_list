[{"title": "Towards Resource Efficient and Interpretable Bias Mitigation in Large Language Models", "link": "https://arxiv.org/pdf/2412.01711", "details": "S Tong, E Zemour, R Lohanimit, L Kagal - arXiv preprint arXiv:2412.01711, 2024", "abstract": "Although large language models (LLMs) have demonstrated their effectiveness in a wide range of applications, they have also been observed to perpetuate unwanted biases present in the training data, potentially leading to harm for marginalized \u2026"}, {"title": "Lookahead Counterfactual Fairness", "link": "https://arxiv.org/pdf/2412.01065", "details": "Z Zuo, T Xie, X Tan, X Zhang, MM Khalili - arXiv preprint arXiv:2412.01065, 2024", "abstract": "As machine learning (ML) algorithms are used in applications that involve humans, concerns have arisen that these algorithms may be biased against certain social groups.\\textit {Counterfactual fairness}(CF) is a fairness notion proposed in Kusner et \u2026"}, {"title": "Verbalized Representation Learning for Interpretable Few-Shot Generalization", "link": "https://arxiv.org/pdf/2411.18651", "details": "CF Yang, D Yin, W Hu, N Peng, B Zhou, KW Chang - arXiv preprint arXiv:2411.18651, 2024", "abstract": "Humans recognize objects after observing only a few examples, a remarkable capability enabled by their inherent language understanding of the real-world environment. Developing verbalized and interpretable representation can \u2026"}, {"title": "Sparse Attention Vectors: Generative Multimodal Model Features Are Discriminative Vision-Language Classifiers", "link": "https://arxiv.org/pdf/2412.00142", "details": "C Mitra, B Huang, T Chai, Z Lin, A Arbelle, R Feris\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generative Large Multimodal Models (LMMs) like LLaVA and Qwen-VL excel at a wide variety of vision-language (VL) tasks such as image captioning or visual question answering. Despite strong performance, LMMs are not directly suited for \u2026"}, {"title": "Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic Vision-language Context Sparsification", "link": "https://arxiv.org/pdf/2412.00876", "details": "W Huang, Z Zhai, Y Shen, S Cao, F Zhao, X Xu, Z Ye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in vision understanding, reasoning, and interaction. However, the inference computation and memory increase progressively with the generation of output tokens \u2026"}, {"title": "Factuality of Large Language Models: A Survey", "link": "https://aclanthology.org/2024.emnlp-main.1088.pdf", "details": "Y Wang, M Wang, MA Manzoor, F Liu, G Georgiev\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Large language models (LLMs), especially when instruction-tuned for chat, have become part of our daily lives, freeing people from the process of searching, extracting, and integrating information from multiple sources by offering a \u2026"}, {"title": "A Comprehensive Guide to Explainable AI: From Classical Models to LLMs", "link": "https://arxiv.org/pdf/2412.00800", "details": "W Hsieh, Z Bi, C Jiang, J Liu, B Peng, S Zhang, X Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Explainable Artificial Intelligence (XAI) addresses the growing need for transparency and interpretability in AI systems, enabling trust and accountability in decision- making processes. This book offers a comprehensive guide to XAI, bridging \u2026"}, {"title": "Quantifying perturbation impacts for large language models", "link": "https://arxiv.org/pdf/2412.00868", "details": "P Rauba, Q Wei, M van der Schaar - arXiv preprint arXiv:2412.00868, 2024", "abstract": "We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability. A key obstacle in this domain is disentangling the \u2026"}, {"title": "Evaluating and Training Long-Context Large Language Models for Question Answering on Scientific Papers", "link": "https://aclanthology.org/2024.customnlp4u-1.17.pdf", "details": "L Hilgert, D Liu, J Niehues - Proceedings of the 1st Workshop on Customizable \u2026, 2024", "abstract": "With the number of scientific papers published every year growing and current large language models (LLMs) showing state-of-the-art performance on natural language processing (NLP) tasks, we ask the question if LLMs could be utilized to answer \u2026"}]
