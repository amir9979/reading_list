[{"title": "Privacy-ensuring open-weights large language models are competitive with closed-weights GPT-4o in extracting chest radiography findings from free-text reports", "link": "https://pubs.rsna.org/doi/pdf/10.1148/radiol.240895", "details": "S Nowak, B Wulff, YC Layer, M Theis, A Isaak, B Salam\u2026 - Radiology, 2025", "abstract": "Background Large-scale secondary use of clinical databases requires automated tools for retrospective extraction of structured content from free-text radiology reports. Purpose To share data and insights on the application of privacy-preserving open \u2026"}, {"title": "Knowledge Enhanced Language Model for Biomedical Natural Language Processing: Introducing a New Language Model for BioNLP", "link": "https://ieeexplore.ieee.org/abstract/document/10836827/", "details": "U Naseem, Q Zhang, L Hu, S Hussain, S Wang - IEEE Systems, Man, and \u2026, 2025", "abstract": "Following the success of pre-trained language models (PLMs), the biomedical research community has presented various domain-specific PLMs trained on a large biomedical and clinical corpus for biomedical natural language processing (BioNLP) \u2026"}, {"title": "BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and Vision-Language Models Derived from Scientific Literature", "link": "https://arxiv.org/pdf/2501.07171", "details": "A Lozano, MW Sun, J Burgess, L Chen, JJ Nirschl, J Gu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The development of vision-language models (VLMs) is driven by large-scale and diverse multimodal datasets. However, progress toward generalist biomedical VLMs is limited by the lack of annotated, publicly accessible datasets across biology and \u2026"}, {"title": "DPO: Discrete Prompt Optimization for Vision-Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10839035/", "details": "N Liang, Y Liu - IEEE Signal Processing Letters, 2025", "abstract": "In recent years, the emergence of large visionlanguage models (VLMs) has catalyzed the development of prompt learning, where networks are trained to enhance VLM performance by learning continuous prompts. However, traditional \u2026"}, {"title": "Focus Your Attention: Multiple Instance Learning with Attention Modification for Whole Slide Pathological Image Classification", "link": "https://ieeexplore.ieee.org/iel8/76/4358651/10838539.pdf", "details": "H Cheng, S Huang, L Cai, Y Xu, R Wang, Y Zhang - IEEE Transactions on Circuits \u2026, 2025", "abstract": "Computer-aided pathology diagnosis based on whole slide images, which is often formulated as a weakly supervised multiple instance learning (MIL) paradigm. Current approaches generally employ attention mechanisms to aggregate instance \u2026"}]
