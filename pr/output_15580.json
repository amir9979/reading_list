[{"title": "ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data", "link": "https://arxiv.org/pdf/2504.14452", "details": "T Chen, F Brahman, J Liu, N Mireshghallah, W Shi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Language models (LMs) can memorize and reproduce segments from their pretraining data verbatim even in non-adversarial settings, raising concerns about copyright, plagiarism, privacy, and creativity. We introduce Paraphrase Preference \u2026"}, {"title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models", "link": "https://arxiv.org/pdf/2504.14194", "details": "X Zhuang, J Peng, R Ma, Y Wang, T Bai, X Wei, J Qiu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality, a critical driver of model performance. Current data selection methods, such as natural \u2026"}, {"title": "Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models", "link": "https://arxiv.org/pdf/2504.15271", "details": "G Chen, Z Li, S Wang, J Jiang, Y Liu, L Lu, DA Huang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce Eagle 2.5, a family of frontier vision-language models (VLMs) for long- context multimodal learning. Our work addresses the challenges in long video comprehension and high-resolution image understanding, introducing a generalist \u2026"}, {"title": "Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data", "link": "https://arxiv.org/pdf/2504.04740", "details": "S Mishra, K Saenko, V Saligrama - arXiv preprint arXiv:2504.04740, 2025", "abstract": "Compositionality, or correctly recognizing scenes as compositions of atomic visual concepts, remains difficult for multimodal large language models (MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in distinguishing \u2026"}, {"title": "CARE: Aligning Language Models for Regional Cultural Awareness", "link": "https://arxiv.org/pdf/2504.05154%3F", "details": "G Guo, T Naous, H Wakaki, Y Nishimura, Y Mitsufuji\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing language models (LMs) often exhibit a Western-centric bias and struggle to represent diverse cultural knowledge. Previous attempts to address this rely on synthetic data and express cultural knowledge only in English. In this work, we study \u2026"}, {"title": "Vision-language foundation model for generalizable nasal disease diagnosis using unlabeled endoscopic records", "link": "https://www.sciencedirect.com/science/article/pii/S0031320325003061", "details": "X Liu, W Gong, X Chen, Z Li, Y Liu, L Wang, Q Liu\u2026 - Pattern Recognition, 2025", "abstract": "Medical artificial intelligence (AI) holds significant potential in identifying signs of health conditions in nasal endoscopic images, thereby accelerating the diagnosis of diseases and systemic disorders. However, the performance of AI models heavily \u2026"}, {"title": "Unlocking language boundaries: AraCLIP-transforming Arabic language and image understanding through cross-lingual models", "link": "https://www.sciencedirect.com/science/article/pii/S0952197625005779", "details": "M Al-Barham, I Afyouni, K Almubarak, A Turky\u2026 - Engineering Applications of \u2026, 2025", "abstract": "In the domain of image retrieval, the integration of text and images has been transformative, facilitating models that transcend language barriers. This paper introduces Arabic Contrastive Language-Image Pre-training (AraCLIP), an extension \u2026"}, {"title": "ELOQUENT CLEF Shared Tasks for Evaluation of Generative Language Model Quality, 2025 Edition", "link": "https://link.springer.com/chapter/10.1007/978-3-031-88720-8_56", "details": "J Karlgren, E Artemova, O Bojar, V Mikhailov\u2026 - European Conference on \u2026, 2025", "abstract": "The ELOQUENT lab for evaluation of generative language model quality and usefulness addresses high-level quality criteria through a set of open-ended shared tasks implemented, where possible, to leverage the ability of systems built on \u2026"}, {"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}]
