[{"title": "Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function", "link": "https://arxiv.org/pdf/2502.03591", "details": "M Asadi, K Sodok\u00e9, IJ Gerard, M Kersten-Oertel - arXiv preprint arXiv:2502.03591, 2025", "abstract": "In this work, we present a novel approach to multi-label chest X-ray (CXR) image classification that enhances clinical interpretability while maintaining a streamlined, single-model, single-run training pipeline. Leveraging the CheXpert dataset and \u2026"}, {"title": "Weakly supervised multi-modal contrastive learning framework for predicting the HER2 scores in breast cancer", "link": "https://www.sciencedirect.com/science/article/pii/S0895611125000114", "details": "J Shi, D Sun, Z Jiang, J Du, W Wang, Y Zheng, H Wu - Computerized Medical Imaging \u2026, 2025", "abstract": "Human epidermal growth factor receptor 2 (HER2) is an important biomarker for prognosis and prediction of treatment response in breast cancer (BC). HER2 scoring is typically evaluated by pathologist microscopic observation on \u2026"}, {"title": "Semantic-aware contrastive learning via multi-prompt alignment", "link": "https://link.springer.com/article/10.1007/s10994-024-06665-1", "details": "Z Zhao, H Qin, M Kong, L Chen, D Xie, J Zhu, Q Zhu - Machine Learning, 2025", "abstract": "The role of the sample generation mechanism in contrastive learning is pivotal. It not only determines the pairings of positive and negative samples but also enriches the diversity of the sample pool, thereby substantially affecting the quality of the learned \u2026"}, {"title": "MM-Retinal V2: Transfer an Elite Knowledge Spark into Fundus Vision-Language Pretraining", "link": "https://arxiv.org/pdf/2501.15798", "details": "R Wu, N Su, C Zhang, T Ma, T Zhou, Z Cui, N Tang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language pretraining (VLP) has been investigated to generalize across diverse downstream tasks for fundus image analysis. Although recent methods showcase promising achievements, they significantly rely on large-scale private \u2026"}, {"title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "link": "https://arxiv.org/pdf/2501.12266", "details": "C Patr\u00edcio, I Rio-Torto, JS Cardoso, LF Teixeira\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The main challenges limiting the adoption of deep learning-based solutions in medical workflows are the availability of annotated data and the lack of interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the latter \u2026"}, {"title": "Are Traditional Deep Learning Model Approaches as Effective as a Retinal-Specific Foundation Model for Ocular and Systemic Disease Detection?", "link": "https://arxiv.org/pdf/2501.12016", "details": "SME Yew, X Lei, JHL Goh, Y Chen, S Srinivasan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Background: RETFound, a self-supervised, retina-specific foundation model (FM), showed potential in downstream applications. However, its comparative performance with traditional deep learning (DL) models remains incompletely understood. This \u2026"}, {"title": "Focus Your Attention: Multiple Instance Learning with Attention Modification for Whole Slide Pathological Image Classification", "link": "https://ieeexplore.ieee.org/iel8/76/4358651/10838539.pdf", "details": "H Cheng, S Huang, L Cai, Y Xu, R Wang, Y Zhang - IEEE Transactions on Circuits \u2026, 2025", "abstract": "Computer-aided pathology diagnosis based on whole slide images, which is often formulated as a weakly supervised multiple instance learning (MIL) paradigm. Current approaches generally employ attention mechanisms to aggregate instance \u2026"}, {"title": "Fine-grained medical image out-of-distribution detection through multi-view feature uncertainty and adversarial sample generation", "link": "https://www.sciencedirect.com/science/article/pii/S0031320325000615", "details": "J Wei, G Wang, S Zhang - Pattern Recognition, 2025", "abstract": "Abstract Out-Of-Distribution (OOD) detection is important for reliable deployment of medical image classifiers but challenging considering the fine-grained distinction between in-distribution and OOD samples. Existing medical image OOD detection \u2026"}, {"title": "Valley2: Exploring Multimodal Models with Scalable Vision-Language Design", "link": "https://arxiv.org/pdf/2501.05901", "details": "Z Wu, Z Chen, R Luo, C Zhang, Y Gao, Z He, X Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, vision-language models have made remarkable progress, demonstrating outstanding capabilities in various tasks such as image captioning and video understanding. We introduce Valley2, a novel multimodal large language model \u2026"}]
