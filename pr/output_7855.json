[{"title": "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models", "link": "https://arxiv.org/pdf/2410.12011", "details": "K Tatariya, V Araujo, T Bauwens, M de Lhoneux - arXiv preprint arXiv:2410.12011, 2024", "abstract": "Pixel-based language models have emerged as a compelling alternative to subword- based language modelling, particularly because they can represent virtually any script. PIXEL, a canonical example of such a model, is a vision transformer that has \u2026"}, {"title": "SeRA: Self-Reviewing and Alignment of Large Language Models using Implicit Reward Margins", "link": "https://arxiv.org/pdf/2410.09362", "details": "J Ko, S Dingliwal, B Ganesh, S Sengupta, S Bodapati\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Direct alignment algorithms (DAAs), such as direct preference optimization (DPO), have become popular alternatives for Reinforcement Learning from Human Feedback (RLHF) due to their simplicity, efficiency, and stability. However, the \u2026"}, {"title": "Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Generator-Validator Fine-tuning", "link": "https://arxiv.org/pdf/2410.12164", "details": "J Xing, Y He, M Zhou, H Dong, S Han, D Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this work, we propose Table-LLM-Specialist, or Table-Specialist for short, as a new self-trained fine-tuning paradigm specifically designed for table tasks. Our insight is that for each table task, there often exist two dual versions of the same task, one \u2026"}, {"title": "Inference-Time Language Model Alignment via Integrated Value Guidance", "link": "https://arxiv.org/pdf/2409.17819%3F", "details": "Z Liu, Z Zhou, Y Wang, C Yang, Y Qiao - arXiv preprint arXiv:2409.17819, 2024", "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce $\\textit {Integrated Value Guidance} $(IVG), a method that uses implicit and \u2026"}, {"title": "Self-Data Distillation for Recovering Quality in Pruned Large Language Models", "link": "https://arxiv.org/pdf/2410.09982", "details": "V Thangarasa, G Venkatesh, N Sinnadurai, S Lie - arXiv preprint arXiv:2410.09982, 2024", "abstract": "Large language models have driven significant progress in natural language processing, but their deployment requires substantial compute and memory resources. As models scale, compression techniques become essential for \u2026"}, {"title": "Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs", "link": "https://arxiv.org/pdf/2410.10739", "details": "I Jindal, C Badrinath, P Bharti, L Vinay, SD Sharma - arXiv preprint arXiv:2410.10739, 2024", "abstract": "Large Language Models (LLMs) for public use require continuous pre-training to remain up-to-date with the latest data. The models also need to be fine-tuned with specific instructions to maintain their ability to follow instructions accurately. Typically \u2026"}, {"title": "Safety-Aware Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2410.10014", "details": "HK Choi, X Du, Y Li - arXiv preprint arXiv:2410.10014, 2024", "abstract": "Fine-tuning Large Language Models (LLMs) has emerged as a common practice for tailoring models to individual needs and preferences. The choice of datasets for fine- tuning can be diverse, introducing safety concerns regarding the potential inclusion \u2026"}, {"title": "Negative-Prompt-driven Alignment for Generative Language Model", "link": "https://arxiv.org/pdf/2410.12194", "details": "S Qiao, N Xv, B Liu, X Geng - arXiv preprint arXiv:2410.12194, 2024", "abstract": "Large language models have achieved remarkable capabilities, but aligning their outputs with human values and preferences remains a significant challenge. Existing alignment methods primarily focus on positive examples while overlooking the \u2026"}, {"title": "Beyond Exact Match: Semantically Reassessing Event Extraction by Large Language Models", "link": "https://arxiv.org/pdf/2410.09418", "details": "YF Lu, XL Mao, T Lan, C Xu, H Huang - arXiv preprint arXiv:2410.09418, 2024", "abstract": "Event extraction has gained extensive research attention due to its broad range of applications. However, the current mainstream evaluation method for event extraction relies on token-level exact match, which misjudges numerous semantic \u2026"}]
