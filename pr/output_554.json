'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [MiniCPM: Unveiling the Potential of Small Language Mod'
[{"title": "FairPair: A Robust Evaluation of Biases in Language Models through Paired Perturbations", "link": "https://arxiv.org/pdf/2404.06619", "details": "J Dwivedi-Yu, R Dwivedi, T Schick - arXiv preprint arXiv:2404.06619, 2024", "abstract": "The accurate evaluation of differential treatment in language models to specific groups is critical to ensuring a positive and safe user experience. An ideal evaluation should have the properties of being robust, extendable to new groups or attributes \u2026"}, {"title": "A Novel Corpus of Annotated Medical Imaging Reports and Information Extraction Results Using BERT-based Language Models", "link": "https://arxiv.org/pdf/2403.18975", "details": "N Park, K Lybarger, GK Ramachandran, S Lewis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Medical imaging is critical to the diagnosis, surveillance, and treatment of many health conditions, including oncological, neurological, cardiovascular, and musculoskeletal disorders, among others. Radiologists interpret these complex \u2026"}, {"title": "Tree-of-Reasoning Question Decomposition for Complex Question Answering with Large Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29928/31621", "details": "K Zhang, J Zeng, F Meng, Y Wang, S Sun, L Bai\u2026 - Proceedings of the AAAI \u2026, 2024", "abstract": "Large language models (LLMs) have recently demonstrated remarkable performance across various natual language processing tasks. In the field of multi- hop reasoning, the Chain-of-thought (CoT) prompt method has emerged as a \u2026"}]
