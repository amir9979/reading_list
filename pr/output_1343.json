'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Phi-3 technical report: A highly capable language mode'
[{"title": "Achieving> 97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners", "link": "https://arxiv.org/pdf/2404.14963", "details": "Q Zhong, K Wang, Z Xu, J Liu, L Ding, B Du, D Tao - arXiv preprint arXiv:2404.14963, 2024", "abstract": "Chain of Thought prompting strategy has enhanced the performance of Large Language Models (LLMs) across various NLP tasks. However, it still has shortcomings when dealing with complex reasoning tasks, following~\\citet {cot_wei} \u2026"}, {"title": "SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs", "link": "https://arxiv.org/pdf/2404.13081", "details": "J Kim, J Nam, S Mo, J Park, SW Lee, M Seo, JW Ha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have made significant advancements in various natural language processing tasks, including question answering (QA) tasks. While incorporating new information with the retrieval of relevant passages is a promising \u2026"}, {"title": "Enhancing Confidence Expression in Large Language Models Through Learning from Past Experience", "link": "https://arxiv.org/pdf/2404.10315", "details": "H Han, T Li, S Chen, J Shi, C Du, Y Xiao, J Liang, X Lin - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have exhibited remarkable performance across various downstream tasks, but they may generate inaccurate or false information with a confident tone. One of the possible solutions is to empower the LLM confidence \u2026"}, {"title": "MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems", "link": "https://arxiv.org/pdf/2404.09486", "details": "K Li, Y Tian, Q Hu, Z Luo, J Ma - arXiv preprint arXiv:2404.09486, 2024", "abstract": "Programming often involves converting detailed and complex specifications into code, a process during which developers typically utilize visual aids to more effectively convey concepts. While recent developments in Large Multimodal Models \u2026"}, {"title": "LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet?): A Comprehensive Evaluation, Framework, and Benchmarks", "link": "https://seclab.bu.edu/people/gianluca/papers/llm-oakland2024.pdf", "details": "S Ullah, M Han, S Pujar, H Pearce, A Coskun\u2026 - 2024 IEEE Symposium on \u2026, 2024", "abstract": "Large Language Models (LLMs) have been suggested for use in automated vulnerability repair, but benchmarks showing they can consistently identify security- related bugs are lacking. We thus develop SecLLMHolmes, a fully automated \u2026"}, {"title": "Retrieval Augmented Generation for Domain-specific Question Answering", "link": "https://arxiv.org/pdf/2404.14760", "details": "S Sharma, DS Yoon, F Dernoncourt, D Sultania\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Question answering (QA) has become an important application in the advanced development of large language models. General pre-trained large language models for question-answering are not trained to properly understand the knowledge or \u2026"}, {"title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation", "link": "https://arxiv.org/pdf/2404.11216", "details": "Z He, H Jiang, Z Wang, Y Yang, L Qiu, L Qiu - arXiv preprint arXiv:2404.11216, 2024", "abstract": "The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task \u2026"}, {"title": "On the Empirical Complexity of Reasoning and Planning in LLMs", "link": "https://arxiv.org/pdf/2404.11041", "details": "L Kang, Z Zhao, D Hsu, WS Lee - arXiv preprint arXiv:2404.11041, 2024", "abstract": "Large Language Models (LLMs) work surprisingly well for some complex reasoning problems via chain-of-thought (CoT) or tree-of-thought (ToT), but the underlying reasons remain unclear. We seek to understand the performance of these methods \u2026"}, {"title": "AlpaPICO: Extraction of PICO Frames from Clinical Trial Documents Using LLMs", "link": "https://www.sciencedirect.com/science/article/pii/S1046202324000896", "details": "M Ghosh, S Mukherjee, A Ganguly, P Basuchowdhuri\u2026 - Methods, 2024", "abstract": "In recent years, there has been a surge in the publication of clinical trial reports, making it challenging to conduct systematic reviews. Automatically extracting Population, Intervention, Comparator, and Outcome (PICO) from clinical trial studies \u2026"}]
