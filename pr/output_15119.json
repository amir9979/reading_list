[{"title": "MLLM-Selector: Necessity and Diversity-driven High-Value Data Selection for Enhanced Visual Instruction Tuning", "link": "https://arxiv.org/pdf/2503.20502%3F", "details": "Y Ma, G Xu, X Sun, J Ji, J Lou, D Zhang, R Ji - arXiv preprint arXiv:2503.20502, 2025", "abstract": "Visual instruction tuning (VIT) has emerged as a crucial technique for enabling multi- modal large language models (MLLMs) to follow user instructions adeptly. Yet, a significant gap persists in understanding the attributes of high-quality instruction \u2026"}, {"title": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "link": "https://arxiv.org/pdf/2504.07416", "details": "J Park, S Kim, B Yoon, K Choi - arXiv preprint arXiv:2504.07416, 2025", "abstract": "Recent advancements in multi-modal models have significantly improved vision- language alignment in radiology. However, existing approaches struggle to effectively utilize complex radiology reports for learning, rely on low-resolution \u2026"}, {"title": "Can Language Models Follow Multiple Turns of Entangled Instructions?", "link": "https://arxiv.org/pdf/2503.13222%3F", "details": "C Han - arXiv preprint arXiv:2503.13222, 2025", "abstract": "Despite significant achievements in improving the instruction-following capabilities of large language models (LLMs), the ability to process multiple potentially entangled or conflicting instructions remains a considerable challenge. Real-world scenarios \u2026"}, {"title": "Vision-Language Adaptive Clustering and Meta-Adaptation for Unsupervised Few-Shot Action Recognition", "link": "https://ieeexplore.ieee.org/abstract/document/10960322/", "details": "J Chen, J Peng, Y Lu, JH Lai, AJ Ma - IEEE Transactions on Circuits and Systems for \u2026, 2025", "abstract": "Unsupervised few-shot action recognition is a practical but challenging task, which adapts knowledge learned from unlabeled videos to novel action classes with only limited labeled data. Without annotated data of base action classes for meta \u2026"}, {"title": "Unsupervised Deep Learning of Electronic Health Records to Characterize Heterogeneity Across Alzheimer Disease and Related Dementias: Cross-Sectional Study", "link": "https://aging.jmir.org/2025/1/e65178/", "details": "M West, Y Cheng, Y He, Y Leng, C Magdamo\u2026 - JMIR aging, 2025", "abstract": "Background: Alzheimer disease and related dementias (ADRD) exhibit prominent heterogeneity. Identifying clinically meaningful ADRD subtypes is essential for tailoring treatments to specific patient phenotypes. Objective: We aimed to use \u2026"}, {"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2504.00869%3F", "details": "X Huang, J Wu, H Liu, X Tang, Y Zhou - arXiv preprint arXiv:2504.00869, 2025", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from \u2026"}, {"title": "GPBench: A Comprehensive and Fine-Grained Benchmark for Evaluating Large Language Models as General Practitioners", "link": "https://arxiv.org/pdf/2503.17599", "details": "Z Li, Y Yang, J Lang, W Jiang, Y Zhao, S Li, D Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "General practitioners (GPs) serve as the cornerstone of primary healthcare systems by providing continuous and comprehensive medical services. However, due to community-oriented nature of their practice, uneven training and resource gaps, the \u2026"}]
