[{"title": "ARC: A Layer Replacement Compression Method Based on Fine-Grained Self-Attention Distillation for Compressing Pre-Trained Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10663832/", "details": "D Yu, L Qiu - IEEE Transactions on Emerging Topics in \u2026, 2024", "abstract": "The primary objective of model compression is to maintain the performance of the original model while reducing its size as much as possible. Knowledge distillation has become the mainstream method in the field of model compression due to its \u2026"}, {"title": "MobileQuant: Mobile-friendly Quantization for On-device Language Models", "link": "https://arxiv.org/pdf/2408.13933", "details": "F Tan, R Lee, \u0141 Dudziak, SX Hu, S Bhattacharya\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have revolutionized language processing, delivering outstanding results across multiple applications. However, deploying LLMs on edge devices poses several challenges with respect to memory, energy, and compute \u2026"}, {"title": "ContextVLM: Zero-Shot and Few-Shot Context Understanding for Autonomous Driving using Vision Language Models", "link": "https://arxiv.org/pdf/2409.00301", "details": "S Sural, R Rajkumar - arXiv preprint arXiv:2409.00301, 2024", "abstract": "In recent years, there has been a notable increase in the development of autonomous vehicle (AV) technologies aimed at improving safety in transportation systems. While AVs have been deployed in the real-world to some extent, a full-scale \u2026"}, {"title": "The Impact of Collaborative Documentation on Person-Centered Care: Textual Analysis of Clinical Notes", "link": "https://medinform.jmir.org/2024/1/e52678", "details": "V Stanhope, N Yoo, E Matthews, D Baslock, Y Hu - JMIR Medical Informatics, 2024", "abstract": "Background Collaborative documentation (CD) is a behavioral health practice involving shared writing of clinic visit notes by providers and consumers. Despite widespread dissemination of CD, research on its effectiveness or impact on person \u2026"}, {"title": "Designing Retrieval-Augmented Language Models for Clinical Decision", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DWcMbEQAAQBAJ%26oi%3Dfnd%26pg%3DPA159%26ots%3DtCwYsZVKft%26sig%3Dig4kwzLfqMDCKpa3AgV2qDed60Q", "details": "K Quigley, T Koker, J Taylor, V Mancuso - AI for Health Equity and Fairness: Leveraging AI to \u2026", "abstract": "Ever-increasing demands for physician expertise drive the need for trust-worthy point- of-care tools that can help aid decision-making in all clinical settings. Retrieval- augmented language models carry potential to relieve the information burden on \u2026"}, {"title": "Efficient Fine-Tuning for Low-Resource Tibetan Pre-trained Language Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-72350-6_28", "details": "M Zhou, Z Daiqing, N Qun, T Nyima - International Conference on Artificial Neural \u2026, 2024", "abstract": "For low-resource languages like Tibetan, the availability of pre-trained language models (PLMs) is severely limited both in quantity and performance. Therefore, it is crucial to explore the optimization of these limited PLMs. In this paper, leveraging the \u2026"}, {"title": "Reasoning and Planning with Large Language Models in Code Development", "link": "https://dl.acm.org/doi/pdf/10.1145/3637528.3671452", "details": "H Ding, Z Fan, I Guehring, G Gupta, W Ha, J Huan\u2026 - Proceedings of the 30th \u2026, 2024", "abstract": "Large Language Models (LLMs) are revolutionizing the field of code development by leveraging their deep understanding of code patterns, syntax, and semantics to assist developers in various tasks, from code generation and testing to code \u2026"}, {"title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks", "link": "https://arxiv.org/pdf/2409.03381", "details": "Y Deng, X Qiu, X Tan, C Qu, J Pan, Y Cheng, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Cognitive psychology investigates perception, attention, memory, language, problem- solving, decision-making, and reasoning. Kahneman's dual-system theory elucidates the human decision-making process, distinguishing between the rapid, intuitive \u2026"}, {"title": "Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models", "link": "https://arxiv.org/pdf/2408.15915", "details": "Y Yang, Y Qin, T Wu, Z Xu, G Li, P Guo, H Shao, Y Shi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The cultivation of expertise for large language models (LLMs) to solve tasks of specific areas often requires special-purpose tuning with calibrated behaviors on the expected stable outputs. To avoid huge cost brought by manual preparation of \u2026"}]
