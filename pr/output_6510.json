[{"title": "CLIP-DPO: Vision-Language Models as a Source of Preference for Fixing Hallucinations in LVLMs", "link": "https://arxiv.org/pdf/2408.10433", "details": "Y Ouali, A Bulat, B Martinez, G Tzimiropoulos - arXiv preprint arXiv:2408.10433, 2024", "abstract": "Despite recent successes, LVLMs or Large Vision Language Models are prone to hallucinating details like objects and their properties or relations, limiting their real- world deployment. To address this and improve their robustness, we present CLIP \u2026"}, {"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "CoDi: Conversational Distillation for Grounded Question Answering", "link": "https://arxiv.org/pdf/2408.11219", "details": "P Huber, A Einolghozati, R Conway, K Narang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Distilling conversational skills into Small Language Models (SLMs) with approximately 1 billion parameters presents significant challenges. Firstly, SLMs have limited capacity in their model parameters to learn extensive knowledge \u2026"}, {"title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection", "link": "https://arxiv.org/pdf/2409.06072", "details": "J Chakraborty, W Xia, A Majumder, D Ma, W Chaabene\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks. However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further \u2026"}, {"title": "DCMSL: Dual influenced community strength-boosted multi-scale graph contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124011067", "details": "H Chen, Y Li, SY Philip, Y Zou, R Li - Knowledge-Based Systems, 2024", "abstract": "Abstract Graph Contrastive Learning (GCL) effectively mitigates label dependency, defining positive and negative pairs for node embeddings. Nevertheless, most GCL methods, including those considering communities, overlooking the simultaneous \u2026"}, {"title": "Towards Harnessing Large Language Models as Autonomous Agents for Semantic Triple Extraction from Unstructured Text", "link": "https://ceur-ws.org/Vol-3747/text2kg_paper1.pdf", "details": "A Ananya, S Tiwari, N Mihindukulasooriya, T Soru\u2026 - 2024", "abstract": "Abstract The use of Large Language Models as autonomous agents interacting with tools has shown to improve the performance of several tasks from code generation to API calling and sequencing. This paper proposes a framework for using Large \u2026"}, {"title": "E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning", "link": "https://arxiv.org/pdf/2409.06679", "details": "Z Liao, J Wang, H Yu, L Wei, J Li, W Zhang - arXiv preprint arXiv:2409.06679, 2024", "abstract": "In the realm of Large Language Models (LLMs), the ability to process long contexts is increasingly crucial for tasks such as multi-round dialogues, code generation, and document summarization. This paper addresses the challenges of enhancing the \u2026"}, {"title": "Few-shot Multilingual Open-domain QA from 5 Examples", "link": "https://fantabulous-j.github.io/files/TACL__Few_shot_Multilingual_Open_domain_QA_from_5_Examples.pdf", "details": "F Jiang, T Drummond, T Cohn", "abstract": "Recent approaches to multilingual opendomain question answering (MLODQA) have achieved promising results given abundant language-specific training data. However, the considerable annotation cost limits the probability of these methods for \u2026"}]
