[{"title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities", "link": "https://arxiv.org/pdf/2502.12025%3F", "details": "F Jiang, Z Xu, Y Li, L Niu, Z Xiang, B Li, BY Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage long chain-of-thought (CoT) reasoning to generate structured intermediate steps, enhancing their reasoning capabilities. However, long CoT does not inherently \u2026"}, {"title": "Multidimensional Consistency Improves Reasoning in Language Models", "link": "https://arxiv.org/pdf/2503.02670", "details": "H Lai, X Zhang, M Nissim - arXiv preprint arXiv:2503.02670, 2025", "abstract": "While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across \u2026"}, {"title": "Systems and Algorithms for Convolutional Multi-Hybrid Language Models at Scale", "link": "https://arxiv.org/pdf/2503.01868", "details": "J Ku, E Nguyen, DW Romero, G Brixi, B Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce convolutional multi-hybrid architectures, with a design grounded on two simple observations. First, operators in hybrid models can be tailored to token manipulation tasks such as in-context recall, multi-token recall, and compression \u2026"}, {"title": "AnyEdit: Edit Any Knowledge Encoded in Language Models", "link": "https://arxiv.org/pdf/2502.05628", "details": "H Jiang, J Fang, N Zhang, G Ma, M Wan, X Wang, X He\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) often produce incorrect or outdated information, necessitating efficient and precise knowledge updates. Current model editing methods, however, struggle with long-form knowledge in diverse formats, such as \u2026"}, {"title": "Do we really have to filter out random noise in pre-training data for language models?", "link": "https://arxiv.org/pdf/2502.06604", "details": "J Ru, Y Xie, X Zhuang, Y Yin, Y Zou - arXiv preprint arXiv:2502.06604, 2025", "abstract": "Web-scale pre-training datasets are the cornerstone of LLMs' success. However, text data curated from the internet inevitably contains random noise caused by decoding errors or unregulated web content. In contrast to previous works that focus on low \u2026"}, {"title": "Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2502.08922", "details": "X Zhou, Y Guo, R Ma, T Gui, Q Zhang, X Huang - arXiv preprint arXiv:2502.08922, 2025", "abstract": "Aligning Large Language Models (LLMs) with human preferences is crucial for their deployment in real-world applications. Recent advancements in Self-Rewarding Language Models suggest that an LLM can use its internal reward models (such as \u2026"}, {"title": "Audio-Reasoner: Improving Reasoning Capability in Large Audio Language Models", "link": "https://arxiv.org/pdf/2503.02318", "details": "Z Xie, M Lin, Z Liu, P Wu, S Yan, C Miao - arXiv preprint arXiv:2503.02318, 2025", "abstract": "Recent advancements in multimodal reasoning have largely overlooked the audio modality. We introduce Audio-Reasoner, a large-scale audio language model for deep reasoning in audio tasks. We meticulously curated a large-scale and diverse \u2026"}, {"title": "LLM Compiler: Foundation Language Models for Compiler Optimization", "link": "https://dl.acm.org/doi/pdf/10.1145/3708493.3712691", "details": "C Cummins, V Seeker, D Grubisic, B Roziere\u2026 - Proceedings of the 34th \u2026, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a variety of software engineering and coding tasks. However, their application in the domain of code and compiler optimization remains underexplored. Training LLMs is \u2026"}, {"title": "Words or Vision: Do Vision-Language Models Have Blind Faith in Text?", "link": "https://arxiv.org/pdf/2503.02199", "details": "A Deng, T Cao, Z Chen, B Hooi - arXiv preprint arXiv:2503.02199, 2025", "abstract": "Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual \u2026"}]
