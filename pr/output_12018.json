[{"title": "Boosting Multimodal LLMs via Visual Token Supervision", "link": "https://zpbao.github.io/files/vlm.pdf", "details": "Z Bao, M Liu, A Ramchandani, M Wang, F Juefei-Xu\u2026", "abstract": "Multimodal large language models (MLLMs) have shown impressive performance on tasks requiring integrated visual and textual understanding. A key factor in their success is the model's ability to accurately recognize and understand visual \u2026"}, {"title": "Embedding-Driven Diversity Sampling to Improve Few-Shot Synthetic Data Generation", "link": "https://arxiv.org/pdf/2501.11199", "details": "I Lopez, FN Haredasht, K Caoili, JH Chen, A Chaudhari - arXiv preprint arXiv \u2026, 2025", "abstract": "Accurate classification of clinical text often requires fine-tuning pre-trained language models, a process that is costly and time-consuming due to the need for high-quality data and expert annotators. Synthetic data generation offers an alternative, though \u2026"}, {"title": "ChartAdapter: Large Vision-Language Model for Chart Summarization", "link": "https://arxiv.org/pdf/2412.20715", "details": "P Xu, Y Ding, W Fan - arXiv preprint arXiv:2412.20715, 2024", "abstract": "Chart summarization, which focuses on extracting key information from charts and interpreting it in natural language, is crucial for generating and delivering insights through effective and accessible data analysis. Traditional methods for chart \u2026"}]
