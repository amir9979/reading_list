[{"title": "Large Language Models Prompting With Episodic Memory", "link": "https://arxiv.org/pdf/2408.07465", "details": "D Do, Q Tran, S Venkatesh, H Le - arXiv preprint arXiv:2408.07465, 2024", "abstract": "Prompt optimization is essential for enhancing the performance of Large Language Models (LLMs) in a range of Natural Language Processing (NLP) tasks, particularly in scenarios of few-shot learning where training examples are incorporated directly \u2026"}, {"title": "Relation labeling in product knowledge graphs with large language models for e-commerce", "link": "https://link.springer.com/article/10.1007/s13042-024-02274-5", "details": "J Chen, L Ma, X Li, J Xu, JHD Cho, K Nag, E Korpeoglu\u2026 - International Journal of \u2026, 2024", "abstract": "Abstract Product Knowledge Graphs (PKGs) play a crucial role in enhancing e- commerce system performance by providing structured information about entities and their relationships, such as complementary or substitutable relations between \u2026"}, {"title": "Mitigating Privacy Seesaw in Large Language Models: Augmented Privacy Neuron Editing via Activation Patching", "link": "https://aclanthology.org/2024.findings-acl.315.pdf", "details": "X Wu, W Dong, S Xu, D Xiong - Findings of the Association for Computational \u2026, 2024", "abstract": "Protecting privacy leakage in large language models remains a paramount challenge. In this paper, we reveal Privacy Seesaw in LLM privacy safeguarding, a phenomenon where measures to secure specific private information inadvertently \u2026"}, {"title": "Adversarial preference optimization: Enhancing your alignment via rm-llm game", "link": "https://aclanthology.org/2024.findings-acl.221.pdf", "details": "P Cheng, Y Yang, J Li, Y Dai, T Hu, P Cao, N Du, X Li - Findings of the Association for \u2026, 2024", "abstract": "Human preference alignment is essential to improve the interaction quality of large language models (LLMs). Existing alignment methods depend on manually annotated preference data to guide the LLM optimization directions. However \u2026"}, {"title": "Self-Para-Consistency: Improving Reasoning Tasks at Low Cost for Large Language Models", "link": "https://aclanthology.org/2024.findings-acl.842.pdf", "details": "W Chen, W Wang, Z Chu, K Ren, Z Zheng, Z Lu - Findings of the Association for \u2026, 2024", "abstract": "Recently, the self-consistency decoding strategy has shown the ability to improve performance for complex reasoning tasks with large language models (LLMs). However, the costs may be high because the sampling process of the strategy \u2026"}, {"title": "SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models", "link": "https://arxiv.org/pdf/2408.08545", "details": "KK Maurya, KV Srivatsa, E Kochmar - arXiv preprint arXiv:2408.08545, 2024", "abstract": "Large language models (LLMs) have gained increased popularity due to their remarkable success across various tasks, which has led to the active development of a large set of diverse LLMs. However, individual LLMs have limitations when applied \u2026"}, {"title": "MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing", "link": "https://arxiv.org/pdf/2408.11396", "details": "H Zhou, Z Wang, S Huang, X Huang, X Han, J Feng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) are often English-centric due to the disproportionate distribution of languages in their pre-training data. Enhancing non-English language capabilities through post-pretraining often results in catastrophic forgetting of the \u2026"}, {"title": "EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models", "link": "https://arxiv.org/pdf/2408.11308", "details": "C Zhao, Z Dou, K Huang - arXiv preprint arXiv:2408.11308, 2024", "abstract": "Large Language Models (LLMs) are increasingly attracting attention in various applications. Nonetheless, there is a growing concern as some users attempt to exploit these models for malicious purposes, including the synthesis of controlled \u2026"}, {"title": "Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer", "link": "https://arxiv.org/pdf/2408.11313", "details": "W Jiang, Z Wang, J Zhai, S Ma, Z Zhao, C Shen - arXiv preprint arXiv:2408.11313, 2024", "abstract": "Despite prior safety alignment efforts, mainstream LLMs can still generate harmful and unethical content when subjected to jailbreaking attacks. Existing jailbreaking methods fall into two main categories: template-based and optimization-based \u2026"}]
