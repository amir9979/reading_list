[{"title": "Making Language Models Robust Against Negation", "link": "https://arxiv.org/pdf/2502.07717", "details": "MH Rezaei, E Blanco - arXiv preprint arXiv:2502.07717, 2025", "abstract": "Negation has been a long-standing challenge for language models. Previous studies have shown that they struggle with negation in many natural language understanding tasks. In this work, we propose a self-supervised method to make \u2026"}, {"title": "MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification", "link": "https://arxiv.org/pdf/2502.07409", "details": "AT Nguyen, DMH Nguyen, NT Diep, TQ Nguyen, N Ho\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Whole slide pathology image classification presents challenges due to gigapixel image sizes and limited annotation labels, hindering model generalization. This paper introduces a prompt learning method to adapt large vision-language models \u2026"}, {"title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "link": "https://arxiv.org/pdf/2502.06589", "details": "Y Zhuang, J Yang, H Jiang, X Liu, K Cheng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous agents typically rely on complex prompting or extensive fine-tuning, which often fails to introduce new capabilities while preserving strong generalizability. We introduce \u2026"}, {"title": "Auditing Prompt Caching in Language Model APIs", "link": "https://arxiv.org/pdf/2502.07776", "details": "C Gu, XL Li, R Kuditipudi, P Liang, T Hashimoto - arXiv preprint arXiv:2502.07776, 2025", "abstract": "Prompt caching in large language models (LLMs) results in data-dependent timing variations: cached prompts are processed faster than non-cached prompts. These timing differences introduce the risk of side-channel timing attacks. For example, if \u2026"}, {"title": "A multimodal multidomain multilingual medical foundation model for zero shot clinical diagnosis", "link": "https://www.nature.com/articles/s41746-024-01339-7", "details": "F Liu, Z Li, Q Yin, J Huang, J Luo, A Thakur, K Branson\u2026 - npj Digital Medicine, 2025", "abstract": "Radiology images are one of the most commonly used in daily clinical diagnosis. Typically, clinical diagnosis using radiology images involves disease reporting and classification, where the former is a multimodal task whereby textual reports are \u2026"}, {"title": "IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large Language Models", "link": "https://arxiv.org/pdf/2502.07072", "details": "SM Imtiaz, A Singh, F Batole, H Rajan - arXiv preprint arXiv:2502.07072, 2025", "abstract": "Not a day goes by without hearing about the impressive feats of large language models (LLMs), and equally, not a day passes without hearing about their challenges. LLMs are notoriously vulnerable to biases in their dataset, leading to \u2026"}, {"title": "MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning", "link": "https://arxiv.org/pdf/2501.14105", "details": "J Davis, T Sounack, K Sciacca, JM Brain, BN Durieux\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Extracting sections from clinical notes is crucial for downstream analysis but is challenging due to variability in formatting and labor-intensive nature of manual sectioning. While proprietary large language models (LLMs) have shown promise \u2026"}]
