[{"title": "Do we really have to filter out random noise in pre-training data for language models?", "link": "https://arxiv.org/pdf/2502.06604", "details": "J Ru, Y Xie, X Zhuang, Y Yin, Y Zou - arXiv preprint arXiv:2502.06604, 2025", "abstract": "Web-scale pre-training datasets are the cornerstone of LLMs' success. However, text data curated from the internet inevitably contains random noise caused by decoding errors or unregulated web content. In contrast to previous works that focus on low \u2026"}]
