[{"title": "Parrot: Enhancing Multi-Turn Instruction Following for Large Language Models", "link": "https://aclanthology.org/2024.acl-long.525.pdf", "details": "Y Sun, C Liu, K Zhou, J Huang, R Song, WX Zhao\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Humans often interact with large language models (LLMs) in multi-turn interaction to obtain desired answers or more information. However, most existing studies overlook the multi-turn instruction following ability of LLMs, in terms of training dataset, training \u2026"}, {"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "WatME: Towards Lossless Watermarking Through Lexical Redundancy", "link": "https://aclanthology.org/2024.acl-long.496.pdf", "details": "L Chen, Y Bian, Y Deng, D Cai, S Li, P Zhao, KF Wong - Proceedings of the 62nd \u2026, 2024", "abstract": "Text watermarking has emerged as a pivotal technique for identifying machine- generated text. However, existing methods often rely on arbitrary vocabulary partitioning during decoding to embed watermarks, which compromises the \u2026"}, {"title": "Fine-Tuning Pre-Trained Language Models with Gaze Supervision", "link": "https://aclanthology.org/2024.acl-short.21.pdf", "details": "S Deng, P Prasse, D Reich, T Scheffer, L J\u00e4ger - \u2026 of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Human gaze data provide cognitive information that reflect human language comprehension and has been effectively integrated into a variety of natural language processing (NLP) tasks, demonstrating improved performance over corresponding \u2026"}, {"title": "Rescue: Ranking llm responses with partial ordering to improve response generation", "link": "https://aclanthology.org/2024.acl-srw.32.pdf", "details": "Y Wang, R Zheng, H Li, Q Zhang, T Gui, F Liu - \u2026 of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Customizing LLMs for a specific task involves separating high-quality responses from lower-quality ones. This skill can be developed using supervised fine-tuning with extensive human preference data. However, obtaining a large volume of expert \u2026"}, {"title": "T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step", "link": "https://aclanthology.org/2024.acl-long.515.pdf", "details": "Z Chen, W Du, W Zhang, K Liu, J Liu, M Zheng, J Zhuo\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Large language models (LLMs) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool utilization capability of LLMs is still under-explored. In contrast \u2026"}, {"title": "On the Vulnerability of Safety Alignment in Open-Access LLMs", "link": "https://aclanthology.org/2024.findings-acl.549.pdf", "details": "J Yi, R Ye, Q Chen, B Zhu, S Chen, D Lian, G Sun\u2026 - Findings of the Association \u2026, 2024", "abstract": "Large language models (LLMs) possess immense capabilities but are susceptible to malicious exploitation. To mitigate the risk, safety alignment is employed to align LLMs with ethical standards. However, safety-aligned LLMs may remain vulnerable \u2026"}, {"title": "BEnQA: A Question Answering Benchmark for Bengali and English", "link": "https://aclanthology.org/2024.findings-acl.68.pdf", "details": "S Shafayat, H Hasan, M Mahim, R Putri, J Thorne, A Oh - Findings of the Association \u2026, 2024", "abstract": "In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with \u2026"}, {"title": "Demystifying Instruction Mixing for Fine-tuning Large Language Models", "link": "https://aclanthology.org/2024.acl-srw.15.pdf", "details": "R Wang, H Li, M Wu, Y Wang, X Han, C Zhang\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study \u2026"}]
