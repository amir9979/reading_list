[{"title": "Identifying and Mitigating Social Bias Knowledge in Language Models", "link": "https://aclanthology.org/2025.findings-naacl.39.pdf", "details": "R Chen, Y Li, J Yang, Y Feng, JT Zhou, J Wu, Z Liu - Findings of the Association for \u2026, 2025", "abstract": "Generating fair and accurate predictions plays a pivotal role in deploying pre-trained language models (PLMs) in the real world. However, existing debiasing methods may inevitably generate incorrect or nonsensical predictions as they are designed \u2026"}, {"title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "link": "https://arxiv.org/pdf/2504.06260", "details": "N Mudur, H Cui, S Venugopalan, P Raccuglia\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Building precise simulations of the real world and invoking numerical solvers to answer quantitative problems is an essential requirement in engineering and science. We present FEABench, a benchmark to evaluate the ability of large \u2026"}, {"title": "AI Alignment in Medical Imaging: Unveiling Hidden Biases Through Counterfactual Analysis", "link": "https://arxiv.org/pdf/2504.19621", "details": "H Ma, F Quinzan, T Willem, S Bauer - arXiv preprint arXiv:2504.19621, 2025", "abstract": "Machine learning (ML) systems for medical imaging have demonstrated remarkable diagnostic capabilities, but their susceptibility to biases poses significant risks, since biases may negatively impact generalization performance. In this paper, we \u2026"}, {"title": "Argumentative Large Language Models for Explainable and Contestable Claim Verification", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/33637/35792", "details": "G Freedman, A Dejl, D Gorur, X Yin, A Rago, F Toni - Proceedings of the AAAI \u2026, 2025", "abstract": "The profusion of knowledge encoded in large language models (LLMs) and their ability to apply this knowledge zero-shot in a range of settings makes them promising candidates for use in decision-making. However, they are currently limited by their \u2026"}, {"title": "Overcoming Heterogeneous Data in Federated Medical Vision-Language Pre-training: A Triple-Embedding Model Selector Approach", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32807/34962", "details": "A Wang, Z Zhang, D Wang, F Wang, H Hu, J Guo\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "The scarcity data of medical field brings the collaborative training in medical vision- language pre-training (VLP) cross different clients. Therefore, the collaborative training in medical VLP faces two challenges: First, the medical data requires \u2026"}, {"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2504.00869%3F", "details": "X Huang, J Wu, H Liu, X Tang, Y Zhou - arXiv preprint arXiv:2504.00869, 2025", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from \u2026"}, {"title": "SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning", "link": "https://arxiv.org/pdf/2504.19162", "details": "J Chen, B Zhang, R Ma, P Wang, X Liang, Z Tu, X Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Evaluating the step-by-step reliability of large language model (LLM) reasoning, such as Chain-of-Thought, remains challenging due to the difficulty and cost of obtaining high-quality step-level supervision. In this paper, we introduce Self-Play \u2026"}, {"title": "ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection", "link": "https://arxiv.org/pdf/2504.00695", "details": "X Zhu, Z Gu, S Zheng, T Wang, T Li, H Feng, Y Xiao - arXiv preprint arXiv:2504.00695, 2025", "abstract": "Pre-training large language models (LLMs) necessitates enormous diverse textual corpora, making effective data selection a key challenge for balancing computational resources and model performance. Current methodologies primarily emphasize data \u2026"}, {"title": "Fast-Slow Thinking for Large Vision-Language Model Reasoning", "link": "https://arxiv.org/pdf/2504.18458", "details": "W Xiao, L Gan, W Dai, W He, Z Huang, H Li, F Shu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in large vision-language models (LVLMs) have revealed an\\textit {overthinking} phenomenon, where models generate verbose reasoning across all tasks regardless of questions. To address this issue, we present\\textbf {FAST}, a \u2026"}]
