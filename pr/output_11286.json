[{"title": "Embedding Style Beyond Topics: Analyzing Dispersion Effects Across Different Language Models", "link": "https://arxiv.org/pdf/2501.00828", "details": "B Icard, E Zve, L Sainero, A Breton, JG Ganascia - arXiv preprint arXiv:2501.00828, 2025", "abstract": "This paper analyzes how writing style affects the dispersion of embedding vectors across multiple, state-of-the-art language models. While early transformer models primarily aligned with topic modeling, this study examines the role of writing style in \u2026"}, {"title": "How Private are Language Models in Abstractive Summarization?", "link": "https://arxiv.org/pdf/2412.12040%3F", "details": "A Hughes, N Aletras, N Ma - arXiv preprint arXiv:2412.12040, 2024", "abstract": "Language models (LMs) have shown outstanding performance in text summarization including sensitive domains such as medicine and law. In these settings, it is important that personally identifying information (PII) included in the source \u2026"}, {"title": "Cross-Lingual Text-Rich Visual Comprehension: An Information Theory Perspective", "link": "https://arxiv.org/pdf/2412.17787%3F", "details": "X Yu, X Feng, Y Li, M Liao, YQ Yu, X Feng, W Zhong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent Large Vision-Language Models (LVLMs) have shown promising reasoning capabilities on text-rich images from charts, tables, and documents. However, the abundant text within such images may increase the model's sensitivity to language \u2026"}, {"title": "Leveraging Large Vision-Language Model as User Intent-aware Encoder for Composed Image Retrieval", "link": "https://arxiv.org/pdf/2412.11087", "details": "Z Sun, D Jing, G Yang, N Fei, Z Lu - arXiv preprint arXiv:2412.11087, 2024", "abstract": "Composed Image Retrieval (CIR) aims to retrieve target images from candidate set using a hybrid-modality query consisting of a reference image and a relative caption that describes the user intent. Recent studies attempt to utilize Vision-Language Pre \u2026"}, {"title": "Unraveling Indirect In-Context Learning Using Influence Functions", "link": "https://arxiv.org/pdf/2501.01473", "details": "H Askari, S Gupta, T Tong, F Wang, A Chhabra\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This work introduces a novel paradigm for generalized In-Context Learning (ICL), termed Indirect In-Context Learning. In Indirect ICL, we explore demonstration selection strategies tailored for two distinct real-world scenarios: Mixture of Tasks \u2026"}]
