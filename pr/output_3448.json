[{"title": "GenderBias-\\emph {VL}: Benchmarking Gender Bias in Vision Language Models via Counterfactual Probing", "link": "https://arxiv.org/pdf/2407.00600", "details": "Y Xiao, A Liu, QJ Cheng, Z Yin, S Liang, J Li, J Shao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have been widely adopted in various applications; however, they exhibit significant gender biases. Existing benchmarks primarily evaluate gender bias at the demographic group level, neglecting individual \u2026"}, {"title": "Investigating the Effects of Large-Scale Pseudo-Stereo Data and Different Speech Foundation Model on Dialogue Generative Spoken Language Model", "link": "https://arxiv.org/pdf/2407.01911", "details": "YK Fu, CK Lee, HH Wang, H Lee - arXiv preprint arXiv:2407.01911, 2024", "abstract": "Recent efforts in Spoken Dialogue Modeling aim to synthesize spoken dialogue without the need for direct transcription, thereby preserving the wealth of non-textual information inherent in speech. However, this approach faces a challenge when \u2026"}, {"title": "Neural Fields for Co-Reconstructing 3D Objects from Incidental 2D Data", "link": "https://openaccess.thecvf.com/content/CVPR2024W/NRI/papers/Campbell_Neural_Fields_for_Co-Reconstructing_3D_Objects_from_Incidental_2D_Data_CVPRW_2024_paper.pdf", "details": "D Campbell, E Insafutdinov, JF Henriques, A Vedaldi - Proceedings of the IEEE/CVF \u2026, 2024", "abstract": "We ask whether 3D objects can be reconstructed from real world data collected for some other purpose such as autonomous driving or augmented reality thus inferring objects only incidentally. 3D reconstruction from incidental data is a major challenge \u2026"}, {"title": "ReFiNe: Recursive Field Networks for Cross-modal Multi-scene Representation", "link": "https://arxiv.org/pdf/2406.04309", "details": "S Zakharov, K Liu, A Gaidon, R Ambrus - arXiv preprint arXiv:2406.04309, 2024", "abstract": "The common trade-offs of state-of-the-art methods for multi-shape representation (a single model\" packing\" multiple objects) involve trading modeling accuracy against memory and storage. We show how to encode multiple shapes represented as \u2026"}, {"title": "Effective Context Selection in LLM-based Leaderboard Generation: An Empirical Study", "link": "https://arxiv.org/pdf/2407.02409", "details": "S Kabongo, J D'Souza, S Auer - arXiv preprint arXiv:2407.02409, 2024", "abstract": "This paper explores the impact of context selection on the efficiency of Large Language Models (LLMs) in generating Artificial Intelligence (AI) research leaderboards, a task defined as the extraction of (Task, Dataset, Metric, Score) \u2026"}, {"title": "3D Snapshot: Invertible Embedding of 3D Neural Representations in a Single Image", "link": "https://ieeexplore.ieee.org/abstract/document/10552101/", "details": "Y Lu, B Deng, Z Zhong, T Zhang, Y Quan, H Cai, S He - IEEE Transactions on Pattern \u2026, 2024", "abstract": "3D neural rendering enables photo-realistic reconstruction of a specific scene by encoding discontinuous inputs into a neural representation. Despite the remarkable rendering results, the storage of network parameters is not transmission-friendly and \u2026"}, {"title": "Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration", "link": "https://arxiv.org/pdf/2406.18516", "details": "K Liao, Z Yue, Z Wang, CC Loy - arXiv preprint arXiv:2406.18516, 2024", "abstract": "Although deep learning-based image restoration methods have made significant progress, they still struggle with limited generalization to real-world scenarios due to the substantial domain gap caused by training on synthetic data. Existing methods \u2026"}, {"title": "Training Compute-Optimal Protein Language Models", "link": "https://www.biorxiv.org/content/10.1101/2024.06.06.597716.full.pdf", "details": "X Cheng, B Chen, P Li, J Gong, J Tang, L Song - bioRxiv, 2024", "abstract": "We explore optimally training protein language models, an area of significant interest in biological research where guidance on best practices is limited. Most models are trained with extensive compute resources until performance gains plateau, focusing \u2026"}, {"title": "Benchmarking Vision-Language Contrastive Methods for Medical Representation Learning", "link": "https://arxiv.org/pdf/2406.07450", "details": "S Roy, Y Parhizkar, F Ogidi, VR Khazaie, M Colacci\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We perform a comprehensive benchmarking of contrastive frameworks for learning multimodal representations in the medical domain. Through this study, we aim to answer the following research questions:(i) How transferable are general-domain \u2026"}]
