[{"title": "From head to tail: Towards balanced representation in large vision-language models through adaptive data calibration", "link": "https://arxiv.org/pdf/2503.12821", "details": "M Song, X Qu, J Zhou, Y Cheng - arXiv preprint arXiv:2503.12821, 2025", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant progress in combining visual comprehension with language generation. Despite this success, the training data of LVLMs still suffers from Long-Tail (LT) problems, where the data \u2026"}, {"title": "REVAL: A Comprehension Evaluation on Reliability and Values of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.16566", "details": "J Zhang, Z Yuan, Z Wang, B Yan, S Wang, X Cao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The rapid evolution of Large Vision-Language Models (LVLMs) has highlighted the necessity for comprehensive evaluation frameworks that assess these models across diverse dimensions. While existing benchmarks focus on specific aspects such as \u2026"}, {"title": "Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization", "link": "https://arxiv.org/pdf/2503.22577%3F", "details": "I Pikabea, I Lacunza, O Pareras, C Escolano\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as \u2026"}, {"title": "Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks", "link": "https://arxiv.org/pdf/2504.01308", "details": "J Wang, Y Zuo, Y Chai, Z Liu, Y Fu, Y Feng, K Lam - arXiv preprint arXiv:2504.01308, 2025", "abstract": "Vision-Language Models (VLMs) extend the capabilities of Large Language Models (LLMs) by incorporating visual information, yet they remain vulnerable to jailbreak attacks, especially when processing noisy or corrupted images. Although existing \u2026"}, {"title": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models", "link": "https://arxiv.org/pdf/2503.18923", "details": "M Cao, P Hu, Y Wang, J Gu, H Tang, H Zhao, J Dong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we \u2026"}, {"title": "Unveiling the mist over 3d vision-language understanding: Object-centric evaluation with chain-of-analysis", "link": "https://arxiv.org/pdf/2503.22420", "details": "J Huang, B Jia, Y Wang, Z Zhu, X Linghu, Q Li, SC Zhu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing 3D vision-language (3D-VL) benchmarks fall short in evaluating 3D-VL models, creating a\" mist\" that obscures rigorous insights into model capabilities and 3D-VL tasks. This mist persists due to three key limitations. First, flawed test data, like \u2026"}, {"title": "2-D Transformer: Extending Large Language Models to Long-Context With Few Memory", "link": "https://ieeexplore.ieee.org/abstract/document/10937248/", "details": "X He, J Liu, Y Duan - IEEE Transactions on Neural Networks and Learning \u2026, 2025", "abstract": "The ability of processing long contexts is crucial for large language models (LLMs), but training LLMs with a long-context window requires substantial computational resources. Many sought to mitigate this through the sparse attention mechanism \u2026"}, {"title": "From Chaos to Order: The Atomic Reasoner Framework for Fine-grained Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2503.15944", "details": "J Liu, Y Zheng, R Cheng, Q Wu, W Guo, F Ni, H Liang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in large language models (LLMs) have shown remarkable progress, yet their capacity for logical``slow-thinking''reasoning persists as a critical research frontier. Current inference scaling paradigms suffer from two fundamental \u2026"}, {"title": "Trajectory Balance with Asynchrony: Decoupling Exploration and Learning for Fast, Scalable LLM Post-Training", "link": "https://arxiv.org/pdf/2503.18929", "details": "BR Bartoldson, S Venkatraman, J Diffenderfer, M Jain\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reinforcement learning (RL) is a critical component of large language model (LLM) post-training. However, existing on-policy algorithms used for post-training are inherently incompatible with the use of experience replay buffers, which can be \u2026"}]
