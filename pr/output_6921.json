[{"title": "Selective Self-Rehearsal: A Fine-Tuning Approach to Improve Generalization in Large Language Models", "link": "https://arxiv.org/pdf/2409.04787", "details": "S Gupta, Y Nandwani, A Yehudai, M Mishra, G Pandey\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Fine-tuning Large Language Models (LLMs) on specific datasets is a common practice to improve performance on target tasks. However, this performance gain often leads to overfitting, where the model becomes too specialized in either the task \u2026"}, {"title": "Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications", "link": "https://arxiv.org/pdf/2409.05314", "details": "A Maatouk, KC Ampudia, R Ying, L Tassiulas - arXiv preprint arXiv:2409.05314, 2024", "abstract": "The emergence of large language models (LLMs) has significantly impacted various fields, from natural language processing to sectors like medicine and finance. However, despite their rapid proliferation, the applications of LLMs in \u2026"}, {"title": "PiTe: Pixel-Temporal Alignment for Large Video-Language Model", "link": "https://arxiv.org/pdf/2409.07239", "details": "Y Liu, P Ding, S Huang, M Zhang, H Zhao, D Wang - arXiv preprint arXiv:2409.07239, 2024", "abstract": "Fueled by the Large Language Models (LLMs) wave, Large Visual-Language Models (LVLMs) have emerged as a pivotal advancement, bridging the gap between image and text. However, video making it challenging for LVLMs to perform \u2026"}, {"title": "Targeted training for numerical reasoning with large language models", "link": "https://link.springer.com/article/10.1007/s10115-024-02216-1", "details": "X Li, S Liu, Y Zhu, G Cheng - Knowledge and Information Systems, 2024", "abstract": "After recent gains achieved by large language models (LLMs) on numerical reasoning tasks, it has become of interest to have LLMs teach small models to improve on numerical reasoning. Instructing LLMs to generate Chains of Thought to \u2026"}, {"title": "Self-Evolutionary Large Language Models through Uncertainty-Enhanced Preference Optimization", "link": "https://arxiv.org/pdf/2409.11212", "details": "J Wang, Y Zhou, X Zhang, M Bao, P Yan - arXiv preprint arXiv:2409.11212, 2024", "abstract": "Iterative preference optimization has recently become one of the de-facto training paradigms for large language models (LLMs), but the performance is still underwhelming due to too much noisy preference data yielded in the loop. To \u2026"}, {"title": "Towards Data Contamination Detection for Modern Large Language Models: Limitations, Inconsistencies, and Oracle Challenges", "link": "https://arxiv.org/pdf/2409.09927", "details": "V Samuel, Y Zhou, HP Zou - arXiv preprint arXiv:2409.09927, 2024", "abstract": "As large language models achieve increasingly impressive results, questions arise about whether such performance is from generalizability or mere data memorization. Thus, numerous data contamination detection methods have been proposed \u2026"}, {"title": "ELMS: Elasticized Large Language Models On Mobile Devices", "link": "https://arxiv.org/pdf/2409.09071", "details": "W Yin, R Yi, D Xu, G Huang, M Xu, X Liu - arXiv preprint arXiv:2409.09071, 2024", "abstract": "On-device Large Language Models (LLMs) are revolutionizing mobile AI, enabling applications such as UI automation while addressing privacy concerns. Currently, the standard approach involves deploying a single, robust LLM as a universal solution \u2026"}, {"title": "The representation landscape of few-shot learning and fine-tuning in large language models", "link": "https://arxiv.org/pdf/2409.03662", "details": "D Doimo, A Serra, A Ansuini, A Cazzaniga - arXiv preprint arXiv:2409.03662, 2024", "abstract": "In-context learning (ICL) and supervised fine-tuning (SFT) are two common strategies for improving the performance of modern large language models (LLMs) on specific tasks. Despite their different natures, these strategies often lead to \u2026"}, {"title": "Generated Data with Fake Privacy: Hidden Dangers of Fine-tuning Large Language Models on Generated Data", "link": "https://arxiv.org/pdf/2409.11423", "details": "A Akkus, M Li, J Chu, M Backes, Y Zhang, S Sav - arXiv preprint arXiv:2409.11423, 2024", "abstract": "Large language models (LLMs) have shown considerable success in a range of domain-specific tasks, especially after fine-tuning. However, fine-tuning with real- world data usually leads to privacy risks, particularly when the fine-tuning samples \u2026"}]
