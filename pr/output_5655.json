[{"title": "Language Models Don't Learn the Physical Manifestation of Language", "link": "https://aclanthology.org/2024.acl-long.195.pdf", "details": "B Lee, J Lim - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "We argue that language-only models don't learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test. These tasks highlight a \u2026"}, {"title": "MindLLM: Lightweight large language model pre-training, evaluation and domain application", "link": "https://www.sciencedirect.com/science/article/pii/S2666651024000111", "details": "Y Yang, H Sun, J Li, R Liu, Y Li, Y Liu, Y Gao, H Huang - AI Open, 2024", "abstract": "Abstract Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is \u2026"}, {"title": "MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models", "link": "https://arxiv.org/pdf/2408.01337", "details": "B Weck, I Manco, E Benetos, E Quinton, G Fazekas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal models that jointly process audio and language hold great promise in audio understanding and are increasingly being adopted in the music domain. By allowing users to query via text and obtain information about a given audio input \u2026"}, {"title": "Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning", "link": "https://arxiv.org/pdf/2407.18248", "details": "T Wang, S Li, W Lu - arXiv preprint arXiv:2407.18248, 2024", "abstract": "Effective training of language models (LMs) for mathematical reasoning tasks demands high-quality supervised fine-tuning data. Besides obtaining annotations from human experts, a common alternative is sampling from larger and more \u2026"}, {"title": "InstructCoder: Instruction Tuning Large Language Models for Code Editing", "link": "https://aclanthology.org/2024.acl-srw.6.pdf", "details": "K Li, Q Hu, J Zhao, H Chen, Y Xie, T Liu, M Shieh, J He - Proceedings of the 62nd \u2026, 2024", "abstract": "Code editing encompasses a variety of pragmatic tasks that developers deal with daily. Despite its relevance and practical usefulness, automatic code editing remains an underexplored area in the evolution of deep learning models, partly due to data \u2026"}, {"title": "CLIP-DPO: Vision-Language Models as a Source of Preference for Fixing Hallucinations in LVLMs", "link": "https://arxiv.org/pdf/2408.10433", "details": "Y Ouali, A Bulat, B Martinez, G Tzimiropoulos - arXiv preprint arXiv:2408.10433, 2024", "abstract": "Despite recent successes, LVLMs or Large Vision Language Models are prone to hallucinating details like objects and their properties or relations, limiting their real- world deployment. To address this and improve their robustness, we present CLIP \u2026"}, {"title": "Goldfish: Monolingual Language Models for 350 Languages", "link": "https://arxiv.org/pdf/2408.10441", "details": "TA Chang, C Arnett, Z Tu, BK Bergen - arXiv preprint arXiv:2408.10441, 2024", "abstract": "For many low-resource languages, the only available language models are large multilingual models trained on many languages simultaneously. However, using FLORES perplexity as a metric, we find that these models perform worse than \u2026"}, {"title": "Using Natural Language Explanations to Improve Robustness of In-context Learning", "link": "https://aclanthology.org/2024.acl-long.728.pdf", "details": "X He, Y Wu, OM Camburu, P Minervini, P Stenetorp - \u2026 of the 62nd Annual Meeting of \u2026, 2024", "abstract": "Recent studies demonstrated that large language models (LLMs) can excel in many tasks via in-context learning (ICL). However, recentworks show that ICL-prompted models tend to produce inaccurate results when presented with adversarial inputs. In \u2026"}, {"title": "BEnQA: A Question Answering Benchmark for Bengali and English", "link": "https://aclanthology.org/2024.findings-acl.68.pdf", "details": "S Shafayat, H Hasan, M Mahim, R Putri, J Thorne, A Oh - Findings of the Association \u2026, 2024", "abstract": "In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with \u2026"}]
