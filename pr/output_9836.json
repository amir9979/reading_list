[{"title": "PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning", "link": "https://arxiv.org/pdf/2411.19335", "details": "S Li, ECH Ngai, F Ye, T Voigt - arXiv preprint arXiv:2411.19335, 2024", "abstract": "Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising paradigm for privacy-preserving and efficient adaptation of Pre-trained Language Models (PLMs) in Federated Learning (FL) settings. It preserves data privacy by \u2026"}, {"title": "DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators", "link": "https://arxiv.org/pdf/2412.02467", "details": "T Afonja, HP Wang, R Kerkouche, M Fritz - arXiv preprint arXiv:2412.02467, 2024", "abstract": "Generating tabular data under differential privacy (DP) protection ensures theoretical privacy guarantees but poses challenges for training machine learning models, primarily due to the need to capture complex structures under noisy supervision \u2026"}, {"title": "VISCO: Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning", "link": "https://arxiv.org/pdf/2412.02172", "details": "X Wu, Y Ding, B Li, P Lu, D Yin, KW Chang, N Peng - arXiv preprint arXiv:2412.02172, 2024", "abstract": "The ability of large vision-language models (LVLMs) to critique and correct their reasoning is an essential building block towards their self-improvement. However, a systematic analysis of such capabilities in LVLMs is still lacking. We propose VISCO \u2026"}, {"title": "ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?", "link": "https://arxiv.org/pdf/2412.02368", "details": "L Zhang, S Eger, Y Cheng, W Zhai, J Belouadi, C Leiter\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal large language models (LLMs) have demonstrated impressive capabilities in generating high-quality images from textual instructions. However, their performance in generating scientific images--a critical application for \u2026"}, {"title": "METEOR: Evolutionary Journey of Large Language Models from Guidance to Self-Growth", "link": "https://arxiv.org/pdf/2411.11933", "details": "J Li, C Feng, Y Gao - arXiv preprint arXiv:2411.11933, 2024", "abstract": "Model evolution enables learning from feedback to refine experiences and update skills, transforming models from having no domain knowledge to becoming domain experts. However, there is currently no unified and effective method for guiding this \u2026"}, {"title": "Clean-label backdoor attack and defense: An examination of language model vulnerability", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424027234", "details": "S Zhao, X Xu, L Xiao, J Wen, LA Tuan - Expert Systems with Applications, 2024", "abstract": "Prompt-based learning, a paradigm that creates a bridge between pre-training and fine-tuning stages, has proven to be highly effective concerning various NLP tasks, particularly in few-shot scenarios. However, such a paradigm is not immune to \u2026"}, {"title": "A Simple and Provable Scaling Law for the Test-Time Compute of Large Language Models", "link": "https://arxiv.org/pdf/2411.19477", "details": "Y Chen, X Pan, Y Li, B Ding, J Zhou - arXiv preprint arXiv:2411.19477, 2024", "abstract": "We propose a general two-stage algorithm that enjoys a provable scaling law for the test-time compute of large language models (LLMs). Given an input problem, the proposed algorithm first generates $ N $ candidate solutions, and then chooses the \u2026"}, {"title": "The Dark Side of Trust: Authority Citation-Driven Jailbreak Attacks on Large Language Models", "link": "https://arxiv.org/pdf/2411.11407", "details": "X Yang, X Tang, J Han, S Hu - arXiv preprint arXiv:2411.11407, 2024", "abstract": "The widespread deployment of large language models (LLMs) across various domains has showcased their immense potential while exposing significant safety vulnerabilities. A major concern is ensuring that LLM-generated content aligns with \u2026"}, {"title": "Training Agents with Weakly Supervised Feedback from Large Language Models", "link": "https://arxiv.org/pdf/2411.19547", "details": "D Gong, P Lu, Z Wang, M Zhou, X He - arXiv preprint arXiv:2411.19547, 2024", "abstract": "Large Language Models (LLMs) offer a promising basis for creating agents that can tackle complex tasks through iterative environmental interaction. Existing methods either require these agents to mimic expert-provided trajectories or rely on definitive \u2026"}]
