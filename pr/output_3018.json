[{"title": "Bridging the Gap: A Hybrid Approach to Medical Relation Extraction Using Pretrained Language Models and Traditional Machine Learning", "link": "https://www.jait.us/articles/2024/JAIT-V15N6-723.pdf", "details": "NA Hassan, RAA Seoud, DA Salem - Journal of Advances in Information Technology, 2024", "abstract": "Feature engineering can be time-consuming and challenging, requiring expertise in Natural Language Processing (NLP) techniques and methods. The objective of this study was to explore the use of contextual word embeddings, specifically \u2026"}, {"title": "Assessing the Reliability of Artificial Intelligence Systems: Challenges, Metrics, and Future Directions", "link": "https://www.ijimes.ir/index.php/ijimes/article/view/133", "details": "STH Mortaji, ME Sadeghi - International Journal of Innovation in Management \u2026, 2024", "abstract": "Purpose: As artificial intelligence (AI) systems become integral to diverse applications, ensuring their reliability is of paramount importance. This paper explores the multifaceted landscape of AI reliability, encompassing challenges \u2026"}, {"title": "DiscreteSLU: A Large Language Model with Self-Supervised Discrete Speech Units for Spoken Language Understanding", "link": "https://arxiv.org/pdf/2406.09345", "details": "S Shon, K Kim, YT Hsu, P Sridhar, S Watanabe\u2026 - arXiv e-prints, 2024", "abstract": "The integration of pre-trained text-based large language models (LLM) with speech input has enabled instruction-following capabilities for diverse speech tasks. This integration requires the use of a speech encoder, a speech adapter, and an LLM \u2026"}, {"title": "mDPO: Conditional Preference Optimization for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2406.11839", "details": "F Wang, W Zhou, JY Huang, N Xu, S Zhang, H Poon\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Direct preference optimization (DPO) has shown to be an effective method for large language model (LLM) alignment. Recent works have attempted to apply DPO to multimodal scenarios but have found it challenging to achieve consistent \u2026"}, {"title": "Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss", "link": "https://openreview.net/pdf%3Fid%3DKSNl7VgeVr", "details": "R Zheng, Y Liang, X Wang, S Ma, H Daum\u00e9 III, H Xu\u2026 - Forty-first International \u2026, 2024", "abstract": "We present Premier-TACO, a multitask feature representation learning approach designed to improve few-shot policy learning efficiency in sequential decision- making tasks. Premier-TACO leverages a subset of multitask offline datasets for \u2026"}, {"title": "BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation", "link": "https://arxiv.org/pdf/2405.17039", "details": "C Jia, P Wang, Z Li, YC Li, Z Zhang, N Tang, Y Yu - arXiv preprint arXiv:2405.17039, 2024", "abstract": "Large language models (LLMs) have catalyzed a paradigm shift in natural language processing, yet their limited controllability poses a significant challenge for downstream applications. We aim to address this by drawing inspiration from the \u2026"}]
