[{"title": "Federated Foundation Model for GI Endoscopy Images", "link": "https://arxiv.org/pdf/2505.24108", "details": "A Devkota, A Amireskandari, J Palko, S Thakkar\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Gastrointestinal (GI) endoscopy is essential in identifying GI tract abnormalities in order to detect diseases in their early stages and improve patient outcomes. Although deep learning has shown success in supporting GI diagnostics and \u2026", "entry_id": "http://arxiv.org/abs/2505.24108v1", "updated": "2025-05-30 01:18:17", "published": "2025-05-30 01:18:17", "authors": "Alina Devkota;Annahita Amireskandari;Joel Palko;Shyam Thakkar;Donald Adjeroh;Xiajun Jiang;Binod Bhattarai;Prashnna K. Gyawali", "summary": "Gastrointestinal (GI) endoscopy is essential in identifying GI tract\nabnormalities in order to detect diseases in their early stages and improve\npatient outcomes. Although deep learning has shown success in supporting GI\ndiagnostics and decision-making, these models require curated datasets with\nlabels that are expensive to acquire. Foundation models offer a promising\nsolution by learning general-purpose representations, which can be finetuned\nfor specific tasks, overcoming data scarcity. Developing foundation models for\nmedical imaging holds significant potential, but the sensitive and protected\nnature of medical data presents unique challenges. Foundation model training\ntypically requires extensive datasets, and while hospitals generate large\nvolumes of data, privacy restrictions prevent direct data sharing, making\nfoundation model training infeasible in most scenarios. In this work, we\npropose a FL framework for training foundation models for gastroendoscopy\nimaging, enabling data to remain within local hospital environments while\ncontributing to a shared model. We explore several established FL algorithms,\nassessing their suitability for training foundation models without relying on\ntask-specific labels, conducting experiments in both homogeneous and\nheterogeneous settings. We evaluate the trained foundation model on three\ncritical downstream tasks--classification, detection, and segmentation--and\ndemonstrate that it achieves improved performance across all tasks,\nhighlighting the effectiveness of our approach in a federated,\nprivacy-preserving setting.", "comment": "11 pages, 11 figures, submitted to BHI2025", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.LG;I.2.10; I.4; I.5", "links": "http://arxiv.org/abs/2505.24108v1;http://arxiv.org/pdf/2505.24108v1", "pdf_url": "http://arxiv.org/pdf/2505.24108v1"}, {"title": "Foundation model embeddings for quantitative tumor imaging biomarkers", "link": "https://www.researchsquare.com/article/rs-6630446/latest", "details": "H Aerts, S Pai, I Hadzic, A Fedorov, R Mak - 2025", "abstract": "Foundation models are increasingly used in medical imaging, yet their ability to extract reliable quantitative radiographic phenotypes of cancer across diverse clinical contexts lacks systematic evaluation. Here, we introduce \u2026"}]
