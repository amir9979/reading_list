[{"title": "NNTile: a machine learning framework capable of training extremely large GPT language models on a single node", "link": "https://arxiv.org/pdf/2504.13236", "details": "A Mikhalev, A Katrutsa, K Sozykin, I Oseledets - arXiv preprint arXiv:2504.13236, 2025", "abstract": "This study presents an NNTile framework for training large deep neural networks in heterogeneous clusters. The NNTile is based on a StarPU library, which implements task-based parallelism and schedules all provided tasks onto all available \u2026"}, {"title": "A Survey of Foundation Model-Powered Recommender Systems: From Feature-Based, Generative to Agentic Paradigms", "link": "https://arxiv.org/pdf/2504.16420", "details": "C Huang, H Huang, T Yu, K Xie, J Wu, S Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recommender systems (RS) have become essential in filtering information and personalizing content for users. RS techniques have traditionally relied on modeling interactions between users and items as well as the features of content using models \u2026"}, {"title": "Agentic Large Language Models, a survey", "link": "https://arxiv.org/pdf/2503.23037", "details": "A Plaat, M van Duijn, N van Stein, M Preuss\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "There is great interest in agentic LLMs, large language models that act as agents. We review the growing body of work in this area and provide a research agenda. Agentic LLMs are LLMs that (1) reason,(2) act, and (3) interact. We organize the \u2026"}, {"title": "Understanding contraceptive switching rationales from real world clinical notes using large language models", "link": "https://www.nature.com/articles/s41746-025-01615-0", "details": "BY Miao, CYK Williams, E Chinedu-Eneh, T Zack\u2026 - npj Digital Medicine, 2025", "abstract": "Understanding reasons for treatment switching is of significant medical interest, but these factors are often only found in unstructured clinical notes and can be difficult to extract. We evaluated the zero-shot abilities of GPT-4 and eight other open-source \u2026"}, {"title": "Developing safe and responsible large language model: can we balance bias reduction and language understanding?", "link": "https://link.springer.com/article/10.1007/s10994-025-06767-4", "details": "S Raza, O Bamgbose, S Ghuge, F Tavakoli, DJ Reji\u2026 - Machine Learning, 2025", "abstract": "Abstract Large Language Models (LLMs) have advanced various Natural Language Processing (NLP) tasks, such as text generation and translation, among others. However, these models often generate texts that can perpetuate biases. Existing \u2026"}]
