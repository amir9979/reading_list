[{"title": "HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/32171/34326", "details": "KHI Arif, JY Yoon, DS Nikolopoulos, H Vandierendonck\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "Abstract High-resolution Vision-Language Models (VLMs) are widely used in multimodal tasks to enhance accuracy by preserving detailed image information. However, these models often generate an excessive number of visual tokens due to \u2026"}, {"title": "Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization", "link": "https://arxiv.org/pdf/2503.22577%3F", "details": "I Pikabea, I Lacunza, O Pareras, C Escolano\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as \u2026"}, {"title": "Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks", "link": "https://arxiv.org/pdf/2504.01308", "details": "J Wang, Y Zuo, Y Chai, Z Liu, Y Fu, Y Feng, K Lam - arXiv preprint arXiv:2504.01308, 2025", "abstract": "Vision-Language Models (VLMs) extend the capabilities of Large Language Models (LLMs) by incorporating visual information, yet they remain vulnerable to jailbreak attacks, especially when processing noisy or corrupted images. Although existing \u2026"}, {"title": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "link": "https://arxiv.org/pdf/2504.07416", "details": "J Park, S Kim, B Yoon, K Choi - arXiv preprint arXiv:2504.07416, 2025", "abstract": "Recent advancements in multi-modal models have significantly improved vision- language alignment in radiology. However, existing approaches struggle to effectively utilize complex radiology reports for learning, rely on low-resolution \u2026"}, {"title": "Unveiling the mist over 3d vision-language understanding: Object-centric evaluation with chain-of-analysis", "link": "https://arxiv.org/pdf/2503.22420", "details": "J Huang, B Jia, Y Wang, Z Zhu, X Linghu, Q Li, SC Zhu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing 3D vision-language (3D-VL) benchmarks fall short in evaluating 3D-VL models, creating a\" mist\" that obscures rigorous insights into model capabilities and 3D-VL tasks. This mist persists due to three key limitations. First, flawed test data, like \u2026"}, {"title": "Contrastive learning for anomaly detection in hierarchical subgraph", "link": "https://www.sciencedirect.com/science/article/pii/S0950705125004824", "details": "J Wu, W Gan, J Zhang, PS Yu - Knowledge-Based Systems, 2025", "abstract": "Anomaly detection in attribute graphs is a crucial task in various domains, such as cybersecurity, finance, and social networks. However, existing methods face challenges due to the sparse connectivity of anomalous nodes and the irregular \u2026"}, {"title": "Efficient Tuning of Large Language Models for Knowledge-Grounded Dialogue Generation", "link": "https://arxiv.org/pdf/2504.07754", "details": "B Zhang, H Ma, D Li, J Ding, J Wang, B Xu, HF Lin - arXiv preprint arXiv:2504.07754, 2025", "abstract": "Large language models (LLMs) demonstrate remarkable text comprehension and generation capabilities but often lack the ability to utilize up-to-date or domain- specific knowledge not included in their training data. To address this gap, we \u2026"}, {"title": "SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding", "link": "https://arxiv.org/pdf/2504.07745", "details": "Y Hu, Z Song, N Feng, Y Luo, J Yu, YPP Chen, W Yang - arXiv preprint arXiv \u2026, 2025", "abstract": "Video-based Large Language Models (Video-LLMs) have witnessed substantial advancements in recent years, propelled by the advancement in multi-modal LLMs. Although these models have demonstrated proficiency in providing the overall \u2026"}, {"title": "Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?", "link": "https://arxiv.org/pdf/2504.00509", "details": "K Yan, Y Xu, Z Du, X Yao, Z Wang, X Guo, J Chen - arXiv preprint arXiv:2504.00509, 2025", "abstract": "The rapid escalation from elementary school-level to frontier problems of the difficulty for LLM benchmarks in recent years have weaved a miracle for researchers that we are only inches away from surpassing human intelligence. However, is the LLMs' \u2026"}]
