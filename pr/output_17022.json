[{"title": "Coordination in Multi-Agent LLM Systems: The Role of a Question-Asking Agent in Guiding Collaborative Consensus", "link": "https://digital.wpi.edu/downloads/fq978037t", "details": "K Roohani - 2025", "abstract": "\u2026 This observation aligns with other findings in **LLM** **evaluation** \u2014namely, that language models struggle with maintaining state coherence in chess [6, 11, 16]. Even while using the QAA and collaborative processing, increasing the input length \u2026"}, {"title": "Designing a framework for ethnography-driven prompt engineering in social work", "link": "https://www.ht.csr-pub.eu/index.php/ht/article/download/460/317", "details": "M Seniutis, V Gru\u017eauskas, A Sas, V Navickas\u2026 - Human Technology, 2025", "abstract": "\u2026 These components were further elaborated into various prompting techniques and developed into a set of prompt templates that can be applied to **LLM** **evaluation** and further customization. \u2026"}, {"title": "Does Johnny Get the Message? Evaluating Cybersecurity Notifications for Everyday Users", "link": "https://arxiv.org/pdf/2505.22435", "details": "V J\u00fcttner, E Buchmann - arXiv preprint arXiv:2505.22435, 2025", "abstract": "\u2026 These dimensions are derived from existing work on general **LLM** **evaluation** frameworks [7], [8] and research in security communication [9\u2026 We adapted the dimensions Context, Correctness, and Intuitiveness from general **LLM** **evaluation** \u2026", "entry_id": "http://arxiv.org/abs/2505.22435v1", "updated": "2025-05-28 14:58:29", "published": "2025-05-28 14:58:29", "authors": "Victor J\u00fcttner;Erik Buchmann", "summary": "Due to the increasing presence of networked devices in everyday life, not\nonly cybersecurity specialists but also end users benefit from security\napplications such as firewalls, vulnerability scanners, and intrusion detection\nsystems. Recent approaches use large language models (LLMs) to rewrite brief,\ntechnical security alerts into intuitive language and suggest actionable\nmeasures, helping everyday users understand and respond appropriately to\nsecurity risks. However, it remains an open question how well such alerts are\nexplained to users. LLM outputs can also be hallucinated, inconsistent, or\nmisleading. In this work, we introduce the Human-Centered Security Alert\nEvaluation Framework (HCSAEF). HCSAEF assesses LLM-generated cybersecurity\nnotifications to support researchers who want to compare notifications\ngenerated for everyday users, improve them, or analyze the capabilities of\ndifferent LLMs in explaining cybersecurity issues. We demonstrate HCSAEF\nthrough three use cases, which allow us to quantify the impact of prompt\ndesign, model selection, and output consistency. Our findings indicate that\nHCSAEF effectively differentiates generated notifications along dimensions such\nas intuitiveness, urgency, and correctness.", "comment": null, "journal_ref": null, "primary_category": "cs.CR", "categories": "cs.CR", "links": "http://arxiv.org/abs/2505.22435v1;http://arxiv.org/pdf/2505.22435v1", "pdf_url": "http://arxiv.org/pdf/2505.22435v1"}, {"title": "Fusion Steering: Prompt-Specific Activation Control", "link": "https://arxiv.org/pdf/2505.22572", "details": "W Chang, A Yasin - arXiv preprint arXiv:2505.22572, 2025", "abstract": "We present Fusion Steering, an activation steering methodology that improves factual accuracy in large language models (LLMs) for question-answering (QA) tasks. This approach introduces flexible steering configurations, including full-layer \u2026", "entry_id": "http://arxiv.org/abs/2505.22572v1", "updated": "2025-05-28 16:46:55", "published": "2025-05-28 16:46:55", "authors": "Waldemar Chang;Alhassan Yasin", "summary": "We present Fusion Steering, an activation steering methodology that improves\nfactual accuracy in large language models (LLMs) for question-answering (QA)\ntasks. This approach introduces flexible steering configurations, including\nfull-layer steering and segmented steering. Unlike traditional methods\nconstrained to single-layer or fixed-layer operations, Fusion Steering employs\ndynamic injection of prompt-specific activation deltas across all transformer\nlayers. These activation deltas are derived from reference completions that\ncombine the ground-truth answer with a model-generated explanation to\nfacilitate semantically enriched, example-specific steering. The injection\nweights are optimized per prompt using Optuna, targeting a joint objective that\nbalances token overlap (factual alignment) and perplexity (fluency proxy).\nEvaluation employs a composite score integrating token overlap and LLM-graded\nquality, encompassing factual accuracy, coherence, and relevance. Empirical\nresults on 260 SimpleQA prompts (selected from 500 where the baseline failed)\nshowcase the efficacy of segmented steering. Using Gemma-2-2B-IT with 8-bit\nquantization, segmented steering achieves an accuracy of 25.4% (outputs scoring\n$\\geq 0.6$), outperforming the baseline at 3.5% and full-layer steering at\n16.2%. Under the stricter SimpleQA rubric, segmented steering boosts fully\ncorrect responses from 0.0% to 13.1%. These findings highlight the strengths of\nsegmented, dynamic intervention strategies and the promise of per-prompt,\nfull-network activation control. Fusion Steering is also amenable to sparse\nrepresentations, such as Neuronpedia or sparse crosscoders, suggesting a\npromising direction for interpretable and scalable activation-level control in\nLLMs.", "comment": "14 pages, 4 figures, 2 tables", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2505.22572v1;http://arxiv.org/pdf/2505.22572v1", "pdf_url": "http://arxiv.org/pdf/2505.22572v1"}, {"title": "Judging LLMs on a Simplex", "link": "https://arxiv.org/pdf/2505.21972", "details": "P Vossler, F Xia, Y Mai, J Feng - arXiv preprint arXiv:2505.21972, 2025", "abstract": "\u2026 to the case of multi-level ratings, which are commonly used for **LLM** **evaluation**. The geometric arguments substantially extend [12, 3, 19, 10], \u2026 help LLM practitioners and researchers take a more deliberate approach when leveraging \u2026", "entry_id": "http://arxiv.org/abs/2505.21972v1", "updated": "2025-05-28 04:50:41", "published": "2025-05-28 04:50:41", "authors": "Patrick Vossler;Fan Xia;Yifan Mai;Jean Feng", "summary": "Automated evaluation of free-form outputs from large language models (LLMs)\nis challenging because many distinct answers can be equally valid. A common\npractice is to use LLMs themselves as judges, but the theoretical properties of\nthis approach are not yet well understood. We show that a geometric framework\nthat represents both judges and candidates as points on a probability simplex\ncan provide helpful insight on what is or is not identifiable using LLM judges.\nOur theoretical analysis uncovers a \"phase transition\" in ranking\nidentifiability: for binary scoring systems, true rankings are identifiable\neven with weak judges under mild assumptions, while rankings become\nnon-identifiable for three or more scoring levels even with infinite data,\nabsent additional prior knowledge. This non-identifiability highlights how\nuncertainty in rankings stems from not only aleatoric uncertainty (i.e.,\ninherent stochasticity in the data) but also epistemic uncertainty regarding\nwhich assumptions hold, an aspect that has received limited attention until\nnow. To integrate both types of uncertainty, we use Bayesian inference to\nencode assumptions as priors and conduct sensitivity analysis of ranking\nestimates and credible intervals. Empirical evaluations across multiple\nbenchmarks demonstrate that Bayesian inference yields more accurate rankings\nand substantially improves coverage rates. These results underscore the\nimportance of taking a more holistic approach to uncertainty quantification\nwhen using LLMs as judges.", "comment": "28 pages, 7 figures", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.AI;stat.ML", "links": "http://arxiv.org/abs/2505.21972v1;http://arxiv.org/pdf/2505.21972v1", "pdf_url": "http://arxiv.org/pdf/2505.21972v1"}, {"title": "Xinyu AI Search: Enhanced Relevance and Comprehensive Results with Rich Answer Presentations", "link": "https://arxiv.org/pdf/2505.21849", "details": "B Tang, J Zhu, C Xi, Y Ge, J Wu, Y Feng, Y Niu, W Wei\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 **LLM** **evaluation** has been adopted in many studies [27]. We used GPT-4O (gpt-40125-preview) \u2026 1 shows that the **LLM** **evaluation** is highly correlated with human evaluation based on the \u2026 **LLM** **evaluation** is used to rate the responses based on the multi-faceted \u2026", "entry_id": "http://arxiv.org/abs/2505.21849v1", "updated": "2025-05-28 00:30:22", "published": "2025-05-28 00:30:22", "authors": "Bo Tang;Junyi Zhu;Chenyang Xi;Yunhang Ge;Jiahao Wu;Yuchen Feng;Yijun Niu;Wenqiang Wei;Yu Yu;Chunyu Li;Zehao Lin;Hao Wu;Ning Liao;Yebin Yang;Jiajia Wang;Zhiyu Li;Feiyu Xiong;Jingrun Chen", "summary": "Traditional search engines struggle to synthesize fragmented information for\ncomplex queries, while generative AI search engines face challenges in\nrelevance, comprehensiveness, and presentation. To address these limitations,\nwe introduce Xinyu AI Search, a novel system that incorporates a\nquery-decomposition graph to dynamically break down complex queries into\nsub-queries, enabling stepwise retrieval and generation. Our retrieval pipeline\nenhances diversity through multi-source aggregation and query expansion, while\nfiltering and re-ranking strategies optimize passage relevance. Additionally,\nXinyu AI Search introduces a novel approach for fine-grained, precise built-in\ncitation and innovates in result presentation by integrating timeline\nvisualization and textual-visual choreography. Evaluated on recent real-world\nqueries, Xinyu AI Search outperforms eight existing technologies in human\nassessments, excelling in relevance, comprehensiveness, and insightfulness.\nAblation studies validate the necessity of its key sub-modules. Our work\npresents the first comprehensive framework for generative AI search engines,\nbridging retrieval, generation, and user-centric presentation.", "comment": null, "journal_ref": null, "primary_category": "cs.IR", "categories": "cs.IR;cs.AI", "links": "http://arxiv.org/abs/2505.21849v1;http://arxiv.org/pdf/2505.21849v1", "pdf_url": "http://arxiv.org/pdf/2505.21849v1"}, {"title": "An Exhaustive Analysis Of Large Language Models", "link": "https://www.researchgate.net/profile/Tejesvi-Prasad-2/publication/392131562_Nanotechnology_Perceptions_ISSN_1660-6795_www/links/68366237df0e3f544f5b1a92/Nanotechnology-Perceptions-ISSN-1660-6795-www.pdf", "details": "TA Prasad", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence by achieving human-level performance in language understanding, generation, and reasoning. This paper provides a comprehensive technical analysis of LLMs \u2026"}, {"title": "Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic Languages", "link": "https://arxiv.org/pdf/2505.21937", "details": "PR Singh, K Prasad, M Zaki, P Wasnik - arXiv preprint arXiv:2505.21937, 2025", "abstract": "\u2026 In Figure 4, we have shown on average **LLM** **evaluation** for different models on various methods across languages. Notably, results for the IdiomKB baseline are shown only for the seen dataset, as IdiomKB supports only idioms present in the \u2026", "entry_id": "http://arxiv.org/abs/2505.21937v1", "updated": "2025-05-28 03:42:16", "published": "2025-05-28 03:42:16", "authors": "Pratik Rakesh Singh;Kritarth Prasad;Mohammadi Zaki;Pankaj Wasnik", "summary": "Translating multi-word expressions (MWEs) and idioms requires a deep\nunderstanding of the cultural nuances of both the source and target languages.\nThis challenge is further amplified by the one-to-many nature of idiomatic\ntranslations, where a single source idiom can have multiple target-language\nequivalents depending on cultural references and contextual variations.\nTraditional static knowledge graphs (KGs) and prompt-based approaches struggle\nto capture these complex relationships, often leading to suboptimal\ntranslations. To address this, we propose IdiomCE, an adaptive graph neural\nnetwork (GNN) based methodology that learns intricate mappings between\nidiomatic expressions, effectively generalizing to both seen and unseen nodes\nduring training. Our proposed method enhances translation quality even in\nresource-constrained settings, facilitating improved idiomatic translation in\nsmaller models. We evaluate our approach on multiple idiomatic translation\ndatasets using reference-less metrics, demonstrating significant improvements\nin translating idioms from English to various Indian languages.", "comment": null, "journal_ref": "ACL Findings 2025", "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.21937v1;http://arxiv.org/pdf/2505.21937v1", "pdf_url": "http://arxiv.org/pdf/2505.21937v1"}, {"title": "Neural language models as content analysis tools in psychology", "link": "https://www.tandfonline.com/doi/abs/10.1080/09515089.2025.2508942", "details": "A Acciai, L Guerrisi, A Plebe, R Suriano - Philosophical Psychology, 2025", "abstract": "\u2026 We proposed 30 out of 110 stories included in the **LLM** **evaluation** dataset to a selected group of human evaluators with expertise in psychology. The group, consisting of five individuals, includes psychology doctoral students, professionals \u2026"}]
