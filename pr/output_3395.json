[{"title": "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees", "link": "https://arxiv.org/pdf/2407.00499", "details": "Z Wang, J Duan, L Cheng, Y Zhang, Q Wang, H Shen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Uncertainty quantification (UQ) in natural language generation (NLG) tasks remains an open challenge, exacerbated by the intricate nature of the recent large language models (LLMs). This study investigates adapting conformal prediction (CP), which \u2026"}, {"title": "TMO-Net: an explainable pretrained multi-omics model for multi-task learning in oncology", "link": "https://genomebiology.biomedcentral.com/articles/10.1186/s13059-024-03293-9", "details": "F Wang, Z Zhuang, F Gao, R He, S Zhang, L Wang\u2026 - Genome Biology, 2024", "abstract": "Cancer is a complex disease composing systemic alterations in multiple scales. In this study, we develop the Tumor Multi-Omics pre-trained Network (TMO-Net) that integrates multi-omics pan-cancer datasets for model pre-training, facilitating cross \u2026"}]
