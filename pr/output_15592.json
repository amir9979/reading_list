[{"title": "Achieving GPT-4o level performance in astronomy with a specialized 8B-parameter large language model", "link": "https://www.nature.com/articles/s41598-025-97131-y", "details": "T de Haan, YS Ting, T Ghosal, TD Nguyen\u2026 - Scientific Reports, 2025", "abstract": "Abstract AstroSage-Llama-3.1-8B is a domain-specialized natural-language AI assistant tailored for research in astronomy, astrophysics, cosmology, and astronomical instrumentation. Trained on the complete collection of astronomy \u2026"}, {"title": "FarsEval-PKBETS: A new diverse benchmark for evaluating Persian large language models", "link": "https://arxiv.org/pdf/2504.14690", "details": "M Shamsfard, Z Saaberi, SMH Hashemi, Z Vatankhah\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Research on evaluating and analyzing large language models (LLMs) has been extensive for resource-rich languages such as English, yet their performance in languages such as Persian has received considerably less attention. This paper \u2026"}, {"title": "A Scalable Framework for Evaluating Health Language Models", "link": "https://arxiv.org/pdf/2503.23339", "details": "N Mallinar, AA Heydari, X Liu, AZ Faranesh, B Winslow\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have emerged as powerful tools for analyzing complex datasets. Recent studies demonstrate their potential to generate useful, personalized responses when provided with patient-specific health information that \u2026"}, {"title": "Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure", "link": "https://arxiv.org/pdf/2504.10049", "details": "T Gigant, C Guinaudeau, F Dufaux - arXiv preprint arXiv:2504.10049, 2025", "abstract": "Vision-Language Models (VLMs) can process visual and textual information in multiple formats: texts, images, interleaved texts and images, or even hour-long videos. In this work, we conduct fine-grained quantitative and qualitative analyses of \u2026"}, {"title": "Context and Layers in Harmony: A Unified Strategy for Mitigating LLM Hallucinations", "link": "https://www.preprints.org/frontend/manuscript/47a4a250e74296356b42f9c388872f2e/download_pub", "details": "S Yu, G Kim, S Kang - 2025", "abstract": "Large language models, despite their strong performance, frequently produce hallucinated content by excessively relying on pre-trained knowledge and overlooking newly provided prompts. We introduce LACD, a technique that \u2026"}, {"title": "SWI: Speaking with Intent in Large Language Models", "link": "https://arxiv.org/pdf/2503.21544%3F", "details": "Y Yin, EJ Hwang, G Carenini - arXiv preprint arXiv:2503.21544, 2025", "abstract": "Intent, typically clearly formulated and planned, functions as a cognitive framework for reasoning and problem-solving. This paper introduces the concept of Speaking with Intent (SWI) in large language models (LLMs), where the explicitly generated \u2026"}]
