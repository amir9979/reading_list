[{"title": "Neighbor Does Matter: Density-Aware Contrastive Learning for Medical Semi-supervised Segmentation", "link": "https://arxiv.org/pdf/2412.19871", "details": "F Tang, Z Xu, M Hu, W Li, P Xia, Y Zhong, H Wu, J Su\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In medical image analysis, multi-organ semi-supervised segmentation faces challenges such as insufficient labels and low contrast in soft tissues. To address these issues, existing studies typically employ semi-supervised segmentation \u2026"}, {"title": "UniMed-CLIP: Towards a Unified Image-Text Pretraining Paradigm for Diverse Medical Imaging Modalities", "link": "https://arxiv.org/pdf/2412.10372", "details": "MU Khattak, S Kunhimon, M Naseer, S Khan, FS Khan - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Models (VLMs) trained via contrastive learning have achieved notable success in natural image tasks. However, their application in the medical domain remains limited due to the scarcity of openly accessible, large-scale medical \u2026"}, {"title": "A Knowledge-enhanced Pathology Vision-language Foundation Model for Cancer Diagnosis", "link": "https://arxiv.org/pdf/2412.13126", "details": "X Zhou, L Sun, D He, W Guan, R Wang, L Wang, X Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Deep learning has enabled the development of highly robust foundation models for various pathological tasks across diverse diseases and patient cohorts. Among these models, vision-language pre-training, which leverages large-scale paired data to \u2026"}, {"title": "Graph contrastive learning with multiple information fusion", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424029968", "details": "X Wang, J Yang, Z Wang, D He, J Zhao, Y Huang, D Jin - Expert Systems with \u2026, 2024", "abstract": "Graph contrastive learning has been extensively studied and achieved great success in many graph downstream tasks. Currently, some works try to construct positive and negative samples in an augmented-free manner. However, most existing methods \u2026"}, {"title": "Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG", "link": "https://arxiv.org/pdf/2412.16086", "details": "HMT Alam, D Srivastav, MA Kadir, D Sonntag - arXiv preprint arXiv:2412.16086, 2024", "abstract": "Deep learning has advanced medical image classification, but interpretability challenges hinder its clinical adoption. This study enhances interpretability in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs) and a multi \u2026"}, {"title": "GraphCLIP: Image-graph contrastive learning for multimodal artwork classification", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124014916", "details": "R Scaringi, G Fiameni, G Vessio, G Castellano - Knowledge-Based Systems, 2024", "abstract": "We present GraphCLIP, a novel contrastive learning framework for multimodal artwork classification that integrates visual and contextual information to improve predictive accuracy and interpretability. Traditional computer vision methods often \u2026"}, {"title": "Label-template based Few-Shot Text Classification with Contrastive Learning", "link": "https://arxiv.org/pdf/2412.10110%3F", "details": "G Hou, S Cao, D Ouyang, N Wang - arXiv preprint arXiv:2412.10110, 2024", "abstract": "As an algorithmic framework for learning to learn, meta-learning provides a promising solution for few-shot text classification. However, most existing research fail to give enough attention to class labels. Traditional basic framework building \u2026"}, {"title": "Multi-Scale Contrastive Learning for Video Temporal Grounding", "link": "https://arxiv.org/pdf/2412.07157", "details": "TT Nguyen, Y Bin, X Wu, Z Hu, CDT Nguyen, SK Ng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Temporal grounding, which localizes video moments related to a natural language query, is a core problem of vision-language learning and video understanding. To encode video moments of varying lengths, recent methods employ a multi-level \u2026"}, {"title": "DomCLP: Domain-wise Contrastive Learning with Prototype Mixup for Unsupervised Domain Generalization", "link": "https://arxiv.org/pdf/2412.09074", "details": "JS Lee, N Kim, JH Lee - arXiv preprint arXiv:2412.09074, 2024", "abstract": "Self-supervised learning (SSL) methods based on the instance discrimination tasks with InfoNCE have achieved remarkable success. Despite their success, SSL models often struggle to generate effective representations for unseen-domain data. To \u2026"}]
