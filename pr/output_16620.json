[{"title": "HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics", "link": "https://arxiv.org/pdf/2505.05602", "details": "L Luettgau, H Coppock, M Dubois, C Summerfield\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "As Large Language Models (LLMs) and other AI systems evolve, robustly estimating their capabilities from inherently stochastic outputs while systematically quantifying uncertainty in these estimates becomes increasingly important. Further, advanced AI \u2026", "entry_id": "http://arxiv.org/abs/2505.05602v1", "updated": "2025-05-08 19:05:02", "published": "2025-05-08 19:05:02", "authors": "Lennart Luettgau;Harry Coppock;Magda Dubois;Christopher Summerfield;Cozmin Ududec", "summary": "As Large Language Models (LLMs) and other AI systems evolve, robustly\nestimating their capabilities from inherently stochastic outputs while\nsystematically quantifying uncertainty in these estimates becomes increasingly\nimportant. Further, advanced AI evaluations often have a nested hierarchical\nstructure, exhibit high levels of complexity, and come with high costs in\ntesting the most advanced AI systems. To address these challenges, we introduce\nHiBayES, a generalizable Hierarchical Bayesian modeling framework for AI\nEvaluation Statistics. HiBayES supports robust inferences in classical\nquestion-answer benchmarks and advanced agentic evaluations, particularly in\nlow-data scenarios (e.g., < 20 data points per evaluation). Built on\nGeneralized Linear Models (GLMs), Bayesian data analysis, and formal model\ncomparison, HiBayES provides principled uncertainty quantification and robust\nparameter estimation. This paper offers a comprehensive introduction to\nHiBayES, including illustrative examples, comparisons to conventional\nstatistical methods, and practical guidance for implementing multilevel\nBayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta\nversion) for out-of-the-box implementation.", "comment": "23 pages, 9 figures", "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI;stat.AP", "links": "http://arxiv.org/abs/2505.05602v1;http://arxiv.org/pdf/2505.05602v1", "pdf_url": "http://arxiv.org/pdf/2505.05602v1"}, {"title": "Evaluating Logical Reasoning Ability of Large Language Models", "link": "https://www.preprints.org/frontend/manuscript/9e037bed340c892b7e0f2084f1f17252/download_pub", "details": "E Chan - 2025", "abstract": "Large language models (LLMs) such as ChatGPT and DeepSeek have recently made significant progress in natural language processing, demonstrating reasoning ability close to human intelligence. This has sparked considerable research interest \u2026"}]
