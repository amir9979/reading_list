[{"title": "Evolution-based Region Adversarial Prompt Learning for Robustness Enhancement in Vision-Language Models", "link": "https://arxiv.org/pdf/2503.12874", "details": "X Jia, S Gao, S Qin, K Ma, X Li, Y Huang, W Dong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large pre-trained vision-language models (VLMs), such as CLIP, demonstrate impressive generalization but remain highly vulnerable to adversarial examples (AEs). Previous work has explored robust text prompts through adversarial training \u2026"}, {"title": "Machine-assisted writing evaluation: Exploring pre-trained language models in analyzing argumentative moves", "link": "https://arxiv.org/pdf/2503.19279", "details": "W Qin, W Wang, Y Yang, T Gui - arXiv preprint arXiv:2503.19279, 2025", "abstract": "The study investigates the efficacy of pre-trained language models (PLMs) in analyzing argumentative moves in a longitudinal learner corpus. Prior studies on argumentative moves often rely on qualitative analysis and manual coding, limiting \u2026"}, {"title": "Integrating Large Language Models with Human Expertise for Disease Detection in Electronic Health Records", "link": "https://arxiv.org/pdf/2504.00053", "details": "J Pan, S Lee, C Cheligeer, EA Martin, K Riazi, H Quan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Objective: Electronic health records (EHR) are widely available to complement administrative data-based disease surveillance and healthcare performance evaluation. Defining conditions from EHR is labour-intensive and requires extensive \u2026"}, {"title": "Adapting Large Language Models for Multi-Domain Retrieval-Augmented-Generation", "link": "https://arxiv.org/pdf/2504.02411", "details": "A Misrahi, N Chirkova, M Louis, V Nikoulina - arXiv preprint arXiv:2504.02411, 2025", "abstract": "Retrieval-Augmented Generation (RAG) enhances LLM factuality, but multi-domain applications face challenges like lack of diverse benchmarks and poor out-of-domain generalization. The first contribution of this work is to introduce a diverse benchmark \u2026"}]
