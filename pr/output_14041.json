[{"title": "A Survey on Feedback-based Multi-step Reasoning for Large Language Models on Mathematics", "link": "https://arxiv.org/pdf/2502.14333", "details": "TR Wei, H Liu, X Wu, Y Fang - arXiv preprint arXiv:2502.14333, 2025", "abstract": "Recent progress in large language models (LLM) found chain-of-thought prompting strategies to improve the reasoning ability of LLMs by encouraging problem solving through multiple steps. Therefore, subsequent research aimed to integrate the multi \u2026"}, {"title": "A survey on large language models for automated planning", "link": "https://arxiv.org/pdf/2502.12435", "details": "M Aghzal, E Plaku, GJ Stein, Z Yao - arXiv preprint arXiv:2502.12435, 2025", "abstract": "The planning ability of Large Language Models (LLMs) has garnered increasing attention in recent years due to their remarkable capacity for multi-step reasoning and their ability to generalize across a wide range of domains. While some \u2026"}, {"title": "DBR: Divergence-Based Regularization for Debiasing Natural Language Understanding Models", "link": "https://arxiv.org/pdf/2502.18353", "details": "Z Li, R Tang, L Cheng, S Wang, D Yin, M Du - arXiv preprint arXiv:2502.18353, 2025", "abstract": "Pre-trained language models (PLMs) have achieved impressive results on various natural language processing tasks. However, recent research has revealed that these models often rely on superficial features and shortcuts instead of developing a \u2026"}, {"title": "QA-Calibration of language model confidence scores", "link": "https://www.amazon.science/publications/qa-calibration-of-language-model-confidence-scores", "details": "A Mastakouri, E Kirschbaum, S Kasiviswanathan\u2026 - 2025", "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim \u2026"}]
