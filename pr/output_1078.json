'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [FairPair: A Robust Evaluation of Biases in Language Mo'
[{"title": "Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data", "link": "https://arxiv.org/pdf/2404.03862", "details": "J Zhang, M Marone, T Li, B Van Durme, D Khashabi - arXiv preprint arXiv:2404.03862, 2024", "abstract": "For humans to trust the fluent generations of large language models (LLMs), they must be able to verify their correctness against trusted, external sources. Recent efforts aim to increase verifiability through citations of retrieved documents or post \u2026"}, {"title": "Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models", "link": "https://arxiv.org/pdf/2405.01535", "details": "S Kim, J Suk, S Longpre, BY Lin, J Shin, S Welleck\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Proprietary LMs such as GPT-4 are often employed to assess the quality of responses from various LMs. However, concerns including transparency, controllability, and affordability strongly motivate the development of open-source \u2026"}, {"title": "CodecLM: Aligning Language Models with Tailored Synthetic Data", "link": "https://arxiv.org/pdf/2404.05875", "details": "Z Wang, CL Li, V Perot, LT Le, J Miao, Z Zhang, CY Lee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next- token prediction objective and users' actual goals. To reduce the labor and time cost \u2026"}, {"title": "Continuous patient state attention model for addressing irregularity in electronic health records", "link": "https://link.springer.com/article/10.1186/s12911-024-02514-2", "details": "VK Chauhan, A Thakur, O O'Donoghue, O Rohanian\u2026 - BMC Medical Informatics \u2026, 2024", "abstract": "Background Irregular time series (ITS) are common in healthcare as patient data is recorded in an electronic health record (EHR) system as per clinical guidelines/ requirements but not for research and depends on a patient's health status. Due to \u2026"}, {"title": "Speech Recognition for Indigenous Language Using Self-Supervised Learning and Natural Language Processing", "link": "https://www.scitepress.org/Papers/2024/123963/123963.pdf", "details": "S Tamura, T Hattori, Y Kato, N Noguchi", "abstract": "This paper proposes a new concept to build a speech recognition system for an indigenous under-resourced language, by using another speech recognizer for a major language as well as neural machine translation and text autoencoder \u2026"}, {"title": "Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think", "link": "https://arxiv.org/pdf/2404.08382", "details": "X Wang, C Hu, B Ma, P R\u00f6ttger, B Plank - arXiv preprint arXiv:2404.08382, 2024", "abstract": "Multiple choice questions (MCQs) are commonly used to evaluate the capabilities of large language models (LLMs). One common way to evaluate the model response is to rank the candidate answers based on the log probability of the first token \u2026"}, {"title": "Calibrating Language Models With Adaptive Temperature Scaling", "link": "https://openreview.net/pdf%3Fid%3DBgfGqNpoMi", "details": "J Xie, AS Chen, Y Lee, E Mitchell, C Finn - ICLR 2024 Workshop on Secure and Trustworthy \u2026", "abstract": "The effectiveness of large language models (LLMs) is not only measured by their ability to generate accurate outputs but also by their calibration\u2014how well their confidence scores reflect the probability of their outputs being correct. While \u2026"}, {"title": "Beyond Internet Images: Evaluating Vision-Language Models for Domain Generalization on Synthetic-to-Real Industrial Datasets", "link": "https://openreview.net/pdf%3Fid%3DBgpApqspGw", "details": "L H\u00e9madou, H Vorobieva, E Kijak, F Jurie - Synthetic Data for Computer Vision Workshop \u2026", "abstract": "Vision Language Foundation Models (VLFMs) have shown impressive generalization capabilities, making them suitable for Domain Generalization (DG) tasks, such as training on synthetic images and testing on real data. However \u2026"}, {"title": "Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation", "link": "https://arxiv.org/pdf/2404.08491", "details": "H Zhao, Z Cai, S Si, L Chen, Y He, K An, B Chang - arXiv preprint arXiv:2404.08491, 2024", "abstract": "Large-scale multilingual Pretrained Language Models (mPLMs) yield impressive performance on cross-language tasks, yet significant performance disparities exist across different languages within the same mPLM. Previous studies endeavored to \u2026"}]
