[{"title": "ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts", "link": "https://arxiv.org/pdf/2506.06192", "details": "D Proios, A Bornet, A Yazdani, JF Rodrigues Jr\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Patient stratification identifying clinically meaningful subgroups is essential for advancing personalized medicine through improved diagnostics and treatment strategies. Electronic health records (EHRs), particularly those from intensive care \u2026", "entry_id": "http://arxiv.org/abs/2506.06192v1", "updated": "2025-06-06 15:52:50", "published": "2025-06-06 15:52:50", "authors": "Dimitrios Proios;Alban Bornet;Anthony Yazdani;Jose F Rodrigues Jr;Douglas Teodoro", "summary": "Patient stratification identifying clinically meaningful subgroups is\nessential for advancing personalized medicine through improved diagnostics and\ntreatment strategies. Electronic health records (EHRs), particularly those from\nintensive care units (ICUs), contain rich temporal clinical data that can be\nleveraged for this purpose. In this work, we introduce ICU-TSB (Temporal\nStratification Benchmark), the first comprehensive benchmark for evaluating\npatient stratification based on temporal patient representation learning using\nthree publicly available ICU EHR datasets. A key contribution of our benchmark\nis a novel hierarchical evaluation framework utilizing disease taxonomies to\nmeasure the alignment of discovered clusters with clinically validated disease\ngroupings. In our experiments with ICU-TSB, we compared statistical methods and\nseveral recurrent neural networks, including LSTM and GRU, for their ability to\ngenerate effective patient representations for subsequent clustering of patient\ntrajectories. Our results demonstrate that temporal representation learning can\nrediscover clinically meaningful patient cohorts; nevertheless, it remains a\nchallenging task, with v-measuring varying from up to 0.46 at the top level of\nthe taxonomy to up to 0.40 at the lowest level. To further enhance the\npractical utility of our findings, we also evaluate multiple strategies for\nassigning interpretable labels to the identified clusters. The experiments and\nbenchmark are fully reproducible and available at\nhttps://github.com/ds4dh/CBMS2025stratification.", "comment": "6 pages 1 table 6 figures", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2506.06192v1;http://arxiv.org/pdf/2506.06192v1", "pdf_url": "http://arxiv.org/pdf/2506.06192v1"}, {"title": "Harnessing Vision-Language Models for Time Series Anomaly Detection", "link": "https://arxiv.org/pdf/2506.06836", "details": "Z He, S Alnegheimish, M Reimherr - arXiv preprint arXiv:2506.06836, 2025", "abstract": "Time-series anomaly detection (TSAD) has played a vital role in a variety of fields, including healthcare, finance, and industrial monitoring. Prior methods, which mainly focus on training domain-specific models on numerical data, lack the visual-temporal \u2026", "entry_id": "http://arxiv.org/abs/2506.06836v1", "updated": "2025-06-07 15:27:30", "published": "2025-06-07 15:27:30", "authors": "Zelin He;Sarah Alnegheimish;Matthew Reimherr", "summary": "Time-series anomaly detection (TSAD) has played a vital role in a variety of\nfields, including healthcare, finance, and industrial monitoring. Prior\nmethods, which mainly focus on training domain-specific models on numerical\ndata, lack the visual-temporal reasoning capacity that human experts have to\nidentify contextual anomalies. To fill this gap, we explore a solution based on\nvision language models (VLMs). Recent studies have shown the ability of VLMs\nfor visual reasoning tasks, yet their direct application to time series has\nfallen short on both accuracy and efficiency. To harness the power of VLMs for\nTSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening\nstage built on a relatively lightweight pretrained vision encoder, which\nleverages 2-D time-series representations to accurately localize candidate\nanomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal\ncontext and VLM reasoning capacity to refine the detection upon the candidates\nprovided by ViT4TS. We show that without any time-series training, VLM4TS\noutperforms time-series pretrained and from-scratch baselines in most cases,\nyielding a 24.6 percent improvement in F1-max score over the best baseline.\nMoreover, VLM4TS also consistently outperforms existing language-model-based\nTSAD methods and is on average 36 times more efficient in token usage.", "comment": null, "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.AI;cs.LG", "links": "http://arxiv.org/abs/2506.06836v1;http://arxiv.org/pdf/2506.06836v1", "pdf_url": "http://arxiv.org/pdf/2506.06836v1"}, {"title": "Robust self-supervised machine learning for single cell embeddings and annotations", "link": "https://www.biorxiv.org/content/biorxiv/early/2025/06/08/2025.06.05.658097.full.pdf", "details": "CY Yeh, MW Sun, D Zhu, L Jerby - bioRxiv, 2025", "abstract": "Dimensionality reduction and clustering are critical steps in single-cell and spatial genomics studies. Here, we show that existing dimensionality reduction and clustering methods suffer from:(1) overfitting to the dominant patterns while missing \u2026"}, {"title": "Features fusion or not: harnessing multiple pathological foundation models using Meta-Encoder for downstream tasks fine-tuning", "link": "https://www.biorxiv.org/content/10.1101/2025.06.05.657960.full.pdf", "details": "R Gao, Z Yang, X Yuan, Y Wang, Y Xia, Y Zhang\u2026 - bioRxiv, 2025", "abstract": "The emergence of diverse pathological foundation models has empowered computational pathology tasks, including tumor classification, biomarker prediction, and RNA expression prediction. However, variations in model architecture and data \u2026"}]
