[{"title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge", "link": "https://arxiv.org/pdf/2407.19594", "details": "T Wu, W Yuan, O Golovneva, J Xu, Y Tian, J Jiao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains. While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can \u2026"}, {"title": "Explainable spatio-temporal graph evolution learning with applications to dynamic brain network analysis during development", "link": "https://www.sciencedirect.com/science/article/pii/S1053811924002684", "details": "L Chen, C Qiao, K Ren, G Qu, VD Calhoun\u2026 - NeuroImage, 2024", "abstract": "Modeling dynamic interactions among network components is crucial to uncovering the evolution mechanisms of complex networks. Recently, spatio-temporal graph learning methods have achieved noteworthy results in characterizing the dynamic \u2026"}, {"title": "Language Driven Slice Discovery and Error Rectification", "link": "https://arxiv.org/pdf/2408.07832", "details": "S Ghosh, C Wang, K Batmanghelich - arXiv preprint arXiv:2408.07832, 2024", "abstract": "Error slice discovery associates structured patterns with model errors. Existing methods discover error slices by clustering the error-prone samples with similar patterns or assigning discrete attributes to each sample for post-hoc analysis. While \u2026"}, {"title": "Federated Fairness Analytics: Quantifying Fairness in Federated Learning", "link": "https://arxiv.org/pdf/2408.08214", "details": "O Dilley, JM Parra-Ullauri, R Hussain, D Simeonidou - arXiv preprint arXiv \u2026, 2024", "abstract": "Federated Learning (FL) is a privacy-enhancing technology for distributed ML. By training models locally and aggregating updates-a federation learns together, while bypassing centralised data collection. FL is increasingly popular in healthcare \u2026"}, {"title": "Diversification of Adaptive Policy for Effective Offline Reinforcement Learning", "link": "https://www.ijcai.org/proceedings/2024/0427.pdf", "details": "Y Choi, L Zhao, C Zhang, L Song, J Bian, KE Kim", "abstract": "Abstract Offline Reinforcement Learning (RL) aims to learn policies from pre- collected datasets that capture only a subset of the environment's dynamics. The predominant approach has been to solve a constrained optimization formulation \u2026"}, {"title": "A Comprehensive View of Personalized Federated Learning on Heterogeneous Clinical Datasets", "link": "https://openreview.net/pdf%3Fid%3DbtijACJ4QU", "details": "A Verma, F Razak - 2024", "abstract": "Federated learning (FL) is increasingly being recognized as a key approach to overcoming the data silos that so frequently obstruct the training and deployment of machine-learning models in clinical settings. This work contributes to a growing body \u2026"}, {"title": "Evaluating the necessity of the multiple metrics for assessing explainable AI: A critical examination", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224010531", "details": "M Pawlicki, A Pawlicka, F Uccello, S Szelest\u2026 - Neurocomputing, 2024", "abstract": "This paper investigates the specific properties of Explainable Artificial Intelligence (xAI), particularly when implemented in AI/ML models across high-stakes sectors, in this case cybersecurity. The authors execute a comprehensive systematic review of \u2026"}, {"title": "MixPrompt: Enhancing Generalizability and Adversarial Robustness for Vision-Language Models via Prompt Fusion", "link": "https://link.springer.com/chapter/10.1007/978-981-97-5606-3_28", "details": "H Fan, Z Ma, Y Li, R Tian, Y Chen, C Gao - International Conference on Intelligent \u2026, 2024", "abstract": "Abstract Pretrained Vision-Language Models (VLMs) like CLIP have exhibited remarkable capacities across downstream tasks, while their image encoders are vulnerable to adversarial examples. A recently introduced lightweight approach \u2026"}, {"title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education", "link": "https://arxiv.org/pdf/2407.17022", "details": "S Kim, S Kim - arXiv preprint arXiv:2407.17022, 2024", "abstract": "Large language model (LLM)-based evaluation pipelines have demonstrated their capability to robustly evaluate machine-generated text. Extending this methodology to assess human-written text could significantly benefit educational settings by \u2026"}]
