[{"title": "Looking at Model Debiasing through the Lens of Anomaly Detection", "link": "https://arxiv.org/pdf/2407.17449", "details": "VP Pastore, M Ciranni, D Marinelli, F Odone, V Murino - arXiv preprint arXiv \u2026, 2024", "abstract": "It is widely recognized that deep neural networks are sensitive to bias in the data. This means that during training these models are likely to learn spurious correlations between data and labels, resulting in limited generalization abilities and low \u2026"}, {"title": "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.03560", "details": "AS Joaquin, B Wang, Z Liu, N Asher, B Lim, P Muller\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite advancements, fine-tuning Large Language Models (LLMs) remains costly due to the extensive parameter count and substantial data requirements for model generalization. Accessibility to computing resources remains a barrier for the open \u2026"}, {"title": "A Systematic Evaluation of GPT-4V's Multimodal Capability for Chest X-ray Image Analysis", "link": "https://www.sciencedirect.com/science/article/pii/S2950162824000535", "details": "Y Liu, Y Li, Z Wang, X Liang, L Liu, L Wang, L Cui, Z Tu\u2026 - Meta-Radiology, 2024", "abstract": "This work evaluates GPT-4V's multimodal capability for medical image analysis, focusing on three representative tasks radiology report generation, medical visual question answering, and medical visual grounding. For the evaluation, a set of \u2026"}, {"title": "EVLM: An Efficient Vision-Language Model for Visual Understanding", "link": "https://arxiv.org/pdf/2407.14177", "details": "K Chen, D Shen, H Zhong, H Zhong, K Xia, D Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the field of multi-modal language models, the majority of methods are built on an architecture similar to LLaVA. These models use a single-layer ViT feature as a visual prompt, directly feeding it into the language models alongside textual tokens \u2026"}, {"title": "AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization", "link": "https://arxiv.org/pdf/2407.11591", "details": "A Afzal, R Chalumattu, F Matthes, LM Espuny - arXiv preprint arXiv:2407.11591, 2024", "abstract": "Despite the advances in the abstractive summarization task using Large Language Models (LLM), there is a lack of research that asses their abilities to easily adapt to different domains. We evaluate the domain adaptation abilities of a wide range of \u2026"}, {"title": "L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks", "link": "https://dl.acm.org/doi/abs/10.1145/3638530.3664121", "details": "P Guo, F Liu, X Lin, Q Zhao, Q Zhang - Proceedings of the Genetic and Evolutionary \u2026, 2024", "abstract": "In the rapidly evolving field of machine learning, adversarial attacks pose a significant threat to the robustness and security of models. Amongst these, decision- based attacks are particularly insidious due to their nature of requiring only the \u2026"}, {"title": "MindLLM: Lightweight large language model pre-training, evaluation and domain application", "link": "https://www.sciencedirect.com/science/article/pii/S2666651024000111", "details": "Y Yang, H Sun, J Li, R Liu, Y Li, Y Liu, Y Gao, H Huang - AI Open, 2024", "abstract": "Abstract Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is \u2026"}, {"title": "Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment", "link": "https://arxiv.org/pdf/2407.10804", "details": "J Jiang, J Li, WX Zhao, Y Song, T Zhang, JR Wen - arXiv preprint arXiv:2407.10804, 2024", "abstract": "Adapting general large language models (LLMs) to specialized domains presents great challenges due to varied data distributions. This adaptation typically requires continual pre-training on massive domain-specific corpora to facilitate knowledge \u2026"}, {"title": "Model-Agnostic Causal Embedding Learning for Counterfactually Group-Fair Recommendation", "link": "https://ieeexplore.ieee.org/abstract/document/10598228/", "details": "X Zhang, T Shi, J Xu, Z Dong, JR Wen - IEEE Transactions on Knowledge and Data \u2026, 2024", "abstract": "Group-fair recommendation aims at ensuring the equality of recommendation results across user groups categorized by sensitive attributes (eg, gender, occupation, etc.). Existing group-fair recommendation models traditionally employ original user \u2026"}]
