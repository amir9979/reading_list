[{"title": "Multi-Modal Information Bottleneck Attribution with Cross-Attention Guidance", "link": "https://bmva-archive.org.uk/bmvc/2024/papers/Paper_64/paper.pdf", "details": "P Bourigault, E Bourigault, DP Mandic - 2024", "abstract": "For the progression of interpretable machine learning, particularly in the intersection of vision and language, ensuring transparency and comprehensibility in model decisions is crucial. This work introduces an enhancement to the Multi-modal \u2026"}, {"title": "Lightweight convolutional neural network for chest X-ray images classification", "link": "https://www.nature.com/articles/s41598-024-80826-z", "details": "CT Yen, CY Tsao - Scientific Reports, 2024", "abstract": "In this study, we developed a lightweight and rapid convolutional neural network (CNN) architecture for chest X-ray images; it primarily consists of a redesigned feature extraction (FE) module and multiscale feature (MF) module and validated \u2026"}, {"title": "Enhancing Radiology Report Generation: The Impact of Locally Grounded Vision and Language Training", "link": "https://bmva-archive.org.uk/bmvc/2024/papers/Paper_857/paper.pdf", "details": "SS Santiesteban, M Awais, YZ Song, J Kittler - 2024", "abstract": "In the medical domain, the integration of multimodal data\u2014specifically radiology images paired with corresponding reports\u2014presents a valuable opportunity for enhanced diagnostics. Recently, there has been growing interest in using \u2026"}]
