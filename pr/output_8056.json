[{"title": "Simulating clinical features on chest radiographs for medical image exploration and CNN explainability using a style-based generative adversarial autoencoder", "link": "https://www.nature.com/articles/s41598-024-75886-0", "details": "KA Hasenstab, L Hahn, N Chao, A Hsiao - Scientific Reports, 2024", "abstract": "Explainability of convolutional neural networks (CNNs) is integral for their adoption into radiological practice. Commonly used attribution methods localize image areas important for CNN prediction but do not characterize relevant imaging features \u2026"}, {"title": "Structural Causality-based Generalizable Concept Discovery Models", "link": "https://arxiv.org/pdf/2410.15491", "details": "S Sinha, G Xiong, A Zhang - arXiv preprint arXiv:2410.15491, 2024", "abstract": "The rising need for explainable deep neural network architectures has utilized semantic concepts as explainable units. Several approaches utilizing disentangled representation learning estimate the generative factors and utilize them as concepts \u2026"}, {"title": "HiLite: Hierarchical Level-implemented Architecture Attaining Part-Whole Interpretability", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679538", "details": "YH Jeong, S Hwang, DK Chae - Proceedings of the 33rd ACM International \u2026, 2024", "abstract": "Beyond the traditional CNN structure, we have recently witnessed lots of breakthroughs in computer vision architectures such as Vision Transformer, MLP- Mixer, SNN-MLP, and so on. However, many efforts in developing novel \u2026"}, {"title": "Incremental Image Generation with Diffusion Models by Label Embedding Initialization and Fusion", "link": "https://dl.acm.org/doi/abs/10.1145/3688859.3690084", "details": "B Li, D Ren, H Liu, TH Yu, C Peng, Y Gao - Proceedings of the 1st on Continual \u2026, 2024", "abstract": "Recent diffusion models have excelled in image generation, but adapting them incrementally to new, unseen classes remains difficult. This paper presents LeifDM, an incremental diffusion model that efficiently adapts pre-trained models to new \u2026"}]
