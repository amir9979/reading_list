[{"title": "Classification of fundus autofluorescence images based on macular function in retinitis pigmentosa using convolutional neural networks", "link": "https://link.springer.com/article/10.1007/s10384-025-01163-w", "details": "T Kominami, S Ueno, J Ota, T Inooka, M Oda, K Mori\u2026 - Japanese Journal of \u2026, 2025", "abstract": "Purpose To determine whether convolutional neural networks (CNN) can classify the severity of central vision loss using fundus autofluorescence (FAF) images and color fundus images of retinitis pigmentosa (RP), and to evaluate the utility of those images \u2026"}, {"title": "Scaling Pre-training to One Hundred Billion Data for Vision Language Models", "link": "https://arxiv.org/pdf/2502.07617", "details": "X Wang, I Alabdulmohsin, D Salz, Z Li, K Rong, X Zhai - arXiv preprint arXiv \u2026, 2025", "abstract": "We provide an empirical investigation of the potential of pre-training vision-language models on an unprecedented scale: 100 billion examples. We find that model performance tends to saturate at this scale on many common Western-centric \u2026"}, {"title": "Policing the Boundary Between Responsible and Irresponsible Placing on the Market of LLM Health Applications", "link": "https://www.sciencedirect.com/science/article/pii/S2949761225000033", "details": "O Freyer, IC Wiest, S Gilbert - Mayo Clinic Proceedings: Digital Health, 2025", "abstract": "Health applications based on the technology of foundation models, specifically large language models (LLMs) 1, referred to as LLM-based health applications (LLM-HA), are an evolving phenomenon with some initial commercial products already on the \u2026"}, {"title": "MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs", "link": "https://arxiv.org/pdf/2502.07221", "details": "Q Zhou, TM Dang, W Zhong, Y Guo, H Ma, S Na\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Pathology plays a critical role in diagnosing a wide range of diseases, yet existing approaches often rely heavily on task-specific models trained on extensive, well- labeled datasets. These methods face sustainability challenges due to the diversity \u2026"}, {"title": "MammoVLM: A generative large vision-language model for mammography-related diagnostic assistance", "link": "https://www.sciencedirect.com/science/article/pii/S1566253525000715", "details": "Z Cao, Z Deng, J Ma, J Hu, L Ma - Information Fusion, 2025", "abstract": "Inspired by the recent success of large language models (LLMs) in the general domain, many large multimodal models, such as vision-language models, have been developed to tackle problems across modalities. In the realm of breast cancer, which \u2026"}]
