[{"title": "Block diffusion: Interpolating between autoregressive and diffusion language models", "link": "https://arxiv.org/pdf/2503.09573%3F", "details": "M Arriola, A Gokaslan, JT Chiu, Z Yang, Z Qi, J Han\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Diffusion language models offer unique benefits over autoregressive models due to their potential for parallelized generation and controllability, yet they lag in likelihood modeling and are limited to fixed-length generation. In this work, we introduce a \u2026"}, {"title": "VALIDATION OF NATURAL LANGUAGE PROCESSING FOR SURGICAL COMPLICATION SURVEILLANCE: DETECTING ELEVEN POSTOPERATIVE \u2026", "link": "https://www.medrxiv.org/content/10.1101/2025.04.07.25325367.full.pdf", "details": "EE Dencker, A Bonde, A Troelsen, M Sillesen - medRxiv, 2025", "abstract": "Background Postoperative complications (PCs) rates are crucial quality metrics in surgery, as they reflect both patient outcomes, perioperative care effectiveness and healthcare resource strain. Despite their importance, efficient, accurate, and \u2026"}, {"title": "Cross-Lingual Consistency: A Novel Inference Framework for Advancing Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2504.01857", "details": "Z Yu, T Li, C Wang, H Chen, L Zhou - arXiv preprint arXiv:2504.01857, 2025", "abstract": "Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing reasoning capabilities in large language models (LLMs), with self-consistency demonstrating notable promise in boosting performance. However, inherent \u2026"}]
