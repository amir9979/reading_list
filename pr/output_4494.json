[{"title": "The Oscars of AI Theater: A Survey on Role-Playing with Language Models", "link": "https://arxiv.org/pdf/2407.11484", "details": "N Chen, Y Wang, Y Deng, J Li - arXiv preprint arXiv:2407.11484, 2024", "abstract": "This survey explores the burgeoning field of role-playing with language models, focusing on their development from early persona-based models to advanced character-driven simulations facilitated by Large Language Models (LLMs). Initially \u2026"}, {"title": "Improving Context-Aware Preference Modeling for Language Models", "link": "https://arxiv.org/pdf/2407.14916", "details": "S Pitis, Z Xiao, NL Roux, A Sordoni - arXiv preprint arXiv:2407.14916, 2024", "abstract": "While finetuning language models from pairwise preferences has proven remarkably effective, the underspecified nature of natural language presents critical challenges. Direct preference feedback is uninterpretable, difficult to provide where \u2026"}, {"title": "Perceptions of Linguistic Uncertainty by Language Models and Humans", "link": "https://arxiv.org/pdf/2407.15814", "details": "CG Belem, M Kelly, M Steyvers, S Singh, P Smyth - arXiv preprint arXiv:2407.15814, 2024", "abstract": "Uncertainty expressions such as``probably''or``highly unlikely''are pervasive in human language. While prior work has established that there is population-level agreement in terms of how humans interpret these expressions, there has been little \u2026"}, {"title": "Language models are robotic planners: reframing plans as goal refinement graphs", "link": "https://arxiv.org/pdf/2407.15677", "details": "A Sharfuddin, T Breaux - arXiv preprint arXiv:2407.15677, 2024", "abstract": "Successful application of large language models (LLMs) to robotic planning and execution may pave the way to automate numerous real-world tasks. Promising recent research has been conducted showing that the knowledge contained in LLMs \u2026"}, {"title": "MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2407.11681", "details": "H Cheng, M Zhang, JQ Shi - arXiv preprint arXiv:2407.11681, 2024", "abstract": "As Large Language Models (LLMs) grow dramatically in size, there is an increasing trend in compressing and speeding up these models. Previous studies have highlighted the usefulness of gradients for importance scoring in neural network \u2026"}, {"title": "Imposter. AI: Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models", "link": "https://arxiv.org/pdf/2407.15399", "details": "X Liu, L Li, T Xiang, F Ye, L Wei, W Li, N Garcia - arXiv preprint arXiv:2407.15399, 2024", "abstract": "With the development of large language models (LLMs) like ChatGPT, both their vast applications and potential vulnerabilities have come to the forefront. While developers have integrated multiple safety mechanisms to mitigate their misuse, a \u2026"}, {"title": "Causal-driven Large Language Models with Faithful Reasoning for Knowledge Question Answering", "link": "https://openreview.net/pdf%3Fid%3DcuWUx0RzgC", "details": "J Wang, D Cao, S Lu, Z Ma, J Xiao, TS Chua - ACM Multimedia 2024", "abstract": "In Large Language Models (LLMs), text generation that involves knowledge representation is often fraught with the risk of''hallucinations'', where models confidently produce erroneous or fabricated content. These inaccuracies often stem \u2026"}, {"title": "Reinforced Prompt Personalization for Recommendation with Large Language Models", "link": "https://arxiv.org/pdf/2407.17115", "details": "W Mao, J Wu, W Chen, C Gao, X Wang, X He - arXiv preprint arXiv:2407.17115, 2024", "abstract": "Designing effective prompts can empower LLMs to understand user preferences and provide recommendations by leveraging LLMs' intent comprehension and knowledge utilization capabilities. However, existing research predominantly \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}]
