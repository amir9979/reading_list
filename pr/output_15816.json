[{"title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation", "link": "https://arxiv.org/pdf/2504.02438", "details": "C Cheng, J Guan, W Wu, R Yan - arXiv preprint arXiv:2504.02438, 2025", "abstract": "Long-form video processing fundamentally challenges vision-language models (VLMs) due to the high computational costs of handling extended temporal sequences. Existing token pruning and feature merging methods often sacrifice \u2026"}, {"title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "link": "https://arxiv.org/pdf/2504.19467", "details": "J Wu, B Gu, R Zhou, K Xie, D Snyder, Y Jiang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) hold great promise for medical applications and are evolving rapidly, with new models being released at an accelerated pace. However, current evaluations of LLMs in clinical contexts remain limited. Most existing \u2026"}, {"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}, {"title": "VI3NR: Variance Informed Initialization for Implicit Neural Representations", "link": "https://arxiv.org/pdf/2504.19270", "details": "CH Koneputugodage, Y Ben-Shabat, S Ramasinghe\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Implicit Neural Representations (INRs) are a versatile and powerful tool for encoding various forms of data, including images, videos, sound, and 3D shapes. A critical factor in the success of INRs is the initialization of the network, which can significantly \u2026"}, {"title": "SpecialtyScribe: Enhancing SOAP note Scribing for Medical Specialties using LLM's", "link": "https://aclanthology.org/2025.cl4health-1.4.pdf", "details": "S Goyal, E Rastogi, F Zhao, D Yuan, A Beinstein - \u2026 of the Second Workshop on Patient \u2026, 2025", "abstract": "The healthcare industry has accumulated vast amounts of clinical data, much of which has traditionally been unstructured, including medical records, clinical data, patient communications, and visit notes. Clinician-patient conversations form a \u2026"}, {"title": "Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models", "link": "https://arxiv.org/pdf/2504.19061", "details": "AB Das, S Ahmed, SK Sakib - arXiv preprint arXiv:2504.19061, 2025", "abstract": "Clinical summarization is crucial in healthcare as it distills complex medical data into digestible information, enhancing patient understanding and care management. Large language models (LLMs) have shown significant potential in automating and \u2026"}, {"title": "Aligning Language Models for Icelandic Legal Text Summarization", "link": "https://arxiv.org/pdf/2504.18180", "details": "\u00deH Har\u00f0arson, H Loftsson, S \u00d3lafsson - arXiv preprint arXiv:2504.18180, 2025", "abstract": "The integration of language models in the legal domain holds considerable promise for streamlining processes and improving efficiency in managing extensive workloads. However, the specialized terminology, nuanced language, and formal \u2026"}, {"title": "Entity Pair-guided Relation Summarization and Retrieval in LLMs for Document-level Relation Extraction", "link": "https://aclanthology.org/2025.findings-naacl.224.pdf", "details": "F Zhang, H Yu, J Cheng, H Xu - Findings of the Association for Computational \u2026, 2025", "abstract": "Document-level relation extraction (DocRE) aims to extract relations between entities in a document. While previous research has primarily focused on traditional small models, recent studies have extended the scope to large language models (LLMs) \u2026"}, {"title": "Can dependency parses facilitate generalization in language models? A case study of cross-lingual relation extraction", "link": "https://aclanthology.org/2025.knowledgenlp-1.28.pdf", "details": "R Dutt, S Sural, C Rose - Proceedings of the 4th International Workshop on \u2026, 2025", "abstract": "In this work, we propose DEPGEN, a framework for evaluating the generalization capabilities of language models on the task of relation extraction, with dependency parses as scaffolds. We use a GNN-based framework that takes dependency parses \u2026"}]
