[{"title": "Learning local discrete features in explainable-by-design convolutional neural networks", "link": "https://arxiv.org/pdf/2411.00139", "details": "PI Kaplanoglou, K Diamantaras - arXiv preprint arXiv:2411.00139, 2024", "abstract": "Our proposed framework attempts to break the trade-off between performance and explainability by introducing an explainable-by-design convolutional neural network (CNN) based on the lateral inhibition mechanism. The ExplaiNet model consists of \u2026"}, {"title": "Counterfactual and Prototypical Explanations for Tabular Data via Interpretable Latent Space", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10753432.pdf", "details": "S Piaggesi, F Bodria, R Guidotti, F Giannotti\u2026 - IEEE Access, 2024", "abstract": "Artificial Intelligence decision-making systems have dramatically increased their predictive power in recent years, beating humans in many different specific tasks. However, with increased performance has come an increase in the complexity of the \u2026"}, {"title": "Steering Language Model Refusal with Sparse Autoencoders", "link": "https://arxiv.org/pdf/2411.11296", "details": "K O'Brien, D Majercak, X Fernandes, R Edgar, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Responsible practices for deploying language models include guiding models to recognize and refuse answering prompts that are considered unsafe, while complying with safe prompts. Achieving such behavior typically requires updating \u2026"}, {"title": "Generative Example-Based Explanations: Bridging the Gap between Generative Modeling and Explainability", "link": "https://arxiv.org/pdf/2410.20890", "details": "P Vaeth, AM Fruehwald, B Paassen, M Gregorova - arXiv preprint arXiv:2410.20890, 2024", "abstract": "Recently, several methods have leveraged deep generative modeling to produce example-based explanations of decision algorithms for high-dimensional input data. Despite promising results, a disconnect exists between these methods and the \u2026"}, {"title": "Test-time Conditional Text-to-Image Synthesis Using Diffusion Models", "link": "https://arxiv.org/pdf/2411.10800", "details": "T Shukla, S Karanam, BV Srinivasan - arXiv preprint arXiv:2411.10800, 2024", "abstract": "We consider the problem of conditional text-to-image synthesis with diffusion models. Most recent works need to either finetune specific parts of the base diffusion model or introduce new trainable parameters, leading to deployment inflexibility due to the \u2026"}, {"title": "Trustworthy and Explainable Offline Reinforcement Learning by Inferring a Discrete-State Discrete-Action MDP from a Continous-State Continuous-Action Dataset", "link": "https://bnaic2024.sites.uu.nl/wp-content/uploads/sites/986/2024/10/Trustworthy-and-Explainable-Offline-Reinforcement-Learning-by-Inferring-a-Discrete-State-Discrete-Action-MDP-from-a-Continous-State-Continuous-Action-dataset.pdf", "details": "D Steckelmacher, A Now\u00e9", "abstract": "Offline Reinforcement Learning allows to learn a controller for a system from a history of states, actions and rewards, without requiring to interact with the system or a simulator of it. Current Offline RL approaches mainly build on Off-policy RL, such as \u2026"}, {"title": "Towards Explainable Rejects for prototype-Based Classifiers?", "link": "https://www.techfak.uni-bielefeld.de/~fschleif/mlr/mlr_01_2024.pdf%23page%3D16", "details": "J Brinkrolf, V Vaquet, F Hinder, B Hammer - MiWoCI Workshop-2024", "abstract": "Prototype-based methods constitute a robust and transparent family of machine- learning models. To increase robustness in real-world applications, they are frequently coupled with reject options. While the state-of-the-art method, relative \u2026"}, {"title": "CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense", "link": "https://arxiv.org/pdf/2410.23091", "details": "M Zhang, K Bi, W Chen, Q Chen, J Guo, X Cheng - arXiv preprint arXiv:2410.23091, 2024", "abstract": "Despite ongoing efforts to defend neural classifiers from adversarial attacks, they remain vulnerable, especially to unseen attacks. In contrast, humans are difficult to be cheated by subtle manipulations, since we make judgments only based on \u2026"}, {"title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning", "link": "https://arxiv.org/pdf/2410.19560", "details": "S Mo, S Tong - arXiv preprint arXiv:2410.19560, 2024", "abstract": "In recent advancements in unsupervised visual representation learning, the Joint- Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabeled imagery through an innovative masking \u2026"}]
