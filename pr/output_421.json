'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HCL: A Hierarchical Contrastive Learning Framework for Zero-'
[{"title": "OCI-SSL: Open Class-Imbalanced Semi-Supervised Learning With Contrastive Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10480417/", "details": "Y Zhou, C Gao, J Zhou, W Ding, L Shen, Z Lai - IEEE Transactions on Emerging \u2026, 2024", "abstract": "Semi-supervised learning (SSL) is a powerful technique that leverages unlabeled data to improve model performance. Conventional SSL algorithms generally make the assumption that the unlabeled data are derived from approximately balanced \u2026"}, {"title": "Category-Level Contrastive Learning for Unsupervised Hashing in Cross-Modal Retrieval", "link": "https://link.springer.com/article/10.1007/s41019-024-00248-9", "details": "M Xu, L Luo, H Lai, J Yin - Data Science and Engineering, 2024", "abstract": "Unsupervised hashing for cross-modal retrieval has received much attention in the data mining area. Recent methods rely on image-text paired data to conduct unsupervised cross-modal hashing in batch samples. There are two main limitations \u2026"}, {"title": "Improving Radiology Report Generation Quality and Diversity through Reinforcement Learning and Text Augmentation", "link": "https://www.mdpi.com/2306-5354/11/4/351", "details": "D Parres, A Albiol, R Paredes - Bioengineering, 2024", "abstract": "Deep learning is revolutionizing radiology report generation (RRG) with the adoption of vision encoder\u2013decoder (VED) frameworks, which transform radiographs into detailed medical reports. Traditional methods, however, often generate reports of \u2026"}, {"title": "Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance", "link": "https://arxiv.org/html/2403.05842v1", "details": "H Xu, L Xiang, X Ma, B Yang, B Li - arXiv preprint arXiv:2403.05842, 2024", "abstract": "With the blossom of deep learning models and services, it has become an imperative concern to safeguard the valuable model parameters from being stolen. Watermarking is considered an important tool for ownership verification. However \u2026"}, {"title": "Heterogeneous Contrastive Learning for Foundation Models and Beyond", "link": "https://arxiv.org/html/2404.00225v1", "details": "L Zheng, B Jing, Z Li, H Tong, J He - arXiv preprint arXiv:2404.00225, 2024", "abstract": "In the era of big data and Artificial Intelligence, an emerging paradigm is to utilize contrastive self-supervised learning to model large-scale heterogeneous data. Many existing foundation models benefit from the generalization capability of contrastive \u2026"}, {"title": "Improving Adversarial Transferability of Visual-Language Pre-training Models through Collaborative Multimodal Interaction", "link": "https://arxiv.org/html/2403.10883v1", "details": "J Fu, Z Chen, K Jiang, H Guo, J Wang, S Gao, W Zhang - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the substantial advancements in Vision-Language Pre-training (VLP) models, their susceptibility to adversarial attacks poses a significant challenge. Existing work rarely studies the transferability of attacks on VLP models, resulting in a \u2026"}, {"title": "Evaluating large language models as agents in the clinic", "link": "https://www.nature.com/articles/s41746-024-01083-y", "details": "N Mehandru, BY Miao, ER Almaraz, M Sushil, AJ Butte\u2026 - npj Digital Medicine, 2024", "abstract": "Recent developments in large language models (LLMs) have unlocked opportunities for healthcare, from information synthesis to clinical decision support. These LLMs are not just capable of modeling language, but can also act as intelligent \u201cagents\u201d \u2026"}, {"title": "Smaller Language Models are Better Zero-shot Machine-Generated Text Detectors", "link": "https://aclanthology.org/2024.eacl-short.25.pdf", "details": "N Mireshghallah, J Mattern, S Gao, R Shokri\u2026 - Proceedings of the 18th \u2026, 2024", "abstract": "As large language models are becoming more embedded in different user-facing services, it is important to be able to distinguish between human-written and machine- generated text to verify the authenticity of news articles, product reviews, etc. Thus, in \u2026"}, {"title": "Unsupervised real-time hallucination detection based on the internal states of large language models", "link": "https://arxiv.org/html/2403.06448v1", "details": "W Su, C Wang, Q Ai, Y Hu, Z Wu, Y Zhou, Y Liu - arXiv preprint arXiv:2403.06448, 2024", "abstract": "Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. This issue undermines the effectiveness of LLMs in practical applications, necessitating \u2026"}]
