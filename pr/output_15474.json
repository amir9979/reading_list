[{"title": "Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model", "link": "https://arxiv.org/pdf/2503.21782", "details": "A Shaker, M Maaz, C Gou, H Rezatofighi, S Khan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Video understanding models often struggle with high computational requirements, extensive parameter counts, and slow inference speed, making them inefficient for practical use. To tackle these challenges, we propose Mobile-VideoGPT, an efficient \u2026"}, {"title": "AdvFusion: Adapter-based Knowledge Transfer for Code Summarization on Code Language Models", "link": "https://figshare.le.ac.uk/articles/conference_contribution/AdvFusion_Adapter-based_Knowledge_Transfer_for_Code_Summarization_on_Code_Language_Models/28658645/1/files/53208368.pdf", "details": "F Chen, I Saberi, A Esmaeili, F Fard - 2025", "abstract": "Programming languages can benefit from one an-other by utilizing a pre-trained model for software engineeringtasks such as code summarization and method name prediction. While full fine-tuning of Code Language Models (Code-LMs) hasbeen \u2026"}, {"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2504.00869%3F", "details": "X Huang, J Wu, H Liu, X Tang, Y Zhou - arXiv preprint arXiv:2504.00869, 2025", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from \u2026"}, {"title": "Automated Radiology Report Labeling in Chest X-Ray Pathologies: Development and Evaluation of a Large Language Model Framework", "link": "https://medinform.jmir.org/2025/1/e68618/", "details": "A Abdullah, ST Kim - JMIR Medical Informatics, 2025", "abstract": "Background: Labeling unstructured radiology reports is crucial for creating structured datasets that facilitate downstream tasks, such as training large-scale medical imaging models. Current approaches typically rely on Bidirectional Encoder \u2026"}, {"title": "Foundation Model for Predicting Prognosis and Adjuvant Therapy Benefit From Digital Pathology in GI Cancers", "link": "https://ascopubs.org/doi/abs/10.1200/JCO-24-01501", "details": "X Wang, Y Jiang, S Yang, F Wang, X Zhang, W Wang\u2026 - Journal of Clinical Oncology, 2025", "abstract": "PURPOSE Artificial intelligence (AI) holds significant promise for improving cancer diagnosis and treatment. Here, we present a foundation AI model for prognosis prediction on the basis of standard hematoxylin and eosin\u2013stained histopathology \u2026"}, {"title": "A large-scale vision-language dataset derived from open scientific literature to advance biomedical generalist ai", "link": "https://arxiv.org/pdf/2503.22727", "details": "A Lozano, MW Sun, J Burgess, JJ Nirschl, C Polzak\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite the excitement behind biomedical artificial intelligence (AI), access to high- quality, diverse, and large-scale data-the foundation for modern AI systems-is still a bottleneck to unlocking its full potential. To address this gap, we introduce \u2026"}, {"title": "PonderV2: Improved 3D Representation with A Universal Pre-training Paradigm", "link": "https://ieeexplore.ieee.org/abstract/document/10969802/", "details": "H Zhu, H Yang, X Wu, D Huang, S Zhang, X He\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "In contrast to numerous NLP and 2D vision foundational models, training a 3D foundational model poses considerably greater challenges. This is primarily due to the inherent data variability and diversity of downstream tasks. In this paper, we \u2026"}, {"title": "SVLA: A Unified Speech-Vision-Language Assistant with Multimodal Reasoning and Speech Generation", "link": "https://arxiv.org/pdf/2503.24164", "details": "ND Huynh, MR Bouadjenek, I Razzak, H Hacid, S Aryal - arXiv preprint arXiv \u2026, 2025", "abstract": "Large vision and language models show strong performance in tasks like image captioning, visual question answering, and retrieval. However, challenges remain in integrating speech, text, and vision into a unified model, especially for spoken tasks \u2026"}, {"title": "DeCAP: Context-Adaptive Prompt Generation for Debiasing Zero-shot Question Answering in Large Language Models", "link": "https://arxiv.org/pdf/2503.19426%3F", "details": "S Bae, YS Choi, JH Lee - arXiv preprint arXiv:2503.19426, 2025", "abstract": "While Large Language Models (LLMs) excel in zero-shot Question Answering (QA), they tend to expose biases in their internal knowledge when faced with socially sensitive questions, leading to a degradation in performance. Existing zero-shot \u2026"}]
