[{"title": "Large-scale Validation of the Feasibility of GPT-4 as a Proofreading Tool for Head CT Reports", "link": "https://pubs.rsna.org/doi/abs/10.1148/radiol.240701", "details": "S Kim, D Kim, HJ Shin, SH Lee, Y Kang, S Jeong, J Kim\u2026 - Radiology, 2025", "abstract": "Background The increasing workload of radiologists can lead to burnout and errors in radiology reports. Large language models, such as OpenAI's GPT-4, hold promise as error revision tools for radiology. Purpose To test the feasibility of GPT-4 use by \u2026"}, {"title": "Supervision-free Vision-Language Alignment", "link": "https://arxiv.org/pdf/2501.04568%3F", "details": "G Giannone, R Li, Q Feng, E Perevodchikov, R Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation \u2026"}, {"title": "An Efficient Transferred Cascade System for COVID-19 Detection from Chest X-ray Images", "link": "https://www.informatica.si/index.php/informatica/article/download/5923/3710", "details": "N Dif, Z Elberrichi - Informatica, 2025", "abstract": "Analysing x-ray images for detecting Covid-19 presents one cost-effective approach. To automate this task, deep learning techniques have been suggested to reduce doctors workload. However, existing datasets classify X-ray images into three \u2026"}, {"title": "Focus Your Attention: Multiple Instance Learning with Attention Modification for Whole Slide Pathological Image Classification", "link": "https://ieeexplore.ieee.org/iel8/76/4358651/10838539.pdf", "details": "H Cheng, S Huang, L Cai, Y Xu, R Wang, Y Zhang - IEEE Transactions on Circuits \u2026, 2025", "abstract": "Computer-aided pathology diagnosis based on whole slide images, which is often formulated as a weakly supervised multiple instance learning (MIL) paradigm. Current approaches generally employ attention mechanisms to aggregate instance \u2026"}, {"title": "Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning", "link": "https://arxiv.org/pdf/2501.05069", "details": "H Liu, F Ilievski, CGM Snoek - arXiv preprint arXiv:2501.05069, 2025", "abstract": "This paper proposes the first video-grounded entailment tree reasoning method for commonsense video question answering (VQA). Despite the remarkable progress of large visual-language models (VLMs), there are growing concerns that they learn \u2026"}, {"title": "Assessing the Image Quality of Digitally Reconstructed Radiographs from Chest CT", "link": "https://link.springer.com/article/10.1007/s10278-025-01406-9", "details": "OT Paalvast, O Hertgers, M Sevenster, HJ Lamb - Journal of Imaging Informatics in \u2026, 2025", "abstract": "Rising computed tomography (CT) workloads require more efficient image interpretation methods. Digitally reconstructed radiographs (DRRs), generated from CT data, may enhance workflow efficiency by enabling faster radiological \u2026"}, {"title": "Valley2: Exploring Multimodal Models with Scalable Vision-Language Design", "link": "https://arxiv.org/pdf/2501.05901", "details": "Z Wu, Z Chen, R Luo, C Zhang, Y Gao, Z He, X Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, vision-language models have made remarkable progress, demonstrating outstanding capabilities in various tasks such as image captioning and video understanding. We introduce Valley2, a novel multimodal large language model \u2026"}, {"title": "Enhancing few-shot KB-VQA with panoramic image captions guided by Large Language Models", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225000451", "details": "P Qiang, H Tan, X Li, D Wang, R Li, X Sun, H Zhang\u2026 - Neurocomputing, 2025", "abstract": "Current state-of-the-art (SOTA) KB-VQA techniques involve transforming images into image captions as prompts to harness the potent reasoning capabilities of large language models (LLMs) for generating answers. However, generic image captions \u2026"}, {"title": "A Novel Pathology Foundation Model by Mayo Clinic, Charit\\'e, and Aignostics", "link": "https://arxiv.org/pdf/2501.05409", "details": "M Alber, S Tietz, J Dippel, T Milbich, T Lesort\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in digital pathology have demonstrated the effectiveness of foundation models across diverse applications. In this report, we present a novel vision foundation model based on the RudolfV approach. Our model was trained on \u2026"}]
