[{"title": "Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders", "link": "https://arxiv.org/pdf/2407.03863", "details": "MY Avci, E Chan, V Zimmer, D Rueckert, B Wiestler\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the increasing incidence of neurodegenerative diseases such as Alzheimer's Disease (AD), there is a need for further research that enhances detection and monitoring of the diseases. We present MORPHADE (Morphological Autoencoders \u2026"}, {"title": "Comparing Differentiable Logics for Learning with Logical Constraints", "link": "https://arxiv.org/pdf/2407.03847", "details": "T Flinkow, BA Pearlmutter, R Monahan - arXiv preprint arXiv:2407.03847, 2024", "abstract": "Extensive research on formal verification of machine learning systems indicates that learning from data alone often fails to capture underlying background knowledge such as specifications implicitly available in the data. Various neural network verifiers \u2026"}, {"title": "Automated Disentangled Sequential Recommendation with Large Language Models", "link": "https://dl.acm.org/doi/pdf/10.1145/3675164", "details": "X Wang, H Chen, Z Pan, Y Zhou, C Guan, L Sun\u2026 - ACM Transactions on Information \u2026", "abstract": "Sequential recommendation aims to recommend the next items that a target user may have interest in based on the user's sequence of past behaviors, which has become a hot research topic in both academia and industry. In the literature \u2026"}, {"title": "Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination", "link": "https://ieeecai.org/2024/wp-content/pdfs/540900a486/540900a486.pdf", "details": "X Zhong, K Batmanghelich, L Sun", "abstract": "Vision-language models pre-trained on large scale of unlabeled biomedical images and associated reports learn generalizable semantic representations. These multi- modal representations can benefit various downstream tasks in the biomedical \u2026"}, {"title": "Adaptive Concept Bottleneck for Foundation Models", "link": "https://openreview.net/pdf%3Fid%3DgVswBbGg2C", "details": "J Choi, J Raghuram, Y Li, S Banerjee, S Jha - ICML 2024 Workshop on Foundation Models \u2026", "abstract": "Advancements in foundation models have led to a paradigm shift in deep learning pipelines. The rich, expressive feature representations from these pre-trained, large- scale backbones are leveraged for multiple downstream tasks, usually via light \u2026"}]
