[{"title": "Analysing the Residual Stream of Language Models Under Knowledge Conflicts", "link": "https://arxiv.org/pdf/2410.16090", "details": "Y Zhao, X Du, G Hong, AP Gema, A Devoto, H Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) can store a significant amount of factual knowledge in their parameters. However, their parametric knowledge may conflict with the information provided in the context. Such conflicts can lead to undesirable model \u2026"}, {"title": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models", "link": "https://openreview.net/pdf%3Fid%3DHOLs697aIx", "details": "A Dutta, YC Hsiao - NeurIPS 2024 Workshop on Open-World Agents", "abstract": "We propose a novel in-context learning algorithm for building autonomous decision- making language agents. The language agent continuously attempts to solve the same task by reasoning, acting, observing and then self-correcting each time the task \u2026"}, {"title": "AdaEDL: Early Draft Stopping for Speculative Decoding of Large Language Models via an Entropy-based Lower Bound on Token Acceptance Probability", "link": "https://arxiv.org/pdf/2410.18351", "details": "S Agrawal, W Jeon, M Lee - arXiv preprint arXiv:2410.18351, 2024", "abstract": "Speculative decoding is a powerful technique that attempts to circumvent the autoregressive constraint of modern Large Language Models (LLMs). The aim of speculative decoding techniques is to improve the average inference time of a large \u2026"}, {"title": "CLR-Bench: Evaluating Large Language Models in College-level Reasoning", "link": "https://arxiv.org/pdf/2410.17558", "details": "J Dong, Z Hong, Y Bei, F Huang, X Wang, X Huang - arXiv preprint arXiv:2410.17558, 2024", "abstract": "Large language models (LLMs) have demonstrated their remarkable performance across various language understanding tasks. While emerging benchmarks have been proposed to evaluate LLMs in various domains such as mathematics and \u2026"}, {"title": "LLaVA-KD: A Framework of Distilling Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2410.16236", "details": "Y Cai, J Zhang, H He, X He, A Tong, Z Gan, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The success of Large Language Models (LLM) has led researchers to explore Multimodal Large Language Models (MLLM) for unified visual and linguistic understanding. However, the increasing model size and computational complexity of \u2026"}, {"title": "Aligning Large Language Models via Self-Steering Optimization", "link": "https://arxiv.org/pdf/2410.17131", "details": "H Xiang, B Yu, H Lin, K Lu, Y Lu, X Han, L Sun, J Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Automated alignment develops alignment systems with minimal human intervention. The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation. In this paper, we introduce \u2026"}, {"title": "Cross-lingual Transfer of Reward Models in Multilingual Alignment", "link": "https://arxiv.org/pdf/2410.18027", "details": "J Hong, N Lee, R Mart\u00ednez-Casta\u00f1o, C Rodr\u00edguez\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reinforcement learning with human feedback (RLHF) is shown to largely benefit from precise reward models (RMs). However, recent studies in reward modeling schemes are skewed towards English, limiting the applicability of RLHF in \u2026"}, {"title": "Pre-training Distillation for Large Language Models: A Design Space Exploration", "link": "https://arxiv.org/pdf/2410.16215", "details": "H Peng, X Lv, Y Bai, Z Yao, J Zhang, L Hou, J Li - arXiv preprint arXiv:2410.16215, 2024", "abstract": "Knowledge distillation (KD) aims to transfer knowledge from a large teacher model to a smaller student model. Previous work applying KD in the field of large language models (LLMs) typically focused on the post-training phase, where the student LLM \u2026"}, {"title": "Accounting for Sycophancy in Language Model Uncertainty Estimation", "link": "https://arxiv.org/pdf/2410.14746", "details": "A Sicilia, M Inan, M Alikhani - arXiv preprint arXiv:2410.14746, 2024", "abstract": "Effective human-machine collaboration requires machine learning models to externalize uncertainty, so users can reflect and intervene when necessary. For language models, these representations of uncertainty may be impacted by \u2026"}]
