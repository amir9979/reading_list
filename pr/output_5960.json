[{"title": "KnowComp at DialAM-2024: Fine-tuning Pre-trained Language Models for Dialogical Argument Mining with Inference Anchoring Theory", "link": "https://aclanthology.org/2024.argmining-1.10.pdf", "details": "Y Wu, Y Zhou, B Xu, W Wang, Y Song - Proceedings of the 11th Workshop on \u2026, 2024", "abstract": "In this paper, we present our framework for DialAM-2024 TaskA: Identification of Propositional Relations and TaskB: Identification of Illocutionary Relations. The goal of task A is to detect argumentative relations between propositions in an \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models", "link": "https://arxiv.org/pdf/2408.03297", "details": "R Zhang, Y Xu, Y Xiao, R Zhu, X Jiang, X Chu, J Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "By integrating external knowledge, Retrieval-Augmented Generation (RAG) has become an effective strategy for mitigating the hallucination problems that large language models (LLMs) encounter when dealing with knowledge-intensive tasks \u2026"}, {"title": "Differentially Private and Heterogeneity-Robust Federated Learning with Theoretical Guarantee", "link": "https://ieeexplore.ieee.org/abstract/document/10643038/", "details": "X Wang, S Wang, Y Li, F Fan, S Li, X Lin - IEEE Transactions on Artificial Intelligence, 2024", "abstract": "Federated learning (FL) is a popular distributed paradigm where enormous clients collaboratively train a machine learning (ML) model under the orchestration of a central server without knowing the clients' private raw data. The development of \u2026"}, {"title": "Does Data-Efficient Generalization Exacerbate Bias in Foundation Models?", "link": "https://arxiv.org/pdf/2408.16154", "details": "D Queiroz, A Carlos, M Fatoretto, A Anjos, L Berton\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Foundation models have emerged as robust models with label efficiency in diverse domains. In medical imaging, these models contribute to the advancement of medical diagnoses due to the difficulty in obtaining labeled data. However, it is \u2026"}, {"title": "Pre-training data selection for biomedical domain adaptation using journal impact metrics", "link": "https://aclanthology.org/2024.bionlp-1.27.pdf", "details": "M Lai-king, P Paroubek - Proceedings of the 23rd Workshop on Biomedical \u2026, 2024", "abstract": "Abstract Domain adaptation is a widely used method in natural language processing (NLP) to improve the performance of a language model within a specific domain. This method is particularly common in the biomedical domain, which sees regular \u2026"}, {"title": "Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?", "link": "https://arxiv.org/pdf/2408.02651", "details": "MB Karkevandi, N Vishwamitra, P Najafirad - arXiv preprint arXiv:2408.02651, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in natural language tasks, but their safety and morality remain contentious due to their training on internet text corpora. To address these concerns, alignment techniques \u2026"}, {"title": "StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements", "link": "https://arxiv.org/pdf/2408.15666", "details": "J Fisher, S Hallinan, X Lu, M Gordon, Z Harchaoui\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Authorship obfuscation, rewriting a text to intentionally obscure the identity of the author, is an important but challenging task. Current methods using large language models (LLMs) lack interpretability and controllability, often ignoring author-specific \u2026"}, {"title": "Large Language Models Can Learn Representation in Natural Language", "link": "https://aclanthology.org/2024.findings-acl.542.pdf", "details": "Y Guo, Y Liang, D Zhao, N Duan - Findings of the Association for Computational \u2026, 2024", "abstract": "One major challenge for Large Language Models (LLMs) is completing complex tasks involving multiple entities, such as tool APIs. To tackle this, one approach is to retrieve relevant entities to enhance LLMs in task completion. A crucial issue here is \u2026"}]
