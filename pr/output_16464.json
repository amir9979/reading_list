[{"title": "GroundCocoa: A Benchmark for Evaluating Compositional & Conditional Reasoning in Language Models", "link": "https://aclanthology.org/2025.naacl-long.420.pdf", "details": "H Kohli, S Kumar, H Sun - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their reasoning to \u2026"}, {"title": "Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math", "link": "https://arxiv.org/pdf/2504.21233", "details": "H Xu, B Peng, H Awadalla, D Chen, YC Chen, M Gao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Chain-of-Thought (CoT) significantly enhances formal reasoning capabilities in Large Language Models (LLMs) by training them to explicitly generate intermediate reasoning steps. While LLMs readily benefit from such techniques, improving \u2026"}, {"title": "ALGOPUZZLEVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Algorithmic Multimodal Puzzles", "link": "https://aclanthology.org/2025.naacl-long.486.pdf", "details": "D Ghosal, V Toh, YK Chia, S Poria - Proceedings of the 2025 Conference of the \u2026, 2025", "abstract": "This paper introduces the novel task of multimodal puzzle solving, framed within the context of visual question-answering. We present a new dataset, AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal language models \u2026"}, {"title": "Exploring Multimodal Language Models for Sustainability Disclosure Extraction: A Comparative Study", "link": "https://aclanthology.org/2025.insights-1.13.pdf", "details": "T Gupta, T Goel, I Verma - The Sixth Workshop on Insights from Negative Results \u2026, 2025", "abstract": "Sustainability metrics have increasingly become a crucial non-financial criterion in investment decision-making. Organizations worldwide are recognizing the importance of sustainability and are proactively highlighting their efforts through \u2026"}, {"title": "Enhancing Structure-aware Protein Language Models with Efficient Fine-tuning for Various Protein Prediction Tasks", "link": "https://www.biorxiv.org/content/10.1101/2025.04.23.650337.full.pdf", "details": "Y Zhang, Y Qin, M Pourmirzaei, Q Shao, D Wang, D Xu - bioRxiv, 2025", "abstract": "Proteins are crucial in a wide range of biological and engineering processes. Large protein language models (PLMs) can significantly advance our understanding and engineering of proteins. However, the effectiveness of PLMs in prediction and design \u2026"}, {"title": "Modern causal inference approaches to improve power for subgroup analysis in randomized controlled trials", "link": "https://arxiv.org/pdf/2505.08960", "details": "A D'Alessandro, J Kim, S Adhikari, D Goff, FB Stoffi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In randomized controlled trials (RCTs), subgroup analyses are often planned to evaluate the heterogeneity of treatment effects within pre-specified subgroups of interest. However, these analyses frequently have small sample sizes, reducing the \u2026"}, {"title": "Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society", "link": "https://arxiv.org/pdf/2504.17404%3F", "details": "F Zhao, Y Wang, E Lu, D Zhao, B Han, H Tong, Y Liang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Artificial Intelligence (AI) systems are becoming increasingly powerful and autonomous, and may progress to surpass human intelligence levels, namely Artificial Superintelligence (ASI). During the progression from AI to ASI, it may exceed \u2026"}, {"title": "Toward Generalizable Evaluation in the LLM Era: A Survey Beyond Benchmarks", "link": "https://arxiv.org/pdf/2504.18838", "details": "Y Cao, S Hong, X Li, J Ying, Y Ma, H Liang, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) are advancing at an amazing speed and have become indispensable across academia, industry, and daily applications. To keep pace with the status quo, this survey probes the core challenges that the rise of LLMs \u2026"}, {"title": "Atoxia: Red-teaming Large Language Models with Target Toxic Answers", "link": "https://aclanthology.org/2025.findings-naacl.179.pdf", "details": "Y Du, Z Li, P Cheng, X Wan, A Gao - Findings of the Association for Computational \u2026, 2025", "abstract": "Despite the substantial advancements in artificial intelligence, large language models (LLMs) remain being challenged by generation safety. With adversarial jailbreaking prompts, one can effortlessly induce LLMs to output harmful content \u2026"}]
