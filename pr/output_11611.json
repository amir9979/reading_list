[{"title": "Linguistic Entity Masking to Improve Cross-Lingual Representation of Multilingual Language Models for Low-Resource Languages", "link": "https://arxiv.org/pdf/2501.05700", "details": "A Fernando, S Ranathunga - arXiv preprint arXiv:2501.05700, 2025", "abstract": "Multilingual Pre-trained Language models (multiPLMs), trained on the Masked Language Modelling (MLM) objective are commonly being used for cross-lingual tasks such as bitext mining. However, the performance of these models is still \u2026"}, {"title": "Grounding Deliberate Reasoning in Multimodal Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-96-2061-6_2", "details": "J Chen, Y Liu, D Li, X An, W Deng, Z Feng, Y Zhao\u2026 - International Conference on \u2026, 2024", "abstract": "Abstract The rise of Multimodal Large Language Models, renowned for their advanced instruction-following and reasoning capabilities, has significantly propelled the field of visual reasoning. However, due to limitations in their image \u2026"}, {"title": "LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models", "link": "https://arxiv.org/pdf/2501.00055", "details": "M Yu, J Fang, Y Zhou, X Fan, K Wang, S Pan, Q Wen - arXiv preprint arXiv \u2026, 2024", "abstract": "While safety-aligned large language models (LLMs) are increasingly used as the cornerstone for powerful systems such as multi-agent frameworks to solve complex real-world problems, they still suffer from potential adversarial queries, such as \u2026"}, {"title": "Aligning Crowd-Sourced Human Feedback for Reinforcement Learning on Code Generation by Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10818581/", "details": "MF Wong, CW Tan - IEEE Transactions on Big Data, 2024", "abstract": "This paper studies how AI-assisted programming and large language models (LLM) improve software developers' ability via AI tools (LLM agents) like Github Copilot and Amazon CodeWhisperer, while integrating human feedback to enhance \u2026"}, {"title": "Cascaded Self-Evaluation Augmented Training for Efficient Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2501.05662", "details": "Z Lv, W Wang, J Wang, S Zhang, F Wu - arXiv preprint arXiv:2501.05662, 2025", "abstract": "Efficient Multimodal Large Language Models (EMLLMs) have rapidly advanced recently. Incorporating Chain-of-Thought (CoT) reasoning and step-by-step self- evaluation has improved their performance. However, limited parameters often \u2026"}, {"title": "Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization", "link": "https://arxiv.org/pdf/2412.18279%3F", "details": "J Liu, C Wang, CY Liu, L Zeng, R Yan, Y Sun, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The role of reinforcement learning (RL) in enhancing the reasoning of large language models (LLMs) is becoming increasingly significant. Despite the success of RL in many scenarios, there are still many challenges in improving the reasoning of \u2026"}, {"title": "SKEWACT: Red Teaming Large Language Models via Activation-Skewed Adversarial Prompt Optimization", "link": "https://openreview.net/pdf%3Fid%3DQPdVqbcBgi", "details": "H Guo, S Cheng, G Tao, G Shen, Z Zhang, S An\u2026", "abstract": "Abstract Large Language Models (LLMs) have become increasingly impactful across various domains, including coding and data analysis. However, their widespread adoption has raised concerns about misuse, particularly in generating harmful or \u2026"}, {"title": "Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models", "link": "https://arxiv.org/pdf/2412.19450%3F", "details": "H Moon, J Seo, S Lee, C Park, H Lim - arXiv preprint arXiv:2412.19450, 2024", "abstract": "One of the key strengths of Large Language Models (LLMs) is their ability to interact with humans by generating appropriate responses to given instructions. This ability, known as instruction-following capability, has established a foundation for the use of \u2026"}, {"title": "Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models", "link": "https://arxiv.org/pdf/2412.17034", "details": "L Gao, X Zhang, P Nakov, X Chen - arXiv preprint arXiv:2412.17034, 2024", "abstract": "Jailbreaking in Large Language Models (LLMs) is a major security concern as it can deceive LLMs to generate harmful text. Yet, there is still insufficient understanding of how jailbreaking works, which makes it hard to develop effective defense strategies \u2026"}]
