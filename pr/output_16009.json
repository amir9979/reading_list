[{"title": "Argumentative Large Language Models for Explainable and Contestable Claim Verification", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/33637/35792", "details": "G Freedman, A Dejl, D Gorur, X Yin, A Rago, F Toni - Proceedings of the AAAI \u2026, 2025", "abstract": "The profusion of knowledge encoded in large language models (LLMs) and their ability to apply this knowledge zero-shot in a range of settings makes them promising candidates for use in decision-making. However, they are currently limited by their \u2026"}, {"title": "Overcoming Heterogeneous Data in Federated Medical Vision-Language Pre-training: A Triple-Embedding Model Selector Approach", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32807/34962", "details": "A Wang, Z Zhang, D Wang, F Wang, H Hu, J Guo\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "The scarcity data of medical field brings the collaborative training in medical vision- language pre-training (VLP) cross different clients. Therefore, the collaborative training in medical VLP faces two challenges: First, the medical data requires \u2026"}, {"title": "RL-GCL: Reinforcement Learning-Guided Contrastive Learning for molecular property prediction", "link": "https://www.sciencedirect.com/science/article/pii/S1566253525002817", "details": "Y Fu, J Han, Y Xu, K Liu, J Lu, S He, X Bo - Information Fusion, 2025", "abstract": "High-quality molecular characterizations for downstream tasks, such as molecular property prediction and drug design, have been effectively achieved through graph contrastive learning in biomolecules. However, many previous studies have treated \u2026"}, {"title": "LLM-guided Decoupled Probabilistic Prompt for Continual Learning in Medical Image Diagnosis", "link": "https://ieeexplore.ieee.org/abstract/document/10981824/", "details": "Y Luo, W Li, C Chen, X Li, T Liu, T Niu, Y Yuan - IEEE Transactions on Medical \u2026, 2025", "abstract": "Deep learning-based traditional diagnostic models typically exhibit limitations when applied to dynamic clinical environments that require handling the emergence of new diseases. Continual learning (CL) offers a promising solution, aiming to learn \u2026"}, {"title": "HalluShift: Measuring Distribution Shifts towards Hallucination Detection in LLMs", "link": "https://arxiv.org/pdf/2504.09482", "details": "S Dasgupta, S Nath, A Basu, P Shamsolmoali, S Das - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have recently garnered widespread attention due to their adeptness at generating innovative responses to the given prompts across a multitude of domains. However, LLMs often suffer from the inherent limitation of \u2026"}, {"title": "Fast-Slow-Thinking: Complex Task Solving with Large Language Models", "link": "https://arxiv.org/pdf/2504.08690%3F", "details": "Y Sun, Y Zhang, Z Zhao, S Wan, D Tao, C Gong - arXiv preprint arXiv:2504.08690, 2025", "abstract": "Nowadays, Large Language Models (LLMs) have been gradually employed to solve complex tasks. To face the challenge, task decomposition has become an effective way, which proposes to divide a complex task into multiple simpler subtasks and \u2026"}, {"title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models", "link": "https://arxiv.org/pdf/2504.06214", "details": "C Xu, W Ping, P Xu, Z Liu, B Wang, M Shoeybi, B Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context learning, and inference-time scaling, all of which require models to process and reason over long sequences of text and \u2026"}, {"title": "Large language models could be rote learners", "link": "https://arxiv.org/pdf/2504.08300", "details": "Y Xu, R Hu, H Ying, J Wu, X Shi, W Lin - arXiv preprint arXiv:2504.08300, 2025", "abstract": "Multiple-choice question (MCQ) benchmarks are widely used for evaluating Large Language Models (LLMs), yet their reliability is undermined by benchmark contamination. In this study, we reframe contamination as an inherent aspect of \u2026"}, {"title": "Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection", "link": "https://arxiv.org/pdf/2504.09440", "details": "MS Liu, S Bo, J Fang - arXiv preprint arXiv:2504.09440, 2025", "abstract": "Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical \u2026"}]
