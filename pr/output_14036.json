[{"title": "An Efficient and Interpretable Foundation Model for Retinal Image Analysis in Disease Diagnosis", "link": "https://www.medrxiv.org/content/10.1101/2025.02.19.25322447.full.pdf", "details": "W Dai, ZJ Chen, Y Yao, Y Chen, J Fang, Q Bai, C Xu\u2026 - medRxiv, 2025", "abstract": "Artificial intelligence (AI) foundation models for colour fundus photography (CFP) have been extensively studied and demonstrated great potential for advancing ocular and systemic health screening. However, their high computational demands \u2026"}, {"title": "Counterfactual Bidirectional Co-Attention Transformer for Integrative Histology-Genomic Cancer Risk Stratification", "link": "https://ieeexplore.ieee.org/abstract/document/10910138/", "details": "Z Ji, Y Ge, C Chukwudi, SM Zhang, Y Peng, J Zhu\u2026 - IEEE Journal of Biomedical \u2026, 2025", "abstract": "Applying deep learning to predict patient prognostic survival outcomes using histological whole-slide images (WSIs) and genomic data is challenging due to the morphological and transcriptomic heterogeneity present in the tumor \u2026"}, {"title": "A Robust Approach to Early Glaucoma Identification from Retinal Fundus Images using Dirichlet-based Weighted Average Ensemble and Bayesian Optimization", "link": "https://pubmed.ncbi.nlm.nih.gov/40017250/", "details": "M Mouhafid, Y Zhou, C Shan, Z Xiao - Current medical imaging", "abstract": "Objective Glaucoma is a leading cause of irreversible visual impairment and blindness worldwide, primarily linked to increased intraocular pressure (IOP). Early detection is essential to prevent further visual impairment, yet the manual diagnosis \u2026"}, {"title": "Words or Vision: Do Vision-Language Models Have Blind Faith in Text?", "link": "https://arxiv.org/pdf/2503.02199", "details": "A Deng, T Cao, Z Chen, B Hooi - arXiv preprint arXiv:2503.02199, 2025", "abstract": "Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual \u2026"}, {"title": "FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis", "link": "https://arxiv.org/pdf/2502.14807", "details": "F Maani, N Saeed, T Saleem, Z Farooq, H Alasmawi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Foundation models are becoming increasingly effective in the medical domain, offering pre-trained models on large datasets that can be readily adapted for downstream tasks. Despite progress, fetal ultrasound images remain a challenging \u2026"}, {"title": "Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline", "link": "https://arxiv.org/pdf/2502.18531", "details": "X Gui, H Lv, X Wang, L Lv, Y Xiao, L Wang - arXiv preprint arXiv:2502.18531, 2025", "abstract": "Background: Recruitment for cohorts involving complex liver diseases, such as hepatocellular carcinoma and liver cirrhosis, often requires interpreting semantically complex criteria. Traditional manual screening methods are time-consuming and \u2026"}, {"title": "IDEA Prune: An Integrated Enlarge-and-Prune Pipeline in Generative Language Model Pretraining", "link": "https://arxiv.org/pdf/2503.05920", "details": "Y Li, X Du, A Jaiswal, T Lei, T Zhao, C Wang, J Wang - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in large language models have intensified the need for efficient and deployable models within limited inference budgets. Structured pruning pipelines have shown promise in token efficiency compared to training target-size \u2026"}, {"title": "Language Models Can Predict Their Own Behavior", "link": "https://arxiv.org/pdf/2502.13329", "details": "D Ashok, J May - arXiv preprint arXiv:2502.13329, 2025", "abstract": "Autoregressive Language Models output text by sequentially predicting the next token to generate, with modern methods like Chain-of-Thought (CoT) prompting achieving state-of-the-art reasoning capabilities by scaling the number of generated \u2026"}, {"title": "Multidimensional Consistency Improves Reasoning in Language Models", "link": "https://arxiv.org/pdf/2503.02670", "details": "H Lai, X Zhang, M Nissim - arXiv preprint arXiv:2503.02670, 2025", "abstract": "While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across \u2026"}]
