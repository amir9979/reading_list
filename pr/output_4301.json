[{"title": "Language models, like humans, show content effects on reasoning tasks", "link": "https://academic.oup.com/pnasnexus/article/3/7/pgae233/7712372", "details": "AK Lampinen, I Dasgupta, SCY Chan, HR Sheahan\u2026 - PNAS nexus, 2024", "abstract": "Abstract reasoning is a key ability for an intelligent system. Large language models (LMs) achieve above-chance performance on abstract reasoning tasks but exhibit many imperfections. However, human abstract reasoning is also imperfect. Human \u2026"}, {"title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models", "link": "https://arxiv.org/pdf/2407.03181", "details": "H Puerto, T Chubakov, X Zhu, HT Madabushi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Requiring a Large Language Model to generate intermediary reasoning steps has been shown to be an effective way of boosting performance. In fact, it has been found that instruction tuning on these intermediary reasoning steps improves model \u2026"}, {"title": "Aligning Language Models with the Human World", "link": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi%3Farticle%3D1241%26context%3Ddissertations", "details": "R LIU - 2024", "abstract": "Abstract The field of Natural Language Processing (NLP) has undergone a significant transformation with the emergence of large language models (LMs). These models have enabled the development of human-like conversational \u2026"}, {"title": "Matching tasks to objectives: Fine-tuning and prompt-tuning strategies for encoder-decoder pre-trained language models", "link": "https://link.springer.com/article/10.1007/s10489-024-05660-2", "details": "A Pouramini, H Faili - Applied Intelligence, 2024", "abstract": "Prompt-based learning has emerged as a dominant paradigm in natural language processing. This study explores the impact of diverse pre-training objectives on the performance of encoder-decoder pre-trained language models across generation \u2026"}, {"title": "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale", "link": "https://arxiv.org/pdf/2407.02118", "details": "W Zheng, W Pan, X Xu, L Qin, L Yue, M Zhou - arXiv preprint arXiv:2407.02118, 2024", "abstract": "In recent years, Large Language Models (LLMs) have made significant strides towards Artificial General Intelligence. However, training these models from scratch requires substantial computational resources and vast amounts of text data. In this \u2026"}, {"title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application", "link": "https://arxiv.org/pdf/2407.01885", "details": "C Yang, W Lu, Y Zhu, Y Wang, Q Chen, C Gao, B Yan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in various domains, attracting significant interest from both academia and industry. Despite their impressive performance, the substantial size and computational demands of LLMs \u2026"}, {"title": "Just read twice: closing the recall gap for recurrent language models", "link": "https://arxiv.org/pdf/2407.05483", "details": "S Arora, A Timalsina, A Singhal, B Spector, S Eyuboglu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recurrent large language models that compete with Transformers in language modeling perplexity are emerging at a rapid rate (eg, Mamba, RWKV). Excitingly, these architectures use a constant amount of memory during inference. However \u2026"}, {"title": "Generalization vs Memorization: Tracing Language Models' Capabilities Back to Pretraining Data", "link": "https://arxiv.org/pdf/2407.14985", "details": "A Antoniades, X Wang, Y Elazar, A Amayuelas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the proven utility of large language models (LLMs) in real-world applications, there remains a lack of understanding regarding how they leverage their large-scale pretraining text corpora to achieve such capabilities. In this work, we investigate the \u2026"}, {"title": "Reflective Instruction Tuning: Mitigating Hallucinations in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2407.11422", "details": "J Zhang, T Wang, H Zhang, P Lu, F Zheng - arXiv preprint arXiv:2407.11422, 2024", "abstract": "Large vision-language models (LVLMs) have shown promising performance on a variety of vision-language tasks. However, they remain susceptible to hallucinations, generating outputs misaligned with visual content or instructions. While various \u2026"}]
