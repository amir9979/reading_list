[{"title": "Preserving Generalization of Language models in Few-shot Continual Relation Extraction", "link": "https://arxiv.org/pdf/2410.00334", "details": "Q Tran, NX Thanh, NH Anh, NL Hai, T Le, L Van Ngo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic area of study where models can sequentially integrate knowledge from new relations with limited labeled data while circumventing catastrophic forgetting and preserving prior \u2026"}, {"title": "Do Vision and Language Models Share Concepts? A Vector Space Alignment Study", "link": "https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00698/124631", "details": "J Li, Y Kementchedjhieva, C Fierro, A S\u00f8gaard - Transactions of the Association for \u2026, 2024", "abstract": "Large-scale pretrained language models (LMs) are said to \u201clack the ability to connect utterances to the world\u201d(Bender and Koller,), because they do not have \u201cmental models of the world\u201d(Mitchell and Krakauer,). If so, one would expect LM \u2026"}, {"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "Exploring the Learning Capabilities of Language Models using LEVERWORLDS", "link": "https://arxiv.org/pdf/2410.00519", "details": "E Wagner, A Feder, O Abend - arXiv preprint arXiv:2410.00519, 2024", "abstract": "Learning a model of a stochastic setting often involves learning both general structure rules and specific properties of the instance. This paper investigates the interplay between learning the general and the specific in various learning methods \u2026"}, {"title": "Frequency-Based Federated Domain Generalization for Polyp Segmentation", "link": "https://arxiv.org/pdf/2410.02044", "details": "H Pan, D Jha, K Biswas, U Bagci - arXiv preprint arXiv:2410.02044, 2024", "abstract": "Federated Learning (FL) offers a powerful strategy for training machine learning models across decentralized datasets while maintaining data privacy, yet domain shifts among clients can degrade performance, particularly in medical imaging tasks \u2026"}, {"title": "A unified multimodal classification framework based on deep metric learning", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024006713", "details": "L Peng, S Jian, M Li, Z Kan, L Qiao, D Li - Neural Networks, 2025", "abstract": "Multimodal classification algorithms play an essential role in multimodal machine learning, aiming to categorize distinct data points by analyzing data characteristics from multiple modalities. Extensive research has been conducted on distilling \u2026"}, {"title": "Explainable deep learning for diabetes diagnosis with DeepNetX2", "link": "https://www.sciencedirect.com/science/article/pii/S1746809424009601", "details": "SA Tanim, TE Shrestha, MDRI Emon, MF Mridha\u2026 - \u2026 Signal Processing and \u2026, 2025", "abstract": "Diabetes is a leading health global health challenge because of its high blood sugar levels and the risk of extensive damage to other internal organs. Early and accurate identification of diabetes is important because it may cause other diseases including \u2026"}, {"title": "RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models", "link": "https://arxiv.org/pdf/2409.19886", "details": "S Chen, W Jiang, B Lin, JT Kwok, Y Zhang - arXiv preprint arXiv:2409.19886, 2024", "abstract": "Recent works show that assembling multiple off-the-shelf large language models (LLMs) can harness their complementary abilities. To achieve this, routing is a promising method, which learns a router to select the most suitable LLM for each \u2026"}, {"title": "SETA: Semantic-Aware Edge-Guided Token Augmentation for Domain Generalization", "link": "https://ieeexplore.ieee.org/abstract/document/10705912/", "details": "J Guo, L Qi, Y Shi, Y Gao - IEEE Transactions on Image Processing, 2024", "abstract": "Domain generalization (DG) aims to enhance the model robustness against domain shifts without accessing target domains. A prevalent category of methods for DG is data augmentation, which focuses on generating virtual samples to simulate domain \u2026"}]
