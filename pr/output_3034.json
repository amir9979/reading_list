[{"title": "Explainable Graph Neural Networks Under Fire", "link": "https://arxiv.org/pdf/2406.06417", "details": "Z Li, S Geisler, Y Wang, S G\u00fcnnemann\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Predictions made by graph neural networks (GNNs) usually lack interpretability due to their complex computational behavior and the abstract nature of graphs. In an attempt to tackle this, many GNN explanation methods have emerged. Their goal is \u2026"}, {"title": "Conceptual Learning via Embedding Approximations for Reinforcing Interpretability and Transparency", "link": "https://arxiv.org/pdf/2406.08840", "details": "M Dikter, T Blau, C Baskin - arXiv preprint arXiv:2406.08840, 2024", "abstract": "Concept bottleneck models (CBMs) have emerged as critical tools in domains where interpretability is paramount. These models rely on predefined textual descriptions, referred to as concepts, to inform their decision-making process and offer more \u2026"}, {"title": "Towards Explainable Visual Vessel Recognition Using Fine-Grained Classification and Image Retrieval", "link": "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/papers/Karus_Towards_Explainable_Visual_Vessel_Recognition_Using_Fine-Grained_Classification_and_Image_CVPRW_2024_paper.pdf", "details": "H Karus, F Schwenker, M Munz, M Teutsch - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "The precise recognition of vessel types is critical for applications in maritime surveillance but manual visual inspection is slow and error-prone. Automated fine- grained object recognition helps to quickly and accurately categorize vessels as long \u2026"}, {"title": "Empowering Tuberculosis Screening with Explainable Self-Supervised Deep Neural Networks", "link": "https://arxiv.org/pdf/2406.13750", "details": "N Patel, A Wong, A Ebadi - arXiv preprint arXiv:2406.13750, 2024", "abstract": "Tuberculosis persists as a global health crisis, especially in resource-limited populations and remote regions, with more than 10 million individuals newly infected annually. It stands as a stark symbol of inequity in public health. Tuberculosis \u2026"}, {"title": "MVAIBNet: Multiview Disentangled Representation Learning With Information Bottleneck", "link": "https://ieeexplore.ieee.org/abstract/document/10557786/", "details": "M Yin, X Liu, J Gao, H Yuan, T Jin, S Zhang, L Li - IEEE Transactions on Industrial \u2026, 2024", "abstract": "Multiview representation learning has recently attracted significant attention in the machine learning and computer vision community. However, during fusing information from multiple views, existing work often neglect to exploit the \u2026"}, {"title": "Enhancing Size Generalization in Graph Neural Networks through Disentangled Representation Learning", "link": "https://arxiv.org/pdf/2406.04601", "details": "Z Huang, Q Yang, D Zhou, Y Yan - arXiv preprint arXiv:2406.04601, 2024", "abstract": "Although most graph neural networks (GNNs) can operate on graphs of any size, their classification performance often declines on graphs larger than those encountered during training. Existing methods insufficiently address the removal of \u2026"}, {"title": "Diffusion Bridge AutoEncoders for Unsupervised Representation Learning", "link": "https://arxiv.org/pdf/2405.17111", "details": "Y Kim, K Lee, M Park, B Na, IC Moon - arXiv preprint arXiv:2405.17111, 2024", "abstract": "Diffusion-based representation learning has achieved substantial attention due to its promising capabilities in latent representation and sample generation. Recent studies have employed an auxiliary encoder to identify a corresponding \u2026"}, {"title": "Discriminative Hamiltonian Variational Autoencoder for Accurate Tumor Segmentation in Data-Scarce Regimes", "link": "https://arxiv.org/pdf/2406.11659", "details": "A Kebaili, J Lapuyade-Lahorgue, P Vera, S Ruan - arXiv preprint arXiv:2406.11659, 2024", "abstract": "Deep learning has gained significant attention in medical image segmentation. However, the limited availability of annotated training data presents a challenge to achieving accurate results. In efforts to overcome this challenge, data augmentation \u2026"}, {"title": "IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning", "link": "https://arxiv.org/pdf/2406.13683", "details": "SS Ghosal, S Basu, S Feizi, D Manocha - arXiv preprint arXiv:2406.13683, 2024", "abstract": "Image-text contrastive models such as CLIP learn transferable and robust representations for zero-shot transfer to a variety of downstream tasks. However, to obtain strong downstream performances, prompts need to be carefully curated \u2026"}]
