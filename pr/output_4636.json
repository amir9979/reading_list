[{"title": "On Pre-training of Multimodal Language Models Customized for Chart Understanding", "link": "https://arxiv.org/pdf/2407.14506", "details": "WC Fan, YC Chen, M Liu, L Yuan, L Sigal - arXiv preprint arXiv:2407.14506, 2024", "abstract": "Recent studies customizing Multimodal Large Language Models (MLLMs) for domain-specific tasks have yielded promising results, especially in the field of scientific chart comprehension. These studies generally utilize visual instruction \u2026"}, {"title": "Cognitive Assessment of Language Models", "link": "https://openreview.net/pdf%3Fid%3DpxRh1meUvN", "details": "D McDuff, D Munday, X Liu, I Galatzer-Levy - ICML 2024 Workshop on LLMs and Cognition", "abstract": "Large language models (LLMs) are a subclass of generative artificial intelligence that can interpret language inputs to generate novel responses. These capabilities are conceptualized as a significant step forward in artificial intelligence because the \u2026"}, {"title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge", "link": "https://arxiv.org/pdf/2407.19594", "details": "T Wu, W Yuan, O Golovneva, J Xu, Y Tian, J Jiao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains. While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can \u2026"}, {"title": "On Speeding Up Language Model Evaluation", "link": "https://arxiv.org/pdf/2407.06172", "details": "JP Zhou, CK Belardi, R Wu, T Zhang, CP Gomes\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks. Developing a model of this nature, from training to inference, requires making \u2026"}, {"title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization", "link": "https://arxiv.org/pdf/2407.07880", "details": "J Wu, Y Xie, Z Yang, J Wu, J Chen, J Gao, B Ding\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences. We categorize noise into pointwise noise, which includes low \u2026"}, {"title": "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning", "link": "https://arxiv.org/pdf/2407.06112", "details": "Y Zhang, S Mao, W Wu, Y Xia, T Ge, M Lan, F Wei - arXiv preprint arXiv:2407.06112, 2024", "abstract": "This paper introduces BI-Directional DEliberation Reasoning (BIDDER), a novel reasoning approach to enhance the decision rationality of language models. Traditional reasoning methods typically rely on historical information and employ uni \u2026"}, {"title": "Distilling System 2 into System 1", "link": "https://arxiv.org/pdf/2407.06023", "details": "P Yu, J Xu, J Weston, I Kulikov - arXiv preprint arXiv:2407.06023, 2024", "abstract": "Large language models (LLMs) can spend extra compute during inference to generate intermediate thoughts, which helps to produce better final responses. Since Chain-of-Thought (Wei et al., 2022), many such System 2 techniques have been \u2026"}, {"title": "Meta-prompting Optimized Retrieval-augmented Generation", "link": "https://arxiv.org/pdf/2407.03955", "details": "J Rodrigues, A Branco - arXiv preprint arXiv:2407.03955, 2024", "abstract": "Retrieval-augmented generation resorts to content retrieved from external sources in order to leverage the performance of large language models in downstream tasks. The excessive volume of retrieved content, the possible dispersion of its parts, or \u2026"}, {"title": "SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training", "link": "https://arxiv.org/pdf/2407.06654", "details": "N He, W Xiong, H Liu, Y Liao, L Ding, K Zhang, G Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The effectiveness of large language models (LLMs) is often hindered by duplicated data in their extensive pre-training datasets. Current approaches primarily focus on detecting and removing duplicates, which risks the loss of valuable information and \u2026"}]
