[{"title": "FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks", "link": "https://arxiv.org/pdf/2407.05412", "details": "J Miao, C Chen, K Zhang, J Chuai, Q Li, PA Heng - arXiv preprint arXiv:2407.05412, 2024", "abstract": "One-shot detection of anatomical landmarks is gaining significant attention for its efficiency in using minimal labeled data to produce promising results. However, the success of current methods heavily relies on the employment of extensive unlabeled \u2026"}, {"title": "Unicoder: Scaling code large language model via universal code", "link": "https://arxiv.org/pdf/2406.16441", "details": "T Sun, L Chai, J Yang, Y Yin, H Guo, J Liu, B Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various downstream natural language processing (NLP) tasks. When applying LLMs for code generation, recent works mainly focus on \u2026"}, {"title": "Low-Redundant Optimization for Large Language Model Alignment", "link": "https://arxiv.org/pdf/2406.12606", "details": "Z Chen, K Zhou, WX Zhao, J Wang, JR Wen - arXiv preprint arXiv:2406.12606, 2024", "abstract": "Large language models (LLMs) are still struggling in aligning with human preference in complex tasks and scenarios. They are prone to overfit into the unexpected patterns or superficial styles in the training data. We conduct an empirical study that \u2026"}]
