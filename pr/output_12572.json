[{"title": "From My View to Yours: Ego-Augmented Learning in Large Vision Language Models for Understanding Exocentric Daily Living Activities", "link": "https://arxiv.org/pdf/2501.05711", "details": "D Reilly, MK Govind, S Das - arXiv preprint arXiv:2501.05711, 2025", "abstract": "Large Vision Language Models (LVLMs) have demonstrated impressive capabilities in video understanding, yet their adoption for Activities of Daily Living (ADL) remains limited by their inability to capture fine-grained interactions and spatial relationships \u2026"}, {"title": "RadVLM: A Multitask Conversational Vision-Language Model for Radiology", "link": "https://arxiv.org/pdf/2502.03333", "details": "N Deperrois, H Matsuo, S Ruip\u00e9rez-Campillo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The widespread use of chest X-rays (CXRs), coupled with a shortage of radiologists, has driven growing interest in automated CXR analysis and AI-assisted reporting. While existing vision-language models (VLMs) show promise in specific tasks such \u2026"}, {"title": "KIA: Knowledge-Guided Implicit Vision-Language Alignment for Chest X-Ray Report Generation", "link": "https://aclanthology.org/2025.coling-main.276.pdf", "details": "H Yin, S Zhou, P Wang, Z Wu, Y Hao - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "Report generation (RG) faces challenges in understanding complex medical images and establishing cross-modal semantic alignment in radiology image-report pairs. Previous methods often overlook fine-grained cross-modal interaction, leading to \u2026"}, {"title": "FreqSpace-NeRF: A fourier-enhanced Neural Radiance Fields method via dual-domain contrastive learning for novel view synthesis", "link": "https://www.sciencedirect.com/science/article/pii/S009784932500010X", "details": "X Yu, X Tian, J Chen, Y Wang - Computers & Graphics, 2025", "abstract": "Abstract Inspired by Neural Radiance Field's (NeRF) groundbreaking success in novel view synthesis, current methods mostly employ variants of various deep neural network architectures, and use the combination of multi-scale feature maps with the \u2026"}, {"title": "Leveraging Language Models for Summarizing Mental State Examinations: A Comprehensive Evaluation and Dataset Release", "link": "https://aclanthology.org/2025.coling-main.182.pdf", "details": "NK Sahu, M Yadav, M Chaturvedi, S Gupta, HR Lone - Proceedings of the 31st \u2026, 2025", "abstract": "Mental health disorders affect a significant portion of the global population, with diagnoses primarily conducted through Mental State Examinations (MSEs). MSEs serve as structured assessments to evaluate behavioral and cognitive functioning \u2026"}, {"title": "Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models", "link": "https://arxiv.org/pdf/2501.18533%3F", "details": "Y Ding, L Li, B Cao, J Shao - arXiv preprint arXiv:2501.18533, 2025", "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable performance across a wide range of tasks. However, their deployment in safety-critical domains poses significant challenges. Existing safety fine-tuning methods, which focus on \u2026"}, {"title": "Vision-Language Model Dialog Games for Self-Improvement", "link": "https://arxiv.org/pdf/2502.02740", "details": "K Konyushkova, C Kaplanis, S Cabi, M Denil - arXiv preprint arXiv:2502.02740, 2025", "abstract": "The increasing demand for high-quality, diverse training data poses a significant bottleneck in advancing vision-language models (VLMs). This paper presents VLM Dialog Games, a novel and scalable self-improvement framework for VLMs. Our \u2026"}, {"title": "Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval", "link": "https://arxiv.org/pdf/2501.09134", "details": "D Deanda, YP Masupalli, J Yang, Y Lee, Z Cao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical images and reports offer invaluable insights into patient health. The heterogeneity and complexity of these data hinder effective analysis. To bridge this gap, we investigate contrastive learning models for cross-domain retrieval, which \u2026"}, {"title": "EHM: Exploring dynamic alignment and hierarchical clustering in unsupervised domain adaptation via high-order moment-guided contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S089360802500067X", "details": "T Xu, J Dan - Neural Networks, 2025", "abstract": "Unsupervised domain adaptation (UDA) aims to annotate unlabeled target domain samples using transferable knowledge learned from the labeled source domain. Optimal transport (OT) is a widely adopted probability metric in transfer learning for \u2026"}]
