[{"title": "VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images", "link": "https://arxiv.org/pdf/2408.16176", "details": "M Maruf, A Daw, KS Mehrab, HB Manogaran, A Neog\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Images are increasingly becoming the currency for documenting biodiversity on the planet, providing novel opportunities for accelerating scientific discoveries in the field of organismal biology, especially with the advent of large vision-language models \u2026"}, {"title": "Analysis of Plan-based Retrieval for Grounded Text Generation", "link": "https://arxiv.org/pdf/2408.10490", "details": "A Godbole, N Monath, S Kim, AS Rawat, A McCallum\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In text generation, hallucinations refer to the generation of seemingly coherent text that contradicts established knowledge. One compelling hypothesis is that hallucinations occur when a language model is given a generation task outside its \u2026"}, {"title": "Language Models Pre-training", "link": "https://link.springer.com/content/pdf/10.1007/978-3-031-65647-7_2.pdf", "details": "U Kamath, K Keenan, G Somers, S Sorenson - Large Language Models: A Deep Dive \u2026, 2024", "abstract": "Pre-training forms the foundation for LLMs' capabilities. LLMs gain vital language comprehension and generative language skills by using large-scale datasets. The size and quality of these datasets are essential for maximizing LLMs' potential. It is \u2026"}, {"title": "LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models", "link": "https://arxiv.org/pdf/2408.10631", "details": "Y Su, Z Guan, X Liu, T Jin, D Wu, G Chesi, N Wong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have grown significantly in scale, leading to a critical need for efficient model pruning techniques. Existing post-training pruning techniques primarily focus on measuring weight importance on converged dense \u2026"}, {"title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection", "link": "https://arxiv.org/pdf/2409.06072", "details": "J Chakraborty, W Xia, A Majumder, D Ma, W Chaabene\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks. However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further \u2026"}, {"title": "Measuring and Controlling Instruction (In) Stability in Language Model Dialogs", "link": "https://openreview.net/pdf%3Fid%3D60a1SAtH4e", "details": "K Li, T Liu, N Bashkansky, D Bau, F Vi\u00e9gas, H Pfister\u2026 - First Conference on \u2026, 2024", "abstract": "System-prompting is a standard tool for customizing language-model chatbots, enabling them to follow a specific instruction. An implicit assumption in the use of system prompts is that they will be _stable_, so the chatbot will continue to generate \u2026"}, {"title": "Importance Weighting Can Help Large Language Models Self-Improve", "link": "https://arxiv.org/pdf/2408.09849", "details": "C Jiang, C Chan, W Xue, Q Liu, Y Guo - arXiv preprint arXiv:2408.09849, 2024", "abstract": "Large language models (LLMs) have shown remarkable capability in numerous tasks and applications. However, fine-tuning LLMs using high-quality datasets under external supervision remains prohibitively expensive. In response, LLM self \u2026"}, {"title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models", "link": "https://arxiv.org/pdf/2408.15778", "details": "J Gui, Y Liu, J Cheng, X Gu, X Liu, H Wang, Y Dong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across various tasks, showcasing complex problem-solving abilities. Understanding and executing complex rules, along with multi-step planning, are fundamental to logical \u2026"}, {"title": "Efficient Detection of Toxic Prompts in Large Language Models", "link": "https://arxiv.org/pdf/2408.11727", "details": "Y Liu, J Yu, H Sun, L Shi, G Deng, Y Chen, Y Liu - arXiv preprint arXiv:2408.11727, 2024", "abstract": "Large language models (LLMs) like ChatGPT and Gemini have significantly advanced natural language processing, enabling various applications such as chatbots and automated content generation. However, these models can be \u2026"}]
