[{"title": "Effective prompt extraction from language models", "link": "https://openreview.net/pdf%3Fid%3D0o95CVdNuz", "details": "Y Zhang, N Carlini, D Ippolito - First Conference on Language Modeling, 2024", "abstract": "The text generated by large language models is commonly controlled by prompting, where a prompt prepended to a user's query guides the model's output. The prompts used by companies to guide their models are often treated as secrets, to be hidden \u2026"}, {"title": "Understanding Defects in Generated Codes by Language Models", "link": "https://arxiv.org/pdf/2408.13372", "details": "AM Esfahani, N Kahani, SA Ajila - arXiv preprint arXiv:2408.13372, 2024", "abstract": "This study investigates the reliability of code generation by Large Language Models (LLMs), focusing on identifying and analyzing defects in the generated code. Despite the advanced capabilities of LLMs in automating code generation, ensuring the \u2026"}, {"title": "DP-MemArc: Differential Privacy Transfer Learning for Memory Efficient Language Models", "link": "https://www.researchgate.net/profile/Yanming-Liu-16/publication/383395255_DP-MemArc_Differential_Privacy_Transfer_Learning_for_Memory_Efficient_Language_Models/links/66ca3a35c2eaa5002314bfbf/DP-MemArc-Differential-Privacy-Transfer-Learning-for-Memory-Efficient-Language-Models.pdf", "details": "Y Liu, X Peng, Y Zhang, X Ke, S Deng, J Cao, C Ma\u2026", "abstract": "Large language models have repeatedly shown outstanding performance across diverse applications. However, deploying these models can inadvertently risk user privacy. The significant memory demands during training pose a major challenge in \u2026"}, {"title": "On Robustness-Accuracy Characterization of Language Models using Synthetic Datasets", "link": "https://openreview.net/pdf%3Fid%3DC0j44uRPcl", "details": "CY Ko, PY Chen, P Das, YS Chuang, L Daniel - First Conference on Language \u2026, 2024", "abstract": "In recent years, language models (LMs) that were pretrained at scale on diverse data have proven to be a successful approach for solving different downstream tasks. However, new concerns about proper performance evaluation have been raised \u2026"}, {"title": "Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.14470", "details": "A Agarwal, SK Ramesh, A Sengupta, T Chakraborty - arXiv preprint arXiv:2408.14470, 2024", "abstract": "Fine-tuning large language models (LLMs) on downstream tasks requires substantial computational resources. A class of parameter-efficient fine-tuning (PEFT) aims to mitigate these computational challenges by selectively fine-tuning only a small \u2026"}, {"title": "Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition", "link": "https://arxiv.org/pdf/2408.13227", "details": "A Pouramini, H Faili - arXiv preprint arXiv:2408.13227, 2024", "abstract": "In recent years, multi-task prompt tuning has garnered considerable attention for its inherent modularity and potential to enhance parameter-efficient transfer learning across diverse tasks. This paper aims to analyze and improve the performance of \u2026"}, {"title": "Importance Weighting Can Help Large Language Models Self-Improve", "link": "https://arxiv.org/pdf/2408.09849", "details": "C Jiang, C Chan, W Xue, Q Liu, Y Guo - arXiv preprint arXiv:2408.09849, 2024", "abstract": "Large language models (LLMs) have shown remarkable capability in numerous tasks and applications. However, fine-tuning LLMs using high-quality datasets under external supervision remains prohibitively expensive. In response, LLM self \u2026"}, {"title": "RecExplainer: Aligning Large Language Models for Explaining Recommendation Models", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671802", "details": "Y Lei, J Lian, J Yao, X Huang, D Lian, X Xie - Proceedings of the 30th ACM SIGKDD \u2026, 2024", "abstract": "Recommender systems are widely used in online services, with embedding-based models being particularly popular due to their expressiveness in representing complex signals. However, these models often function as a black box, making them \u2026"}, {"title": "A Law of Next-Token Prediction in Large Language Models", "link": "https://arxiv.org/pdf/2408.13442", "details": "H He, WJ Su - arXiv preprint arXiv:2408.13442, 2024", "abstract": "Large language models (LLMs) have been widely employed across various application domains, yet their black-box nature poses significant challenges to understanding how these models process input data internally to make predictions \u2026"}]
