[{"title": "Enhancing zero-shot multilingual semantic parsing: A framework leveraging large language models for data augmentation and advanced prompting techniques", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224018794", "details": "DT Do, MP Nguyen, LM Nguyen - Neurocomputing, 2024", "abstract": "In recent years, significant progress has been made in semantic parsing tasks due to the introduction of pre-trained language models. However, there remains a notable gap between English and other languages because of the limited availability of \u2026"}, {"title": "Membership Inference Attacks against Large Language Models via Self-prompt Calibration", "link": "https://fi.ee.tsinghua.edu.cn/~gaochen/papers/NeurIPS2024-SPV-MIA.pdf", "details": "W Fu, H Wang, G Liu, Y Li, T Jiang", "abstract": "Abstract Membership Inference Attacks (MIA) aim to infer whether a target data record has been utilized for model training or not. Existing MIAs designed for large language models (LLMs) can be bifurcated into two types: reference-free and \u2026"}]
