[{"title": "A dual medical ontology and relational graph framework with neural ordinary differential equations for diagnostic prediction", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225011919", "details": "S Li, F Dong, R Li, W Li - Neurocomputing, 2025", "abstract": "Accurate diagnostic prediction from Electronic Health Records (EHRs) is critical for advancing clinical decision-making and improving patient outcomes. Current works often struggle to systematically integrate medical domain knowledge, leverage \u2026"}, {"title": "Time-series deep learning and conformal prediction for improved sepsis diagnosis in primarily Non-ICU hospitalized patients", "link": "https://www.sciencedirect.com/science/article/pii/S0010482525008480", "details": "S Dalal, AK Ardabili, AS Bonavia - Computers in Biology and Medicine, 2025", "abstract": "Purpose Sepsis, a life-threatening condition from an uncontrolled immune response to infection, is a leading cause of in-hospital mortality. Early detection is crucial, yet traditional diagnostic methods, like SIRS and SOFA, often fail to identify sepsis in non \u2026"}, {"title": "Cross-Modal Causal Representation Learning for Radiology Report Generation", "link": "https://ieeexplore.ieee.org/abstract/document/11005686/", "details": "W Chen, Y Liu, C Wang, J Zhu, G Li, CL Liu, L Lin - IEEE Transactions on Image \u2026, 2025", "abstract": "Radiology Report Generation (RRG) is essential for computer-aided diagnosis and medication guidance, which can relieve the heavy burden of radiologists by automatically generating the corresponding radiology reports according to the given \u2026"}, {"title": "Hybrid graph-based radiology report generation", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425019475", "details": "D Sun, C Mu, X Fan, J Tang, Z Li, J Zhu, Z Ding - Expert Systems with Applications, 2025", "abstract": "Automatic report generation plays a crucial role in clinical practice by alleviating the heavy workload on doctors and helping to prevent misdiagnoses or missed diagnoses. In the context of radiology report generation, knowledge injection is \u2026"}, {"title": "Will Large Language Models Transform Clinical Prediction?", "link": "https://arxiv.org/pdf/2505.18246", "details": "Y Yildiz, G Nenadic, M Jani, DA Jenkins - arXiv preprint arXiv:2505.18246, 2025", "abstract": "Background: Large language models (LLMs) are attracting increasing interest in healthcare. Their ability to summarise large datasets effectively, answer questions accurately, and generate synthesised text is widely recognised. These capabilities \u2026", "entry_id": "http://arxiv.org/abs/2505.18246v1", "updated": "2025-05-23 17:02:04", "published": "2025-05-23 17:02:04", "authors": "Yusuf Yildiz;Goran Nenadic;Meghna Jani;David A. Jenkins", "summary": "Background: Large language models (LLMs) are attracting increasing interest\nin healthcare. Their ability to summarise large datasets effectively, answer\nquestions accurately, and generate synthesised text is widely recognised. These\ncapabilities are already finding applications in healthcare. Body: This\ncommentary discusses LLMs usage in the clinical prediction context and\nhighlight potential benefits and existing challenges. In these early stages,\nthe focus should be on extending the methodology, specifically on validation,\nfairness and bias evaluation, survival analysis and development of regulations.\nConclusion: We conclude that further work and domain-specific considerations\nneed to be made for full integration into the clinical prediction workflows.", "comment": "Submitted to: BMC Diagnostic and Prognostic Research", "journal_ref": null, "primary_category": "cs.CY", "categories": "cs.CY;cs.CL", "links": "http://arxiv.org/abs/2505.18246v1;http://arxiv.org/pdf/2505.18246v1", "pdf_url": "http://arxiv.org/pdf/2505.18246v1"}, {"title": "MAKE: Multi-Aspect Knowledge-Enhanced Vision-Language Pretraining for Zero-shot Dermatological Assessment", "link": "https://arxiv.org/pdf/2505.09372", "details": "S Yan, X Li, M Hu, Y Jiang, Z Yu, Z Ge - arXiv preprint arXiv:2505.09372, 2025", "abstract": "Dermatological diagnosis represents a complex multimodal challenge that requires integrating visual features with specialized clinical knowledge. While vision- language pretraining (VLP) has advanced medical AI, its effectiveness in \u2026", "entry_id": "http://arxiv.org/abs/2505.09372v1", "updated": "2025-05-14 13:24:08", "published": "2025-05-14 13:24:08", "authors": "Siyuan Yan;Xieji Li;Ming Hu;Yiwen Jiang;Zhen Yu;Zongyuan Ge", "summary": "Dermatological diagnosis represents a complex multimodal challenge that\nrequires integrating visual features with specialized clinical knowledge. While\nvision-language pretraining (VLP) has advanced medical AI, its effectiveness in\ndermatology is limited by text length constraints and the lack of structured\ntexts. In this paper, we introduce MAKE, a Multi-Aspect Knowledge-Enhanced\nvision-language pretraining framework for zero-shot dermatological tasks.\nRecognizing that comprehensive dermatological descriptions require multiple\nknowledge aspects that exceed standard text constraints, our framework\nintroduces: (1) a multi-aspect contrastive learning strategy that decomposes\nclinical narratives into knowledge-enhanced sub-texts through large language\nmodels, (2) a fine-grained alignment mechanism that connects subcaptions with\ndiagnostically relevant image features, and (3) a diagnosis-guided weighting\nscheme that adaptively prioritizes different sub-captions based on clinical\nsignificance prior. Through pretraining on 403,563 dermatological image-text\npairs collected from education resources, MAKE significantly outperforms\nstate-of-the-art VLP models on eight datasets across zero-shot skin disease\nclassification, concept annotation, and cross-modal retrieval tasks. Our code\nwill be made publicly available at https: //github.com/SiyuanYan1/MAKE.", "comment": "MICCAI2025 early acceptance; First two authors contribute equally", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.09372v1;http://arxiv.org/pdf/2505.09372v1", "pdf_url": "http://arxiv.org/pdf/2505.09372v1"}, {"title": "CMIF: A Cross-Modal Information Fusion Approach for Molecular Property Prediction", "link": "https://link.springer.com/chapter/10.1007/978-3-031-92741-6_17", "details": "M Zang, X Gong, R Han, Q Liu - International Joint Conference on Rough Sets, 2025", "abstract": "Molecular property prediction is vital in bioinformatics, as accurate and efficient predictions can greatly speed up drug discovery and lower R&D costs. In recent years, the development of deep learning has driven the innovation of data-driven \u2026"}, {"title": "Benchmarking Radiology Report Generation From Noisy Free-Texts", "link": "https://ieeexplore.ieee.org/abstract/document/11002452/", "details": "Y Yuan, Y Zheng, L Qu - IEEE Journal of Biomedical and Health Informatics, 2025", "abstract": "Automatic radiology report generation can enhance diagnostic efficiency and accuracy. However, clean open-source imaging scan-report pairs are limited in scale and variety. Moreover, the vast amount of radiological texts available online is often \u2026"}, {"title": "PLHF: Prompt Optimization with Few-Shot Human Feedback", "link": "https://arxiv.org/pdf/2505.07886", "details": "CP Yang, K Zheng, SD Lin - arXiv preprint arXiv:2505.07886, 2025", "abstract": "Automatic prompt optimization frameworks are developed to obtain suitable prompts for large language models (LLMs) with respect to desired output quality metrics. Although existing approaches can handle conventional tasks such as fixed-solution \u2026", "entry_id": "http://arxiv.org/abs/2505.07886v1", "updated": "2025-05-11 00:56:03", "published": "2025-05-11 00:56:03", "authors": "Chun-Pai Yang;Kan Zheng;Shou-De Lin", "summary": "Automatic prompt optimization frameworks are developed to obtain suitable\nprompts for large language models (LLMs) with respect to desired output quality\nmetrics. Although existing approaches can handle conventional tasks such as\nfixed-solution question answering, defining the metric becomes complicated when\nthe output quality cannot be easily assessed by comparisons with standard\ngolden samples. Consequently, optimizing the prompts effectively and\nefficiently without a clear metric becomes a critical challenge. To address the\nissue, we present PLHF (which stands for \"P\"rompt \"L\"earning with \"H\"uman\n\"F\"eedback), a few-shot prompt optimization framework inspired by the\nwell-known RLHF technique. Different from naive strategies, PLHF employs a\nspecific evaluator module acting as the metric to estimate the output quality.\nPLHF requires only a single round of human feedback to complete the entire\nprompt optimization process. Empirical results on both public and industrial\ndatasets show that PLHF outperforms prior output grading strategies for LLM\nprompt optimizations.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2505.07886v1;http://arxiv.org/pdf/2505.07886v1", "pdf_url": "http://arxiv.org/pdf/2505.07886v1"}]
