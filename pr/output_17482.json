[{"title": "Empirical evaluation of artificial intelligence distillation techniques for ascertaining cancer outcomes from electronic health records", "link": "https://www.nature.com/articles/s41746-025-01646-7", "details": "IB Riaz, SAA Naqvi, N Ashraf, GJ Harris, KL Kehl - npj Digital Medicine, 2025", "abstract": "Phenotypic information for cancer research is embedded in unstructured electronic health records (EHR), requiring effort to extract. Deep learning models can automate this but face scalability issues due to privacy concerns. We evaluated techniques for \u2026"}, {"title": "RADAR: Benchmarking Language Models on Imperfect Tabular Data", "link": "https://arxiv.org/abs/2506.08249", "details": "K Gu, Z Zhang, K Lin, Y Zhang, A Paruchuri, H Yu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Language models (LMs) are increasingly being deployed to perform autonomous data analyses. However, their data awareness--the ability to recognize, reason over, and appropriately handle data artifacts such as missing values, outliers, and logical \u2026", "entry_id": "http://arxiv.org/abs/2506.08249v1", "updated": "2025-06-09 21:32:47", "published": "2025-06-09 21:32:47", "authors": "Ken Gu;Zhihan Zhang;Kate Lin;Yuwei Zhang;Akshay Paruchuri;Hong Yu;Mehran Kazemi;Kumar Ayush;A. Ali Heydari;Maxwell A. Xu;Girish Narayanswamy;Yun Liu;Ming-Zher Poh;Yuzhe Yang;Mark Malhotra;Shwetak Patel;Hamid Palangi;Xuhai Xu;Daniel McDuff;Tim Althoff;Xin Liu", "summary": "Language models (LMs) are increasingly being deployed to perform autonomous\ndata analyses. However, their data awareness -- the ability to recognize,\nreason over, and appropriately handle data artifacts such as missing values,\noutliers, and logical inconsistencies -- remains underexplored. These artifacts\nare especially common in real-world tabular data and, if mishandled, can\nsignificantly compromise the validity of analytical conclusions. To address\nthis gap, we present RADAR, a benchmark for systematically evaluating\ndata-aware reasoning on tabular data. We develop a framework to simulate data\nartifacts via programmatic perturbations to enable targeted evaluation of model\nbehavior. RADAR comprises 2980 table query pairs, grounded in real-world data\nspanning 9 domains and 5 data artifact types. In addition to evaluating\nartifact handling, RADAR systematically varies table size to study how\nreasoning performance holds when increasing table size. Our evaluation reveals\nthat, despite decent performance on tables without data artifacts, frontier\nmodels degrade significantly when data artifacts are introduced, exposing\ncritical gaps in their capacity for robust, data-aware analysis. Designed to be\nflexible and extensible, RADAR supports diverse perturbation types and\ncontrollable table sizes, offering a valuable resource for advancing tabular\nreasoning.", "comment": null, "journal_ref": null, "primary_category": "cs.DB", "categories": "cs.DB;cs.CL", "links": "http://arxiv.org/abs/2506.08249v1;http://arxiv.org/pdf/2506.08249v1", "pdf_url": "http://arxiv.org/pdf/2506.08249v1"}, {"title": "Few-Shot Multilingual Open-Domain QA from Five Examples", "link": "https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00750/131279", "details": "F Jiang, T Drummond, T Cohn - Transactions of the Association for Computational \u2026, 2025", "abstract": "Recent approaches to multilingual open-domain question answering (MLODQA) have achieved promising results given abundant language-specific training data. However, the considerable annotation cost limits the application of these methods for \u2026"}, {"title": "Solving Inequality Proofs with Large Language Models", "link": "https://arxiv.org/pdf/2506.07927", "details": "J Sheng, L Lyu, J Jin, T Xia, A Gu, J Zou, P Lu - arXiv preprint arXiv:2506.07927, 2025", "abstract": "Inequality proving, crucial across diverse scientific and mathematical fields, tests advanced reasoning skills such as discovering tight bounds and strategic theorem application. This makes it a distinct, demanding frontier for large language models \u2026", "entry_id": "http://arxiv.org/abs/2506.07927v1", "updated": "2025-06-09 16:43:38", "published": "2025-06-09 16:43:38", "authors": "Jiayi Sheng;Luna Lyu;Jikai Jin;Tony Xia;Alex Gu;James Zou;Pan Lu", "summary": "Inequality proving, crucial across diverse scientific and mathematical\nfields, tests advanced reasoning skills such as discovering tight bounds and\nstrategic theorem application. This makes it a distinct, demanding frontier for\nlarge language models (LLMs), offering insights beyond general mathematical\nproblem-solving. Progress in this area is hampered by existing datasets that\nare often scarce, synthetic, or rigidly formal. We address this by proposing an\ninformal yet verifiable task formulation, recasting inequality proving into two\nautomatically checkable subtasks: bound estimation and relation prediction.\nBuilding on this, we release IneqMath, an expert-curated dataset of\nOlympiad-level inequalities, including a test set and training corpus enriched\nwith step-wise solutions and theorem annotations. We also develop a novel\nLLM-as-judge evaluation framework, combining a final-answer judge with four\nstep-wise judges designed to detect common reasoning flaws. A systematic\nevaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even\ntop models like o1 achieve less than 10% overall accuracy under step-wise\nscrutiny; this is a drop of up to 65.5% from their accuracy considering only\nfinal answer equivalence. This discrepancy exposes fragile deductive chains and\na critical gap for current LLMs between merely finding an answer and\nconstructing a rigorous proof. Scaling model size and increasing test-time\ncomputation yield limited gains in overall proof correctness. Instead, our\nfindings highlight promising research directions such as theorem-guided\nreasoning and self-refinement. Code and data are available at\nhttps://ineqmath.github.io/.", "comment": "52 pages, 16 figures", "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI;cs.CL;cs.LG", "links": "http://arxiv.org/abs/2506.07927v1;http://arxiv.org/pdf/2506.07927v1", "pdf_url": "http://arxiv.org/pdf/2506.07927v1"}]
