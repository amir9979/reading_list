[{"title": "FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models", "link": "https://arxiv.org/pdf/2405.10286", "details": "A Bulat, Y Ouali, G Tzimiropoulos - arXiv preprint arXiv:2405.10286, 2024", "abstract": "Despite noise and caption quality having been acknowledged as important factors impacting vision-language contrastive pre-training, in this paper, we show that the full potential of improving the training process by addressing such issues is yet to be \u2026"}, {"title": "Pseudo-Prompt Generating in Pre-trained Vision-Language Models for Multi-Label Medical Image Classification", "link": "https://arxiv.org/pdf/2405.06468", "details": "Y Ye, J Zhang, H Shi - arXiv preprint arXiv:2405.06468, 2024", "abstract": "The task of medical image recognition is notably complicated by the presence of varied and multiple pathological indications, presenting a unique challenge in multi- label classification with unseen labels. This complexity underlines the need for \u2026"}, {"title": "Observational Scaling Laws and the Predictability of Language Model Performance", "link": "https://arxiv.org/pdf/2405.10938", "details": "Y Ruan, CJ Maddison, T Hashimoto - arXiv preprint arXiv:2405.10938, 2024", "abstract": "Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different \u2026"}, {"title": "Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models", "link": "https://arxiv.org/pdf/2406.04320", "details": "A Behrouz, M Santacatterina, R Zabih - arXiv preprint arXiv:2406.04320, 2024", "abstract": "Modeling multivariate time series is a well-established problem with a wide range of applications from healthcare to financial markets. Traditional State Space Models (SSMs) are classical approaches for univariate time series modeling due to their \u2026"}, {"title": "Unelicitable Backdoors in Language Models via Cryptographic Transformer Circuits", "link": "https://arxiv.org/pdf/2406.02619", "details": "A Draguns, A Gritsevskiy, SR Motwani, C Rogers-Smith\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid proliferation of open-source language models significantly increases the risks of downstream backdoor attacks. These backdoors can introduce dangerous behaviours during model deployment and can evade detection by conventional \u2026"}, {"title": "Compositional Text-to-Image Generation with Dense Blob Representations", "link": "https://arxiv.org/pdf/2405.08246", "details": "W Nie, S Liu, M Mardani, C Liu, B Eckart, A Vahdat - arXiv preprint arXiv:2405.08246, 2024", "abstract": "Existing text-to-image models struggle to follow complex text prompts, raising the need for extra grounding inputs for better controllability. In this work, we propose to decompose a scene into visual primitives-denoted as dense blob representations \u2026"}, {"title": "Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings", "link": "https://arxiv.org/pdf/2405.10745", "details": "A Sawczyn, J Binkowski, P Bielak, T Kajdanowicz - arXiv preprint arXiv:2405.10745, 2024", "abstract": "Knowledge-intensive tasks pose a significant challenge for Machine Learning (ML) techniques. Commonly adopted methods, such as Large Language Models (LLMs), often exhibit limitations when applied to such tasks. Nevertheless, there have been \u2026"}, {"title": "Backdoor Removal for Generative Large Language Models", "link": "https://arxiv.org/pdf/2405.07667", "details": "H Li, Y Chen, Z Zheng, Q Hu, C Chan, H Liu, Y Song - arXiv preprint arXiv \u2026, 2024", "abstract": "With rapid advances, generative large language models (LLMs) dominate various Natural Language Processing (NLP) tasks from understanding to reasoning. Yet, language models' inherent vulnerabilities may be exacerbated due to increased \u2026"}, {"title": "A Survey on Vision-Language-Action Models for Embodied AI", "link": "https://arxiv.org/pdf/2405.14093", "details": "Y Ma, Z Song, Y Zhuang, J Hao, I King - arXiv preprint arXiv:2405.14093, 2024", "abstract": "Deep learning has demonstrated remarkable success across many domains, including computer vision, natural language processing, and reinforcement learning. Representative artificial neural networks in these fields span convolutional neural \u2026"}]
