[{"title": "SignCLIP: Connecting Text and Sign Language by Contrastive Learning", "link": "https://arxiv.org/pdf/2407.01264", "details": "Z Jiang, G Sant, A Moryossef, M M\u00fcller, R Sennrich\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present SignCLIP, which re-purposes CLIP (Contrastive Language-Image Pretraining) to project spoken language text and sign language videos, two classes of natural languages of distinct modalities, into the same space. SignCLIP is an \u2026"}, {"title": "Symmetric Dot-Product Attention for Efficient Training of BERT Language Models", "link": "https://arxiv.org/pdf/2406.06366", "details": "M Courtois, M Ostendorff, L Hennig, G Rehm - arXiv preprint arXiv:2406.06366, 2024", "abstract": "Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing \u2026"}, {"title": "CGFTrans: Cross-Modal Global Feature Fusion Transformer for Medical Report Generation", "link": "https://ieeexplore.ieee.org/abstract/document/10557585/", "details": "L Xu, Q Tang, B Zheng, J Lv, W Li, X Zeng - IEEE Journal of Biomedical and Health \u2026, 2024", "abstract": "Medical report generation, as a cross-modal automatic text generation task, can be highly significant both in research and clinical fields. The core is to generate diagnosis reports in clinical language from medical images. However, several \u2026"}]
