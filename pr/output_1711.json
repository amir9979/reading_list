'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [HW-GPT-Bench: Hardware-Aware Architecture Benchmark fo'
[{"title": "Relative Counterfactual Contrastive Learning for Mitigating Pretrained Stance Bias in Stance Detection", "link": "https://arxiv.org/pdf/2405.10991", "details": "J Zhang, S Wu, X Zhang, Z Feng - arXiv preprint arXiv:2405.10991, 2024", "abstract": "Stance detection classifies stance relations (namely, Favor, Against, or Neither) between comments and targets. Pretrained language models (PLMs) are widely used to mine the stance relation to improve the performance of stance detection \u2026"}, {"title": "DP-RuL: Differentially-Private Rule Learning for Clinical Decision Support Systems", "link": "https://arxiv.org/pdf/2405.09721", "details": "J Lamp, L Feng, D Evans - arXiv preprint arXiv:2405.09721, 2024", "abstract": "Serious privacy concerns arise with the use of patient data in rule-based clinical decision support systems (CDSS). The goal of a privacy-preserving CDSS is to learn a population ruleset from individual clients' local rulesets, while protecting the \u2026"}, {"title": "Generalizing Orthogonalization for Models with Non-linearities", "link": "https://arxiv.org/pdf/2405.02475", "details": "D R\u00fcgamer, C Kolb, T Weber, L Kook, T Nagler - arXiv preprint arXiv:2405.02475, 2024", "abstract": "The complexity of black-box algorithms can lead to various challenges, including the introduction of biases. These biases present immediate risks in the algorithms' application. It was, for instance, shown that neural networks can deduce racial \u2026"}, {"title": "CBDMoE: Consistent-but-Diverse Mixture of Experts for Domain Generalization", "link": "https://ieeexplore.ieee.org/abstract/document/10528872/", "details": "F Xu, D Chen, T Jia, S Deng, H Wang - IEEE Transactions on Multimedia, 2024", "abstract": "Machine learning models often suffer from severe performance degradation due to distributional shifts between testing and training data. To address this issue, researchers have focused on domain generalization (DG), which aims to generalize \u2026"}, {"title": "Continuous Predictive Modeling of Clinical Notes and ICD Codes in Patient Health Records", "link": "https://arxiv.org/pdf/2405.11622", "details": "MH Caralt, CBL Ng, M Rei - arXiv preprint arXiv:2405.11622, 2024", "abstract": "Electronic Health Records (EHR) serve as a valuable source of patient information, offering insights into medical histories, treatments, and outcomes. Previous research has developed systems for detecting applicable ICD codes that should be assigned \u2026"}, {"title": "Observational Scaling Laws and the Predictability of Language Model Performance", "link": "https://arxiv.org/pdf/2405.10938", "details": "Y Ruan, CJ Maddison, T Hashimoto - arXiv preprint arXiv:2405.10938, 2024", "abstract": "Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different \u2026"}, {"title": "Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting", "link": "https://arxiv.org/pdf/2405.10216", "details": "D Gupta, A Bhatti, S Parmar, C Dan, Y Liu, B Shen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Low-Rank Adaptation (LoRA) is a widely used technique for fine-tuning large pre- trained or foundational models across different modalities and tasks. However, its application to time series data, particularly within foundational models, remains \u2026"}]
