[{"title": "Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge Distillation on Language Models", "link": "https://arxiv.org/pdf/2412.14528", "details": "X Cui, M Zhu, Y Qin, L Xie, W Zhou, H Li - arXiv preprint arXiv:2412.14528, 2024", "abstract": "Knowledge distillation (KD) has become a prevalent technique for compressing large language models (LLMs). Existing KD methods are constrained by the need for identical tokenizers (ie, vocabularies) between teacher and student models, limiting \u2026"}, {"title": "Federated Learning with Partially Labeled Data: A Conditional Distillation Approach", "link": "https://arxiv.org/pdf/2412.18833", "details": "P Wang, C Shen, M Oda, CS Fuh, K Mori, W Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In medical imaging, developing generalized segmentation models that can handle multiple organs and lesions is crucial. However, the scarcity of fully annotated datasets and strict privacy regulations present significant barriers to data sharing \u2026"}, {"title": "Practical Guide to Image-Based Big Data Research", "link": "https://jamanetwork.com/journals/jamasurgery/article-abstract/2828664", "details": "EG Ross, S Arya, ML Melcher - JAMA surgery, 2025", "abstract": "Imaging is a cornerstone of modern surgical care. Computed tomography (CT) allows us to quickly diagnose a ruptured aortic aneurysm, 4K high-definition laparoscopes enable laparoscopic and robotic surgeries, and digital histopathology \u2026"}, {"title": "Evaluation and Enhancement of Large Language Models for In-Patient Diagnostic Support", "link": "https://www.researchsquare.com/article/rs-5599195/latest.pdf", "details": "Y Yuan - 2025", "abstract": "In-patient diagnosis demands complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited \u2026"}]
