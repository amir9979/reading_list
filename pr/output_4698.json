[{"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "On Pre-training of Multimodal Language Models Customized for Chart Understanding", "link": "https://arxiv.org/pdf/2407.14506", "details": "WC Fan, YC Chen, M Liu, L Yuan, L Sigal - arXiv preprint arXiv:2407.14506, 2024", "abstract": "Recent studies customizing Multimodal Large Language Models (MLLMs) for domain-specific tasks have yielded promising results, especially in the field of scientific chart comprehension. These studies generally utilize visual instruction \u2026"}, {"title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering", "link": "https://arxiv.org/pdf/2407.21368", "details": "D Guo, D Terzopoulos - arXiv preprint arXiv:2407.21368, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in recent years, and they have been extended to the medical domain. Although demonstrating satisfactory performance on medical Visual Question Answering (VQA) tasks \u2026"}, {"title": "NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models", "link": "https://arxiv.org/pdf/2407.10380", "details": "P Pandya, AS Talwarr, V Gupta, T Kataria, V Gupta\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Cognitive textual and visual reasoning tasks, such as puzzles, series, and analogies, demand the ability to quickly reason, decipher, and evaluate patterns both textually and spatially. While LLMs and VLMs, through extensive training on large amounts of \u2026"}, {"title": "VIOLA: Conditional Language Models for Speech Recognition, Synthesis, and Translation", "link": "https://ieeexplore.ieee.org/abstract/document/10613503/", "details": "T Wang, L Zhou, Z Zhang, Y Wu, S Liu, Y Gaur, Z Chen\u2026 - IEEE/ACM Transactions on \u2026, 2024", "abstract": "Recent research shows a big convergence in model architecture, training objectives, and inference methods across various tasks for different modalities. In this paper, we propose VIOLA, a single auto-regressive Transformer decoder-only network that \u2026"}, {"title": "Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models", "link": "https://arxiv.org/pdf/2407.19474", "details": "N Bitton-Guetta, A Slobodkin, A Maimon, E Habba\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Imagine observing someone scratching their arm; to understand why, additional context would be necessary. However, spotting a mosquito nearby would immediately offer a likely explanation for the person's discomfort, thereby alleviating \u2026"}, {"title": "The Llama 3 Herd of Models", "link": "https://arxiv.org/pdf/2407.21783", "details": "A Dubey, A Jauhri, A Pandey, A Kadian, A Al-Dahle\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool \u2026"}, {"title": "Patch-Level Training for Large Language Models", "link": "https://arxiv.org/pdf/2407.12665", "details": "C Shao, F Meng, J Zhou - arXiv preprint arXiv:2407.12665, 2024", "abstract": "As Large Language Models (LLMs) achieve remarkable progress in language understanding and generation, their training efficiency has become a critical concern. Traditionally, LLMs are trained to predict the next token in a sequence \u2026"}, {"title": "Exploring and Improving Drafts in Blockwise Parallel Decoding", "link": "https://openreview.net/pdf%3Fid%3DKtnUTS1f91", "details": "T Kim, AT Suresh, KA Papineni, M Riley, S Kumar\u2026 - Workshop on Efficient Systems for \u2026", "abstract": "Blockwise parallel decoding (BPD) was proposed in Stern et al.(2018) as a method to improve the inference speed of language models by simultaneously predicting multiple future tokens, termed block drafts, which are subsequently verified by the \u2026"}]
