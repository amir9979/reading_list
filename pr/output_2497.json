[{"title": "Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction", "link": "https://arxiv.org/pdf/2406.00755", "details": "X Li, W Wang, M Li, J Guo, Y Zhang, F Feng - arXiv preprint arXiv:2406.00755, 2024", "abstract": "The rapid advancement of Large Language Models (LLMs) in the realm of mathematical reasoning necessitates comprehensive evaluations to gauge progress and inspire future directions. Existing assessments predominantly focus on problem \u2026"}, {"title": "Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots", "link": "https://arxiv.org/pdf/2405.07990", "details": "C Wu, Y Ge, Q Guo, J Wang, Z Liang, Z Lu, Y Shan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The remarkable progress of Multi-modal Large Language Models (MLLMs) has attracted significant attention due to their superior performance in visual contexts. However, their capabilities in turning visual figure to executable code, have not been \u2026"}, {"title": "What Makes Good Few-shot Examples for Vision-Language Models?", "link": "https://arxiv.org/pdf/2405.13532", "details": "Z Guo, J Lu, X Liu, R Zhao, ZX Qian, F Tan - arXiv preprint arXiv:2405.13532, 2024", "abstract": "Despite the notable advancements achieved by leveraging pre-trained vision- language (VL) models through few-shot tuning for downstream tasks, our detailed empirical study highlights a significant dependence of few-shot learning outcomes \u2026"}, {"title": "Backdoor Removal for Generative Large Language Models", "link": "https://arxiv.org/pdf/2405.07667", "details": "H Li, Y Chen, Z Zheng, Q Hu, C Chan, H Liu, Y Song - arXiv preprint arXiv \u2026, 2024", "abstract": "With rapid advances, generative large language models (LLMs) dominate various Natural Language Processing (NLP) tasks from understanding to reasoning. Yet, language models' inherent vulnerabilities may be exacerbated due to increased \u2026"}, {"title": "Multi-task transfer learning for the prediction of entity modifiers in clinical text: application to opioid use disorder case detection", "link": "https://link.springer.com/article/10.1186/s13326-024-00311-4", "details": "AI Almudaifer, W Covington, JM Hairston, Z Deitch\u2026 - Journal of Biomedical \u2026, 2024", "abstract": "Background The semantics of entities extracted from a clinical text can be dramatically altered by modifiers, including entity negation, uncertainty, conditionality, severity, and subject. Existing models for determining modifiers of \u2026"}, {"title": "Medical Concept Normalization", "link": "https://link.springer.com/chapter/10.1007/978-3-031-55865-8_6", "details": "H Xu, D Demner Fushman, N Hong, K Raja - Natural Language Processing in \u2026, 2024", "abstract": "Medical concept normalization, which maps clinical entities to concepts in standard terminology, is essential for supporting downstream computational applications in clinical settings. This chapter starts with an overview of existing biomedical \u2026"}, {"title": "Towards improved breast cancer detection on digital mammograms using local self-attention-based transformer", "link": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13174/131741T/Towards-improved-breast-cancer-detection-on-digital-mammograms-using-local/10.1117/12.3025375.short", "details": "H Chen, AL Martel - 17th International Workshop on Breast Imaging (IWBI \u2026, 2024", "abstract": "Deep-learning-based models have been proposed as an automated second reader for mammograms that might help reduce radiologists' workload and improve screening accuracy. However, the inherent traits of mammograms, characterized by \u2026"}]
