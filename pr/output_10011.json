[{"title": "Free $^ 2$ Guide: Gradient-Free Path Integral Control for Enhancing Text-to-Video Generation with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2411.17041", "details": "J Kim, BS Kim, JC Ye - arXiv preprint arXiv:2411.17041, 2024", "abstract": "Diffusion models have achieved impressive results in generative tasks like text-to- image (T2I) and text-to-video (T2V) synthesis. However, achieving accurate text alignment in T2V generation remains challenging due to the complex temporal \u2026"}, {"title": "GEOBench-VLM: Benchmarking Vision-Language Models for Geospatial Tasks", "link": "https://arxiv.org/pdf/2411.19325", "details": "MS Danish, MA Munir, SRA Shah, K Kuckreja, FS Khan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While numerous recent benchmarks focus on evaluating generic Vision-Language Models (VLMs), they fall short in addressing the unique demands of geospatial applications. Generic VLM benchmarks are not designed to handle the complexities \u2026"}, {"title": "Evaluating Vision-Language Models as Evaluators in Path Planning", "link": "https://arxiv.org/pdf/2411.18711", "details": "M Aghzal, X Yue, E Plaku, Z Yao - arXiv preprint arXiv:2411.18711, 2024", "abstract": "Despite their promise to perform complex reasoning, large language models (LLMs) have been shown to have limited effectiveness in end-to-end planning. This has inspired an intriguing question: if these models cannot plan well, can they still \u2026"}, {"title": "Devils in Middle Layers of Large Vision-Language Models: Interpreting, Detecting and Mitigating Object Hallucinations via Attention Lens", "link": "https://arxiv.org/pdf/2411.16724", "details": "Z Jiang, J Chen, B Zhu, T Luo, Y Shen, X Yang - arXiv preprint arXiv:2411.16724, 2024", "abstract": "Hallucinations in Large Vision-Language Models (LVLMs) significantly undermine their reliability, motivating researchers to explore the causes of hallucination. However, most studies primarily focus on the language aspect rather than the visual \u2026"}, {"title": "Enhancing zero-shot multilingual semantic parsing: A framework leveraging large language models for data augmentation and advanced prompting techniques", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224018794", "details": "DT Do, MP Nguyen, LM Nguyen - Neurocomputing, 2024", "abstract": "In recent years, significant progress has been made in semantic parsing tasks due to the introduction of pre-trained language models. However, there remains a notable gap between English and other languages because of the limited availability of \u2026"}, {"title": "Zero-Shot Prompting and Few-Shot Fine-Tuning: Revisiting Document Image Classification Using Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-78495-8_10", "details": "A Scius-Bertrand, M Jungo, L V\u00f6gtlin, JM Spat\u2026 - International Conference on \u2026, 2025", "abstract": "Classifying scanned documents is a challenging problem that involves image, layout, and text analysis for document understanding. Nevertheless, for certain benchmark datasets, notably RVL-CDIP, the state of the art is closing in to near-perfect \u2026"}, {"title": "Exploring the Abilities of Large Language Models to Solve Proportional Analogies via Knowledge-Enhanced Prompting", "link": "https://arxiv.org/pdf/2412.00869", "details": "T Wijesiriwardene, R Wickramarachchi, S Vennam\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Making analogies is fundamental to cognition. Proportional analogies, which consist of four terms, are often used to assess linguistic and cognitive abilities. For instance, completing analogies like\" Oxygen is to Gas as< blank> is to< blank>\" requires \u2026"}, {"title": "Rephrasing Electronic Health Records for Pretraining Clinical Language Models", "link": "https://arxiv.org/pdf/2411.18940", "details": "J Liu, A Nguyen - arXiv preprint arXiv:2411.18940, 2024", "abstract": "Clinical language models are important for many applications in healthcare, but their development depends on access to extensive clinical text for pretraining. However, obtaining clinical notes from electronic health records (EHRs) at scale is challenging \u2026"}, {"title": "Incorporating Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3D1fpjV6xQ6Q", "details": "C Zhang, Z Wan, Z Kan, MQ Ma, S Stepputtis\u2026 - Workshop on Responsibly \u2026", "abstract": "While recent Large Vision-Language Models (LVLMs) have shown remarkable performance in multi-modal tasks, they are prone to generating hallucinatory text responses that do not align with the given visual input, which restricts their practical \u2026"}]
