[{"title": "MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing", "link": "https://arxiv.org/pdf/2505.07984", "details": "A Koksal, AA Alatan - arXiv preprint arXiv:2505.07984, 2025", "abstract": "Remarkable capabilities in understanding and generating text-image content have been demonstrated by recent advancements in multimodal large language models (MLLMs). However, their effectiveness in specialized domains-particularly those \u2026", "entry_id": "http://arxiv.org/abs/2505.07984v1", "updated": "2025-05-12 18:30:02", "published": "2025-05-12 18:30:02", "authors": "Aybora Koksal;A. Aydin Alatan", "summary": "Remarkable capabilities in understanding and generating text-image content\nhave been demonstrated by recent advancements in multimodal large language\nmodels (MLLMs). However, their effectiveness in specialized\ndomains-particularly those requiring resource-efficient and domain-specific\nadaptations-has remained limited. In this work, a lightweight multimodal\nlanguage model termed MilChat is introduced, specifically adapted to analyze\nremote sensing imagery in secluded areas, including challenging missile launch\nsites. A new dataset, MilData, was compiled by verifying hundreds of aerial\nimages through expert review, and subtle military installations were\nhighlighted via detailed captions. Supervised fine-tuning on a 2B-parameter\nopen-source MLLM with chain-of-thought (CoT) reasoning annotations was\nperformed, enabling more accurate and interpretable explanations. Additionally,\nGroup Relative Policy Optimization (GRPO) was leveraged to enhance the model's\nability to detect critical domain-specific cues-such as defensive layouts and\nkey military structures-while minimizing false positives on civilian scenes.\nThrough empirical evaluations, it has been shown that MilChat significantly\noutperforms both larger, general-purpose multimodal models and existing remote\nsensing-adapted approaches on open-ended captioning and classification metrics.\nOver 80% recall and 98% precision were achieved on the newly proposed MilData\nbenchmark, underscoring the potency of targeted fine-tuning and reinforcement\nlearning in specialized real-world applications.", "comment": "Submitted to JSTARS on April 2, 2025. Code and dataset will be\n  available upon acceptance", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.07984v1;http://arxiv.org/pdf/2505.07984v1", "pdf_url": "http://arxiv.org/pdf/2505.07984v1"}, {"title": "Dense Communication between Language Models", "link": "https://arxiv.org/pdf/2505.12741", "details": "S Wu, Y Wang, Q Yao - arXiv preprint arXiv:2505.12741, 2025", "abstract": "As higher-level intelligence emerges from the combination of modular components with lower-level intelligence, many works combines Large Language Models (LLMs) for collective intelligence. Such combination is achieved by building communications \u2026", "entry_id": "http://arxiv.org/abs/2505.12741v1", "updated": "2025-05-19 05:56:06", "published": "2025-05-19 05:56:06", "authors": "Shiguang Wu;Yaqing Wang;Quanming Yao", "summary": "As higher-level intelligence emerges from the combination of modular\ncomponents with lower-level intelligence, many works combines Large Language\nModels (LLMs) for collective intelligence. Such combination is achieved by\nbuilding communications among LLMs. While current systems primarily facilitate\nsuch communication through natural language, this paper proposes a novel\nparadigm of direct dense vector communication between LLMs. Our approach\neliminates the unnecessary embedding and de-embedding steps when LLM interact\nwith another, enabling more efficient information transfer, fully\ndifferentiable optimization pathways, and exploration of capabilities beyond\nhuman heuristics. We use such stripped LLMs as vertexes and optimizable seq2seq\nmodules as edges to construct LMNet, with similar structure as MLPs. By\nutilizing smaller pre-trained LLMs as vertexes, we train a LMNet that achieves\ncomparable performance with LLMs in similar size with only less than 0.1%\ntraining cost. This offers a new perspective on scaling for general\nintelligence rather than training a monolithic LLM from scratch. Besides, the\nproposed method can be used for other applications, like customizing LLM with\nlimited data, showing its versatility.", "comment": null, "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI", "links": "http://arxiv.org/abs/2505.12741v1;http://arxiv.org/pdf/2505.12741v1", "pdf_url": "http://arxiv.org/pdf/2505.12741v1"}, {"title": "DiagnosisArena: Benchmarking Diagnostic Reasoning for Large Language Models", "link": "https://arxiv.org/pdf/2505.14107", "details": "Y Zhu, Z Huang, L Mu, Y Huang, W Nie, S Zhang, P Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The emergence of groundbreaking large language models capable of performing complex reasoning tasks holds significant promise for addressing various scientific challenges, including those arising in complex clinical scenarios. To enable their \u2026", "entry_id": "http://arxiv.org/abs/2505.14107v1", "updated": "2025-05-20 09:14:53", "published": "2025-05-20 09:14:53", "authors": "Yakun Zhu;Zhongzhen Huang;Linjie Mu;Yutong Huang;Wei Nie;Shaoting Zhang;Pengfei Liu;Xiaofan Zhang", "summary": "The emergence of groundbreaking large language models capable of performing\ncomplex reasoning tasks holds significant promise for addressing various\nscientific challenges, including those arising in complex clinical scenarios.\nTo enable their safe and effective deployment in real-world healthcare\nsettings, it is urgently necessary to benchmark the diagnostic capabilities of\ncurrent models systematically. Given the limitations of existing medical\nbenchmarks in evaluating advanced diagnostic reasoning, we present\nDiagnosisArena, a comprehensive and challenging benchmark designed to\nrigorously assess professional-level diagnostic competence. DiagnosisArena\nconsists of 1,113 pairs of segmented patient cases and corresponding diagnoses,\nspanning 28 medical specialties, deriving from clinical case reports published\nin 10 top-tier medical journals. The benchmark is developed through a\nmeticulous construction pipeline, involving multiple rounds of screening and\nreview by both AI systems and human experts, with thorough checks conducted to\nprevent data leakage. Our study reveals that even the most advanced reasoning\nmodels, o3-mini, o1, and DeepSeek-R1, achieve only 45.82%, 31.09%, and 17.79%\naccuracy, respectively. This finding highlights a significant generalization\nbottleneck in current large language models when faced with clinical diagnostic\nreasoning challenges. Through DiagnosisArena, we aim to drive further\nadvancements in AIs diagnostic reasoning capabilities, enabling more effective\nsolutions for real-world clinical diagnostic challenges. We provide the\nbenchmark and evaluation tools for further research and development\nhttps://github.com/SPIRAL-MED/DiagnosisArena.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2505.14107v1;http://arxiv.org/pdf/2505.14107v1", "pdf_url": "http://arxiv.org/pdf/2505.14107v1"}, {"title": "Fine-Grained ECG-Text Contrastive Learning via Waveform Understanding Enhancement", "link": "https://arxiv.org/pdf/2505.11939", "details": "H Li, C Liu, Z Ding, Z Liu, Z Huang - arXiv preprint arXiv:2505.11939, 2025", "abstract": "Electrocardiograms (ECGs) are essential for diagnosing cardiovascular diseases. While previous ECG-text contrastive learning methods have shown promising results, they often overlook the incompleteness of the reports. Given an ECG, the \u2026", "entry_id": "http://arxiv.org/abs/2505.11939v1", "updated": "2025-05-17 10:03:06", "published": "2025-05-17 10:03:06", "authors": "Haitao Li;Che Liu;Zhengyao Ding;Ziyi Liu;Zhengxing Huang", "summary": "Electrocardiograms (ECGs) are essential for diagnosing cardiovascular\ndiseases. While previous ECG-text contrastive learning methods have shown\npromising results, they often overlook the incompleteness of the reports. Given\nan ECG, the report is generated by first identifying key waveform features and\nthen inferring the final diagnosis through these features. Despite their\nimportance, these waveform features are often not recorded in the report as\nintermediate results. Aligning ECGs with such incomplete reports impedes the\nmodel's ability to capture the ECG's waveform features and limits its\nunderstanding of diagnostic reasoning based on those features. To address this,\nwe propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which\naims to recover these waveform features from incomplete reports with the help\nof large language models (LLMs), under the challenges of hallucinations and the\nnon-bijective relationship between waveform features and diagnoses.\nAdditionally, considering the frequent false negatives due to the prevalence of\ncommon diagnoses in ECGs, we introduce a semantic similarity matrix to guide\ncontrastive learning. Furthermore, we adopt a sigmoid-based loss function to\naccommodate the multi-label nature of ECG-related tasks. Experiments on six\ndatasets demonstrate that FG-CLEP outperforms state-of-the-art methods in both\nzero-shot prediction and linear probing across these datasets.", "comment": null, "journal_ref": null, "primary_category": "eess.SP", "categories": "eess.SP;cs.AI;cs.LG", "links": "http://arxiv.org/abs/2505.11939v1;http://arxiv.org/pdf/2505.11939v1", "pdf_url": "http://arxiv.org/pdf/2505.11939v1"}, {"title": "COBIAS: Assessing the Contextual Reliability of Bias Benchmarks for Language Models", "link": "https://dl.acm.org/doi/abs/10.1145/3717867.3717923", "details": "P Govil, H Jain, V Bonagiri, A Chadha, P Kumaraguru\u2026 - Proceedings of the 17th \u2026, 2025", "abstract": "Large Language Models (LLMs) often inherit biases from the web data they are trained on, which contains stereotypes and prejudices. Current methods for evaluating and mitigating these biases rely on bias-benchmark datasets. These \u2026"}, {"title": "ORQA: A Benchmark and Foundation Model for Holistic Operating Room Modeling", "link": "https://arxiv.org/pdf/2505.12890", "details": "E \u00d6zsoy, C Pellegrini, D Bani-Harouni, K Yuan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The real-world complexity of surgeries necessitates surgeons to have deep and holistic comprehension to ensure precision, safety, and effective interventions. Computational systems are required to have a similar level of comprehension within \u2026", "entry_id": "http://arxiv.org/abs/2505.12890v1", "updated": "2025-05-19 09:20:29", "published": "2025-05-19 09:20:29", "authors": "Ege \u00d6zsoy;Chantal Pellegrini;David Bani-Harouni;Kun Yuan;Matthias Keicher;Nassir Navab", "summary": "The real-world complexity of surgeries necessitates surgeons to have deep and\nholistic comprehension to ensure precision, safety, and effective\ninterventions. Computational systems are required to have a similar level of\ncomprehension within the operating room. Prior works, limited to single-task\nefforts like phase recognition or scene graph generation, lack scope and\ngeneralizability. In this work, we introduce ORQA, a novel OR question\nanswering benchmark and foundational multimodal model to advance OR\nintelligence. By unifying all four public OR datasets into a comprehensive\nbenchmark, we enable our approach to concurrently address a diverse range of OR\nchallenges. The proposed multimodal large language model fuses diverse OR\nsignals such as visual, auditory, and structured data, for a holistic modeling\nof the OR. Finally, we propose a novel, progressive knowledge distillation\nparadigm, to generate a family of models optimized for different speed and\nmemory requirements. We show the strong performance of ORQA on our proposed\nbenchmark, and its zero-shot generalization, paving the way for scalable,\nunified OR modeling and significantly advancing multimodal surgical\nintelligence. We will release our code and data upon acceptance.", "comment": null, "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.12890v1;http://arxiv.org/pdf/2505.12890v1", "pdf_url": "http://arxiv.org/pdf/2505.12890v1"}, {"title": "Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI", "link": "https://arxiv.org/pdf/2505.06912", "details": "C Ding, M Bian, P Chen, H Zhang, T Li, L Liu, J Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite strong performance in medical question-answering, the clinical adoption of Large Language Models (LLMs) is critically hampered by their opaque'black- box'reasoning, limiting clinician trust. This challenge is compounded by the \u2026", "entry_id": "http://arxiv.org/abs/2505.06912v1", "updated": "2025-05-11 09:17:28", "published": "2025-05-11 09:17:28", "authors": "Chao Ding;Mouxiao Bian;Pengcheng Chen;Hongliang Zhang;Tianbin Li;Lihao Liu;Jiayuan Chen;Zhuoran Li;Yabei Zhong;Yongqi Liu;Haiqing Huang;Dongming Shan;Junjun He;Jie Xu", "summary": "Despite strong performance in medical question-answering, the clinical\nadoption of Large Language Models (LLMs) is critically hampered by their opaque\n'black-box' reasoning, limiting clinician trust. This challenge is compounded\nby the predominant reliance of current medical LLMs on corpora from scientific\nliterature or synthetic data, which often lack the granular expert validation\nand high clinical relevance essential for advancing their specialized medical\ncapabilities. To address these critical gaps, we introduce a highly clinically\nrelevant dataset with 31,247 medical question-answer pairs, each accompanied by\nexpert-validated chain-of-thought (CoT) explanations. This resource, spanning\nmultiple clinical domains, was curated via a scalable human-LLM hybrid\npipeline: LLM-generated rationales were iteratively reviewed, scored, and\nrefined by medical experts against a structured rubric, with substandard\noutputs revised through human effort or guided LLM regeneration until expert\nconsensus. This publicly available dataset provides a vital source for the\ndevelopment of medical LLMs that capable of transparent and verifiable\nreasoning, thereby advancing safer and more interpretable AI in medicine.", "comment": null, "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.06912v1;http://arxiv.org/pdf/2505.06912v1", "pdf_url": "http://arxiv.org/pdf/2505.06912v1"}, {"title": "Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts", "link": "https://arxiv.org/pdf/2505.12363", "details": "Q Feng, H Shimodaira - arXiv preprint arXiv:2505.12363, 2025", "abstract": "While Multimodal Large Language Models (MLLMs) excel at general vision- language tasks, visuospatial cognition-reasoning about spatial layouts, relations, and dynamics-remains a significant challenge. Existing models often lack the \u2026", "entry_id": "http://arxiv.org/abs/2505.12363v1", "updated": "2025-05-18 10:57:33", "published": "2025-05-18 10:57:33", "authors": "Qi Feng;Hidetoshi Shimodaira", "summary": "While Multimodal Large Language Models (MLLMs) excel at general\nvision-language tasks, visuospatial cognition - reasoning about spatial\nlayouts, relations, and dynamics - remains a significant challenge. Existing\nmodels often lack the necessary architectural components and specialized\ntraining data for fine-grained spatial understanding. We introduce ViCA2\n(Visuospatial Cognitive Assistant 2), a novel MLLM designed to enhance spatial\nreasoning. ViCA2 features a dual vision encoder architecture integrating SigLIP\nfor semantics and Hiera for spatial structure, coupled with a token ratio\ncontrol mechanism for efficiency. We also developed ViCA-322K, a new\nlarge-scale dataset with over 322,000 spatially grounded question-answer pairs\nfor targeted instruction tuning. On the challenging VSI-Bench benchmark, our\nViCA2-7B model achieves a state-of-the-art average score of 56.8, significantly\nsurpassing larger open-source models (e.g., LLaVA-NeXT-Video-72B, 40.9) and\nleading proprietary models (Gemini-1.5 Pro, 45.4). This demonstrates the\neffectiveness of our approach in achieving strong visuospatial intelligence\nwith a compact model. We release ViCA2, its codebase, and the ViCA-322K dataset\nto facilitate further research.", "comment": "26 pages, 19 figures, 4 tables. Code, models, and dataset are\n  available at our project page: https://github.com/nkkbr/ViCA", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.AI;cs.CL;cs.LG;cs.RO", "links": "http://arxiv.org/abs/2505.12363v1;http://arxiv.org/pdf/2505.12363v1", "pdf_url": "http://arxiv.org/pdf/2505.12363v1"}, {"title": "On the Thinking-Language Modeling Gap in Large Language Models", "link": "https://arxiv.org/pdf/2505.12896", "details": "C Liu, Y Chen, T Liu, J Cheng, B Han, K Zhang - arXiv preprint arXiv:2505.12896, 2025", "abstract": "System 2 reasoning is one of the defining characteristics of intelligence, which requires slow and logical thinking. Human conducts System 2 reasoning via the language of thoughts that organizes the reasoning process as a causal sequence of \u2026", "entry_id": "http://arxiv.org/abs/2505.12896v1", "updated": "2025-05-19 09:31:52", "published": "2025-05-19 09:31:52", "authors": "Chenxi Liu;Yongqiang Chen;Tongliang Liu;James Cheng;Bo Han;Kun Zhang", "summary": "System 2 reasoning is one of the defining characteristics of intelligence,\nwhich requires slow and logical thinking. Human conducts System 2 reasoning via\nthe language of thoughts that organizes the reasoning process as a causal\nsequence of mental language, or thoughts. Recently, it has been observed that\nSystem 2 reasoning can be elicited from Large Language Models (LLMs)\npre-trained on large-scale natural languages. However, in this work, we show\nthat there is a significant gap between the modeling of languages and thoughts.\nAs language is primarily a tool for humans to share knowledge and thinking,\nmodeling human language can easily absorb language biases into LLMs deviated\nfrom the chain of thoughts in minds. Furthermore, we show that the biases will\nmislead the eliciting of \"thoughts\" in LLMs to focus only on a biased part of\nthe premise. To this end, we propose a new prompt technique termed\nLanguage-of-Thoughts (LoT) to demonstrate and alleviate this gap. Instead of\ndirectly eliciting the chain of thoughts from partial information, LoT\ninstructs LLMs to adjust the order and token used for the expressions of all\nthe relevant information. We show that the simple strategy significantly\nreduces the language modeling biases in LLMs and improves the performance of\nLLMs across a variety of reasoning tasks.", "comment": "Chenxi and Yongqiang contributed equally; project page:\n  https://causalcoat.github.io/lot.html", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.LG;stat.ML", "links": "http://arxiv.org/abs/2505.12896v1;http://arxiv.org/pdf/2505.12896v1", "pdf_url": "http://arxiv.org/pdf/2505.12896v1"}]
