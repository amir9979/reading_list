[{"title": "DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding", "link": "https://arxiv.org/pdf/2412.10302%3F", "details": "Z Wu, X Chen, Z Pan, X Liu, W Liu, D Dai, H Gao, Y Ma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades. For the vision component, we \u2026"}, {"title": "Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning", "link": "https://arxiv.org/pdf/2412.08614", "details": "F Lu, W Wu, K Zheng, S Ma, B Gong, J Liu, W Zhai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generating detailed captions comprehending text-rich visual content in images has received growing attention for Large Vision-Language Models (LVLMs). However, few studies have developed benchmarks specifically tailored for detailed captions to \u2026"}, {"title": "Domain knowledge boosted adaptation: Leveraging vision-language models for multi-source domain adaptation", "link": "https://www.sciencedirect.com/science/article/pii/S092523122401885X", "details": "Y He, J Feng, G Ding, Y Guo, T He - Neurocomputing, 2024", "abstract": "Multi-source domain adaptation (MSDA) aims to adapt a model trained on multiple labeled source domains to an unlabeled target domain. Existing MSDA methods primarily focus on reducing domain gaps by aligning the source domains with the \u2026"}, {"title": "AdvDreamer Unveils: Are Vision-Language Models Truly Ready for Real-World 3D Variations?", "link": "https://arxiv.org/pdf/2412.03002", "details": "S Ruan, H Liu, Y Huang, X Wang, C Kang, H Su\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision Language Models (VLMs) have exhibited remarkable generalization capabilities, yet their robustness in dynamic real-world scenarios remains largely unexplored. To systematically evaluate VLMs' robustness to real-world 3D variations \u2026"}, {"title": "PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation", "link": "https://arxiv.org/pdf/2412.15209%3F", "details": "M Wahed, KA Nguyen, AS Juvekar, X Li, X Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite significant advancements in Large Vision-Language Models (LVLMs), existing pixel-grounding models operate on single-image settings, limiting their ability to perform detailed, fine-grained comparisons across multiple images \u2026"}, {"title": "An Approach to Complex Visual Data Interpretation with Vision-Language Models", "link": "https://openaccess.thecvf.com/content/ACCV2024W/LAVA/papers/Nguyen_An_Approach_to_Complex_Visual_Data_Interpretation_with_Vision-Language_Models_ACCVW_2024_paper.pdf", "details": "TS Nguyen, VT Huynh, VL Nguyen, MT Tran - \u2026 of the Asian Conference on Computer \u2026, 2024", "abstract": "The LAVA Workshop 2024 challenge aimed to assess the capability of Large Vision- Language Models (VLMs) to interpret and understand complex visual data accurately. This includes intricate visual formats such as data flow diagrams, class \u2026"}, {"title": "Delve into Visual Contrastive Decoding for Hallucination Mitigation of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.06775", "details": "YL Lee, YH Tsai, WC Chiu - arXiv preprint arXiv:2412.06775, 2024", "abstract": "While large vision-language models (LVLMs) have shown impressive capabilities in generating plausible responses correlated with input visual contents, they still suffer from hallucinations, where the generated text inaccurately reflects visual contents. To \u2026"}, {"title": "Deliberative alignment: Reasoning enables safer language models", "link": "https://arxiv.org/pdf/2412.16339", "details": "MY Guan, M Joglekar, E Wallace, S Jain, B Barak\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large-scale language models increasingly impact safety-critical domains, ensuring their reliable adherence to well-defined principles remains a fundamental challenge. We introduce Deliberative Alignment, a new paradigm that directly \u2026"}, {"title": "From Models to Microtheories: Distilling a Model's Topical Knowledge for Grounded Question Answering", "link": "https://arxiv.org/pdf/2412.17701", "details": "N Weir, BD Mishra, O Weller, O Tafjord, S Hornstein\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent reasoning methods (eg, chain-of-thought, entailment reasoning) help users understand how language models (LMs) answer a single question, but they do little to reveal the LM's overall understanding, or\" theory,\" about the question's $\\textit \u2026"}]
