[{"title": "MiMo: Unlocking the Reasoning Potential of Language Model--From Pretraining to Posttraining", "link": "https://arxiv.org/pdf/2505.07608", "details": "B Xia, B Shen, D Zhu, D Zhang, G Wang, H Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing \u2026"}, {"title": "HF4Rec: Human-Like Feedback-Driven Optimization Framework for Explainable Recommendation", "link": "https://arxiv.org/pdf/2504.14147", "details": "J Tang, J Zhang, Z Tian, X Feng, L Wang, X Chen - arXiv preprint arXiv:2504.14147, 2025", "abstract": "Recent advancements in explainable recommendation have greatly bolstered user experience by elucidating the decision-making rationale. However, the existing methods actually fail to provide effective feedback signals for potentially better or \u2026"}, {"title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning", "link": "https://arxiv.org/pdf/2504.09772%3F", "details": "C Jin, H Peng, Q Zhang, Y Tang, DN Metaxas, T Che - arXiv preprint arXiv \u2026, 2025", "abstract": "Multi-agent systems (MAS) built on large language models (LLMs) offer a promising path toward solving complex, real-world tasks that single-agent systems often struggle to manage. While recent advancements in test-time scaling (TTS) have \u2026"}, {"title": "A Context-Aware Contrastive Learning Framework for Hateful Meme Detection and Segmentation", "link": "https://aclanthology.org/2025.findings-naacl.289.pdf", "details": "X Su, Y Li, D Inkpen, N Japkowicz - Findings of the Association for Computational \u2026, 2025", "abstract": "Amidst the rise of Large Multimodal Models (LMMs) and their widespread application in generating and interpreting complex content, the risk of propagating biased and harmful memes remains significant. Current safety measures often fail to detect \u2026"}, {"title": "Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation", "link": "https://arxiv.org/pdf/2504.12108", "details": "S Cai, L Ding, D Tao - arXiv preprint arXiv:2504.12108, 2025", "abstract": "The rapid development of Large Language Models (LLMs) has intensified concerns about content traceability and potential misuse. Existing watermarking schemes for sampled text often face trade-offs between maintaining text quality and ensuring \u2026"}]
