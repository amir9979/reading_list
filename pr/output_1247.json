'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Detecting Edited Knowledge in Language Models](https:/'
[{"title": "Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents", "link": "https://arxiv.org/pdf/2405.02732", "details": "S Singhania, S Razniewski, G Weikum - arXiv preprint arXiv:2405.02732, 2024", "abstract": "Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be \u2026"}, {"title": "Small Language Models Need Strong Verifiers to Self-Correct Reasoning", "link": "https://arxiv.org/pdf/2404.17140", "details": "Y Zhang, M Khalifa, L Logeswaran, J Kim, M Lee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether \u2026"}, {"title": "You Only Cache Once: Decoder-Decoder Architectures for Language Models", "link": "https://arxiv.org/pdf/2405.05254", "details": "Y Sun, L Dong, Y Zhu, S Huang, W Wang, S Ma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce a decoder-decoder architecture, YOCO, for large language models, which only caches key-value pairs once. It consists of two components, ie, a cross- decoder stacked upon a self-decoder. The self-decoder efficiently encodes global \u2026"}, {"title": "Soft Preference Optimization: Aligning Language Models to Expert Distributions", "link": "https://arxiv.org/pdf/2405.00747", "details": "A Sharifnassab, S Ghiassian, S Salehkaleybar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We propose Soft Preference Optimization (SPO), a method for aligning generative models, such as Large Language Models (LLMs), with human preferences, without the need for a reward model. SPO optimizes model outputs directly over a preference \u2026"}, {"title": "Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking", "link": "https://arxiv.org/pdf/2405.04685", "details": "EC Acikgoz, M Erdogan, D Yuret - arXiv preprint arXiv:2405.04685, 2024", "abstract": "Large Language Models (LLMs) are becoming crucial across various fields, emphasizing the urgency for high-quality models in underrepresented languages. This study explores the unique challenges faced by low-resource languages, such \u2026"}, {"title": "Introducing cosmosGPT: Monolingual Training for Turkish Language Models", "link": "https://arxiv.org/pdf/2404.17336", "details": "HT Kesgin, MK Yuce, E Dogan, ME Uzun, A Uz\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The number of open source language models that can produce Turkish is increasing day by day, as in other languages. In order to create the basic versions of such models, the training of multilingual models is usually continued with Turkish corpora \u2026"}, {"title": "A Dataset for Evaluating Contextualized Representation of Biomedical Concepts in Language Models", "link": "https://www.nature.com/articles/s41597-024-03317-w", "details": "H Rouhizadeh, I Nikishina, A Yazdani, A Bornet\u2026 - Scientific Data, 2024", "abstract": "Due to the complexity of the biomedical domain, the ability to capture semantically meaningful representations of terms in context is a long-standing challenge. Despite important progress in the past years, no evaluation benchmark has been developed \u2026"}, {"title": "R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2405.02659", "details": "T Zhang, D Li, Q Chen, C Wang, L Huang, H Xue, X He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Retrieval-augmented large language models (LLMs) leverage relevant content retrieved by information retrieval systems to generate correct responses, aiming to alleviate the hallucination problem. However, existing retriever-responder methods \u2026"}, {"title": "A Framework for Real-time Safeguarding the Text Generation of Large Language", "link": "https://arxiv.org/pdf/2404.19048", "details": "X Dong, D Lin, S Wang, AE Hassan - arXiv preprint arXiv:2404.19048, 2024", "abstract": "Large Language Models (LLMs) have significantly advanced natural language processing (NLP) tasks but also pose ethical and societal risks due to their propensity to generate harmful content. To address this, various approaches have \u2026"}]
