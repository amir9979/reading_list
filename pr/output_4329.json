[{"title": "AutoCTS++: Zero-shot Joint Neural Architecture and Hyperparameter Search for Correlated Time Series Forecasting", "link": "https://vbn.aau.dk/files/730426496/AutoCTS_.pdf", "details": "X Wu, B Yang, C Guo, J Hu, CS Jensen - The VLDB Journal, 2024", "abstract": "Sensors in cyber-physical systems often capture interconnected processes and thus emit correlated time series (CTS), the forecasting of which enables important applications. Recent deep learning based forecasting methods show strong \u2026"}, {"title": "Relation-Preserving Masked Modeling for Semi-Supervised Time-Series Classification", "link": "https://www.sciencedirect.com/science/article/pii/S0020025524011277", "details": "S Lee, C Choi, Y Son - Information Sciences, 2024", "abstract": "In this study, we address the challenge of label sparsity in time-series classification using semi-supervised learning that effectively leverages numerous unlabeled instances. Our approach introduces a pioneering framework for semi-supervised \u2026"}, {"title": "Federated Distillation for Medical Image Classification: Towards Trustworthy Computer-Aided Diagnosis", "link": "https://arxiv.org/pdf/2407.02261", "details": "S Ren, Y Hu, S Chen, G Wang - arXiv preprint arXiv:2407.02261, 2024", "abstract": "Medical image classification plays a crucial role in computer-aided clinical diagnosis. While deep learning techniques have significantly enhanced efficiency and reduced costs, the privacy-sensitive nature of medical imaging data complicates centralized \u2026"}, {"title": "FedPA: Generator-Based Heterogeneous Federated Prototype Adversarial Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10579863/", "details": "L Jiang, X Wang, X Yang, J Shu, H Lin, X Yi - IEEE Transactions on Dependable and \u2026, 2024", "abstract": "Federated Learning is an emerging distributed algorithm that is designed to collaboratively train the global model without accessing clients' private data. However, heterogeneity of data among clients leads to significant degradation in \u2026"}, {"title": "FMamba: Mamba based on Fast-attention for Multivariate Time-series Forecasting", "link": "https://arxiv.org/pdf/2407.14814", "details": "S Ma, Y Kang, P Bai, YB Zhao - arXiv preprint arXiv:2407.14814, 2024", "abstract": "In multivariate time-series forecasting (MTSF), extracting the temporal correlations of the input sequences is crucial. While popular Transformer-based predictive models can perform well, their quadratic computational complexity results in inefficiency and \u2026"}, {"title": "One Process Spatiotemporal Learning of Transformers via Vcls Token for Multivariate Time Series Forecasting", "link": "https://www.researchgate.net/profile/Jingzehua-Xu/publication/381739943_One_Process_Spatiotemporal_Learning_of_Transformers_via_Vcls_Token_for_Multivariate_Time_Series_Forecasting/links/667d11d5f3b61c4e2c8ebd08/One-Process-Spatiotemporal-Learning-of-Transformers-via-Vcls-Token-for-Multivariate-Time-Series-Forecasting.pdf", "details": "T Cai, H Wu, D Niu, X Xia, J Jiang, J Xu", "abstract": "Previous Transformer-based models for multivariate time series forecasting mainly focus on temporal dependence learning and neglect the association between variables. The recent method of adding Attention on spatial (variate) tokens before or \u2026"}]
