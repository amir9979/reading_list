'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Clinical information extraction for Low-resource langu'
[{"title": "Machine learning for healthcare that matters: Reorienting from technical novelty to equitable impact", "link": "https://journals.plos.org/digitalhealth/article%3Fid%3D10.1371/journal.pdig.0000474", "details": "A Balagopalan, I Baldini, LA Celi, J Gichoya, LG McCoy\u2026 - PLOS Digital Health, 2024", "abstract": "Despite significant technical advances in machine learning (ML) over the past several years, the tangible impact of this technology in healthcare has been limited. This is due not only to the particular complexities of healthcare, but also due to \u2026"}, {"title": "AI-Generated Draft Replies Integrated Into Health Records and Physicians' Electronic Communication", "link": "https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2817615", "details": "M Tai-Seale, SL Baxter, F Vaida, A Walker, AM Sitapati\u2026 - JAMA Network Open, 2024", "abstract": "Importance Timely tests are warranted to assess the association between generative artificial intelligence (GenAI) use and physicians' work efforts. Objective To investigate the association between GenAI-drafted replies for patient messages and \u2026"}, {"title": "Pre-training Small Base LMs with Fewer Tokens", "link": "https://arxiv.org/pdf/2404.08634", "details": "S Sanyal, S Sanghavi, AG Dimakis - arXiv preprint arXiv:2404.08634, 2024", "abstract": "We study the effectiveness of a simple approach to develop a small base language model (LM) starting from an existing large base LM: first inherit a few transformer blocks from the larger LM, and then train this smaller model on a very small subset \u2026"}, {"title": "Temporal-Spatial Prediction: Pre-Training on Diverse Datasets for EEG Classification", "link": "https://ieeexplore.ieee.org/abstract/document/10447845/", "details": "Z Li, LM Zhao, WL Zheng, BL Lu - ICASSP 2024-2024 IEEE International Conference \u2026, 2024", "abstract": "Electroencephalogram (EEG) classification tasks have received increasing attention because its high application value. Meanwhile, the great success of general pre- training models in language processing areas inspires us to excavate the potential of \u2026"}, {"title": "AI for Biomedicine in the Era of Large Language Models", "link": "https://arxiv.org/pdf/2403.15673", "details": "Z Bi, SA Dip, D Hajialigol, S Kommu, H Liu, M Lu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The capabilities of AI for biomedicine span a wide spectrum, from the atomic level, where it solves partial differential equations for quantum systems, to the molecular level, predicting chemical or protein structures, and further extending to societal \u2026"}, {"title": "DKE-Research at SemEval-2024 Task 2: Incorporating Data Augmentation with Generative Models and Biomedical Knowledge to Enhance Inference Robustness", "link": "https://arxiv.org/pdf/2404.09206", "details": "Y Wang, Z Wang, W Wang, Q Chen, K Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Safe and reliable natural language inference is critical for extracting insights from clinical trial reports but poses challenges due to biases in large pre-trained language models. This paper presents a novel data augmentation technique to improve model \u2026"}]
