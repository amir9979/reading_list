[{"title": "A vision\u2013language foundation model for precision oncology", "link": "https://www.nature.com/articles/s41586-024-08378-w", "details": "J Xiang, X Wang, X Zhang, Y Xi, F Eweje, Y Chen, Y Li\u2026 - Nature, 2025", "abstract": "Clinical decision-making is driven by multimodal data, including clinical notes and pathological characteristics. Artificial intelligence approaches that can effectively integrate multimodal data hold significant promise in advancing clinical care \u2026"}, {"title": "Str-GCL: Structural Commonsense Driven Graph Contrastive Learning", "link": "https://openreview.net/pdf%3Fid%3DzefCoSncYR", "details": "D He, Y Huang, J Zhao, X Wang, Z Wang - THE WEB CONFERENCE 2025", "abstract": "Graph Contrastive Learning (GCL) is a widely adopted approach in unsupervised representation learning, utilizing representational constraints to derive effective embeddings. However, current GCL methods primarily focus on capturing implicit \u2026"}, {"title": "Lightweight Weighted Average Ensemble Model for Pneumonia Detection in Chest X-Ray Images", "link": "https://arxiv.org/pdf/2501.16249", "details": "SB Nettur, S Karpurapu, U Nettur, LS Gajja, S Myneni\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Pneumonia is a leading cause of illness and death in children, underscoring the need for early and accurate detection. In this study, we propose a novel lightweight ensemble model for detecting pneumonia in children using chest X-ray images. This \u2026"}, {"title": "AI-Driven Radiology Report Generation for Traumatic Brain Injuries", "link": "https://link.springer.com/article/10.1007/s10278-025-01411-y", "details": "R Bouslimi, H Trabelsi, WBA Karaa, H Hedhli - Journal of Imaging Informatics in \u2026, 2025", "abstract": "Traumatic brain injuries present significant diagnostic challenges in emergency medicine, where the timely interpretation of medical images is crucial for patient outcomes. In this paper, we propose a novel AI-based approach for automatic \u2026"}, {"title": "Focus Your Attention: Multiple Instance Learning with Attention Modification for Whole Slide Pathological Image Classification", "link": "https://ieeexplore.ieee.org/iel8/76/4358651/10838539.pdf", "details": "H Cheng, S Huang, L Cai, Y Xu, R Wang, Y Zhang - IEEE Transactions on Circuits \u2026, 2025", "abstract": "Computer-aided pathology diagnosis based on whole slide images, which is often formulated as a weakly supervised multiple instance learning (MIL) paradigm. Current approaches generally employ attention mechanisms to aggregate instance \u2026"}, {"title": "Supervision-free Vision-Language Alignment", "link": "https://arxiv.org/pdf/2501.04568%3F", "details": "G Giannone, R Li, Q Feng, E Perevodchikov, R Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation \u2026"}, {"title": "Valley2: Exploring Multimodal Models with Scalable Vision-Language Design", "link": "https://arxiv.org/pdf/2501.05901", "details": "Z Wu, Z Chen, R Luo, C Zhang, Y Gao, Z He, X Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, vision-language models have made remarkable progress, demonstrating outstanding capabilities in various tasks such as image captioning and video understanding. We introduce Valley2, a novel multimodal large language model \u2026"}, {"title": "A Lung CT Foundation Model Facilitating Disease Diagnosis and Medical Imaging", "link": "https://www.medrxiv.org/content/medrxiv/early/2025/01/15/2025.01.13.25320295.full.pdf", "details": "Z Gao, G Zhang, H Liang, J Liu, L Ma, T Wang, Y Guo\u2026 - medRxiv, 2025", "abstract": "The concomitant development and evolution of lung computed tomography (CT) and artificial intelligence (AI) has allowed non-invasive lung imaging to be a key part of the clinical care of patients with major diseases, such as lung cancer. However, the \u2026"}, {"title": "Enhancing few-shot KB-VQA with panoramic image captions guided by Large Language Models", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225000451", "details": "P Qiang, H Tan, X Li, D Wang, R Li, X Sun, H Zhang\u2026 - Neurocomputing, 2025", "abstract": "Current state-of-the-art (SOTA) KB-VQA techniques involve transforming images into image captions as prompts to harness the potent reasoning capabilities of large language models (LLMs) for generating answers. However, generic image captions \u2026"}]
