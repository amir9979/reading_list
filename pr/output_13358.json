[{"title": "Scaling Laws for Upcycling Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2502.03009", "details": "SP Liew, T Kato, S Takase - arXiv preprint arXiv:2502.03009, 2025", "abstract": "Pretraining large language models (LLMs) is resource-intensive, often requiring months of training time even with high-end GPU clusters. There are two approaches of mitigating such computational demands: reusing smaller models to train larger \u2026"}, {"title": "Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search", "link": "https://arxiv.org/pdf/2502.02508", "details": "M Shen, G Zeng, Z Qi, ZW Hong, Z Chen, W Lu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning capabilities across diverse domains. Recent studies have shown that increasing test- time computation enhances LLMs' reasoning capabilities. This typically involves \u2026"}, {"title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution", "link": "https://arxiv.org/pdf/2502.18449", "details": "Y Wei, O Duchenne, J Copet, Q Carbonneaux, L Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The recent DeepSeek-R1 release has demonstrated the immense potential of reinforcement learning (RL) in enhancing the general reasoning capabilities of large language models (LLMs). While DeepSeek-R1 and other follow-up work primarily \u2026"}, {"title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization", "link": "https://arxiv.org/pdf/2502.04306%3F", "details": "Y Wang, L Yang, G Li, M Wang, B Aragam - arXiv preprint arXiv:2502.04306, 2025", "abstract": "Recent research has leveraged large language model multi-agent systems for complex problem-solving while trying to reduce the manual effort required to build them, driving the development of automated agent workflow optimization methods \u2026"}, {"title": "Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant", "link": "https://arxiv.org/pdf/2501.17546", "details": "G He, N Aishwarya, U Gadiraju - arXiv preprint arXiv:2501.17546, 2025", "abstract": "Explainable artificial intelligence (XAI) methods are being proposed to help interpret and understand how AI systems reach specific predictions. Inspired by prior work on conversational user interfaces, we argue that augmenting existing XAI methods with \u2026"}, {"title": "A Training Data Recipe to Accelerate A* Search with Large Language Models", "link": "http://www.boyangli.org/paper/Gupta-EMNLP-2024.pdf", "details": "D Gupta, B Li", "abstract": "Abstract Combining Large Language Models (LLMs) with heuristic search algorithms like A* holds the promise of enhanced LLM reasoning and scalable inference. To accelerate training and reduce computational demands, we investigate the coreset \u2026"}, {"title": "From Text to Trust: Empowering AI-assisted Decision Making with Adaptive LLM-powered Analysis", "link": "https://arxiv.org/pdf/2502.11919", "details": "Z Li, H Zhu, Z Lu, Z Xiao, M Yin - arXiv preprint arXiv:2502.11919, 2025", "abstract": "AI-assisted decision making becomes increasingly prevalent, yet individuals often fail to utilize AI-based decision aids appropriately especially when the AI explanations are absent, potentially as they do not% understand reflect on AI's \u2026"}, {"title": "Smoothing Out Hallucinations: Mitigating LLM Hallucination with Smoothed Knowledge Distillation", "link": "https://arxiv.org/pdf/2502.11306", "details": "H Nguyen, Z He, SA Gandre, U Pasupulety\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) often suffer from hallucination, generating factually incorrect or ungrounded content, which limits their reliability in high-stakes applications. A key factor contributing to hallucination is the use of hard labels during \u2026"}, {"title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies", "link": "https://arxiv.org/pdf/2502.08554", "details": "SSY Kim, JW Vaughan, QV Liao, T Lombrozo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study \u2026"}]
