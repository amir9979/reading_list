[{"title": "Matching tasks to objectives: Fine-tuning and prompt-tuning strategies for encoder-decoder pre-trained language models", "link": "https://link.springer.com/article/10.1007/s10489-024-05660-2", "details": "A Pouramini, H Faili - Applied Intelligence, 2024", "abstract": "Prompt-based learning has emerged as a dominant paradigm in natural language processing. This study explores the impact of diverse pre-training objectives on the performance of encoder-decoder pre-trained language models across generation \u2026"}, {"title": "Reflective Instruction Tuning: Mitigating Hallucinations in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2407.11422", "details": "J Zhang, T Wang, H Zhang, P Lu, F Zheng - arXiv preprint arXiv:2407.11422, 2024", "abstract": "Large vision-language models (LVLMs) have shown promising performance on a variety of vision-language tasks. However, they remain susceptible to hallucinations, generating outputs misaligned with visual content or instructions. While various \u2026"}, {"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "Evaluating language models as risk scores", "link": "https://arxiv.org/pdf/2407.14614", "details": "AF Cruz, M Hardt, C Mendler-D\u00fcnner - arXiv preprint arXiv:2407.14614, 2024", "abstract": "Current question-answering benchmarks predominantly focus on accuracy in realizable prediction tasks. Conditioned on a question and answer-key, does the most likely token match the ground truth? Such benchmarks necessarily fail to \u2026"}, {"title": "Compact Language Models via Pruning and Knowledge Distillation", "link": "https://arxiv.org/pdf/2407.14679", "details": "S Muralidharan, ST Sreenivas, R Joshi, M Chochowski\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) targeting different deployment scales and sizes are currently produced by training each variant from scratch; this is extremely compute- intensive. In this paper, we investigate if pruning an existing LLM and then re-training \u2026"}, {"title": "In-Context Learning Improves Compositional Understanding of Vision-Language Models", "link": "https://arxiv.org/pdf/2407.15487", "details": "M Nulli, A Ibrahimi, A Pal, H Lee, I Najdenkoska - arXiv preprint arXiv:2407.15487, 2024", "abstract": "Vision-Language Models (VLMs) have shown remarkable capabilities in a large number of downstream tasks. Nonetheless, compositional image understanding remains a rather difficult task due to the object bias present in training data. In this \u2026"}, {"title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability", "link": "https://arxiv.org/pdf/2407.19842", "details": "J Garc\u00eda-Carrasco, A Mat\u00e9, J Trujillo - arXiv preprint arXiv:2407.19842, 2024", "abstract": "Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the \u2026"}, {"title": "Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment", "link": "https://arxiv.org/pdf/2407.03051", "details": "J Lee, S Park, S Hong, M Kim, DS Chang, J Choi - arXiv preprint arXiv:2407.03051, 2024", "abstract": "The rapid advancement of large language models (LLMs) has facilitated their transformation into conversational chatbots that can grasp contextual nuances and generate pertinent sentences, closely mirroring human values through advanced \u2026"}, {"title": "Improving Context-Aware Preference Modeling for Language Models", "link": "https://arxiv.org/pdf/2407.14916", "details": "S Pitis, Z Xiao, NL Roux, A Sordoni - arXiv preprint arXiv:2407.14916, 2024", "abstract": "While finetuning language models from pairwise preferences has proven remarkably effective, the underspecified nature of natural language presents critical challenges. Direct preference feedback is uninterpretable, difficult to provide where \u2026"}]
