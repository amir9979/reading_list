[{"title": "Vision-Language Model Dialog Games for Self-Improvement", "link": "https://arxiv.org/pdf/2502.02740", "details": "K Konyushkova, C Kaplanis, S Cabi, M Denil - arXiv preprint arXiv:2502.02740, 2025", "abstract": "The increasing demand for high-quality, diverse training data poses a significant bottleneck in advancing vision-language models (VLMs). This paper presents VLM Dialog Games, a novel and scalable self-improvement framework for VLMs. Our \u2026"}, {"title": "Computer-aided cholelithiasis diagnosis using explainable convolutional neural network", "link": "https://www.nature.com/articles/s41598-025-85798-2", "details": "D Kumar, MA Mehta, K Kotecha, A Kulkarni - Scientific Reports, 2025", "abstract": "Accurate and precise identification of cholelithiasis is essential for saving the lives of millions of people worldwide. Although several computer-aided cholelithiasis diagnosis approaches have been introduced in the literature, their use is limited \u2026"}, {"title": "Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective", "link": "https://arxiv.org/pdf/2502.02719", "details": "S Azzolin, S Malhotra, A Passerini, S Teso - arXiv preprint arXiv:2502.02719, 2025", "abstract": "Self-Explainable Graph Neural Networks (SE-GNNs) are popular explainable-by- design GNNs, but the properties and the limitations of their explanations are not well understood. Our first contribution fills this gap by formalizing the explanations \u2026"}, {"title": "Quasi-Metric Learning for Bilateral Person-Job Fit", "link": "https://www.computer.org/csdl/journal/tp/5555/01/10870255/24481RMCk9i", "details": "Y Du, H Liu, H Zhu, Y Song, Z Zheng, Z Wu - IEEE Transactions on Pattern Analysis & \u2026, 2025", "abstract": "Matching suitable jobs provided by employers with qualified candidates is a crucial task for online recruitment. Typically, candidates and employers have specific expectations in recruitment market, leading them to prefer similar jobs and \u2026"}, {"title": "Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2502.03147", "details": "X Wen, S Zheng, Z Xu, Y Sun, J Bian - arXiv preprint arXiv:2502.03147, 2025", "abstract": "Recent studies have shown that large language models (LLMs), when customized with post-training on tabular data, can acquire general tabular in-context learning (TabICL) capabilities. These models are able to transfer effectively across diverse \u2026"}, {"title": "Supervision-free Vision-Language Alignment", "link": "https://arxiv.org/pdf/2501.04568%3F", "details": "G Giannone, R Li, Q Feng, E Perevodchikov, R Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation \u2026"}, {"title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models", "link": "https://arxiv.org/pdf/2502.03199", "details": "J Wu, Y Shen, S Liu, Y Tang, S Song, X Wang, L Cai - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the \u2026"}, {"title": "A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)", "link": "https://arxiv.org/pdf/2502.03450", "details": "Y Chen, H Sawhney, N Gyd\u00e9, Y Jian, J Saunders\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Scene graphs have emerged as a structured and serializable environment representation for grounded spatial reasoning with Large Language Models (LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason \u2026"}]
