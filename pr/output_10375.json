[{"title": "Can Language Models Rival Mathematics Students? Evaluating Mathematical Reasoning through Textual Manipulation and Human Experiments", "link": "https://arxiv.org/pdf/2412.11908", "details": "A Nikolaiev, Y Stathopoulos, S Teufel - arXiv preprint arXiv:2412.11908, 2024", "abstract": "In this paper we look at the ability of recent large language models (LLMs) at solving mathematical problems in combinatorics. We compare models LLaMA-2, LLaMA-3.1, GPT-4, and Mixtral against each other and against human pupils and \u2026"}, {"title": "Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis", "link": "https://arxiv.org/pdf/2412.09521", "details": "S Zhang, W Li, T Gao, J Hu, H Luo, M Song, X Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pathological diagnosis is vital for determining disease characteristics, guiding treatment, and assessing prognosis, relying heavily on detailed, multi-scale analysis of high-resolution whole slide images (WSI). However, traditional pure vision models \u2026"}, {"title": "Leveraging Large Vision-Language Model as User Intent-aware Encoder for Composed Image Retrieval", "link": "https://arxiv.org/pdf/2412.11087", "details": "Z Sun, D Jing, G Yang, N Fei, Z Lu - arXiv preprint arXiv:2412.11087, 2024", "abstract": "Composed Image Retrieval (CIR) aims to retrieve target images from candidate set using a hybrid-modality query consisting of a reference image and a relative caption that describes the user intent. Recent studies attempt to utilize Vision-Language Pre \u2026"}, {"title": "Domain-Invariant Few-Shot Contrastive Learning for Hyperspectral Image Classification", "link": "https://www.mdpi.com/2076-3417/14/23/11053", "details": "W Chen, Y Zhang, J Chu, X Wang - Applied Sciences, 2024", "abstract": "In Hyperspectral Image (HSI) classification, acquiring large quantities of high-quality labeled samples is typically costly and impractical. Traditional deep learning methods are limited in such scenarios due to their dependence on sample quantities \u2026"}, {"title": "Foundation model of ECG diagnosis: Diagnostics and explanations of any form and rhythm on ECG", "link": "https://www.cell.com/cell-reports-medicine/fulltext/S2666-3791\\(24\\)00646-3", "details": "Y Tian, Z Li, Y Jin, M Wang, X Wei, L Zhao, Y Liu, J Liu\u2026 - Cell Reports Medicine, 2024", "abstract": "We propose a knowledge-enhanced electrocardiogram (ECG) diagnosis foundation model (KED) that utilizes large language models to incorporate domain-specific knowledge of ECG signals. This model is trained on 800,000 ECGs from nearly \u2026"}, {"title": "The Vulnerability of Language Model Benchmarks: Do They Accurately Reflect True LLM Performance?", "link": "https://arxiv.org/pdf/2412.03597%3F", "details": "S Banerjee, A Agarwal, E Singh - arXiv preprint arXiv:2412.03597, 2024", "abstract": "The pursuit of leaderboard rankings in Large Language Models (LLMs) has created a fundamental paradox: models excel at standardized tests while failing to demonstrate genuine language understanding and adaptability. Our systematic \u2026"}]
