[{"title": "BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems", "link": "https://arxiv.org/pdf/2408.15971", "details": "W Wang, D Zhang, T Feng, B Wang, J Tang - arXiv preprint arXiv:2408.15971, 2024", "abstract": "Large Language Models (LLMs) are becoming increasingly powerful and capable of handling complex tasks, eg, building single agents and multi-agent systems. Compared to single agents, multi-agent systems have higher requirements for the \u2026"}, {"title": "DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?", "link": "https://arxiv.org/pdf/2409.07703", "details": "L Jing, Z Huang, X Wang, W Yao, W Yu, K Ma, H Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI \u2026"}, {"title": "Safety Layers of Aligned Large Language Models: The Key to LLM Security", "link": "https://arxiv.org/pdf/2408.17003", "details": "S Li, L Yao, L Zhang, Y Li - arXiv preprint arXiv:2408.17003, 2024", "abstract": "Aligned LLMs are highly secure, capable of recognizing and refusing to answer malicious questions. However, the role of internal parameters in maintaining this security is not well understood, further these models are vulnerable to security \u2026"}, {"title": "Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models", "link": "https://arxiv.org/pdf/2408.14866", "details": "H Liu, Y Xie, Y Wang, M Shieh - arXiv preprint arXiv:2408.14866, 2024", "abstract": "Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy \u2026"}, {"title": "Focused Large Language Models are Stable Many-Shot Learners", "link": "https://arxiv.org/pdf/2408.13987", "details": "P Yuan, S Feng, Y Li, X Wang, Y Zhang, C Tan, B Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In-Context Learning (ICL) enables large language models (LLMs) to achieve rapid task adaptation by learning from demonstrations. With the increase in available context length of LLMs, recent experiments have shown that the performance of ICL \u2026"}, {"title": "Towards a Unified View of Preference Learning for Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2409.02795", "details": "B Gao, F Song, Y Miao, Z Cai, Z Yang, L Chen, H Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to \u2026"}, {"title": "AutoTQA: Towards Autonomous Tabular Question Answering through Multi-Agent Large Language Models", "link": "https://www.vldb.org/pvldb/vol17/p3920-zhu.pdf", "details": "JP Zhu, P Cai, K Xu, L Li, Y Sun, S Zhou, H Su, L Tang\u2026", "abstract": "With the growing significance of data analysis, several studies aim to provide precise answers to users' natural language questions from tables, a task referred to as tabular question answering (TQA). The state-of-the-art TQA approaches are limited to \u2026"}, {"title": "Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.14470", "details": "A Agarwal, SK Ramesh, A Sengupta, T Chakraborty - arXiv preprint arXiv:2408.14470, 2024", "abstract": "Fine-tuning large language models (LLMs) on downstream tasks requires substantial computational resources. A class of parameter-efficient fine-tuning (PEFT) aims to mitigate these computational challenges by selectively fine-tuning only a small \u2026"}, {"title": "An Evaluation Framework for Attributed Information Retrieval using Large Language Models", "link": "https://arxiv.org/pdf/2409.08014", "details": "H Djeddal, P Erbacher, R Toukal, L Soulier\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the growing success of Large Language models (LLMs) in information-seeking scenarios, search engines are now adopting generative approaches to provide answers along with in-line citations as attribution. While existing work focuses mainly \u2026"}]
