[{"title": "VisDiaHalBench: A Visual Dialogue Benchmark For Diagnosing Hallucination in Large Vision-Language Models", "link": "https://aclanthology.org/2024.acl-long.658.pdf", "details": "Q Cao, J Cheng, X Liang, L Lin - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Despite the significant success of large vision-language models (LVLMs), some studies have revealed that LVLMs suffer from the hallucination problem, where the LVLMs' response contains descriptions of non-existent objects. Although various \u2026"}, {"title": "Towards Holistic Disease Risk Prediction using Small Language Models", "link": "https://arxiv.org/pdf/2408.06943", "details": "L Bj\u00f6rkdahl, O Pauli, J \u00d6stman, C Ceccobello\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Data in the healthcare domain arise from a variety of sources and modalities, such as x-ray images, continuous measurements, and clinical notes. Medical practitioners integrate these diverse data types daily to make informed and accurate decisions \u2026"}, {"title": "Advancement in Graph Understanding: A Multimodal Benchmark and Fine-Tuning of Vision-Language Models", "link": "https://aclanthology.org/2024.acl-long.404.pdf", "details": "Q Ai, J Li, J Dai, J Zhou, L Liu, H Jiang, S Shi - \u2026 of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Graph data organizes complex relationships and interactions between objects, facilitating advanced analysis and decision-making across different fields. In this paper, we propose a new paradigm for interactive and instructional graph data \u2026"}, {"title": "Look, Compare, Decide: Alleviating Hallucination in Large Vision-Language Models via Multi-View Multi-Path Reasoning", "link": "https://arxiv.org/pdf/2408.17150", "details": "X Qu, J Sun, W Wei, Y Cheng - arXiv preprint arXiv:2408.17150, 2024", "abstract": "Recently, Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities in multi-modal context comprehension. However, they still suffer from hallucination problems referring to generating inconsistent outputs with the image \u2026"}, {"title": "Making Large Vision Language Models to be Good Few-shot Learners", "link": "https://arxiv.org/pdf/2408.11297", "details": "F Liu, W Cai, J Huo, C Zhang, D Chen, J Zhou - arXiv preprint arXiv:2408.11297, 2024", "abstract": "Few-shot classification (FSC) is a fundamental yet challenging task in computer vision that involves recognizing novel classes from limited data. While previous methods have focused on enhancing visual features or incorporating additional \u2026"}, {"title": "Language Models Don't Learn the Physical Manifestation of Language", "link": "https://aclanthology.org/2024.acl-long.195.pdf", "details": "B Lee, J Lim - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "We argue that language-only models don't learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test. These tasks highlight a \u2026"}, {"title": "SPARK: Multi-Vision Sensor Perception and Reasoning Benchmark for Large-scale Vision-Language Models", "link": "https://arxiv.org/pdf/2408.12114", "details": "Y Yu, S Chung, BK Lee, YM Ro - arXiv preprint arXiv:2408.12114, 2024", "abstract": "Large-scale Vision-Language Models (LVLMs) have significantly advanced with text- aligned vision inputs. They have made remarkable progress in computer vision tasks by aligning text modality with vision inputs. There are also endeavors to incorporate \u2026"}, {"title": "Evaluating Attribute Comprehension in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.13898", "details": "H Zhang, Z Yang, Y Liu, X Wang, Z He, K Liang, Z Ma - arXiv preprint arXiv \u2026, 2024", "abstract": "Currently, large vision-language models have gained promising progress on many downstream tasks. However, they still suffer many challenges in fine-grained visual understanding tasks, such as object attribute comprehension. Besides, there have \u2026"}, {"title": "Understanding Defects in Generated Codes by Language Models", "link": "https://arxiv.org/pdf/2408.13372", "details": "AM Esfahani, N Kahani, SA Ajila - arXiv preprint arXiv:2408.13372, 2024", "abstract": "This study investigates the reliability of code generation by Large Language Models (LLMs), focusing on identifying and analyzing defects in the generated code. Despite the advanced capabilities of LLMs in automating code generation, ensuring the \u2026"}]
