[{"title": "Efficient Architectures for High Resolution Vision-Language Models", "link": "https://arxiv.org/pdf/2501.02584", "details": "M Carvalho, B Martins - arXiv preprint arXiv:2501.02584, 2025", "abstract": "Vision-Language Models (VLMs) have recently experienced significant advancements. However, challenges persist in the accurate recognition of fine details within high resolution images, which limits performance in multiple tasks. This \u2026"}, {"title": "Vision-BioLLM: Large vision language model for visual dialogue in biomedical imagery", "link": "https://www.sciencedirect.com/science/article/pii/S1746809424014952", "details": "A AlShibli, Y Bazi, MM Al Rahhal, M Zuair - Biomedical Signal Processing and Control, 2025", "abstract": "In this paper, we present a vision-language model tailored for visual dialogue in the biomedical domain, utilizing a LanguageBind transformer as the vision encoder and Llama3-OpenBioLLM as the language decoder. Our training approach involves three \u2026"}]
