[{"title": "CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations", "link": "https://arxiv.org/pdf/2412.04254", "details": "S Neupane, H Tripathi, S Mitra, S Bozorgzad, S Mittal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper presents ClinicSum, a novel framework designed to automatically generate clinical summaries from patient-doctor conversations. It utilizes a two- module architecture: a retrieval-based filtering module that extracts Subjective \u2026"}, {"title": "Enhancing vision-language models for medical imaging: bridging the 3D gap with innovative slice selection", "link": "https://openreview.net/pdf%3Fid%3DJrJW21IP9p", "details": "Y Wang, Y Dai, C Jones, HI Sair, J Shen, N Loizou\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent approaches to vision-language tasks are built on the remarkable capabilities of large vision-language models (VLMs). These models excel in zero-shot and few- shot learning, enabling them to learn new tasks without parameter updates \u2026"}, {"title": "Mixed Distillation Helps Smaller Language Models Reason Better", "link": "https://aclanthology.org/2024.findings-emnlp.91.pdf", "details": "L Chenglin, Q Chen, L Li, C Wang, F Tao, Y Li, Z Chen\u2026 - Findings of the Association \u2026, 2024", "abstract": "As large language models (LLMs) have demonstrated impressive multiple step-by- step reasoning capabilities in recent natural language processing (NLP) reasoning tasks, many studies are interested in distilling reasoning abilities into smaller \u2026"}, {"title": "VisionZip: Longer is Better but Not Necessary in Vision Language Models", "link": "https://arxiv.org/pdf/2412.04467", "details": "S Yang, Y Chen, Z Tian, C Wang, J Li, B Yu, J Jia - arXiv preprint arXiv:2412.04467, 2024", "abstract": "Recent advancements in vision-language models have enhanced performance by increasing the length of visual tokens, making them much longer than text tokens and significantly raising computational costs. However, we observe that the visual tokens \u2026"}, {"title": "AdvDreamer Unveils: Are Vision-Language Models Truly Ready for Real-World 3D Variations?", "link": "https://arxiv.org/pdf/2412.03002", "details": "S Ruan, H Liu, Y Huang, X Wang, C Kang, H Su\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision Language Models (VLMs) have exhibited remarkable generalization capabilities, yet their robustness in dynamic real-world scenarios remains largely unexplored. To systematically evaluate VLMs' robustness to real-world 3D variations \u2026"}, {"title": "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "link": "https://aclanthology.org/2024.findings-emnlp.61.pdf", "details": "X Wei, H Chen, H Yu, H Fei, Q Liu - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) have achieved notable success in commonsense reasoning tasks, benefiting from their extensive world knowledge acquired through extensive pretraining. While approaches like Chain-of-Thought \u2026"}, {"title": "Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion", "link": "https://arxiv.org/pdf/2412.04424", "details": "J Chen, J Yang, H Wu, D Li, J Gao, T Zhou, B Xiao - arXiv preprint arXiv:2412.04424, 2024", "abstract": "We present Florence-VL, a new family of multimodal large language models (MLLMs) with enriched visual representations produced by Florence-2, a generative vision foundation model. Unlike the widely used CLIP-style vision transformer trained \u2026"}, {"title": "The quality and safety of using generative AI to produce patient-centred discharge instructions", "link": "https://www.nature.com/articles/s41746-024-01336-w", "details": "K Stanceski, S Zhong, X Zhang, S Khadra, M Tracy\u2026 - npj Digital Medicine, 2024", "abstract": "Patient-centred instructions on discharge can improve adherence and outcomes. Using GPT-3.5 to generate patient-centred discharge instructions, we evaluated responses for safety, accuracy and language simplification. When tested on 100 \u2026"}, {"title": "Label correlated contrastive learning for medical report generation", "link": "https://www.sciencedirect.com/science/article/pii/S0169260724004759", "details": "X Liu, J Xin, B Dai, Q Shen, Z Huang, Z Wang - Computer Methods and Programs in \u2026, 2024", "abstract": "Abstract Background and Objective: Automatic generation of medical reports reduces both the burden on radiologists and the possibility of errors due to the inexperience of radiologists. The model that utilizes attention mechanism and contrastive learning \u2026"}]
