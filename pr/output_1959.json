[{"title": "Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning", "link": "https://arxiv.org/pdf/2405.13448", "details": "Y Yue, C Wang, J Huang, P Wang - arXiv preprint arXiv:2405.13448, 2024", "abstract": "The process of instruction tuning aligns pre-trained large language models (LLMs) with open-domain instructions and human-preferred responses. While several studies have explored autonomous approaches to distilling and annotating \u2026"}, {"title": "MBIAS: Mitigating Bias in Large Language Models While Retaining Context", "link": "https://arxiv.org/pdf/2405.11290", "details": "S Raza, A Raval, V Chatrath - arXiv preprint arXiv:2405.11290, 2024", "abstract": "In addressing the critical need for safety in Large Language Models (LLMs), it is crucial to ensure that the outputs are not only safe but also retain their contextual accuracy. Many existing LLMs are safe fine-tuned either with safety demonstrations \u2026"}, {"title": "Lonas: Elastic low-rank adapters for efficient large language models", "link": "https://aclanthology.org/2024.lrec-main.940.pdf", "details": "JP Munoz, J Yuan, Y Zheng, N Jain - Proceedings of the 2024 Joint International \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) continue to grow, reaching hundreds of billions of parameters and making it challenging for Deep Learning practitioners with resource-constrained systems to use them, eg, fine-tuning these models for a \u2026"}, {"title": "C3L: Content Correlated Vision-Language Instruction Tuning Data Generation via Contrastive Learning", "link": "https://arxiv.org/pdf/2405.12752", "details": "J Ma, W Suo, P Wang, Y Zhang - arXiv preprint arXiv:2405.12752, 2024", "abstract": "Vision-Language Instruction Tuning (VLIT) is a critical training phase for Large Vision- Language Models (LVLMs). With the improving capabilities of open-source LVLMs, researchers have increasingly turned to generate VLIT data by using open-source \u2026"}, {"title": "DocReLM: Mastering Document Retrieval with Language Model", "link": "https://arxiv.org/pdf/2405.11461", "details": "G Wei, X Pang, T Zhang, Y Sun, X Qian, C Lin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With over 200 million published academic documents and millions of new documents being written each year, academic researchers face the challenge of searching for information within this vast corpus. However, existing retrieval systems \u2026"}, {"title": "Correcting Language Model Bias for Text Classification in True Zero-Shot Learning", "link": "https://aclanthology.org/2024.lrec-main.359.pdf", "details": "F Zhao, W Xianlin, C Yan, CK Loo - Proceedings of the 2024 Joint International \u2026, 2024", "abstract": "Combining pre-trained language models (PLMs) and manual templates is a common practice for text classification in zero-shot scenarios. However, the effect of this approach is highly volatile, ranging from random guesses to near state-of-the-art \u2026"}, {"title": "Leros: Learning Explicit Reasoning on Synthesized Data for Commonsense Question Answering", "link": "https://aclanthology.org/2024.lrec-main.900.pdf", "details": "C Wang, P Cao, J Li, Y Chen, K Liu, X Jiang, J Xu\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Recent work shows large language models can be prompted to generate useful rationales for commonsense question answering (CQA), which can improve the performance of both themselves and other models. However, the cost of deployment \u2026"}, {"title": "Exploring and Mitigating Shortcut Learning for Generative Large Language Models", "link": "https://aclanthology.org/2024.lrec-main.602.pdf", "details": "Z Sun, Y Xiao, J Li, Y Ji, W Chen, M Zhang - Proceedings of the 2024 Joint \u2026, 2024", "abstract": "Recent generative large language models (LLMs) have exhibited incredible instruction-following capabilities while keeping strong task completion ability, even without task-specific fine-tuning. Some works attribute this to the bonus of the new \u2026"}, {"title": "xFinder: Robust and Pinpoint Answer Extraction for Large Language Models", "link": "https://arxiv.org/pdf/2405.11874", "details": "Q Yu, Z Zheng, S Song, Z Li, F Xiong, B Tang, D Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "The continuous advancement of large language models (LLMs) has brought increasing attention to the critical issue of developing fair and reliable methods for evaluating their performance. Particularly, the emergence of subjective or non \u2026"}]
