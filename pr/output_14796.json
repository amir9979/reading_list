[{"title": "Boosting the Generalization and Reasoning of Vision Language Models with Curriculum Reinforcement Learning", "link": "https://arxiv.org/pdf/2503.07065%3F", "details": "H Deng, D Zou, R Ma, H Luo, Y Cao, Y Kang - arXiv preprint arXiv:2503.07065, 2025", "abstract": "While state-of-the-art vision-language models (VLMs) have demonstrated remarkable capabilities in complex visual-text tasks, their success heavily relies on massive model scaling, limiting their practical deployment. Small-scale VLMs offer a \u2026"}, {"title": "Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense", "link": "https://arxiv.org/pdf/2503.07020", "details": "Y Hu, C Xu, R Qin, D Liu, A Nassereldine, Y Shi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Partial perception deficits can compromise autonomous vehicle safety by disrupting environmental understanding. Current protocols typically respond with immediate stops or minimal-risk maneuvers, worsening traffic flow and lacking flexibility for rare \u2026"}, {"title": "Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance", "link": "https://arxiv.org/pdf/2503.13445", "details": "NY Siegel, N Heess, M Perez-Ortiz, OM Camburu - arXiv preprint arXiv:2503.13445, 2025", "abstract": "As large language models (LLMs) become increasingly capable, ensuring that their self-generated explanations are faithful to their internal decision-making process is critical for safety and oversight. In this work, we conduct a comprehensive \u2026"}, {"title": "Combinatorial Optimization via LLM-driven Iterated Fine-tuning", "link": "https://arxiv.org/pdf/2503.06917", "details": "P Awasthi, S Gollapudi, R Kumar, K Munagala - arXiv preprint arXiv:2503.06917, 2025", "abstract": "We present a novel way to integrate flexible, context-dependent constraints into combinatorial optimization by leveraging Large Language Models (LLMs) alongside traditional algorithms. Although LLMs excel at interpreting nuanced, locally specified \u2026"}, {"title": "Dancing with Critiques: Enhancing LLM Reasoning with Stepwise Natural Language Self-Critique", "link": "https://arxiv.org/pdf/2503.17363%3F", "details": "Y Li, J Xu, T Liang, X Chen, Z He, Q Liu, R Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Enhancing the reasoning capabilities of large language models (LLMs), particularly for complex tasks requiring multi-step logical deductions, remains a significant challenge. Traditional inference time scaling methods utilize scalar reward signals \u2026"}, {"title": "SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks", "link": "https://arxiv.org/pdf/2503.15478", "details": "Y Zhou, S Jiang, Y Tian, J Weston, S Levine\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language model (LLM) agents need to perform multi-turn interactions in real- world tasks. However, existing multi-turn RL algorithms for optimizing LLM agents fail to perform effective credit assignment over multiple turns while leveraging the \u2026"}, {"title": "Aligning Multimodal LLM with Human Preference: A Survey", "link": "https://arxiv.org/pdf/2503.14504", "details": "T Yu, C Fu, J Wu, J Lu, K Wang, X Lu, Y Shen, G Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) can handle a wide variety of general tasks with simple prompts, without the need for task-specific training. Multimodal Large Language Models (MLLMs), built upon LLMs, have demonstrated impressive \u2026"}, {"title": "A Comprehensive Study of LLM Secure Code Generation", "link": "https://arxiv.org/pdf/2503.15554%3F", "details": "SC Dai, J Xu, G Tao - arXiv preprint arXiv:2503.15554, 2025", "abstract": "LLMs are widely used in software development. However, the code generated by LLMs often contains vulnerabilities. Several secure code generation methods have been proposed to address this issue, but their current evaluation schemes leave \u2026"}, {"title": "Exploring the Multilingual NLG Evaluation Abilities of LLM-Based Evaluators", "link": "https://arxiv.org/pdf/2503.04360", "details": "J Chang, M Gao, X Hu, X Wan - arXiv preprint arXiv:2503.04360, 2025", "abstract": "Previous research has shown that LLMs have potential in multilingual NLG evaluation tasks. However, existing research has not fully explored the differences in the evaluation capabilities of LLMs across different languages. To this end, this study \u2026"}]
