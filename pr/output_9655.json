[{"title": "RedPajama: an Open Dataset for Training Large Language Models", "link": "https://arxiv.org/pdf/2411.12372%3F", "details": "M Weber, D Fu, Q Anthony, Y Oren, S Adams\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models are increasingly becoming a cornerstone technology in artificial intelligence, the sciences, and society as a whole, yet the optimal strategies for dataset composition and filtering remain largely elusive. Many of the top \u2026"}, {"title": "metaTextGrad: Learning to learn with language models as optimizers", "link": "https://openreview.net/pdf%3Fid%3DyzieYIT9hu", "details": "G Xu, M Yuksekgonul, C Guestrin, J Zou - Adaptive Foundation Models: Evolving AI for \u2026", "abstract": "Large language models (LLMs) are increasingly used in learning algorithms, evaluations, and optimization tasks. Recent studies have shown that incorporating self-criticism into LLMs can significantly enhance model performance, with \u2026"}, {"title": "LLaVA-o1: Let Vision Language Models Reason Step-by-Step", "link": "https://arxiv.org/pdf/2411.10440%3F", "details": "G Xu, P Jin, L Hao, Y Song, L Sun, L Yuan - arXiv preprint arXiv:2411.10440, 2024", "abstract": "Large language models have demonstrated substantial advancements in reasoning capabilities, particularly through inference-time scaling, as illustrated by models such as OpenAI's o1. However, current Vision-Language Models (VLMs) often struggle to \u2026"}, {"title": "LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models", "link": "https://arxiv.org/pdf/2411.09595", "details": "Z Wang, J Lorraine, Y Wang, H Su, J Zhu, S Fidler\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived \u2026"}, {"title": "Hidden in Plain Sight: Evaluating Abstract Shape Recognition in Vision-Language Models", "link": "https://arxiv.org/pdf/2411.06287", "details": "A Hemmat, A Davies, TA Lamb, J Yuan, P Torr\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the importance of shape perception in human vision, early neural image classifiers relied less on shape information for object recognition than other (often spurious) features. While recent research suggests that current large Vision \u2026"}, {"title": "VERITAS: A Unified Approach to Reliability Evaluation", "link": "https://arxiv.org/pdf/2411.03300%3F", "details": "R Ramamurthy, MA Rajeev, O Molenschot, J Zou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) often fail to synthesize information from their context to generate an accurate response. This renders them unreliable in knowledge intensive settings where reliability of the output is key. A critical component for \u2026"}, {"title": "Mixtures of In-Context Learners", "link": "https://arxiv.org/pdf/2411.02830", "details": "G Hong, E van Krieken, E Ponti, N Malkin, P Minervini - arXiv preprint arXiv \u2026, 2024", "abstract": "In-context learning (ICL) adapts LLMs by providing demonstrations without fine- tuning the model parameters; however, it does not differentiate between demonstrations and quadratically increases the complexity of Transformer LLMs \u2026"}, {"title": "Measuring Non-Adversarial Reproduction of Training Data in Large Language Models", "link": "https://arxiv.org/pdf/2411.10242%3F", "details": "M Aerni, J Rando, E Debenedetti, N Carlini, D Ippolito\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models memorize parts of their training data. Memorizing short snippets and facts is required to answer questions about the world and to be fluent in any language. But models have also been shown to reproduce long verbatim \u2026"}, {"title": "MEMO-Bench: A Multiple Benchmark for Text-to-Image and Multimodal Large Language Models on Human Emotion Analysis", "link": "https://arxiv.org/pdf/2411.11235", "details": "Y Zhou, Z Zhang, J Cao, J Jia, Y Jiang, F Wen, X Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Artificial Intelligence (AI) has demonstrated significant capabilities in various fields, and in areas such as human-computer interaction (HCI), embodied intelligence, and the design and animation of virtual digital humans, both practitioners and users are \u2026"}]
