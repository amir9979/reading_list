[{"title": "A theoretical design of concept sets: improving the predictability of concept bottleneck models", "link": "https://openreview.net/pdf%3Fid%3DoTv6Qa12G0", "details": "MR Luyten, M van der Schaar - The Thirty-eighth Annual Conference on Neural \u2026, 2024", "abstract": "Concept-based learning, a promising approach in machine learning, emphasizes the value of high-level representations called concepts. However, despite growing interest in concept-bottleneck models (CBMs), there is a lack of clear understanding \u2026"}, {"title": "Exploring the Impact of Backbone Architecture on Explainable CNNs' Interpretability", "link": "https://www.researchgate.net/profile/Zalan-Bodo/publication/384925487_Exploring_the_Impact_of_Backbone_Architecture_on_Explainable_CNNs%27_Interpretability/links/670e3ccf77bab74415a19534/Exploring-the-Impact-of-Backbone-Architecture-on-Explainable-CNNs-Interpretability.pdf", "details": "\u00c1 PORTIK, A BAJCSI, A SZENKOVITS, Z BOD\u00d3 - Acta Univ. Sapientiae, 2024", "abstract": "The growing demand for interpretable models in machine learning underscores the importance of transparency in decision-making processes for building trust and ensuring accountability in AI systems. Unlike complex black-box models \u2026"}, {"title": "LG-CAV: Train Any Concept Activation Vector with Language Guidance", "link": "https://arxiv.org/pdf/2410.10308", "details": "Q Huang, J Song, M Xue, H Zhang, B Hu, H Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Concept activation vector (CAV) has attracted broad research interest in explainable AI, by elegantly attributing model predictions to specific concepts. However, the training of CAV often necessitates a large number of high-quality images, which are \u2026"}, {"title": "Counterfactual Generative Modeling with Variational Causal Inference", "link": "https://arxiv.org/pdf/2410.12730", "details": "Y Wu, L McConnell, C Iriondo - arXiv preprint arXiv:2410.12730, 2024", "abstract": "Estimating an individual's potential outcomes under counterfactual treatments is a challenging task for traditional causal inference and supervised learning approaches when the outcome is high-dimensional (eg gene expressions, facial images) and \u2026"}, {"title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?", "link": "https://arxiv.org/pdf/2410.13523", "details": "C Liu, Z Wan, H Wang, Y Chen, T Qaiser, C Jin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Medical Vision-Language Pre-training (MedVLP) has made significant progress in enabling zero-shot tasks for medical image understanding. However, training MedVLP models typically requires large-scale datasets with paired, high-quality \u2026"}, {"title": "Interactive Deep Clustering via Value Mining", "link": "http://pengxi.me/wp-content/uploads/2024/11/Interactive_Deep_Clustering_via_Value_Mining.pdf", "details": "H Liu, P Hu, C Zhang, Y Li, X Peng", "abstract": "In the absence of class priors, recent deep clustering methods resort to data augmentation and pseudo-labeling strategies to generate supervision signals. Though achieved remarkable success, existing works struggle to discriminate hard \u2026"}, {"title": "Self-supervised contrastive learning performs non-linear system identification", "link": "https://arxiv.org/pdf/2410.14673%3F", "details": "RG Laiz, T Schmidt, S Schneider - arXiv preprint arXiv:2410.14673, 2024", "abstract": "Self-supervised learning (SSL) approaches have brought tremendous success across many tasks and domains. It has been argued that these successes can be attributed to a link between SSL and identifiable representation learning: Temporal \u2026"}, {"title": "A Two-Step Concept-Based Approach for Enhanced Interpretability and Trust in Skin Lesion Diagnosis", "link": "https://arxiv.org/pdf/2411.05609", "details": "C Patr\u00edcio, LF Teixeira, JC Neves - arXiv preprint arXiv:2411.05609, 2024", "abstract": "The main challenges hindering the adoption of deep learning-based systems in clinical settings are the scarcity of annotated data and the lack of interpretability and trust in these systems. Concept Bottleneck Models (CBMs) offer inherent \u2026"}, {"title": "GraphMETRO: Mitigating Complex Graph Distribution Shifts via Mixture of Aligned Experts", "link": "https://openreview.net/pdf%3Fid%3DQtYg4g3Deu", "details": "S Wu, K Cao, B Ribeiro, J Zou, J Leskovec - The Thirty-eighth Annual Conference on \u2026, 2024", "abstract": "Graph data are inherently complex and heterogeneous, leading to a high natural diversity of distributional shifts. However, it remains unclear how to build machine learning architectures that generalize to the complex distributional shifts naturally \u2026"}]
