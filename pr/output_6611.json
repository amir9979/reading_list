[{"title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models", "link": "https://arxiv.org/pdf/2408.15313", "details": "W Zhang, PHS Torr, M Elhoseiny, A Bibi - arXiv preprint arXiv:2408.15313, 2024", "abstract": "Fine-tuning large language models (LLMs) on human preferences, typically through reinforcement learning from human feedback (RLHF), has proven successful in enhancing their capabilities. However, ensuring the safety of LLMs during the fine \u2026"}, {"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task Specific Expert Pruning", "link": "https://arxiv.org/pdf/2409.01483", "details": "S Sarkar, L Lausen, V Cevher, S Zha, T Brox, G Karypis - arXiv preprint arXiv \u2026, 2024", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative to dense models in language modeling. These models use conditionally activated feedforward subnetworks in transformer blocks, allowing for a separation between \u2026"}, {"title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection", "link": "https://arxiv.org/pdf/2409.06072", "details": "J Chakraborty, W Xia, A Majumder, D Ma, W Chaabene\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks. However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further \u2026"}, {"title": "Pushing the Limits of Vision-Language Models in Remote Sensing without Human Annotations", "link": "https://arxiv.org/pdf/2409.07048", "details": "K Cha, D Yu, J Seo - arXiv preprint arXiv:2409.07048, 2024", "abstract": "The prominence of generalized foundation models in vision-language integration has witnessed a surge, given their multifarious applications. Within the natural domain, the procurement of vision-language datasets to construct these foundation \u2026"}, {"title": "QPO: Query-dependent Prompt Optimization via Multi-Loop Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2408.10504", "details": "Y Kong, H Mao, Q Zhao, B Zhang, J Ruan, L Shen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Prompt engineering has demonstrated remarkable success in enhancing the performance of large language models (LLMs) across diverse tasks. However, most existing prompt optimization methods only focus on the task-level performance \u2026"}, {"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries", "link": "https://arxiv.org/pdf/2409.00844", "details": "B Yang, F Cui, K Paster, J Ba, P Vaezipoor, S Pitis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid development and dynamic nature of large language models (LLMs) make it difficult for conventional quantitative benchmarks to accurately assess their capabilities. We propose report cards, which are human-interpretable, natural \u2026"}, {"title": "On the Relationship between Truth and Political Bias in Language Models", "link": "https://arxiv.org/pdf/2409.05283", "details": "S Fulay, W Brannon, S Mohanty, C Overney\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model alignment research often attempts to ensure that models are not only helpful and harmless, but also truthful and unbiased. However, optimizing these objectives simultaneously can obscure how improving one aspect might impact the \u2026"}]
