[{"title": "No Need to Talk: Asynchronous Mixture of Language Models", "link": "https://arxiv.org/pdf/2410.03529%3F", "details": "A Filippova, A Katharopoulos, D Grangier, R Collobert - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce SmallTalk LM, an innovative method for training a mixture of language models in an almost asynchronous manner. Each model of the mixture specializes in distinct parts of the data distribution, without the need of high-bandwidth \u2026"}, {"title": "Scaling Parameter-Constrained Language Models with Quality Data", "link": "https://arxiv.org/pdf/2410.03083", "details": "E Chang, M Paltenghi, Y Li, PJ Lin, C Zhao, P Huber\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Scaling laws in language modeling traditionally quantify training loss as a function of dataset size and model parameters, providing compute-optimal estimates but often neglecting the impact of data quality on model generalization. In this paper, we \u2026"}, {"title": "Small Language Models: Survey, Measurements, and Insights", "link": "https://arxiv.org/pdf/2409.15790%3F", "details": "Z Lu, X Li, D Cai, R Yi, F Liu, X Zhang, ND Lane, M Xu - arXiv preprint arXiv \u2026, 2024", "abstract": "Small language models (SLMs), despite their widespread adoption in modern smart devices, have received significantly less academic attention compared to their large language model (LLM) counterparts, which are predominantly deployed in data \u2026"}, {"title": "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning", "link": "https://arxiv.org/pdf/2410.03122", "details": "Z Zhao, Y Yang, Y Li, Y Cao - arXiv preprint arXiv:2410.03122, 2024", "abstract": "The ripple effect poses a significant challenge in knowledge editing for large language models. Namely, when a single fact is edited, the model struggles to accurately update the related facts in a sequence, which is evaluated by multi-hop \u2026"}, {"title": "MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.10139", "details": "P Xia, S Han, S Qiu, Y Zhou, Z Wang, W Zheng, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Interleaved multimodal comprehension and generation, enabling models to produce and interpret both images and text in arbitrary sequences, have become a pivotal area in multimodal learning. Despite significant advancements, the evaluation of this \u2026"}, {"title": "Ascle\u2014A Python Natural Language Processing Toolkit for Medical Text Generation: Development and Evaluation Study", "link": "https://www.jmir.org/2024/1/e60601/", "details": "R Yang, Q Zeng, K You, Y Qiao, L Huang, CC Hsieh\u2026 - Journal of Medical Internet \u2026, 2024", "abstract": "Background Medical texts present significant domain-specific challenges, and manually curating these texts is a time-consuming and labor-intensive process. To address this, natural language processing (NLP) algorithms have been developed to \u2026"}, {"title": "CriSPO: Multi-Aspect Critique-Suggestion-guided Automatic Prompt Optimization for Text Generation", "link": "https://arxiv.org/pdf/2410.02748%3F", "details": "H He, Q Liu, L Xu, C Shivade, Y Zhang, S Srinivasan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) can generate fluent summaries across domains using prompting techniques, reducing the need to train models for summarization applications. However, crafting effective prompts that guide LLMs to generate \u2026"}, {"title": "PALM: Few-Shot Prompt Learning for Audio Language Models", "link": "https://arxiv.org/pdf/2409.19806", "details": "A Hanif, MT Agro, MA Qazi, H Aldarmaki - arXiv preprint arXiv:2409.19806, 2024", "abstract": "Audio-Language Models (ALMs) have recently achieved remarkable success in zero- shot audio recognition tasks, which match features of audio waveforms with class- specific text prompt features, inspired by advancements in Vision-Language Models \u2026"}, {"title": "Prompt Learning for Few-Shot Question Answering via Self-Context Data Augmentation", "link": "https://ieeexplore.ieee.org/abstract/document/10723112/", "details": "JQ Qiu, CY Zhang, CLP Chen - IEEE Transactions on Artificial Intelligence, 2024", "abstract": "Pre-trained language models (PLMs) have shown remarkable performance on question answering (QA) tasks, but they usually require fine-tuning that depends on a substantial quantity of QA pairs. Therefore, improving the performance of PLMs in \u2026"}]
