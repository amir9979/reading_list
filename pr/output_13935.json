[{"title": "Open-Weight Language Models and Retrieval Augmented Generation for Automated Structured Data Extraction from Diagnostic Reports: Assessment of Approaches \u2026", "link": "https://pubs.rsna.org/doi/abs/10.1148/ryai.240551", "details": "MS Jabal, P Warman, J Zhang, K Gupta, A Jain\u2026 - Radiology: Artificial \u2026, 2025", "abstract": "\u201cJust Accepted\u201d papers have undergone full peer review and have been accepted for publication in Radiology: Artificial Intelligence. This article will undergo copyediting, layout, and proof review before it is published in its final version. Please note that \u2026"}, {"title": "Can Memory-Augmented Language Models Generalize on Reasoning-in-a-Haystack Tasks?", "link": "https://arxiv.org/pdf/2503.07903", "details": "P Das, CY Ko, S Dai, G Kollias, S Chaudhury\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models often expose their brittleness in reasoning tasks, especially while executing long chains of reasoning over context. We propose MemReasoner, a new and simple memory-augmented LLM architecture, in which the memory learns \u2026"}, {"title": "Attention-Based Synthetic Data Generation for Calibration-Enhanced Survival Analysis: A Case Study for Chronic Kidney Disease Using Electronic Health Records", "link": "https://arxiv.org/pdf/2503.06096", "details": "NI Kuo, B Gallego, L Jorm - arXiv preprint arXiv:2503.06096, 2025", "abstract": "Access to real-world healthcare data is limited by stringent privacy regulations and data imbalances, hindering advancements in research and clinical applications. Synthetic data presents a promising solution, yet existing methods often fail to ensure \u2026"}, {"title": "Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models", "link": "https://arxiv.org/pdf/2502.12825", "details": "R Lu, J Sedoc, A Sundararajan - arXiv preprint arXiv:2502.12825, 2025", "abstract": "When encountering increasingly frequent performance improvements or cost reductions from a new large language model (LLM), developers of applications leveraging LLMs must decide whether to take advantage of these improvements or \u2026"}]
