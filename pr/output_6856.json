[{"title": "Probing Fundamental Visual Comprehend Capabilities on Vision Language Models via Visual Phrases from Structural Data", "link": "https://link.springer.com/article/10.1007/s12559-024-10351-8", "details": "P Xie, B Liu - Cognitive Computation, 2024", "abstract": "Does the model demonstrate exceptional proficiency in \u201citem counting,\u201d\u201ccolor recognition,\u201d or other Fundamental Visual Comprehension Capability (FVCC)? There have been remarkable advancements in the field of multimodal, the pretrained \u2026"}, {"title": "Few-shot Adaptation of Medical Vision-Language Models", "link": "https://arxiv.org/pdf/2409.03868", "details": "F Shakeri, Y Huang, J Silva-Rodr\u00edguez, H Bahig\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Integrating image and text data through multi-modal learning has emerged as a new approach in medical imaging research, following its successful deployment in computer vision. While considerable efforts have been dedicated to establishing \u2026"}, {"title": "PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions", "link": "https://arxiv.org/pdf/2409.05076", "details": "Y Zhang, R Xie, J Chen, X Sun, Y Wang - arXiv preprint arXiv:2409.05076, 2024", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated their powerful multimodal capabilities. However, they also face serious safety problems, as adversaries can induce robustness issues in LVLMs through the use of well \u2026"}, {"title": "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables", "link": "https://arxiv.org/pdf/2408.13860", "details": "SV Mathur, JS Bafna, K Kartik, H Khandelwal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing datasets for tabular question answering typically focus exclusively on text within cells. However, real-world data is inherently multimodal, often blending images such as symbols, faces, icons, patterns, and charts with textual content in \u2026"}, {"title": "GraphWiz: An Instruction-Following Language Model for Graph Computational Problems", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3672010", "details": "N Chen, Y Li, J Tang, J Li - Proceedings of the 30th ACM SIGKDD Conference on \u2026, 2024", "abstract": "Large language models (LLMs) have achieved impressive success across various domains, but their capability in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel \u2026"}, {"title": "Selective Self-Rehearsal: A Fine-Tuning Approach to Improve Generalization in Large Language Models", "link": "https://arxiv.org/pdf/2409.04787", "details": "S Gupta, Y Nandwani, A Yehudai, M Mishra, G Pandey\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Fine-tuning Large Language Models (LLMs) on specific datasets is a common practice to improve performance on target tasks. However, this performance gain often leads to overfitting, where the model becomes too specialized in either the task \u2026"}, {"title": "RecExplainer: Aligning Large Language Models for Explaining Recommendation Models", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671802", "details": "Y Lei, J Lian, J Yao, X Huang, D Lian, X Xie - Proceedings of the 30th ACM SIGKDD \u2026, 2024", "abstract": "Recommender systems are widely used in online services, with embedding-based models being particularly popular due to their expressiveness in representing complex signals. However, these models often function as a black box, making them \u2026"}, {"title": "Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.14470", "details": "A Agarwal, SK Ramesh, A Sengupta, T Chakraborty - arXiv preprint arXiv:2408.14470, 2024", "abstract": "Fine-tuning large language models (LLMs) on downstream tasks requires substantial computational resources. A class of parameter-efficient fine-tuning (PEFT) aims to mitigate these computational challenges by selectively fine-tuning only a small \u2026"}, {"title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models", "link": "https://arxiv.org/pdf/2408.15778", "details": "J Gui, Y Liu, J Cheng, X Gu, X Liu, H Wang, Y Dong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across various tasks, showcasing complex problem-solving abilities. Understanding and executing complex rules, along with multi-step planning, are fundamental to logical \u2026"}]
