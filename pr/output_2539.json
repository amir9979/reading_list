[{"title": "A robust multi-scale feature extraction framework with dual memory module for multivariate time series anomaly detection", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024003198", "details": "B Xue, X Gao, B Li, F Zhai, J Lu, J Yu, S Fu, C Xiao - Neural Networks, 2024", "abstract": "Although existing reconstruction-based multivariate time series anomaly detection (MTSAD) methods have shown advanced performance, most assume the training data is clean. When faced with noise or contamination in training data, they can also \u2026"}, {"title": "Credal Wrapper of Model Averaging for Uncertainty Estimation on Out-Of-Distribution Detection", "link": "https://arxiv.org/pdf/2405.15047", "details": "K Wang, F Cuzzolin, K Shariatmadar, D Moens\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper presents an innovative approach, called credal wrapper, to formulating a credal set representation of model averaging for Bayesian neural networks (BNNs) and deep ensembles, capable of improving uncertainty estimation in classification \u2026"}, {"title": "Learning from Random Demonstrations: Offline Reinforcement Learning with Importance-Sampled Diffusion Models", "link": "https://arxiv.org/pdf/2405.19878", "details": "Z Fang, T Lan - arXiv preprint arXiv:2405.19878, 2024", "abstract": "Generative models such as diffusion have been employed as world models in offline reinforcement learning to generate synthetic data for more effective learning. Existing work either generates diffusion models one-time prior to training or requires \u2026"}, {"title": "Improved Distribution Matching Distillation for Fast Image Synthesis", "link": "https://arxiv.org/pdf/2405.14867", "details": "T Yin, M Gharbi, T Park, R Zhang, E Shechtman\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent approaches have shown promises distilling diffusion models into efficient one-step generators. Among them, Distribution Matching Distillation (DMD) produces one-step generators that match their teacher in distribution, without enforcing a one \u2026"}, {"title": "Score-based generative models are provably robust: an uncertainty quantification perspective", "link": "https://arxiv.org/pdf/2405.15754", "details": "N Mimikos-Stamatopoulos, BJ Zhang, MA Katsoulakis - arXiv preprint arXiv \u2026, 2024", "abstract": "Through an uncertainty quantification (UQ) perspective, we show that score-based generative models (SGMs) are provably robust to the multiple sources of error in practical implementation. Our primary tool is the Wasserstein uncertainty propagation \u2026"}, {"title": "Diff-MGR: Dynamic Causal Graph Attention and Pattern Reproduction Guided Diffusion Model for Multivariate Time Series Probabilistic Forecasting", "link": "https://www.sciencedirect.com/science/article/pii/S002002552400656X", "details": "T Zhao, G Song, X Li, L Cui, C Zhang - Information Sciences, 2024", "abstract": "Time series probability forecasting provides insight into future trends and their inherent uncertainties from past data. In order to obtain more accurate forecasting as the reliable basis for future decision-making and planning, a new probabilistic \u2026"}, {"title": "MGCP: A Multi-Grained Correlation based Prediction Network for Multivariate Time Series", "link": "https://arxiv.org/pdf/2405.19661", "details": "Z Chen, X Xiao, K Xu, Z Zhang, Y Rong, Q Li, G Gan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multivariate time series prediction is widely used in daily life, which poses significant challenges due to the complex correlations that exist at multi-grained levels. Unfortunately, the majority of current time series prediction models fail to \u2026"}]
