[{"title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2412.09827", "details": "C Li, C Ding, K Luan, X Di - arXiv preprint arXiv:2412.09827, 2024", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. LoRA is one of the most widely used methods, which assumes that the optimization process is essentially low \u2026"}, {"title": "TAB: Transformer Attention Bottlenecks enable User Intervention and Debugging in Vision-Language Models", "link": "https://arxiv.org/pdf/2412.18675", "details": "P Rahmanzadehgrevi, HH Nguyen, R Liu, L Mai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multi-head self-attention (MHSA) is a key component of Transformers, a widely popular architecture in both language and vision. Multiple heads intuitively enable different parallel processes over the same input. Yet, they also obscure the attribution \u2026"}, {"title": "HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models", "link": "https://arxiv.org/pdf/2412.08378", "details": "S Zhu, W Dong, J Song, Y Guo, B Zheng - arXiv preprint arXiv:2412.08378, 2024", "abstract": "Recently, there has been growing interest in the capability of multimodal large language models (MLLMs) to process high-resolution images. A common approach currently involves dynamically cropping the original high-resolution image into \u2026"}, {"title": "ChartAdapter: Large Vision-Language Model for Chart Summarization", "link": "https://arxiv.org/pdf/2412.20715", "details": "P Xu, Y Ding, W Fan - arXiv preprint arXiv:2412.20715, 2024", "abstract": "Chart summarization, which focuses on extracting key information from charts and interpreting it in natural language, is crucial for generating and delivering insights through effective and accessible data analysis. Traditional methods for chart \u2026"}, {"title": "Vinci: A Real-time Embodied Smart Assistant based on Egocentric Vision-Language Model", "link": "https://arxiv.org/pdf/2412.21080%3F", "details": "Y Huang, J Xu, B Pei, Y He, G Chen, L Yang, X Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce Vinci, a real-time embodied smart assistant built upon an egocentric vision-language model. Designed for deployment on portable devices such as smartphones and wearable cameras, Vinci operates in an\" always on\" mode \u2026"}, {"title": "Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model", "link": "https://arxiv.org/pdf/2412.04729", "details": "KP Yu, A Dave, R Ambrus, J Mercat - arXiv preprint arXiv:2412.04729, 2024", "abstract": "Most of the current vision-language models (VLMs) for videos struggle to understand videos longer than a few seconds. This is primarily due to the fact that they do not scale to utilizing a large number of frames. In order to address this limitation, we \u2026"}, {"title": "SAT: Spatial Aptitude Training for Multimodal Language Models", "link": "https://arxiv.org/pdf/2412.07755", "details": "A Ray, J Duan, R Tan, D Bashkirova, R Hendrix\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Spatial perception is a fundamental component of intelligence. While many studies highlight that large multimodal language models (MLMs) struggle to reason about space, they only test for static spatial reasoning, such as categorizing the relative \u2026"}, {"title": "An evaluation framework for clinical use of large language models in patient interaction tasks", "link": "https://www.nature.com/articles/s41591-024-03328-5", "details": "S Johri, J Jeong, BA Tran, DI Schlessinger\u2026 - Nature Medicine, 2025", "abstract": "The integration of large language models (LLMs) into clinical diagnostics has the potential to transform doctor\u2013patient interactions. However, the readiness of these models for real-world clinical application remains inadequately tested. This paper \u2026"}, {"title": "Biased or Flawed? Mitigating Stereotypes in Generative Language Models by Addressing Task-Specific Flaws", "link": "https://arxiv.org/pdf/2412.11414%3F", "details": "A Jha, S Kabra, CK Reddy - arXiv preprint arXiv:2412.11414, 2024", "abstract": "Recent studies have shown that generative language models often reflect and amplify societal biases in their outputs. However, these studies frequently conflate observed biases with other task-specific shortcomings, such as comprehension \u2026"}]
