[{"title": "Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models", "link": "https://arxiv.org/pdf/2405.16413", "details": "J Wang, S Ahn, T Dalal, X Zhang, W Pan, Q Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Alzheimer's disease (AD) is the fifth-leading cause of death among Americans aged 65 and older. Screening and early detection of AD and related dementias (ADRD) are critical for timely intervention and for identifying clinical trial participants. The \u2026"}, {"title": "Comparative Analysis of Open-Source Language Models in Summarizing Medical Text Data", "link": "https://arxiv.org/pdf/2405.16295", "details": "Y Chen, Z Wang, B Wen, F Zulkernine - arXiv preprint arXiv:2405.16295, 2024", "abstract": "Unstructured text in medical notes and dialogues contains rich information. Recent advancements in Large Language Models (LLMs) have demonstrated superior performance in question answering and summarization tasks on unstructured text \u2026"}, {"title": "Few-shot Tuning of Foundation Models for Class-incremental Learning", "link": "https://arxiv.org/pdf/2405.16625", "details": "S Roy, E Dolatabadi, A Afkanpour, A Etemad - arXiv preprint arXiv:2405.16625, 2024", "abstract": "For the first time, we explore few-shot tuning of vision foundation models for class- incremental learning. Unlike existing few-shot class incremental learning (FSCIL) methods, which train an encoder on a base session to ensure forward compatibility \u2026"}]
