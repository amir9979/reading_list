[{"title": "CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images and Patients", "link": "https://arxiv.org/pdf/2405.19538", "details": "P Chambon, JB Delbrouck, T Sounack, SC Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Since the release of the original CheXpert paper five years ago, CheXpert has become one of the most widely used and cited clinical AI datasets. The emergence of vision language models has sparked an increase in demands for sharing reports \u2026"}, {"title": "ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text", "link": "https://arxiv.org/pdf/2405.19366", "details": "H Yu, P Guo, A Sano - arXiv preprint arXiv:2405.19366, 2024", "abstract": "The utilization of deep learning on electrocardiogram (ECG) analysis has brought the advanced accuracy and efficiency of cardiac healthcare diagnostics. By leveraging the capabilities of deep learning in semantic understanding, especially in feature \u2026"}, {"title": "Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training", "link": "https://arxiv.org/pdf/2405.19654", "details": "J Yang, B Su, WX Zhao, JR Wen - arXiv preprint arXiv:2405.19654, 2024", "abstract": "Medical vision-language pre-training methods mainly leverage the correspondence between paired medical images and radiological reports. Although multi-view spatial images and temporal sequences of image-report pairs are available in off-the-shelf \u2026"}, {"title": "X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions", "link": "https://arxiv.org/pdf/2405.19744", "details": "C Li, W Yang, J Zhang, J Lu, S Wang, C Zong - arXiv preprint arXiv:2405.19744, 2024", "abstract": "Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples \u2026"}]
