[{"title": "Detecting LLM Fact-conflicting Hallucinations Enhanced by Temporal-logic-based Reasoning", "link": "https://arxiv.org/pdf/2502.13416", "details": "N Li, Y Song, K Wang, Y Li, L Shi, Y Liu, H Wang - arXiv preprint arXiv:2502.13416, 2025", "abstract": "Large language models (LLMs) face the challenge of hallucinations--outputs that seem coherent but are actually incorrect. A particularly damaging type is fact- conflicting hallucination (FCH), where generated content contradicts established \u2026"}, {"title": "Stackelberg Game Preference Optimization for Data-Efficient Alignment of Language Models", "link": "https://arxiv.org/pdf/2502.18099", "details": "X Chu, Z Zhang, T Jia, Y Jin - arXiv preprint arXiv:2502.18099, 2025", "abstract": "Aligning language models with human preferences is critical for real-world deployment, but existing methods often require large amounts of high-quality human annotations. Aiming at a data-efficient alignment method, we propose Stackelberg \u2026"}, {"title": "EXAONE Deep: Reasoning Enhanced Language Models", "link": "https://arxiv.org/pdf/2503.12524", "details": "LG Research, K Bae, E Choi, K Choi, SJ Choi, Y Choi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present EXAONE Deep series, which exhibits superior capabilities in various reasoning tasks, including math and coding benchmarks. We train our models mainly on the reasoning-specialized dataset that incorporates long streams of thought \u2026"}, {"title": "Transfer-Prompting: Enhancing Cross-Task Adaptation in Large Language Models via Dual-Stage Prompts Optimization", "link": "https://arxiv.org/pdf/2502.14211", "details": "Y Chang, Y Chang, Y Wu - arXiv preprint arXiv:2502.14211, 2025", "abstract": "Large language models (LLMs) face significant challenges when balancing multiple high-level objectives, such as generating coherent, relevant, and high-quality responses while maintaining efficient task adaptation across diverse tasks. To \u2026"}, {"title": "Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs", "link": "https://arxiv.org/pdf/2502.14645", "details": "Y Wu, L Ding, L Shen, D Tao - arXiv preprint arXiv:2502.14645, 2025", "abstract": "Knowledge editing allows for efficient adaptation of large language models (LLMs) to new information or corrections without requiring full retraining. However, prior methods typically focus on either single-language editing or basic multilingual \u2026"}, {"title": "Maporl: Multi-agent post-co-training for collaborative large language models with reinforcement learning", "link": "https://arxiv.org/pdf/2502.18439", "details": "C Park, S Han, X Guo, A Ozdaglar, K Zhang, JK Kim - arXiv preprint arXiv:2502.18439, 2025", "abstract": "Leveraging multiple large language models (LLMs) to build collaborative multi- agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability \u2026"}, {"title": "Faithful Self-Refinement in Mathematical Reasoning via Progressive Back-Translation", "link": "https://ieeexplore.ieee.org/abstract/document/10890054/", "details": "H Liao, Z Zhu, S Hu, H He, Y Jin - ICASSP 2025-2025 IEEE International Conference \u2026, 2025", "abstract": "Large language models (LLMs) can achieve superior results through iterative refinement based on internal or external signals, compared to the unstable outputs from a single pass. However, the reliability of existing internal signals is questionable \u2026"}, {"title": "Fact or Guesswork? Evaluating Large Language Model's Medical Knowledge with Structured One-Hop Judgment", "link": "https://arxiv.org/pdf/2502.14275", "details": "J Li, Y Wang, K Zhang, Y Cai, B Hooi, N Peng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have been widely adopted in various downstream task domains. However, their ability to directly recall and apply factual medical knowledge remains under-explored. Most existing medical QA benchmarks assess \u2026"}, {"title": "Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks", "link": "https://openreview.net/pdf%3Fid%3D3YyyiyV4B6", "details": "F Lin, S Mao, E La Malfa, V Hofmann, A de Wynter\u2026 - Workshop on Reasoning and \u2026", "abstract": "Language is not monolithic. While benchmarks, including those designed for multiple languages, are often used as proxies to evaluate the performance of Large Language Models (LLMs), they tend to overlook the nuances of within-language \u2026"}]
