[{"title": "HREF: Human Response-Guided Evaluation of Instruction Following in Language Models", "link": "https://arxiv.org/pdf/2412.15524", "details": "X Lyu, Y Wang, H Hajishirzi, P Dasigi - arXiv preprint arXiv:2412.15524, 2024", "abstract": "Evaluating the capability of Large Language Models (LLMs) in following instructions has heavily relied on a powerful LLM as the judge, introducing unresolved biases that deviate the judgments from human judges. In this work, we reevaluate various \u2026"}, {"title": "Biased or Flawed? Mitigating Stereotypes in Generative Language Models by Addressing Task-Specific Flaws", "link": "https://arxiv.org/pdf/2412.11414", "details": "A Jha, S Kabra, CK Reddy - arXiv preprint arXiv:2412.11414, 2024", "abstract": "Recent studies have shown that generative language models often reflect and amplify societal biases in their outputs. However, these studies frequently conflate observed biases with other task-specific shortcomings, such as comprehension \u2026"}, {"title": "Large language models for extracting histopathologic diagnoses from electronic health records", "link": "https://www.medrxiv.org/content/10.1101/2024.11.27.24318083.full.pdf", "details": "B Johnson, T Bath, X Huang, M Lamm, A Earles\u2026 - medRxiv, 2024", "abstract": "Background & Aims Accurate data resources are essential for impactful medical research. To date, most large-scale studies have relied on structured sources, such as International Classification of Diseases codes, to determine patient diagnoses \u2026"}, {"title": "Frequency Is What You Need: Word-frequency Masking Benefits Vision-Language Model Pre-training", "link": "https://arxiv.org/pdf/2412.16148", "details": "M Liang, M Larson - arXiv preprint arXiv:2412.16148, 2024", "abstract": "Vision Language Models (VLMs) can be trained more efficiently if training sets can be reduced in size. Recent work has shown the benefits of masking text during VLM training using a variety of approaches: truncation, random masking, block masking \u2026"}, {"title": "X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models", "link": "https://arxiv.org/pdf/2412.01824%3F", "details": "Z Sun, Z Chu, P Zhang, T Wu, X Dong, Y Zang, Y Xiong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In-context generation is a key component of large language models'(LLMs) open- task generalization capability. By leveraging a few examples as context, LLMs can perform both in-domain and out-of-domain tasks. Recent advancements in auto \u2026"}, {"title": "Domain-Invariant Few-Shot Contrastive Learning for Hyperspectral Image Classification", "link": "https://www.mdpi.com/2076-3417/14/23/11053", "details": "W Chen, Y Zhang, J Chu, X Wang - Applied Sciences, 2024", "abstract": "In Hyperspectral Image (HSI) classification, acquiring large quantities of high-quality labeled samples is typically costly and impractical. Traditional deep learning methods are limited in such scenarios due to their dependence on sample quantities \u2026"}]
