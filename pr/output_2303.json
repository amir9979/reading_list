[{"title": "CSAMDT: Conditional Self Attention Memory-Driven Transformers for Radiology Report Generation from Chest X-Ray", "link": "https://link.springer.com/article/10.1007/s10278-024-01126-6", "details": "I Shahzadi, TM Madni, UI Janjua, G Batool, B Naz\u2026 - Journal of Imaging \u2026, 2024", "abstract": "A radiology report plays a crucial role in guiding patient treatment, but writing these reports is a time-consuming task that demands a radiologist's expertise. In response to this challenge, researchers in the subfields of artificial intelligence for healthcare \u2026"}, {"title": "Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization", "link": "https://arxiv.org/pdf/2406.01314", "details": "F Khader, OSM El Nahhas, T Han, G M\u00fcller-Franzes\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The Transformer model has been pivotal in advancing fields such as natural language processing, speech recognition, and computer vision. However, a critical limitation of this model is its quadratic computational and memory complexity relative \u2026"}, {"title": "Language Augmentation in CLIP for Improved Anatomy Detection on Multi-modal Medical Images", "link": "https://arxiv.org/pdf/2405.20735", "details": "M Kakkar, D Shanbhag, C Aladahalli - arXiv preprint arXiv:2405.20735, 2024", "abstract": "Vision-language models have emerged as a powerful tool for previously challenging multi-modal classification problem in the medical domain. This development has led to the exploration of automated image description generation for multi-modal clinical \u2026"}, {"title": "Textual Inversion and Self-supervised Refinement for Radiology Report Generation", "link": "https://arxiv.org/pdf/2405.20607", "details": "Y Luo, H Li, X Wu, M Cao, X Huang, Z Zhu, P Liao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing mainstream approaches follow the encoder-decoder paradigm for generating radiology reports. They focus on improving the network structure of encoders and decoders, which leads to two shortcomings: overlooking the modality \u2026"}, {"title": "Correlation-aware Coarse-to-fine MLPs for Deformable Medical Image Registration", "link": "https://arxiv.org/pdf/2406.00123", "details": "M Meng, D Feng, L Bi, J Kim - arXiv preprint arXiv:2406.00123, 2024", "abstract": "Deformable image registration is a fundamental step for medical image analysis. Recently, transformers have been used for registration and outperformed Convolutional Neural Networks (CNNs). Transformers can capture long-range \u2026"}]
