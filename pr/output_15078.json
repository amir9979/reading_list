[{"title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models", "link": "https://arxiv.org/pdf/2504.05258", "details": "A Bazaga, R Blloshmi, B Byrne, A de Gispert - arXiv preprint arXiv:2504.05258, 2025", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating coherent text, understanding context, and performing reasoning tasks. However, they struggle with temporal reasoning, which requires processing time-related information \u2026"}, {"title": "NoveltyBench: Evaluating Creativity and Diversity in Language Models", "link": "https://arxiv.org/pdf/2504.05228", "details": "Y Zhang, H Diddee, S Holm, H Liu, X Liu, V Samuel\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Language models have demonstrated remarkable capabilities on standard benchmarks, yet they struggle increasingly from mode collapse, the inability to generate diverse and novel outputs. Our work introduces NoveltyBench, a \u2026"}, {"title": "Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models", "link": "https://arxiv.org/pdf/2504.05050", "details": "J Lian, J Pan, L Wang, Y Wang, S Mei, LP Chau - arXiv preprint arXiv:2504.05050, 2025", "abstract": "Large language models (LLMs) are foundational explorations to artificial general intelligence, yet their alignment with human values via instruction tuning and preference learning achieves only superficial compliance. Here, we demonstrate that \u2026"}, {"title": "What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models", "link": "https://arxiv.org/pdf/2503.24235%3F", "details": "Q Zhang, F Lyu, Z Sun, L Wang, W Zhang, Z Guo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as``test-time computing''has emerged as a prominent research focus. Recent studies demonstrate \u2026"}, {"title": "Agentic Large Language Models, a survey", "link": "https://arxiv.org/pdf/2503.23037", "details": "A Plaat, M van Duijn, N van Stein, M Preuss\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "There is great interest in agentic LLMs, large language models that act as agents. We review the growing body of work in this area and provide a research agenda. Agentic LLMs are LLMs that (1) reason,(2) act, and (3) interact. We organize the \u2026"}, {"title": "Beyond Accuracy: The Role of Calibration in Self-Improving Large Language Models", "link": "https://arxiv.org/pdf/2504.02902", "details": "L Huang, D Li, H Liu, L Cheng - arXiv preprint arXiv:2504.02902, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable self-improvement capabilities, whereby models iteratively revise their outputs through self-generated feedback. While this reflective mechanism has shown promise in enhancing task \u2026"}, {"title": "Modality Plug-and-Play: Runtime Modality Adaptation in LLM-Driven Autonomous Mobile Systems", "link": "https://sites.pitt.edu/~weigao/publications/mobicom25_mpnp.pdf", "details": "K Huang, X Yin, H Huang, W Gao - ACM MobiCom, 2025", "abstract": "Multimodal reasoning by LLMs is critical to autonomous mobile systems, but the growing diversity of input data modalities prevents incorporating all modalities into LLMs. Instead, only the useful modalities should be adaptively involved at runtime \u2026"}, {"title": "Reasoning Under 1 Billion: Memory-Augmented Reinforcement Learning for Large Language Models", "link": "https://arxiv.org/pdf/2504.02273", "details": "H Le, D Do, D Nguyen, S Venkatesh - arXiv preprint arXiv:2504.02273, 2025", "abstract": "Recent advances in fine-tuning large language models (LLMs) with reinforcement learning (RL) have shown promising improvements in complex reasoning tasks, particularly when paired with chain-of-thought (CoT) prompting. However, these \u2026"}, {"title": "$\\textit {Agents Under Siege} $: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks", "link": "https://arxiv.org/pdf/2504.00218", "details": "RMS Khan, Z Tan, S Yun, C Flemming, T Chen - arXiv preprint arXiv:2504.00218, 2025", "abstract": "Most discussions about Large Language Model (LLM) safety have focused on single- agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and \u2026"}]
