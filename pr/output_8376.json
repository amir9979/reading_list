[{"title": "Improved Depth Estimation of Bayesian Neural Networks", "link": "https://arxiv.org/pdf/2410.10395", "details": "B van Erp, B de Vries - arXiv preprint arXiv:2410.10395, 2024", "abstract": "This paper proposes improvements over earlier work by Nazareth and Blei (2022) for estimating the depth of Bayesian neural networks. Here, we propose a discrete truncated normal distribution over the network depth to independently learn its mean \u2026"}, {"title": "Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning", "link": "https://arxiv.org/pdf/2410.14390", "details": "B Zhang, D Liu, O Simeone, G Wang, D Pezaros, G Zhu - arXiv preprint arXiv \u2026, 2024", "abstract": "To support real-world decision-making, it is crucial for models to be well-calibrated, ie, to assign reliable confidence estimates to their predictions. Uncertainty quantification is particularly important in personalized federated learning (PFL), as \u2026"}, {"title": "Time Series Classification with Large Language Models via Linguistic Scaffolding", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10706904.pdf", "details": "H Jang, JY Yang, J Hwang, E Yang - IEEE Access, 2024", "abstract": "Time series classification requires specialized models that can effectively capture temporal structures. Consequently, Large Language Models (LLMs) have emerged as promising candidates due to their proficiency in sequence modeling and semantic \u2026"}, {"title": "Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models", "link": "https://arxiv.org/pdf/2410.09385", "details": "SK Bhethanabhotla, O Swelam, J Siems, D Salinas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces Mamba4Cast, a zero-shot foundation model for time series forecasting. Based on the Mamba architecture and inspired by Prior-data Fitted Networks (PFNs), Mamba4Cast generalizes robustly across diverse time series tasks \u2026"}, {"title": "Self-Supervised Learning of Disentangled Representations for Multivariate Time-Series", "link": "https://arxiv.org/pdf/2410.12606", "details": "C Chang, CT Chan, WY Wang, WC Peng, TF Chen - arXiv preprint arXiv:2410.12606, 2024", "abstract": "Multivariate time-series data in fields like healthcare and industry are informative but challenging due to high dimensionality and lack of labels. Recent self-supervised learning methods excel in learning rich representations without labels but struggle \u2026"}, {"title": "DyGraphformer: Transformer combining dynamic spatio-temporal graph network for multivariate time series forecasting", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024007007", "details": "S Han, Y Xun, J Cai, H Yang, Y Li - Neural Networks, 2024", "abstract": "Transformer-based models demonstrate tremendous potential for Multivariate Time Series (MTS) forecasting due to their ability to capture long-term temporal dependencies by using the self-attention mechanism. However, effectively modeling \u2026"}, {"title": "DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting", "link": "https://arxiv.org/pdf/2410.22981", "details": "Z Liu, J Yang, Q Mao, Y Zhao, M Cheng, Z Li, Q Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multivariate time series forecasting plays a crucial role in various real-world applications. Significant efforts have been made to integrate advanced network architectures and training strategies that enhance the capture of temporal \u2026"}, {"title": "Dynamic deep graph convolution with enhanced transformer networks for time series anomaly detection in IoT", "link": "https://link.springer.com/article/10.1007/s10586-024-04707-w", "details": "R Gao, Z Chen, X Wu, Y Yu, L Zhang - Cluster Computing, 2025", "abstract": "Anomaly detection of multi-time series data during the working process of Internet of Things systems that utilize sensors is one of the key aspects to prevent accidents in industrial information systems. The key challenge is to discover generalized normal \u2026"}, {"title": "ELBOing Stein: Variational Bayes with Stein Mixture Inference", "link": "https://arxiv.org/pdf/2410.22948", "details": "O R\u00f8nning, E Nalisnick, C Ley, P Smyth, T Hamelryck - arXiv preprint arXiv \u2026, 2024", "abstract": "Stein variational gradient descent (SVGD)[Liu and Wang, 2016] performs approximate Bayesian inference by representing the posterior with a set of particles. However, SVGD suffers from variance collapse, ie poor predictions due to \u2026"}]
