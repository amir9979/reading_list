[{"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task Specific Expert Pruning", "link": "https://arxiv.org/pdf/2409.01483", "details": "S Sarkar, L Lausen, V Cevher, S Zha, T Brox, G Karypis - arXiv preprint arXiv \u2026, 2024", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative to dense models in language modeling. These models use conditionally activated feedforward subnetworks in transformer blocks, allowing for a separation between \u2026"}, {"title": "VTPL: Visual and Text Prompt Learning for visual-language models", "link": "https://www.sciencedirect.com/science/article/pii/S1047320324002360", "details": "B Sun, Z Wu, H Zhang, J He - Journal of Visual Communication and Image \u2026, 2024", "abstract": "Visual-language (VL) models have achieved remarkable success in learning combined visual\u2013textual representations from large web datasets. Prompt learning, as a solution for downstream tasks, can address the forgetting of knowledge \u2026"}, {"title": "Zero-Shot Visual Reasoning by Vision-Language Models: Benchmarking and Analysis", "link": "https://arxiv.org/pdf/2409.00106", "details": "A Nagar, S Jaiswal, C Tan - arXiv preprint arXiv:2409.00106, 2024", "abstract": "Vision-language models (VLMs) have shown impressive zero-and few-shot performance on real-world visual question answering (VQA) benchmarks, alluding to their capabilities as visual reasoning engines. However, the benchmarks being used \u2026"}, {"title": "CARL: Unsupervised Code-Based Adversarial Attacks for Programming Language Models via Reinforcement Learning", "link": "https://dl.acm.org/doi/abs/10.1145/3688839", "details": "K Yao, H Wang, C Qin, H Zhu, Y Wu, L Zhang - ACM Transactions on Software Engineering \u2026", "abstract": "Code based adversarial attacks play a crucial role in revealing vulnerabilities of software system. Recently, pre-trained programming language models (PLMs) have demonstrated remarkable success in various significant software engineering tasks \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "DP-MemArc: Differential Privacy Transfer Learning for Memory Efficient Language Models", "link": "https://www.researchgate.net/profile/Yanming-Liu-16/publication/383395255_DP-MemArc_Differential_Privacy_Transfer_Learning_for_Memory_Efficient_Language_Models/links/66ca3a35c2eaa5002314bfbf/DP-MemArc-Differential-Privacy-Transfer-Learning-for-Memory-Efficient-Language-Models.pdf", "details": "Y Liu, X Peng, Y Zhang, X Ke, S Deng, J Cao, C Ma\u2026", "abstract": "Large language models have repeatedly shown outstanding performance across diverse applications. However, deploying these models can inadvertently risk user privacy. The significant memory demands during training pose a major challenge in \u2026"}, {"title": "Enhancing Discriminative Tasks by Guiding the Pre-trained Language Model with Large Language Model's Experience", "link": "https://arxiv.org/pdf/2408.08553", "details": "X Yin, C Ni, X Xu, X Li, X Yang - arXiv preprint arXiv:2408.08553, 2024", "abstract": "Large Language Models (LLMs) and pre-trained Language Models (LMs) have achieved impressive success on many software engineering tasks (eg, code completion and code generation). By leveraging huge existing code corpora (eg \u2026"}, {"title": "Towards a Unified View of Preference Learning for Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2409.02795", "details": "B Gao, F Song, Y Miao, Z Cai, Z Yang, L Chen, H Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to \u2026"}, {"title": "BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models", "link": "https://arxiv.org/pdf/2408.12798", "details": "Y Li, H Huang, Y Zhao, X Ma, J Sun - arXiv preprint arXiv:2408.12798, 2024", "abstract": "Generative Large Language Models (LLMs) have made significant strides across various tasks, but they remain vulnerable to backdoor attacks, where specific triggers in the prompt cause the LLM to generate adversary-desired responses. While most \u2026"}]
