[{"title": "TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles", "link": "https://arxiv.org/pdf/2410.05262", "details": "Q Yu, S Song, K Fang, Y Shi, Z Zheng, H Wang, S Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the application of Large Language Models (LLMs) expands, the demand for reliable evaluations increases. Existing LLM evaluation benchmarks primarily rely on static datasets, making it challenging to assess model performance in dynamic \u2026"}, {"title": "Fine-tuning large language models to improve accuracy and comprehensibility of automated code review", "link": "https://dl.acm.org/doi/pdf/10.1145/3695993", "details": "Y Yu, G Rong, H Shen, H Zhang, D Shao, M Wang\u2026 - ACM Transactions on \u2026, 2024", "abstract": "As code review is a tedious and costly software quality practice, researchers have proposed several machine learning-based methods to automate the process. The primary focus has been on accuracy, that is, how accurately the algorithms are able \u2026"}, {"title": "Generative LLM Powered Conversational AI Application for Personalized Risk Assessment: A Case Study in COVID-19", "link": "https://arxiv.org/pdf/2409.15027", "details": "MA Roshani, X Zhou, Y Qiang, S Suresh, S Hicks\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have shown remarkable capabilities in various natural language tasks and are increasingly being applied in healthcare domains. This work demonstrates a new LLM-powered disease risk assessment approach via \u2026"}, {"title": "Parameter Efficiency, Few-Shot, Zero-Shot, Prompting", "link": "https://jonmay.github.io/USC-CS662/assets/files/llm.pdf", "details": "J May - 2024", "abstract": "The models we've discussed so far follow the paradigm that, out of the box, they don't do too much, but when you expose them to some supervised data that is an exemplar of a task and fine-tune their parameters they can do the task when given \u2026"}, {"title": "An Inference Method for Professional Texts with Computational Expressions under Few-shot Scenarios", "link": "https://splab.sdu.edu.cn/calc_infer.pdf", "details": "L Yang, W Zheng, F Yuan, Y Sun", "abstract": "We propose an inference method for complex professional texts with computational expressions. We use the expert rules to locate and rewrite the expressions. We adopt the pre-trained language model as the initial model and select the high quality \u2026"}, {"title": "Evaluation of Large Language Model Performance on the Biomedical Language Understanding and Reasoning Benchmark: Comparative Study", "link": "https://www.medrxiv.org/content/10.1101/2024.05.17.24307411.pdf", "details": "H Feng, F Ronzano, J LaFleur, M Garber, R de Oliveira\u2026", "abstract": "Background: The availability of increasingly powerful large language models (LLMs) has attracted substantial interest in their potential for interpreting and generating human-like text for biomedical and clinical applications. However, there are often \u2026"}, {"title": "ARB-LLM: Alternating Refined Binarizations for Large Language Models", "link": "https://arxiv.org/pdf/2410.03129", "details": "Z Li, X Yan, T Zhang, H Qin, D Xie, J Tian, L Kong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have greatly pushed forward advancements in natural language processing, yet their high memory and computational demands hinder practical deployment. Binarization, as an effective compression technique \u2026"}, {"title": "Zero-Shot Multi-Hop Question Answering via Monte-Carlo Tree Search with Large Language Models", "link": "https://arxiv.org/pdf/2409.19382", "details": "S Lee, J Shin, Y Ahn, S Seo, O Kwon, KE Kim - arXiv preprint arXiv:2409.19382, 2024", "abstract": "Recent advances in large language models (LLMs) have significantly impacted the domain of multi-hop question answering (MHQA), where systems are required to aggregate information and infer answers from disparate pieces of text. However, the \u2026"}, {"title": "CITI: Enhancing Tool Utilizing Ability in Large Language Models without Sacrificing General Performance", "link": "https://arxiv.org/pdf/2409.13202", "details": "Y Hao, P Cao, Z Jin, H Liao, K Liu, J Zhao - arXiv preprint arXiv:2409.13202, 2024", "abstract": "Tool learning enables the Large Language Models (LLMs) to interact with the external environment by invoking tools, enriching the accuracy and capability scope of LLMs. However, previous works predominantly focus on improving model's tool \u2026"}]
