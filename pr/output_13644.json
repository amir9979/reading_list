[{"title": "From Deep Additive Kernel Learning to Last-Layer Bayesian Neural Networks via Induced Prior Approximation", "link": "https://arxiv.org/pdf/2502.10540", "details": "W Zhao, H Chen, T Liu, R Tuo, C Tian - arXiv preprint arXiv:2502.10540, 2025", "abstract": "With the strengths of both deep learning and kernel methods like Gaussian Processes (GPs), Deep Kernel Learning (DKL) has gained considerable attention in recent years. From the computational perspective, however, DKL becomes \u2026"}, {"title": "CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards Zero-shot Adversarial Robustness of CLIP", "link": "https://arxiv.org/pdf/2503.03613", "details": "S Xing, Z Zhao, N Sebe - arXiv preprint arXiv:2503.03613, 2025", "abstract": "Despite its prevalent use in image-text matching tasks in a zero-shot manner, CLIP has been shown to be highly vulnerable to adversarial perturbations added onto images. Recent studies propose to finetune the vision encoder of CLIP with \u2026"}, {"title": "Causal-Informed Contrastive Learning: Towards Bias-Resilient Pre-training under Concept Drift", "link": "https://arxiv.org/pdf/2502.07620%3F", "details": "X Yang, J Lu, E Yu - arXiv preprint arXiv:2502.07620, 2025", "abstract": "The evolution of large-scale contrastive pre-training propelled by top-tier datasets has reached a transition point in the scaling law. Consequently, sustaining and enhancing a model's pre-training capabilities in drift environments have surfaced as \u2026"}, {"title": "Deep Out-of-Distribution Uncertainty Quantification via Weight Entropy Maximization", "link": "http://www.jmlr.org/papers/volume26/23-1359/23-1359.pdf", "details": "A de Mathelin, F Deheeger, M Mougeot, N Vayatis - Journal of Machine Learning \u2026, 2025", "abstract": "This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods. It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches \u2026"}, {"title": "Variational Linearized Laplace Approximation for bayesian deep learning", "link": "https://repositorio.comillas.edu/xmlui/bitstream/handle/11531/97863/IIT-24-279C%3Fsequence%3D-1", "details": "S Rodr\u00edguez Santana, D Hern\u00e1ndez Lobato - 2025", "abstract": "The Linearized Laplace Approximation (LLA) has been recently used to perform uncertainty estimation on the predictions of pre-trained deep neural networks (DNNs). However, its widespread application is hindered by significant \u2026"}, {"title": "TopoCL: Topological Contrastive Learning for Time Series", "link": "https://arxiv.org/pdf/2502.02924", "details": "N Kim, H Baik, Y Yoon - arXiv preprint arXiv:2502.02924, 2025", "abstract": "Universal time series representation learning is challenging but valuable in real- world applications such as classification, anomaly detection, and forecasting. Recently, contrastive learning (CL) has been actively explored to tackle time series \u2026"}]
