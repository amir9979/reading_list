[{"title": "Online Preference Alignment for Language Models via Count-based Exploration", "link": "https://arxiv.org/pdf/2501.12735", "details": "C Bai, Y Zhang, S Qiu, Q Zhang, K Xu, X Li - arXiv preprint arXiv:2501.12735, 2025", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has shown great potential in fine-tuning Large Language Models (LLMs) to align with human preferences. Existing methods perform preference alignment from a fixed dataset, which can be \u2026"}, {"title": "When Evolution Strategy Meets Language Models Tuning", "link": "https://aclanthology.org/2025.coling-main.357.pdf", "details": "B Huang, Y Jiang, M Chen, Y Wang, H Chen, W Wang - Proceedings of the 31st \u2026, 2025", "abstract": "Supervised Fine-tuning has been pivotal in training autoregressive language models, yet it introduces exposure bias. To mitigate this, Post Fine-tuning, including on-policy and off-policy methods, has emerged as a solution to enhance models \u2026"}, {"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "link": "https://arxiv.org/pdf/2501.04322", "details": "M Rang, Z Bi, C Liu, Y Tang, K Han, Y Wang - arXiv preprint arXiv:2501.04322, 2025", "abstract": "Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are \u2026"}, {"title": "OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models", "link": "https://arxiv.org/pdf/2501.12975", "details": "C Sun, Y Li, D Wu, B Boulet - arXiv preprint arXiv:2501.12975, 2025", "abstract": "Large Language Models (LLMs) are highly capable but require significant computational resources for both training and inference. Within the LLM family, smaller models (those with fewer than 10 billion parameters) also perform well \u2026"}, {"title": "Selected Languages are All You Need for Cross-lingual Truthfulness Transfer", "link": "https://aclanthology.org/2025.coling-main.601.pdf", "details": "W Liu, N Wu, W Ding, S Liang, M Gong, D Zhang - Proceedings of the 31st \u2026, 2025", "abstract": "Truthfulness stands out as an essential challenge for Large Language Models (LLMs). Although many works have developed various ways for truthfulness enhancement, they seldom focus on truthfulness in multilingual scenarios \u2026"}, {"title": "Double Visual Defense: Adversarial Pre-training and Instruction Tuning for Improving Vision-Language Model Robustness", "link": "https://arxiv.org/pdf/2501.09446", "details": "Z Wang, C Xie, B Bartoldson, B Kailkhura - arXiv preprint arXiv:2501.09446, 2025", "abstract": "This paper investigates the robustness of vision-language models against adversarial visual perturbations and introduces a novel``double visual defense\" to enhance this robustness. Unlike previous approaches that resort to lightweight \u2026"}, {"title": "Topology-of-Question-Decomposition: Enhancing Large Language Models with Information Retrieval for Knowledge-Intensive Tasks", "link": "https://aclanthology.org/2025.coling-main.191.pdf", "details": "W Li, J Wang, LC Yu, X Zhang - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) are increasingly deployed for general problem- solving across various domains yet remain constrained to chaining immediate reasoning steps and depending solely on parametric knowledge. Integrating an \u2026"}, {"title": "Exploring the Efficacy of Meta-Learning: Unveiling Superior Data Diversity Utilization of MAML Over Pre-training", "link": "https://arxiv.org/pdf/2501.08506", "details": "K Selva, S Vittayaareekul, B Miranda - arXiv preprint arXiv:2501.08506, 2025", "abstract": "Currently, data and model size dominate the narrative in the training of super-large, powerful models. However, there has been a lack of exploration on the effect of other attributes of the training dataset on model performance. We hypothesize that dataset \u2026"}, {"title": "LLM360 K2: Scaling Up 360-Open-Source Large Language Models", "link": "https://arxiv.org/pdf/2501.07124", "details": "Z Liu, B Tan, H Wang, W Neiswanger, T Tao, H Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We detail the training of the LLM360 K2-65B model, scaling up our 360-degree OPEN SOURCE approach to the largest and most powerful models under project LLM360. While open-source LLMs continue to advance, the answer to\" How are the \u2026"}]
