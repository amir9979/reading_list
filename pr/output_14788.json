[{"title": "Sparseformer: a Transferable Transformer with Multi-granularity Token Sparsification for Medical Time Series Classification", "link": "https://arxiv.org/pdf/2503.15578", "details": "J Ye, W Zhang, Z Li, J Li, F Tsung - arXiv preprint arXiv:2503.15578, 2025", "abstract": "Medical time series (MedTS) classification is crucial for improved diagnosis in healthcare, and yet it is challenging due to the varying granularity of patterns, intricate inter-channel correlation, information redundancy, and label scarcity. While \u2026"}, {"title": "MPTSNet: Integrating Multiscale Periodic Local Patterns and Global Dependencies for Multivariate Time Series Classification", "link": "https://arxiv.org/pdf/2503.05582%3F", "details": "Y Mu, M Shahzad, XX Zhu - arXiv preprint arXiv:2503.05582, 2025", "abstract": "Multivariate Time Series Classification (MTSC) is crucial in extensive practical applications, such as environmental monitoring, medical EEG analysis, and action recognition. Real-world time series datasets typically exhibit complex dynamics. To \u2026"}, {"title": "MSNet: Multi-task self-supervised network for time series classification", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525000923", "details": "D Huang, X Lv, Y Zhang - Pattern Recognition Letters, 2025", "abstract": "Learning rich representations from unlabeled temporal data is essential for effective time series classification. Most existing self-supervised learning methods for time series focus on a single task, often relying on contrastive learning or reconstruction \u2026"}, {"title": "High Quality Diffusion Distillation on a Single GPU with Relative and Absolute Position Matching", "link": "https://arxiv.org/pdf/2503.20744%3F", "details": "G Zhang, K Niwa, JP Lewis, C Mesnage, WB Kleijn - arXiv preprint arXiv:2503.20744, 2025", "abstract": "We introduce relative and absolute position matching (RAPM), a diffusion distillation method resulting in high quality generation that can be trained efficiently on a single GPU. Recent diffusion distillation research has achieved excellent results for high \u2026"}, {"title": "Hardware-Aware Iterative One-Shot Neural Architecture Search with Adaptable Knowledge Distillation for Efficient Edge Computing", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10938148.pdf", "details": "OTC Chen, YX Chang, CY Chung, YY Cheng, MH Ha - IEEE Access, 2025", "abstract": "The growing demand for edge applications calls for efficient and optimized deep neural network models. Neural Architecture Search (NAS) is instrumental in designing such models, but achieving optimal architectures quickly remains a key \u2026"}, {"title": "MAD-DGTD: Multivariate time series Anomaly Detection based on Dynamic Graph structure learning with Time Delay", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225005594", "details": "K Wang, J Kong, M Zhang, M Jiang, T Liu - Neurocomputing, 2025", "abstract": "Anomaly detection of multivariate time series data is extremely important in the industrial operation maintenance of Internet of Things (IoT). Researchers have found that the relationship between multiple sensors can be modeled as graph structure \u2026"}, {"title": "Language Model Uncertainty Quantification with Attention Chain", "link": "https://arxiv.org/pdf/2503.19168", "details": "Y Li, R Qiang, L Moukheiber, C Zhang - arXiv preprint arXiv:2503.19168, 2025", "abstract": "Accurately quantifying a large language model's (LLM) predictive uncertainty is crucial for judging the reliability of its answers. While most existing research focuses on short, directly answerable questions with closed-form outputs (eg, multiple \u2026"}, {"title": "TSRM: ALightweight TEMPORAL FEATURE ENCODING ARCHITECTURE FOR TIME SERIES FORECASTING AND IMPUTATION", "link": "https://www.researchgate.net/profile/Robert-Leppich-2/publication/389759430_TSRM_A_Lightweight_Temporal_Feature_Encoding_Architecture_for_Time_Series_Forecasting_and_Imputation/links/67d1452d32265243f58520ab/TSRM-A-Lightweight-Temporal-Feature-Encoding-Architecture-for-Time-Series-Forecasting-and-Imputation.pdf", "details": "R Leppich, M Stenger, D Grillmeyer, V Borst, S Kounev", "abstract": "We introduce a temporal feature encoding architecture called Time Series Representation Model (TSRM) for multivariate time series forecasting and imputation. The architecture is structured around CNN-based representation layers \u2026"}, {"title": "Teacher privileged distillation: How to deal with imperfect teachers?", "link": "https://www.sciencedirect.com/science/article/pii/S0950705125003855", "details": "M Mart\u00ednez-Garc\u00eda, I Inza, JA Lozano - Knowledge-Based Systems, 2025", "abstract": "The paradigm of learning using privileged information leverages privileged features present at training time, but not at prediction, as additional training information. The privileged learning process is addressed through a knowledge distillation \u2026"}]
