[{"title": "Machine learning approaches enable the discovery of therapeutics across domains", "link": "https://www.cell.com/molecular-therapy-family/molecular-therapy/pdf/S1525-0016\\(25\\)00275-8.pdf", "details": "P Chhibbar, J Das - Molecular Therapy, 2025", "abstract": "Multi-modal datasets have grown exponentially in the last decade. This has created an enormous demand for machine learning models that can predict complex outcomes by leveraging cellular, molecular and humoral profiles. Corresponding \u2026"}, {"title": "scTrans: Sparse attention powers fast and accurate cell type annotation in single-cell RNA-seq data", "link": "https://journals.plos.org/ploscompbiol/article%3Fid%3D10.1371/journal.pcbi.1012904", "details": "Z Zou, Y Liu, Y Bai, J Luo, Z Zhang - PLOS Computational Biology, 2025", "abstract": "Cell type annotation is crucial in single-cell RNA sequencing data analysis because it enables significant biological discoveries and deepens our understanding of tissue biology. Given the high-dimensional and highly sparse nature of single-cell RNA \u2026"}, {"title": "VeriLA: A Human-Centered Evaluation Framework for Interpretable Verification of LLM Agent Failures", "link": "https://arxiv.org/pdf/2503.12651", "details": "YY Sung, H Kim, D Zhang - arXiv preprint arXiv:2503.12651, 2025", "abstract": "AI practitioners increasingly use large language model (LLM) agents in compound AI systems to solve complex reasoning tasks, these agent executions often fail to meet human standards, leading to errors that compromise the system's overall \u2026"}, {"title": "Conversational User-AI Intervention: A Study on Prompt Rewriting for Improved LLM Response Generation", "link": "https://arxiv.org/pdf/2503.16789", "details": "R Sarkar, B Sarrafzadeh, N Chandrasekaran\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Human-LLM conversations are increasingly becoming more pervasive in peoples' professional and personal lives, yet many users still struggle to elicit helpful responses from LLM Chatbots. One of the reasons for this issue is users' lack of \u2026"}, {"title": "Generative Evaluation of Complex Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2504.02810", "details": "H Lin, X Wang, R Yan, B Huang, H Ye, J Zhu, Z Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly \u2026"}, {"title": "Group Preference Alignment: Customized LLM Response Generation from In-Situ Conversations", "link": "https://arxiv.org/pdf/2503.08035", "details": "I Mondal, JW Stokes, SK Jauhar, L Yang, M Wan, X Xu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "LLMs often fail to meet the specialized needs of distinct user groups due to their one- size-fits-all training paradigm\\cite {lucy-etal-2024-one} and there is limited research on what personalization aspects each group expect. To address these limitations, we \u2026"}, {"title": "XAttack: Counterfactual Explainable Prompt Attack Analysis on Large Language Models", "link": "https://scholar.xjtlu.edu.cn/files/52603047/IEEE_Big_Data_XAttack_Counterfactual_Explainable_Prompt_Attack_Analysis.pdf", "details": "D Shu, M Jin, C Zhang, T Chen, L Li, Y Zhang", "abstract": "This study sheds light on the imperative need to bolster safety and privacy measures in large language models (LLMs), such as GPT-4 and llama-2, by identifying and mitigating their vulnerabilities through explainable analysis of prompt attacks. We \u2026"}, {"title": "User-friendly Foundation Model Adapters for Multivariate Time Series Classification", "link": "https://romilbert.github.io/adapters/adapters_multisa.pdf", "details": "R Ilbert, V Feofanov, M Tiomoko, I Redko, T Palpanas", "abstract": "Foundation models, while highly effective, are often resource-intensive, requiring substantial inference time and memory. This paper addresses the challenge of making these models more accessible with limited computational resources through \u2026"}, {"title": "Sample-aware Adaptive Structured Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2503.06184%3F", "details": "J Kong, X Ma, J Wang, X Zhang - arXiv preprint arXiv:2503.06184, 2025", "abstract": "Large language models (LLMs) have achieved outstanding performance in natural language processing, but enormous model sizes and high computational costs limit their practical deployment. Structured pruning can effectively reduce the resource \u2026"}]
