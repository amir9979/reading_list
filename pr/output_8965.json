[{"title": "LM2: A Simple Society of Language Models Solves Complex Reasoning", "link": "https://aclanthology.org/2024.emnlp-main.920.pdf", "details": "G Juneja, S Dutta, T Chakraborty - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Despite demonstrating emergent reasoning abilities, Large Language Models (LLMS) often lose track of complex, multi-step reasoning. Existing studies show that providing guidance via decomposing the original question into multiple subproblems \u2026"}, {"title": "Eliciting In-Context Learning in Vision-Language Models for Videos Through Curated Data Distributional Properties", "link": "https://aclanthology.org/2024.emnlp-main.1137.pdf", "details": "K Yu, Z Zhang, F Hu, S Storks, J Chai - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "A major reason behind the recent success of large language models (LLMs) is their incontext learning capability, which makes it possible to rapidly adapt them to downstream textbased tasks by prompting them with a small number of relevant \u2026"}, {"title": "Improving Referring Ability for Biomedical Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.375.pdf", "details": "J Jiang, F Cheng, A Aizawa - Findings of the Association for Computational \u2026, 2024", "abstract": "Existing auto-regressive large language models (LLMs) are primarily trained using documents from general domains. In the biomedical domain, continual pre-training is a prevalent method for domain adaptation to inject professional knowledge into \u2026"}, {"title": "Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models", "link": "https://aclanthology.org/2024.emnlp-main.566.pdf", "details": "XH Feng, C Chen, Y Li, Z Lin - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Pre-trained language models acquire knowledge from vast amounts of text data, which can inadvertently contain sensitive information. To mitigate the presence of undesirable knowledge, the task of knowledge unlearning becomes crucial for \u2026"}, {"title": "Is Small Really Beautiful for Central Bank Communication? Evaluating Language Models for Finance: Llama-3-70B, GPT-4, FinBERT-FOMC, FinBERT, and VADER", "link": "https://dl.acm.org/doi/pdf/10.1145/3677052.3698675", "details": "W Kim, J Sp\u00f6rer, CL Lee, S Handschuh - Proceedings of the 5th ACM International \u2026, 2024", "abstract": "This study compares the sentiment detection capabilities of language models for the domain of central bank communication, particularly the official statements released by the US Federal Open Market Committee (FOMC). While previous studies have \u2026"}, {"title": "TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models", "link": "https://arxiv.org/pdf/2411.04642", "details": "J Fhima, EB Avraham, O Nuriel, Y Kittenplon, R Ganz\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language (VL) models have garnered considerable research interest; however, they still face challenges in effectively handling text within images. To address this limitation, researchers have developed two approaches. The first \u2026"}, {"title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "link": "https://aclanthology.org/2024.emnlp-main.1220.pdf", "details": "S Singla, Z Wang, T Liu, A Ashfaq, Z Hu, E Xing - \u2026 of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Abstract Aligning Large Language Models (LLMs) traditionally relies on complex and costly training processes like supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF). To address the challenge of achieving \u2026"}, {"title": "Two Heads are Better than One: Zero-shot Cognitive Reasoning via Multi-LLM Knowledge Fusion", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679744", "details": "L Liu, D Zhang, S Li, G Zhou, E Cambria - Proceedings of the 33rd ACM International \u2026, 2024", "abstract": "Cognitive reasoning holds a significant place within Natural Language Processing (NLP). Yet, the exploration of zero-shot scenarios, which align more closely with real- life situations than supervised scenarios, has been relatively limited. While a few \u2026"}, {"title": "How Much Do Prompting Methods Help LLMs on Quantitative Reasoning with Irrelevant Information?", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679840", "details": "SH Song, W Tavanapong - Proceedings of the 33rd ACM International Conference \u2026, 2024", "abstract": "Real-world quantitative reasoning problems are complex, often including extra information irrelevant to the question (or\" IR noise\" for short). State-of-the-art (SOTA) prompting methods have increased the Large Language Model's ability for \u2026"}]
