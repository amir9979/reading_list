[{"title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models", "link": "https://arxiv.org/pdf/2410.18785%3F", "details": "Q Li, X Liu, Z Tang, P Dong, Z Li, X Pan, X Chu - arXiv preprint arXiv:2410.18785, 2024", "abstract": "Model editing has become an increasingly popular alternative for efficiently updating knowledge within language models. Current methods mainly focus on reliability, generalization, and locality, with many methods excelling across these criteria. Some \u2026"}, {"title": "From Babbling to Fluency: Evaluating the Evolution of Language Models in Terms of Human Language Acquisition", "link": "https://arxiv.org/pdf/2410.13259", "details": "Q Yang, P Wang, LD Plonsky, FL Oswald, H Chen - arXiv preprint arXiv:2410.13259, 2024", "abstract": "We examine the language capabilities of language models (LMs) from the critical perspective of human language acquisition. Building on classical language development theories, we propose a three-stage framework to assess the abilities of \u2026"}, {"title": "CREAM: Consistency Regularized Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2410.12735%3F", "details": "Z Wang, W He, Z Liang, X Zhang, C Bansal, Y Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent self-rewarding large language models (LLM) have successfully applied LLM- as-a-Judge to iteratively improve the alignment performance without the need of human annotations for preference data. These methods commonly utilize the same \u2026"}, {"title": "Reducing the Scope of Language Models with Circuit Breakers", "link": "https://arxiv.org/pdf/2410.21597", "details": "D Yunis, S Huo, C Gunasekara, D Contractor - arXiv preprint arXiv:2410.21597, 2024", "abstract": "Language models are now deployed in a wide variety of user-facing applications, often for specific purposes like answering questions about documentation or acting as coding assistants. As these models are intended for particular purposes, they \u2026"}, {"title": "From Sparse Dependence to Sparse Attention: Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency", "link": "https://arxiv.org/pdf/2410.05459", "details": "K Wen, H Zhang, H Lin, J Zhang - arXiv preprint arXiv:2410.05459, 2024", "abstract": "Chain-of-thought (CoT) significantly enhances the reasoning performance of large language models (LLM). While current theoretical studies often attribute this improvement to increased expressiveness and computational capacity, we argue \u2026"}, {"title": "Moe++: Accelerating mixture-of-experts methods with zero-computation experts", "link": "https://arxiv.org/pdf/2410.07348", "details": "P Jin, B Zhu, L Yuan, S Yan - arXiv preprint arXiv:2410.07348, 2024", "abstract": "In this work, we aim to simultaneously enhance the effectiveness and efficiency of Mixture-of-Experts (MoE) methods. To achieve this, we propose MoE++, a general and heterogeneous MoE framework that integrates both Feed-Forward \u2026"}, {"title": "Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes", "link": "https://arxiv.org/pdf/2410.05052", "details": "K Nishida, K Nishida, K Saito - arXiv preprint arXiv:2410.05052, 2024", "abstract": "Loss spikes, a phenomenon in which the loss value diverges suddenly, is a fundamental issue in the pre-training of large language models. This paper supposes that the non-uniformity of the norm of the parameters is one of the causes \u2026"}, {"title": "Probing-RAG: Self-Probing to Guide Language Models in Selective Document Retrieval", "link": "https://arxiv.org/pdf/2410.13339", "details": "I Baek, H Chang, B Kim, J Lee, H Lee - arXiv preprint arXiv:2410.13339, 2024", "abstract": "Retrieval-Augmented Generation (RAG) enhances language models by retrieving and incorporating relevant external knowledge. However, traditional retrieve-and- generate processes may not be optimized for real-world scenarios, where queries \u2026"}, {"title": "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories", "link": "https://arxiv.org/pdf/2410.07706", "details": "Y Song, W Xiong, X Zhao, D Zhu, W Wu, K Wang, C Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Fine-tuning on agent-environment interaction trajectory data holds significant promise for surfacing generalized agent capabilities in open-source large language models (LLMs). In this work, we introduce AgentBank, by far the largest trajectory \u2026"}]
