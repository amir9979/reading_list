[{"title": "Does Data-Efficient Generalization Exacerbate Bias in Foundation Models?", "link": "https://arxiv.org/pdf/2408.16154", "details": "D Queiroz, A Carlos, M Fatoretto, A Anjos, L Berton\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Foundation models have emerged as robust models with label efficiency in diverse domains. In medical imaging, these models contribute to the advancement of medical diagnoses due to the difficulty in obtaining labeled data. However, it is \u2026"}, {"title": "Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios", "link": "https://aclanthology.org/2024.findings-acl.230.pdf", "details": "L Lin, J Fu, P Liu, Q Li, Y Gong, J Wan, F Zhang\u2026 - Findings of the Association \u2026, 2024", "abstract": "Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local \u2026"}, {"title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation", "link": "https://arxiv.org/pdf/2408.03281", "details": "B Cao, M Ren, H Lin, X Han, F Zhang, J Zhan, L Sun - arXiv preprint arXiv \u2026, 2024", "abstract": "Evaluation is the baton for the development of large language models. Current evaluations typically employ a single-item assessment paradigm for each atomic test objective, which struggles to discern whether a model genuinely possesses the \u2026"}]
