[{"title": "Self-Memory Alignment: Mitigating Factual Hallucinations with Generalized Improvement", "link": "https://arxiv.org/pdf/2502.19127", "details": "S Zhang, Y Zhang, Y Dong, H Su - arXiv preprint arXiv:2502.19127, 2025", "abstract": "Large Language Models (LLMs) often struggle to align their responses with objective facts, resulting in the issue of factual hallucinations, which can be difficult to detect and mislead users without relevant knowledge. While post-training techniques have \u2026"}, {"title": "DeepThink: Aligning Language Models with Domain-Specific User Intents", "link": "https://arxiv.org/pdf/2502.05497", "details": "Y Li, M Luo, Y Gong, C Lin, J Jiao, Y Liu, K Huang - arXiv preprint arXiv:2502.05497, 2025", "abstract": "Supervised fine-tuning with synthesized instructions has been a common practice for adapting LLMs to domain-specific QA tasks. However, the synthesized instructions deviate from real user questions and expected answers. This study proposes a novel \u2026"}, {"title": "\" See the World, Discover Knowledge\": A Chinese Factuality Evaluation for Large Vision Language Models", "link": "https://arxiv.org/pdf/2502.11718", "details": "J Gu, Y Wang, P Bu, C Wang, Z Wang, T Song, D Wei\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The evaluation of factual accuracy in large vision language models (LVLMs) has lagged behind their rapid development, making it challenging to fully reflect these models' knowledge capacity and reliability. In this paper, we introduce the first \u2026"}, {"title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models", "link": "https://arxiv.org/pdf/2502.10250%3F", "details": "GK Kumar, I Chaabane, K Wu - arXiv preprint arXiv:2502.10250, 2025", "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved \u2026"}, {"title": "Multilingual Language Model Pretraining using Machine-translated Data", "link": "https://arxiv.org/pdf/2502.13252", "details": "J Wang, Y Lu, M Weber, M Ryabinin, D Adelani\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "High-resource languages such as English, enables the pretraining of high-quality large language models (LLMs). The same can not be said for most other languages as LLMs still underperform for non-English languages, likely due to a gap in the \u2026"}, {"title": "AnyEdit: Edit Any Knowledge Encoded in Language Models", "link": "https://arxiv.org/pdf/2502.05628", "details": "H Jiang, J Fang, N Zhang, G Ma, M Wan, X Wang, X He\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) often produce incorrect or outdated information, necessitating efficient and precise knowledge updates. Current model editing methods, however, struggle with long-form knowledge in diverse formats, such as \u2026"}, {"title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation", "link": "https://arxiv.org/pdf/2502.19414", "details": "S Sinha, S Goel, P Kumaraguru, J Geiping, M Bethge\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery. Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time. This process requires significant \u2026"}, {"title": "Investigating the Robustness of Deductive Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2502.04352", "details": "F Hoppe, F Ilievski, JC Kalo - arXiv preprint arXiv:2502.04352, 2025", "abstract": "Large Language Models (LLMs) have been shown to achieve impressive results for many reasoning-based Natural Language Processing (NLP) tasks, suggesting a degree of deductive reasoning capability. However, it remains unclear to which \u2026"}, {"title": "Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG", "link": "https://arxiv.org/pdf/2502.08356", "details": "K Bhushan, Y Nandwani, D Khandelwal, S Gupta\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a prominent method for incorporating domain knowledge into Large Language Models (LLMs). While RAG enhances response relevance by incorporating retrieved domain knowledge in the \u2026"}]
