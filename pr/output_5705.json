[{"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Language Models Don't Learn the Physical Manifestation of Language", "link": "https://aclanthology.org/2024.acl-long.195.pdf", "details": "B Lee, J Lim - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "We argue that language-only models don't learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test. These tasks highlight a \u2026"}, {"title": "Shifting Attention to Relevance: Towards the Predictive Uncertainty Quantification of Free-Form Large Language Models", "link": "https://aclanthology.org/2024.acl-long.276.pdf", "details": "J Duan, H Cheng, S Wang, A Zavalny, C Wang, R Xu\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) show promising results in language generation and instruction following but frequently \u201challucinate\u201d, making their outputs less reliable. Despite Uncertainty Quantification's (UQ) potential solutions \u2026"}, {"title": "SCFL: Spatio-temporal consistency federated learning for next POI recommendation", "link": "https://www.sciencedirect.com/science/article/pii/S0306457324002115", "details": "L Zhong, J Zeng, Z Wang, W Zhou, J Wen - Information Processing & Management, 2024", "abstract": "Existing personalized federated learning frameworks fail to significantly improve the personalization of user preference learning in next Point-Of-Interest (POI) recommendations, causing notable performance deficits. These frameworks do not \u2026"}, {"title": "Towards Harnessing Large Language Models as Autonomous Agents for Semantic Triple Extraction from Unstructured Text", "link": "https://ceur-ws.org/Vol-3747/text2kg_paper1.pdf", "details": "A Ananya, S Tiwari, N Mihindukulasooriya, T Soru\u2026 - 2024", "abstract": "Abstract The use of Large Language Models as autonomous agents interacting with tools has shown to improve the performance of several tasks from code generation to API calling and sequencing. This paper proposes a framework for using Large \u2026"}, {"title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "link": "https://arxiv.org/pdf/2408.02103", "details": "P Wang, X Wang, C Lou, S Mao, P Xie, Y Jiang - arXiv preprint arXiv:2408.02103, 2024", "abstract": "In-context learning (ICL) is a few-shot learning paradigm that involves learning mappings through input-output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language \u2026"}, {"title": "Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs", "link": "https://aclanthology.org/2024.findings-acl.938.pdf", "details": "D Wang, J Zhao, H Pei, S Tan, S Zha - Findings of the Association for Computational \u2026, 2024", "abstract": "Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs \u2026"}, {"title": "Parrot: Enhancing Multi-Turn Instruction Following for Large Language Models", "link": "https://aclanthology.org/2024.acl-long.525.pdf", "details": "Y Sun, C Liu, K Zhou, J Huang, R Song, WX Zhao\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Humans often interact with large language models (LLMs) in multi-turn interaction to obtain desired answers or more information. However, most existing studies overlook the multi-turn instruction following ability of LLMs, in terms of training dataset, training \u2026"}]
