'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Autonomous Data Selection with Language Models for Mat'
[{"title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies", "link": "https://arxiv.org/pdf/2404.06395", "details": "S Hu, Y Tu, X Han, C He, G Cui, X Long, Z Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This \u2026"}, {"title": "Property Existence Inference against Generative Models", "link": "https://www.usenix.org/system/files/sec24fall-prepub-2868-wang-lijin.pdf", "details": "L Wang, J Wang, J Wan, L Long, Z Yang, Z Qin\u2026", "abstract": "Generative models have served as the backbone of versatile tools with a wide range of applications across various fields in recent years. However, it has been demonstrated that privacy concerns, such as membership information leakage of the \u2026"}, {"title": "Intrinsic LoRA: A Generalist Approach for Discovering Knowledge in Generative Models", "link": "https://openreview.net/pdf%3Fid%3DxHKWN3Yi6U", "details": "X Du, N Kolkin, G Shakhnarovich, A Bhattad - Synthetic Data for Computer Vision Workshop \u2026", "abstract": "Generative models have been shown to be capable of creating images that closely mimic real scenes, suggesting they inherently encode scene representations. We introduce Intrinsic LoRA (I-LoRA), a general approach that uses Low-Rank \u2026"}, {"title": "RS-LLaVA: A Large Vision-Language Model for Joint Captioning and Question Answering in Remote Sensing Imagery", "link": "https://www.mdpi.com/2072-4292/16/9/1477", "details": "Y Bazi, L Bashmal, MM Al Rahhal, R Ricci, F Melgani - Remote Sensing, 2024", "abstract": "In this paper, we delve into the innovative application of large language models (LLMs) and their extension, large vision-language models (LVLMs), in the field of remote sensing (RS) image analysis. We particularly emphasize their multi-tasking \u2026"}, {"title": "Refining Pre-trained Language Models for Domain Adaptation with Entity-Aware Discriminative and Contrastive Learning", "link": "https://epubs.siam.org/doi/pdf/10.1137/1.9781611978032.48", "details": "J Yang, X Hu, Y Shen, G xiao - Proceedings of the 2024 SIAM International \u2026, 2024", "abstract": "With the rapid advancement of pre-trained language models (PLMs), the adaptation of these models to specialized domains has emerged as an essential area of research. However, PLMs encounter substantial challenges when deployed in highly \u2026"}, {"title": "FairPair: A Robust Evaluation of Biases in Language Models through Paired Perturbations", "link": "https://arxiv.org/pdf/2404.06619", "details": "J Dwivedi-Yu, R Dwivedi, T Schick - arXiv preprint arXiv:2404.06619, 2024", "abstract": "The accurate evaluation of differential treatment in language models to specific groups is critical to ensuring a positive and safe user experience. An ideal evaluation should have the properties of being robust, extendable to new groups or attributes \u2026"}, {"title": "HyFit: Hybrid Fine-Tuning With Diverse Sampling for Abstractive Summarization", "link": "https://ieeexplore.ieee.org/abstract/document/10496256/", "details": "S Zhao, Y Cheng, Y Zhang, J Chen, Z Duan, Y Sun\u2026 - IEEE Transactions on Big \u2026, 2024", "abstract": "Abstractive summarization has made significant progress in recent years, which aims to generate a concise and coherent summary that contains the most important facts from the source document. Current fine-tuning approaches based on pre-training \u2026"}, {"title": "Toward Data-driven Skill Identification for General-purpose Vision-language Models", "link": "https://openreview.net/pdf%3Fid%3DqURmfSHKqx", "details": "A Tiong, J Zhao, J Li, S Hoi, C Xiong, B Li - ICLR 2024 Workshop on Navigating and \u2026", "abstract": "The evolution of vision-language (VL) models towards broad competencies has complicated benchmarking, necessitating diverse tasks for accurate evaluation. Moving beyond intuition-guided task selection common in existing benchmarks, we \u2026"}, {"title": "A Language Model based Framework for New Concept Placement in Ontologies", "link": "https://2024.eswc-conferences.org/wp-content/uploads/2024/04/146640077.pdf", "details": "I Horrocks", "abstract": "We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (ie, subsumptions \u2026"}]
