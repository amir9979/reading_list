[{"title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark", "link": "https://arxiv.org/pdf/2504.07749%3F", "details": "V Mikhailov, T Enstad, D Samuel, HC Farseth\u00e5s\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces NorEval, a new and comprehensive evaluation suite for large- scale standardized benchmarking of Norwegian generative language models (LMs). NorEval consists of 24 high-quality human-created datasets--of which five are \u2026"}, {"title": "RankAlign: A Ranking View of the Generator-Validator Gap in Large Language Models", "link": "https://arxiv.org/pdf/2504.11381%3F", "details": "JD Rodriguez, W Ding, K Erk, G Durrett - arXiv preprint arXiv:2504.11381, 2025", "abstract": "Although large language models (LLMs) have become generally more capable and accurate across many tasks, some fundamental sources of unreliability remain in their behavior. One key limitation is their inconsistency at reporting the the same \u2026"}, {"title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2504.07887", "details": "R Cantini, A Orsino, M Ruggiero, D Talia - arXiv preprint arXiv:2504.07887, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, driving advancements in machine translation, summarization, and conversational agents. However, their increasing integration into critical societal domains has raised \u2026"}, {"title": "Large language models could be rote learners", "link": "https://arxiv.org/pdf/2504.08300", "details": "Y Xu, R Hu, H Ying, J Wu, X Shi, W Lin - arXiv preprint arXiv:2504.08300, 2025", "abstract": "Multiple-choice question (MCQ) benchmarks are widely used for evaluating Large Language Models (LLMs), yet their reliability is undermined by benchmark contamination. In this study, we reframe contamination as an inherent aspect of \u2026"}, {"title": "Exploring Human-Like Thinking in Search Simulations with Large Language Models", "link": "https://arxiv.org/pdf/2504.07570", "details": "E Zhang, X Wang, P Gong, Z Yang, J Mao - arXiv preprint arXiv:2504.07570, 2025", "abstract": "Simulating user search behavior is a critical task in information retrieval, which can be employed for user behavior modeling, data augmentation, and system evaluation. Recent advancements in large language models (LLMs) have opened up new \u2026"}]
