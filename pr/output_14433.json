[{"title": "Federated Koopman-Reservoir Learning for Large-Scale Multivariate Time-Series Anomaly Detection", "link": "https://arxiv.org/pdf/2503.11255", "details": "LT Le, TA Nguyen, H Shu, S Seneviratne, CS Hong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The proliferation of edge devices has dramatically increased the generation of multivariate time-series (MVTS) data, essential for applications from healthcare to smart cities. Such data streams, however, are vulnerable to anomalies that signal \u2026"}, {"title": "A Time Series Self-Supervised Contrastive Pre-Training Method with Data Augmentation using Discrepancy of Reconstruction Information Loss", "link": "https://ieeexplore.ieee.org/abstract/document/10912708/", "details": "Z Zhang, Y Han, B Ma, Z Geng - IEEE Transactions on Instrumentation and \u2026, 2025", "abstract": "Self-supervised pre-training has shown considerable advantages in multiple time series tasks. A widely used class of methods is based on contrastive learning and a key problem is how to construct augmented samples. At present, explicit \u2026"}, {"title": "Hardware-Aware Iterative One-Shot Neural Architecture Search with Adaptable Knowledge Distillation for Efficient Edge Computing", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10938148.pdf", "details": "OTC Chen, YX Chang, CY Chung, YY Cheng, MH Ha - IEEE Access, 2025", "abstract": "The growing demand for edge applications calls for efficient and optimized deep neural network models. Neural Architecture Search (NAS) is instrumental in designing such models, but achieving optimal architectures quickly remains a key \u2026"}, {"title": "Fusionformer: A Novel Adversarial Transformer Utilizing Fusion Attention for Multivariate Anomaly Detection", "link": "https://ieeexplore.ieee.org/abstract/document/10922726/", "details": "C Wang, Z Wang, H Dong, S Lauria, W Liu, Y Wang\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "Multivariate time series forecasting (MTSF) is of significant importance in the enhancement and optimization of real-world applications. The task of MTSF poses substantial challenges due to the unpredictability of temporal patterns and the \u2026"}, {"title": "One-Class Classification Constraint in Reconstruction Networks for Multivariate Time Series Anomaly Detection", "link": "https://ieeexplore.ieee.org/abstract/document/10912658/", "details": "J Li, Z Yu, Q Jiang, Z Cao - IEEE Transactions on Instrumentation and \u2026, 2025", "abstract": "Detecting anomalies in multivariate time series (MTS) data is crucial for maintaining the stability of industrial manufacturing processes and biochemical operations. However, current methods often focus on capturing the normal patterns of training \u2026"}, {"title": "Series clustering and dynamic periodic patching-based transformer for multivariate time series forecasting", "link": "https://www.sciencedirect.com/science/article/pii/S1568494625002911", "details": "Y Wang, X Wu, J Zhang, W Wang, L Zheng, J Shang - Applied Soft Computing, 2025", "abstract": "Multivariate time series forecasting (MTSF) is widely employed in research-intensive domains, such as weather forecasting. Recently, Transformer-based models have outstanding ability to achieve SOTA performance, benefiting from its self-attention \u2026"}, {"title": "Tinyr1-32b-preview: Boosting accuracy with branch-merge distillation", "link": "https://arxiv.org/pdf/2503.04872", "details": "L Sun, G Zhao, X Jian, Y Wu, W Lin, Y Zhu, L Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The challenge of reducing the size of Large Language Models (LLMs) while maintaining their performance has gained significant attention. However, existing methods, such as model distillation and transfer learning, often fail to achieve high \u2026"}, {"title": "Teacher privileged distillation: How to deal with imperfect teachers?", "link": "https://www.sciencedirect.com/science/article/pii/S0950705125003855", "details": "M Mart\u00ednez-Garc\u00eda, I Inza, JA Lozano - Knowledge-Based Systems, 2025", "abstract": "The paradigm of learning using privileged information leverages privileged features present at training time, but not at prediction, as additional training information. The privileged learning process is addressed through a knowledge distillation \u2026"}, {"title": "Contrastive Learning via Randomly Generated Deep Supervision", "link": "https://ieeexplore.ieee.org/abstract/document/10890867/", "details": "S Wang, Z Ma, KH Chan, Y Liu, T Tong, Q Gao, G Zhai\u2026 - ICASSP 2025-2025 IEEE \u2026, 2025", "abstract": "Unsupervised visual representation learning has gained significant attention in the computer vision community, driven by recent advancements in contrastive learning. Most existing contrastive learning frameworks rely on instance discrimination as a \u2026"}]
