'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Data Visualization Analysis Based on Explainable Artif'
[{"title": "Deep Clustering with Hybrid-Grained Contrastive and Discriminative Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10528344/", "details": "D Huang, X Deng, DH Chen, Z Wen, W Sun, CD Wang\u2026 - IEEE Transactions on \u2026, 2024", "abstract": "Deep contrastive clustering has recently gained significant attention due to its advantageous ability to leverage the contrastive learning paradigm for joint representation learning and clustering. However, previous deep contrastive \u2026"}, {"title": "FireXplainNet: Optimizing Convolution Block Architecture for Enhanced Wildfire Detection and Interpretability", "link": "https://www.mdpi.com/2079-9292/13/10/1881", "details": "MA Khan, H Park - Electronics, 2024", "abstract": "The early detection of wildfires is a crucial challenge in environmental monitoring, pivotal for effective disaster management and ecological conservation. Traditional detection methods often fail to detect fires accurately and in a timely manner \u2026"}, {"title": "Semantic Attribution for Explainable Uncertainty Quantification", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DXs0DEQAAQBAJ%26oi%3Dfnd%26pg%3DPA101%26ots%3DfmuuDAZjAx%26sig%3DLX2V1JBaT5StyfTTgAkA9Xm72ns", "details": "S Wang, Q Ji - Epistemic Uncertainty in Artificial Intelligence: First \u2026", "abstract": "Bayesian deep learning, with an emphasis on uncertainty quantification, is receiving growing interest in building reliable models. Nonetheless, interpreting and explaining the origins and reasons for uncertainty presents a significant challenge. In \u2026"}, {"title": "ENERGY-BASED CONCEPT BOTTLENECK MODELS: UNIFYING PREDICTION, CONCEPT INTERVENTION, AND PROBABILISTIC INTERPRETATIONS", "link": "http://wanghao.in/paper/ICLR24_ECBM.pdf", "details": "X Xu, Y Qin, L Mi, H Wang, X Li", "abstract": "Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final \u2026"}]
