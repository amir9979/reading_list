[{"title": "ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement", "link": "https://arxiv.org/pdf/2410.02108", "details": "X Peng, C Xia, X Yang, C Xiong, CS Wu, C Xing - arXiv preprint arXiv:2410.02108, 2024", "abstract": "Post-training Large Language Models (LLMs) with explicit reasoning trajectories can enhance their reasoning abilities. However, acquiring such high-quality trajectory data typically demands meticulous supervision from humans or superior models \u2026"}, {"title": "AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models", "link": "https://arxiv.org/pdf/2410.02355", "details": "J Fang, H Jiang, K Wang, Y Ma, X Wang, X He, T Chua - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) often exhibit hallucinations due to incorrect or outdated knowledge. Hence, model editing methods have emerged to enable targeted knowledge updates. To achieve this, a prevailing paradigm is the locating \u2026"}, {"title": "POSIX: A Prompt Sensitivity Index For Large Language Models", "link": "https://arxiv.org/pdf/2410.02185", "details": "A Chatterjee, HK Renduchintala, S Bhatia\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) are found to be surprisingly sensitive to minor variations in prompts, often generating significantly divergent outputs in response to minor variations in the prompts, such as spelling \u2026"}, {"title": "Attention Prompting on Image for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2409.17143", "details": "R Yu, W Yu, X Wang - arXiv preprint arXiv:2409.17143, 2024", "abstract": "Compared with Large Language Models (LLMs), Large Vision-Language Models (LVLMs) can also accept images as input, thus showcasing more interesting emergent capabilities and demonstrating impressive performance on various vision \u2026"}, {"title": "Quantifying Generalization Complexity for Large Language Models", "link": "https://arxiv.org/pdf/2410.01769", "details": "Z Qi, H Luo, X Huang, Z Zhao, Y Jiang, X Fan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While large language models (LLMs) have shown exceptional capabilities in understanding complex queries and performing sophisticated tasks, their generalization abilities are often deeply entangled with memorization, necessitating \u2026"}, {"title": "Do Vision and Language Models Share Concepts? A Vector Space Alignment Study", "link": "https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00698/124631", "details": "J Li, Y Kementchedjhieva, C Fierro, A S\u00f8gaard - Transactions of the Association for \u2026, 2024", "abstract": "Large-scale pretrained language models (LMs) are said to \u201clack the ability to connect utterances to the world\u201d(Bender and Koller,), because they do not have \u201cmental models of the world\u201d(Mitchell and Krakauer,). If so, one would expect LM \u2026"}, {"title": "On the Inductive Bias of Stacking Towards Improving Reasoning", "link": "https://arxiv.org/pdf/2409.19044", "details": "N Saunshi, S Karp, S Krishnan, S Miryoosefi, SJ Reddi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Given the increasing scale of model sizes, novel training strategies like gradual stacking [Gong et al., 2019, Reddi et al., 2023] have garnered interest. Stacking enables efficient training by gradually growing the depth of a model in stages and \u2026"}, {"title": "SecCoder: Towards Generalizable and Robust Secure Code Generation", "link": "https://arxiv.org/pdf/2410.01488", "details": "B Zhang, T Du, J Tong, X Zhang, K Chow, S Cheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "After large models (LMs) have gained widespread acceptance in code-related tasks, their superior generative capacity has greatly promoted the application of the code LM. Nevertheless, the security of the generated code has raised attention to its \u2026"}, {"title": "Instance-adaptive Zero-shot Chain-of-Thought Prompting", "link": "https://arxiv.org/pdf/2409.20441%3F", "details": "X Yuan, C Shen, S Yan, X Zhang, L Xie, W Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective strategy for enhancing the performance of large language models (LLMs) in real- world reasoning tasks. Nonetheless, the efficacy of a singular, task-level prompt \u2026"}]
