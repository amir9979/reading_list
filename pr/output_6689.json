[{"title": "GP-GPT: Large Language Model for Gene-Phenotype Mapping", "link": "https://arxiv.org/pdf/2409.09825", "details": "Y Lyu, Z Wu, L Zhang, J Zhang, Y Li, W Ruan, Z Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained large language models (LLMs) have attracted increasing attention in biomedical domains due to their success in natural language processing. However, the complex traits and heterogeneity of multi-sources genomics data pose significant \u2026"}, {"title": "Robust image representations with counterfactual contrastive learning", "link": "https://arxiv.org/pdf/2409.10365", "details": "M Roschewitz, FDS Ribeiro, T Xia, G Khara, B Glocker - arXiv preprint arXiv \u2026, 2024", "abstract": "Contrastive pretraining can substantially increase model generalisation and downstream performance. However, the quality of the learned representations is highly dependent on the data augmentation strategy applied to generate positive \u2026"}, {"title": "Statistical Shape Models for Grasp Point Determination in Laparoscopic Surgeries", "link": "https://www.degruyter.com/document/doi/10.1515/cdbme-2024-0111/pdf", "details": "C Kunz, M Kraus, R Younis, M Wagner, F Mathis-Ullrich - Current Directions in \u2026, 2024", "abstract": "Robotic assistance systems are being used more and more frequently in the operating room, with the goal to support surgeons and to automate parts of a procedure. The laparoscopic cholecystectomy is one of the most common \u2026"}, {"title": "An open chest X-ray dataset with benchmarks for automatic radiology report generation in French", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224012499", "details": "H Metmer, X Yang - Neurocomputing, 2024", "abstract": "Medical report generation (MRG), which aims to automatically generate a textual description of a specific medical image (eg, a chest X-ray), has recently received increasing research interest. Building on the success of image captioning, MRG has \u2026"}, {"title": "Language Models Pre-training", "link": "https://link.springer.com/content/pdf/10.1007/978-3-031-65647-7_2.pdf", "details": "U Kamath, K Keenan, G Somers, S Sorenson - Large Language Models: A Deep Dive \u2026, 2024", "abstract": "Pre-training forms the foundation for LLMs' capabilities. LLMs gain vital language comprehension and generative language skills by using large-scale datasets. The size and quality of these datasets are essential for maximizing LLMs' potential. It is \u2026"}, {"title": "The more quality information the better: Hierarchical generation of multi-evidence alignment and fusion model for multimodal entity and relation extraction", "link": "https://www.sciencedirect.com/science/article/pii/S0306457324002346", "details": "X He, S Li, Y Zhang, B Li, S Xu, Y Zhou - Information Processing & Management, 2025", "abstract": "Abstract Multimodal Entity and Relation Extraction (MERE) encompasses tasks, including Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction (MRE), aiming to extract valuable information from environments rich in \u2026"}, {"title": "Generating colloquial radiology reports with large language models", "link": "https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae223/7740004", "details": "CC Tang, S Nagesh, DA Fussell, J Glavis-Bloom\u2026 - Journal of the American \u2026, 2024", "abstract": "Objectives Patients are increasingly being given direct access to their medical records. However, radiology reports are written for clinicians and typically contain medical jargon, which can be confusing. One solution is for radiologists to provide a \u2026"}]
