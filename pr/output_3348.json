[{"title": "Confidence Regulation Neurons in Language Models", "link": "https://arxiv.org/pdf/2406.16254", "details": "A Stolfo, B Wu, W Gurnee, Y Belinkov, X Song\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their widespread use, the mechanisms by which large language models (LLMs) represent and regulate uncertainty in next-token predictions remain largely unexplored. This study investigates two critical components believed to influence this \u2026"}, {"title": "Timo: Towards Better Temporal Reasoning for Language Models", "link": "https://arxiv.org/pdf/2406.14192", "details": "Z Su, J Zhang, T Zhu, X Qu, J Li, M Zhang, Y Cheng - arXiv preprint arXiv:2406.14192, 2024", "abstract": "Reasoning about time is essential for Large Language Models (LLMs) to understand the world. Previous works focus on solving specific tasks, primarily on time-sensitive question answering. While these methods have proven effective, they cannot \u2026"}, {"title": "Monitoring Latent World States in Language Models with Propositional Probes", "link": "https://arxiv.org/pdf/2406.19501", "details": "J Feng, S Russell, J Steinhardt - arXiv preprint arXiv:2406.19501, 2024", "abstract": "Language models are susceptible to bias, sycophancy, backdoors, and other tendencies that lead to unfaithful responses to the input context. Interpreting internal states of language models could help monitor and correct unfaithful behavior. We \u2026"}, {"title": "Aligning Language Models with the Human World", "link": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi%3Farticle%3D1241%26context%3Ddissertations", "details": "R LIU - 2024", "abstract": "Abstract The field of Natural Language Processing (NLP) has undergone a significant transformation with the emergence of large language models (LMs). These models have enabled the development of human-like conversational \u2026"}, {"title": "Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment", "link": "https://arxiv.org/pdf/2406.19759", "details": "O Xhelili, Y Liu, H Sch\u00fctze - arXiv preprint arXiv:2406.19759, 2024", "abstract": "Multilingual pre-trained models (mPLMs) have shown impressive performance on cross-lingual transfer tasks. However, the transfer performance is often hindered when a low-resource target language is written in a different script than the high \u2026"}, {"title": "Entropy-Based Decoding for Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2406.17519", "details": "Z Qiu, Z Ou, B Wu, J Li, A Liu, I King - arXiv preprint arXiv:2406.17519, 2024", "abstract": "Augmenting Large Language Models (LLMs) with retrieved external knowledge has proven effective for improving the factual accuracy of generated responses. Despite their success, retrieval-augmented LLMs still face the distractibility issue, where the \u2026"}, {"title": "Direct Preference Knowledge Distillation for Large Language Models", "link": "https://arxiv.org/pdf/2406.19774", "details": "Y Li, Y Gu, L Dong, D Wang, Y Cheng, F Wei - arXiv preprint arXiv:2406.19774, 2024", "abstract": "In the field of large language models (LLMs), Knowledge Distillation (KD) is a critical technique for transferring capabilities from teacher models to student models. However, existing KD methods face limitations and challenges in distillation of LLMs \u2026"}, {"title": "The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models", "link": "https://arxiv.org/pdf/2406.19999", "details": "X Chen, B Liao, J Qi, P Eustratiadis, C Monz, A Bisazza\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Following multiple instructions is a crucial ability for large language models (LLMs). Evaluating this ability comes with significant challenges:(i) limited coherence between multiple instructions,(ii) positional bias where the order of instructions \u2026"}, {"title": "Large Language Models have Intrinsic Self-Correction Ability", "link": "https://arxiv.org/pdf/2406.15673", "details": "D Liu, A Nassereldine, Z Yang, C Xu, Y Hu, J Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have attracted significant attention for their remarkable abilities in various natural language processing tasks, but they suffer from hallucinations that will cause performance degradation. One promising solution \u2026"}]
