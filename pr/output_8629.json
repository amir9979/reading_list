[{"title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.17637", "details": "Z Liu, Y Zang, X Dong, P Zhang, Y Cao, H Duan, C He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing \u2026"}, {"title": "Self-Comparison for Dataset-Level Membership Inference in Large (Vision-) Language Models", "link": "https://arxiv.org/pdf/2410.13088", "details": "J Ren, K Chen, C Chen, V Sehwag, Y Xing, J Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) and Vision-Language Models (VLMs) have made significant advancements in a wide range of natural language processing and vision- language tasks. Access to large web-scale datasets has been a key factor in their \u2026"}, {"title": "Can Language Models Learn to Skip Steps?", "link": "https://arxiv.org/pdf/2411.01855", "details": "T Liu, Q Guo, X Hu, C Jiayang, Y Zhang, X Qiu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Trained on vast corpora of human language, language models demonstrate emergent human-like reasoning abilities. Yet they are still far from true intelligence, which opens up intriguing opportunities to explore the parallels of humans and \u2026"}, {"title": "Language Models-enhanced Semantic Topology Representation Learning For Temporal Knowledge Graph Extrapolation", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679602", "details": "T Zhang, T Zheng, Z Xiao, Z Chen, L Li, Z Feng\u2026 - Proceedings of the 33rd \u2026, 2024", "abstract": "Temporal Knowledge Graph (TKG) extrapolation aims to predict future missing facts based on historical information, which has exhibited both semantics and topology of events. The mainstream methods have advanced the prediction performance by \u2026"}, {"title": "Faster Language Models with Better Multi-Token Prediction Using Tensor Decomposition", "link": "https://arxiv.org/pdf/2410.17765", "details": "A Basharin, A Chertkov, I Oseledets - arXiv preprint arXiv:2410.17765, 2024", "abstract": "We propose a new model for multi-token prediction in transformers, aiming to enhance sampling efficiency without compromising accuracy. Motivated by recent work that predicts the probabilities of subsequent tokens using multiple heads, we \u2026"}, {"title": "Testing Generalizability in Causal Inference", "link": "https://arxiv.org/pdf/2411.03021", "details": "DV Manela, L Yang, RJ Evans - arXiv preprint arXiv:2411.03021, 2024", "abstract": "Ensuring robust model performance across diverse real-world scenarios requires addressing both transportability across domains with covariate shifts and extrapolation beyond observed data ranges. However, there is no formal procedure \u2026"}, {"title": "Large language models enabled multiagent ensemble method for efficient EHR data labeling", "link": "https://arxiv.org/pdf/2410.16543", "details": "J Huang, K Nezafati, I Villanueva-Miranda, Z Gu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This study introduces a novel multiagent ensemble method powered by LLMs to address a key challenge in ML-data labeling, particularly in large-scale EHR datasets. Manual labeling of such datasets requires domain expertise and is labor \u2026"}, {"title": "Retrieval In Decoder benefits generative models for explainable complex question answering", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024007573", "details": "J Feng, Q Wang, H Qiu, L Liu - Neural Networks, 2024", "abstract": "Abstract Large-scale Language Models (LLMs) utilizing the Chain-of-Thought prompting demonstrate exceptional performance in a variety of tasks. However, the persistence of factual hallucinations remains a significant challenge in practical \u2026"}, {"title": "$\\beta $-calibration of Language Model Confidence Scores for Generative QA", "link": "https://arxiv.org/pdf/2410.06615", "details": "P Manggala, A Mastakouri, E Kirschbaum\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim \u2026"}]
