[{"title": "Exploring and Enhancing the Transfer of Distribution in Knowledge Distillation for Autoregressive Language Models", "link": "https://arxiv.org/pdf/2409.12512", "details": "J Rao, X Liu, Z Lin, L Ding, J Li, D Tao - arXiv preprint arXiv:2409.12512, 2024", "abstract": "Knowledge distillation (KD) is a technique that compresses large teacher models by training smaller student models to mimic them. The success of KD in auto-regressive language models mainly relies on Reverse KL for mode-seeking and student \u2026"}, {"title": "Learning To Help: Training Models to Assist Legacy Devices", "link": "https://arxiv.org/pdf/2409.16253", "details": "Y Wu, A Sarwate - arXiv preprint arXiv:2409.16253, 2024", "abstract": "Machine learning models implemented in hardware on physical devices may be deployed for a long time. The computational abilities of the device may be limited and become outdated with respect to newer improvements. Because of the size of \u2026"}, {"title": "Optimizing personalized treatments for targeted patient populations across multiple domains", "link": "https://www.degruyter.com/document/doi/10.1515/ijb-2024-0068/html", "details": "Y Chen, D Zeng, Y Wang - The International Journal of Biostatistics, 2024", "abstract": "Learning individualized treatment rules (ITRs) for a target patient population with mental disorders is confronted with many challenges. First, the target population may be different from the training population that provided data for learning ITRs. Ignoring \u2026"}, {"title": "Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Science", "link": "https://arxiv.org/pdf/2409.14673", "details": "T Wang, X Xu, Y Wang, Y Jiang - arXiv preprint arXiv:2409.14673, 2024", "abstract": "Real-world applications of large language models (LLMs) in computational social science (CSS) tasks primarily depend on the effectiveness of instruction tuning (IT) or in-context learning (ICL). While IT has shown highly effective at fine-tuning LLMs for \u2026"}, {"title": "Counterfactual Token Generation in Large Language Models", "link": "https://arxiv.org/pdf/2409.17027", "details": "I Chatzi, NC Benz, E Straitouri, S Tsirtsis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "\" Sure, I am happy to generate a story for you: Captain Lyra stood at the helm of her trusty ship, the Maelstrom's Fury, gazing out at the endless sea.[...] Lyra's eyes welled up with tears as she realized the bitter truth-she had sacrificed everything for fleeting \u2026"}, {"title": "Optimal Transport of Diverse Unsupervised Tasks for Robust Learning from Noisy Few-Shot Data", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05600.pdf", "details": "X Que, Q Yu", "abstract": "Noisy few-shot learning (NFSL) presents novel challenges primarily due to the interplay between noisy labels and limited training data. While data cleansing offers a viable solution to address noisy labels in the general learning settings, it \u2026"}, {"title": "HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2409.16191", "details": "H Que, F Duan, L He, Y Mou, W Zhou, J Liu, W Rong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks (eg, long-context understanding), and many benchmarks have been proposed. However, we observe that long text generation capabilities are \u2026"}, {"title": "Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications", "link": "https://arxiv.org/pdf/2409.16605", "details": "E Lin, Z Peng, Y Fang - arXiv preprint arXiv:2409.16605, 2024", "abstract": "Recent studies have evaluated the creativity/novelty of large language models (LLMs) primarily from a semantic perspective, using benchmarks from cognitive science. However, accessing the novelty in scholarly publications is a largely \u2026"}, {"title": "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction", "link": "https://arxiv.org/pdf/2409.16783", "details": "J Zhang, Y Zhou, Y Liu, Z Li, S Hu - arXiv preprint arXiv:2409.16783, 2024", "abstract": "Automated red teaming is an effective method for identifying misaligned behaviors in large language models (LLMs). Existing approaches, however, often focus primarily on improving attack success rates while overlooking the need for comprehensive test \u2026"}]
