[{"title": "NLP-AKG: Few-Shot Construction of NLP Academic Knowledge Graph Based on LLM", "link": "https://arxiv.org/pdf/2502.14192", "details": "J Lan, J Li, B Wang, M Liu, D Wu, S Wang, B Qin - arXiv preprint arXiv:2502.14192, 2025", "abstract": "Large language models (LLMs) have been widely applied in question answering over scientific research papers. To enhance the professionalism and accuracy of responses, many studies employ external knowledge augmentation. However \u2026"}, {"title": "LLM Alignment as Retriever Optimization: An Information Retrieval Perspective", "link": "https://arxiv.org/pdf/2502.03699", "details": "B Jin, J Yoon, Z Qin, Z Wang, W Xiong, Y Meng, J Han\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence with capabilities in reasoning, coding, and communication, driving innovation across industries. Their true potential depends on effective alignment to ensure correct \u2026"}, {"title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization", "link": "https://arxiv.org/pdf/2502.04306%3F", "details": "Y Wang, L Yang, G Li, M Wang, B Aragam - arXiv preprint arXiv:2502.04306, 2025", "abstract": "Recent research has leveraged large language model multi-agent systems for complex problem-solving while trying to reduce the manual effort required to build them, driving the development of automated agent workflow optimization methods \u2026"}, {"title": "On the Query Complexity of Verifier-Assisted Language Generation", "link": "https://arxiv.org/pdf/2502.12123", "details": "E Botta, Y Li, A Mehta, JT Ash, C Zhang, A Risteski - arXiv preprint arXiv:2502.12123, 2025", "abstract": "Recently, a plethora of works have proposed inference-time algorithms (eg best-of- n), which incorporate verifiers to assist the generation process. Their quality- efficiency trade-offs have been empirically benchmarked on a variety of constrained \u2026"}, {"title": "Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder", "link": "https://arxiv.org/pdf/2502.14050", "details": "X Yang, S Nie, L Liu, S Gururangan, U Karn, R Hou\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Current pre-trained large language models typically need instruction tuning to align with human preferences. However, instruction tuning data is often quantity-saturated due to the large volume of data collection and fast model iteration, leaving coreset \u2026"}, {"title": "EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration", "link": "https://arxiv.org/pdf/2502.14735", "details": "M Hong, Y Xia, Z Wang, J Zhu, Y Wang, S Cai, X Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) are increasingly leveraged as foundational backbones in the development of advanced recommender systems, offering enhanced capabilities through their extensive knowledge and reasoning. Existing llm \u2026"}, {"title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2501.18099%3F", "details": "S Saha, X Li, M Ghazvininejad, J Weston, T Wang - arXiv preprint arXiv:2501.18099, 2025", "abstract": "LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to capture the step-bystep reasoning process that underlies the final evaluation of a response. However, due to the lack of human annotated CoTs for evaluation, the \u2026"}, {"title": "ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization", "link": "https://arxiv.org/pdf/2502.05605", "details": "Y Zeng, X Cui, X Jin, G Liu, Z Sun, Q He, D Li, N Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we \u2026"}, {"title": "CryptoX: Compositional Reasoning Evaluation of Large Language Models", "link": "https://arxiv.org/pdf/2502.07813", "details": "J Shi, C Wei, L Yang, ZM Wang, C Yang, G Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The compositional reasoning capacity has long been regarded as critical to the generalization and intelligence emergence of large language models LLMs. However, despite numerous reasoning-related benchmarks, the compositional \u2026"}]
