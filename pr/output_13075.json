[{"title": "How Linguistics Learned to Stop Worrying and Love the Language Models", "link": "https://arxiv.org/pdf/2501.17047%3F", "details": "R Futrell, K Mahowald - arXiv preprint arXiv:2501.17047, 2025", "abstract": "Language models can produce fluent, grammatical text. Nonetheless, some maintain that language models don't really learn language and also that, even if they did, that would not be informative for the study of human learning and processing. On the \u2026"}, {"title": "How Green are Neural Language Models? Analyzing Energy Consumption in Text Summarization Fine-tuning", "link": "https://arxiv.org/pdf/2501.15398", "details": "T Rehman, DK Sanyal, S Chattopadhyay - arXiv preprint arXiv:2501.15398, 2025", "abstract": "Artificial intelligence systems significantly impact the environment, particularly in natural language processing (NLP) tasks. These tasks often require extensive computational resources to train deep neural networks, including large-scale \u2026"}, {"title": "Explainable and Efficient Editing for Large Language Models", "link": "https://openreview.net/pdf%3Fid%3DiAn7rlIfgc", "details": "T Zhang, J Fang, H Jiang, B Bi, X Wang, X He - THE WEB CONFERENCE 2025", "abstract": "Large Language Models (LLMs) possess remarkable capabilities in storing and retrieving vast factual knowledge but often retain outdated or incorrect information from web corpora. While full retraining is costly, locate-and-edit model editing \u2026"}, {"title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation", "link": "https://arxiv.org/pdf/2502.09838", "details": "T Lin, W Zhang, S Li, Y Yuan, B Yu, H Li, W He, H Jiang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present HealthGPT, a powerful Medical Large Vision-Language Model (Med- LVLM) that integrates medical visual comprehension and generation capabilities within a unified autoregressive paradigm. Our bootstrapping philosophy is to \u2026"}, {"title": "Decision Information Meets Large Language Models: The Future of Explainable Operations Research", "link": "https://arxiv.org/pdf/2502.09994", "details": "Y Zhang, Q Kang, WY Yu, H Gong, X Fu, X Han\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Operations Research (OR) is vital for decision-making in many industries. While recent OR methods have seen significant improvements in automation and efficiency through integrating Large Language Models (LLMs), they still struggle to produce \u2026"}, {"title": "A Survey on Human-Centered Evaluation of Explainable AI Methods in Clinical Decision Support Systems", "link": "https://arxiv.org/pdf/2502.09849", "details": "A Gambetti, Q Han, H Shen, C Soares - arXiv preprint arXiv:2502.09849, 2025", "abstract": "Explainable AI (XAI) has become a crucial component of Clinical Decision Support Systems (CDSS) to enhance transparency, trust, and clinical adoption. However, while many XAI methods have been proposed, their effectiveness in real-world \u2026"}, {"title": "The Data Artifacts Glossary: a community-based repository for bias on health datasets", "link": "https://link.springer.com/article/10.1186/s12929-024-01106-6", "details": "RR Gameiro, NL Woite, CM Sauer, S Hao\u2026 - Journal of Biomedical \u2026, 2025", "abstract": "Abstract Background The deployment of Artificial Intelligence (AI) in healthcare has the potential to transform patient care through improved diagnostics, personalized treatment plans, and more efficient resource management. However, the \u2026"}, {"title": "Elastic Representation: Mitigating Spurious Correlations for Group Robustness", "link": "https://arxiv.org/pdf/2502.09850", "details": "T Wen, Z Wang, Q Zhang, Q Lei - arXiv preprint arXiv:2502.09850, 2025", "abstract": "Deep learning models can suffer from severe performance degradation when relying on spurious correlations between input features and labels, making the models perform well on training data but have poor prediction accuracy for minority groups \u2026"}, {"title": "On Teacher Hacking in Language Model Distillation", "link": "https://arxiv.org/pdf/2502.02671", "details": "D Tiapkin, D Calandriello, J Ferret, S Perrin, N Vieillard\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Post-training of language models (LMs) increasingly relies on the following two stages:(i) knowledge distillation, where the LM is trained to imitate a larger teacher LM, and (ii) reinforcement learning from human feedback (RLHF), where the LM is \u2026"}]
