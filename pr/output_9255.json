[{"title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality", "link": "https://arxiv.org/pdf/2411.11531", "details": "V Chekalina, A Razzigaev, E Goncharova, A Kuznetsov - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper we present an approach to reduce hallucinations in Large Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional modality. Our method involves transforming input text into a set of KG embeddings and using \u2026"}, {"title": "You Are What You Write: Author re-identification privacy attacks in the era of pre-trained language models", "link": "https://www.sciencedirect.com/science/article/pii/S0885230824001293", "details": "R Plant, V Giuffrida, D Gkatzia - Computer Speech & Language, 2024", "abstract": "The widespread use of pre-trained language models has revolutionised knowledge transfer in natural language processing tasks. However, there is a concern regarding potential breaches of user trust due to the risk of re-identification attacks, where \u2026"}, {"title": "Transformer-Based Contextualized Language Models Joint with Neural Networks for Natural Language Inference in Vietnamese", "link": "https://arxiv.org/pdf/2411.13407", "details": "DVT Nguyen, T Van Huynh, K Van Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Natural Language Inference (NLI) is a task within Natural Language Processing (NLP) that holds value for various AI applications. However, there have been limited studies on Natural Language Inference in Vietnamese that explore the concept of \u2026"}, {"title": "BetterBench: Assessing AI Benchmarks, Uncovering Issues, and Establishing Best Practices", "link": "https://arxiv.org/pdf/2411.12990", "details": "A Reuel, A Hardy, C Smith, M Lamparth, M Hardy\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "AI models are increasingly prevalent in high-stakes environments, necessitating thorough assessment of their capabilities and risks. Benchmarks are popular for measuring these attributes and for comparing model performance, tracking progress \u2026"}, {"title": "BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices", "link": "https://arxiv.org/pdf/2411.10640", "details": "X Lu, Y Chen, C Chen, H Tan, B Chen, Y Xie, R Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence and growing popularity of multimodal large language models (MLLMs) have significant potential to enhance various aspects of daily life, from improving communication to facilitating learning and problem-solving. Mobile \u2026"}, {"title": "Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations", "link": "https://arxiv.org/pdf/2411.07237", "details": "C Malaviya, JC Chang, D Roth, M Iyyer, M Yatskar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model users often issue queries that lack specification, where the context under which a query was issued--such as the user's identity, the query's intent, and the criteria for a response to be useful--is not explicit. For instance, a good response \u2026"}, {"title": "Group Robust Best-of-K Decoding of Language Models for Pluralistic Alignment", "link": "https://openreview.net/pdf%3Fid%3DJI6j4NUGHv", "details": "S Yoon, W Bankes, S Son, A Petrovic, SS Ramesh\u2026 - Pluralistic Alignment Workshop at \u2026", "abstract": "The desirable behaviour of a chat agent can be described with multiple criteria, such as harmlessness, helpfulness, and conciseness, each of which can be scored by a reward model. While each user, or a group of users, may perceive each criterion with \u2026"}, {"title": "Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning", "link": "https://aclanthology.org/2024.emnlp-main.1258.pdf", "details": "S Wu, S Yang, Z Chen, Q Su - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "This study addresses the challenges of assessing and enhancing social-pragmatic inference in large language models (LLMs). We first highlight the inadequacy of current accuracy-based multiple choice question answering (MCQA) formats in \u2026"}, {"title": "LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote Sensing Vision-Language Interpretation", "link": "https://arxiv.org/pdf/2411.09301", "details": "Z Li, D Muhtar, F Gu, X Zhang, P Xiao, G He, X Zhu - arXiv preprint arXiv:2411.09301, 2024", "abstract": "Automatically and rapidly understanding Earth's surface is fundamental to our grasp of the living environment and informed decision-making. This underscores the need for a unified system with comprehensive capabilities in analyzing Earth's surface to \u2026"}]
