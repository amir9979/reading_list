[{"title": "Rethinking Addressing in Language Models via Contexualized Equivariant Positional Encoding", "link": "https://arxiv.org/pdf/2501.00712", "details": "J Zhu, P Wang, R Cai, JD Lee, P Li, Z Wang - arXiv preprint arXiv:2501.00712, 2025", "abstract": "Transformers rely on both content-based and position-based addressing mechanisms to make predictions, but existing positional encoding techniques often diminish the effectiveness of position-based addressing. Many current methods \u2026"}, {"title": "Privacy-ensuring open-weights large language models are competitive with closed-weights GPT-4o in extracting chest radiography findings from free-text reports", "link": "https://pubs.rsna.org/doi/pdf/10.1148/radiol.240895", "details": "S Nowak, B Wulff, YC Layer, M Theis, A Isaak, B Salam\u2026 - Radiology, 2025", "abstract": "Background Large-scale secondary use of clinical databases requires automated tools for retrospective extraction of structured content from free-text radiology reports. Purpose To share data and insights on the application of privacy-preserving open \u2026"}, {"title": "Knowledge Enhanced Language Model for Biomedical Natural Language Processing: Introducing a New Language Model for BioNLP", "link": "https://ieeexplore.ieee.org/abstract/document/10836827/", "details": "U Naseem, Q Zhang, L Hu, S Hussain, S Wang - IEEE Systems, Man, and \u2026, 2025", "abstract": "Following the success of pre-trained language models (PLMs), the biomedical research community has presented various domain-specific PLMs trained on a large biomedical and clinical corpus for biomedical natural language processing (BioNLP) \u2026"}, {"title": "MetaRuleGPT: Recursive Numerical Reasoning of Language Models Trained with Simple Rules", "link": "https://arxiv.org/pdf/2412.13536", "details": "K Chen, L Wang, Q Zhang, R Xu - arXiv preprint arXiv:2412.13536, 2024", "abstract": "Recent studies have highlighted the limitations of large language models in mathematical reasoning, particularly their inability to capture the underlying logic. Inspired by meta-learning, we propose that models should acquire not only task \u2026"}, {"title": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment", "link": "https://arxiv.org/pdf/2501.07525", "details": "D Gu, Y Gao, Y Zhou, M Zhou, D Metaxas - arXiv preprint arXiv:2501.07525, 2025", "abstract": "Automated chest radiographs interpretation requires both accurate disease classification and detailed radiology report generation, presenting a significant challenge in the clinical workflow. Current approaches either focus on classification \u2026"}, {"title": "Dynamically Scaled Temperature in Self-Supervised Contrastive Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10820841/", "details": "S Manna, S Chattopadhyay, R Dey, U Pal\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples of different classes is primarily affected by the presence of \u2026"}, {"title": "LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models", "link": "https://arxiv.org/pdf/2501.05464", "details": "H Yang, H Chen, H Guo, Y Chen, CS Lin, S Hu, J Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Accurate and efficient question-answering systems are essential for delivering high- quality patient care in the medical field. While Large Language Models (LLMs) have made remarkable strides across various domains, they continue to face significant \u2026"}]
