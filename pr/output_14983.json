[{"title": "Safety Modulation: Enhancing Safety in Reinforcement Learning through Cost-Modulated Rewards", "link": "https://arxiv.org/pdf/2504.03040", "details": "H Zhang, Y Guo - arXiv preprint arXiv:2504.03040, 2025", "abstract": "Safe Reinforcement Learning (Safe RL) aims to train an RL agent to maximize its performance in real-world environments while adhering to safety constraints, as exceeding safety violation limits can result in severe consequences. In this paper, we \u2026"}, {"title": "Sparseformer: a Transferable Transformer with Multi-granularity Token Sparsification for Medical Time Series Classification", "link": "https://arxiv.org/pdf/2503.15578%3F", "details": "J Ye, W Zhang, Z Li, J Li, F Tsung - arXiv preprint arXiv:2503.15578, 2025", "abstract": "Medical time series (MedTS) classification is crucial for improved diagnosis in healthcare, and yet it is challenging due to the varying granularity of patterns, intricate inter-channel correlation, information redundancy, and label scarcity. While \u2026"}, {"title": "MSNet: Multi-task self-supervised network for time series classification", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525000923", "details": "D Huang, X Lv, Y Zhang - Pattern Recognition Letters, 2025", "abstract": "Learning rich representations from unlabeled temporal data is essential for effective time series classification. Most existing self-supervised learning methods for time series focus on a single task, often relying on contrastive learning or reconstruction \u2026"}, {"title": "MAD-DGTD: Multivariate time series Anomaly Detection based on Dynamic Graph structure learning with Time Delay", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225005594", "details": "K Wang, J Kong, M Zhang, M Jiang, T Liu - Neurocomputing, 2025", "abstract": "Anomaly detection of multivariate time series data is extremely important in the industrial operation maintenance of Internet of Things (IoT). Researchers have found that the relationship between multiple sensors can be modeled as graph structure \u2026"}, {"title": "Language Model Uncertainty Quantification with Attention Chain", "link": "https://arxiv.org/pdf/2503.19168", "details": "Y Li, R Qiang, L Moukheiber, C Zhang - arXiv preprint arXiv:2503.19168, 2025", "abstract": "Accurately quantifying a large language model's (LLM) predictive uncertainty is crucial for judging the reliability of its answers. While most existing research focuses on short, directly answerable questions with closed-form outputs (eg, multiple \u2026"}, {"title": "Know What You do Not Know: Verbalized Uncertainty Estimation Robustness on Corrupted Images in Vision-Language Models", "link": "https://arxiv.org/pdf/2504.03440", "details": "M Borszukovszki, IP de Jong, M Valdenegro-Toro - arXiv preprint arXiv:2504.03440, 2025", "abstract": "To leverage the full potential of Large Language Models (LLMs) it is crucial to have some information on their answers' uncertainty. This means that the model has to be able to quantify how certain it is in the correctness of a given response. Bad \u2026"}, {"title": "Robust Classification in Bayesian Neural Networks", "link": "https://www.researchgate.net/profile/Vu-Linh-Nguyen/publication/390347093_Robust_Classification_in_Bayesian_Neural_Networks/links/67ee522795231d5ba5ae552a/Robust-Classification-in-Bayesian-Neural-Networks.pdf", "details": "KD Tran, XT Hoang, VL Nguyen, S Destercke\u2026 - International Symposium on \u2026, 2025", "abstract": "Bayesian neural networks (BNNs) are competitive multi-class classifiers with reasonably sound probabilistic characteristics. In this paper, we consider BNNs as classifier ensembles obtained through sampling, and define the inference problem in \u2026"}, {"title": "TSRM: ALightweight TEMPORAL FEATURE ENCODING ARCHITECTURE FOR TIME SERIES FORECASTING AND IMPUTATION", "link": "https://www.researchgate.net/profile/Robert-Leppich-2/publication/389759430_TSRM_A_Lightweight_Temporal_Feature_Encoding_Architecture_for_Time_Series_Forecasting_and_Imputation/links/67d1452d32265243f58520ab/TSRM-A-Lightweight-Temporal-Feature-Encoding-Architecture-for-Time-Series-Forecasting-and-Imputation.pdf", "details": "R Leppich, M Stenger, D Grillmeyer, V Borst, S Kounev", "abstract": "We introduce a temporal feature encoding architecture called Time Series Representation Model (TSRM) for multivariate time series forecasting and imputation. The architecture is structured around CNN-based representation layers \u2026"}, {"title": "SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation", "link": "https://arxiv.org/pdf/2503.09641", "details": "J Chen, S Xue, Y Zhao, J Yu, S Paul, J Chen, H Cai\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper presents SANA-Sprint, an efficient diffusion model for ultra-fast text-to- image (T2I) generation. SANA-Sprint is built on a pre-trained foundation model and augmented with hybrid distillation, dramatically reducing inference steps from 20 to 1 \u2026"}]
