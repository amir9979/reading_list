[{"title": "X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions", "link": "https://arxiv.org/pdf/2405.19744", "details": "C Li, W Yang, J Zhang, J Lu, S Wang, C Zong - arXiv preprint arXiv:2405.19744, 2024", "abstract": "Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples \u2026"}, {"title": "RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical Diagnostic Reports", "link": "https://arxiv.org/pdf/2405.14137", "details": "J Du, J Guo, W Zhang, S Yang, H Liu, H Li, N Wang - arXiv preprint arXiv:2405.14137, 2024", "abstract": "The Vision-Language Foundation model is increasingly investigated in the fields of computer vision and natural language processing, yet its exploration in ophthalmology and broader medical applications remains limited. The challenge is \u2026"}, {"title": "Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training", "link": "https://arxiv.org/pdf/2405.19654", "details": "J Yang, B Su, WX Zhao, JR Wen - arXiv preprint arXiv:2405.19654, 2024", "abstract": "Medical vision-language pre-training methods mainly leverage the correspondence between paired medical images and radiological reports. Although multi-view spatial images and temporal sequences of image-report pairs are available in off-the-shelf \u2026"}, {"title": "Probabilistically Plausible Counterfactual Explanations with Normalizing Flows", "link": "https://arxiv.org/pdf/2405.17640", "details": "P Wielopolski, O Furman, J Stefanowski, M Zi\u0119ba - arXiv preprint arXiv:2405.17640, 2024", "abstract": "We present PPCEF, a novel method for generating probabilistically plausible counterfactual explanations (CFs). PPCEF advances beyond existing methods by combining a probabilistic formulation that leverages the data distribution with the \u2026"}]
