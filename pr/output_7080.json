[{"title": "OLMoE: Open Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2409.02060", "details": "N Muennighoff, L Soldaini, D Groeneveld, K Lo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce OLMoE, a fully open, state-of-the-art language model leveraging sparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but uses only 1B per input token. We pretrain it on 5 trillion tokens and further adapt it to \u2026"}, {"title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries", "link": "https://arxiv.org/pdf/2409.00844", "details": "B Yang, F Cui, K Paster, J Ba, P Vaezipoor, S Pitis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid development and dynamic nature of large language models (LLMs) make it difficult for conventional quantitative benchmarks to accurately assess their capabilities. We propose report cards, which are human-interpretable, natural \u2026"}, {"title": "Calibration and correctness of language models for code", "link": "https://software-lab.org/publications/icse2025_calibration.pdf", "details": "C Spiess, D Gros, KS Pai, M Pradel, MRI Rabin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Machine learning models are widely used, but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or \u2026"}, {"title": "Improving Extraction of Clinical Event Contextual Properties from Electronic Health Records: A Comparative Study", "link": "https://arxiv.org/pdf/2408.17181", "details": "S Agarwal, T Searle, M Ratas, A Shek, J Teo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Electronic Health Records are large repositories of valuable clinical data, with a significant portion stored in unstructured text format. This textual data includes clinical events (eg, disorders, symptoms, findings, medications and procedures) in \u2026"}, {"title": "Segmenting Brazilian legislative text using weak supervision and active learning", "link": "https://link.springer.com/article/10.1007/s10506-024-09419-5", "details": "FA Siqueira, D Pressato, FSF Pereira, NFF da Silva\u2026 - Artificial Intelligence and \u2026, 2024", "abstract": "Legislative houses all over the world are adopting tools based on artificial intelligence to support their work. The incorporation of these tools can improve the analysis of the text of the proposed new laws and speed the preparation and \u2026"}, {"title": "Generalization vs. Specialization under Concept Shift", "link": "https://arxiv.org/pdf/2409.15582", "details": "A Nguyen, DJ Schwab, V Ngampruetikorn - arXiv preprint arXiv:2409.15582, 2024", "abstract": "Machine learning models are often brittle under distribution shift, ie, when data distributions at test time differ from those during training. Understanding this failure mode is central to identifying and mitigating safety risks of mass adoption of machine \u2026"}, {"title": "Extracting lung cancer staging descriptors from pathology reports: A generative language model approach", "link": "https://www.sciencedirect.com/science/article/pii/S1532046424001382", "details": "H Cho, S Yoo, B Kim, S Jang, L Sunwoo, S Kim, D Lee\u2026 - Journal of Biomedical \u2026, 2024", "abstract": "Background In oncology, electronic health records contain textual key information for the diagnosis, staging, and treatment planning of patients with cancer. However, text data processing requires a lot of time and effort, which limits the utilization of these \u2026"}, {"title": "Supplementary Materials of Grounding Language Models for Visual Entity Recognition", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01783-supp.pdf", "details": "Z Xiao, M Gong, P Cascante-Bonilla, X Zhang, J Wu\u2026", "abstract": "We present the hyperparameter choice in Table 1. As the effectiveness of contrastive learning only reveals in a large batch size setting, we conduct all pieces of training in a batch size of 256 on 32 V100-SXM2-32GB GPUs. Utilizing DeepSpeed [2] for \u2026"}, {"title": "How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model?", "link": "https://arxiv.org/pdf/2409.02253", "details": "SA Taghanaki, J Lambourne, A Mongkhounsavath - arXiv preprint arXiv:2409.02253, 2024", "abstract": "Large foundation models have revolutionized the field, yet challenges remain in optimizing multi-modal models for specialized visual tasks. We propose a novel, generalizable methodology to identify preferred image distributions for black-box \u2026"}]
