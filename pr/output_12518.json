[{"title": "Test-time Loss Landscape Adaptation for Zero-Shot Generalization in Vision-Language Models", "link": "https://arxiv.org/pdf/2501.18864", "details": "A Li, L Zhuang, X Long, M Yao, S Wang - arXiv preprint arXiv:2501.18864, 2025", "abstract": "Test-time adaptation of pre-trained vision-language models has emerged as a technique for tackling distribution shifts during the test time. Although existing methods, especially those based on Test-time Prompt Tuning (TPT), have shown \u2026"}, {"title": "Parallel Heterogeneous Graph Learning based Internet of Things Multivariate Time Series Anomaly Detection and Explanation via Cross-channel Feature Fusion", "link": "https://assets-eu.researchsquare.com/files/rs-5868019/v1/3d496c9d7c627657d72659cd.pdf", "details": "Q Xi, X Li, P Chen, J Chen, X Niu, L Xu", "abstract": "The volume of data from Internet of Things (IoT) systems has increased dramatically, so anomaly detection for multivariate time series (MTS) data collected by IoT systems is becoming particularly important. However, due to the lack of anomaly labels and \u2026"}, {"title": "Mitigating the Modality Gap: Few-Shot Out-of-Distribution Detection with Multi-modal Prototypes and Image Bias Estimation", "link": "https://arxiv.org/pdf/2502.00662", "details": "Y Wang, E Riddell, A Chow, S Sedwards, K Czarnecki - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing vision-language model (VLM)-based methods for out-of-distribution (OOD) detection typically rely on similarity scores between input images and in-distribution (ID) text prototypes. However, the modality gap between image and text often results \u2026"}]
