[{"title": "Calibration and correctness of language models for code", "link": "https://software-lab.org/publications/icse2025_calibration.pdf", "details": "C Spiess, D Gros, KS Pai, M Pradel, MRI Rabin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Machine learning models are widely used, but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or \u2026"}, {"title": "On Robustness-Accuracy Characterization of Language Models using Synthetic Datasets", "link": "https://openreview.net/pdf%3Fid%3DC0j44uRPcl", "details": "CY Ko, PY Chen, P Das, YS Chuang, L Daniel - First Conference on Language Modeling", "abstract": "In recent years, language models (LMs) that were pretrained at scale on diverse data have proven to be a successful approach for solving different downstream tasks. However, new concerns about proper performance evaluation have been raised \u2026"}, {"title": "BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems", "link": "https://arxiv.org/pdf/2408.15971", "details": "W Wang, D Zhang, T Feng, B Wang, J Tang - arXiv preprint arXiv:2408.15971, 2024", "abstract": "Large Language Models (LLMs) are becoming increasingly powerful and capable of handling complex tasks, eg, building single agents and multi-agent systems. Compared to single agents, multi-agent systems have higher requirements for the \u2026"}, {"title": "A Merge Sort Based Ranking System for the Evaluation of Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-70378-2_15", "details": "C Li, L Shi, C Zhou, Z Huan, C Tang, X Zhang, X Wang\u2026 - Joint European Conference \u2026, 2024", "abstract": "Efficient and accurate evaluation of Large Language Models (LLMs) is essential for progress in the field of natural language processing. To address this, our paper introduces Transitive Merge Sort (TMS), a novel method that harnesses the \u2026"}, {"title": "Selecting from Multiple Strategies Improves the Foreseeable Reasoning of Tool-Augmented Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-70352-2_12", "details": "Y Wu, A Henriksson - Joint European Conference on Machine Learning and \u2026, 2024", "abstract": "Large language models (LLMs) can be augmented by interacting with external tools and knowledge bases, allowing them to overcome some of their known limitations, such as not having access to up-to-date information or struggling to solve math \u2026"}, {"title": "BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models", "link": "https://arxiv.org/pdf/2408.12798", "details": "Y Li, H Huang, Y Zhao, X Ma, J Sun - arXiv preprint arXiv:2408.12798, 2024", "abstract": "Generative Large Language Models (LLMs) have made significant strides across various tasks, but they remain vulnerable to backdoor attacks, where specific triggers in the prompt cause the LLM to generate adversary-desired responses. While most \u2026"}, {"title": "Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models", "link": "https://arxiv.org/pdf/2408.14866", "details": "H Liu, Y Xie, Y Wang, M Shieh - arXiv preprint arXiv:2408.14866, 2024", "abstract": "Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy \u2026"}, {"title": "A Law of Next-Token Prediction in Large Language Models", "link": "https://arxiv.org/pdf/2408.13442", "details": "H He, WJ Su - arXiv preprint arXiv:2408.13442, 2024", "abstract": "Large language models (LLMs) have been widely employed across various application domains, yet their black-box nature poses significant challenges to understanding how these models process input data internally to make predictions \u2026"}, {"title": "Measuring and Controlling Instruction (In) Stability in Language Model Dialogs", "link": "https://openreview.net/pdf%3Fid%3D60a1SAtH4e", "details": "K Li, T Liu, N Bashkansky, D Bau, F Vi\u00e9gas, H Pfister\u2026 - First Conference on \u2026, 2024", "abstract": "System-prompting is a standard tool for customizing language-model chatbots, enabling them to follow a specific instruction. An implicit assumption in the use of system prompts is that they will be _stable_, so the chatbot will continue to generate \u2026"}]
