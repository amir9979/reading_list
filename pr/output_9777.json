[{"title": "VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information", "link": "https://arxiv.org/pdf/2412.00947", "details": "R Kamoi, Y Zhang, SSS Das, RH Zhang, R Zhang - arXiv preprint arXiv:2412.00947, 2024", "abstract": "Errors in understanding visual information in images (ie, visual perception errors) remain a major source of mistakes in Large Vision Language Models (LVLMs). While further analysis is essential, there is a deficiency in datasets for evaluating the visual \u2026"}, {"title": "Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic Vision-language Context Sparsification", "link": "https://arxiv.org/pdf/2412.00876", "details": "W Huang, Z Zhai, Y Shen, S Cao, F Zhao, X Xu, Z Ye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in vision understanding, reasoning, and interaction. However, the inference computation and memory increase progressively with the generation of output tokens \u2026"}, {"title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization", "link": "https://arxiv.org/pdf/2411.10442", "details": "W Wang, Z Chen, W Wang, Y Cao, Y Liu, Z Gao, J Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing open-source multimodal large language models (MLLMs) generally follow a training process involving pre-training and supervised fine-tuning. However, these models suffer from distribution shifts, which limit their multimodal reasoning \u2026"}, {"title": "Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2411.14432", "details": "Y Dong, Z Liu, HL Sun, J Yang, W Hu, Y Rao, Z Liu - arXiv preprint arXiv:2411.14432, 2024", "abstract": "Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1. Despite various efforts to improve LLM reasoning, high \u2026"}, {"title": "Accelerating Multimodel Large Language Models by Searching Optimal Vision Token Reduction", "link": "https://arxiv.org/pdf/2412.00556", "details": "S Zhao, Z Wang, F Juefei-Xu, X Xia, M Liu, X Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Prevailing Multimodal Large Language Models (MLLMs) encode the input image (s) as vision tokens and feed them into the language backbone, similar to how Large Language Models (LLMs) process the text tokens. However, the number of vision \u2026"}, {"title": "Evaluating and Advancing Multimodal Large Language Models in Ability Lens", "link": "https://arxiv.org/pdf/2411.14725", "details": "F Chen, C Gou, J Liu, Y Yang, Z Li, J Zhang, Z Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As multimodal large language models (MLLMs) advance rapidly, rigorous evaluation has become essential, providing further guidance for their development. In this work, we focus on a unified and robust evaluation of\\textbf {vision perception} abilities, the \u2026"}, {"title": "Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective", "link": "https://arxiv.org/pdf/2412.00554", "details": "Y Zhou, B Di Eugenio, L Cheng - arXiv preprint arXiv:2412.00554, 2024", "abstract": "This paper studies the performance of large language models (LLMs), particularly regarding demographic fairness, in solving real-world healthcare tasks. We evaluate state-of-the-art LLMs with three prevalent learning frameworks across six diverse \u2026"}, {"title": "MC-NEST--Enhancing Mathematical Reasoning in Large Language Models with a Monte Carlo Nash Equilibrium Self-Refine Tree", "link": "https://arxiv.org/pdf/2411.15645", "details": "G Rabby, F Keya, P Zamil, S Auer - arXiv preprint arXiv:2411.15645, 2024", "abstract": "Mathematical reasoning has proven to be a critical yet challenging task for large language models (LLMs), as they often struggle with complex multi-step problems. To address these limitations, we introduce the Monte Carlo Nash Equilibrium Self \u2026"}, {"title": "Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training", "link": "https://arxiv.org/pdf/2411.14318%3F", "details": "Z Luo, X Zhang, X Liu, H Li, Y Gong, C Qi, P Cheng - arXiv preprint arXiv:2411.14318, 2024", "abstract": "It is well-known that a diverse corpus is critical for training large language models, which are typically constructed from a mixture of various domains. In general, previous efforts resort to sampling training data from different domains with static \u2026"}]
