[{"title": "VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images", "link": "https://arxiv.org/pdf/2408.16176", "details": "M Maruf, A Daw, KS Mehrab, HB Manogaran, A Neog\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Images are increasingly becoming the currency for documenting biodiversity on the planet, providing novel opportunities for accelerating scientific discoveries in the field of organismal biology, especially with the advent of large vision-language models \u2026"}, {"title": "IQAGPT: computed tomography image quality assessment with vision-language and ChatGPT models", "link": "https://link.springer.com/article/10.1186/s42492-024-00171-w", "details": "Z Chen, B Hu, C Niu, T Chen, Y Li, H Shan, G Wang - Visual Computing for Industry \u2026, 2024", "abstract": "Large language models (LLMs), such as ChatGPT, have demonstrated impressive capabilities in various tasks and attracted increasing interest as a natural language interface across many domains. Recently, large vision-language models (VLMs) that \u2026"}, {"title": "Bridging Items and Language: A Transition Paradigm for Large Language Model-Based Recommendation", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671884", "details": "X Lin, W Wang, Y Li, F Feng, SK Ng, TS Chua - Proceedings of the 30th ACM SIGKDD \u2026, 2024", "abstract": "Harnessing Large Language Models (LLMs) for recommendation is rapidly emerging, which relies on two fundamental steps to bridge the recommendation item space and the language space: 1) item indexing utilizes identifiers to represent items \u2026"}]
