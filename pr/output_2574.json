[{"title": "Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models", "link": "https://arxiv.org/pdf/2405.09605", "details": "AA Ivanova, A Sathe, B Lipkin, U Kumar, S Radkani\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The ability to build and leverage world models is essential for a general-purpose AI agent. Testing such capabilities is hard, in part because the building blocks of world models are ill-defined. We present Elements of World Knowledge (EWOK), a \u2026"}, {"title": "An in-depth evaluation of federated learning on biomedical natural language processing for information extraction", "link": "https://www.nature.com/articles/s41746-024-01126-4", "details": "L Peng, G Luo, S Zhou, J Chen, Z Xu, J Sun, R Zhang - NPJ Digital Medicine, 2024", "abstract": "Abstract Language models (LMs) such as BERT and GPT have revolutionized natural language processing (NLP). However, the medical field faces challenges in training LMs due to limited data access and privacy constraints imposed by \u2026"}, {"title": "NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition", "link": "https://arxiv.org/pdf/2405.07609", "details": "E Merdjanovska, A Aynetdinov, A Akbik - arXiv preprint arXiv:2405.07609, 2024", "abstract": "Available training data for named entity recognition (NER) often contains a significant percentage of incorrect labels for entity types and entity boundaries. Such label noise poses challenges for supervised learning and may significantly deteriorate model \u2026"}, {"title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models", "link": "https://openreview.net/pdf%3Fid%3D1tRLxQzdep", "details": "P Dong, L Li, Z Tang, X Liu, X Pan, Q Wang, X Chu - Forty-first International \u2026, 2024", "abstract": "Despite the remarkable capabilities, Large Language Models (LLMs) face deployment challenges due to their extensive size. Pruning methods drop a subset of weights to accelerate, but many of them require retraining, which is prohibitively \u2026"}, {"title": "Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective", "link": "https://arxiv.org/pdf/2405.16747", "details": "A Tomihari, I Sato - arXiv preprint arXiv:2405.16747, 2024", "abstract": "The two-stage fine-tuning (FT) method, linear probing then fine-tuning (LP-FT), consistently outperforms linear probing (LP) and FT alone in terms of accuracy for both in-distribution (ID) and out-of-distribution (OOD) data. This success is largely \u2026"}, {"title": "Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses", "link": "https://arxiv.org/pdf/2406.01288", "details": "X Zheng, T Pang, C Du, Q Liu, J Jiang, M Lin - arXiv preprint arXiv:2406.01288, 2024", "abstract": "Recently, Anil et al.(2024) show that many-shot (up to hundreds of) demonstrations can jailbreak state-of-the-art LLMs by exploiting their long-context capability. Nevertheless, is it possible to use few-shot demonstrations to efficiently jailbreak \u2026"}, {"title": "Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "link": "https://arxiv.org/pdf/2405.10431", "details": "S Furniturewala, S Jandial, A Java, P Banerjee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing debiasing techniques are typically training-based or require access to the model's internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine \u2026"}, {"title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2405.07551", "details": "S Yin, W You, Z Ji, G Zhong, J Bai - arXiv preprint arXiv:2405.07551, 2024", "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math \u2026"}, {"title": "Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots", "link": "https://arxiv.org/pdf/2405.07990", "details": "C Wu, Y Ge, Q Guo, J Wang, Z Liang, Z Lu, Y Shan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The remarkable progress of Multi-modal Large Language Models (MLLMs) has attracted significant attention due to their superior performance in visual contexts. However, their capabilities in turning visual figure to executable code, have not been \u2026"}]
