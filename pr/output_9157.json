[{"title": "Bi-Branching Feature Interaction Representation Learning for Multivariate Time Series", "link": "https://www.sciencedirect.com/science/article/pii/S1568494624011578", "details": "W Wang, E Zuo, R Wang, J Zhong, C Chen, C Chen\u2026 - Applied Soft Computing, 2024", "abstract": "Representational learning of time series plays a crucial role in various fields. However, existing time-series models do not perform well in representation learning. These models usually focus only on the relationship between variables at the same \u2026"}, {"title": "Enhancing Few-Shot Out-of-Distribution Detection with Pre-Trained Model Features", "link": "https://ieeexplore.ieee.org/abstract/document/10735106/", "details": "J Dong, Y Yao, W Jin, H Zhou, Y Gao, Z Fang - IEEE Transactions on Image \u2026, 2024", "abstract": "Ensuring the reliability of open-world intelligent systems heavily relies on effective out-of-distribution (OOD) detection. Despite notable successes in existing OOD detection methods, their performance in scenarios with limited training samples is \u2026"}, {"title": "Abstracted Shapes as Tokens--A Generalizable and Interpretable Model for Time-series Classification", "link": "https://arxiv.org/pdf/2411.01006", "details": "Y Wen, T Ma, TW Weng, LM Nguyen, AA Julius - arXiv preprint arXiv:2411.01006, 2024", "abstract": "In time-series analysis, many recent works seek to provide a unified view and representation for time-series across multiple domains, leading to the development of foundation models for time-series data. Despite diverse modeling techniques \u2026"}, {"title": "ELBOing Stein: Variational Bayes with Stein Mixture Inference", "link": "https://arxiv.org/pdf/2410.22948%3F", "details": "O R\u00f8nning, E Nalisnick, C Ley, P Smyth, T Hamelryck - arXiv preprint arXiv \u2026, 2024", "abstract": "Stein variational gradient descent (SVGD)[Liu and Wang, 2016] performs approximate Bayesian inference by representing the posterior with a set of particles. However, SVGD suffers from variance collapse, ie poor predictions due to \u2026"}, {"title": "Improving Out-of-Distribution Detection with Disentangled Foreground and Background Features", "link": "https://dl.acm.org/doi/pdf/10.1145/3664647.3681614", "details": "C Ding, G Pang - Proceedings of the 32nd ACM International \u2026, 2024", "abstract": "Detecting out-of-distribution (OOD) inputs is a principal task for ensuring the safety of deploying deep-neural-network classifiers in open-set scenarios. OOD samples can be drawn from arbitrary distributions and exhibit deviations from in-distribution (ID) \u2026"}, {"title": "FedGKD: personalized federated learning through grouping and distillation", "link": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13404/134040E/FedGKD-personalized-federated-learning-through-grouping-and-distillation/10.1117/12.3050605.short", "details": "T Li, S Lin, P Zhao, Z Li, J Wang - Fifth International Conference on Control, Robotics \u2026, 2024", "abstract": "As is well known, the objective of traditional Federated Learning (FL) is to train a global model collaboratively across multiple clients without directly accessing client data. However, traditional federated learning is frequently impeded by the \u2026"}]
