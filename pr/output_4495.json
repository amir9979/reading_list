[{"title": "Matching tasks to objectives: Fine-tuning and prompt-tuning strategies for encoder-decoder pre-trained language models", "link": "https://link.springer.com/article/10.1007/s10489-024-05660-2", "details": "A Pouramini, H Faili - Applied Intelligence, 2024", "abstract": "Prompt-based learning has emerged as a dominant paradigm in natural language processing. This study explores the impact of diverse pre-training objectives on the performance of encoder-decoder pre-trained language models across generation \u2026"}, {"title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application", "link": "https://arxiv.org/pdf/2407.01885", "details": "C Yang, W Lu, Y Zhu, Y Wang, Q Chen, C Gao, B Yan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in various domains, attracting significant interest from both academia and industry. Despite their impressive performance, the substantial size and computational demands of LLMs \u2026"}, {"title": "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale", "link": "https://arxiv.org/pdf/2407.02118", "details": "W Zheng, W Pan, X Xu, L Qin, L Yue, M Zhou - arXiv preprint arXiv:2407.02118, 2024", "abstract": "In recent years, Large Language Models (LLMs) have made significant strides towards Artificial General Intelligence. However, training these models from scratch requires substantial computational resources and vast amounts of text data. In this \u2026"}, {"title": "Reflective Instruction Tuning: Mitigating Hallucinations in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2407.11422", "details": "J Zhang, T Wang, H Zhang, P Lu, F Zheng - arXiv preprint arXiv:2407.11422, 2024", "abstract": "Large vision-language models (LVLMs) have shown promising performance on a variety of vision-language tasks. However, they remain susceptible to hallucinations, generating outputs misaligned with visual content or instructions. While various \u2026"}, {"title": "Evaluating language models as risk scores", "link": "https://arxiv.org/pdf/2407.14614", "details": "AF Cruz, M Hardt, C Mendler-D\u00fcnner - arXiv preprint arXiv:2407.14614, 2024", "abstract": "Current question-answering benchmarks predominantly focus on accuracy in realizable prediction tasks. Conditioned on a question and answer-key, does the most likely token match the ground truth? Such benchmarks necessarily fail to \u2026"}, {"title": "Compact Language Models via Pruning and Knowledge Distillation", "link": "https://arxiv.org/pdf/2407.14679", "details": "S Muralidharan, ST Sreenivas, R Joshi, M Chochowski\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) targeting different deployment scales and sizes are currently produced by training each variant from scratch; this is extremely compute- intensive. In this paper, we investigate if pruning an existing LLM and then re-training \u2026"}, {"title": "In-Context Learning Improves Compositional Understanding of Vision-Language Models", "link": "https://arxiv.org/pdf/2407.15487", "details": "M Nulli, A Ibrahimi, A Pal, H Lee, I Najdenkoska - arXiv preprint arXiv:2407.15487, 2024", "abstract": "Vision-Language Models (VLMs) have shown remarkable capabilities in a large number of downstream tasks. Nonetheless, compositional image understanding remains a rather difficult task due to the object bias present in training data. In this \u2026"}, {"title": "Deciphering the Factors Influencing the Efficacy of Chain-of-Thought: Probability, Memorization, and Noisy Reasoning", "link": "https://arxiv.org/pdf/2407.01687", "details": "A Prabhakar, TL Griffiths, RT McCoy - arXiv preprint arXiv:2407.01687, 2024", "abstract": "Chain-of-Thought (CoT) prompting has been shown to enhance the multi-step reasoning capabilities of Large Language Models (LLMs). However, debates persist about whether LLMs exhibit abstract generalization or rely on shallow heuristics \u2026"}, {"title": "Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment", "link": "https://arxiv.org/pdf/2407.03051", "details": "J Lee, S Park, S Hong, M Kim, DS Chang, J Choi - arXiv preprint arXiv:2407.03051, 2024", "abstract": "The rapid advancement of large language models (LLMs) has facilitated their transformation into conversational chatbots that can grasp contextual nuances and generate pertinent sentences, closely mirroring human values through advanced \u2026"}]
