[{"title": "Evaluating machine learning approaches for multi-label classification of unstructured electronic health records with a generative large language model", "link": "https://www.medrxiv.org/content/10.1101/2024.06.24.24309441.full.pdf", "details": "D Vithanage, C Deng, L Wang, M Yin, M Alkhalaf\u2026 - medRxiv, 2024", "abstract": "Multi-label classification of unstructured electronic health records (EHR) poses challenges due to the inherent semantic complexity in textual data. Advances in natural language processing (NLP) using large language models (LLMs) show \u2026"}, {"title": "Unsupervised Latent Stain Adaption for Digital Pathology", "link": "https://arxiv.org/pdf/2406.19081", "details": "D Reisenb\u00fcchler, L Luttner, NS Schaadt, F Feuerhake\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In digital pathology, deep learning (DL) models for tasks such as segmentation or tissue classification are known to suffer from domain shifts due to different staining techniques. Stain adaptation aims to reduce the generalization error between \u2026"}, {"title": "The Art of Saying No: Contextual Noncompliance in Language Models", "link": "https://arxiv.org/pdf/2407.12043", "details": "F Brahman, S Kumar, V Balachandran, P Dasigi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Chat-based language models are designed to be helpful, yet they should not comply with every user request. While most existing work primarily focuses on refusal of\" unsafe\" queries, we posit that the scope of noncompliance should be broadened. We \u2026"}, {"title": "Choriocapillaris Impairment, Visual Function, and Distance to Fovea in Aging and Age-Related Macular Degeneration: ALSTAR2 Baseline", "link": "https://iovs.arvojournals.org/article.aspx%3Farticleid%3D2800605", "details": "D Kar, M Amjad, G Corradetti, TA Swain, ME Clark\u2026 - \u2026 Ophthalmology & Visual \u2026, 2024", "abstract": "Purpose: In aging and early-intermediate age-related macular degeneration (AMD), rod-mediated dark adaptation (RMDA) slows more at 5 superior than at 12. Using optical coherence tomography angiography (OCTA), we asked whether \u2026"}, {"title": "A Refer-and-Ground Multimodal Large Language Model for Biomedicine", "link": "https://arxiv.org/pdf/2406.18146", "details": "X Huang, H Huang, L Shen, Y Yang, F Shang, J Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the rapid development of multimodal large language models (MLLMs), especially their capabilities in visual chat through refer and ground functionalities, their significance is increasingly recognized. However, the biomedical field currently \u2026"}]
