[{"title": "An open-source framework for end-to-end analysis of electronic health record data", "link": "https://www.nature.com/articles/s41591-024-03214-0", "details": "L Heumos, P Ehmele, T Treis, J Upmeier zu Belzen\u2026 - Nature Medicine, 2024", "abstract": "With progressive digitalization of healthcare systems worldwide, large-scale collection of electronic health records (EHRs) has become commonplace. However, an extensible framework for comprehensive exploratory analysis that accounts for \u2026"}, {"title": "Designing Retrieval-Augmented Language Models for Clinical Decision", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DWcMbEQAAQBAJ%26oi%3Dfnd%26pg%3DPA159%26ots%3DtCwYr-RIaq%26sig%3DDyP_VZpGS1d_dyyE_sUcwHx1JLk", "details": "K Quigley, T Koker, J Taylor, V Mancuso - AI for Health Equity and Fairness: Leveraging AI to \u2026", "abstract": "Ever-increasing demands for physician expertise drive the need for trust-worthy point- of-care tools that can help aid decision-making in all clinical settings. Retrieval- augmented language models carry potential to relieve the information burden on \u2026"}, {"title": "Accurate customer address matching via weak supervision for geocode learning", "link": "https://www.amazon.science/publications/accurate-customer-address-matching-via-weak-supervision-for-geocode-learning", "details": "A Paul, S Maheshwary, S Sohoney - 2024", "abstract": "Determining the precise location of customers is important for an efficient and reliable delivery experience, both for customers and delivery associates. Address text is a primary source of information provided by customers about their location. In \u2026"}, {"title": "Bilingual Evaluation of Language Models on General Knowledge in University Entrance Exams with Minimal Contamination", "link": "https://arxiv.org/pdf/2409.12746", "details": "ES Salido, R Morante, J Gonzalo, G Marco\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this article we present UNED-ACCESS 2024, a bilingual dataset that consists of 1003 multiple-choice questions of university entrance level exams in Spanish and English. Questions are originally formulated in Spanish and translated manually into \u2026"}, {"title": "NEST: Self-supervised Fast Conformer as All-purpose Seasoning to Speech Processing Tasks", "link": "https://arxiv.org/pdf/2408.13106", "details": "H Huang, T Park, K Dhawan, I Medennikov\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-supervised learning has been proved to benefit a wide range of speech processing tasks, such as speech recognition/translation, speaker verification and diarization, etc. However, most of these approaches are computationally intensive \u2026"}, {"title": "Enhanced Prompt Learning for Few-shot Text Classification Method", "link": "https://search.proquest.com/openview/58909c856764791ee70d5ec9bee01321/1%3Fpq-origsite%3Dgscholar%26cbl%3D2048897", "details": "L Ruifan, W Zhiyu, F Yuantao, Y Shuqin, Z Guangwei - Beijing Da Xue Xue Bao, 2024", "abstract": "An enhanced prompt learning method (EPL4FTC) for few-shot text classification task is proposed. This algorithm first converts the text classification task into the form of prompt learning based on natural language inference. Thus, the implicit data \u2026"}, {"title": "Focused Large Language Models are Stable Many-Shot Learners", "link": "https://arxiv.org/pdf/2408.13987", "details": "P Yuan, S Feng, Y Li, X Wang, Y Zhang, C Tan, B Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In-Context Learning (ICL) enables large language models (LLMs) to achieve rapid task adaptation by learning from demonstrations. With the increase in available context length of LLMs, recent experiments have shown that the performance of ICL \u2026"}, {"title": "Automated Mining of Structured Knowledge from Text in the Era of Large Language Models", "link": "https://dl.acm.org/doi/pdf/10.1145/3637528.3671469", "details": "Y Zhang, M Zhong, S Ouyang, Y Jiao, S Zhou, L Ding\u2026 - Proceedings of the 30th \u2026, 2024", "abstract": "Massive amount of unstructured text data are generated daily, ranging from news articles to scientific papers. How to mine structured knowledge from the text data remains a crucial research question. Recently, large language models (LLMs) have \u2026"}, {"title": "Towards Harnessing Large Language Models as Autonomous Agents for Semantic Triple Extraction from Unstructured Text", "link": "https://ceur-ws.org/Vol-3747/text2kg_paper1.pdf", "details": "A Ananya, S Tiwari, N Mihindukulasooriya, T Soru\u2026 - 2024", "abstract": "Abstract The use of Large Language Models as autonomous agents interacting with tools has shown to improve the performance of several tasks from code generation to API calling and sequencing. This paper proposes a framework for using Large \u2026"}]
