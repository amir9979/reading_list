[{"title": "AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization", "link": "https://arxiv.org/pdf/2407.11591", "details": "A Afzal, R Chalumattu, F Matthes, LM Espuny - arXiv preprint arXiv:2407.11591, 2024", "abstract": "Despite the advances in the abstractive summarization task using Large Language Models (LLM), there is a lack of research that asses their abilities to easily adapt to different domains. We evaluate the domain adaptation abilities of a wide range of \u2026"}, {"title": "Benchmarking Vision Language Models for Cultural Understanding", "link": "https://arxiv.org/pdf/2407.10920", "details": "S Nayak, K Jain, R Awal, S Reddy, S van Steenkiste\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Foundation models and vision-language pre-training have notably advanced Vision Language Models (VLMs), enabling multimodal processing of visual and linguistic data. However, their performance has been typically assessed on general scene \u2026"}, {"title": "Denoising, Deblurring, and optical Deconvolution for cryo-ET and light microscopy with a physics-informed deep neural network DeBCR", "link": "https://www.biorxiv.org/content/biorxiv/early/2024/07/16/2024.07.12.603278.full.pdf", "details": "R Li, A Yushkevich, X Chu, M Kudryashev\u2026 - bioRxiv, 2024", "abstract": "Computational image-quality enhancement for microscopy (deblurring, denoising, and optical deconvolution) provides researchers with detailed information on samples. Recent general-purpose deep learning solutions advanced in this task. Yet \u2026"}, {"title": "Quantized Prompt for Efficient Generalization of Vision-Language Models", "link": "https://arxiv.org/pdf/2407.10704", "details": "T Hao, X Ding, J Feng, Y Yang, H Chen, G Ding - arXiv preprint arXiv:2407.10704, 2024", "abstract": "In the past few years, large-scale pre-trained vision-language models like CLIP have achieved tremendous success in various fields. Naturally, how to transfer the rich knowledge in such huge pre-trained models to downstream tasks and datasets \u2026"}, {"title": "Discrete Diffusion Language Model for Long Text Summarization", "link": "https://arxiv.org/pdf/2407.10998", "details": "DH Dat, DD Anh, AT Luu, W Buntine - arXiv preprint arXiv:2407.10998, 2024", "abstract": "While diffusion models excel at conditional generating high-quality images, prior works in discrete diffusion models were not evaluated on conditional long-text generation. In this work, we address the limitations of prior discrete diffusion models \u2026"}, {"title": "STORYSUMM: Evaluating Faithfulness in Story Summarization", "link": "https://arxiv.org/pdf/2407.06501", "details": "M Subbiah, F Ladhak, A Mishra, G Adams, LB Chilton\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Human evaluation has been the gold standard for checking faithfulness in abstractive summarization. However, with a challenging source domain like narrative, multiple annotators can agree a summary is faithful, while missing details \u2026"}, {"title": "CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph", "link": "https://arxiv.org/pdf/2406.17231", "details": "T Zhou, Y Chen, K Liu, J Zhao - arXiv preprint arXiv:2406.17231, 2024", "abstract": "Large language models have become integral to question-answering applications despite their propensity for generating hallucinations and factually inaccurate content. Querying knowledge graphs to reduce hallucinations in LLM meets the \u2026"}]
