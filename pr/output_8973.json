[{"title": "Interpretable Representation Learning from Videos using Nonlinear Priors", "link": "https://arxiv.org/pdf/2410.18539", "details": "M Longa, JF Henriques - arXiv preprint arXiv:2410.18539, 2024", "abstract": "Learning interpretable representations of visual data is an important challenge, to make machines' decisions understandable to humans and to improve generalisation outside of the training distribution. To this end, we propose a deep learning \u2026"}, {"title": "Self-supervised contrastive learning performs non-linear system identification", "link": "https://arxiv.org/pdf/2410.14673%3F", "details": "RG Laiz, T Schmidt, S Schneider - arXiv preprint arXiv:2410.14673, 2024", "abstract": "Self-supervised learning (SSL) approaches have brought tremendous success across many tasks and domains. It has been argued that these successes can be attributed to a link between SSL and identifiable representation learning: Temporal \u2026"}, {"title": "Generative Example-Based Explanations: Bridging the Gap between Generative Modeling and Explainability", "link": "https://arxiv.org/pdf/2410.20890", "details": "P Vaeth, AM Fruehwald, B Paassen, M Gregorova - arXiv preprint arXiv:2410.20890, 2024", "abstract": "Recently, several methods have leveraged deep generative modeling to produce example-based explanations of decision algorithms for high-dimensional input data. Despite promising results, a disconnect exists between these methods and the \u2026"}, {"title": "Using Diffusion Models as Generative Replay in Continual Federated Learning--What will Happen?", "link": "https://arxiv.org/pdf/2411.06618", "details": "Y Mei, L Yuan, DJ Han, KS Chan, CG Brinton, T Lan - arXiv preprint arXiv:2411.06618, 2024", "abstract": "Federated learning (FL) has become a cornerstone in decentralized learning, where, in many scenarios, the incoming data distribution will change dynamically over time, introducing continuous learning (CL) problems. This continual federated learning \u2026"}, {"title": "Interactive Deep Clustering via Value Mining", "link": "https://openreview.net/pdf%3Fid%3DY7HPB7pL1f", "details": "H Liu, P Hu, C Zhang, Y Li, X Peng - The Thirty-eighth Annual Conference on Neural \u2026", "abstract": "In the absence of class priors, recent deep clustering methods resort to data augmentation and pseudo-labeling strategies to generate supervision signals. Though achieved remarkable success, existing works struggle to discriminate hard \u2026"}, {"title": "Trustworthy and Explainable Offline Reinforcement Learning by Inferring a Discrete-State Discrete-Action MDP from a Continous-State Continuous-Action Dataset", "link": "https://bnaic2024.sites.uu.nl/wp-content/uploads/sites/986/2024/10/Trustworthy-and-Explainable-Offline-Reinforcement-Learning-by-Inferring-a-Discrete-State-Discrete-Action-MDP-from-a-Continous-State-Continuous-Action-dataset.pdf", "details": "D Steckelmacher, A Now\u00e9", "abstract": "Offline Reinforcement Learning allows to learn a controller for a system from a history of states, actions and rewards, without requiring to interact with the system or a simulator of it. Current Offline RL approaches mainly build on Off-policy RL, such as \u2026"}, {"title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning", "link": "https://arxiv.org/pdf/2410.19560", "details": "S Mo, S Tong - arXiv preprint arXiv:2410.19560, 2024", "abstract": "In recent advancements in unsupervised visual representation learning, the Joint- Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabeled imagery through an innovative masking \u2026"}, {"title": "MultiSpectral diffusion: joint generation of wavelet coefficients for image synthesis and upsampling", "link": "https://link.springer.com/article/10.1007/s11042-024-20383-9", "details": "I Goudarzvand, AM Eftekhari Moghadam - Multimedia Tools and Applications, 2024", "abstract": "Diffusion models have become a prevalent framework in deep generative modeling across various modalities. However, despite producing high quality results, these models are computationally expensive and suffer from slow convergence. In this \u2026"}, {"title": "Bigr: Harnessing binary latent codes for image generation and improved visual representation capabilities", "link": "https://arxiv.org/pdf/2410.14672%3F", "details": "S Hao, X Liu, X Qi, S Zhao, B Zi, R Xiao, K Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce BiGR, a novel conditional image generation model using compact binary latent codes for generative training, focusing on enhancing both generation and representation capabilities. BiGR is the first conditional generative model that \u2026"}]
