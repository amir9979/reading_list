[{"title": "Context-Aware Vision Language Foundation Models for Ocular Disease Screening in Retinal Images", "link": "https://arxiv.org/pdf/2503.15212", "details": "L Berger, M Lamard, P Zhang, L Borderie, AL Guilcher\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Foundation models are large-scale versatile systems trained on vast quantities of diverse data to learn generalizable representations. Their adaptability with minimal fine-tuning makes them particularly promising for medical imaging, where data \u2026"}, {"title": "Proteomic Analysis of Aqueous Humor Identified Clinically Relevant Molecular Targets for Neovascular Complications in Diabetic Retinopathy", "link": "https://www.sciencedirect.com/science/article/pii/S1535947625000519", "details": "JW Oh, SJ Ahn, JH Jung, TW Kim, KP Kim - Molecular & Cellular Proteomics, 2025", "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness in adults under 40 in the developed world, with a significant proportion progressing to vision-threatening stages such as proliferative diabetic retinopathy (PDR) and neovascular glaucoma \u2026"}, {"title": "Open-source framework for detecting bias and overfitting for large pathology images", "link": "https://arxiv.org/pdf/2503.01827%3F", "details": "A Sildnes, N Shvetsov, M Tafavvoghi, VNN Tran\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Even foundational models that are trained on datasets with billions of data samples may develop shortcuts that lead to overfitting and bias. Shortcuts are non-relevant patterns in data, such as the background color or color intensity. So, to ensure the \u2026"}, {"title": "MedHEval: Benchmarking Hallucinations and Mitigation Strategies in Medical Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.02157", "details": "A Chang, L Huang, P Bhatia, T Kass-Hout, F Ma\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision Language Models (LVLMs) are becoming increasingly important in the medical domain, yet Medical LVLMs (Med-LVLMs) frequently generate hallucinations due to limited expertise and the complexity of medical applications \u2026"}, {"title": "UMIT: Unifying Medical Imaging Tasks via Vision-Language Models", "link": "https://arxiv.org/pdf/2503.15892", "details": "H Yu, S Yi, K Niu, M Zhuo, B Li - arXiv preprint arXiv:2503.15892, 2025", "abstract": "With the rapid advancement of deep learning, particularly in the field of medical image analysis, an increasing number of Vision-Language Models (VLMs) are being widely applied to solve complex health and biomedical challenges. However \u2026"}, {"title": "CoCa-CXR: Contrastive Captioners Learn Strong Temporal Structures for Chest X-Ray Vision-Language Understanding", "link": "https://arxiv.org/pdf/2502.20509", "details": "Y Chen, S Xu, A Sellergren, Y Matias, A Hassidim\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models have proven to be of great benefit for medical image analysis since they learn rich semantics from both images and reports. Prior efforts have focused on better alignment of image and text representations to enhance \u2026"}, {"title": "HistoMoCo: Momentum Contrastive Learning Pre-Training on Unlabeled Histopathological Images for Oral Squamous Cell Carcinoma Detection", "link": "https://www.mdpi.com/2079-9292/14/7/1252", "details": "W Liao, Y He, B Jiang, J Zhao, M Gao, X Zhang - Electronics, 2025", "abstract": "The early detection and intervention of oral squamous cell carcinoma (OSCC) using histopathological images are crucial for improving patient outcomes. The current literature for identifying OSCC predominantly relies on models pre-trained on \u2026"}, {"title": "Toward a Large Language Model-Driven Medical Knowledge Retrieval and QA System: Framework Design and Evaluation", "link": "https://www.sciencedirect.com/science/article/pii/S2095809925001080", "details": "Y Liu, X Li, Y Luo, J Du, Y Zhang, T Lv, H Yin, X Tang\u2026 - Engineering, 2025", "abstract": "Recent advancements in large language models (LLMs) have driven remarkable progress in text processing, opening new avenues for medical knowledge discovery. In this study, we present ERQA, a mEdical (E) knowledge Retrieval (R) and Question \u2026"}]
