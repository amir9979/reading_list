[{"title": "Scalable Multi-Domain Adaptation of Language Models using Modular Experts", "link": "https://arxiv.org/pdf/2410.10181", "details": "P Schafhalter, S Liao, Y Zhou, CK Yeh, A Kandoor\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Domain-specific adaptation is critical to maximizing the performance of pre-trained language models (PLMs) on one or multiple targeted tasks, especially under resource-constrained use cases, such as edge devices. However, existing methods \u2026"}, {"title": "NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples", "link": "https://arxiv.org/pdf/2410.14669", "details": "B Li, Z Lin, W Peng, JD Nyandwi, D Jiang, Z Ma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models (VLMs) have made significant progress in recent visual- question-answering (VQA) benchmarks that evaluate complex visio-linguistic reasoning. However, are these models truly effective? In this work, we show that \u2026"}, {"title": "Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning", "link": "https://arxiv.org/pdf/2410.14464", "details": "J Tang, T Xia, Y Lu, C Mascolo, A Saeed - arXiv preprint arXiv:2410.14464, 2024", "abstract": "Electrocardiogram (ECG) interpretation requires specialized expertise, often involving synthesizing insights from ECG signals with complex clinical queries posed in natural language. The scarcity of labeled ECG data coupled with the diverse \u2026"}, {"title": "Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models", "link": "https://arxiv.org/pdf/2410.09047%3F", "details": "Q Liu, C Shang, L Liu, N Pappas, J Ma, NA John\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The safety alignment ability of Vision-Language Models (VLMs) is prone to be degraded by the integration of the vision module compared to its LLM backbone. We investigate this phenomenon, dubbed as''safety alignment degradation''in this paper \u2026"}, {"title": "Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models", "link": "https://arxiv.org/pdf/2410.16168", "details": "D Aggarwal, A Sathe, S Sitaram - arXiv preprint arXiv:2410.16168, 2024", "abstract": "Large Language Models (LLMs) demonstrate exceptional capabilities in a multitude of NLP tasks. However, the efficacy of such models to languages other than English is often limited. Prior works have shown that encoder-only models such as BERT or \u2026"}, {"title": "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "link": "https://arxiv.org/pdf/2410.05077", "details": "FM Molfese, S Conia, R Orlando, R Navigli - arXiv preprint arXiv:2410.05077, 2024", "abstract": "Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have \u2026"}, {"title": "Transformer-based Language Models for Reasoning in the Description Logic ALCQ", "link": "https://arxiv.org/pdf/2410.09613", "details": "A Poulis, E Tsalapati, M Koubarakis - arXiv preprint arXiv:2410.09613, 2024", "abstract": "Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order \u2026"}, {"title": "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server", "link": "https://arxiv.org/pdf/2410.05725", "details": "W Wang, X Liang, R Ye, J Chai, S Chen, Y Wang - arXiv preprint arXiv:2410.05725, 2024", "abstract": "The success of large language models (LLMs) facilitate many parties to fine-tune LLMs on their own private data. However, this practice raises privacy concerns due to the memorization of LLMs. Existing solutions, such as utilizing synthetic data for \u2026"}, {"title": "Evolutionary Contrastive Distillation for Language Model Alignment", "link": "https://arxiv.org/pdf/2410.07513", "details": "J Katz-Samuels, Z Li, H Yun, P Nigam, Y Xu, V Petricek\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The ability of large language models (LLMs) to execute complex instructions is essential for their real-world applications. However, several recent studies indicate that LLMs struggle with challenging instructions. In this paper, we propose \u2026"}]
