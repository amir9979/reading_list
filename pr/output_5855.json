[{"title": "Variational Autoencoder for Anomaly Detection: A Comparative Study", "link": "https://arxiv.org/pdf/2408.13561", "details": "HH Nguyen, CN Nguyen, XT Dao, QT Duong, DPT Kim\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper aims to conduct a comparative analysis of contemporary Variational Autoencoder (VAE) architectures employed in anomaly detection, elucidating their performance and behavioral characteristics within this specific task. The architectural \u2026"}, {"title": "Perturbation on Feature Coalition: Towards Interpretable Deep Neural Networks", "link": "https://arxiv.org/pdf/2408.13397", "details": "X Hu, M Zhu, Z Feng, M Dakovi\u0107, L Stankovi\u0107 - arXiv preprint arXiv:2408.13397, 2024", "abstract": "The inherent\" black box\" nature of deep neural networks (DNNs) compromises their transparency and reliability. Recently, explainable AI (XAI) has garnered increasing attention from researchers. Several perturbation-based interpretations have \u2026"}, {"title": "DIAGen: Diverse Image Augmentation with Generative Models", "link": "https://arxiv.org/pdf/2408.14584", "details": "T Lingenberg, M Reuter, G Sudhakaran, D Gojny\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Simple data augmentation techniques, such as rotations and flips, are widely used to enhance the generalization power of computer vision models. However, these techniques often fail to modify high-level semantic attributes of a class. To address \u2026"}, {"title": "SeA: Semantic Adversarial Augmentation for Last Layer Features from Unsupervised Representation Learning", "link": "https://arxiv.org/pdf/2408.13351", "details": "Q Qian, Y Xu, J Hu - arXiv preprint arXiv:2408.13351, 2024", "abstract": "Deep features extracted from certain layers of a pre-trained deep model show superior performance over the conventional hand-crafted features. Compared with fine-tuning or linear probing that can explore diverse augmentations,\\eg, random \u2026"}, {"title": "Curvature index of image samples used to evaluate the interpretability informativeness", "link": "https://www.sciencedirect.com/science/article/pii/S0952197624012028", "details": "Z Zhang, S Xiao, M Xi, J Wen, J Yang - Engineering Applications of Artificial \u2026, 2024", "abstract": "Although there are many thoughts in Artificial Intelligence (AI) interpretability methods, research on the data aspect of artificial intelligence interpretability is still relatively scarce. Previous work has evaluated the value of samples by analyzing the \u2026"}, {"title": "OctFusion: Octree-based Diffusion Models for 3D Shape Generation", "link": "https://arxiv.org/pdf/2408.14732", "details": "B Xiong, ST Wei, XY Zheng, YP Cao, Z Lian, PS Wang - arXiv preprint arXiv \u2026, 2024", "abstract": "Diffusion models have emerged as a popular method for 3D generation. However, it is still challenging for diffusion models to efficiently generate diverse and high-quality 3D shapes. In this paper, we introduce OctFusion, which can generate 3D shapes \u2026"}]
