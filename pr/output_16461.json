[{"title": "MiMo: Unlocking the Reasoning Potential of Language Model--From Pretraining to Posttraining", "link": "https://arxiv.org/pdf/2505.07608", "details": "B Xia, B Shen, D Zhu, D Zhang, G Wang, H Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing \u2026"}, {"title": "RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning", "link": "https://arxiv.org/pdf/2505.03238", "details": "L Boyle, N Baumann, P Sivasothilingam, M Magno\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Future robotic systems operating in real-world environments will require on-board embodied intelligence without continuous cloud connection, balancing capabilities with constraints on computational power and memory. This work presents an \u2026"}, {"title": "Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2504.21277", "details": "G Zhou, P Qiu, C Chen, J Wang, Z Yang, J Xu, M Qiu - arXiv preprint arXiv \u2026, 2025", "abstract": "The integration of reinforcement learning (RL) into the reasoning capabilities of Multimodal Large Language Models (MLLMs) has rapidly emerged as a transformative research direction. While MLLMs significantly extend Large Language \u2026"}, {"title": "MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance", "link": "https://arxiv.org/pdf/2505.03804", "details": "X Hu, Z Chen, D Yang, Z Xu, C Xu, Z Yuan, S Zhou\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Mixture-of-Experts (MoE) large language models (LLMs), which leverage dynamic routing and sparse activation to enhance efficiency and scalability, have achieved higher performance while reducing computational costs. However, these models \u2026"}, {"title": "Forest for the Trees: Overarching Prompting Evokes High-Level Reasoning in Large Language Models", "link": "https://aclanthology.org/2025.naacl-long.66.pdf", "details": "H Liao, S Hu, Z Zhu, H He, Y Jin - Proceedings of the 2025 Conference of the Nations \u2026, 2025", "abstract": "Abstract Chain-of-thought (CoT) and subsequent methods adopted a deductive paradigm that decomposes the reasoning process, demonstrating remarkable performances across NLP tasks. However, such a paradigm faces the challenge of \u2026"}, {"title": "LLM-based Interactive Imitation Learning for Robotic Manipulation", "link": "https://arxiv.org/pdf/2504.21769", "details": "J Werner, K Chu, C Weber, S Wermter - arXiv preprint arXiv:2504.21769, 2025", "abstract": "Recent advancements in machine learning provide methods to train autonomous agents capable of handling the increasing complexity of sequential decision-making in robotics. Imitation Learning (IL) is a prominent approach, where agents learn to \u2026"}, {"title": "$\\texttt {SAGE} $: A Generic Framework for LLM Safety Evaluation", "link": "https://arxiv.org/pdf/2504.19674", "details": "M Jindal, H Shrawgi, P Agrawal, S Dandapat - arXiv preprint arXiv:2504.19674, 2025", "abstract": "Safety evaluation of Large Language Models (LLMs) has made progress and attracted academic interest, but it remains challenging to keep pace with the rapid integration of LLMs across diverse applications. Different applications expose users \u2026"}, {"title": "NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models", "link": "https://arxiv.org/pdf/2504.21053", "details": "Y Zhou, W Xing, D Kong, C Lin, M Han - arXiv preprint arXiv:2504.21053, 2025", "abstract": "Safety alignment in large language models (LLMs) is achieved through fine-tuning mechanisms that regulate neuron activations to suppress harmful content. In this work, we propose a novel approach to induce disalignment by identifying and \u2026"}, {"title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2505.08971", "details": "Y Chen, H Peng, T Zhang, H Ji - arXiv preprint arXiv:2505.08971, 2025", "abstract": "In standard large vision-language models (LVLMs) pre-training, the model typically maximizes the joint probability of the caption conditioned on the image via next-token prediction (NTP); however, since only a small subset of caption tokens directly \u2026"}]
