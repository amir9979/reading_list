[{"title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.17637", "details": "Z Liu, Y Zang, X Dong, P Zhang, Y Cao, H Duan, C He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing \u2026"}, {"title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding", "link": "https://arxiv.org/pdf/2410.21311", "details": "F Zhu, Z Liu, XY Ng, H Wu, W Wang, F Feng, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable performance in many vision-language tasks, yet their capabilities in fine-grained visual understanding remain insufficiently evaluated. Existing benchmarks either contain \u2026"}, {"title": "CREAM: Consistency Regularized Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2410.12735%3F", "details": "Z Wang, W He, Z Liang, X Zhang, C Bansal, Y Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent self-rewarding large language models (LLM) have successfully applied LLM- as-a-Judge to iteratively improve the alignment performance without the need of human annotations for preference data. These methods commonly utilize the same \u2026"}, {"title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models", "link": "https://arxiv.org/pdf/2410.05639", "details": "R Zhao, ZL Thai, Y Zhang, S Hu, Y Ba, J Zhou, J Cai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The performance of Large Language Models (LLMs) is substantially influenced by the pretraining corpus, which consists of vast quantities of unsupervised data processed by the models. Despite its critical role in model performance, ensuring the \u2026"}, {"title": "Sleep apnea test prediction based on Electronic Health Records", "link": "https://www.sciencedirect.com/science/article/pii/S1532046424001552", "details": "LA Tahoun, AS Green, T Patalon, Y Dagan\u2026 - Journal of Biomedical \u2026, 2024", "abstract": "Abstract The identification of Obstructive Sleep Apnea (OSA) is done by a Polysomnography test which is often done in later ages. Being able to notify potential insured members at earlier ages is desirable. For that, we develop predictive models \u2026"}, {"title": "ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering", "link": "https://arxiv.org/pdf/2410.05077", "details": "FM Molfese, S Conia, R Orlando, R Navigli - arXiv preprint arXiv:2410.05077, 2024", "abstract": "Current Large Language Models (LLMs) have shown strong reasoning capabilities in commonsense question answering benchmarks, but the process underlying their success remains largely opaque. As a consequence, recent approaches have \u2026"}, {"title": "Assessments of Generative AI as Clinical Decision Support Ought to be Incorporated into Randomised Controlled Trials of Electronic Alerts for Acute Kidney Injury", "link": "https://www.sciencedirect.com/science/article/pii/S2949761224001019", "details": "DJ Sexton, C Judge - Mayo Clinic Proceedings: Digital Health, 2024", "abstract": "Acute Kidney Injury (AKI), characterised by an acute deterioration in kidney function occurs in approximately 25% of hospitalised individuals and is associated with prolonged stay, higher cost and increased morbidity and mortality. 1 Clinical \u2026"}, {"title": "MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.10139", "details": "P Xia, S Han, S Qiu, Y Zhou, Z Wang, W Zheng, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Interleaved multimodal comprehension and generation, enabling models to produce and interpret both images and text in arbitrary sequences, have become a pivotal area in multimodal learning. Despite significant advancements, the evaluation of this \u2026"}, {"title": "Optimized biomedical entity relation extraction method with data augmentation and classification using GPT-4 and Gemini", "link": "https://academic.oup.com/database/article/doi/10.1093/database/baae104/7816180", "details": "CP Phan, B Phan, JH Chiang - Database, 2024", "abstract": "Despite numerous research efforts by teams participating in the BioCreative VIII Track 01 employing various techniques to achieve the high accuracy of biomedical relation tasks, the overall performance in this area still has substantial room for \u2026"}]
