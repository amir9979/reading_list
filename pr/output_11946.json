[{"title": "Efficient Vocabulary Reduction for Small Language Models", "link": "https://aclanthology.org/2025.coling-industry.64.pdf", "details": "Y Nozaki, D Nakashima, R Sato, N Asaba - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "The increasing size of large language models (LLMs) poses significant challenges due to their high computational costs and energy consumption, making their deployment in industrial settings difficult. Small language models (SLMs) have been \u2026"}, {"title": "Cognitive Biases, Task Complexity, and Result Intepretability in Large Language Models", "link": "https://aclanthology.org/2025.coling-main.120.pdf", "details": "M Mina, V Ru\u00edz-Fern\u00e1ndez, J Falc\u00e3o, L Vasquez-Reina\u2026 - Proceedings of the 31st \u2026, 2025", "abstract": "In humans, cognitive biases are systematic deviations from rationality in judgment that simplify complex decisions. They typically manifest as a consequence of learned behaviors or limitations on information processing capabilities. Recent work has \u2026"}, {"title": "Partial Order-centered Hyperbolic Representation Learning for Few-shot Relation Extraction", "link": "https://aclanthology.org/2025.coling-main.101.pdf", "details": "B Hu, Z Huang, M Hu, P Yang, P Qiao, Y Dou, Z Wang - Proceedings of the 31st \u2026, 2025", "abstract": "Prototype network-based methods have made substantial progress in few-shot relation extraction (FSRE) by enhancing relation prototypes with relation descriptions. However, the distribution of relations and instances in distinct \u2026"}, {"title": "Large Language Models are Good Annotators for Type-aware Data Augmentation in Grammatical Error Correction", "link": "https://aclanthology.org/2025.coling-main.14.pdf", "details": "X Li, Y Lan - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) have achieved outstanding performance across various NLP tasks. Grammatical Error Correction (GEC) is a task aiming at automatically correcting grammatical errors in text, but it encounters a severe \u2026"}, {"title": "Topology-of-Question-Decomposition: Enhancing Large Language Models with Information Retrieval for Knowledge-Intensive Tasks", "link": "https://aclanthology.org/2025.coling-main.191.pdf", "details": "W Li, J Wang, LC Yu, X Zhang - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) are increasingly deployed for general problem- solving across various domains yet remain constrained to chaining immediate reasoning steps and depending solely on parametric knowledge. Integrating an \u2026"}, {"title": "What large language models know and what people think they know", "link": "https://www.nature.com/articles/s42256-024-00976-7", "details": "M Steyvers, H Tejeda, A Kumar, C Belem, S Karny\u2026 - Nature Machine Intelligence, 2025", "abstract": "As artificial intelligence systems, particularly large language models (LLMs), become increasingly integrated into decision-making processes, the ability to trust their outputs is crucial. To earn human trust, LLMs must be well calibrated such that they \u2026"}, {"title": "Enhancing Large Language Models for Document-Level Translation Post-Editing Using Monolingual Data", "link": "https://aclanthology.org/2025.coling-main.591.pdf", "details": "Z Li, Z Rao, H Shang, J Guo, S Li, D Wei, H Yang - Proceedings of the 31st \u2026, 2025", "abstract": "The translation capabilities of neural machine translation (NMT) models based on the encoder-decoder framework are extremely potent. Although Large Language Models (LLMs) have achieved remarkable results in many tasks, they have not \u2026"}, {"title": "ALIS: Aligned LLM Instruction Security Strategy for Unsafe Input Prompt", "link": "https://aclanthology.org/2025.coling-main.613.pdf", "details": "X Song, S Duan, G Liu - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "In large language models, existing instruction tuning methods may fail to balance the performance with robustness against attacks from user input like prompt injection and jailbreaking. Inspired by computer hardware and operating systems, we propose \u2026"}, {"title": "DORA: Dynamic Optimization Prompt for Continuous Reflection of LLM-based Agent", "link": "https://aclanthology.org/2025.coling-main.504.pdf", "details": "K Li, T Zhao, W Zhou, S Hu - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Autonomous agents powered by large language models (LLMs) hold significant potential across various domains. The Reflection framework is designed to help agents learn from past mistakes in complex tasks. While previous research has \u2026"}]
