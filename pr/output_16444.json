[{"title": "Empirical Evaluation of Knowledge Distillation from Transformers to Subquadratic Language Models", "link": "https://arxiv.org/pdf/2504.14366", "details": "P Haller, J Golde, A Akbik - arXiv preprint arXiv:2504.14366, 2025", "abstract": "Knowledge distillation is a widely used technique for compressing large language models (LLMs) by training a smaller student model to mimic a larger teacher model. Typically, both the teacher and student are Transformer-based architectures \u2026"}, {"title": "Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?", "link": "https://arxiv.org/pdf/2505.08468", "details": "MTR Laskar, MS Islam, R Mahbub, A Masry\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Charts are ubiquitous as they help people understand and reason with data. Recently, various downstream tasks, such as chart question answering, chart2text, and fact-checking, have emerged. Large Vision-Language Models (LVLMs) show \u2026"}, {"title": "Efficient multivariate time series forecasting via calibrated language models with privileged knowledge distillation", "link": "https://arxiv.org/pdf/2505.02138", "details": "C Liu, S Zhou, H Miao, Q Xu, C Long, Z Li, R Zhao - arXiv preprint arXiv:2505.02138, 2025", "abstract": "Multivariate time series forecasting (MTSF) endeavors to predict future observations given historical data, playing a crucial role in time series data management systems. With advancements in large language models (LLMs), recent studies employ textual \u2026"}, {"title": "Small but Significant: On the Promise of Small Language Models for Accessible AIED", "link": "https://arxiv.org/pdf/2505.08588", "details": "Y Wei, P Carvalho, J Stamper - arXiv preprint arXiv:2505.08588, 2025", "abstract": "GPT has become nearly synonymous with large language models (LLMs), an increasingly popular term in AIED proceedings. A simple keyword-based search reveals that 61% of the 76 long and short papers presented at AIED 2024 describe \u2026"}, {"title": "Platonic Grounding for Efficient Multimodal Language Models", "link": "https://arxiv.org/pdf/2504.19327", "details": "M Choraria, X Wu, A Bhimaraju, N Sekhar, Y Wu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The hyperscaling of data and parameter count in Transformer-based models is yielding diminishing performance improvement, especially when weighed against training costs. Such plateauing indicates the importance of methods for more efficient \u2026"}, {"title": "Can Long-Context Language Models Solve Repository-Level Code Generation?", "link": "https://openreview.net/pdf%3Fid%3DpmcWo9DtDw", "details": "Y PENG, ZZ Wang, D Fried - LTI Student Research Symposium 2025", "abstract": "With the advance of real-world tasks that necessitate increasingly long contexts, recent language models (LMs) have begun to support longer context windows. One particularly complex task is repository-level code generation, where retrieval \u2026"}, {"title": "Towards trustworthy and reliable language models", "link": "https://dr.ntu.edu.sg/bitstream/10356/184392/2/Amended%2520Thesis.pdf", "details": "R Zhao - 2025", "abstract": "This thesis addresses the critical challenge of developing trustworthy and reliable Natural Language Processing (NLP) systems, specifically the newly emerged Large Language Models (LLMs). As LLMs become increasingly prevalent in various \u2026"}, {"title": "Optimizing LLM Queries in Relational Data Analytics Workloads", "link": "https://openreview.net/forum%3Fid%3DR7bK9yycHp", "details": "S Liu, A Biswal, A Kamsetty, A Cheng, LG Schroeder\u2026 - Eighth Conference on \u2026, 2025", "abstract": "Batch data analytics is a growing application for Large Language Models (LLMs). LLMs enable users to perform a wide range of natural language tasks, such as classification, entity extraction, and translation, over large datasets. However, LLM \u2026"}, {"title": "Stigmatizing and Positive Language in Birth Clinical Notes Associated With Race and Ethnicity", "link": "https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2833892", "details": "II Hulchafo, JK Scroggins, SE Harkins, H Moen\u2026 - JAMA Network Open, 2025", "abstract": "Importance Language used in clinical documentation can reflect biases, potentially contributing to health disparities. Understanding associations between patient race and ethnicity and documentation of stigmatizing and positive language in clinical \u2026"}]
