[{"title": "Neural codec language models are zero-shot text to speech synthesizers", "link": "https://ieeexplore.ieee.org/abstract/document/10842513/", "details": "S Chen, C Wang, Y Wu, Z Zhang, L Zhou, S Liu\u2026 - IEEE Transactions on Audio \u2026, 2025", "abstract": "We introduce a language modeling approach for text to speech synthesis (TTS). Specifically, we train a neural codec language model (called VALL-E) using discrete codes derived from an off-the-shelf neural audio codec model, and regard TTS as a \u2026"}, {"title": "CTPT: Continual Test-time Prompt Tuning for vision-language models", "link": "https://www.sciencedirect.com/science/article/pii/S0031320324010513", "details": "F Wang, Z Han, X Liu, Y Yin, X Gao - Pattern Recognition, 2024", "abstract": "Abstract Test-time Prompt Tuning (TPT) aims to further enhance the generalization capabilities of pre-trained vision-language models, eg, CLIP, on streaming test samples from a new distribution. Current TPT methods primarily utilize self-training \u2026"}, {"title": "BenCzechMark: A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism", "link": "https://arxiv.org/pdf/2412.17933", "details": "M Fajcik, M Docekal, J Dolezal, K Ondrej, K Bene\u0161\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present BenCzechMark (BCM), the first comprehensive Czech language benchmark designed for large language models, offering diverse tasks, multiple task formats, and multiple evaluation metrics. Its scoring system is grounded in statistical \u2026"}, {"title": "The Power of Negative Zero: Datatype Customization for Quantized Large Language Models", "link": "https://arxiv.org/pdf/2501.04052", "details": "Y Chen, X Dai, C Chang, Y Akhauri, MS Abdelfattah - arXiv preprint arXiv:2501.04052, 2025", "abstract": "Large language models (LLMs) have demonstrated remarkable performance across various machine learning tasks, quickly becoming one of the most prevalent AI workloads. Yet the substantial memory requirement of LLMs significantly hinders \u2026"}, {"title": "LLM360 K2: Scaling Up 360-Open-Source Large Language Models", "link": "https://arxiv.org/pdf/2501.07124", "details": "Z Liu, B Tan, H Wang, W Neiswanger, T Tao, H Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We detail the training of the LLM360 K2-65B model, scaling up our 360-degree OPEN SOURCE approach to the largest and most powerful models under project LLM360. While open-source LLMs continue to advance, the answer to\" How are the \u2026"}, {"title": "LEO: Boosting Mixture of Vision Encoders for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2501.06986", "details": "MN Azadani, J Riddell, S Sedwards, K Czarnecki - arXiv preprint arXiv:2501.06986, 2025", "abstract": "Enhanced visual understanding serves as a cornerstone for multimodal large language models (MLLMs). Recent hybrid MLLMs incorporate a mixture of vision experts to address the limitations of using a single vision encoder and excessively \u2026"}, {"title": "Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models", "link": "https://arxiv.org/pdf/2501.04945", "details": "Q Ren, J Zeng, Q He, J Liang, Y Xiao, W Zhou, Z Sun\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "It is crucial for large language models (LLMs) to follow instructions that involve multiple constraints. However, soft constraints are semantically related and difficult to verify through automated methods. These constraints remain a significant challenge \u2026"}, {"title": "GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2412.21036", "details": "S Xing, C Xiang, Y Han, Y Yue, Z Wu, X Liu, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal large language models (MLLMs) have achieved significant advancements in integrating visual and linguistic understanding. While existing benchmarks evaluate these models in context-rich, real-life scenarios, they often \u2026"}, {"title": "Analyzing Memorization in Large Language Models through the Lens of Model Attribution", "link": "https://arxiv.org/pdf/2501.05078", "details": "TR Menta, S Agrawal, C Agarwal - arXiv preprint arXiv:2501.05078, 2025", "abstract": "Large Language Models (LLMs) are prevalent in modern applications but often memorize training data, leading to privacy breaches and copyright issues. Existing research has mainly focused on posthoc analyses, such as extracting memorized \u2026"}]
