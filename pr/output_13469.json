[{"title": "CoT2Align: Cross-Chain of Thought Distillation via Optimal Transport Alignment for Language Models with Different Tokenizers", "link": "https://arxiv.org/pdf/2502.16806", "details": "AD Le, T Vu, NL Hai, NTN Diep, LN Van, T Le\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) achieve state-of-the-art performance across various NLP tasks but face deployment challenges due to high computational costs and memory constraints. Knowledge distillation (KD) is a promising solution, transferring \u2026"}, {"title": "Every Expert Matters: Towards Effective Knowledge Distillation for Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2502.12947", "details": "G Kim, G Chu, E Yang - arXiv preprint arXiv:2502.12947, 2025", "abstract": "With the emergence of Mixture-of-Experts (MoE), the efficient scaling of model size has accelerated the development of large language models in recent years. However, their high memory requirements prevent their use in resource-constrained \u2026"}, {"title": "Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images", "link": "https://arxiv.org/pdf/2502.13928", "details": "S Wu, FY Sun, K Wen, N Haber - arXiv preprint arXiv:2502.13928, 2025", "abstract": "Recent studies have shown that Large Vision-Language Models (VLMs) tend to neglect image content and over-rely on language-model priors, resulting in errors in visually grounded tasks and hallucinations. We hypothesize that this issue arises \u2026"}, {"title": "Enhancing Generalization in Camera Trap Image Recognition: Fine-Tuning Visual Language Models", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225004989", "details": "Z Yang, Y Tian, L Wang, J Zhang - Neurocomputing, 2025", "abstract": "This study introduces a novel fine-tuning approach for enhancing the generalization capabilities of visual language models in the context of wildlife monitoring, particularly for camera trap image recognition. In this paper, we introduce Ecological \u2026"}, {"title": "PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14504", "details": "Y Meng, K Li, C Huang, C Gao, X Chen, Y Li, X Zhang - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across a range of multimodal tasks. However, their inference efficiency is constrained by the large number of visual tokens processed during decoding. To address this \u2026"}, {"title": "Toward Responsible Federated Large Language Models: Leveraging a Safety Filter and Constitutional AI", "link": "https://arxiv.org/pdf/2502.16691", "details": "E Noh, J Baek - arXiv preprint arXiv:2502.16691, 2025", "abstract": "Recent research has increasingly focused on training large language models (LLMs) using federated learning, known as FedLLM. However, responsible AI (RAI), which aims to ensure safe responses, remains underexplored in the context of FedLLM. In \u2026"}, {"title": "GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation", "link": "https://arxiv.org/pdf/2502.18990", "details": "J He, J Neville, M Wan, L Yang, H Liu, X Xu, X Song\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) can enhance their capabilities as AI assistants by integrating external tools, allowing them to access a wider range of information. While recent LLMs are typically fine-tuned with tool usage examples during \u2026"}, {"title": "Comparing Large Language Models for Generating Complex Queries", "link": "https://www.scirp.org/journal/paperinformation%3Fpaperid%3D140921", "details": "L Ma, K Pu, Y Zhu, W Taylor - Journal of Computer and Communications, 2025", "abstract": "This study presents a comparative analysis of a complex SQL benchmark, TPC-DS, with two existing text-to-SQL benchmarks, BIRD and Spider. Our findings reveal that TPC-DS queries exhibit a significantly higher level of structural complexity compared \u2026"}, {"title": "Comprehensive analysis of transparency and accessibility of chatgpt, deepseek, and other sota large language models", "link": "https://arxiv.org/pdf/2502.18505", "details": "R Sapkota, S Raza, M Karkee - arXiv preprint arXiv:2502.18505, 2025", "abstract": "Despite increasing discussions on open-source Artificial Intelligence (AI), existing research lacks a discussion on the transparency and accessibility of state-of-the-art (SoTA) Large Language Models (LLMs). The Open Source Initiative (OSI) has \u2026"}]
