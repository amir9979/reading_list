[{"title": "Towards Explainable Evolution Strategies with Large Language Models", "link": "https://arxiv.org/pdf/2407.08331", "details": "J Baumann, O Kramer - arXiv preprint arXiv:2407.08331, 2024", "abstract": "This paper introduces an approach that integrates self-adaptive Evolution Strategies (ES) with Large Language Models (LLMs) to enhance the explainability of complex optimization processes. By employing a self-adaptive ES equipped with a restart \u2026"}, {"title": "COMI: COrrect and MItigate Shortcut Learning Behavior in Deep Neural Networks", "link": "https://dl.acm.org/doi/abs/10.1145/3626772.3657729", "details": "L Zhao, Q Liu, L Yue, W Chen, L Chen, R Sun, C Song - Proceedings of the 47th \u2026, 2024", "abstract": "Deep Neural Networks (DNNs), despite their notable progress across information retrieval tasks, encounter the issues of shortcut learning and struggle with poor generalization due to their reliance on spurious correlations between features and \u2026"}, {"title": "Interdependence-Adaptive Mutual Information Maximization for Graph Contrastive Learning", "link": "https://www.computer.org/csdl/journal/tk/5555/01/10596072/1YuPLjP6OXe", "details": "Q Sun, K Wang, W Zhang, P Cheng, X Lin - IEEE Transactions on Knowledge & Data \u2026, 2024", "abstract": "Despite remarkable advancements in graph contrastive learning techniques, the identification of interdependent relationships when maximizing cross-view mutual information remains a challenging issue, primarily due to the complexity of graph \u2026"}, {"title": "A Deep Metric Learning Based Method for Predicting MiRNA-Disease Associations", "link": "https://link.springer.com/chapter/10.1007/978-981-97-5128-0_21", "details": "NPX Quynh, HN Tran, C Yan, J Wang - International Symposium on Bioinformatics \u2026, 2024", "abstract": "MicroRNAs (miRNAs) play crucial roles in various human diseases. Identifying miRNA-disease associations (MDAs) can supply us with an understanding for prevention, diagnosis, and treatment of diseases. However, predicting MDAs through \u2026"}, {"title": "Hybrid Explanatory Interactive Machine Learning for Medical Diagnosis", "link": "https://link.springer.com/chapter/10.1007/978-3-031-63211-2_9", "details": "E Slany, S Scheele, U Schmid - IFIP International Conference on Artificial Intelligence \u2026, 2024", "abstract": "Abstract Machine learning (ML) models can be an effective assistance in medical diagnosis if they allow physicians to project their knowledge into model's internal mechanism. Using model-agnostic explanatory interactive ML (XIML), physicians \u2026"}, {"title": "Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models", "link": "https://arxiv.org/pdf/2406.14091", "details": "D Lee, D Rim, M Choi, J Choo - arXiv preprint arXiv:2406.14091, 2024", "abstract": "Although language models (LMs) demonstrate exceptional capabilities on various tasks, they are potentially vulnerable to extraction attacks, which represent a significant privacy risk. To mitigate the privacy concerns of LMs, machine unlearning \u2026"}, {"title": "SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation", "link": "https://arxiv.org/pdf/2406.12975", "details": "X Liu, T Sun, T Xu, F Wu, C Wang, X Wang, J Gao - arXiv preprint arXiv:2406.12975, 2024", "abstract": "Large Language Models (LLMs) have transformed machine learning but raised significant legal concerns due to their potential to produce text that infringes on copyrights, resulting in several high-profile lawsuits. The legal landscape is \u2026"}, {"title": "Uncovering Latent Memories: Assessing Data Leakage and Memorization Patterns in Large Language Models", "link": "https://arxiv.org/pdf/2406.14549", "details": "S Duan, M Khona, A Iyer, R Schaeffer, IR Fiete - arXiv preprint arXiv:2406.14549, 2024", "abstract": "The proliferation of large language models has revolutionized natural language processing tasks, yet it raises profound concerns regarding data privacy and security. Language models are trained on extensive corpora including potentially sensitive or \u2026"}, {"title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs", "link": "https://arxiv.org/pdf/2406.14282", "details": "J Wang, M Chen, B Hu, D Yang, Z Liu, Y Shen, P Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Improving the performance of large language models (LLMs) in complex question- answering (QA) scenarios has always been a research focal point. Recent studies have attempted to enhance LLMs' performance by combining step-wise planning \u2026"}]
