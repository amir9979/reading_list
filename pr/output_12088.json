[{"title": "Zero-Shot Verification-guided Chain of Thoughts", "link": "https://arxiv.org/pdf/2501.13122", "details": "JR Chowdhury, C Caragea - arXiv preprint arXiv:2501.13122, 2025", "abstract": "Previous works have demonstrated the effectiveness of Chain-of-Thought (COT) prompts and verifiers in guiding Large Language Models (LLMs) through the space of reasoning. However, most such studies either use a fine-tuned verifier or rely on \u2026"}, {"title": "CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries", "link": "https://arxiv.org/pdf/2501.01282", "details": "S Liu, Y Jin, C Li, DF Wong, Q Wen, L Sun, H Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models (VLMs) have advanced human-AI interaction but struggle with cultural understanding, often misinterpreting symbols, gestures, and artifacts due to biases in predominantly Western-centric training data. In this paper, we \u2026"}, {"title": "Unveiling the power of language models in chemical research question answering", "link": "https://www.nature.com/articles/s42004-024-01394-x", "details": "X Chen, T Wang, T Guo, K Guo, J Zhou, H Li, Z Song\u2026 - Communications Chemistry, 2025", "abstract": "While the abilities of language models are thoroughly evaluated in areas like general domains and biomedicine, academic chemistry remains less explored. Chemical QA tools also play a crucial role in both education and research by effectively translating \u2026"}, {"title": "Vision-Language Models Do Not Understand Negation", "link": "https://arxiv.org/pdf/2501.09425", "details": "K Alhamoud, S Alshammari, Y Tian, G Li, P Torr, Y Kim\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Many practical vision-language applications require models that understand negation, eg, when using natural language to retrieve images which contain certain objects but not others. Despite advancements in vision-language models (VLMs) \u2026"}, {"title": "Large Vision-Language Models for Knowledge-Grounded Data Annotation of Memes", "link": "https://arxiv.org/pdf/2501.13851", "details": "S Deng, S Belongie, PE Christensen - arXiv preprint arXiv:2501.13851, 2025", "abstract": "Memes have emerged as a powerful form of communication, integrating visual and textual elements to convey humor, satire, and cultural messages. Existing research has focused primarily on aspects such as emotion classification, meme generation \u2026"}, {"title": "LASS: A Novel and Economical Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization", "link": "https://aclanthology.org/2025.coling-main.412.pdf", "details": "Y Zhang, P Li, Y Lai, Y He, D Zhou - Proceedings of the 31st International Conference \u2026, 2025", "abstract": "As more than 70% of reviews in the existing opinion summary data set are positive, current opinion summarization approaches are hesitant to generate negative summaries given the input of negative texts. To address such sentiment bias, a direct \u2026"}, {"title": "ImageRef-VL: Enabling Contextual Image Referencing in Vision-Language Models", "link": "https://arxiv.org/pdf/2501.12418", "details": "J Yi, J Yin, J Xu, P Bao, Y Wang, W Fan, H Wang - arXiv preprint arXiv:2501.12418, 2025", "abstract": "Vision-Language Models (VLMs) have demonstrated remarkable capabilities in understanding multimodal inputs and have been widely integrated into Retrieval- Augmented Generation (RAG) based conversational systems. While current VLM \u2026"}, {"title": "Leveraging Language Models for Summarizing Mental State Examinations: A Comprehensive Evaluation and Dataset Release", "link": "https://aclanthology.org/2025.coling-main.182.pdf", "details": "NK Sahu, M Yadav, M Chaturvedi, S Gupta, HR Lone - Proceedings of the 31st \u2026, 2025", "abstract": "Mental health disorders affect a significant portion of the global population, with diagnoses primarily conducted through Mental State Examinations (MSEs). MSEs serve as structured assessments to evaluate behavioral and cognitive functioning \u2026"}, {"title": "[Uncaptioned image] RedPajama: an Open Dataset for Training Large Language Models", "link": "https://jalms.net/2411.12372v1/", "details": "M Weber, DY Fu, Q Anthony, Y Oren, S Adams\u2026", "abstract": "\u5927\u898f\u6a21\u8a00\u8a9e\u30e2\u30c7\u30eb\u306f, \u4eba\u5de5\u77e5\u80fd, \u79d1\u5b66, \u305d\u3057\u3066\u793e\u4f1a\u5168\u4f53\u306b\u304a\u3044\u3066, \u307e\u3059\u307e\u3059\u91cd\u8981\u306a\u57fa\u76e4\u6280\u8853 \u3068\u306a\u308a\u3064\u3064\u3042\u308b. \u3057\u304b\u3057, \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u69cb\u6210\u3068\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u306e\u6700\u9069\u306a\u6226\u7565\u306f, \u4f9d\u7136\u3068\u3057\u3066\u5927\u90e8\u5206\u304c\u4e0d\u660e\u77ad\u306a\u307e\u307e\u3067\u3042\u308b. \u6700\u9ad8\u6027\u80fd\u306e\u30e2\u30c7\u30eb\u306e\u591a\u304f\u306f, \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u9078\u5b9a\u3084 \u2026"}]
