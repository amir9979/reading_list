[{"title": "Demystifying AI Agents: The Final Generation of Intelligence", "link": "https://arxiv.org/pdf/2505.09932", "details": "KJ McNamara, RP Marpu - arXiv preprint arXiv:2505.09932, 2025", "abstract": "The trajectory of artificial intelligence (AI) has been one of relentless acceleration, evolving from rudimentary rule-based systems to sophisticated, autonomous agents capable of complex reasoning and interaction. This whitepaper chronicles this \u2026", "entry_id": "http://arxiv.org/abs/2505.09932v1", "updated": "2025-05-15 03:35:12", "published": "2025-05-15 03:35:12", "authors": "Kevin J McNamara;Rhea Pritham Marpu", "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence.", "comment": null, "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI;cs.ET;cs.LG;cs.MA", "links": "http://arxiv.org/abs/2505.09932v1;http://arxiv.org/pdf/2505.09932v1", "pdf_url": "http://arxiv.org/pdf/2505.09932v1"}, {"title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "link": "https://arxiv.org/pdf/2505.10413", "details": "J Jin, X Li, G Dong, Y Zhang, Y Zhu, Y Wu, Z Li, Q Ye\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Real-world RAG applications often encounter long-context input scenarios, where redundant information and noise results in higher inference costs and reduced performance. To address these challenges, we propose LongRefiner, an efficient \u2026", "entry_id": "http://arxiv.org/abs/2505.10413v1", "updated": "2025-05-15 15:34:15", "published": "2025-05-15 15:34:15", "authors": "Jiajie Jin;Xiaoxi Li;Guanting Dong;Yuyao Zhang;Yutao Zhu;Yongkang Wu;Zhonghua Li;Qi Ye;Zhicheng Dou", "summary": "Real-world RAG applications often encounter long-context input scenarios,\nwhere redundant information and noise results in higher inference costs and\nreduced performance. To address these challenges, we propose LongRefiner, an\nefficient plug-and-play refiner that leverages the inherent structural\ncharacteristics of long documents. LongRefiner employs dual-level query\nanalysis, hierarchical document structuring, and adaptive refinement through\nmulti-task learning on a single foundation model. Experiments on seven QA\ndatasets demonstrate that LongRefiner achieves competitive performance in\nvarious scenarios while using 10x fewer computational costs and latency\ncompared to the best baseline. Further analysis validates that LongRefiner is\nscalable, efficient, and effective, providing practical insights for real-world\nlong-text RAG applications. Our code is available at\nhttps://github.com/ignorejjj/LongRefiner.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.10413v1;http://arxiv.org/pdf/2505.10413v1", "pdf_url": "http://arxiv.org/pdf/2505.10413v1"}]
