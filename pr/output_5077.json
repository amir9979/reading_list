[{"title": "Making Long-Context Language Models Better Multi-Hop Reasoners", "link": "https://arxiv.org/pdf/2408.03246", "details": "Y Li, S Liang, MR Lyu, L Wang - arXiv preprint arXiv:2408.03246, 2024", "abstract": "Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased \u2026"}, {"title": "Evaluating language models as risk scores", "link": "https://arxiv.org/pdf/2407.14614", "details": "AF Cruz, M Hardt, C Mendler-D\u00fcnner - arXiv preprint arXiv:2407.14614, 2024", "abstract": "Current question-answering benchmarks predominantly focus on accuracy in realizable prediction tasks. Conditioned on a question and answer-key, does the most likely token match the ground truth? Such benchmarks necessarily fail to \u2026"}, {"title": "TaD: A Plug-and-Play Task-Aware Decoding Method to Better Adapt LLMs on Downstream Tasks", "link": "https://www.ijcai.org/proceedings/2024/0728.pdf", "details": "X Xu, H Chen, Z Lin, J Han, L Gong, G Wang, Y Bao\u2026 - Proceedings of the Thirty \u2026, 2024", "abstract": "Fine-tuning pre-trained models on downstream tasks is a common practice in leveraging large language models (LLMs) today. A critical issue is how to adapt pre- trained models to downstream tasks better, thereby enhancing their performance \u2026"}, {"title": "Data Contamination Report from the 2024 CONDA Shared Task", "link": "https://arxiv.org/pdf/2407.21530", "details": "O Sainz, I Garc\u00eda-Ferrero, A Jacovi, JA Campos\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The 1st Workshop on Data Contamination (CONDA 2024) focuses on all relevant aspects of data contamination in natural language processing, where data contamination is understood as situations where evaluation data is included in pre \u2026"}, {"title": "Effectiveness of Scalable Monolingual Data and Trigger Words Prompting on Cross-Lingual Emotion Detection Task", "link": "https://aclanthology.org/2024.wassa-1.51.pdf", "details": "YF Cheng, J Hong, A Wang, A Silva, GA Levow - Proceedings of the 14th Workshop \u2026, 2024", "abstract": "This paper introduces our submitted systems for WASSA 2024 Shared Task 2: Cross- Lingual Emotion Detection. We implemented a BERT-based classifier and an in- context learning-based system. Our best-performing model, using English Chain of \u2026"}, {"title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering", "link": "https://arxiv.org/pdf/2407.21368", "details": "D Guo, D Terzopoulos - arXiv preprint arXiv:2407.21368, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in recent years, and they have been extended to the medical domain. Although demonstrating satisfactory performance on medical Visual Question Answering (VQA) tasks \u2026"}, {"title": "Efficiency in Focus: LayerNorm as a Catalyst for Fine-tuning Medical Visual Language Models", "link": "https://openreview.net/pdf%3Fid%3DgYxocD2XGO", "details": "J Chen, D Yang, Y Jiang, M Li, J Wei, X Hou, L Zhang - ACM Multimedia 2024", "abstract": "In the realm of Medical Visual Language Models (VLMs), the quest for universal efficient fine-tuning mechanisms remains paramount, especially given researchers in interdisciplinary fields are often extremely short of training resources, yet largely \u2026"}, {"title": "Subjectivity Detection in English News using Large Language Models", "link": "https://aclanthology.org/2024.wassa-1.17.pdf", "details": "M Shokri, V Sharma, E Filatova, S Jain, S Levitan - Proceedings of the 14th Workshop \u2026, 2024", "abstract": "Trust in media has reached a historical low as consumers increasingly doubt the credibility of the news they encounter. This growing skepticism is exacerbated by the prevalence of opinion-driven articles, which can influence readers' beliefs to align \u2026"}, {"title": "Skip\\n: A simple method to reduce hallucination in large vision-language models", "link": "https://oar.a-star.edu.sg/storage/d/d66g61dkp7/nn-bias-in-visual-language-models-camera-ready.pdf", "details": "Z Han, Z Bai, H Mei, Q Xu, C Zhang, MZ Shou - arXiv preprint arXiv:2402.01345, 2024", "abstract": "Recent advancements in large vision-language models (LVLMs) have demonstrated impressive capability in visual information understanding with human language. Despite these advances, LVLMs still face challenges with multimodal hallucination \u2026"}]
