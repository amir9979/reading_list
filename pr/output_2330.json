[{"title": "Multi-Dimensional Optimization for Text Summarization via Reinforcement Learning", "link": "https://arxiv.org/pdf/2406.00303", "details": "S Ryu, H Do, Y Kim, GG Lee, J Ok - arXiv preprint arXiv:2406.00303, 2024", "abstract": "The evaluation of summary quality encompasses diverse dimensions such as consistency, coherence, relevance, and fluency. However, existing summarization methods often target a specific dimension, facing challenges in generating well \u2026"}, {"title": "iGWAS: Image-based genome-wide association of self-supervised deep phenotyping of retina fundus images", "link": "https://journals.plos.org/plosgenetics/article%3Fid%3D10.1371/journal.pgen.1011273", "details": "Z Xie, T Zhang, S Kim, J Lu, W Zhang, CH Lin, MR Wu\u2026 - PLoS genetics, 2024", "abstract": "Existing imaging genetics studies have been mostly limited in scope by using imaging-derived phenotypes defined by human experts. Here, leveraging new breakthroughs in self-supervised deep representation learning, we propose a new \u2026"}, {"title": "Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning", "link": "https://arxiv.org/pdf/2405.20625", "details": "A Gundawar, M Verma, L Guan, K Valmeekam\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the applicability of Large Language Models (LLMs) extends beyond traditional text processing tasks, there is a burgeoning interest in their potential to excel in planning and reasoning assignments, realms traditionally reserved for System 2 \u2026"}]
