[{"title": "CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.285.pdf", "details": "Z Zha, X Zhu, Y Xu, C Huang, J Liu, Z Li, X Wang\u2026 - Findings of the Association \u2026, 2024", "abstract": "Abstract Multimodal Large Language Models (MLLMs) have shown promising results in various tasks, but their ability to perceive the visual world with deep, hierarchical understanding similar to humans remains uncertain. To address this gap, we \u2026"}, {"title": "MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation and Fine-grained Classification", "link": "https://aclanthology.org/2024.findings-emnlp.73.pdf", "details": "K Sun, Y Bai, J Qi, L Hou, J Li - Findings of the Association for Computational \u2026, 2024", "abstract": "To advance the evaluation of multimodal math reasoning in large multimodal models (LMMs), this paper introduces a novel benchmark, MM-MATH. MM-MATH consists of 5,929 open-ended middle school math problems with visual contexts, with fine \u2026"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://openreview.net/pdf%3Fid%3DHd2EOwKItm", "details": "Z Huang, Q Ye, B Kang, J Feng, H Fan - The Thirty-eighth Annual Conference on Neural \u2026", "abstract": "We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised \u2026"}, {"title": "Smoothie: Label Free Language Model Routing", "link": "https://openreview.net/pdf%3Fid%3DpPSWHsgqRp", "details": "N Guha, MF Chen, T Chow, IS Khare, C Re - The Thirty-eighth Annual Conference on Neural \u2026", "abstract": "Large language models (LLMs) are increasingly used in applications where LLM inputs may span many different tasks. Recent work has found that the choice of LLM is consequential, and different LLMs may be good for different input samples. Prior \u2026"}, {"title": "A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models", "link": "https://aclanthology.org/2024.emnlp-main.210.pdf", "details": "J Wang, F Mo, W Ma, P Sun, M Zhang, JY Nie - \u2026 of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Large language models (LLMs) are essential tools that users employ across various scenarios, so evaluating their performance and guiding users in selecting the suitable service is important. Although many benchmarks exist, they mainly focus on \u2026"}, {"title": "Guided Profile Generation Improves Personalization with Large Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.231.pdf", "details": "J Zhang - Findings of the Association for Computational \u2026, 2024", "abstract": "In modern commercial systems, including Recommendation, Ranking, and E- Commerce platforms, there is a trend towards improving customer experiences by incorporating Personalization context as input into Large Language Models (LLM) \u2026"}, {"title": "A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning", "link": "https://arxiv.org/pdf/2410.12288%3F", "details": "Y Cui, Z Sun, W Hu - arXiv preprint arXiv:2410.12288, 2024", "abstract": "Extensive knowledge graphs (KGs) have been constructed to facilitate knowledge- driven tasks across various scenarios. However, existing work usually develops separate reasoning models for different KGs, lacking the ability to generalize and \u2026"}, {"title": "Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance", "link": "https://aclanthology.org/2024.findings-emnlp.554.pdf", "details": "I Cho, G Kwon, J Hockenmaier - Findings of the Association for Computational \u2026, 2024", "abstract": "There has been a growing body of work focusing on the in-context learning (ICL) abilities of large language models (LLMs). However, it is an open question how effective ICL can be. This paper presents Tutor-ICL, a simple prompting method for \u2026"}, {"title": "SQL Injection Jailbreak: a structural disaster of large language models", "link": "https://arxiv.org/pdf/2411.01565", "details": "J Zhao, K Chen, W Zhang, N Yu - arXiv preprint arXiv:2411.01565, 2024", "abstract": "In recent years, the rapid development of large language models (LLMs) has brought new vitality to the various domains and generated substantial social and economic benefits. However, the swift advancement of LLMs has introduced new security \u2026"}]
