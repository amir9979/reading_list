[{"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "In-Context Learning Improves Compositional Understanding of Vision-Language Models", "link": "https://arxiv.org/pdf/2407.15487", "details": "M Nulli, A Ibrahimi, A Pal, H Lee, I Najdenkoska - arXiv preprint arXiv:2407.15487, 2024", "abstract": "Vision-Language Models (VLMs) have shown remarkable capabilities in a large number of downstream tasks. Nonetheless, compositional image understanding remains a rather difficult task due to the object bias present in training data. In this \u2026"}, {"title": "Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.02032", "details": "F Huo, W Xu, Z Zhang, H Wang, Z Chen, P Zhao - arXiv preprint arXiv:2408.02032, 2024", "abstract": "While Large Vision-Language Models (LVLMs) have rapidly advanced in recent years, the prevalent issue known as thehallucination'problem has emerged as a significant bottleneck, hindering their real-world deployments. Existing methods \u2026"}, {"title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability", "link": "https://arxiv.org/pdf/2407.19842", "details": "J Garc\u00eda-Carrasco, A Mat\u00e9, J Trujillo - arXiv preprint arXiv:2407.19842, 2024", "abstract": "Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the \u2026"}, {"title": "Improving Context-Aware Preference Modeling for Language Models", "link": "https://arxiv.org/pdf/2407.14916", "details": "S Pitis, Z Xiao, NL Roux, A Sordoni - arXiv preprint arXiv:2407.14916, 2024", "abstract": "While finetuning language models from pairwise preferences has proven remarkably effective, the underspecified nature of natural language presents critical challenges. Direct preference feedback is uninterpretable, difficult to provide where \u2026"}, {"title": "Efficiency in Focus: LayerNorm as a Catalyst for Fine-tuning Medical Visual Language Models", "link": "https://openreview.net/pdf%3Fid%3DgYxocD2XGO", "details": "J Chen, D Yang, Y Jiang, M Li, J Wei, X Hou, L Zhang - ACM Multimedia 2024", "abstract": "In the realm of Medical Visual Language Models (VLMs), the quest for universal efficient fine-tuning mechanisms remains paramount, especially given researchers in interdisciplinary fields are often extremely short of training resources, yet largely \u2026"}, {"title": "Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation", "link": "https://arxiv.org/pdf/2408.00555", "details": "X Qu, Q Chen, W Wei, J Sun, J Dong - arXiv preprint arXiv:2408.00555, 2024", "abstract": "Despite the remarkable ability of large vision-language models (LVLMs) in image comprehension, these models frequently generate plausible yet factually incorrect responses, a phenomenon known as hallucination. Recently, in large language \u2026"}, {"title": "Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and Semantically-Rich Vision-Language Models", "link": "https://arxiv.org/pdf/2407.14971", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2407.14971, 2024", "abstract": "Vision-language models (VLMs) have achieved significant strides in recent times specially in multimodal tasks, yet they remain susceptible to adversarial attacks on their vision components. To address this, we propose Sim-CLIP, an unsupervised \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}]
