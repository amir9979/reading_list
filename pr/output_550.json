'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Global Contrastive Training for Multimodal Electronic '
[{"title": "FairPair: A Robust Evaluation of Biases in Language Models through Paired Perturbations", "link": "https://arxiv.org/pdf/2404.06619", "details": "J Dwivedi-Yu, R Dwivedi, T Schick - arXiv preprint arXiv:2404.06619, 2024", "abstract": "The accurate evaluation of differential treatment in language models to specific groups is critical to ensuring a positive and safe user experience. An ideal evaluation should have the properties of being robust, extendable to new groups or attributes \u2026"}, {"title": "Understanding emergent abilities of language models from the loss perspective", "link": "https://arxiv.org/pdf/2403.15796", "details": "Z Du, A Zeng, Y Dong, J Tang - arXiv preprint arXiv:2403.15796, 2024", "abstract": "Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) \u2026"}, {"title": "An Efficient Approach for Studying Cross-Lingual Transfer in Multilingual Language Models", "link": "https://arxiv.org/pdf/2403.20088", "details": "F Faisal, A Anastasopoulos - arXiv preprint arXiv:2403.20088, 2024", "abstract": "The capacity and effectiveness of pre-trained multilingual models (MLMs) for zero- shot cross-lingual transfer is well established. However, phenomena of positive or negative transfer, and the effect of language choice still need to be fully understood \u2026"}, {"title": "A Comparison of Parameter-Efficient ASR Domain Adaptation Methods for Universal Speech and Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10445894/", "details": "KC Sim, Z Huo, T Munkhdalai, N Siddhartha, A Stooke\u2026 - ICASSP 2024-2024 IEEE \u2026, 2024", "abstract": "A recent paradigm shift in artificial intelligence has seen the rise of foundation models, such as the large language models and the universal speech models. With billions of model parameters and trained with a wide range of data, these foundation \u2026"}, {"title": "Retrieval augmented text-to-SQL generation for epidemiological question answering using electronic health records", "link": "https://arxiv.org/pdf/2403.09226", "details": "A Ziletti, L D'Ambrosi - arXiv preprint arXiv:2403.09226, 2024", "abstract": "Electronic health records (EHR) and claims data are rich sources of real-world data that reflect patient health status and healthcare utilization. Querying these databases to answer epidemiological questions is challenging due to the intricacy of medical \u2026"}, {"title": "2 Unlocking information in electronic health records using natural language processing: a case study in medication information extraction", "link": "https://www.degruyter.com/document/doi/10.1515/9781614513902.33/pdf%3FlicenseType%3Drestricted", "details": "H Xu, JC Denny", "abstract": "Clinical natural language processing (NLP), which can unlock detailed patient information from clinical narratives stored in electronic health records, has been frequently used to support clinical research and operations. This chapter introduces \u2026"}, {"title": "DINGO: Towards Diverse and Fine-Grained Instruction-Following Evaluation", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29768/31322", "details": "Z Gu, X Sun, F Lian, Z Kang, C Xu, J Fan - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Instruction-following is particularly crucial for large language models (LLMs) to support diverse user requests. While existing work has made progress in aligning LLMs with human preferences, evaluating their capabilities on instruction-following \u2026"}, {"title": "Comparing Two Model Designs for Clinical Note Generation; Is an LLM a Useful Evaluator of Consistency?", "link": "https://arxiv.org/pdf/2404.06503", "details": "N Brake, T Schaaf - arXiv preprint arXiv:2404.06503, 2024", "abstract": "Following an interaction with a patient, physicians are responsible for the submission of clinical documentation, often organized as a SOAP note. A clinical note is not simply a summary of the conversation but requires the use of appropriate medical \u2026"}, {"title": "Few-Shot Recalibration of Language Models", "link": "https://arxiv.org/pdf/2403.18286", "details": "XL Li, U Khandelwal, K Guu - arXiv preprint arXiv:2403.18286, 2024", "abstract": "Recent work has uncovered promising ways to extract well-calibrated confidence estimates from language models (LMs), where the model's confidence score reflects how likely it is to be correct. However, while LMs may appear well-calibrated over \u2026"}]
