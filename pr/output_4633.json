[{"title": "Accurate diagnosis achieved via super-resolution whole slide images by pathologists and artificial intelligence", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/07/07/2024.07.05.24310022.full.pdf", "details": "kuansong wang, R LIU, Y chen, ying wang, yanning qiu\u2026 - medRxiv, 2024", "abstract": "Background: Digital pathology significantly improves diagnostic efficiency and accuracy; however, pathological tissue sections are scanned at high resolutions (HR), magnified by 40 times (40X) incurring high data volume, leading to storage \u2026"}, {"title": "Short-term effects of sunlight exposure on fundus blood flow perfusion in children: a randomised controlled trial", "link": "https://bjo.bmj.com/content/bjophthalmol/early/2024/07/09/bjo-2024-325715.full.pdf", "details": "L Zhao, B Zhang, J Wang, J Yang, L Du, T Wang, X Xu\u2026 - British Journal of \u2026, 2024", "abstract": "Aim To evaluate the short-term effects of different sunlight exposure on fundus blood flow perfusion (BFP) after near work. Methods In this parallel randomised controlled trial, 81 students aged 7\u201315 with spherical equivalent refraction between\u2212 2.00 and+ \u2026"}, {"title": "AutoTutor meets Large Language Models: A Language Model Tutor with Rich Pedagogy and Guardrails", "link": "https://dl.acm.org/doi/abs/10.1145/3657604.3662041", "details": "S Pal Chowdhury, V Zouhar, M Sachan - \u2026 of the Eleventh ACM Conference on \u2026, 2024", "abstract": "Large Language Models (LLMs) have found several use cases in education, ranging from automatic question generation to essay evaluation. In this paper, we explore the potential of using LLMs to author Intelligent Tutoring Systems. A common pitfall of \u2026"}, {"title": "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models", "link": "https://arxiv.org/pdf/2407.05131", "details": "P Xia, K Zhu, H Li, H Zhu, Y Li, G Li, L Zhang, H Yao - arXiv preprint arXiv:2407.05131, 2024", "abstract": "The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has enhanced medical diagnosis. However, current Med-LVLMs frequently encounter factual issues, often generating responses that do not align with established medical \u2026"}, {"title": "The Art of Saying No: Contextual Noncompliance in Language Models", "link": "https://arxiv.org/pdf/2407.12043", "details": "F Brahman, S Kumar, V Balachandran, P Dasigi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Chat-based language models are designed to be helpful, yet they should not comply with every user request. While most existing work primarily focuses on refusal of\" unsafe\" queries, we posit that the scope of noncompliance should be broadened. We \u2026"}, {"title": "MixPrompt: Enhancing Generalizability and Adversarial Robustness for Vision-Language Models via Prompt Fusion", "link": "https://link.springer.com/chapter/10.1007/978-981-97-5606-3_28", "details": "H Fan, Z Ma, Y Li, R Tian, Y Chen, C Gao - International Conference on Intelligent \u2026, 2024", "abstract": "Abstract Pretrained Vision-Language Models (VLMs) like CLIP have exhibited remarkable capacities across downstream tasks, while their image encoders are vulnerable to adversarial examples. A recently introduced lightweight approach \u2026"}, {"title": "XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training", "link": "https://arxiv.org/pdf/2407.19546", "details": "B Wu, Y Xie, Z Zhang, MH Phan, Q Chen, L Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-and-language pretraining (VLP) in the medical field utilizes contrastive learning on image-text pairs to achieve effective transfer across tasks. Yet, current VLP approaches with the masked modelling strategy face two challenges when \u2026"}]
