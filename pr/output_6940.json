[{"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "Application of Machine Learning Models to Predict E-Learning Engagement Using EEG Data", "link": "http://www.image.ece.ntua.gr/papers/1134.pdf", "details": "E Dritsas, M Trigka, P Mylonas", "abstract": "The rapid evolution of e-learning platforms necessitates the development of innovative methods to enhance learner engagement. This study leverages machine learning (ML) techniques and models to predict e-learning engagement using EEG \u2026"}, {"title": "Non-instructional Fine-tuning: Enabling Instruction-Following Capabilities in Pre-trained Language Models without Instruction-Following Data", "link": "https://arxiv.org/pdf/2409.00096", "details": "J Xie, S Syu, H Lee - arXiv preprint arXiv:2409.00096, 2024", "abstract": "Instruction fine-tuning is crucial for today's large language models (LLMs) to learn to follow instructions and align with human preferences. Conventionally, supervised data, including the instruction and the correct response, is required for instruction fine \u2026"}, {"title": "Two-Stage Medical Image-Text Transfer with Supervised Contrastive Learning", "link": "https://link.springer.com/chapter/10.1007/978-3-031-72353-7_32", "details": "X Wang, S Yin, Y Wang, J Li, S Li - International Conference on Artificial Neural \u2026, 2024", "abstract": "Cross-modal translation enables automatic information transformation across different modalities, including images, text, and speech, enabling various applications in the medical domain, such as medical image description and Medical \u2026"}]
