[{"title": "Multimodal Outer Arithmetic Block Dual Fusion of Whole Slide Images and Omics Data for Precision Oncology", "link": "https://arxiv.org/pdf/2411.17418", "details": "O Alwazzan, A Gallagher-Syed, T Millner, I Patras\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Developing a central nervous system (CNS) tumor classifier by integrating DNA methylation data with Whole Slide Images (WSI) offers significant potential for enhancing diagnostic precision in neuropathology. Existing approaches typically \u2026"}, {"title": "Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations", "link": "https://arxiv.org/pdf/2411.05261", "details": "Y Fang, Z Jin, S Guo, J Liu, Y Gao, J Ning, Z Yue, Z Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite significant advancements in report generation methods, a critical limitation remains: the lack of interpretability in the generated text. This paper introduces an innovative approach to enhance the explainability of text generated by report \u2026"}, {"title": "PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for Enhanced Survival Prediction from Histopathology Images", "link": "https://arxiv.org/pdf/2411.00749", "details": "A Krishna, NC Kurian, A Patil, A Parulekar, A Sethi - arXiv preprint arXiv:2411.00749, 2024", "abstract": "Accurate survival prediction is essential for personalized cancer treatment. However, genomic data-often a more powerful predictor than pathology data-is costly and inaccessible. We present the cross-modal genomic feature translation and alignment \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}, {"title": "Attention induction based on pathologist annotations for improving whole slide pathology image classifier", "link": "https://www.sciencedirect.com/science/article/pii/S215335392400052X", "details": "R Koga, T Yokota, K Arihiro, H Hontani - Journal of Pathology Informatics, 2024", "abstract": "We propose a method of attention induction to improve an attention mechanism in a whole slide image (WSI) classifier. Generally, only some regions in a WSI are useful for lesion classification, and the WSI classifier is required to find and focus on such \u2026"}, {"title": "Language-Emphasized Cross-Lingual In-Context Learning for Multilingual LLM", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9437-9_26", "details": "J Li, X Wei, X Wang, N Zhuang, L Wang, J Dang - CCF International Conference on \u2026, 2024", "abstract": "With the recent rise of large language models (LLMs), in-context learning (ICL) has shown remarkable performance, eliminating the need for fine-tuning parameters and reducing the reliance on extensive labeled data. However, the intricacies of cross \u2026"}, {"title": "Chain of Attack: On the Robustness of Vision-Language Models Against Transfer-Based Adversarial Attacks", "link": "https://arxiv.org/pdf/2411.15720", "details": "P Xie, Y Bie, J Mao, Y Song, Y Wang, H Chen, K Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained vision-language models (VLMs) have showcased remarkable performance in image and natural language understanding, such as image captioning and response generation. As the practical applications of vision-language \u2026"}]
