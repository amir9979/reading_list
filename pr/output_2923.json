[{"title": "QDA-SQL: Questions Enhanced Dialogue Augmentation for Multi-Turn Text-to-SQL", "link": "https://arxiv.org/pdf/2406.10593", "details": "Y Sun, Z Guo, H Yu, C Liu, X Li, B Wang, X Yu, T Zhao - arXiv preprint arXiv \u2026, 2024", "abstract": "Fine-tuning large language models (LLMs) for specific domain tasks has achieved great success in Text-to-SQL tasks. However, these fine-tuned models often face challenges with multi-turn Text-to-SQL tasks caused by ambiguous or unanswerable \u2026"}, {"title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models", "link": "https://aclanthology.org/2024.findings-naacl.18.pdf", "details": "Z Su, Z Lin, B Baixue, H Chen, S Hu, W Zhou, G Ding\u2026 - Findings of the Association \u2026, 2024", "abstract": "Generative language models are usually pre-trained on large text corpus via predicting the next token (ie, sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language \u2026"}, {"title": "TSCMamba: Mamba Meets Multi-View Learning for Time Series Classification", "link": "https://arxiv.org/pdf/2406.04419", "details": "MA Ahamed, Q Cheng - arXiv preprint arXiv:2406.04419, 2024", "abstract": "Time series classification (TSC) on multivariate time series is a critical problem. We propose a novel multi-view approach integrating frequency-domain and time-domain features to provide complementary contexts for TSC. Our method fuses continuous \u2026"}, {"title": "Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data", "link": "https://openreview.net/pdf%3Fid%3DsBJNokmYuV", "details": "J Zhang, Q Wei, F Liu, L Feng - Forty-first International Conference on Machine \u2026, 2024", "abstract": "Fine-tuning vision-language models (VLMs) with abundant unlabeled data recently has attracted increasing attention. Existing methods that resort to the pseudolabeling strategy would suffer from heavily incorrect hard pseudolabels when VLMs exhibit \u2026"}, {"title": "Why are Visually-Grounded Language Models Bad at Image Classification?", "link": "https://arxiv.org/pdf/2405.18415", "details": "Y Zhang, A Unell, X Wang, D Ghosh, Y Su, L Schmidt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Image classification is one of the most fundamental capabilities of machine vision intelligence. In this work, we revisit the image classification task using visually- grounded language models (VLMs) such as GPT-4V and LLaVA. We find that \u2026"}, {"title": "Visual-Text Cross Alignment: Refining the Similarity Score in Vision-Language Models", "link": "https://arxiv.org/pdf/2406.02915", "details": "J Li, H Li, S Erfani, L Feng, J Bailey, F Liu - arXiv preprint arXiv:2406.02915, 2024", "abstract": "It has recently been discovered that using a pre-trained vision-language model (VLM), eg, CLIP, to align a whole query image with several finer text descriptions generated by a large language model can significantly enhance zero-shot \u2026"}, {"title": "The Impact of Depth on Compositional Generalization in Transformer Language Models", "link": "https://aclanthology.org/2024.naacl-long.402.pdf", "details": "J Petty, S Steenkiste, I Dasgupta, F Sha, D Garrette\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "To process novel sentences, language models (LMs) must generalize compositionally\u2014combine familiar elements in new ways. What aspects of a model's structure promote compositional generalization? Focusing on transformers, we test \u2026"}, {"title": "Language Models as SPARQL Query Filtering for Improving the Quality of Multilingual Question Answering over Knowledge Graphs", "link": "https://link.springer.com/chapter/10.1007/978-3-031-62362-2_1", "details": "A Perevalov, A Gashkov, M Eltsova, A Both - International Conference on Web \u2026, 2024", "abstract": "Question Answering systems working over Knowledge Graphs (KGQA) generate a ranked list of SPARQL query candidates for a given natural-language question. In this paper, we follow our long-term research agenda of providing trustworthy KGQA \u2026"}, {"title": "ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models", "link": "https://aclanthology.org/2024.findings-naacl.261.pdf", "details": "MN Tran, PV Nguyen, L Nguyen, D Dien - Findings of the Association for \u2026, 2024", "abstract": "As the number of language models has increased, various benchmarks have been suggested to assess the proficiency of the models in natural language understanding. However, there is a lack of such a benchmark in Vietnamese due to \u2026"}]
