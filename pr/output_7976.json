[{"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "Tuning Language Models by Mixture-of-Depths Ensemble", "link": "https://arxiv.org/pdf/2410.13077", "details": "H Luo, L Specia - arXiv preprint arXiv:2410.13077, 2024", "abstract": "Transformer-based Large Language Models (LLMs) traditionally rely on final-layer loss for training and final-layer representations for predictions, potentially overlooking the predictive power embedded in intermediate layers. Surprisingly, we \u2026"}, {"title": "TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles", "link": "https://arxiv.org/pdf/2410.05262", "details": "Q Yu, S Song, K Fang, Y Shi, Z Zheng, H Wang, S Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the application of Large Language Models (LLMs) expands, the demand for reliable evaluations increases. Existing LLM evaluation benchmarks primarily rely on static datasets, making it challenging to assess model performance in dynamic \u2026"}, {"title": "Manual Verbalizer Enrichment for Few-Shot Text Classification", "link": "https://arxiv.org/pdf/2410.06173", "details": "QA Nguyen, N Tomeh, M Lebbah, T Charnois, H Azzag\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the continuous development of pre-trained language models, prompt-based training becomes a well-adopted paradigm that drastically improves the exploitation of models for many natural language processing tasks. Prompting also shows great \u2026"}, {"title": "The Role of Deductive and Inductive Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2410.02892", "details": "C Cai, X Zhao, H Liu, Z Jiang, T Zhang, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have achieved substantial progress in artificial intelligence, particularly in reasoning tasks. However, their reliance on static prompt structures, coupled with limited dynamic reasoning capabilities, often constrains their \u2026"}, {"title": "$\\beta $-calibration of Language Model Confidence Scores for Generative QA", "link": "https://arxiv.org/pdf/2410.06615", "details": "P Manggala, A Mastakouri, E Kirschbaum\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim \u2026"}, {"title": "Hyper Adversarial Tuning for Boosting Adversarial Robustness of Pretrained Large Vision Models", "link": "https://arxiv.org/pdf/2410.05951", "details": "K Lv, H Cao, K Tu, Y Xu, Z Zhang, X Ding, Y Wang - arXiv preprint arXiv:2410.05951, 2024", "abstract": "Large vision models have been found vulnerable to adversarial examples, emphasizing the need for enhancing their adversarial robustness. While adversarial training is an effective defense for deep convolutional models, it often faces \u2026"}, {"title": "An Inference Method for Professional Texts with Computational Expressions under Few-shot Scenarios", "link": "https://splab.sdu.edu.cn/calc_infer.pdf", "details": "L Yang, W Zheng, F Yuan, Y Sun", "abstract": "We propose an inference method for complex professional texts with computational expressions. We use the expert rules to locate and rewrite the expressions. We adopt the pre-trained language model as the initial model and select the high quality \u2026"}, {"title": "Communication-Efficient and Tensorized Federated Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2410.13097", "details": "S Ghiasvand, Y Yang, Z Xue, M Alizadeh, Z Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Parameter-efficient fine-tuning (PEFT) methods typically assume that Large Language Models (LLMs) are trained on data from a single device or client. However, real-world scenarios often require fine-tuning these models on private data \u2026"}]
