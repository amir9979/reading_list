[{"title": "Can Language Models Follow Multiple Turns of Entangled Instructions?", "link": "https://arxiv.org/pdf/2503.13222%3F", "details": "C Han - arXiv preprint arXiv:2503.13222, 2025", "abstract": "Despite significant achievements in improving the instruction-following capabilities of large language models (LLMs), the ability to process multiple potentially entangled or conflicting instructions remains a considerable challenge. Real-world scenarios \u2026"}, {"title": "How do language models learn facts? Dynamics, curricula and hallucinations", "link": "https://arxiv.org/pdf/2503.21676", "details": "N Zucchet, J Bornschein, S Chan, A Lampinen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models accumulate vast knowledge during pre-training, yet the dynamics governing this acquisition remain poorly understood. This work investigates the learning dynamics of language models on a synthetic factual recall \u2026"}, {"title": "Deep Contrastive Unlearning for Language Models", "link": "https://arxiv.org/pdf/2503.14900", "details": "E He, T Sarwar, I Khalil, X Yi, K Wang - arXiv preprint arXiv:2503.14900, 2025", "abstract": "The past a few years have witnessed the great success of large language models, demonstrating powerful capabilities in comprehending textual data and generating human-like languages. Large language models achieve success by being trained on \u2026"}, {"title": "Modeling Subjectivity in Cognitive Appraisal with Language Models", "link": "https://arxiv.org/pdf/2503.11381", "details": "Y Zhou, H Xu, DC Ong, P Slovak, Y He - arXiv preprint arXiv:2503.11381, 2025", "abstract": "As the utilization of language models in interdisciplinary, human-centered studies grow, the expectation of model capabilities continues to evolve. Beyond excelling at conventional tasks, models are recently expected to perform well on user-centric \u2026"}, {"title": "What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models", "link": "https://arxiv.org/pdf/2503.24235", "details": "Q Zhang, F Lyu, Z Sun, L Wang, W Zhang, Z Guo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as``test-time computing''has emerged as a prominent research focus. Recent studies demonstrate \u2026"}, {"title": "Agentic Large Language Models, a survey", "link": "https://arxiv.org/pdf/2503.23037", "details": "A Plaat, M van Duijn, N van Stein, M Preuss\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "There is great interest in agentic LLMs, large language models that act as agents. We review the growing body of work in this area and provide a research agenda. Agentic LLMs are LLMs that (1) reason,(2) act, and (3) interact. We organize the \u2026"}, {"title": "Reasoning Under 1 Billion: Memory-Augmented Reinforcement Learning for Large Language Models", "link": "https://arxiv.org/pdf/2504.02273", "details": "H Le, D Do, D Nguyen, S Venkatesh - arXiv preprint arXiv:2504.02273, 2025", "abstract": "Recent advances in fine-tuning large language models (LLMs) with reinforcement learning (RL) have shown promising improvements in complex reasoning tasks, particularly when paired with chain-of-thought (CoT) prompting. However, these \u2026"}, {"title": "$\\textit {Agents Under Siege} $: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks", "link": "https://arxiv.org/pdf/2504.00218", "details": "RMS Khan, Z Tan, S Yun, C Flemming, T Chen - arXiv preprint arXiv:2504.00218, 2025", "abstract": "Most discussions about Large Language Model (LLM) safety have focused on single- agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and \u2026"}, {"title": "Efficient and explainable sequential recommendation with language model", "link": "https://drive.google.com/file/d/11rlrXoCrYwH9mIJCDfw2gHwD8PCImjoK/view", "details": "Z Li, L Zou, C Ma, C Li - Information Processing & Management, 2025", "abstract": "Motivated by the outstanding success of large language models (LLMs) in a broad spectrum of NLP tasks, applying them for explainable recommendation become a cutting-edge recently. However, due to the inherent inconsistency in the information \u2026"}]
