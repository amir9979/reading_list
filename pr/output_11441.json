[{"title": "Guiding Medical Vision-Language Models with Explicit Visual Prompts: Framework Design and Comprehensive Exploration of Prompt Variations", "link": "https://arxiv.org/pdf/2501.02385", "details": "K Zhu, Z Qin, H Yi, Z Jiang, Q Lao, S Zhang, K Li - arXiv preprint arXiv:2501.02385, 2025", "abstract": "With the recent advancements in vision-language models (VLMs) driven by large language models (LLMs), many researchers have focused on models that comprised of an image encoder, an image-to-language projection layer, and a text decoder \u2026"}, {"title": "Multi-P $^ 2$ A: A Multi-perspective Benchmark on Privacy Assessment for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.19496", "details": "J Zhang, X Cao, Z Han, S Shan, X Chen - arXiv preprint arXiv:2412.19496, 2024", "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive potential across various tasks but also face significant privacy risks, limiting their practical applications. Current researches on privacy assessment for LVLMs is limited in scope, with gaps \u2026"}, {"title": "DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding", "link": "https://arxiv.org/pdf/2412.10302%3F", "details": "Z Wu, X Chen, Z Pan, X Liu, W Liu, D Dai, H Gao, Y Ma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades. For the vision component, we \u2026"}, {"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "link": "https://arxiv.org/pdf/2501.04322", "details": "M Rang, Z Bi, C Liu, Y Tang, K Han, Y Wang - arXiv preprint arXiv:2501.04322, 2025", "abstract": "Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are \u2026"}, {"title": "Training Medical Large Vision-Language Models with Abnormal-Aware Feedback", "link": "https://arxiv.org/pdf/2501.01377", "details": "Y Zhou, L Song, J Shen - arXiv preprint arXiv:2501.01377, 2025", "abstract": "Existing Medical Large Vision-Language Models (Med-LVLMs), which encapsulate extensive medical knowledge, demonstrate excellent capabilities in understanding medical images and responding to human queries based on these images \u2026"}, {"title": "PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation", "link": "https://arxiv.org/pdf/2412.15209%3F", "details": "M Wahed, KA Nguyen, AS Juvekar, X Li, X Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite significant advancements in Large Vision-Language Models (LVLMs), existing pixel-grounding models operate on single-image settings, limiting their ability to perform detailed, fine-grained comparisons across multiple images \u2026"}, {"title": "Rethinking Addressing in Language Models via Contexualized Equivariant Positional Encoding", "link": "https://arxiv.org/pdf/2501.00712", "details": "J Zhu, P Wang, R Cai, JD Lee, P Li, Z Wang - arXiv preprint arXiv:2501.00712, 2025", "abstract": "Transformers rely on both content-based and position-based addressing mechanisms to make predictions, but existing positional encoding techniques often diminish the effectiveness of position-based addressing. Many current methods \u2026"}, {"title": "Efficient Architectures for High Resolution Vision-Language Models", "link": "https://arxiv.org/pdf/2501.02584", "details": "M Carvalho, B Martins - arXiv preprint arXiv:2501.02584, 2025", "abstract": "Vision-Language Models (VLMs) have recently experienced significant advancements. However, challenges persist in the accurate recognition of fine details within high resolution images, which limits performance in multiple tasks. This \u2026"}, {"title": "GenEdit: Compounding Operators and Continuous Improvement to Tackle Text-to-SQL in the Enterprise", "link": "https://vldb.org/cidrdb/papers/2025/p28-maamari.pdf", "details": "K Maamari, C Landy, A Mhedhbi", "abstract": "Recent advancements in Text-to-SQL, driven by large language models, are democratizing data access. Despite these advancements, enterprise deployments remain challenging due to the need to capture business-specific knowledge, handle \u2026"}]
