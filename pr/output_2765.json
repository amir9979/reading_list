[{"title": "Interpretable Deep Clustering for Tabular Data", "link": "https://openreview.net/pdf%3Fid%3DQPy7zLfvof", "details": "J Svirsky, O Lindenbaum - Forty-first International Conference on Machine \u2026", "abstract": "Clustering is a fundamental learning task widely used as a first step in data analysis. For example, biologists use cluster assignments to analyze genome sequences, medical records, or images. Since downstream analysis is typically performed at the \u2026"}, {"title": "Why do Variational Autoencoders Really Promote Disentanglement?", "link": "https://openreview.net/pdf%3Fid%3DAo9UUaScAU", "details": "P Bhowal, A Soni, S Rambhatla - Forty-first International Conference on Machine \u2026", "abstract": "Despite not being designed for this purpose, the use of variational autoencoders (VAEs) has proven remarkably effective for disentangled representation learning (DRL). Recent research attributes this success to certain characteristics of the loss \u2026"}, {"title": "DiffAug: Enhance Unsupervised Contrastive Learning with Domain-Knowledge-Free Diffusion-based Data Augmentation", "link": "https://openreview.net/pdf%3Fid%3Ds0UDX7Kswl", "details": "Z Zang, H Luo, K Wang, P Zhang, F Wang, SZ Li, Y You - Forty-first International Conference \u2026", "abstract": "Unsupervised Contrastive learning has gained prominence in fields such as vision, and biology, leveraging predefined positive/negative samples for representation learning. Data augmentation, categorized into hand-designed and model-based \u2026"}, {"title": "Local vs. Global Interpretability: A Computational Complexity Perspective", "link": "https://arxiv.org/pdf/2406.02981", "details": "S Bassan, G Amir, G Katz - Forty-first International Conference on Machine \u2026, 2024", "abstract": "The local and global interpretability of various ML models has been studied extensively in recent years. However, despite significant progress in the field, many known results remain informal or lack sufficient mathematical rigor. We propose a \u2026"}, {"title": "Benchmarking Vision-Language Contrastive Methods for Medical Representation Learning", "link": "https://arxiv.org/pdf/2406.07450", "details": "S Roy, Y Parhizkar, F Ogidi, VR Khazaie, M Colacci\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We perform a comprehensive benchmarking of contrastive frameworks for learning multimodal representations in the medical domain. Through this study, we aim to answer the following research questions:(i) How transferable are general-domain \u2026"}, {"title": "GLAD: Towards Better Reconstruction with Global and Local Adaptive Diffusion Models for Unsupervised Anomaly Detection", "link": "https://arxiv.org/pdf/2406.07487", "details": "H Yao, M Liu, H Wang, Z Yin, Z Yan, X Hong, W Zuo - arXiv preprint arXiv:2406.07487, 2024", "abstract": "Diffusion models have shown superior performance on unsupervised anomaly detection tasks. Since trained with normal data only, diffusion models tend to reconstruct normal counterparts of test images with certain noises added. However \u2026"}]
