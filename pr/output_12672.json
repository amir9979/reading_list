[{"title": "Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models", "link": "https://arxiv.org/pdf/2501.17420", "details": "Y Li, H Shirado, S Das - arXiv preprint arXiv:2501.17420, 2025", "abstract": "While advances in fairness and alignment have helped mitigate overt biases exhibited by large language models (LLMs) when explicitly prompted, we hypothesize that these models may still exhibit implicit biases when simulating \u2026"}, {"title": "Reflection-Window Decoding: Text Generation with Selective Refinement", "link": "https://arxiv.org/pdf/2502.03678", "details": "Z Tang, Z Chen, L Li, X Song, Y Deng, Y Shen, G Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The autoregressive decoding for text generation in large language models (LLMs), while widely used, is inherently suboptimal due to the lack of a built-in mechanism to perform refinement and/or correction of the generated content. In this paper, we \u2026"}, {"title": "Exploring the Efficacy of Meta-Learning: Unveiling Superior Data Diversity Utilization of MAML Over Pre-training", "link": "https://arxiv.org/pdf/2501.08506", "details": "K Selva, S Vittayaareekul, B Miranda - arXiv preprint arXiv:2501.08506, 2025", "abstract": "Currently, data and model size dominate the narrative in the training of super-large, powerful models. However, there has been a lack of exploration on the effect of other attributes of the training dataset on model performance. We hypothesize that dataset \u2026"}, {"title": "Using Large Language Models to Promote Health Equity", "link": "https://ai.nejm.org/doi/abs/10.1056/AIp2400889", "details": "E Pierson, D Shanmugam, R Movva, J Kleinberg\u2026 - NEJM AI, 2025", "abstract": "While the discussion about the effects of large language models (LLMs) on health equity has been largely cautionary, LLMs also present significant opportunities for improving health equity. We highlight three such opportunities: improving the \u2026"}]
