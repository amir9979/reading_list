'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Impact of Preference Noise on the Alignment Performanc'
[{"title": "More Room for Language: Investigating the Effect of Retrieval on Language Models", "link": "https://arxiv.org/pdf/2404.10939", "details": "D Samuel, LGG Charpentier, S Wold - arXiv preprint arXiv:2404.10939, 2024", "abstract": "Retrieval-augmented language models pose a promising alternative to standard language modeling. During pretraining, these models search in a corpus of documents for contextually relevant information that could aid the language \u2026"}, {"title": "Dual Modalities of Text: Visual and Textual Generative Pre-training", "link": "https://arxiv.org/pdf/2404.10710", "details": "Y Chai, Q Liu, J Xiao, S Wang, Y Sun, H Wu - arXiv preprint arXiv:2404.10710, 2024", "abstract": "Harnessing visual texts represents a burgeoning frontier in the evolution of language modeling. In this paper, we introduce a novel pre-training framework for a suite of pixel-based autoregressive language models, pre-training on a corpus of over 400 \u2026"}, {"title": "Speech Recognition for Indigenous Language Using Self-Supervised Learning and Natural Language Processing", "link": "https://www.scitepress.org/Papers/2024/123963/123963.pdf", "details": "S Tamura, T Hattori, Y Kato, N Noguchi", "abstract": "This paper proposes a new concept to build a speech recognition system for an indigenous under-resourced language, by using another speech recognizer for a major language as well as neural machine translation and text autoencoder \u2026"}, {"title": "Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering", "link": "https://arxiv.org/pdf/2404.10193", "details": "Z Khan, Y Fu - arXiv preprint arXiv:2404.10193, 2024", "abstract": "The goal of selective prediction is to allow an a model to abstain when it may not be able to deliver a reliable prediction, which is important in safety-critical contexts. Existing approaches to selective prediction typically require access to the internals of \u2026"}, {"title": "MoE-TinyMed: Mixture of Experts for Tiny Medical Large Vision-Language Models", "link": "https://arxiv.org/pdf/2404.10237", "details": "S Jiang, T Zheng, Y Zhang, Y Jin, Z Liu - arXiv preprint arXiv:2404.10237, 2024", "abstract": "Mixture of Expert Tuning (MoE-Tuning) has effectively enhanced the performance of general MLLMs with fewer parameters, yet its application in resource-limited medical settings has not been fully explored. To address this gap, we developed MoE \u2026"}, {"title": "Calibrating Language Models With Adaptive Temperature Scaling", "link": "https://openreview.net/pdf%3Fid%3DBgfGqNpoMi", "details": "J Xie, AS Chen, Y Lee, E Mitchell, C Finn - ICLR 2024 Workshop on Secure and Trustworthy \u2026", "abstract": "The effectiveness of large language models (LLMs) is not only measured by their ability to generate accurate outputs but also by their calibration\u2014how well their confidence scores reflect the probability of their outputs being correct. While \u2026"}, {"title": "Large language models leverage external knowledge to extend clinical insight beyond language boundaries", "link": "https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae079/7659846", "details": "J Wu, X Wu, Z Qiu, M Li, S Lin, Y Zhang, Y Zheng\u2026 - Journal of the American \u2026, 2024", "abstract": "Abstract Objectives Large Language Models (LLMs) such as ChatGPT and Med- PaLM have excelled in various medical question-answering tasks. However, these English-centric models encounter challenges in non-English clinical settings \u2026"}, {"title": "Foundational challenges in assuring alignment and safety of large language models", "link": "https://arxiv.org/pdf/2404.09932", "details": "U Anwar, A Saparov, J Rando, D Paleka, M Turpin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This work identifies 18 foundational challenges in assuring the alignment and safety of large language models (LLMs). These challenges are organized into three different categories: scientific understanding of LLMs, development and deployment \u2026"}, {"title": "Language Imbalance Can Boost Cross-lingual Generalisation", "link": "https://arxiv.org/pdf/2404.07982", "details": "A Sch\u00e4fer, S Ravfogel, T Hofmann, T Pimentel, I Schlag - arXiv preprint arXiv \u2026, 2024", "abstract": "Multilinguality is crucial for extending recent advancements in language modelling to diverse linguistic communities. To maintain high performance while representing multiple languages, multilingual models ideally align representations, allowing what \u2026"}]
