[{"title": "Multi-P $^ 2$ A: A Multi-perspective Benchmark on Privacy Assessment for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.19496", "details": "J Zhang, X Cao, Z Han, S Shan, X Chen - arXiv preprint arXiv:2412.19496, 2024", "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive potential across various tasks but also face significant privacy risks, limiting their practical applications. Current researches on privacy assessment for LVLMs is limited in scope, with gaps \u2026"}, {"title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models", "link": "https://arxiv.org/pdf/2501.05752", "details": "S Lee, H Park, J Kim, J Ok - arXiv preprint arXiv:2501.05752, 2025", "abstract": "Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer \u2026"}, {"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "link": "https://arxiv.org/pdf/2501.04322", "details": "M Rang, Z Bi, C Liu, Y Tang, K Han, Y Wang - arXiv preprint arXiv:2501.04322, 2025", "abstract": "Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are \u2026"}, {"title": "Training Medical Large Vision-Language Models with Abnormal-Aware Feedback", "link": "https://arxiv.org/pdf/2501.01377", "details": "Y Zhou, L Song, J Shen - arXiv preprint arXiv:2501.01377, 2025", "abstract": "Existing Medical Large Vision-Language Models (Med-LVLMs), which encapsulate extensive medical knowledge, demonstrate excellent capabilities in understanding medical images and responding to human queries based on these images \u2026"}, {"title": "PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation", "link": "https://arxiv.org/pdf/2412.15209%3F", "details": "M Wahed, KA Nguyen, AS Juvekar, X Li, X Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite significant advancements in Large Vision-Language Models (LVLMs), existing pixel-grounding models operate on single-image settings, limiting their ability to perform detailed, fine-grained comparisons across multiple images \u2026"}, {"title": "Rethinking Addressing in Language Models via Contexualized Equivariant Positional Encoding", "link": "https://arxiv.org/pdf/2501.00712", "details": "J Zhu, P Wang, R Cai, JD Lee, P Li, Z Wang - arXiv preprint arXiv:2501.00712, 2025", "abstract": "Transformers rely on both content-based and position-based addressing mechanisms to make predictions, but existing positional encoding techniques often diminish the effectiveness of position-based addressing. Many current methods \u2026"}, {"title": "Efficient Architectures for High Resolution Vision-Language Models", "link": "https://arxiv.org/pdf/2501.02584", "details": "M Carvalho, B Martins - arXiv preprint arXiv:2501.02584, 2025", "abstract": "Vision-Language Models (VLMs) have recently experienced significant advancements. However, challenges persist in the accurate recognition of fine details within high resolution images, which limits performance in multiple tasks. This \u2026"}, {"title": "Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models", "link": "https://arxiv.org/pdf/2412.14133", "details": "I Cohen, D Gottesman, M Geva, R Giryes - arXiv preprint arXiv:2412.14133, 2024", "abstract": "Vision-language models (VLMs) excel at extracting and reasoning about information from images. Yet, their capacity to leverage internal knowledge about specific entities remains underexplored. This work investigates the disparity in model performance \u2026"}, {"title": "Utility-inspired Reward Transformations Improve Reinforcement Learning Training of Language Models", "link": "https://arxiv.org/pdf/2501.06248", "details": "RR Maura-Rivero, C Nagpal, R Patel, F Visin - arXiv preprint arXiv:2501.06248, 2025", "abstract": "Current methods that train large language models (LLMs) with reinforcement learning feedback, often resort to averaging outputs of multiple rewards functions during training. This overlooks crucial aspects of individual reward dimensions and \u2026"}]
