[{"title": "The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer", "link": "https://arxiv.org/pdf/2504.10462", "details": "W Lei, J Wang, H Wang, X Li, JH Liew, J Feng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces SAIL, a single transformer unified multimodal large language model (MLLM) that integrates raw pixel encoding and language decoding within a singular architecture. Unlike existing modular MLLMs, which rely on a pre-trained \u2026"}, {"title": "Zero-shot 3D Scene Representation with Invertible Generative Neural Radiance Fields", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10967257.pdf", "details": "K Ko, S Kim, M Lee - IEEE Access, 2025", "abstract": "Generative Neural Radiance Fields (NeRFs) have recently enabled efficient synthesis of 3D scenes by training on unposed real image sets. However, existing methods for generating multi-view images of specific input images have limitations \u2026"}, {"title": "Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization", "link": "https://arxiv.org/pdf/2505.05017", "details": "Y Bao, X Zhang, T Du, X Zhao, J Zong, H Peng, J Yin - arXiv preprint arXiv \u2026, 2025", "abstract": "Pre-trained large language models (LLMs) are commonly fine-tuned to adapt to downstream tasks. Since the majority of knowledge is acquired during pre-training, attributing the predictions of fine-tuned LLMs to their pre-training data may provide \u2026"}, {"title": "PonderV2: Improved 3D Representation with A Universal Pre-training Paradigm", "link": "https://ieeexplore.ieee.org/abstract/document/10969802/", "details": "H Zhu, H Yang, X Wu, D Huang, S Zhang, X He\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "In contrast to numerous NLP and 2D vision foundational models, training a 3D foundational model poses considerably greater challenges. This is primarily due to the inherent data variability and diversity of downstream tasks. In this paper, we \u2026"}, {"title": "Knowledge-enhanced Parameter-efficient Transfer Learning with METER for medical vision-language tasks", "link": "https://www.sciencedirect.com/science/article/pii/S1532046425000693", "details": "X Liang, J Xie, J Wei, M Zhang, H Zhang - Journal of Biomedical Informatics, 2025", "abstract": "Objective: The full fine-tuning paradigm becomes impractical when applying pre- trained models to downstream tasks due to significant computational and storage costs. Parameter-efficient fine-tuning (PEFT) methods can alleviate the issue \u2026"}, {"title": "Low-hallucination Synthetic Captions for Large-Scale Vision-Language Model Pre-training", "link": "https://arxiv.org/pdf/2504.13123%3F", "details": "X Zhang, Y Zeng, X Huang, H Hu, R Xie, H Hu, Z Kang - arXiv preprint arXiv \u2026, 2025", "abstract": "In recent years, the field of vision-language model pre-training has experienced rapid advancements, driven primarily by the continuous enhancement of textual capabilities in large language models. However, existing training paradigms for \u2026"}, {"title": "Cross-Institutional Evaluation of Large Language Models for Radiology Diagnosis Extraction: A Prompt-Engineering Perspective", "link": "https://link.springer.com/article/10.1007/s10278-025-01523-5", "details": "M Moassefi, S Houshmand, S Faghani, PD Chang\u2026 - Journal of Imaging \u2026, 2025", "abstract": "The rapid evolution of large language models (LLMs) offers promising opportunities for radiology report annotation, aiding in determining the presence of specific findings. This study evaluates the effectiveness of a human-optimized prompt in \u2026"}, {"title": "Unleashing the potential of prompt engineering for large language models", "link": "https://www.cell.com/patterns/fulltext/S2666-3899\\(25\\)00108-4", "details": "B Chen, Z Zhang, N Langren\u00e9, S Zhu - Patterns, 2025", "abstract": "This review explores the role of prompt engineering in unleashing the capabilities of large language models (LLMs). Prompt engineering is the process of structuring inputs, and it has emerged as a crucial technique for maximizing the utility and \u2026"}, {"title": "DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting", "link": "https://arxiv.org/pdf/2504.10486", "details": "Z Jiang, S Wang, S Tang - arXiv preprint arXiv:2504.10486, 2025", "abstract": "Creating relightable and animatable human avatars from monocular videos is a rising research topic with a range of applications, eg virtual reality, sports, and video games. Previous works utilize neural fields together with physically based rendering \u2026"}]
