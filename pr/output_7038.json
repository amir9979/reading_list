[{"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "Few-shot Adaptation of Medical Vision-Language Models", "link": "https://arxiv.org/pdf/2409.03868", "details": "F Shakeri, Y Huang, J Silva-Rodr\u00edguez, H Bahig\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Integrating image and text data through multi-modal learning has emerged as a new approach in medical imaging research, following its successful deployment in computer vision. While considerable efforts have been dedicated to establishing \u2026"}, {"title": "VTPL: Visual and Text Prompt Learning for visual-language models", "link": "https://www.sciencedirect.com/science/article/pii/S1047320324002360", "details": "B Sun, Z Wu, H Zhang, J He - Journal of Visual Communication and Image \u2026, 2024", "abstract": "Visual-language (VL) models have achieved remarkable success in learning combined visual\u2013textual representations from large web datasets. Prompt learning, as a solution for downstream tasks, can address the forgetting of knowledge \u2026"}, {"title": "Empirical Insights on Fine-Tuning Large Language Models for Question-Answering", "link": "https://arxiv.org/pdf/2409.15825", "details": "J Ye, Y Yang, Q Zhang, T Gui, X Huang, P Wang, Z Shi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) encode extensive world knowledge through pre- training on massive datasets, which can then be fine-tuned for the question- answering (QA) task. However, effective strategies for fine-tuning LLMs for the QA \u2026"}, {"title": "LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs", "link": "https://arxiv.org/pdf/2409.06323", "details": "S Li, JD Park, W Huang, X Cao, WY Shin, Z Xu - arXiv preprint arXiv:2409.06323, 2024", "abstract": "Heterogeneous graph neural networks (HGNNs) have significantly propelled the information retrieval (IR) field. Still, the effectiveness of HGNNs heavily relies on high- quality labels, which are often expensive to acquire. This challenge has shifted \u2026"}, {"title": "Exploring Hint Generation Approaches in Open-Domain Question Answering", "link": "https://arxiv.org/pdf/2409.16096", "details": "J Mozafari, A Abdallah, B Piryani, A Jatowt - arXiv preprint arXiv:2409.16096, 2024", "abstract": "Automatic Question Answering (QA) systems rely on contextual information to provide accurate answers. Commonly, contexts are prepared through either retrieval- based or generation-based methods. The former involves retrieving relevant \u2026"}, {"title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models", "link": "https://arxiv.org/pdf/2408.15778", "details": "J Gui, Y Liu, J Cheng, X Gu, X Liu, H Wang, Y Dong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across various tasks, showcasing complex problem-solving abilities. Understanding and executing complex rules, along with multi-step planning, are fundamental to logical \u2026"}]
