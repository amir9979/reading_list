[{"title": "Improving Context-Aware Preference Modeling for Language Models", "link": "https://arxiv.org/pdf/2407.14916", "details": "S Pitis, Z Xiao, NL Roux, A Sordoni - arXiv preprint arXiv:2407.14916, 2024", "abstract": "While finetuning language models from pairwise preferences has proven remarkably effective, the underspecified nature of natural language presents critical challenges. Direct preference feedback is uninterpretable, difficult to provide where \u2026"}, {"title": "Language models are robotic planners: reframing plans as goal refinement graphs", "link": "https://arxiv.org/pdf/2407.15677", "details": "A Sharfuddin, T Breaux - arXiv preprint arXiv:2407.15677, 2024", "abstract": "Successful application of large language models (LLMs) to robotic planning and execution may pave the way to automate numerous real-world tasks. Promising recent research has been conducted showing that the knowledge contained in LLMs \u2026"}, {"title": "Can Language Models Safeguard Themselves, Instantly and For Free?", "link": "https://openreview.net/pdf%3Fid%3DALRWSxT1rl", "details": "D Adila, C Shin, Y Zhang, F Sala - ICML 2024 Next Generation of AI Safety Workshop", "abstract": "Aligning pretrained language models (LMs) to handle a new safety scenario is normally difficult and expensive, often requiring access to large amounts of ground- truth preference data and substantial compute. Are these costs necessary? That is, is \u2026"}, {"title": "Imposter. AI: Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models", "link": "https://arxiv.org/pdf/2407.15399", "details": "X Liu, L Li, T Xiang, F Ye, L Wei, W Li, N Garcia - arXiv preprint arXiv:2407.15399, 2024", "abstract": "With the development of large language models (LLMs) like ChatGPT, both their vast applications and potential vulnerabilities have come to the forefront. While developers have integrated multiple safety mechanisms to mitigate their misuse, a \u2026"}, {"title": "Reinforced Prompt Personalization for Recommendation with Large Language Models", "link": "https://arxiv.org/pdf/2407.17115", "details": "W Mao, J Wu, W Chen, C Gao, X Wang, X He - arXiv preprint arXiv:2407.17115, 2024", "abstract": "Designing effective prompts can empower LLMs to understand user preferences and provide recommendations by leveraging LLMs' intent comprehension and knowledge utilization capabilities. However, existing research predominantly \u2026"}, {"title": "The Art of Refusal: A Survey of Abstention in Large Language Models", "link": "https://arxiv.org/pdf/2407.18418", "details": "B Wen, J Yao, S Feng, C Xu, Y Tsvetkov, B Howe\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Abstention, the refusal of large language models (LLMs) to provide an answer, is increasingly recognized for its potential to mitigate hallucinations and enhance safety in building LLM systems. In this survey, we introduce a framework to examine \u2026"}, {"title": "Internal Consistency and Self-Feedback in Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2407.14507", "details": "X Liang, S Song, Z Zheng, H Wang, Q Yu, X Li, RH Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) are expected to respond accurately but often exhibit deficient reasoning or generate hallucinatory content. To address these, studies prefixed with``Self-''such as Self-Consistency, Self-Improve, and Self-Refine have \u2026"}, {"title": "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching", "link": "https://arxiv.org/pdf/2407.17349", "details": "Y Ding, H Hu, J Zhou, Q Chen, B Jiang, L He - arXiv preprint arXiv:2407.17349, 2024", "abstract": "With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem \u2026"}, {"title": "UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models", "link": "https://arxiv.org/pdf/2407.16160", "details": "L Qi, H Yongyi, L Defu, Z Zhi, X Tong, L Che, C Enhong - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Entity Linking (MEL) is a crucial task that aims at linking ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on using \u2026"}]
