[{"title": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "link": "https://arxiv.org/pdf/2504.07416%3F", "details": "J Park, S Kim, B Yoon, K Choi - arXiv preprint arXiv:2504.07416, 2025", "abstract": "Recent advancements in multi-modal models have significantly improved vision- language alignment in radiology. However, existing approaches struggle to effectively utilize complex radiology reports for learning, rely on low-resolution \u2026"}, {"title": "Leveraging long context in retrieval augmented language models for medical question answering", "link": "https://www.nature.com/articles/s41746-025-01651-w", "details": "G Zhang, Z Xu, Q Jin, F Chen, Y Fang, Y Liu\u2026 - npj Digital Medicine, 2025", "abstract": "While holding great promise for improving and facilitating healthcare through applications of medical literature summarization, large language models (LLMs) struggle to produce up-to-date responses on evolving topics due to outdated \u2026"}, {"title": "Honey, I Shrunk the Language Model: Impact of Knowledge Distillation Methods on Performance and Explainability", "link": "https://arxiv.org/pdf/2504.16056", "details": "D Hendriks, P Spitzer, N K\u00fchl, G Satzger - arXiv preprint arXiv:2504.16056, 2025", "abstract": "Artificial Intelligence (AI) has increasingly influenced modern society, recently in particular through significant advancements in Large Language Models (LLMs). However, high computational and storage demands of LLMs still limit their \u2026"}, {"title": "How to Detect and Defeat Molecular Mirage: A Metric-Driven Benchmark for Hallucination in LLM-based Molecular Comprehension", "link": "https://arxiv.org/pdf/2504.12314%3F", "details": "H Li, L Lv, H Cao, Z Liu, Z Yan, Y Wang, Y Tian, Y Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models are increasingly used in scientific domains, especially for molecular understanding and analysis. However, existing models are affected by hallucination issues, resulting in errors in drug design and utilization. In this paper \u2026"}, {"title": "Leveraging Generative Pre-trained Transformer (GPT) Large Language Models (LLMs) For Interstitial Lung Diseases (ILD) Clinical Research", "link": "https://www.atsjournals.org/doi/abs/10.1164/ajrccm.2025.211.Abstracts.A2086", "details": "S Chen, MV Maddali, C Bluethgen, CP Langlotz, R Raj - American Journal of \u2026, 2025", "abstract": "Rationale: The majority of clinically relevant data is contained in unstructured text such as clinical notes. ILD notes are particularly prone to verbosity and imprecision, making structured data extraction a major bottleneck for clinical research and a costly \u2026"}, {"title": "Can large language models independently complete tasks? A dynamic evaluation framework for multi-turn task planning and completion", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225008070", "details": "J Gao, J Cui, H Wu, L Xiang, H Zhao, X Li, M Fang\u2026 - Neurocomputing, 2025", "abstract": "Large language models (LLMs) are increasingly relied upon for multi-turn dialogue to conduct complex tasks. However, existing benchmarks mainly evaluate LLMs as agents, overlooking their potential as independent systems to accomplish complex \u2026"}, {"title": "Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs", "link": "https://arxiv.org/pdf/2504.07866%3F", "details": "Y Yin, W Huang, K Song, Y Tang, X Wu, W Guo, P Guo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present Pangu Ultra, a Large Language Model (LLM) with 135 billion parameters and dense Transformer modules trained on Ascend Neural Processing Units (NPUs). Although the field of LLM has been witnessing unprecedented advances in pushing \u2026"}, {"title": "DeepCritic: Deliberate Critique with Large Language Models", "link": "https://arxiv.org/pdf/2505.00662", "details": "W Yang, J Chen, Y Lin, JR Wen - arXiv preprint arXiv:2505.00662, 2025", "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem. Leveraging LLMs as critique models to achieve automated supervision is a \u2026"}, {"title": "Theory of Mind in Large Language Models: Assessment and Enhancement", "link": "https://arxiv.org/pdf/2505.00026", "details": "R Chen, W Jiang, C Qin, C Tan - arXiv preprint arXiv:2505.00026, 2025", "abstract": "Theory of Mind (ToM)-the ability to infer and reason about others' mental states-is fundamental to human social intelligence. As Large Language Models (LLMs) become increasingly integrated into daily life, it is crucial to assess and enhance \u2026"}]
