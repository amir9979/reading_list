[{"title": "Vision-Language Models for Automated Chest X-ray Interpretation: Leveraging ViT and GPT-2", "link": "https://arxiv.org/pdf/2501.12356", "details": "MR Islam, MZ Hossain, M Ahmed, M Samu, S Sultana - arXiv preprint arXiv \u2026, 2025", "abstract": "Radiology plays a pivotal role in modern medicine due to its non-invasive diagnostic capabilities. However, the manual generation of unstructured medical reports is time consuming and prone to errors. It creates a significant bottleneck in clinical \u2026"}, {"title": "Neural codec language models are zero-shot text to speech synthesizers", "link": "https://ieeexplore.ieee.org/abstract/document/10842513/", "details": "S Chen, C Wang, Y Wu, Z Zhang, L Zhou, S Liu\u2026 - IEEE Transactions on Audio \u2026, 2025", "abstract": "We introduce a language modeling approach for text to speech synthesis (TTS). Specifically, we train a neural codec language model (called VALL-E) using discrete codes derived from an off-the-shelf neural audio codec model, and regard TTS as a \u2026"}, {"title": "MedFILIP: Medical Fine-Grained Language-Image Pre-Training", "link": "https://arxiv.org/pdf/2501.10775", "details": "X Liang, X Li, F Li, J Jiang, Q Dong, W Wang, K Wang\u2026 - IEEE Journal of Biomedical \u2026, 2025", "abstract": "Medical vision-language pretraining (VLP) that leverages naturally-paired medical image-report data is crucial for medical image analysis. However, existing methods struggle to accurately characterize associations between images and diseases \u2026"}, {"title": "A dataset and benchmark for hospital course summarization with adapted large language models", "link": "https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae312/7934937", "details": "A Aali, D Van Veen, YI Arefeen, J Hom, C Bluethgen\u2026 - Journal of the American \u2026, 2024", "abstract": "Objective Brief hospital course (BHC) summaries are clinical documents that summarize a patient's hospital stay. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for \u2026"}, {"title": "Towards normalized clinical information extraction in Chinese radiology report with large language models", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002076", "details": "Q Xu, X Xu, C Zhou, Z Liu, F Huang, S Li, L Zhu, Z Bai\u2026 - Expert Systems with \u2026, 2025", "abstract": "Radiology reports serve as a fundamental component within electronic medical records. Converting unstructured free-text reports into structured formats holds paramount importance for the management and utilization of radiology reports. In this \u2026"}, {"title": "Towards Compatible Fine-tuning for Vision-Language Model Updates", "link": "https://arxiv.org/pdf/2412.20895", "details": "Z Wang, J Liang, L Sheng, R He, Z Wang, T Tan - arXiv preprint arXiv:2412.20895, 2024", "abstract": "So far, efficient fine-tuning has become a popular strategy for enhancing the capabilities of foundation models on downstream tasks by learning plug-and-play modules. However, existing methods overlook a crucial issue: if the underlying \u2026"}]
