'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Consistency and Uncertainty: Identifying Unreliable Re'
[{"title": "THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2405.05256", "details": "P Kaul, Z Li, H Yang, Y Dukler, A Swaminathan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Mitigating hallucinations in large vision-language models (LVLMs) remains an open problem. Recent benchmarks do not address hallucinations in open-ended free-form responses, which we term\" Type I hallucinations\". Instead, they focus on \u2026"}, {"title": "Can Language Models Solve Olympiad Programming?", "link": "https://arxiv.org/pdf/2404.10952", "details": "Q Shi, M Tang, K Narasimhan, S Yao - arXiv preprint arXiv:2404.10952, 2024", "abstract": "Computing olympiads contain some of the most challenging problems for humans, requiring complex algorithmic reasoning, puzzle solving, in addition to generating efficient code. However, it has been understudied as a domain to evaluate language \u2026"}, {"title": "KS-LLM: Knowledge Selection of Large Language Models with Evidence Document for Question Answering", "link": "https://arxiv.org/pdf/2404.15660", "details": "X Zheng, F Che, J Wu, S Zhang, S Nie, K Liu, J Tao - arXiv preprint arXiv:2404.15660, 2024", "abstract": "Large language models (LLMs) suffer from the hallucination problem and face significant challenges when applied to knowledge-intensive tasks. A promising approach is to leverage evidence documents as extra supporting knowledge, which \u2026"}, {"title": "A Progressive Framework of Vision-language Knowledge Distillation and Alignment for Multilingual Scene", "link": "https://arxiv.org/pdf/2404.11249", "details": "W Zhang, Y Zhang, J Lin, B Huang, J Zhang, W Yu - arXiv preprint arXiv:2404.11249, 2024", "abstract": "Pre-trained vision-language (VL) models such as CLIP have shown excellent performance in many downstream cross-modal tasks. However, most of them are only applicable to the English context. Subsequent research has focused on this \u2026"}, {"title": "Self-playing Adversarial Language Game Enhances LLM Reasoning", "link": "https://arxiv.org/pdf/2404.10642", "details": "P Cheng, T Hu, H Xu, Z Zhang, Y Dai, L Han, N Du - arXiv preprint arXiv:2404.10642, 2024", "abstract": "We explore the self-play training procedure of large language models (LLMs) in a two-player adversarial language game called Adversarial Taboo. In this game, an attacker and a defender communicate with respect to a target word only visible to the \u2026"}, {"title": "Zero-shot LLM-guided Counterfactual Generation for Text", "link": "https://arxiv.org/pdf/2405.04793", "details": "A Bhattacharjee, R Moraffah, J Garland, H Liu - arXiv preprint arXiv:2405.04793, 2024", "abstract": "Counterfactual examples are frequently used for model development and evaluation in many natural language processing (NLP) tasks. Although methods for automated counterfactual generation have been explored, such methods depend on models \u2026"}, {"title": "Consistency Training by Synthetic Question Generation for Conversational Question Answering", "link": "https://arxiv.org/pdf/2404.11109", "details": "HH Hemati, H Beigy - arXiv preprint arXiv:2404.11109, 2024", "abstract": "Efficiently modeling historical information is a critical component in addressing user queries within a conversational question-answering (QA) context, as historical context plays a vital role in clarifying the user's questions. However, irrelevant history \u2026"}, {"title": "Predicting future disorders via temporal knowledge graphs and medical ontologies", "link": "https://ieeexplore.ieee.org/iel7/6221020/6363502/10504898.pdf", "details": "M Postiglione, D Bean, Z Kraljevic, RJB Dobson\u2026 - IEEE Journal of Biomedical \u2026, 2024", "abstract": "Despite the vast potential for insights and value present in Electronic Health Records (EHRs), it is challenging to fully leverage all the available information, particularly that contained in the free-text data written by clinicians describing the health status of \u2026"}, {"title": "MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning", "link": "https://arxiv.org/pdf/2405.05189", "details": "I Nair, L Wang - arXiv preprint arXiv:2405.05189, 2024", "abstract": "We study the task of conducting structured reasoning as generating a reasoning graph from natural language input using large language models (LLMs). Previous approaches have explored various prompting schemes, yet they suffer from error \u2026"}]
