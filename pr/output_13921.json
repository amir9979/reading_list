[{"title": "Towards Scalable and Cross-Lingual Specialist Language Models for Oncology", "link": "https://arxiv.org/pdf/2503.08323", "details": "M Rohanian, T Mehra, N Miglino, F Nooralahzadeh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Clinical oncology generates vast, unstructured data that often contain inconsistencies, missing information, and ambiguities, making it difficult to extract reliable insights for data-driven decision-making. General-purpose large language \u2026"}, {"title": "\" See the World, Discover Knowledge\": A Chinese Factuality Evaluation for Large Vision Language Models", "link": "https://arxiv.org/pdf/2502.11718", "details": "J Gu, Y Wang, P Bu, C Wang, Z Wang, T Song, D Wei\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The evaluation of factual accuracy in large vision language models (LVLMs) has lagged behind their rapid development, making it challenging to fully reflect these models' knowledge capacity and reliability. In this paper, we introduce the first \u2026"}, {"title": "Stackelberg Game Preference Optimization for Data-Efficient Alignment of Language Models", "link": "https://arxiv.org/pdf/2502.18099", "details": "X Chu, Z Zhang, T Jia, Y Jin - arXiv preprint arXiv:2502.18099, 2025", "abstract": "Aligning language models with human preferences is critical for real-world deployment, but existing methods often require large amounts of high-quality human annotations. Aiming at a data-efficient alignment method, we propose Stackelberg \u2026"}, {"title": "Multilingual Language Model Pretraining using Machine-translated Data", "link": "https://arxiv.org/pdf/2502.13252", "details": "J Wang, Y Lu, M Weber, M Ryabinin, D Adelani\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "High-resource languages such as English, enables the pretraining of high-quality large language models (LLMs). The same can not be said for most other languages as LLMs still underperform for non-English languages, likely due to a gap in the \u2026"}, {"title": "Evaluating BERT-based language models for detecting misinformation", "link": "https://link.springer.com/article/10.1007/s00521-025-11101-z", "details": "R Anggrainingsih, GM Hassan, A Datta - Neural Computing and Applications, 2025", "abstract": "Online misinformation poses a significant challenge due to its rapid spread and limited supervision. To address this issue, automated rumour detection techniques are essential for countering the negative impact of false information. Previous \u2026"}, {"title": "Transfer-Prompting: Enhancing Cross-Task Adaptation in Large Language Models via Dual-Stage Prompts Optimization", "link": "https://arxiv.org/pdf/2502.14211", "details": "Y Chang, Y Chang, Y Wu - arXiv preprint arXiv:2502.14211, 2025", "abstract": "Large language models (LLMs) face significant challenges when balancing multiple high-level objectives, such as generating coherent, relevant, and high-quality responses while maintaining efficient task adaptation across diverse tasks. To \u2026"}, {"title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.18439", "details": "C Park, S Han, X Guo, A Ozdaglar, K Zhang, JK Kim - arXiv preprint arXiv:2502.18439, 2025", "abstract": "Leveraging multiple large language models (LLMs) to build collaborative multi- agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability \u2026"}, {"title": "Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval", "link": "https://arxiv.org/pdf/2502.13369", "details": "A Sharma, L Lara, A Zouaq, CJ Pal - arXiv preprint arXiv:2502.13369, 2025", "abstract": "The ability to generate SPARQL queries from natural language questions is crucial for ensuring efficient and accurate retrieval of structured data from knowledge graphs (KG). While large language models (LLMs) have been widely adopted for SPARQL \u2026"}, {"title": "ToolScan: A Benchmark For Characterizing Errors In Tool-Use LLMs", "link": "https://openreview.net/pdf%3Fid%3D09tnQgqKuZ", "details": "S Kokane, M Zhu, TM Awalgaonkar, J Zhang\u2026 - ICLR 2025 Workshop on Building \u2026", "abstract": "Evaluating Large Language Models (LLMs) is one of the most critical aspects of building a performant compound AI system. Since the output from LLMs propagate to downstream steps, identifying LLM errors is crucial to system performance. A \u2026"}]
