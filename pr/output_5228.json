[{"title": "Attribute-guided prototype network for few-shot molecular property prediction", "link": "https://academic.oup.com/bib/article/25/5/bbae394/7731658", "details": "L Hou, H Xiang, X Zeng, D Cao, L Zeng, B Song - Briefings in Bioinformatics, 2024", "abstract": "The molecular property prediction (MPP) plays a crucial role in the drug discovery process, providing valuable insights for molecule evaluation and screening. Although deep learning has achieved numerous advances in this area, its success \u2026"}, {"title": "Scalable information extraction from free text electronic health records using large language models", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/08/10/2024.08.08.24311237.full.pdf", "details": "B Gu, V Shao, Z Liao, V Carducci, S Romero-Brufau\u2026 - medRxiv, 2024", "abstract": "Background: A vast amount of potentially useful information such as description of patient symptoms, family, and social history is recorded as free-text notes in electronic health records (EHRs) but is difficult to reliably extract at scale, limiting \u2026"}, {"title": "Accuracy and transportability of machine learning models for adolescent suicide prediction with longitudinal clinical records", "link": "https://www.nature.com/articles/s41398-024-03034-3", "details": "C Zang, Y Hou, D Lyu, J Jin, S Sacco, K Chen\u2026 - Translational psychiatry, 2024", "abstract": "Abstract Machine Learning models trained from real-world data have demonstrated promise in predicting suicide attempts in adolescents. However, their transportability, namely the performance of a model trained on one dataset and applied to different \u2026"}, {"title": "Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection", "link": "https://arxiv.org/pdf/2408.03554", "details": "S Kimura, R Tanaka, S Miyawaki, J Suzuki\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We explore visual prompt injection (VPI) that maliciously exploits the ability of large vision-language models (LVLMs) to follow instructions drawn onto the input image. We propose a new VPI method,\" goal hijacking via visual prompt injection\"(GHVPI) \u2026"}, {"title": "Exploring Universal Intrinsic Task Subspace for Few-shot Learning via Prompt Tuning", "link": "https://ieeexplore.ieee.org/iel8/6570655/6633080/10603438.pdf", "details": "Y Qin, X Wang, Y Su, Y Lin, N Ding, J Yi, W Chen, Z Liu\u2026 - IEEE/ACM Transactions on \u2026, 2024", "abstract": "Why can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidence indicating that the adaptations of PLMs to various fewshot \u2026"}]
