[{"title": "Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model", "link": "https://arxiv.org/pdf/2503.21782", "details": "A Shaker, M Maaz, C Gou, H Rezatofighi, S Khan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Video understanding models often struggle with high computational requirements, extensive parameter counts, and slow inference speed, making them inefficient for practical use. To tackle these challenges, we propose Mobile-VideoGPT, an efficient \u2026"}, {"title": "Foundation Model for Predicting Prognosis and Adjuvant Therapy Benefit From Digital Pathology in GI Cancers", "link": "https://ascopubs.org/doi/abs/10.1200/JCO-24-01501", "details": "X Wang, Y Jiang, S Yang, F Wang, X Zhang, W Wang\u2026 - Journal of Clinical Oncology, 2025", "abstract": "PURPOSE Artificial intelligence (AI) holds significant promise for improving cancer diagnosis and treatment. Here, we present a foundation AI model for prognosis prediction on the basis of standard hematoxylin and eosin\u2013stained histopathology \u2026"}, {"title": "A Large-Scale Vision-Language Dataset Derived from Open Scientific Literature to Advance Biomedical Generalist AI", "link": "https://arxiv.org/pdf/2503.22727", "details": "A Lozano, MW Sun, J Burgess, JJ Nirschl, C Polzak\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite the excitement behind biomedical artificial intelligence (AI), access to high- quality, diverse, and large-scale data-the foundation for modern AI systems-is still a bottleneck to unlocking its full potential. To address this gap, we introduce \u2026"}, {"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2504.00869%3F", "details": "X Huang, J Wu, H Liu, X Tang, Y Zhou - arXiv preprint arXiv:2504.00869, 2025", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from \u2026"}, {"title": "Summarization Metrics for Spanish and Basque: Do Automatic Scores and LLM-Judges Correlate with Humans?", "link": "https://arxiv.org/pdf/2503.17039", "details": "J Barnes, N Perez, A Bonet-Jover, B Altuna - arXiv preprint arXiv:2503.17039, 2025", "abstract": "Studies on evaluation metrics and LLM-as-a-Judge models for automatic text summarization have largely been focused on English, limiting our understanding of their effectiveness in other languages. Through our new dataset BASSE (BAsque \u2026"}, {"title": "GPT-4o in radiology: In-context learning based automatic generation of radiology impressions", "link": "https://www.sciencedirect.com/science/article/pii/S2949719125000214", "details": "M Mahyoub, Y Wang, MT Khasawneh - Natural Language Processing Journal, 2025", "abstract": "Translating radiological findings into clinical impressions is critical for effective medical communication but is often labor-intensive and prone to variability. This study investigates the potential of the GPT-4o large language model (LLM) to \u2026"}, {"title": "Automated Radiology Report Labeling in Chest X-Ray Pathologies: Development and Evaluation of a Large Language Model Framework", "link": "https://medinform.jmir.org/2025/1/e68618/", "details": "A Abdullah, ST Kim - JMIR Medical Informatics, 2025", "abstract": "Background: Labeling unstructured radiology reports is crucial for creating structured datasets that facilitate downstream tasks, such as training large-scale medical imaging models. Current approaches typically rely on Bidirectional Encoder \u2026"}, {"title": "GPBench: A Comprehensive and Fine-Grained Benchmark for Evaluating Large Language Models as General Practitioners", "link": "https://arxiv.org/pdf/2503.17599", "details": "Z Li, Y Yang, J Lang, W Jiang, Y Zhao, S Li, D Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "General practitioners (GPs) serve as the cornerstone of primary healthcare systems by providing continuous and comprehensive medical services. However, due to community-oriented nature of their practice, uneven training and resource gaps, the \u2026"}, {"title": "SVLA: A Unified Speech-Vision-Language Assistant with Multimodal Reasoning and Speech Generation", "link": "https://arxiv.org/pdf/2503.24164", "details": "ND Huynh, MR Bouadjenek, I Razzak, H Hacid, S Aryal - arXiv preprint arXiv \u2026, 2025", "abstract": "Large vision and language models show strong performance in tasks like image captioning, visual question answering, and retrieval. However, challenges remain in integrating speech, text, and vision into a unified model, especially for spoken tasks \u2026"}]
