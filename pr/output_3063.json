[{"title": "AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2406.13233", "details": "Z Zeng, Y Miao, H Gao, H Zhang, Z Deng - arXiv preprint arXiv:2406.13233, 2024", "abstract": "Mixture of experts (MoE) has become the standard for constructing production-level large language models (LLMs) due to its promise to boost model capacity without causing significant overheads. Nevertheless, existing MoE methods usually enforce \u2026"}, {"title": "Mitigating Social Biases in Language Models through Unlearning", "link": "https://arxiv.org/pdf/2406.13551", "details": "O Dige, D Singh, TF Yau, Q Zhang, B Bolandraftar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Mitigating bias in language models (LMs) has become a critical problem due to the widespread deployment of LMs. Numerous approaches revolve around data pre- processing and fine-tuning of language models, tasks that can be both time \u2026"}, {"title": "Timo: Towards Better Temporal Reasoning for Language Models", "link": "https://arxiv.org/pdf/2406.14192", "details": "Z Su, J Zhang, T Zhu, X Qu, J Li, M Zhang, Y Cheng - arXiv preprint arXiv:2406.14192, 2024", "abstract": "Reasoning about time is essential for Large Language Models (LLMs) to understand the world. Previous works focus on solving specific tasks, primarily on time-sensitive question answering. While these methods have proven effective, they cannot \u2026"}, {"title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models", "link": "https://openreview.net/pdf%3Fid%3DzhCBrgaQZ0", "details": "T Porian, M Wortsman, J Jitsev, L Schmidt, Y Carmon - 2nd Workshop on Advancing Neural \u2026", "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the optimal model size as a function of the compute budget, but these laws yield substantially different predictions. We explain the discrepancy by reproducing the Kaplan scaling \u2026"}, {"title": "ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools", "link": "https://arxiv.org/pdf/2406.12793", "details": "T GLM, A Zeng, B Xu, B Wang, C Zhang, D Yin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce ChatGLM, an evolving family of large language models that we have been developing over time. This report primarily focuses on the GLM-4 language series, which includes GLM-4, GLM-4-Air, and GLM-4-9B. They represent our most \u2026"}, {"title": "Data-Centric AI in the Age of Large Language Models", "link": "https://arxiv.org/pdf/2406.14473", "details": "X Xu, Z Wu, R Qiao, A Verma, Y Shu, J Wang, X Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This position paper proposes a data-centric viewpoint of AI research, focusing on large language models (LLMs). We start by making the key observation that data is instrumental in the developmental (eg, pretraining and fine-tuning) and inferential \u2026"}, {"title": "Abstraction-of-Thought Makes Language Models Better Reasoners", "link": "https://arxiv.org/pdf/2406.12442", "details": "R Hong, H Zhang, X Pan, D Yu, C Zhang - arXiv preprint arXiv:2406.12442, 2024", "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks \u2026"}, {"title": "The Impact of Depth on Compositional Generalization in Transformer Language Models", "link": "https://aclanthology.org/2024.naacl-long.402.pdf", "details": "J Petty, S Steenkiste, I Dasgupta, F Sha, D Garrette\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "To process novel sentences, language models (LMs) must generalize compositionally\u2014combine familiar elements in new ways. What aspects of a model's structure promote compositional generalization? Focusing on transformers, we test \u2026"}, {"title": "Code Pretraining Improves Entity Tracking Abilities of Language Models", "link": "https://arxiv.org/pdf/2405.21068", "details": "N Kim, S Schuster, S Toshniwal - arXiv preprint arXiv:2405.21068, 2024", "abstract": "Recent work has provided indirect evidence that pretraining language models on code improves the ability of models to track state changes of discourse entities expressed in natural language. In this work, we systematically test this claim by \u2026"}]
