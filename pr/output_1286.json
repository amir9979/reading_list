'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [More Room for Language: Investigating the Effect of Re'
[{"title": "Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?", "link": "https://arxiv.org/pdf/2404.12728", "details": "C Qin, W Xia, T Wang, F Jiao, Y Hu, B Ding, R Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Analogical reasoning is a unique ability of humans to address unfamiliar challenges by transferring strategies from relevant past experiences. One key finding in psychology is that compared with irrelevant past experiences, recalling relevant ones \u2026"}, {"title": "Rho-1: Not All Tokens Are What You Need", "link": "https://arxiv.org/pdf/2404.07965", "details": "Z Lin, Z Gou, Y Gong, X Liu, Y Shen, R Xu, C Lin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Previous language model pre-training methods have uniformly applied a next-token prediction loss to all training tokens. Challenging this norm, we posit that\" Not all tokens in a corpus are equally important for language model training\". Our initial \u2026"}, {"title": "Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model", "link": "https://arxiv.org/pdf/2404.09717", "details": "H Cho - arXiv preprint arXiv:2404.09717, 2024", "abstract": "Many recent studies endeavor to improve open-source language models through imitation learning, and re-training on the synthetic instruction data from state-of-the- art proprietary models like ChatGPT and GPT-4. However, the innate nature of \u2026"}, {"title": "UltraEval: A Lightweight Platform for Flexible and Comprehensive Evaluation for LLMs", "link": "https://arxiv.org/pdf/2404.07584", "details": "C He, R Luo, S Hu, Y Zhao, J Zhou, H Wu, J Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Evaluation is pivotal for honing Large Language Models (LLMs), pinpointing their capabilities and guiding enhancements. The rapid development of LLMs calls for a lightweight and easy-to-use framework for swift evaluation deployment. However \u2026"}, {"title": "Pre-training Small Base LMs with Fewer Tokens", "link": "https://arxiv.org/pdf/2404.08634", "details": "S Sanyal, S Sanghavi, AG Dimakis - arXiv preprint arXiv:2404.08634, 2024", "abstract": "We study the effectiveness of a simple approach to develop a small base language model (LM) starting from an existing large base LM: first inherit a few transformer blocks from the larger LM, and then train this smaller model on a very small subset \u2026"}, {"title": "Post-Semantic-Thinking: A Robust Strategy to Distill Reasoning Capacity from Large Language Models", "link": "https://arxiv.org/pdf/2404.09170", "details": "X Chen, S Zhou, K Liang, X Liu - arXiv preprint arXiv:2404.09170, 2024", "abstract": "Chain of thought finetuning aims to endow small student models with reasoning capacity to improve their performance towards a specific task by allowing them to imitate the reasoning procedure of large language models (LLMs) beyond simply \u2026"}, {"title": "Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs", "link": "https://arxiv.org/pdf/2404.13033", "details": "B Guo, H Wang, W Xiao, H Chen, Z Lee, S Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the burgeoning field of Large Language Models (LLMs) like ChatGPT and LLaMA, Prompt Engineering (PE) is renowned for boosting zero-shot or in-context learning (ICL) through prompt modifications. Yet, the realm of the sample design for \u2026"}, {"title": "Fewer Truncations Improve Language Modeling", "link": "https://arxiv.org/pdf/2404.10830", "details": "H Ding, Z Wang, G Paolini, V Kumar, A Deoras, D Roth\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In large language model training, input documents are typically concatenated together and then split into sequences of equal length to avoid padding tokens. Despite its efficiency, the concatenation approach compromises data integrity--it \u2026"}, {"title": "Foundational challenges in assuring alignment and safety of large language models", "link": "https://arxiv.org/pdf/2404.09932", "details": "U Anwar, A Saparov, J Rando, D Paleka, M Turpin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This work identifies 18 foundational challenges in assuring the alignment and safety of large language models (LLMs). These challenges are organized into three different categories: scientific understanding of LLMs, development and deployment \u2026"}]
