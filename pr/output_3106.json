[{"title": "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings", "link": "https://arxiv.org/pdf/2406.16611", "details": "A Posada, D Rueckert, F Meissen, P M\u00fcller - arXiv preprint arXiv:2406.16611, 2024", "abstract": "Since the emergence of the Transformer architecture, language model development has increased, driven by their promising potential. However, releasing these models into production requires properly understanding their behavior, particularly in \u2026"}, {"title": "WARP: On the Benefits of Weight Averaged Rewarded Policies", "link": "https://arxiv.org/pdf/2406.16768", "details": "A Ram\u00e9, J Ferret, N Vieillard, R Dadashi, L Hussenot\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reinforcement learning from human feedback (RLHF) aligns large language models (LLMs) by encouraging their generations to have high rewards, using a reward model trained on human preferences. To prevent the forgetting of pre-trained \u2026"}, {"title": "Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training", "link": "https://arxiv.org/pdf/2405.19654", "details": "J Yang, B Su, WX Zhao, JR Wen - arXiv preprint arXiv:2405.19654, 2024", "abstract": "Medical vision-language pre-training methods mainly leverage the correspondence between paired medical images and radiological reports. Although multi-view spatial images and temporal sequences of image-report pairs are available in off-the-shelf \u2026"}, {"title": "Timo: Towards Better Temporal Reasoning for Language Models", "link": "https://arxiv.org/pdf/2406.14192", "details": "Z Su, J Zhang, T Zhu, X Qu, J Li, M Zhang, Y Cheng - arXiv preprint arXiv:2406.14192, 2024", "abstract": "Reasoning about time is essential for Large Language Models (LLMs) to understand the world. Previous works focus on solving specific tasks, primarily on time-sensitive question answering. While these methods have proven effective, they cannot \u2026"}, {"title": "An Empirical Study of Mamba-based Language Models", "link": "https://arxiv.org/pdf/2406.07887", "details": "R Waleffe, W Byeon, D Riach, B Norick, V Korthikanti\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Selective state-space models (SSMs) like Mamba overcome some of the shortcomings of Transformers, such as quadratic computational complexity with sequence length and large inference-time memory requirements from the key-value \u2026"}, {"title": "Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling", "link": "https://arxiv.org/pdf/2406.07522", "details": "L Ren, Y Liu, Y Lu, Y Shen, C Liang, W Chen - arXiv preprint arXiv:2406.07522, 2024", "abstract": "Efficiently modeling sequences with infinite context length has been a long-standing problem. Past works suffer from either the quadratic computation complexity or the limited extrapolation ability on length generalization. In this work, we present Samba \u2026"}, {"title": "UNDERSTANDING DIABETIC RETINOPATHY SCREENING ATTENDANCE AMONG PEOPLE WITH TYPE 2 DIABETES: The what, why, and how", "link": "https://vbn.aau.dk/files/715862415/PHD_GBP_ONLINE.pdf", "details": "GB Petersen - 2024", "abstract": "The present thesis constitutes the compilation of the research I have conducted during the past years as a PhD fellow at Steno Diabetes Center Copenhagen and Center for General Practice at Aalborg University. It is my hope that the work \u2026"}, {"title": "CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models", "link": "https://arxiv.org/pdf/2406.06007", "details": "P Xia, Z Chen, J Tian, Y Gong, R Hou, Y Xu, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Artificial intelligence has significantly impacted medical applications, particularly with the advent of Medical Large Vision Language Models (Med-LVLMs), sparking optimism for the future of automated and personalized healthcare. However, the \u2026"}, {"title": "Residual-based Language Models are Free Boosters for Biomedical Imaging Tasks", "link": "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Lai_Residual-based_Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks_CVPRW_2024_paper.pdf", "details": "Z Lai, J Wu, S Chen, Y Zhou, N Hovakimyan - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "In this study we uncover the unexpected efficacy of residual-based large language models (LLMs) as part of encoders for biomedical imaging tasks a domain traditionally devoid of language or textual data. The approach diverges from \u2026"}]
