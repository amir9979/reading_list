[{"title": "LLM-CI: Assessing Contextual Integrity Norms in Language Models", "link": "https://arxiv.org/pdf/2409.03735", "details": "Y Shvartzshnaider, V Duddu, J Lacalamita - arXiv preprint arXiv:2409.03735, 2024", "abstract": "Large language models (LLMs), while memorizing parts of their training data scraped from the Internet, may also inadvertently encode societal preferences and norms. As these models are integrated into sociotechnical systems, it is crucial that \u2026"}, {"title": "DP-MemArc: Differential Privacy Transfer Learning for Memory Efficient Language Models", "link": "https://www.researchgate.net/profile/Yanming-Liu-16/publication/383395255_DP-MemArc_Differential_Privacy_Transfer_Learning_for_Memory_Efficient_Language_Models/links/66ca3a35c2eaa5002314bfbf/DP-MemArc-Differential-Privacy-Transfer-Learning-for-Memory-Efficient-Language-Models.pdf", "details": "Y Liu, X Peng, Y Zhang, X Ke, S Deng, J Cao, C Ma\u2026", "abstract": "Large language models have repeatedly shown outstanding performance across diverse applications. However, deploying these models can inadvertently risk user privacy. The significant memory demands during training pose a major challenge in \u2026"}, {"title": "On Robustness-Accuracy Characterization of Language Models using Synthetic Datasets", "link": "https://openreview.net/pdf%3Fid%3DC0j44uRPcl", "details": "CY Ko, PY Chen, P Das, YS Chuang, L Daniel - First Conference on Language \u2026, 2024", "abstract": "In recent years, language models (LMs) that were pretrained at scale on diverse data have proven to be a successful approach for solving different downstream tasks. However, new concerns about proper performance evaluation have been raised \u2026"}, {"title": "BumbleBee: Dynamic KV-Cache Streaming Submodular Summarization for Infinite-Context Transformers", "link": "https://openreview.net/pdf%3Fid%3D8w0RApM5yG", "details": "L Kumari, S Wang, T Zhou, N Sarda, A Rowe, J Bilmes - First Conference on Language \u2026", "abstract": "Transformer-based Large Language Models (LLMs) have shown tremendous advancements across various domains. However, their need to maintain key-value representations (a KV cache) of previously seen tokens in the GPU memory leads to \u2026"}, {"title": "Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.14470", "details": "A Agarwal, SK Ramesh, A Sengupta, T Chakraborty - arXiv preprint arXiv:2408.14470, 2024", "abstract": "Fine-tuning large language models (LLMs) on downstream tasks requires substantial computational resources. A class of parameter-efficient fine-tuning (PEFT) aims to mitigate these computational challenges by selectively fine-tuning only a small \u2026"}, {"title": "Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling", "link": "https://arxiv.org/pdf/2408.16737", "details": "H Bansal, A Hosseini, R Agarwal, VQ Tran, M Kazemi - arXiv preprint arXiv \u2026, 2024", "abstract": "Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs. In this work, we revisit whether this strategy is compute-optimal under a fixed inference budget (eg \u2026"}, {"title": "Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models", "link": "https://arxiv.org/pdf/2408.15915", "details": "Y Yang, Y Qin, T Wu, Z Xu, G Li, P Guo, H Shao, Y Shi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The cultivation of expertise for large language models (LLMs) to solve tasks of specific areas often requires special-purpose tuning with calibrated behaviors on the expected stable outputs. To avoid huge cost brought by manual preparation of \u2026"}, {"title": "CATS: Context-Aware Thresholding for Sparsity in Large Language Models", "link": "https://openreview.net/pdf%3Fid%3Dv3w2a7EInO", "details": "D Lee, J Lee, G Zhang, M Tiwari, A Mirhoseini - First Conference on Language Modeling", "abstract": "The dramatic improvements in Large Language Models (LLMs) come at the cost of increased computational resources for inference. Recent studies ameliorate the computational costs of LLMs by increasing their activation sparsity but suffer from \u2026"}, {"title": "Developer Behaviors in Validating and Repairing LLM-Generated Code Using IDE and Eye Tracking", "link": "https://www.nztang.com/files/papers/tang_vlhcc24.pdf", "details": "N Tang, M Chen, Z Ning, A Bansal, Y Huang\u2026", "abstract": "The increasing use of large language model (LLM)-powered code generation tools, such as GitHub Copilot, is transforming software engineering practices. This paper investigates how developers validate and repair code generated by Copilot and \u2026"}]
