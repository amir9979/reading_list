[{"title": "Self-supervised analogical learning using language models", "link": "https://arxiv.org/pdf/2502.00996", "details": "B Zhou, S Jain, Y Zhang, Q Ning, S Wang, Y Benajiba\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models have been shown to suffer from reasoning inconsistency issues. That is, they fail more in situations unfamiliar to the training data, even though exact or very similar reasoning paths exist in more common cases that they can \u2026"}, {"title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "link": "https://arxiv.org/pdf/2502.05142", "details": "Z Yang, X Xu, J Zhang, G Wang, MK Kalra, P Yan - arXiv preprint arXiv:2502.05142, 2025", "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data \u2026"}, {"title": "Generating Clinically Realistic EHR Data via a Hierarchy-and Semantics-Guided Transformer", "link": "https://arxiv.org/pdf/2502.20719", "details": "G Zhou, S Barbieri - arXiv preprint arXiv:2502.20719, 2025", "abstract": "Generating realistic synthetic electronic health records (EHRs) holds tremendous promise for accelerating healthcare research, facilitating AI model development and enhancing patient privacy. However, existing generative methods typically treat \u2026"}, {"title": "CoCa-CXR: Contrastive Captioners Learn Strong Temporal Structures for Chest X-Ray Vision-Language Understanding", "link": "https://arxiv.org/pdf/2502.20509", "details": "Y Chen, S Xu, A Sellergren, Y Matias, A Hassidim\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models have proven to be of great benefit for medical image analysis since they learn rich semantics from both images and reports. Prior efforts have focused on better alignment of image and text representations to enhance \u2026"}, {"title": "Advancing Vision-Language Models with Generative AI", "link": "https://www.preprints.org/frontend/manuscript/10b5ed95bd23954c58eef830d9d74bfa/download_pub", "details": "A Vats, R Raja - 2025", "abstract": "Generative AI within large vision-language models (LVLMs) has revolutionized multimodal learning, enabling machines to understand and generate visual content from textual descriptions with unprecedented accuracy. This paper explores state-of \u2026"}, {"title": "Towards Statistical Factuality Guarantee for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.20560", "details": "Z Li, C Yan, NJ Jackson, W Cui, B Li, J Zhang, BA Malin - arXiv preprint arXiv \u2026, 2025", "abstract": "Advancements in Large Vision-Language Models (LVLMs) have demonstrated promising performance in a variety of vision-language tasks involving image- conditioned free-form text generation. However, growing concerns about \u2026"}, {"title": "Unsupervised Parameter Efficient Source-free Post-pretraining", "link": "https://arxiv.org/pdf/2502.21313", "details": "A Jha, T Tuytelaars, YM Asano - arXiv preprint arXiv:2502.21313, 2025", "abstract": "Following the success in NLP, the best vision models are now in the billion parameter ranges. Adapting these large models to a target distribution has become computationally and economically prohibitive. Addressing this challenge, we \u2026"}, {"title": "Data-Efficient Radiology Report Generation via Similar Report Features", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DayVEEQAAQBAJ%26oi%3Dfnd%26pg%3DPA252%26ots%3DdH6UhGrFy3%26sig%3D9rNKI-q93yRZa_i7XqpgnRp_3Ws", "details": "J Sun, L Wang - Applications of Medical Artificial Intelligence: Third \u2026", "abstract": "The utilization of Artificial Intelligence in automatically gen-erating radiology reports presents a promising solution for enhancing the efficiency of the diagnostic process and reducing human error. However, existing methods require training on large \u2026"}, {"title": "Generalist World Model Pre-Training for Efficient Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.19544", "details": "Y Zhao, A Scannell, Y Hou, T Cui, L Chen, D B\u00fcchler\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Sample-efficient robot learning is a longstanding goal in robotics. Inspired by the success of scaling in vision and language, the robotics community is now investigating large-scale offline datasets for robot learning. However, existing \u2026"}]
