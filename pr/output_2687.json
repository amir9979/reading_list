[{"title": "Repurposing Language Models into Embedding Models: Finding the Compute-Optimal Recipe", "link": "https://arxiv.org/pdf/2406.04165", "details": "A Ziarko, AQ Jiang, B Piotrowski, W Li, M Jamnik\u2026 - arXiv e-prints, 2024", "abstract": "Text embeddings are essential for many tasks, such as document retrieval, clustering, and semantic similarity assessment. In this paper, we study how to contrastively train text embedding models in a compute-optimal fashion, given a suite \u2026"}, {"title": "Position: Data Authenticity, Consent, & Provenance for AI are all broken: what will it take to fix them?", "link": "https://openreview.net/pdf%3Fid%3D3hSTecKy1b", "details": "S Longpre, R Mahari, N Obeng-Marnu, W Brannon\u2026 - Forty-first International Conference \u2026", "abstract": "New capabilities in foundation models are owed in large part to massive, widely- sourced, and under-documented training data collections. Existing practices in data collection have led to challenges in tracing authenticity, verifying consent, preserving \u2026"}, {"title": "Implicit meta-learning may lead language models to trust more reliable sources", "link": "https://openreview.net/pdf%3Fid%3DFzp1DRzCIN", "details": "D Krasheninnikov, E Krasheninnikov, BK Mlodozeniec\u2026 - Forty-first International Conference \u2026", "abstract": "We demonstrate that large language models (LLMs) may learn indicators of document usefulness and modulate their updates accordingly. We introduce random strings (\" tags\") as indicators of usefulness in a synthetic fine-tuning dataset. Fine \u2026"}, {"title": "BLSP-Emo: Towards Empathetic Large Speech-Language Models", "link": "https://arxiv.org/pdf/2406.03872", "details": "C Wang, M Liao, Z Huang, J Wu, C Zong, J Zhang - arXiv preprint arXiv:2406.03872, 2024", "abstract": "The recent release of GPT-4o showcased the potential of end-to-end multimodal models, not just in terms of low latency but also in their ability to understand and generate expressive speech with rich emotions. While the details are unknown to the \u2026"}, {"title": "DiNADO: Norm-Disentangled Neurally-Decomposed Oracles for Controlling Language Models", "link": "https://openreview.net/forum%3Fid%3Dpvg1OdUtDQ", "details": "S Lu, W Zhao, C Tao, A Gupta, S Wu, T Chung, N Peng - Forty-first International Conference \u2026", "abstract": "NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable generation with large language models. It is designed to avoid catastrophic forgetting while achieving guaranteed convergence to an entropy-maximized closed-form \u2026"}, {"title": "MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures", "link": "https://arxiv.org/pdf/2406.06565", "details": "J Ni, F Xue, X Yue, Y Deng, M Shah, K Jain, G Neubig\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Evaluating large language models (LLMs) is challenging. Traditional ground-truth- based benchmarks fail to capture the comprehensiveness and nuance of real-world queries, while LLM-as-judge benchmarks suffer from grading biases and limited \u2026"}, {"title": "Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models", "link": "https://arxiv.org/pdf/2406.02061", "details": "M Nezhurina, L Cipolina-Kun, M Cherti, J Jitsev - arXiv preprint arXiv:2406.02061, 2024", "abstract": "Large Language Models (LLMs) are often described as being instances of foundation models-that is, models that transfer strongly across various tasks and conditions in few-show or zero-shot manner, while exhibiting scaling laws that \u2026"}, {"title": "Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models", "link": "https://arxiv.org/pdf/2406.03009", "details": "SL Wei, CK Wu, HH Huang, HH Chen - arXiv preprint arXiv:2406.03009, 2024", "abstract": "In this paper, we investigate the phenomena of\" selection biases\" in Large Language Models (LLMs), focusing on problems where models are tasked with choosing the optimal option from an ordered sequence. We delve into biases related to option \u2026"}, {"title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models", "link": "https://openreview.net/pdf%3Fid%3D1tRLxQzdep", "details": "P Dong, L Li, Z Tang, X Liu, X Pan, Q Wang, X Chu - Forty-first International \u2026, 2024", "abstract": "Despite the remarkable capabilities, Large Language Models (LLMs) face deployment challenges due to their extensive size. Pruning methods drop a subset of weights to accelerate, but many of them require retraining, which is prohibitively \u2026"}]
