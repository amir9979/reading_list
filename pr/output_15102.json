[{"title": "Cultural Learning-Based Culture Adaptation of Language Models", "link": "https://arxiv.org/pdf/2504.02953", "details": "CC Liu, A Korhonen, I Gurevych - arXiv preprint arXiv:2504.02953, 2025", "abstract": "Adapting large language models (LLMs) to diverse cultural values is a challenging task, as existing LLMs often reflect the values of specific groups by default, and potentially causing harm to others. In this paper, we present CLCA, a novel \u2026"}, {"title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2504.07887", "details": "R Cantini, A Orsino, M Ruggiero, D Talia - arXiv preprint arXiv:2504.07887, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, driving advancements in machine translation, summarization, and conversational agents. However, their increasing integration into critical societal domains has raised \u2026"}, {"title": "Deceptive Automated Interpretability: Language Models Coordinating to Fool Oversight Systems", "link": "https://arxiv.org/pdf/2504.07831", "details": "S Lermen, M Dziemian, NPC Antol\u00edn - arXiv preprint arXiv:2504.07831, 2025", "abstract": "We demonstrate how AI agents can coordinate to deceive oversight systems using automated interpretability of neural networks. Using sparse autoencoders (SAEs) as our experimental framework, we show that language models (Llama, DeepSeek R1 \u2026"}, {"title": "Encoder-Decoder Gemma: Improving the Quality-Efficiency Trade-Off via Adaptation", "link": "https://arxiv.org/pdf/2504.06225", "details": "B Zhang, F Moiseev, J Ainslie, P Suganthan, M Ma\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "While decoder-only large language models (LLMs) have shown impressive results, encoder-decoder models are still widely adopted in real-world applications for their inference efficiency and richer encoder representation. In this paper, we study a \u2026"}, {"title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models", "link": "https://arxiv.org/pdf/2504.06214", "details": "C Xu, W Ping, P Xu, Z Liu, B Wang, M Shoeybi, B Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context learning, and inference-time scaling, all of which require models to process and reason over long sequences of text and \u2026"}, {"title": "V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric Capabilities in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2504.06148", "details": "X Zheng, L Li, Z Yang, P Yu, AJ Wang, R Yan, Y Yao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have led to significant improvements across various multimodal benchmarks. However, as evaluations shift from static datasets to open-world, dynamic environments, current \u2026"}, {"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2504.00869%3F", "details": "X Huang, J Wu, H Liu, X Tang, Y Zhou - arXiv preprint arXiv:2504.00869, 2025", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from \u2026"}, {"title": "A Neuro-inspired Interpretation of Unlearning in Large Language Models through Sample-level Unlearning Difficulty", "link": "https://arxiv.org/pdf/2504.06658", "details": "X Feng, Y Li, C Wang, J Liu, L Zhang, C Chen - arXiv preprint arXiv:2504.06658, 2025", "abstract": "Driven by privacy protection laws and regulations, unlearning in Large Language Models (LLMs) is gaining increasing attention. However, current research often neglects the interpretability of the unlearning process, particularly concerning sample \u2026"}, {"title": "Can large language models independently complete tasks? A dynamic evaluation framework for multi-turn task planning and completion", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225008070", "details": "J Gao, J Cui, H Wu, L Xiang, H Zhao, X Li, M Fang\u2026 - Neurocomputing, 2025", "abstract": "Large language models (LLMs) are increasingly relied upon for multi-turn dialogue to conduct complex tasks. However, existing benchmarks mainly evaluate LLMs as agents, overlooking their potential as independent systems to accomplish complex \u2026"}]
