[{"title": "Process-based Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2503.03746", "details": "S Zhang, X Liu, X Zhang, J Liu, Z Luo, S Huang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' \u2026"}, {"title": "SPRInT: Scaling Programatic Reasoning for INstruction Tuning in mathematics", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225005405", "details": "Y Yan, L Li, BW Zhang - Neurocomputing, 2025", "abstract": "We present SPRInT, a novel approach for large-scale, cost-effective synthesis of instruction-tuning datasets, leveraging Program-of-Thoughts (PoT) to enhance mathematical reasoning capabilities. Through the SPRInT framework, we \u2026"}, {"title": "MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems", "link": "https://arxiv.org/pdf/2503.03686", "details": "R Ye, S Tang, R Ge, Y Du, Z Yin, S Chen, J Shao - arXiv preprint arXiv:2503.03686, 2025", "abstract": "LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks. However, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability \u2026"}, {"title": "The Multilingual Mind: A Survey of Multilingual Reasoning in Language Models", "link": "https://arxiv.org/pdf/2502.09457", "details": "A Ghosh, D Datta, S Saha, C Agarwal - arXiv preprint arXiv:2502.09457, 2025", "abstract": "While reasoning and multilingual capabilities in Language Models (LMs) have achieved remarkable progress in recent years, their integration into a unified paradigm, multilingual reasoning, is at a nascent stage. Multilingual reasoning \u2026"}, {"title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models", "link": "https://arxiv.org/pdf/2502.03199%3F", "details": "J Wu, Y Shen, S Liu, Y Tang, S Song, X Wang, L Cai - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the \u2026"}, {"title": "\" See the World, Discover Knowledge\": A Chinese Factuality Evaluation for Large Vision Language Models", "link": "https://arxiv.org/pdf/2502.11718", "details": "J Gu, Y Wang, P Bu, C Wang, Z Wang, T Song, D Wei\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The evaluation of factual accuracy in large vision language models (LVLMs) has lagged behind their rapid development, making it challenging to fully reflect these models' knowledge capacity and reliability. In this paper, we introduce the first \u2026"}, {"title": "Multilingual Language Model Pretraining using Machine-translated Data", "link": "https://arxiv.org/pdf/2502.13252", "details": "J Wang, Y Lu, M Weber, M Ryabinin, D Adelani\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "High-resource languages such as English, enables the pretraining of high-quality large language models (LLMs). The same can not be said for most other languages as LLMs still underperform for non-English languages, likely due to a gap in the \u2026"}, {"title": "Promote, Suppress, Iterate: How Language Models Answer One-to-Many Factual Queries", "link": "https://arxiv.org/pdf/2502.20475", "details": "TL Yan, R Jia - arXiv preprint arXiv:2502.20475, 2025", "abstract": "To answer one-to-many factual queries (eg, listing cities of a country), a language model (LM) must simultaneously recall knowledge and avoid repeating previous answers. How are these two subtasks implemented and integrated internally? Across \u2026"}, {"title": "Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs", "link": "https://arxiv.org/pdf/2502.14645", "details": "Y Wu, L Ding, L Shen, D Tao - arXiv preprint arXiv:2502.14645, 2025", "abstract": "Knowledge editing allows for efficient adaptation of large language models (LLMs) to new information or corrections without requiring full retraining. However, prior methods typically focus on either single-language editing or basic multilingual \u2026"}]
