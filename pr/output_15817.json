[{"title": "Getting More Juice Out of Your Data: Hard Pair Refinement Enhances Visual-Language Models Without Extra Data", "link": "https://aclanthology.org/2025.naacl-long.399.pdf", "details": "H Wang, M Huang, R Huang, L Hong, H Xu, T Hu\u2026 - Proceedings of the 2025 \u2026, 2025", "abstract": "Abstract Contrastive Language-Image Pre-training (CLIP) has become the standard for cross-modal image-text representation learning. Improving CLIP typically requires additional data and retraining with new loss functions, but these demands raise \u2026"}, {"title": "GroundCocoa: A Benchmark for Evaluating Compositional & Conditional Reasoning in Language Models", "link": "https://aclanthology.org/2025.naacl-long.420.pdf", "details": "H Kohli, S Kumar, H Sun - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their reasoning to \u2026"}, {"title": "Guiding Medical Vision-Language Models with Diverse Visual Prompts: Framework Design and Comprehensive Exploration of Prompt Variations", "link": "https://aclanthology.org/2025.naacl-long.587.pdf", "details": "K Zhu, Z Qin, H Yi, Z Jiang, Q Lao, S Zhang, K Li - \u2026 of the 2025 Conference of the \u2026, 2025", "abstract": "While mainstream vision-language models (VLMs) have advanced rapidly in understanding image-level information, they still lack the ability to focus on specific areas designated by humans. Rather, they typically rely on large volumes of high \u2026"}, {"title": "VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning", "link": "https://arxiv.org/pdf/2504.19627", "details": "R Luo, R Shan, L Chen, Z Liu, L Wang, M Yang, X Xia - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like embodied intelligence due to their strong vision-language reasoning abilities. However, current LVLMs process entire images at the token level, which is inefficient \u2026"}, {"title": "Towards trustworthy and reliable language models", "link": "https://dr.ntu.edu.sg/bitstream/10356/184392/2/Amended%2520Thesis.pdf", "details": "R Zhao - 2025", "abstract": "This thesis addresses the critical challenge of developing trustworthy and reliable Natural Language Processing (NLP) systems, specifically the newly emerged Large Language Models (LLMs). As LLMs become increasingly prevalent in various \u2026"}, {"title": "Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation", "link": "https://arxiv.org/pdf/2504.18856", "details": "S Albastaki, A Sohail, II Ganapathi, B Alawode, A Khan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In Computational Pathology (CPath), the introduction of Vision-Language Models (VLMs) has opened new avenues for research, focusing primarily on aligning image- text pairs at a single magnification level. However, this approach might not be \u2026"}, {"title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "link": "https://arxiv.org/pdf/2504.19467", "details": "J Wu, B Gu, R Zhou, K Xie, D Snyder, Y Jiang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) hold great promise for medical applications and are evolving rapidly, with new models being released at an accelerated pace. However, current evaluations of LLMs in clinical contexts remain limited. Most existing \u2026"}, {"title": "Large Language Models (LLMs) and Generative Artificial Intelligence (GenAI)", "link": "https://link.springer.com/chapter/10.1007/978-981-96-3208-4_10", "details": "R Lee - Natural Language Processing: A Textbook with Python \u2026, 2025", "abstract": "This chapter explores the evolution and impact of Large Language Models (LLMs) and Generative Artificial Intelligence (GenAI). It traces the development from early Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks \u2026"}]
