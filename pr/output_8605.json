[{"title": "From Babbling to Fluency: Evaluating the Evolution of Language Models in Terms of Human Language Acquisition", "link": "https://arxiv.org/pdf/2410.13259", "details": "Q Yang, P Wang, LD Plonsky, FL Oswald, H Chen - arXiv preprint arXiv:2410.13259, 2024", "abstract": "We examine the language capabilities of language models (LMs) from the critical perspective of human language acquisition. Building on classical language development theories, we propose a three-stage framework to assess the abilities of \u2026"}, {"title": "Reducing the Scope of Language Models with Circuit Breakers", "link": "https://arxiv.org/pdf/2410.21597", "details": "D Yunis, S Huo, C Gunasekara, D Contractor - arXiv preprint arXiv:2410.21597, 2024", "abstract": "Language models are now deployed in a wide variety of user-facing applications, often for specific purposes like answering questions about documentation or acting as coding assistants. As these models are intended for particular purposes, they \u2026"}, {"title": "Vision-Language Models Can Self-Improve Reasoning via Reflection", "link": "https://arxiv.org/pdf/2411.00855", "details": "K Cheng, Y Li, F Xu, J Zhang, H Zhou, Y Liu - arXiv preprint arXiv:2411.00855, 2024", "abstract": "Chain-of-thought (CoT) has proven to improve the reasoning capability of large language models (LLMs). However, due to the complexity of multimodal scenarios and the difficulty in collecting high-quality CoT data, CoT reasoning in multimodal \u2026"}, {"title": "Probing-RAG: Self-Probing to Guide Language Models in Selective Document Retrieval", "link": "https://arxiv.org/pdf/2410.13339", "details": "I Baek, H Chang, B Kim, J Lee, H Lee - arXiv preprint arXiv:2410.13339, 2024", "abstract": "Retrieval-Augmented Generation (RAG) enhances language models by retrieving and incorporating relevant external knowledge. However, traditional retrieve-and- generate processes may not be optimized for real-world scenarios, where queries \u2026"}, {"title": "Sparsing Law: Towards Large Language Models with Greater Activation Sparsity", "link": "https://arxiv.org/pdf/2411.02335", "details": "Y Luo, C Song, X Han, Y Chen, C Xiao, Z Liu, M Sun - arXiv preprint arXiv \u2026, 2024", "abstract": "Activation sparsity denotes the existence of substantial weakly-contributed elements within activation outputs that can be eliminated, benefiting many important applications concerned with large language models (LLMs). Although promoting \u2026"}, {"title": "Membership Inference Attacks against Large Vision-Language Models", "link": "https://arxiv.org/pdf/2411.02902", "details": "Z Li, Y Wu, Y Chen, F Tonin, EA Rocamora, V Cevher - arXiv preprint arXiv \u2026, 2024", "abstract": "Large vision-language models (VLLMs) exhibit promising capabilities for processing multi-modal tasks across various application scenarios. However, their emergence also raises significant data security concerns, given the potential inclusion of \u2026"}, {"title": "From Imitation to Introspection: Probing Self-Consciousness in Language Models", "link": "https://arxiv.org/pdf/2410.18819", "details": "S Chen, S Yu, S Zhao, C Lu - arXiv preprint arXiv:2410.18819, 2024", "abstract": "Self-consciousness, the introspection of one's existence and thoughts, represents a high-level cognitive process. As language models advance at an unprecedented pace, a critical question arises: Are these models becoming self-conscious? Drawing \u2026"}, {"title": "Defining and Evaluating Physical Safety for Large Language Models", "link": "https://arxiv.org/pdf/2411.02317", "details": "YC Tang, PY Chen, TY Ho - arXiv preprint arXiv:2411.02317, 2024", "abstract": "Large Language Models (LLMs) are increasingly used to control robotic systems such as drones, but their risks of causing physical threats and harm in real-world applications remain unexplored. Our study addresses the critical gap in evaluating \u2026"}, {"title": "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets", "link": "https://arxiv.org/pdf/2410.15096", "details": "OJ Kwon, DE Matsunaga, KE Kim - arXiv preprint arXiv:2410.15096, 2024", "abstract": "A critical component of the current generation of language models is preference alignment, which aims to precisely control the model's behavior to meet human needs and values. The most notable among such methods is Reinforcement \u2026"}]
