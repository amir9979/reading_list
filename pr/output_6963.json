[{"title": "Not Only the Last-Layer Features for Spurious Correlations: All Layer Deep Feature Reweighting", "link": "https://arxiv.org/pdf/2409.14637", "details": "HW Hameed, G Nanfack, E Belilovsky - arXiv preprint arXiv:2409.14637, 2024", "abstract": "Spurious correlations are a major source of errors for machine learning models, in particular when aiming for group-level fairness. It has been recently shown that a powerful approach to combat spurious correlations is to re-train the last layer on a \u2026"}, {"title": "Neural-Symbolic Collaborative Distillation: Advancing Small Language Models for Complex Reasoning Tasks", "link": "https://arxiv.org/pdf/2409.13203", "details": "H Liao, S He, Y Xu, Y Zhang, K Liu, J Zhao - arXiv preprint arXiv:2409.13203, 2024", "abstract": "In this paper, we propose $\\textbf {Ne} $ ural-$\\textbf {Sy} $ mbolic $\\textbf {C} $ ollaborative $\\textbf {D} $ istillation ($\\textbf {NesyCD} $), a novel knowledge distillation method for learning the complex reasoning abilities of Large Language \u2026"}, {"title": "DP $^ 2$-FedSAM: Enhancing Differentially Private Federated Learning Through Personalized Sharpness-Aware Minimization", "link": "https://arxiv.org/pdf/2409.13645", "details": "Z Zhang, Y Guo, Y Gong - arXiv preprint arXiv:2409.13645, 2024", "abstract": "Federated learning (FL) is a distributed machine learning approach that allows multiple clients to collaboratively train a model without sharing their raw data. To prevent sensitive information from being inferred through the model updates shared \u2026"}, {"title": "PromptTA: Prompt-driven Text Adapter for Source-free Domain Generalization", "link": "https://arxiv.org/pdf/2409.14163", "details": "H Zhang, S Bai, W Zhou, J Fu, B Chen - arXiv preprint arXiv:2409.14163, 2024", "abstract": "Source-free domain generalization (SFDG) tackles the challenge of adapting models to unseen target domains without access to source domain data. To deal with this challenging task, recent advances in SFDG have primarily focused on leveraging the \u2026"}, {"title": "Analyzing Racial Differences in Imaging Joint Replacement Registries Using Generative Artificial Intelligence: Advancing Orthopaedic Data Equity", "link": "https://www.sciencedirect.com/science/article/pii/S2352344124001882", "details": "B Khosravi, P Rouzrokh, BJ Erickson, HW Garner\u2026 - Arthroplasty Today, 2024", "abstract": "Background Discrepancies in medical data sets can perpetuate bias, especially when training deep learning models, potentially leading to biased outcomes in clinical applications. Understanding these biases is crucial for the development of \u2026"}, {"title": "MAPX: An explainable model-agnostic framework for the detection of false information on social media networks", "link": "https://arxiv.org/pdf/2409.08522", "details": "S Condran, M Bewong, S Kwashie, MZ Islam, I Altas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The automated detection of false information has become a fundamental task in combating the spread of\" fake news\" on online social media networks (OSMN) as it reduces the need for manual discernment by individuals. In the literature, leveraging \u2026"}, {"title": "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting", "link": "https://arxiv.org/pdf/2409.13853", "details": "Z Wang, R Bao, Y Wu, J Taylor, C Xiao, F Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pretrained large language models (LLMs) have revolutionized natural language processing (NLP) tasks such as summarization, question answering, and translation. However, LLMs pose significant security risks due to their tendency to memorize \u2026"}, {"title": "Investigating Layer Importance in Large Language Models", "link": "https://arxiv.org/pdf/2409.14381", "details": "Y Zhang, Y Dong, K Kawaguchi - arXiv preprint arXiv:2409.14381, 2024", "abstract": "Large language models (LLMs) have gained increasing attention due to their prominent ability to understand and process texts. Nevertheless, LLMs largely remain opaque. The lack of understanding of LLMs has obstructed the deployment in \u2026"}, {"title": "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method", "link": "https://arxiv.org/pdf/2409.14781", "details": "W Zhang, R Zhang, J Guo, M de Rijke, Y Fan, X Cheng - arXiv preprint arXiv \u2026, 2024", "abstract": "As the scale of training corpora for large language models (LLMs) grows, model developers become increasingly reluctant to disclose details on their data. This lack of transparency poses challenges to scientific evaluation and ethical deployment \u2026"}]
