[{"title": "Addax: Memory-Efficient Fine-Tuning of Language Models with a Combination of Forward-Backward and Forward-Only Passes", "link": "https://openreview.net/pdf%3Fid%3DYtZv36CY5p", "details": "Z Li, X Zhang, M Razaviyayn - 5th Workshop on practical ML for limited/low resource \u2026", "abstract": "Fine-tuning language models (LMs) with first-order optimizers often demands excessive memory, limiting accessibility, while zeroth-order optimizers use less memory, but suffer from slow convergence depending on model size. We introduce a \u2026"}, {"title": "PLeak: Prompt Leaking Attacks against Large Language Model Applications", "link": "https://arxiv.org/pdf/2405.06823", "details": "B Hui, H Yuan, N Gong, P Burlina, Y Cao - arXiv preprint arXiv:2405.06823, 2024", "abstract": "Large Language Models (LLMs) enable a new ecosystem with many downstream applications, called LLM applications, with different natural language processing tasks. The functionality and performance of an LLM application highly depend on its \u2026"}, {"title": "MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning", "link": "https://arxiv.org/pdf/2405.05189", "details": "I Nair, L Wang - arXiv preprint arXiv:2405.05189, 2024", "abstract": "We study the task of conducting structured reasoning as generating a reasoning graph from natural language input using large language models (LLMs). Previous approaches have explored various prompting schemes, yet they suffer from error \u2026"}, {"title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors", "link": "https://arxiv.org/pdf/2404.17807", "details": "G Li, P Wang, J Liu, Y Guo, K Ji, Z Shang, Z Xu - arXiv preprint arXiv:2404.17807, 2024", "abstract": "Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot \u2026"}, {"title": "Tele-FLM Technical Report", "link": "https://arxiv.org/pdf/2404.16645", "details": "X Li, Y Yao, X Jiang, X Fang, C Wang, X Liu, Z Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have showcased profound capabilities in language understanding and generation, facilitating a wide array of applications. However, there is a notable paucity of detailed, open-sourced methodologies on efficiently \u2026"}, {"title": "Temporal Scaling Law for Large Language Models", "link": "https://arxiv.org/pdf/2404.17785", "details": "Y Xiong, X Chen, X Ye, H Chen, Z Lin, H Lian, J Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, Large Language Models (LLMs) are widely adopted in a wide range of tasks, leading to increasing attention towards the research on how scaling LLMs affects their performance. Existing works, termed as Scaling Laws, have discovered \u2026"}, {"title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning", "link": "https://arxiv.org/pdf/2404.19245", "details": "C Tian, Z Shi, Z Guo, L Li, C Xu - arXiv preprint arXiv:2404.19245, 2024", "abstract": "Adapting Large Language Models (LLMs) to new tasks through fine-tuning has been made more efficient by the introduction of Parameter-Efficient Fine-Tuning (PEFT) techniques, such as LoRA. However, these methods often underperform compared \u2026"}, {"title": "LLMs can Find Mathematical Reasoning Mistakes by Pedagogical Chain-of-Thought", "link": "https://arxiv.org/pdf/2405.06705", "details": "Z Jiang, H Peng, S Feng, F Li, D Li - arXiv preprint arXiv:2405.06705, 2024", "abstract": "Self-correction is emerging as a promising approach to mitigate the issue of hallucination in Large Language Models (LLMs). To facilitate effective self-correction, recent research has proposed mistake detection as its initial step. However, current \u2026"}, {"title": "Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks", "link": "https://dl.acm.org/doi/abs/10.1145/3589334.3645363", "details": "S Xu, L Pang, H Shen, X Cheng, TS Chua - Proceedings of the ACM on Web \u2026, 2024", "abstract": "Making the contents generated by Large Language Model (LLM), accurate, credible and traceable is crucial, especially in complex knowledge-intensive tasks that require multi-step reasoning and each step needs knowledge to solve. Retrieval \u2026"}]
