[{"title": "Detection of diabetic retinopathy severity from fundus images: DCNN", "link": "https://www.inderscienceonline.com/doi/abs/10.1504/IJMEI.2025.145042", "details": "TS Kumar, R Muthalagu, LM Sundari, M Nalini - International Journal of Medical \u2026, 2025", "abstract": "Diabetes retinopathy is a frequent diabetic complication that damages the retina and, if left untreated, may lead to blindness. The exponential rise in the number of diabetics throughout the globe has resulted in an equivalent rise in the number of \u2026"}, {"title": "BUILDING ECHOGPT: A LARGE LANGUAGE MODEL FOR ECHOCARDIOGRAPHY REPORT SUMMARIZATION", "link": "https://www.jacc.org/doi/full/10.1016/S0735-1097%252825%252905175-7", "details": "CJ Chao, I Banerjee, R Arsanjani, C Ayoub, AS Tseng\u2026 - Journal of the American \u2026, 2025", "abstract": "Background The rise in the need for echocardiography tests challenges maintaining quality and timeliness. Large Language Models (LLMs) have potential in echo reporting, though less studied. Methods We analyzed adult echo studies from Mayo \u2026"}, {"title": "MedHEval: Benchmarking Hallucinations and Mitigation Strategies in Medical Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.02157", "details": "A Chang, L Huang, P Bhatia, T Kass-Hout, F Ma\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision Language Models (LVLMs) are becoming increasingly important in the medical domain, yet Medical LVLMs (Med-LVLMs) frequently generate hallucinations due to limited expertise and the complexity of medical applications \u2026"}, {"title": "Open-source framework for detecting bias and overfitting for large pathology images", "link": "https://arxiv.org/pdf/2503.01827%3F", "details": "A Sildnes, N Shvetsov, M Tafavvoghi, VNN Tran\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Even foundational models that are trained on datasets with billions of data samples may develop shortcuts that lead to overfitting and bias. Shortcuts are non-relevant patterns in data, such as the background color or color intensity. So, to ensure the \u2026"}, {"title": "LEVERAGING VISUAL FOUNDATION MODEL FOR ECHOCARDIOGRAPHY WORKFLOW ENHANCEMENT", "link": "https://www.jacc.org/doi/full/10.1016/S0735-1097%252825%252903068-2", "details": "CJ Chao, Y Gu, W Kumar, T Xiang, L Appari, J Farina\u2026 - Journal of the American \u2026, 2025", "abstract": "Background The vision foundation model,\u201cSegment Anything (SAM),\u201d promises to segment any objects in images. However, the performance of SAM on clinical echocardiography images has yet to be investigated and compared against the state \u2026"}]
