[{"title": "Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning", "link": "https://arxiv.org/pdf/2412.08614", "details": "F Lu, W Wu, K Zheng, S Ma, B Gong, J Liu, W Zhai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generating detailed captions comprehending text-rich visual content in images has received growing attention for Large Vision-Language Models (LVLMs). However, few studies have developed benchmarks specifically tailored for detailed captions to \u2026"}, {"title": "PVC: Progressive Visual Token Compression for Unified Image and Video Processing in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.09613%3F", "details": "C Yang, X Dong, X Zhu, W Su, J Wang, H Tian, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (VLMs) have been extended to understand both images and videos. Visual token compression is leveraged to reduce the considerable token length of visual inputs. To meet the needs of different tasks \u2026"}, {"title": "VisionZip: Longer is Better but Not Necessary in Vision Language Models", "link": "https://arxiv.org/pdf/2412.04467", "details": "S Yang, Y Chen, Z Tian, C Wang, J Li, B Yu, J Jia - arXiv preprint arXiv:2412.04467, 2024", "abstract": "Recent advancements in vision-language models have enhanced performance by increasing the length of visual tokens, making them much longer than text tokens and significantly raising computational costs. However, we observe that the visual tokens \u2026"}, {"title": "CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.19331", "details": "KA Nguyen, A Juvekar, T Yu, M Wahed, I Lourentzou - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in Large Vision-Language Models (LVLMs) have sparked significant progress in general-purpose vision tasks through visual instruction tuning. While some works have demonstrated the capability of LVLMs to generate \u2026"}, {"title": "Exploring Visual Multiple-Choice Question Answering with Pre-trained Vision-Language Models", "link": "https://openaccess.thecvf.com/content/ACCV2024W/LAVA/papers/Tran_Exploring_Visual_Multiple-Choice_Question_Answering_with_Pre-trained_Vision-Language_Models_ACCVW_2024_paper.pdf", "details": "GN Tran, DT Luu - Proceedings of the Asian Conference on Computer \u2026, 2024", "abstract": "Visual question answering is a challenging task in computer vision and natural language processing that involves answering questions about an image using both visual and textual information. This task is more challenging when it comes to the \u2026"}, {"title": "Medec: A benchmark for medical error detection and correction in clinical notes", "link": "https://arxiv.org/pdf/2412.19260", "details": "AB Abacha, W Yim, Y Fu, Z Sun, M Yetisgen, F Xia\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Several studies showed that Large Language Models (LLMs) can answer medical questions correctly, even outperforming the average human score in some medical exams. However, to our knowledge, no study has been conducted to assess the \u2026"}, {"title": "Contrastive concept-phrase pre-training for generating clinically accurate and interpretable chest X-ray reports", "link": "https://link.springer.com/article/10.1007/s00521-024-10640-1", "details": "A Tubaishat, T Zia, D Windridge, M Nawaz, S Razzaq - Neural Computing and \u2026, 2024", "abstract": "Automated radiology report generation is an emerging field for improving patient care and alleviating radiologist workload. However, existing methods face a range of challenges such as limited data availability, clinical metric performance, and \u2026"}, {"title": "Domain Aware Multi-Task Pre-Training of 3D Swin Transformer for Brain MRI", "link": "https://openaccess.thecvf.com/content/ACCV2024/papers/Kim_Domain_Aware_Multi-Task_Pre-Training_of_3D_Swin_Transformer_for_Brain_ACCV_2024_paper.pdf", "details": "J Kim, M Kim, H Park - Proceedings of the Asian Conference on Computer \u2026, 2024", "abstract": "The scarcity of annotated medical images is a major bottleneck in developing learning models for medical image analysis. Hence, recent studies have focused on pretrained models with fewer annotation requirements that can be fine-tuned for \u2026"}, {"title": "cryoTIGER: Deep-Learning Based Tilt Interpolation Generator for Enhanced Reconstruction in Cryo Electron Tomography", "link": "https://www.biorxiv.org/content/biorxiv/early/2024/12/20/2024.12.17.628939.full.pdf", "details": "T Majtner, JP Kreysing, MW Tuijtel, S Cruz-Le\u00f3n, J Liu\u2026 - bioRxiv, 2024", "abstract": "Cryo-electron tomography enables the visualization of macromolecular complexes within native cellular environments, but is limited by incomplete angular sampling and the maximal electron dose that biological specimen can be exposed to. Here, we \u2026"}]
