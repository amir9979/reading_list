[{"title": "Mutual Prompt Leaning for Vision Language Models", "link": "https://link.springer.com/article/10.1007/s11263-024-02243-z", "details": "S Long, Z Zhao, J Yuan, Z Tan, J Liu, J Feng, S Wang\u2026 - International Journal of \u2026, 2024", "abstract": "Large pre-trained vision language models (VLMs) have demonstrated impressive representation learning capabilities, but their transferability across various downstream tasks heavily relies on prompt learning. Since VLMs consist of text and \u2026"}, {"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Pushing the Limits of Vision-Language Models in Remote Sensing without Human Annotations", "link": "https://arxiv.org/pdf/2409.07048", "details": "K Cha, D Yu, J Seo - arXiv preprint arXiv:2409.07048, 2024", "abstract": "The prominence of generalized foundation models in vision-language integration has witnessed a surge, given their multifarious applications. Within the natural domain, the procurement of vision-language datasets to construct these foundation \u2026"}, {"title": "ScriptSmith: A Unified LLM Framework for Enhancing IT Operations via Automated Bash Script Generation, Assessment, and Refinement", "link": "https://arxiv.org/pdf/2409.17166", "details": "O Chatterjee, P Aggarwal, S Samanta, T Dai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the rapidly evolving landscape of site reliability engineering (SRE), the demand for efficient and effective solutions to manage and resolve issues in site and cloud applications is paramount. This paper presents an innovative approach to action \u2026"}, {"title": "EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions", "link": "https://arxiv.org/pdf/2409.18042", "details": "K Chen, Y Gou, R Huang, Z Liu, D Tan, J Xu, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "GPT-4o, an omni-modal model that enables vocal conversations with diverse emotions and tones, marks a milestone for omni-modal foundation models. However, empowering Large Language Models to perceive and generate images, texts, and \u2026"}, {"title": "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models", "link": "https://arxiv.org/pdf/2409.17455", "details": "Y Zhou, R Tang, Z Yao, Z Zhu - arXiv preprint arXiv:2409.17455, 2024", "abstract": "Language models (LMs), despite their advances, often depend on spurious correlations, undermining their accuracy and generalizability. This study addresses the overlooked impact of subtler, more complex shortcuts that compromise model \u2026"}, {"title": "Inference-Time Language Model Alignment via Integrated Value Guidance", "link": "https://arxiv.org/pdf/2409.17819", "details": "Z Liu, Z Zhou, Y Wang, C Yang, Y Qiao - arXiv preprint arXiv:2409.17819, 2024", "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce $\\textit {Integrated Value Guidance} $(IVG), a method that uses implicit and \u2026"}, {"title": "Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models", "link": "https://arxiv.org/pdf/2409.09510", "details": "A Salemi, H Zamani - arXiv preprint arXiv:2409.09510, 2024", "abstract": "Privacy-preserving methods for personalizing large language models (LLMs) are relatively under-explored. There are two schools of thought on this topic:(1) generating personalized outputs by personalizing the input prompt through retrieval \u2026"}, {"title": "StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?", "link": "https://arxiv.org/pdf/2409.17167", "details": "G Shen, D Zhao, A Bao, X He, Y Dong, Y Zeng - arXiv preprint arXiv:2409.17167, 2024", "abstract": "Human beings often experience stress, which can significantly influence their performance. This study explores whether Large Language Models (LLMs) exhibit stress responses similar to those of humans and whether their performance \u2026"}]
