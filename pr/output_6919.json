[{"title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models", "link": "https://arxiv.org/pdf/2408.15778", "details": "J Gui, Y Liu, J Cheng, X Gu, X Liu, H Wang, Y Dong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across various tasks, showcasing complex problem-solving abilities. Understanding and executing complex rules, along with multi-step planning, are fundamental to logical \u2026"}, {"title": "Explicit Inductive Inference using Large Language Models", "link": "https://arxiv.org/pdf/2408.14467", "details": "T Liu, T Li, L Cheng, M Steedman - arXiv preprint arXiv:2408.14467, 2024", "abstract": "Large Language Models (LLMs) are reported to hold undesirable attestation bias on inference tasks: when asked to predict if a premise P entails a hypothesis H, instead of considering H's conditional truthfulness entailed by P, LLMs tend to use the out-of \u2026"}, {"title": "Multi-modal Multi-scale State Space Model for Medical Visual Question Answering", "link": "https://link.springer.com/chapter/10.1007/978-3-031-72353-7_24", "details": "Q Chen, M Bian, W He, H Xu - International Conference on Artificial Neural Networks, 2024", "abstract": "Abstract Medical Visual Question Answering (Med-VQA) is pivotal for interpreting medical queries via corresponding images. While multi-modal fusion stages in Med- VQA benefit from attention mechanisms and Transformer-based methods, the latter's \u2026"}, {"title": "Towards Improving Large Language Models' Planning Capabilities on WoT Thing Descriptions by Generating Python Objects as Intermediary Representations", "link": "https://ceur-ws.org/Vol-3749/akr3-06.pdf", "details": "L Kinder, T K\u00e4fer - 2024", "abstract": "This paper presents a novel method for plan generation with Large Language Model (LLM). We propose utilizing Web-of-Thing Thing Descriptions (WoT TD) to inform the LLM about available devices for interaction. We investigate a novel pipeline in \u2026"}]
