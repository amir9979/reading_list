[{"title": "Learning Multimodal Latent Space with EBM Prior and MCMC Inference", "link": "https://arxiv.org/pdf/2408.10467", "details": "S Yuan, C Lipizzi, T Han - arXiv preprint arXiv:2408.10467, 2024", "abstract": "Multimodal generative models are crucial for various applications. We propose an approach that combines an expressive energy-based model (EBM) prior with Markov Chain Monte Carlo (MCMC) inference in the latent space for multimodal generation \u2026"}, {"title": "LCE: A Framework for Explainability of DNNs for Ultrasound Image Based on Concept Discovery", "link": "https://arxiv.org/pdf/2408.09899", "details": "W Kong, X Gong, J Wang - arXiv preprint arXiv:2408.09899, 2024", "abstract": "Explaining the decisions of Deep Neural Networks (DNNs) for medical images has become increasingly important. Existing attribution methods have difficulty explaining the meaning of pixels while existing concept-based methods are limited by additional \u2026"}, {"title": "Low-Quality Image Detection by Hierarchical VAE", "link": "https://arxiv.org/pdf/2408.10885", "details": "T Nanaumi, K Kawamoto, H Kera - arXiv preprint arXiv:2408.10885, 2024", "abstract": "To make an employee roster, photo album, or training dataset of generative models, one needs to collect high-quality images while dismissing low-quality ones. This study addresses a new task of unsupervised detection of low-quality images. We \u2026"}, {"title": "EUDA: An Efficient Unsupervised Domain Adaptation via Self-Supervised Vision Transformer", "link": "https://arxiv.org/pdf/2407.21311", "details": "A Abedi, QM Wu, N Zhang, F Pourpanah - arXiv preprint arXiv:2407.21311, 2024", "abstract": "Unsupervised domain adaptation (UDA) aims to mitigate the domain shift issue, where the distribution of training (source) data differs from that of testing (target) data. Many models have been developed to tackle this problem, and recently vision \u2026"}, {"title": "Uniting contrastive and generative learning for event sequences models", "link": "https://arxiv.org/pdf/2408.09995", "details": "A Yugay, A Zaytsev - arXiv preprint arXiv:2408.09995, 2024", "abstract": "High-quality representation of transactional sequences is vital for modern banking applications, including risk management, churn prediction, and personalized customer offers. Different tasks require distinct representation properties: local tasks \u2026"}, {"title": "Zero-Shot Object-Centric Representation Learning", "link": "https://arxiv.org/pdf/2408.09162", "details": "A Didolkar, A Zadaianchuk, A Goyal, M Mozer\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The goal of object-centric representation learning is to decompose visual scenes into a structured representation that isolates the entities. Recent successes have shown that object-centric representation learning can be scaled to real-world scenes by \u2026"}]
