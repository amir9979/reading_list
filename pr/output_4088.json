[{"title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?", "link": "https://arxiv.org/pdf/2406.16316", "details": "Y Jinnai - arXiv preprint arXiv:2406.16316, 2024", "abstract": "Alignment of the language model with human preferences is a common approach to making a language model useful to end users. However, most alignment work is done in English, and human preference datasets are dominated by English \u2026"}, {"title": "Enhancing Explainable Rating Prediction through Annotated Macro Concepts", "link": "https://www4.comp.polyu.edu.hk/~xiaohuang/docs/2024_ACL_Huachi.pdf", "details": "H Zhou, S Zhou, H Chen, N Liu, F Yang, X Huang - Annual Meeting of the Association \u2026, 2024", "abstract": "Generating recommendation reasons for recommendation results is a long-standing problem because it is challenging to explain the underlying reasons for recommending an item based on user and item IDs. Existing models usually learn \u2026"}, {"title": "A Closer Look at Benchmarking Self-Supervised Pre-training with Image Classification", "link": "https://arxiv.org/pdf/2407.12210", "details": "M Marks, M Knott, N Kondapaneni, E Cole, T Defraeye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-supervised learning (SSL) is a machine learning approach where the data itself provides supervision, eliminating the need for external labels. The model is forced to learn about the data structure or context by solving a pretext task. With SSL, models \u2026"}, {"title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization", "link": "https://arxiv.org/pdf/2406.16743", "details": "Z Zhao, X Zhang, K Xu, X Hu, R Zhang, Z Du, Q Guo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the widespread application of Large Language Models (LLMs), it has become a significant concern to ensure their safety and prevent harmful responses. While current safe-alignment methods based on instruction fine-tuning and Reinforcement \u2026"}, {"title": "Calibrated Diverse Ensemble Entropy Minimization for Robust Test-Time Adaptation in Prostate Cancer Detection", "link": "https://arxiv.org/pdf/2407.12697", "details": "M Gilany, M Harmanani, P Wilson, MNN To, A Jamzad\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "High resolution micro-ultrasound has demonstrated promise in real-time prostate cancer detection, with deep learning becoming a prominent tool for learning complex tissue properties reflected on ultrasound. However, a significant roadblock to real \u2026"}, {"title": "Understanding the Role of User Profile in the Personalization of Large Language Models", "link": "https://arxiv.org/pdf/2406.17803", "details": "B Wu, Z Shi, HA Rahmani, V Ramineni, E Yilmaz - arXiv preprint arXiv:2406.17803, 2024", "abstract": "Utilizing user profiles to personalize Large Language Models (LLMs) has been shown to enhance the performance on a wide range of tasks. However, the precise role of user profiles and their effect mechanism on LLMs remains unclear. This study \u2026"}, {"title": "Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination", "link": "https://ieeecai.org/2024/wp-content/pdfs/540900a486/540900a486.pdf", "details": "X Zhong, K Batmanghelich, L Sun", "abstract": "Vision-language models pre-trained on large scale of unlabeled biomedical images and associated reports learn generalizable semantic representations. These multi- modal representations can benefit various downstream tasks in the biomedical \u2026"}, {"title": "Adversarial Black Box Attacks to Disrupt Large Language Models via Reinforcement Learning", "link": "https://practical-dl.github.io/2024/short_paper/4/CameraReady/4.pdf", "details": "WTJ Le, LJ Sern, YXM Tan", "abstract": "Large Language Models (LLMs) are effective in solving natural language processing (NLP) tasks, ie question answering and text generation. Recent works showed the possibility of generating adversarial suffixes to get valid responses from LLMs to \u2026"}, {"title": "Scaling Laws for Linear Complexity Language Models", "link": "https://arxiv.org/pdf/2406.16690", "details": "X Shen, D Li, R Leng, Z Qin, W Sun, Y Zhong - arXiv preprint arXiv:2406.16690, 2024", "abstract": "The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their \u2026"}]
