[{"title": "Alphaedit: Null-space constrained knowledge editing for language models", "link": "https://arxiv.org/pdf/2410.02355%3F", "details": "J Fang, H Jiang, K Wang, Y Ma, X Wang, X He, T Chua - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) often exhibit hallucinations due to incorrect or outdated knowledge. Hence, model editing methods have emerged to enable targeted knowledge updates. To achieve this, a prevailing paradigm is the locating \u2026"}, {"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2409.19330", "details": "H Chen, W Zhao, Y Li, T Zhong, Y Wang, Y Shang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Medical image analysis is crucial in modern radiological diagnostics, especially given the exponential growth in medical imaging data. The demand for automated report generation systems has become increasingly urgent. While prior research has \u2026"}, {"title": "No Need to Talk: Asynchronous Mixture of Language Models", "link": "https://arxiv.org/pdf/2410.03529%3F", "details": "A Filippova, A Katharopoulos, D Grangier, R Collobert - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce SmallTalk LM, an innovative method for training a mixture of language models in an almost asynchronous manner. Each model of the mixture specializes in distinct parts of the data distribution, without the need of high-bandwidth \u2026"}, {"title": "On Unsupervised Prompt Learning for Classification with Black-box Language Models", "link": "https://arxiv.org/pdf/2410.03124", "details": "ZY Zhang, J Zhang, H Yao, G Niu, M Sugiyama - arXiv preprint arXiv:2410.03124, 2024", "abstract": "Large language models (LLMs) have achieved impressive success in text-formatted learning problems, and most popular LLMs have been deployed in a black-box fashion. Meanwhile, fine-tuning is usually necessary for a specific downstream task \u2026"}, {"title": "Reflections on interactive visualization of electronic health records: past, present, future", "link": "https://academic.oup.com/jamia/article-abstract/31/11/2423/7824391", "details": "A Arleo, AT Chen, D Gotz, S Kandaswamy, J Bernard - Journal of the American \u2026, 2024", "abstract": "In the early 2000s, the transition to paperless documentation of patients' health data begun at large scale, with the introduction of Electronic Health and Medical Records (EHR and EMR, respectively). This constituted a paradigm shift in how patient data \u2026"}, {"title": "ChatGPT-4 extraction of heart failure symptoms and signs from electronic health records", "link": "https://www.sciencedirect.com/science/article/pii/S0033062024001476", "details": "TE Workman, A Ahmed, HM Sheriff, VK Raman\u2026 - Progress in Cardiovascular \u2026, 2024", "abstract": "Background Natural language processing (NLP) can facilitate research utilizing data from electronic health records (EHRs). Large language models can potentially improve NLP applications leveraging EHR notes. The objective of this study was to \u2026"}, {"title": "ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration", "link": "https://arxiv.org/pdf/2410.02551%3F", "details": "Z Wang, Y Zhu, H Zhao, X Zheng, T Wang, W Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with \u2026"}, {"title": "Computationally efficient and stable real-world synthetic emergency room electronic health record data generation: high similarity and privacy preserving diffusion \u2026", "link": "https://www.pfmjournal.org/upload/pdf/pfm-2024-00030.pdf", "details": "J Aguirre, JY Yu, KH Jung, J Yoon, WC Cha - Precision and Future Medicine, 2024", "abstract": "Purpose This study aimed to develop real-world synthetic electronic health record (EHR) for emergency departments using computationally efficient and stable diffusion probabilistic models. Methods In this study, we compared the performance \u2026"}]
