[{"title": "SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning", "link": "https://arxiv.org/pdf/2410.11200", "details": "R Kotoge, Z Chen, T Kimura, Y Matsubara\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While end-to-end multi-channel electroencephalography (EEG) learning approaches have shown significant promise, their applicability is often constrained in neurological diagnostics, such as intracranial EEG resources. When provided with a \u2026"}, {"title": "Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning", "link": "https://arxiv.org/pdf/2410.10144", "details": "H Yuan, S Liu, K Cho, K Liao, A Pereira, T Cai - arXiv preprint arXiv:2410.10144, 2024", "abstract": "We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a framework designed to bridge genetic and biomedical knowledge bases. What sets GENEREL apart is its ability to fine-tune language models to infuse \u2026"}, {"title": "Integrating Natural Language Models with Bayesian Networks for Explainable Machine Learning", "link": "https://www.sba.org.br/cba2024/papers/paper_9497.pdf", "details": "VB de Oliveira Barth, CD Maciel", "abstract": "The advancements brought by machine learning algorithms have significantly contributed to society, notably natural language models based on transformers, which have the capability to interpret user requests and respond in natural language \u2026"}]
