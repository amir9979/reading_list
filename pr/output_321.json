'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [KDMCSE: Knowledge Distillation Multimodal Sentence Em'
[{"title": "Automated Multi-Task Learning for Joint Disease Prediction on Electronic Health Records", "link": "https://arxiv.org/html/2403.04086v1", "details": "S Cui, P Mitra - arXiv preprint arXiv:2403.04086, 2024", "abstract": "In the realm of big data and digital healthcare, Electronic Health Records (EHR) have become a rich source of information with the potential to improve patient care and medical research. In recent years, machine learning models have proliferated for \u2026"}, {"title": "A foundation model utilizing chest CT volumes and radiology reports for supervised-level zero-shot detection of abnormalities", "link": "https://arxiv.org/pdf/2403.17834", "details": "IE Hamamci, S Er, F Almas, AG Simsek, SN Esirgun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "A major challenge in computational research in 3D medical imaging is the lack of comprehensive datasets. Addressing this issue, our study introduces CT-RATE, the first 3D medical imaging dataset that pairs images with textual reports. CT-RATE \u2026"}, {"title": "Prior tissue knowledge-driven contrastive learning for brain CT report generation", "link": "https://link.springer.com/article/10.1007/s00530-024-01289-w", "details": "Y Shi, J Ji, X Zhang, Y Liu, Z Wang, H Xu - Multimedia Systems, 2024", "abstract": "Writing medical reports for brain computed tomography (CT) is essential for radiologists to diagnose cerebrovascular diseases. Recent advances in medical report generation have driven significant progress in producing accurate descriptions \u2026"}, {"title": "Multi-Modal Contrastive Learning for Online Clinical Time-Series Applications", "link": "https://arxiv.org/pdf/2403.18316", "details": "F Baldenweg, M Burger, G R\u00e4tsch, R Kuznetsova - arXiv preprint arXiv:2403.18316, 2024", "abstract": "Electronic Health Record (EHR) datasets from Intensive Care Units (ICU) contain a diverse set of data modalities. While prior works have successfully leveraged multiple modalities in supervised settings, we apply advanced self-supervised multi \u2026"}, {"title": "Boosting Few-Shot Learning with Disentangled Self-Supervised Learning and Meta-Learning for Medical Image Classification", "link": "https://arxiv.org/html/2403.17530v1", "details": "E Pachetti, SA Tsaftaris, S Colantonio - arXiv preprint arXiv:2403.17530, 2024", "abstract": "Background and objective: Employing deep learning models in critical domains such as medical imaging poses challenges associated with the limited availability of training data. We present a strategy for improving the performance and \u2026"}, {"title": "ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models", "link": "https://arxiv.org/pdf/2403.11103", "details": "Y Heng, C Deng, Y Li, Y Yu, Y Li, R Zhang, C Zhang - arXiv preprint arXiv:2403.11103, 2024", "abstract": "Although Large Language Models (LLMs) exhibit remarkable adaptability across domains, these models often fall short in structured knowledge extraction tasks such as named entity recognition (NER). This paper explores an innovative, cost-efficient \u2026"}, {"title": "LCD Benchmark: Long Clinical Document Benchmark on Mortality Prediction", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/03/27/2024.03.26.24304920.full.pdf", "details": "WJ Yoon, S Chen, Y Gao, D Dligach, DS Bitterman\u2026 - medRxiv, 2024", "abstract": "Natural Language Processing (NLP) is a study of automated processing of text data. Application of NLP in the clinical domain is important due to the rich unstructured information implanted in clinical documents, which often remains inaccessible in \u2026"}, {"title": "BioMedLM: A 2.7 B Parameter Language Model Trained On Biomedical Text", "link": "https://arxiv.org/pdf/2403.18421", "details": "E Bolton, A Venigalla, M Yasunaga, D Hall, B Xiong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance on a wide variety of biomedical NLP tasks. However, these models have hundreds of billions of parameters, are computationally expensive to run \u2026"}, {"title": "An Empirical Study of Speech Language Models for Prompt-Conditioned Speech Synthesis", "link": "https://arxiv.org/pdf/2403.12402", "details": "Y Peng, I Kulikov, Y Yang, S Popuri, H Lu, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Speech language models (LMs) are promising for high-quality speech synthesis through in-context learning. A typical speech LM takes discrete semantic units as content and a short utterance as prompt, and synthesizes speech which preserves \u2026"}]
