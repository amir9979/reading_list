[{"title": "Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection", "link": "https://arxiv.org/pdf/2506.03964", "details": "HG Kim, J Mok, D Lee, J Lew, S Kim, S Yoon - arXiv preprint arXiv:2506.03964, 2025", "abstract": "Utilizing the complex inter-variable causal relationships within multivariate time- series provides a promising avenue toward more robust and reliable multivariate time-series anomaly detection (MTSAD) but remains an underexplored area of \u2026", "entry_id": "http://arxiv.org/abs/2506.03964v1", "updated": "2025-06-04 13:57:11", "published": "2025-06-04 13:57:11", "authors": "HyunGi Kim;Jisoo Mok;Dongjun Lee;Jaihyun Lew;Sungjae Kim;Sungroh Yoon", "summary": "Utilizing the complex inter-variable causal relationships within multivariate\ntime-series provides a promising avenue toward more robust and reliable\nmultivariate time-series anomaly detection (MTSAD) but remains an underexplored\narea of research. This paper proposes Causality-Aware contrastive learning for\nRObust multivariate Time-Series (CAROTS), a novel MTSAD pipeline that\nincorporates the notion of causality into contrastive learning. CAROTS employs\ntwo data augmentors to obtain causality-preserving and -disturbing samples that\nserve as a wide range of normal variations and synthetic anomalies,\nrespectively. With causality-preserving and -disturbing samples as positives\nand negatives, CAROTS performs contrastive learning to train an encoder whose\nlatent space separates normal and abnormal samples based on causality.\nMoreover, CAROTS introduces a similarity-filtered one-class contrastive loss\nthat encourages the contrastive learning process to gradually incorporate more\nsemantically diverse samples with common causal relationships. Extensive\nexperiments on five real-world and two synthetic datasets validate that the\nintegration of causal relationships endows CAROTS with improved MTSAD\ncapabilities. The code is available at https://github.com/kimanki/CAROTS.", "comment": "Accepted to ICML 2025", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.AI", "links": "http://arxiv.org/abs/2506.03964v1;http://arxiv.org/pdf/2506.03964v1", "pdf_url": "http://arxiv.org/pdf/2506.03964v1"}, {"title": "Conformal Prediction for Zero-Shot Models", "link": "https://openaccess.thecvf.com/content/CVPR2025/papers/Silva-Rodriguez_Conformal_Prediction_for_Zero-Shot_Models_CVPR_2025_paper.pdf", "details": "J Silva-Rodr\u00edguez, I Ben Ayed, J Dolz - Proceedings of the Computer Vision and \u2026, 2025", "abstract": "Vision-language models pre-trained at large scale have shown unprecedented adaptability and generalization to downstream tasks. Although its discriminative potential has been widely explored, its reliability and uncertainty are still overlooked \u2026"}, {"title": "Out-of-Distribution Detection with Adversarial Outlier Exposure", "link": "https://openaccess.thecvf.com/content/CVPR2025W/SAIAD/papers/Botschen_Out-of-Distribution_Detection_with_Adversarial_Outlier_Exposure_CVPRW_2025_paper.pdf", "details": "T Botschen, K Kirchheim, F Ortmeier - Proceedings of the Computer Vision and \u2026, 2025", "abstract": "Abstract Machine learning models typically perform reliably only on inputs drawn from the distribution they were trained on, making Out-of-Distribution (OOD) detection essential for safety-critical applications. While exposing models to example outliers \u2026"}, {"title": "Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models", "link": "https://arxiv.org/pdf/2506.00457", "details": "J Park, H Lee, D Lee, D Gwak, J Choo - arXiv preprint arXiv:2506.00457, 2025", "abstract": "Large Language Models (LLMs) have shown remarkable performance across diverse tasks without domain-specific training, fueling interest in their potential for time-series forecasting. While LLMs have shown potential in zero-shot forecasting \u2026", "entry_id": "http://arxiv.org/abs/2506.00457v1", "updated": "2025-05-31 08:24:01", "published": "2025-05-31 08:24:01", "authors": "Junwoo Park;Hyuck Lee;Dohyun Lee;Daehoon Gwak;Jaegul Choo", "summary": "Large Language Models (LLMs) have shown remarkable performance across diverse\ntasks without domain-specific training, fueling interest in their potential for\ntime-series forecasting. While LLMs have shown potential in zero-shot\nforecasting through prompting alone, recent studies suggest that LLMs lack\ninherent effectiveness in forecasting. Given these conflicting findings, a\nrigorous validation is essential for drawing reliable conclusions. In this\npaper, we evaluate the effectiveness of LLMs as zero-shot forecasters compared\nto state-of-the-art domain-specific models. Our experiments show that LLM-based\nzero-shot forecasters often struggle to achieve high accuracy due to their\nsensitivity to noise, underperforming even simple domain-specific models. We\nhave explored solutions to reduce LLMs' sensitivity to noise in the zero-shot\nsetting, but improving their robustness remains a significant challenge. Our\nfindings suggest that rather than emphasizing zero-shot forecasting, a more\npromising direction would be to focus on fine-tuning LLMs to better process\nnumerical sequences. Our experimental code is available at\nhttps://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster.", "comment": "Annual Meeting of the Association for Computational Linguistics\n  (ACL), 2025, Accepted as Short Paper", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2506.00457v1;http://arxiv.org/pdf/2506.00457v1", "pdf_url": "http://arxiv.org/pdf/2506.00457v1"}, {"title": "Cluster-Aware Causal Mixer for Online Anomaly Detection in Multivariate Time Series", "link": "https://arxiv.org/pdf/2506.00188", "details": "MMN Murad, Y Yilmaz - arXiv preprint arXiv:2506.00188, 2025", "abstract": "Early and accurate detection of anomalies in time series data is critical, given the significant risks associated with false or missed detections. While MLP-based mixer models have shown promise in time series analysis, they lack a causality mechanism \u2026", "entry_id": "http://arxiv.org/abs/2506.00188v1", "updated": "2025-05-30 19:56:54", "published": "2025-05-30 19:56:54", "authors": "Md Mahmuddun Nabi Murad;Yasin Yilmaz", "summary": "Early and accurate detection of anomalies in time series data is critical,\ngiven the significant risks associated with false or missed detections. While\nMLP-based mixer models have shown promise in time series analysis, they lack a\ncausality mechanism to preserve temporal dependencies inherent in the system.\nMoreover, real-world multivariate time series often contain numerous channels\nwith diverse inter-channel correlations. A single embedding mechanism for all\nchannels does not effectively capture these complex relationships. To address\nthese challenges, we propose a novel cluster-aware causal mixer to effectively\ndetect anomalies in multivariate time series. Our model groups channels into\nclusters based on their correlations, with each cluster processed through a\ndedicated embedding layer. In addition, we introduce a causal mixer in our\nmodel, which mixes the information while maintaining causality. Furthermore, we\npresent an anomaly detection framework that accumulates the anomaly evidence\nover time to prevent false positives due to nominal outliers. Our proposed\nmodel operates in an online fashion, making it suitable for real-time\ntime-series anomaly detection tasks. Experimental evaluations across six public\nbenchmark datasets demonstrate that our model consistently achieves superior F1\nscores.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;stat.ML", "links": "http://arxiv.org/abs/2506.00188v1;http://arxiv.org/pdf/2506.00188v1", "pdf_url": "http://arxiv.org/pdf/2506.00188v1"}, {"title": "CLIPMisD: Few-Shot Prompt Learning for Misclassification Detection with Vision Language Model", "link": "https://link.springer.com/chapter/10.1007/978-981-96-6954-7_23", "details": "F Zeng, Z Cheng, F Zhu, XY Zhang - International Conference on Neural Information \u2026, 2025", "abstract": "Reliable prediction of classifier is essential for its deployment in high security situations. However, modern networks tend to be overconfident for misclassified predictions, urging confidence estimation to identify the erroneous of predictions \u2026"}, {"title": "Robust Few-Shot Vision-Language Model Adaptation", "link": "https://arxiv.org/pdf/2506.04713", "details": "H Wang, T Liu, S Kong - arXiv preprint arXiv:2506.04713, 2025", "abstract": "Pretrained VLMs achieve strong performance on downstream tasks when adapted with just a few labeled examples. As the adapted models inevitably encounter out-of- distribution (OOD) test data that deviates from the in-distribution (ID) task-specific \u2026", "entry_id": "http://arxiv.org/abs/2506.04713v1", "updated": "2025-06-05 07:37:15", "published": "2025-06-05 07:37:15", "authors": "Hanxin Wang;Tian Liu;Shu Kong", "summary": "Pretrained VLMs achieve strong performance on downstream tasks when adapted\nwith just a few labeled examples. As the adapted models inevitably encounter\nout-of-distribution (OOD) test data that deviates from the in-distribution (ID)\ntask-specific training data, enhancing OOD generalization in few-shot\nadaptation is critically important. We study robust few-shot VLM adaptation,\naiming to increase both ID and OOD accuracy. By comparing different adaptation\nmethods (e.g., prompt tuning, linear probing, contrastive finetuning, and full\nfinetuning), we uncover three key findings: (1) finetuning with proper\nhyperparameters significantly outperforms the popular VLM adaptation methods\nprompt tuning and linear probing; (2) visual encoder-only finetuning achieves\nbetter efficiency and accuracy than contrastively finetuning both visual and\ntextual encoders; (3) finetuning the top layers of the visual encoder provides\nthe best balance between ID and OOD accuracy. Building on these findings, we\npropose partial finetuning of the visual encoder empowered with two simple\naugmentation techniques: (1) retrieval augmentation which retrieves\ntask-relevant data from the VLM's pretraining dataset to enhance adaptation,\nand (2) adversarial perturbation which promotes robustness during finetuning.\nResults show that the former/latter boosts OOD/ID accuracy while slightly\nsacrificing the ID/OOD accuracy. Yet, perhaps understandably, naively combining\nthe two does not maintain their best OOD/ID accuracy. We address this dilemma\nwith the developed SRAPF, Stage-wise Retrieval Augmentation-based Adversarial\nPartial Finetuning. SRAPF consists of two stages: (1) partial finetuning the\nvisual encoder using both ID and retrieved data, and (2) adversarial partial\nfinetuning with few-shot ID data. Extensive experiments demonstrate that SRAPF\nachieves the state-of-the-art ID and OOD accuracy on the ImageNet OOD\nbenchmarks.", "comment": "Project website: https://hannawang09.github.io/projects/srapf/", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2506.04713v1;http://arxiv.org/pdf/2506.04713v1", "pdf_url": "http://arxiv.org/pdf/2506.04713v1"}]
