'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [MedDr: Diagnosis-Guided Bootstrapping for Large-Scale '
[{"title": "Addax: Memory-Efficient Fine-Tuning of Language Models with a Combination of Forward-Backward and Forward-Only Passes", "link": "https://openreview.net/pdf%3Fid%3DYtZv36CY5p", "details": "Z Li, X Zhang, M Razaviyayn - 5th Workshop on practical ML for limited/low resource \u2026", "abstract": "Fine-tuning language models (LMs) with first-order optimizers often demands excessive memory, limiting accessibility, while zeroth-order optimizers use less memory, but suffer from slow convergence depending on model size. We introduce a \u2026"}, {"title": "Phi-3 technical report: A highly capable language model locally on your phone", "link": "https://arxiv.org/pdf/2404.14219%3Ftrk%3Dpublic_post_comment-text", "details": "M Abdin, SA Jacobs, AA Awan, J Aneja, A Awadallah\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT \u2026"}, {"title": "ODE-DPS: ODE-based Diffusion Posterior Sampling for Inverse Problems in Partial Differential Equation", "link": "https://arxiv.org/pdf/2404.13496", "details": "E Jiang, J Peng, Z Ma, XB Yan - arXiv preprint arXiv:2404.13496, 2024", "abstract": "In recent years we have witnessed a growth in mathematics for deep learning, which has been used to solve inverse problems of partial differential equations (PDEs). However, most deep learning-based inversion methods either require paired data or \u2026"}, {"title": "Light-VQA+: A Video Quality Assessment Model for Exposure Correction with Vision-Language Guidance", "link": "https://arxiv.org/pdf/2405.03333", "details": "X Zhou, X Liu, Y Dong, T Kou, Y Gao, Z Zhang, C Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, User-Generated Content (UGC) videos have gained popularity in our daily lives. However, UGC videos often suffer from poor exposure due to the limitations of photographic equipment and techniques. Therefore, Video Exposure Correction \u2026"}, {"title": "Markovian Agents for Truthful Language Modeling", "link": "https://arxiv.org/pdf/2404.18988", "details": "S Viteri, M Lamparth, P Chatain, C Barrett - arXiv preprint arXiv:2404.18988, 2024", "abstract": "Chain-of-Thought (CoT) reasoning could in principle enable a deeper understanding of a language model's (LM) internal reasoning. However, prior work suggests that some LMs answer questions similarly despite changes in their CoT, suggesting that \u2026"}, {"title": "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval", "link": "https://arxiv.org/pdf/2404.18424", "details": "S Zhuang, X Ma, B Koopman, J Lin, G Zuccon - arXiv preprint arXiv:2404.18424, 2024", "abstract": "The current use of large language models (LLMs) for zero-shot document ranking follows one of two ways: 1) prompt-based re-ranking methods, which require no further training but are feasible for only re-ranking a handful of candidate documents \u2026"}]
