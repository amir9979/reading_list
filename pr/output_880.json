'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [DELAN: Dual-Level Alignment for Vision-and-Language Na'
[{"title": "Cross Modal Training for ASR Error Correction with Contrastive Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10446621/", "details": "J Jiang, X Wan, W Peng, R Li, J Yang, Y Zhou - ICASSP 2024-2024 IEEE \u2026, 2024", "abstract": "ASR Error Correction (AEC) aims to post-process the output of ASR systems and further reduce the word error rate. In this paper, we propose a cross-modal training framework with contrastive learning on the AEC task. This framework enables a \u2026"}, {"title": "Enabling Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration", "link": "https://arxiv.org/pdf/2404.12715", "details": "Y Huang, X Feng, B Li, Y Xiang, H Wang, B Qin, T Liu - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have shown complementary strengths in various tasks and instances, motivating the research of ensembling LLMs to push the frontier leveraging the wisdom of the crowd. Existing work achieves this objective via training \u2026"}, {"title": "Offset Unlearning for Large Language Models", "link": "https://arxiv.org/pdf/2404.11045", "details": "JY Huang, W Zhou, F Wang, F Morstatter, S Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the strong capabilities of Large Language Models (LLMs) to acquire knowledge from their training corpora, the memorization of sensitive information in the corpora such as copyrighted, harmful, and private content has led to ethical and \u2026"}, {"title": "Meta Learning in Bandits within shared affine Subspaces", "link": "https://proceedings.mlr.press/v238/bilaj24a/bilaj24a.pdf", "details": "S Bilaj, S Dhouib, S Maghsudi - International Conference on Artificial Intelligence and \u2026, 2024", "abstract": "We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the \u2026"}, {"title": "GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided Language Data Generation", "link": "https://arxiv.org/pdf/2403.19754", "details": "M Gholami, M Akbari, C Hu, V Masrani, ZJ Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Knowledge distillation from LLMs is essential for the efficient deployment of language models. Prior works have proposed data generation using LLMs for preparing distilled models. We argue that generating data with LLMs is prone to \u2026"}, {"title": "Foundational Challenges in Assuring Alignment and Safety of Large Language Models", "link": "https://arxiv.org/pdf/2404.09932", "details": "U Anwar, A Saparov, J Rando, D Paleka, M Turpin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This work identifies 18 foundational challenges in assuring the alignment and safety of large language models (LLMs). These challenges are organized into three different categories: scientific understanding of LLMs, development and deployment \u2026"}, {"title": "TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model", "link": "https://arxiv.org/pdf/2404.01273", "details": "Y Wang, Y Lu, Y Xu, Z Ma, H Xu, B Du, H Gao, J Wu - arXiv preprint arXiv:2404.01273, 2024", "abstract": "Recently, there has been a burgeoning interest in virtual clinical trials, which simulate real-world scenarios and hold the potential to significantly enhance patient safety, expedite development, reduce costs, and contribute to the broader scientific \u2026"}, {"title": "Edinburgh Clinical NLP at SemEval-2024 Task 2: Fine-tune your model unless you have access to GPT-4", "link": "https://arxiv.org/pdf/2404.00484", "details": "AP Gema, G Hong, P Minervini, L Daines, B Alex - arXiv preprint arXiv:2404.00484, 2024", "abstract": "The NLI4CT task assesses Natural Language Inference systems in predicting whether hypotheses entail or contradict evidence from Clinical Trial Reports. In this study, we evaluate various Large Language Models (LLMs) with multiple strategies \u2026"}, {"title": "BERT-based language model for accurate drug adverse event extraction from social media: implementation, evaluation, and contributions to pharmacovigilance \u2026", "link": "https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2024.1392180/pdf", "details": "F Dong, W Guo, J Liu, TA Patterson, H Hong - Frontiers in Public Health, 2024", "abstract": "Introduction Social media platforms serve as a valuable resource for users to share health-related information, aiding in the monitoring of adverse events linked to medications and treatments in drug safety surveillance. However, extracting drug \u2026"}]
