[{"title": "MiMo: Unlocking the Reasoning Potential of Language Model--From Pretraining to Posttraining", "link": "https://arxiv.org/pdf/2505.07608", "details": "B Xia, B Shen, D Zhu, D Zhang, G Wang, H Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing \u2026"}, {"title": "Evolutionary thoughts: integration of large language models and evolutionary algorithms", "link": "https://arxiv.org/pdf/2505.05756", "details": "AJ Yepes, P Barnard - arXiv preprint arXiv:2505.05756, 2025", "abstract": "Large Language Models (LLMs) have unveiled remarkable capabilities in understanding and generating both natural language and code, but LLM reasoning is prone to hallucination and struggle with complex, novel scenarios, often getting \u2026"}, {"title": "xGen-small Technical Report", "link": "https://arxiv.org/pdf/2505.06496", "details": "E Nijkamp, B Pang, E Pakhomov, A Gokul, J Qu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce xGen-small, a family of 4B and 9B Transformer decoder models optimized for long-context applications. Our vertically integrated pipeline unites domain-balanced, frequency-aware data curation; multi-stage pre-training with \u2026"}, {"title": "Benchmarking Vision Language Models on German Factual Data", "link": "https://arxiv.org/pdf/2504.11108%3F", "details": "R Peinl, V Tischler - arXiv preprint arXiv:2504.11108, 2025", "abstract": "Similar to LLMs, the development of vision language models is mainly driven by English datasets and models trained in English and Chinese language, whereas support for other languages, even those considered high-resource languages such \u2026"}, {"title": "Knowledge Distillation for Enhancing Walmart E-commerce Search Relevance Using Large Language Models", "link": "https://arxiv.org/pdf/2505.07105", "details": "H Shang, N Vo, N Yadav, T Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Ensuring the products displayed in e-commerce search results are relevant to users queries is crucial for improving the user experience. With their advanced semantic understanding, deep learning models have been widely used for relevance matching \u2026"}, {"title": "Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large Language Models", "link": "https://arxiv.org/pdf/2504.20469", "details": "E Fane, M Surdeanu, E Blanco, SR Corman - arXiv preprint arXiv:2504.20469, 2025", "abstract": "Understanding how news narratives frame entities is crucial for studying media's impact on societal perceptions of events. In this paper, we evaluate the zero-shot capabilities of large language models (LLMs) in classifying framing roles. Through \u2026"}, {"title": "Evaluation of Prompting Strategies for Cyberbullying Detection Using Various Large Language Models", "link": "https://cybersecurityjournal.info/uploads/archivepdf/532921109%2520\\(1\\).pdf", "details": "A Gupta, S Garg, H Bamotra - 2025", "abstract": "Sentiment analysis detects toxic language for safer online spaces and helps businesses refine strategies through customer feedback analysis [1, 2]. Advancements in Large Language Models (LLMs) and prompt engineering have \u2026"}]
