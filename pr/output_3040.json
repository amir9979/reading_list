[{"title": "Media Bias Detection Across Families of Language Models", "link": "https://aclanthology.org/2024.naacl-long.227.pdf", "details": "I Maab, E Marrese-Taylor, S Pad\u00f3, Y Matsuo - Proceedings of the 2024 Conference of \u2026, 2024", "abstract": "Bias in reporting can influence the public's opinion on relevant societal issues. Examples include informational bias (selective presentation of content) and lexical bias (specific framing of content through linguistic choices). The recognition of media \u2026"}, {"title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain", "link": "https://arxiv.org/pdf/2406.06435", "details": "B Hu, B Ray, A Leung, A Summerville, D Joy, C Funk\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In difficult decision-making scenarios, it is common to have conflicting opinions among expert human decision-makers as there may not be a single right answer. Such decisions may be guided by different attributes that can be used to characterize \u2026"}, {"title": "Molecular Data Programming: Towards Molecule Pseudo-labeling with Systematic Weak Supervision", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Juan_Molecular_Data_Programming_Towards_Molecule_Pseudo-labeling_with_Systematic_Weak_Supervision_CVPR_2024_paper.pdf", "details": "X Juan, K Zhou, N Liu, T Chen, X Wang - Proceedings of the IEEE/CVF Conference \u2026, 2024", "abstract": "The premise for the great advancement of molecular machine learning is dependent on a considerable amount of labeled data. In many real-world scenarios the labeled molecules are limited in quantity or laborious to derive. Recent pseudo-labeling \u2026"}, {"title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models", "link": "https://arxiv.org/pdf/2406.04306", "details": "L Aichberger, K Schweighofer, M Ielanskyi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) can suffer from hallucinations when generating text. These hallucinations impede various applications in society and industry by making LLMs untrustworthy. Current LLMs generate text in an autoregressive fashion by \u2026"}, {"title": "Abstraction-of-Thought Makes Language Models Better Reasoners", "link": "https://arxiv.org/pdf/2406.12442", "details": "R Hong, H Zhang, X Pan, D Yu, C Zhang - arXiv preprint arXiv:2406.12442, 2024", "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks \u2026"}, {"title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models", "link": "https://aclanthology.org/2024.findings-naacl.18.pdf", "details": "Z Su, Z Lin, B Baixue, H Chen, S Hu, W Zhou, G Ding\u2026 - Findings of the Association \u2026, 2024", "abstract": "Generative language models are usually pre-trained on large text corpus via predicting the next token (ie, sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language \u2026"}, {"title": "Instruction Pre-Training: Language Models are Supervised Multitask Learners", "link": "https://arxiv.org/pdf/2406.14491", "details": "D Cheng, Y Gu, S Huang, J Bi, M Huang, F Wei - arXiv preprint arXiv:2406.14491, 2024", "abstract": "Unsupervised multitask pre-training has been the critical method behind the recent success of language models (LMs). However, supervised multitask learning still holds significant promise, as scaling it in the post-training stage trends towards better \u2026"}, {"title": "On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning", "link": "https://arxiv.org/pdf/2406.14197", "details": "F Nowak, A Svete, A Butoi, R Cotterell - arXiv preprint arXiv:2406.14197, 2024", "abstract": "The performance of modern language models (LMs) has been improved by chain-of- thought (CoT) reasoning, ie, the process of generating intermediate results that guide the model towards a final answer. A possible explanation for this improvement is that \u2026"}, {"title": "Memory Augmented Language Models through Mixture of Word Experts", "link": "https://aclanthology.org/2024.naacl-long.249.pdf", "details": "C dos Santos, J Lee-Thorp, I Noble, CC Chang\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Scaling up the number of parameters of language models has proven to be an effective approach to improve performance. For dense models, increasing their size proportionally increases their computational footprint. In this work, we seek to \u2026"}]
