[{"title": "IRIT-Berger-Levrault at SemEval-2024: How Sensitive Sentence Embeddings are to Hallucinations?", "link": "https://aclanthology.org/2024.semeval-1.86.pdf", "details": "N Bendahman, K Pinel-Sauvagnat, G Hubert, M Billami - Proceedings of the 18th \u2026, 2024", "abstract": "This article presents our participation to Task 6 of SemEval-2024, named SHROOM (a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes), which aims at detecting hallucinations. We propose two types of approaches for the \u2026"}, {"title": "Task Oriented In-Domain Data Augmentation", "link": "https://arxiv.org/pdf/2406.16694", "details": "X Liang, X Hu, S Zuo, Y Gong, Q Lou, Y Liu, SL Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have shown superior performance in various applications and fields. To achieve better performance on specialized domains such as law and advertisement, LLMs are often continue pre-trained on in-domain data \u2026"}, {"title": "Enhancing Data Privacy in Large Language Models through Private Association Editing", "link": "https://arxiv.org/pdf/2406.18221", "details": "D Venditti, ES Ruzzetti, GA Xompero, C Giannone\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) are powerful tools with extensive applications, but their tendency to memorize private information raises significant concerns as private data leakage can easily happen. In this paper, we introduce Private Association \u2026"}, {"title": "Multi-Turn Hidden Backdoor in Large Language Model-powered Chatbot Models", "link": "https://dl.acm.org/doi/pdf/10.1145/3634737.3656289", "details": "B Chen, N Ivanov, G Wang, Q Yan - Proceedings of the 19th ACM Asia Conference on \u2026, 2024", "abstract": "Large Language Model (LLM)-powered chatbot services like GPTs, simulating human-to-human conversation via machine-generated text, are used in numerous fields. They are enhanced by the model fine-tuning process and the utilization of \u2026"}]
