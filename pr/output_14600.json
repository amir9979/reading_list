[{"title": "Efficient and explainable sequential recommendation with language model", "link": "https://drive.google.com/file/d/11rlrXoCrYwH9mIJCDfw2gHwD8PCImjoK/view", "details": "Z Li, L Zou, C Ma, C Li - Information Processing & Management, 2025", "abstract": "Motivated by the outstanding success of large language models (LLMs) in a broad spectrum of NLP tasks, applying them for explainable recommendation become a cutting-edge recently. However, due to the inherent inconsistency in the information \u2026"}, {"title": "Counterfactual Language Reasoning for Explainable Recommendation Systems", "link": "https://arxiv.org/pdf/2503.08051", "details": "G Li, H Yang, X Liu, Z Wu, X Dai - arXiv preprint arXiv:2503.08051, 2025", "abstract": "Explainable recommendation systems leverage transparent reasoning to foster user trust and improve decision-making processes. Current approaches typically decouple recommendation generation from explanation creation, violating causal \u2026"}, {"title": "Behaviour Discovery and Attribution for Explainable Reinforcement Learning", "link": "https://arxiv.org/pdf/2503.14973%3F", "details": "R Rishav, S Nath, V Michalski, SE Kahou - arXiv preprint arXiv:2503.14973, 2025", "abstract": "Explaining the decisions made by reinforcement learning (RL) agents is critical for building trust and ensuring reliability in real-world applications. Traditional approaches to explainability often rely on saliency analysis, which can be limited in \u2026"}, {"title": "Multi-modal hypergraph contrastive learning for medical image segmentation", "link": "https://www.sciencedirect.com/science/article/pii/S0031320325002043", "details": "W Jing, J Wang, D Di, D Li, Y Song, L Fan - Pattern Recognition, 2025", "abstract": "Self-supervised learning (SSL) has become a dominant approach in multi-modal medical image segmentation. However, existing methods, such as Seq SSL and Joint SSL, suffer from catastrophic forgetting and conflicts in representation learning \u2026"}, {"title": "Hybrid Fine-Tuning of Large Language Models Using LoRA: Enhancing Multi-Task Text Classification Through Knowledge Sharing", "link": "https://jecei.sru.ac.ir/article_2303.html", "details": "J Salimi Sartakhti, A Beirnvand, M Sarhadi - Journal of Electrical and Computer \u2026, 2025", "abstract": "Background and Objectives: Large Language Models have demonstrated\u200e exceptional performance across various NLP tasks, especially when fine-tuned for\u200e specific applications.\u200e\u200f\u200f Full fine-tuning of large language models requires extensive\u200e \u2026"}, {"title": "OUTLIER-AWARE PREFERENCE OPTIMIZATION FOR LARGE LANGUAGE MODELS", "link": "https://openreview.net/pdf%3Fid%3DYevRFGa9I7", "details": "P Srivastava, SS Nalli, A Deshpande, A Sharma - \u2026 in Foundation Models: The Next Frontier in \u2026", "abstract": "Aligning large language models (LLMs) to user preferences often relies on learning a reward model as a proxy from feedback. However, such reward models can fail on out-of-distribution examples and, if kept static, may reinforce incorrect preferences \u2026"}]
