[{"title": "KALIE: Fine-Tuning Vision-Language Models for Open-World Manipulation without Robot Data", "link": "https://arxiv.org/pdf/2409.14066", "details": "G Tang, S Rajkumar, Y Zhou, HR Walke, S Levine\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Building generalist robotic systems involves effectively endowing robots with the capabilities to handle novel objects in an open-world setting. Inspired by the advances of large pre-trained models, we propose Keypoint Affordance Learning \u2026"}, {"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Evaluation of pretrained language models on music understanding", "link": "https://arxiv.org/pdf/2409.11449", "details": "Y Vasilakis, R Bittner, J Pauwels - arXiv preprint arXiv:2409.11449, 2024", "abstract": "Music-text multimodal systems have enabled new approaches to Music Information Research (MIR) applications such as audio-to-text and text-to-audio retrieval, text- based song generation, and music captioning. Despite the reported success, little \u2026"}, {"title": "Synthetic Data Distillation Enables the Extraction of Clinical Information at Scale", "link": "https://www.medrxiv.org/content/10.1101/2024.09.27.24314517.full.pdf", "details": "EG Woo, MC Burkhart, E Alsentzer, B Beaulieu-Jones - medRxiv, 2024", "abstract": "Large-language models (LLMs) have shown promising potential for extracting information from clinical notes. Deploying these models at scale can be challenging due to high computational costs, regulatory constraints, and privacy concerns. To \u2026"}]
