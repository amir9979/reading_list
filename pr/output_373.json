'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [DSDCLNet: Dual-Stream Encoder and Dual-Level Contrastive Lea'
[{"title": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "link": "https://arxiv.org/pdf/2403.12015", "details": "A Sauer, F Boesel, T Dockhorn, A Blattmann, P Esser\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Diffusion models are the main driver of progress in image and video synthesis, but suffer from slow inference speed. Distillation methods, like the recently introduced adversarial diffusion distillation (ADD) aim to shift the model from many-shot to single \u2026"}, {"title": "ConvTimeNet: A Deep Hierarchical Fully Convolutional Model for Multivariate Time Series Analysis", "link": "https://arxiv.org/pdf/2403.01493", "details": "M Cheng, J Yang, T Pan, Q Liu, Z Li - arXiv preprint arXiv:2403.01493, 2024", "abstract": "This paper introduces ConvTimeNet, a novel deep hierarchical fully convolutional network designed to serve as a general-purpose model for time series analysis. The key design of this network is twofold, designed to overcome the limitations of \u2026"}, {"title": "Learning evolving relations for multivariate time series forecasting", "link": "https://link.springer.com/article/10.1007/s10489-023-05220-0", "details": "B Nguyen-Thai, V Le, NDT Tieu, T Tran, S Venkatesh\u2026 - Applied Intelligence, 2024", "abstract": "Multivariate time series forecasting is essential in various fields, including healthcare and traffic management, but it is a challenging task due to the strong dynamics in both intra-channel relations (temporal patterns within individual variables) and inter \u2026"}, {"title": "Approximations to the Fisher Information Metric of Deep Generative Models for Out-Of-Distribution Detection", "link": "https://arxiv.org/html/2403.01485v1", "details": "S Dauncey, C Holmes, C Williams, F Falck - arXiv preprint arXiv:2403.01485, 2024", "abstract": "Likelihood-based deep generative models such as score-based diffusion models and variational autoencoders are state-of-the-art machine learning models approximating high-dimensional distributions of data such as images, text, or audio \u2026"}, {"title": "Taming Pre-trained LLMs for Generalised Time Series Forecasting via Cross-modal Knowledge Distillation", "link": "https://arxiv.org/html/2403.07300v1", "details": "P Liu, H Guo, T Dai, N Li, J Bao, X Ren, Y Jiang, ST Xia - arXiv preprint arXiv \u2026, 2024", "abstract": "Multivariate time series forecasting has recently gained great success with the rapid growth of deep learning models. However, existing approaches usually train models from scratch using limited temporal data, preventing their generalization. Recently \u2026"}, {"title": "Reward Guided Latent Consistency Distillation", "link": "https://arxiv.org/html/2403.11027v1", "details": "J Li, W Feng, W Chen, WY Wang - arXiv preprint arXiv:2403.11027, 2024", "abstract": "Latent Consistency Distillation (LCD) has emerged as a promising paradigm for efficient text-to-image synthesis. By distilling a latent consistency model (LCM) from a pre-trained teacher latent diffusion model (LDM), LCD facilitates the generation of \u2026"}]
