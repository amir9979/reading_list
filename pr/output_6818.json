[{"title": "Bilingual Evaluation of Language Models on General Knowledge in University Entrance Exams with Minimal Contamination", "link": "https://arxiv.org/pdf/2409.12746", "details": "ES Salido, R Morante, J Gonzalo, G Marco\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this article we present UNED-ACCESS 2024, a bilingual dataset that consists of 1003 multiple-choice questions of university entrance level exams in Spanish and English. Questions are originally formulated in Spanish and translated manually into \u2026"}, {"title": "Exploring and Enhancing the Transfer of Distribution in Knowledge Distillation for Autoregressive Language Models", "link": "https://arxiv.org/pdf/2409.12512", "details": "J Rao, X Liu, Z Lin, L Ding, J Li, D Tao - arXiv preprint arXiv:2409.12512, 2024", "abstract": "Knowledge distillation (KD) is a technique that compresses large teacher models by training smaller student models to mimic them. The success of KD in auto-regressive language models mainly relies on Reverse KL for mode-seeking and student \u2026"}, {"title": "The Gaussian Discriminant Variational Autoencoder (GdVAE): A Self-Explainable Model with Counterfactual Explanations", "link": "https://arxiv.org/pdf/2409.12952", "details": "A Haselhoff, K Trelenberg, F K\u00fcppers, J Schneider - arXiv preprint arXiv:2409.12952, 2024", "abstract": "Visual counterfactual explanation (CF) methods modify image concepts, eg, shape, to change a prediction to a predefined outcome while closely resembling the original query image. Unlike self-explainable models (SEMs) and heatmap techniques, they \u2026"}, {"title": "Multi-modal contrastive learning of subcellular organization using DICE", "link": "https://academic.oup.com/bioinformatics/article-pdf/40/Supplement_2/ii105/59016944/btae387.pdf", "details": "R Nasser, LV Schaffer, T Ideker, R Sharan - Bioinformatics, 2024", "abstract": "The data deluge in biology calls for computational approaches that can integrate multiple datasets of different types to build a holistic view of biological processes or structures of interest. An emerging paradigm in this domain is the unsupervised \u2026"}, {"title": "JourneyBench: A Challenging One-Stop Vision-Language Understanding Benchmark of Generated Images", "link": "https://arxiv.org/pdf/2409.12953", "details": "Z Wang, J Liu, CW Tang, H Alomari, A Sivakumar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing vision-language understanding benchmarks largely consist of images of objects in their usual contexts. As a consequence, recent multimodal large language models can perform well with only a shallow visual understanding by relying on \u2026"}, {"title": "RAD-Bench: Evaluating Large Language Models Capabilities in Retrieval Augmented Dialogues", "link": "https://arxiv.org/pdf/2409.12558", "details": "TL Kuo, FT Liao, MW Hsieh, FC Chang, PC Hsu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In real-world applications with Large Language Models (LLMs), external retrieval mechanisms-such as Search-Augmented Generation (SAG), tool utilization, and Retrieval-Augmented Generation (RAG)-are often employed to enhance the quality \u2026"}, {"title": "Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data", "link": "https://arxiv.org/pdf/2409.12437", "details": "J Zhou, A Ghaddar, G Zhang, L Ma, Y Hu, S Pal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite recent advances in training and prompting strategies for Large Language Models (LLMs), these models continue to face challenges with complex logical reasoning tasks that involve long reasoning chains. In this work, we explore the \u2026"}]
