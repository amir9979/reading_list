[{"title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense", "link": "https://arxiv.org/pdf/2503.11619", "details": "S Hao, Y Wang, B Hooi, MH Yang, J Liu, C Tang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations:(1) They solely focus on textual defenses, fail \u2026"}, {"title": "Enhancing Multi-hop Reasoning in Vision-Language Models via Self-Distillation with Multi-Prompt Ensembling", "link": "https://arxiv.org/pdf/2503.01754%3F", "details": "G Wu, H Song, Y Wang, Q Yan, Y Tian, LL Cheong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multi-modal large language models have seen rapid advancement alongside large language models. However, while language models can effectively leverage chain- of-thought prompting for zero or few-shot learning, similar prompting strategies are \u2026"}, {"title": "Process-based self-rewarding language models", "link": "https://arxiv.org/pdf/2503.03746", "details": "S Zhang, X Liu, X Zhang, J Liu, Z Luo, S Huang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' \u2026"}, {"title": "Mitigating Hallucinations in Large Vision-Language Models by Adaptively Constraining Information Flow", "link": "https://arxiv.org/pdf/2502.20750", "details": "J Bai, H Guo, Z Peng, J Yang, Z Li, M Li, Z Tian - arXiv preprint arXiv:2502.20750, 2025", "abstract": "Large vision-language models show tremendous potential in understanding visual information through human languages. However, they are prone to suffer from object hallucination, ie, the generated image descriptions contain objects that do not exist in \u2026"}, {"title": "Multi-Cue Adaptive Visual Token Pruning for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.08019", "details": "B Luan, W Zhou, H Feng, Z Wang, X Li, H Li - arXiv preprint arXiv:2503.08019, 2025", "abstract": "As the computational needs of Large Vision-Language Models (LVLMs) increase, visual token pruning has proven effective in improving inference speed and memory efficiency. Traditional pruning methods in LVLMs predominantly focus on attention \u2026"}, {"title": "MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways", "link": "https://arxiv.org/pdf/2503.13205", "details": "Z Chen, Z Peng, X Liang, C Wang, P Liang, L Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited \u2026"}, {"title": "Inference retrieval-augmented multi-modal chain-of-thoughts reasoning for language models", "link": "https://ieeexplore.ieee.org/abstract/document/10888701/", "details": "Q He, S Qian, J Zhang, C Wang - ICASSP 2025-2025 IEEE International Conference \u2026, 2025", "abstract": "Recent advancements in Large Language Models (LLMs) have catalyzed the exploration of Chain of Thought (CoT) approaches, particularly in extending their application to multimodal tasks to enhance reasoning capabilities. However, current \u2026"}, {"title": "Audio-reasoner: Improving reasoning capability in large audio language models", "link": "https://arxiv.org/pdf/2503.02318", "details": "Z Xie, M Lin, Z Liu, P Wu, S Yan, C Miao - arXiv preprint arXiv:2503.02318, 2025", "abstract": "Recent advancements in multimodal reasoning have largely overlooked the audio modality. We introduce Audio-Reasoner, a large-scale audio language model for deep reasoning in audio tasks. We meticulously curated a large-scale and diverse \u2026"}, {"title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models", "link": "https://arxiv.org/pdf/2503.05005", "details": "B Jamialahmadi, P Kavehzadeh, M Rezagholizadeh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deploying large language models (LLMs) in real-world applications is often hindered by strict computational and latency constraints. While dynamic inference offers the flexibility to adjust model behavior based on varying resource budgets, existing \u2026"}]
