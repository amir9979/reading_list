[{"title": "Emotion AWARE: an artificial intelligence framework for adaptable, robust, explainable, and multi-granular emotion analysis", "link": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-024-00953-2", "details": "G Gamage, D De Silva, N Mills, D Alahakoon, M Manic - Journal of Big Data, 2024", "abstract": "Emotions are fundamental to human behaviour. How we feel, individually and collectively, determines how humanity evolves and advances into our shared future. The rapid digitalisation of our personal, social and professional lives means we are \u2026"}, {"title": "SparseCL: Sparse Contrastive Learning for Contradiction Retrieval", "link": "https://arxiv.org/pdf/2406.10746", "details": "H Xu, Z Lin, Y Sun, KW Chang, P Indyk - arXiv preprint arXiv:2406.10746, 2024", "abstract": "Contradiction retrieval refers to identifying and extracting documents that explicitly disagree with or refute the content of a query, which is important to many downstream applications like fact checking and data cleaning. To retrieve \u2026"}, {"title": "Understanding the Role of User Profile in the Personalization of Large Language Models", "link": "https://arxiv.org/pdf/2406.17803", "details": "B Wu, Z Shi, HA Rahmani, V Ramineni, E Yilmaz - arXiv preprint arXiv:2406.17803, 2024", "abstract": "Utilizing user profiles to personalize Large Language Models (LLMs) has been shown to enhance the performance on a wide range of tasks. However, the precise role of user profiles and their effect mechanism on LLMs remains unclear. This study \u2026"}, {"title": "GCON: Differentially Private Graph Convolutional Network via Objective Perturbation", "link": "https://arxiv.org/pdf/2407.05034", "details": "J Wei, Y Zhu, X Xiao, E Bao, Y Yang, K Cai, BC Ooi - arXiv preprint arXiv:2407.05034, 2024", "abstract": "Graph Convolutional Networks (GCNs) are a popular machine learning model with a wide range of applications in graph analytics, including healthcare, transportation, and finance. Similar to other neural networks, a GCN may memorize parts of the \u2026"}, {"title": "Hybrid Explanatory Interactive Machine Learning for Medical Diagnosis", "link": "https://link.springer.com/chapter/10.1007/978-3-031-63211-2_9", "details": "E Slany, S Scheele, U Schmid - IFIP International Conference on Artificial Intelligence \u2026, 2024", "abstract": "Abstract Machine learning (ML) models can be an effective assistance in medical diagnosis if they allow physicians to project their knowledge into model's internal mechanism. Using model-agnostic explanatory interactive ML (XIML), physicians \u2026"}, {"title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?", "link": "https://arxiv.org/pdf/2406.16316", "details": "Y Jinnai - arXiv preprint arXiv:2406.16316, 2024", "abstract": "Alignment of the language model with human preferences is a common approach to making a language model useful to end users. However, most alignment work is done in English, and human preference datasets are dominated by English \u2026"}, {"title": "Scaling Laws for Linear Complexity Language Models", "link": "https://arxiv.org/pdf/2406.16690", "details": "X Shen, D Li, R Leng, Z Qin, W Sun, Y Zhong - arXiv preprint arXiv:2406.16690, 2024", "abstract": "The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their \u2026"}, {"title": "Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models", "link": "https://arxiv.org/pdf/2406.14091", "details": "D Lee, D Rim, M Choi, J Choo - arXiv preprint arXiv:2406.14091, 2024", "abstract": "Although language models (LMs) demonstrate exceptional capabilities on various tasks, they are potentially vulnerable to extraction attacks, which represent a significant privacy risk. To mitigate the privacy concerns of LMs, machine unlearning \u2026"}, {"title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization", "link": "https://arxiv.org/pdf/2406.16743", "details": "Z Zhao, X Zhang, K Xu, X Hu, R Zhang, Z Du, Q Guo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the widespread application of Large Language Models (LLMs), it has become a significant concern to ensure their safety and prevent harmful responses. While current safe-alignment methods based on instruction fine-tuning and Reinforcement \u2026"}]
