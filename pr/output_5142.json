[{"title": "Contrastive Learning with Counterfactual Explanations for Radiology Report Generation", "link": "https://arxiv.org/pdf/2407.14474", "details": "M Li, H Lin, L Qiu, X Liang, L Chen, A Elsaddik\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Due to the common content of anatomy, radiology images with their corresponding reports exhibit high similarity. Such inherent data bias can predispose automatic report generation models to learn entangled and spurious representations resulting \u2026"}, {"title": "CryoSamba: self-supervised deep volumetric denoising for cryo-electron tomography data", "link": "https://www.biorxiv.org/content/10.1101/2024.07.11.603117.full.pdf", "details": "JI Costa-Filho, L Theveny, M de Sautu, T Kirchhausen - bioRxiv, 2024", "abstract": "Cryogenic electron tomography (cryo-ET) has rapidly advanced as a high-resolution imaging tool for visualizing subcellular structures in 3D with molecular detail. Direct image inspection remains challenging due to inherent low signal-to-noise ratios \u2026"}, {"title": "Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models", "link": "https://arxiv.org/pdf/2407.11717", "details": "C Ju, H Wang, H Cheng, X Chen, Z Zhai, W Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Large Models (VLMs) recently become primary backbone of AI, due to the impressive performance. However, their expensive computation costs, ie, throughput and delay, impede potentials in the real-world scenarios. To achieve \u2026"}, {"title": "UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model", "link": "https://arxiv.org/pdf/2408.02503", "details": "Z Li, W Wang, YQ Cai, X Qi, P Wang, D Zhang, H Song\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Significant advancements has recently been achieved in the field of multi-modal large language models (MLLMs), demonstrating their remarkable capabilities in understanding and reasoning across diverse tasks. However, these models are often \u2026"}, {"title": "Active Testing of Large Language Model via Multi-Stage Sampling", "link": "https://arxiv.org/pdf/2408.03573", "details": "Y Huang, J Song, Q Hu, F Juefei-Xu, L Ma - arXiv preprint arXiv:2408.03573, 2024", "abstract": "Performance evaluation plays a crucial role in the development life cycle of large language models (LLMs). It estimates the model's capability, elucidates behavior characteristics, and facilitates the identification of potential issues and limitations \u2026"}]
