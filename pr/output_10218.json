[{"title": "Style-Pro: Style-Guided Prompt Learning for Generalizable Vision-Language Models", "link": "https://arxiv.org/pdf/2411.16018", "details": "NA Talemi, H Kashiani, F Afghah - arXiv preprint arXiv:2411.16018, 2024", "abstract": "Pre-trained Vision-language (VL) models, such as CLIP, have shown significant generalization ability to downstream tasks, even with minimal fine-tuning. While prompt learning has emerged as an effective strategy to adapt pre-trained VL models \u2026"}, {"title": "Active learning for extracting rare adverse events from electronic health records: A study in pediatric cardiology", "link": "https://www.sciencedirect.com/science/article/pii/S1386505624004246", "details": "S Quennelle, S Malekzadeh-Milani, N Garcelon\u2026 - International Journal of \u2026, 2024", "abstract": "Objective Automate the extraction of adverse events from the text of electronic medical records of patients hospitalized for cardiac catheterization. Methods We focused on events related to cardiac catheterization as defined by the NCDR \u2026"}, {"title": "Minerva LLMs: The First Family of Large Language Models Trained from Scratch on Italian Data", "link": "https://clic2024.ilc.cnr.it/wp-content/uploads/2024/12/76_main_long.pdf", "details": "R Orlando, L Moroni, PLH Cabot, E Barba, S Conia\u2026 - Proc. of CLiC-it, 2024", "abstract": "The growing interest in Large Language Models (LLMs) has accelerated research efforts to adapt these models for various languages. Despite this, pretraining LLMs from scratch for non-English languages remains underexplored. This is the case for \u2026"}, {"title": "Towards Resource Efficient and Interpretable Bias Mitigation in Large Language Models", "link": "https://arxiv.org/pdf/2412.01711", "details": "S Tong, E Zemour, R Lohanimit, L Kagal - arXiv preprint arXiv:2412.01711, 2024", "abstract": "Although large language models (LLMs) have demonstrated their effectiveness in a wide range of applications, they have also been observed to perpetuate unwanted biases present in the training data, potentially leading to harm for marginalized \u2026"}, {"title": "Do Large Language Models have Shared Weaknesses in Medical Question Answering?", "link": "https://openreview.net/pdf%3Fid%3DZjQ04tsRQl", "details": "AM Bean, K Korgul, F Krones, R McCraith, A Mahdi - Advancements In Medical \u2026, 2024", "abstract": "Large language models (LLMs) have made rapid improvement on medical benchmarks, but their unreliability remains a persistent challenge for safe real-world uses. To design for the use LLMs as a category, rather than for specific models \u2026"}, {"title": "Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective", "link": "https://arxiv.org/pdf/2412.00554", "details": "Y Zhou, B Di Eugenio, L Cheng - arXiv preprint arXiv:2412.00554, 2024", "abstract": "This paper studies the performance of large language models (LLMs), particularly regarding demographic fairness, in solving real-world healthcare tasks. We evaluate state-of-the-art LLMs with three prevalent learning frameworks across six diverse \u2026"}, {"title": "Harnessing AI for Patient Engagement in a Study on Large Language Models and Open Notes", "link": "https://osf.io/h5jv8/download", "details": "L Salmi, DM Lewis, J Clarke, Z Dong, R Fischmann\u2026", "abstract": "Background The use of large language models (LLMs) is growing for both clinicians and patients. While researchers and clinicians have explored LLMs to manage patient portal messages and reduce burnout, there is less documentation about how \u2026"}, {"title": "Benchmarking the Ability of Large Language Models to Reason About Event Sets", "link": "https://www.scitepress.org/Papers/2024/130461/130461.pdf", "details": "S Kenneweg, J Deigm\u00f6ller, P Cimiano, J Eggert - Proceedings of the 16th \u2026, 2024", "abstract": "The ability to reason about events and their temporal relations is a key aspect in Natural Language Understanding. In this paper, we investigate the ability of Large Language Models to resolve temporal references with respect to longer event sets \u2026"}]
