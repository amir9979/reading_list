[{"title": "Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent Diffusion Models", "link": "https://arxiv.org/pdf/2506.10633", "details": "K Vilouras, I Stogiannidis, J Yan, AQ O'Neil\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Latent Diffusion Models have shown remarkable results in text-guided image synthesis in recent years. In the domain of natural (RGB) images, recent works have shown that such models can be adapted to various vision-language downstream \u2026", "entry_id": "http://arxiv.org/abs/2506.10633v1", "updated": "2025-06-12 12:19:18", "published": "2025-06-12 12:19:18", "authors": "Konstantinos Vilouras;Ilias Stogiannidis;Junyu Yan;Alison Q. O'Neil;Sotirios A. Tsaftaris", "summary": "Latent Diffusion Models have shown remarkable results in text-guided image\nsynthesis in recent years. In the domain of natural (RGB) images, recent works\nhave shown that such models can be adapted to various vision-language\ndownstream tasks with little to no supervision involved. On the contrary,\ntext-to-image Latent Diffusion Models remain relatively underexplored in the\nfield of medical imaging, primarily due to limited data availability (e.g., due\nto privacy concerns). In this work, focusing on the chest X-ray modality, we\nfirst demonstrate that a standard text-conditioned Latent Diffusion Model has\nnot learned to align clinically relevant information in free-text radiology\nreports with the corresponding areas of the given scan. Then, to alleviate this\nissue, we propose a fine-tuning framework to improve multi-modal alignment in a\npre-trained model such that it can be efficiently repurposed for downstream\ntasks such as phrase grounding. Our method sets a new state-of-the-art on a\nstandard benchmark dataset (MS-CXR), while also exhibiting robust performance\non out-of-distribution data (VinDr-CXR). Our code will be made publicly\navailable.", "comment": "14 pages, 6 figures", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2506.10633v1;http://arxiv.org/pdf/2506.10633v1", "pdf_url": "http://arxiv.org/pdf/2506.10633v1"}]
