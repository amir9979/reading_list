[{"title": "Evaluating and leveraging **large language models** in clinical pharmacology and therapeutics assessment: From exam takers to exam shapers", "link": "https://pubmed.ncbi.nlm.nih.gov/40495266/", "details": "AO G\u00e9rard, D Merino, M Labriffe, F Rocher, D Viard\u2026 - British journal of clinical \u2026", "abstract": "\u2026 Aims: In **medical** education, the ability of **large** **language** **models** (LLMs) to match human performance raises **questions** about their potential as \u2026 This study evaluates LLMs' performance on Clinical Pharmacology and Therapeutics (CPT) \u2026"}, {"title": "Performance analysis of **large language models** in multi-disease detection from chest computed tomography reports: a comparative study: Experimental Research", "link": "https://journals.lww.com/international-journal-of-surgery/abstract/9900/performance_analysis_of_large_language_models_in.2475.aspx", "details": "P Luo, C Fan, A Li, T Jiang, A Jiang, C Qi, W Gan\u2026 - International Journal of Surgery", "abstract": "\u2026 **Large** **Language** **Models** (LLMs) have shown considerable promise in various **medical** applications, particularly in radiology. This study aims to assess the performance of leading LLMs in analyzing unstructured chest CT reports and to \u2026"}, {"title": "Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving", "link": "https://arxiv.org/pdf/2506.08349", "details": "Y Zhou, X Liu, C Yan, C Ning, X Zhang, B Li, X Fu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 Based on these findings, we offer the following insights for applying and developing **large** **language** **models** to address real-world clinical challenges: (1) Model Selection: For low-level **medical** tasks such as knowledge-based **question** \u2026", "entry_id": "http://arxiv.org/abs/2506.08349v1", "updated": "2025-06-10 02:07:33", "published": "2025-06-10 02:07:33", "authors": "Yuxuan Zhou;Xien Liu;Chenwei Yan;Chen Ning;Xiao Zhang;Boxun Li;Xiangling Fu;Shijin Wang;Guoping Hu;Yu Wang;Ji Wu", "summary": "Large language models (LLMs) have demonstrated remarkable performance on\nvarious medical benchmarks, but their capabilities across different cognitive\nlevels remain underexplored. Inspired by Bloom's Taxonomy, we propose a\nmulti-cognitive-level evaluation framework for assessing LLMs in the medical\ndomain in this study. The framework integrates existing medical datasets and\nintroduces tasks targeting three cognitive levels: preliminary knowledge grasp,\ncomprehensive knowledge application, and scenario-based problem solving. Using\nthis framework, we systematically evaluate state-of-the-art general and medical\nLLMs from six prominent families: Llama, Qwen, Gemma, Phi, GPT, and DeepSeek.\nOur findings reveal a significant performance decline as cognitive complexity\nincreases across evaluated models, with model size playing a more critical role\nin performance at higher cognitive levels. Our study highlights the need to\nenhance LLMs' medical capabilities at higher cognitive levels and provides\ninsights for developing LLMs suited to real-world medical applications.", "comment": "20 pages, 11 figures. Accepted by ICML 2025", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2506.08349v1;http://arxiv.org/pdf/2506.08349v1", "pdf_url": "http://arxiv.org/pdf/2506.08349v1"}, {"title": "Evaluating Artificial Intelligence in Patient Education: DeepSeek\u2010V3 Versus ChatGPT\u20104o in **Answering** Common **Questions** on Laparoscopic Cholecystectomy", "link": "https://onlinelibrary.wiley.com/doi/abs/10.1111/ans.70198", "details": "HA Dincer, D Dogu - ANZ Journal of Surgery, 2025", "abstract": "\u2026 (AI- based LLMs) have gained popularity over traditional search engines for obtaining **medical** information. However, the accuracy and \u2026 performing tasks such as learning, **problem** \\- solving, decisionmaking, and language comprehension \u2026"}, {"title": "A comprehensive review of AI-driven Q&A systems with taxonomy, prospects, and challenges", "link": "https://link.springer.com/article/10.1007/s10115-025-02477-4", "details": "Z Albassami, A Algarni, A Qahmash, Z Ahmad - Knowledge and Information Systems, 2025", "abstract": "\u2026 driven **question** **answering** has significantly evolved with advancements in **large** **language** **models** \u2026 Introducing a **healthcare** **question** **answering** system that leverages a unique combination of \u2026 **healthcare** topics, including **medical** subjects \u2026"}, {"title": "Causal Discovery through Synergizing Large Language Model and Data-Driven Reasoning", "link": "https://www.cs.emory.edu/~jyang71/files/llmcd.pdf", "details": "H Du, Y Zheng, B Jing, Y Zhao, G Kou, G Liu, T Gu\u2026 - 2025", "abstract": "\u2026 LLM-CD, which integrates the metadata-based reasoning capabilities of **large** **language** **models** (LLMs) with the data-driven modeling abilities of \u2026 In this section, we evaluate our method on four real-world datasets, including two **medical** domain \u2026"}, {"title": "Application of Gemini in Public Health Amid the Artificial Intelligence Era", "link": "https://ieeexplore.ieee.org/abstract/document/11028593/", "details": "M Tatar, S Farokhi, AA Foumani, E Uzunlar, OM Araz - IEEE Engineering \u2026, 2025", "abstract": "\u2026 Additionally, Gemini can **answer** complex **medical** **questions** in an easy-to-understand context\u2026 applications of Gemini in public health and **medical** research, and as the accuracy of Gemini \u2026 Zhang, Y., et al., Potenfial of mulfimodal **large** **language** \u2026"}, {"title": "Chatbot for the Return of Positive Genetic Screening Results for Hereditary Cancer Syndromes: Prompt Engineering Project", "link": "https://cancer.jmir.org/2025/1/e65848", "details": "E Coen, G Del Fiol, KA Kaphingst, E Borsato\u2026 - JMIR cancer, 2025", "abstract": "\u2026 More recently, the release of **large** **language** **models** (LLMs) such as ChatGPT offers an opportunity to direct open-ended **questions** to \u2026 (eg, do not provide any kind of **medical** advice [\u2026] if the patient asks **questions** outside of your boundaries \u2026"}, {"title": "Exploring ChatGPT 3.5 for structured data extraction from oncological notes", "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12150697/", "details": "TJ Skyles, IJ Freeman, G Kalibbala, D Davila-Garcia\u2026 - AMIA Summits on \u2026, 2025", "abstract": "\u2026 With the adoption of **large** **language** **models** in **medical** research, there is potential to use them \u2026 We assessed how GPT used clinical notes to **answer** six relevant clinical **questions**. Four \u2026 Effective use of LLMs has potential to increase \u2026"}]
