[{"title": "Capybara-OMNI: An Efficient Paradigm for Building Omni-Modal Language Models", "link": "https://arxiv.org/pdf/2504.12315", "details": "X Ji, J Wang, H Zhang, J Zhang, H Zhou, C Sun, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "With the development of Multimodal Large Language Models (MLLMs), numerous outstanding accomplishments have emerged within the open-source community. Due to the complexity of creating and training multimodal data pairs, it is still a \u2026"}, {"title": "EIDT-V: Exploiting Intersections in Diffusion Trajectories for Model-Agnostic, Zero-Shot, Training-Free Text-to-Video Generation", "link": "https://arxiv.org/pdf/2504.06861%3F", "details": "D Jagpal, X Chen, VP Namboodiri - arXiv preprint arXiv:2504.06861, 2025", "abstract": "Zero-shot, training-free, image-based text-to-video generation is an emerging area that aims to generate videos using existing image-based diffusion models. Current methods in this space require specific architectural changes to image generation \u2026"}, {"title": "SRG-Net: A Self-supervised 3D Scene Representation Method via Graph Contrastive Learning for Novel View Synthesis", "link": "https://www.jstage.jst.go.jp/article/transfun/advpub/0/advpub_2024EAL2091/_pdf", "details": "Q Qi, Z Liu, Y Guo - IEICE Transactions on Fundamentals of Electronics \u2026, 2025", "abstract": "SUMMARYAccurate scene representation holds practical significance for autonomous driving and virtual reality. This letter proposes a network to optimize images encoding and features learning for better scene representations \u2026"}, {"title": "MentalRAG: Developing an Agentic Framework for Therapeutic Support Systems", "link": "https://www.scitepress.org/Papers/2025/132674/132674.pdf", "details": "FRE Silva, PA Santos, J Dias", "abstract": "This paper introduces MentalRAG, a multi-agent system built upon an agentic framework designed to support mental health professionals through the automation of patient data collection and analysis. The system effectively gathers and processes \u2026"}, {"title": "Exploring Multimodal Language Models for Sustainability Disclosure Extraction: A Comparative Study", "link": "https://aclanthology.org/2025.insights-1.13.pdf", "details": "T Gupta, T Goel, I Verma - The Sixth Workshop on Insights from Negative Results \u2026, 2025", "abstract": "Sustainability metrics have increasingly become a crucial non-financial criterion in investment decision-making. Organizations worldwide are recognizing the importance of sustainability and are proactively highlighting their efforts through \u2026"}, {"title": "SVLTA: Benchmarking Vision-Language Temporal Alignment via Synthetic Video Situation", "link": "https://arxiv.org/pdf/2504.05925", "details": "H Du, B Wu, Y Lu, Z Mao - arXiv preprint arXiv:2504.05925, 2025", "abstract": "Vision-language temporal alignment is a crucial capability for human dynamic recognition and cognition in real-world scenarios. While existing research focuses on capturing vision-language relevance, it faces limitations due to biased temporal \u2026"}, {"title": "Integrating Large Language Models and M\u00f6bius Group Transformations for Temporal Knowledge Graph Embedding on the Riemann Sphere", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/33449/35604", "details": "S Zhang, X Liang, S Niu, Z Niu, B Wu, G Hua, L Wang\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "Abstract The significance of Temporal Knowledge Graphs (TKGs) in Artificial Intelligence (AI) lies in their capacity to incorporate time-dimensional information, support complex reasoning and prediction, optimize decision-making processes \u2026"}, {"title": "Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs", "link": "https://arxiv.org/pdf/2504.07866%3F", "details": "Y Yin, W Huang, K Song, Y Tang, X Wu, W Guo, P Guo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present Pangu Ultra, a Large Language Model (LLM) with 135 billion parameters and dense Transformer modules trained on Ascend Neural Processing Units (NPUs). Although the field of LLM has been witnessing unprecedented advances in pushing \u2026"}, {"title": "Enhancing Chain of Thought Prompting in Large Language Models via Reasoning Patterns", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/34793/36948", "details": "Y Zhang, X Wang, L Wu, J Wang - Proceedings of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Abstract Chain of Thought (CoT) prompting can encourage language models to engage in multi-step logical reasoning. The quality of the provided demonstrations significantly influences the success of downstream inference tasks. Current \u2026"}]
