'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Autonomous Data Selection with Language Models for Mat'
[{"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "link": "https://arxiv.org/pdf/2405.00402", "details": "L Ranaldi, A Freitas - arXiv preprint arXiv:2405.00402, 2024", "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches \u2026"}, {"title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision", "link": "https://arxiv.org/pdf/2405.04086", "details": "Y Tong, S Wang, D Li, Y Wang, S Han, Z Lin, C Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While Large Language Models (LLMs) have demonstrated proficiency in handling complex queries, much of the past work has depended on extensively annotated datasets by human experts. However, this reliance on fully-supervised annotations \u2026"}, {"title": "Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation", "link": "https://arxiv.org/pdf/2405.06424", "details": "JH Lee, JO Woo, J Seok, P Hassanzadeh, W Jang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Assessing response quality to instructions in language models is vital but challenging due to the complexity of human language across different contexts. This complexity often results in ambiguous or inconsistent interpretations, making \u2026"}, {"title": "Model & Data Insights using Pre-trained Language Models", "link": "https://openreview.net/pdf%3Fid%3DL5T3ZqsD0j", "details": "S Asgari, A Khani, AH Khasahmadi, A Sanghi\u2026 - ICLR 2024 Workshop on \u2026", "abstract": "We propose TExplain, using language models to interpret pre-trained image classifiers' features. Our approach connects the feature space of image classifiers with language models, generating explanatory sentences during inference. By \u2026"}, {"title": "SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2405.08317", "details": "R Peri, SM Jayanthi, S Ronanki, A Bhatia, K Mundnich\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Integrated Speech and Large Language Models (SLMs) that can follow speech instructions and generate relevant text responses have gained popularity lately. However, the safety and robustness of these models remains largely unclear. In this \u2026"}, {"title": "When Quantization Affects Confidence of Large Language Models?", "link": "https://arxiv.org/pdf/2405.00632", "details": "I Proskurina, L Brun, G Metzler, J Velcin - arXiv preprint arXiv:2405.00632, 2024", "abstract": "Recent studies introduced effective compression techniques for Large Language Models (LLMs) via post-training quantization or low-bit weight representation. Although quantized weights offer storage efficiency and allow for faster inference \u2026"}, {"title": "Adversarial Robustness for Visual Grounding of Multimodal Large Language Models", "link": "https://openreview.net/pdf%3Fid%3D2r8n6kNEXN", "details": "K Gao, Y Bai, J Bai, Y Yang, ST Xia - ICLR 2024 Workshop on Reliable and \u2026, 2024", "abstract": "Multi-modal Large Language Models (MLLMs) have recently achieved enhanced performance across various vision-language tasks and unlocked visual grounding capabilities. However, the adversarial threat of visual grounding remains unexplored \u2026"}, {"title": "A Generalize Hardware Debugging Approach for Large Language Models Semi-Syntectic Datasets", "link": "https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.171527592.25632661", "details": "W Fu, S Li, Y Zhao, K Yang, X Zhang, Y Jin, X Guo", "abstract": "Abstract Large Language Models (LLMs) have precipitated emerging trends towards intelligent automation. However, integrating LLMs into the hardware debug domain encounters challenges: the datasets for LLMs for hardware are often plagued by a \u2026"}]
