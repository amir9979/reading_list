[{"title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation", "link": "https://arxiv.org/pdf/2504.20859", "details": "G Hadad, H Roitman, Y Eshel, B Shapira, L Rokach - arXiv preprint arXiv:2504.20859, 2025", "abstract": "As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents``X-Cross''--a novel cross-domain sequential-recommendation model \u2026"}, {"title": "GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data", "link": "https://arxiv.org/pdf/2505.03233", "details": "S Deng, M Yan, S Wei, H Ma, Y Yang, J Chen, Z Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Embodied foundation models are gaining increasing attention for their zero-shot generalization, scalability, and adaptability to new tasks through few-shot post- training. However, existing models rely heavily on real-world data, which is costly \u2026"}, {"title": "Knowledge-augmented Pre-trained Language Models for Biomedical Relation Extraction", "link": "https://arxiv.org/pdf/2505.00814", "details": "M S\u00e4nger, U Leser - arXiv preprint arXiv:2505.00814, 2025", "abstract": "Automatic relationship extraction (RE) from biomedical literature is critical for managing the vast amount of scientific knowledge produced each year. In recent years, utilizing pre-trained language models (PLMs) has become the prevalent \u2026"}, {"title": "MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing", "link": "https://arxiv.org/pdf/2505.07984", "details": "A Koksal, AA Alatan - arXiv preprint arXiv:2505.07984, 2025", "abstract": "Remarkable capabilities in understanding and generating text-image content have been demonstrated by recent advancements in multimodal large language models (MLLMs). However, their effectiveness in specialized domains-particularly those \u2026"}, {"title": "DeepCritic: Deliberate Critique with Large Language Models", "link": "https://arxiv.org/pdf/2505.00662%3F", "details": "W Yang, J Chen, Y Lin, JR Wen - arXiv preprint arXiv:2505.00662, 2025", "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem. Leveraging LLMs as critique models to achieve automated supervision is a \u2026"}, {"title": "Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers", "link": "https://arxiv.org/pdf/2505.04842", "details": "K Sareen, MM Moss, A Sordoni, R Agarwal, A Hosseini - arXiv preprint arXiv \u2026, 2025", "abstract": "Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners, such as GRPO or Leave-one-out PPO, abandon the learned value function in favor of empirically estimated returns. This hinders test-time compute scaling that relies on \u2026"}, {"title": "Unleashing the potential of prompt engineering for large language models", "link": "https://www.cell.com/patterns/fulltext/S2666-3899\\(25\\)00108-4", "details": "B Chen, Z Zhang, N Langren\u00e9, S Zhu - Patterns, 2025", "abstract": "This review explores the role of prompt engineering in unleashing the capabilities of large language models (LLMs). Prompt engineering is the process of structuring inputs, and it has emerged as a crucial technique for maximizing the utility and \u2026"}, {"title": "Which agent causes task failures and when? on automated failure attribution of llm multi-agent systems", "link": "https://arxiv.org/pdf/2505.00212", "details": "S Zhang, M Yin, J Zhang, J Liu, Z Han, J Zhang, B Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Failure attribution in LLM multi-agent systems-identifying the agent and step responsible for task failures-provides crucial clues for systems debugging but remains underexplored and labor-intensive. In this paper, we propose and formulate \u2026"}, {"title": "Option Symbol Matters: Investigating and Mitigating Multiple-Choice Option Symbol Bias of Large Language Models", "link": "https://aclanthology.org/2025.naacl-long.95.pdf", "details": "Z Yang, P Jian, C Li - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "Abstract Multiple-Choice Question Answering (MCQA) is a widely used task in the evaluation of Large Language Models (LLMs). In this work, we reveal that current LLMs' performance in MCQA could be heavily influenced by the choice of option \u2026"}]
