[{"title": "When Evolution Strategy Meets Language Models Tuning", "link": "https://aclanthology.org/2025.coling-main.357.pdf", "details": "B Huang, Y Jiang, M Chen, Y Wang, H Chen, W Wang - Proceedings of the 31st \u2026, 2025", "abstract": "Supervised Fine-tuning has been pivotal in training autoregressive language models, yet it introduces exposure bias. To mitigate this, Post Fine-tuning, including on-policy and off-policy methods, has emerged as a solution to enhance models \u2026"}, {"title": "What large language models know and what people think they know", "link": "https://www.nature.com/articles/s42256-024-00976-7", "details": "M Steyvers, H Tejeda, A Kumar, C Belem, S Karny\u2026 - Nature Machine Intelligence, 2025", "abstract": "As artificial intelligence systems, particularly large language models (LLMs), become increasingly integrated into decision-making processes, the ability to trust their outputs is crucial. To earn human trust, LLMs must be well calibrated such that they \u2026"}, {"title": "Cognitive Biases, Task Complexity, and Result Intepretability in Large Language Models", "link": "https://aclanthology.org/2025.coling-main.120.pdf", "details": "M Mina, V Ru\u00edz-Fern\u00e1ndez, J Falc\u00e3o, L Vasquez-Reina\u2026 - Proceedings of the 31st \u2026, 2025", "abstract": "In humans, cognitive biases are systematic deviations from rationality in judgment that simplify complex decisions. They typically manifest as a consequence of learned behaviors or limitations on information processing capabilities. Recent work has \u2026"}, {"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "link": "https://arxiv.org/pdf/2501.04322", "details": "M Rang, Z Bi, C Liu, Y Tang, K Han, Y Wang - arXiv preprint arXiv:2501.04322, 2025", "abstract": "Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are \u2026"}, {"title": "Distilling Rule-based Knowledge into Large Language Models", "link": "https://aclanthology.org/2025.coling-main.61.pdf", "details": "W Yang, Y Lin, J Zhou, JR Wen - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have shown incredible performance in completing various real-world tasks. The current paradigm of knowledge learning for LLMs is mainly based on learning from examples, in which LLMs learn the internal rule \u2026"}, {"title": "Selected Languages are All You Need for Cross-lingual Truthfulness Transfer", "link": "https://aclanthology.org/2025.coling-main.601.pdf", "details": "W Liu, N Wu, W Ding, S Liang, M Gong, D Zhang - Proceedings of the 31st \u2026, 2025", "abstract": "Truthfulness stands out as an essential challenge for Large Language Models (LLMs). Although many works have developed various ways for truthfulness enhancement, they seldom focus on truthfulness in multilingual scenarios \u2026"}, {"title": "IRUEX: A Study on Large Language Models Problem-Solving Skills in Iran's University Entrance Exam", "link": "https://aclanthology.org/2025.coling-main.434.pdf", "details": "HK Khaledi, H Faili - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "In this paper, we present the IRUEX dataset, a novel multiple-choice educational resource specifically designed to evaluate the performance of Large Language Models (LLMs) across seven distinct categories. The dataset contains 868 Iran \u2026"}, {"title": "Topology-of-Question-Decomposition: Enhancing Large Language Models with Information Retrieval for Knowledge-Intensive Tasks", "link": "https://aclanthology.org/2025.coling-main.191.pdf", "details": "W Li, J Wang, LC Yu, X Zhang - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) are increasingly deployed for general problem- solving across various domains yet remain constrained to chaining immediate reasoning steps and depending solely on parametric knowledge. Integrating an \u2026"}, {"title": "Double Visual Defense: Adversarial Pre-training and Instruction Tuning for Improving Vision-Language Model Robustness", "link": "https://arxiv.org/pdf/2501.09446", "details": "Z Wang, C Xie, B Bartoldson, B Kailkhura - arXiv preprint arXiv:2501.09446, 2025", "abstract": "This paper investigates the robustness of vision-language models against adversarial visual perturbations and introduces a novel``double visual defense\" to enhance this robustness. Unlike previous approaches that resort to lightweight \u2026"}]
