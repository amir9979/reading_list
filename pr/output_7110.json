[{"title": "Efficient Bias Mitigation Without Privileged Information", "link": "https://arxiv.org/pdf/2409.17691", "details": "ME Zarlenga, S Sankaranarayanan, JTA Andrews\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Deep neural networks trained via empirical risk minimisation often exhibit significant performance disparities across groups, particularly when group and task labels are spuriously correlated (eg,\" grassy background\" and\" cows\"). Existing bias mitigation \u2026"}, {"title": "Interpreting and Controlling Linguistic Features in Multilingual Language Models", "link": "https://dspace.cuni.cz/bitstream/handle/20.500.11956/192821/140123221.pdf%3Fsequence%3D1", "details": "T Limisiewicz - 2024", "abstract": "Language models based on neural networks have become the foundation for solving diverse tasks, yet their inner workings remain opaque. This dissertation investigates which components of language models are crucial for representing and processing \u2026"}, {"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE", "link": "https://arxiv.org/pdf/2409.17508", "details": "X Zhu, Y Hu, F Mo, M Li, J Wu - arXiv preprint arXiv:2409.17508, 2024", "abstract": "Multi-modal large language models (MLLMs) have shown impressive capabilities as a general-purpose interface for various visual and linguistic tasks. However, building a unified MLLM for multi-task learning in the medical field remains a thorny \u2026"}, {"title": "Inference-Time Language Model Alignment via Integrated Value Guidance", "link": "https://arxiv.org/pdf/2409.17819", "details": "Z Liu, Z Zhou, Y Wang, C Yang, Y Qiao - arXiv preprint arXiv:2409.17819, 2024", "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce $\\textit {Integrated Value Guidance} $(IVG), a method that uses implicit and \u2026"}, {"title": "Decoding by Factual Prompts and Hallucination Prompts Improves Factuality in Large Language Models", "link": "https://www.preprints.org/manuscript/202409.2037/download/final_file", "details": "B Lv, A Feng, C Xie - 2024", "abstract": "Although large language models demonstrate impressive capabilities, they sometimes generate irrelevant or nonsensical text, or produce outputs that deviate from the provided source input\u2014an occurrence commonly referred to as \u2026"}]
