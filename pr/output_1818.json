[{"title": "Simple-Sampling and Hard-Mixup with Prototypes to Rebalance Contrastive Learning for Text Classification", "link": "https://arxiv.org/pdf/2405.11524", "details": "M Li, Y Liu, F Giunchiglia, X Feng, R Guan - arXiv preprint arXiv:2405.11524, 2024", "abstract": "Text classification is a crucial and fundamental task in natural language processing. Compared with the previous learning paradigm of pre-training and fine-tuning by cross entropy loss, the recently proposed supervised contrastive learning approach \u2026"}, {"title": "Navigating Brain Language Representations: A Comparative Analysis of Neural Language Models and Psychologically Plausible Models", "link": "https://arxiv.org/pdf/2404.19364", "details": "Y Zhang, S Wang, X Dong, J Yu, C Zong - arXiv preprint arXiv:2404.19364, 2024", "abstract": "Neural language models, particularly large-scale ones, have been consistently proven to be most effective in predicting brain neural activity across a range of studies. However, previous research overlooked the comparison of these models \u2026"}, {"title": "Large Language Models for Social Determinants of Health Information Extraction from Clinical Notes-A Generalizable Approach across Institutions", "link": "https://www.medrxiv.org/content/10.1101/2024.05.21.24307726.full.pdf", "details": "VK Keloth, S Selek, Q Chen, C Gilman, S Fu, Y Dang\u2026 - medRxiv, 2024", "abstract": "The consistent and persuasive evidence illustrating the influence of social determinants on health has prompted a growing realization throughout the health care sector that enhancing health and health equity will likely depend, at least to \u2026"}, {"title": "A whole-slide foundation model for digital pathology from real-world data", "link": "https://www.nature.com/articles/s41586-024-07441-w", "details": "H Xu, N Usuyama, J Bagga, S Zhang, R Rao\u2026 - Nature, 2024", "abstract": "Digital pathology poses unique computational challenges, as a standard gigapixel slide may comprise tens of thousands of image tiles,\u2013. Prior models have often resorted to subsampling a small portion of tiles for each slide, thus missing the \u2026"}, {"title": "Fennec: Fine-grained Language Model Evaluation and Correction Extended through Branching and Bridging", "link": "https://arxiv.org/pdf/2405.12163", "details": "X Liang, H Zhang, J Li, J Xu, M Zhang - arXiv preprint arXiv:2405.12163, 2024", "abstract": "The rapid advancement of large language models has given rise to a plethora of applications across a myriad of real-world tasks, mainly centered on aligning with human intent. However, the complexities inherent in human intent necessitate a \u2026"}, {"title": "Few Shot Class Incremental Learning using Vision-Language models", "link": "https://arxiv.org/pdf/2405.01040", "details": "A Kumar, C Bharti, S Dutta, S Karanam, B Banerjee - arXiv preprint arXiv:2405.01040, 2024", "abstract": "Recent advancements in deep learning have demonstrated remarkable performance comparable to human capabilities across various supervised computer vision tasks. However, the prevalent assumption of having an extensive pool of training data \u2026"}]
