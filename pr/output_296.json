'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [Parameter-efficient fine-tuning large language model approac'
[{"title": "Understanding Emergent Abilities of Language Models from the Loss Perspective", "link": "https://arxiv.org/pdf/2403.15796", "details": "Z Du, A Zeng, Y Dong, J Tang - arXiv preprint arXiv:2403.15796, 2024", "abstract": "Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) \u2026"}, {"title": "Adaptive Prompt Routing for Arbitrary Text Style Transfer with Pre-trained Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29832/31446", "details": "Q Liu, J Qin, W Ye, H Mou, Y He, K Wang - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Recently, arbitrary text style transfer (TST) has made significant progress with the paradigm of prompt learning. In this paradigm, researchers often design or search for a fixed prompt for any input. However, existing evidence shows that large language \u2026"}, {"title": "Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation", "link": "https://arxiv.org/pdf/2403.07860", "details": "S Zhao, S Hao, B Zi, H Xu, KYK Wong - arXiv preprint arXiv:2403.07860, 2024", "abstract": "Text-to-image generation has made significant advancements with the introduction of text-to-image diffusion models. These models typically consist of a language model that interprets user prompts and a vision model that generates corresponding \u2026"}, {"title": "Can 3D Vision-Language Models Truly Understand Natural Language?", "link": "https://arxiv.org/pdf/2403.14760", "details": "W Deng, R Ding, J Yang, J Liu, Y Li, X Qi, E Ngai - arXiv preprint arXiv:2403.14760, 2024", "abstract": "Rapid advancements in 3D vision-language (3D-VL) tasks have opened up new avenues for human interaction with embodied agents or robots using natural language. Despite this progress, we find a notable limitation: existing 3D-VL models \u2026"}, {"title": "DINGO: Towards Diverse and Fine-Grained Instruction-Following Evaluation", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29768/31322", "details": "Z Gu, X Sun, F Lian, Z Kang, C Xu, J Fan - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Instruction-following is particularly crucial for large language models (LLMs) to support diverse user requests. While existing work has made progress in aligning LLMs with human preferences, evaluating their capabilities on instruction-following \u2026"}, {"title": "$\\mathbf {(N, K)} $-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model", "link": "https://arxiv.org/html/2403.07191v1", "details": "Y Zhang, L Chen, B Liu, Y Yang, Q Cui, Y Tao, H Yang - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in reinforcement learning (RL) algorithms aim to enhance the performance of language models at scale. Yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these \u2026"}, {"title": "Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving", "link": "https://arxiv.org/html/2403.05907v1", "details": "J Cao, Z Li, N Wang, C Ma - arXiv preprint arXiv:2403.05907, 2024", "abstract": "Recent studies have highlighted the promising application of NeRF in autonomous driving contexts. However, the complexity of outdoor environments, combined with the restricted viewpoints in driving scenarios, complicates the task of precisely \u2026"}, {"title": "EIDNet: Extragradient-based iterative denoising network for image compressive sensing reconstruction", "link": "https://www.sciencedirect.com/science/article/pii/S095741742400695X", "details": "C Wang, Y Huang, C Ci, H Chen, H Wu, Y Zhao - Expert Systems with Applications, 2024", "abstract": "Compressive sensing (CS) is a kind of hardware-friendly technology in effective image reconstruction. Most of the existing CS reconstruction methods can be classified into model-driven iterative optimization methods and data-driven neural \u2026"}, {"title": "A Comprehensive Overhaul of Multimodal Assistant with Small Language Models", "link": "https://arxiv.org/pdf/2403.06199", "details": "M Zhu, Y Zhu, X Liu, N Liu, Z Xu, C Shen, Y Peng, Z Ou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Large Language Models (MLLMs) have showcased impressive skills in tasks related to visual understanding and reasoning. Yet, their widespread application faces obstacles due to the high computational demands during both the \u2026"}]
