[{"title": "Federated Contrastive Learning of Graph-Level Representations", "link": "https://arxiv.org/pdf/2411.12098", "details": "X Li, G Agrawal, R Ramnath, R Jin - arXiv preprint arXiv:2411.12098, 2024", "abstract": "Graph-level representations (and clustering/classification based on these representations) are required in a variety of applications. Examples include identifying malicious network traffic, prediction of protein properties, and many \u2026"}, {"title": "Deepthreatexplainer: a united explainable predictor for threat comments identification on Twitter", "link": "https://link.springer.com/article/10.1007/s13278-024-01389-5", "details": "A Nazarova, MSI Malik, DI Ignatov, I Hussain - Social Network Analysis and Mining, 2024", "abstract": "Identification of threatening comments on social media platforms has recently gained attention. Prior approaches have addressed this task in some low-resource languages but the interpretability of results was not studied. In addition, approaches \u2026"}, {"title": "CLIMB: Imbalanced Data Modelling Using Contrastive Learning with Limited Labels", "link": "https://link.springer.com/chapter/10.1007/978-981-96-0573-6_5", "details": "A Alsuhaibani, I Razzak, S Jameel, X Wang, G Xu - International Conference on Web \u2026, 2024", "abstract": "Abstract Machine learning classifiers typically rely on the assumption of balanced training datasets, with sufficient examples per class to facilitate effective model learning. However, this assumption often fails to hold. Consider a common scenario \u2026"}, {"title": "CPLLM: Clinical prediction with large language models", "link": "https://journals.plos.org/digitalhealth/article%3Fid%3D10.1371/journal.pdig.0000680", "details": "O Ben Shoham, N Rappoport - PLOS Digital Health, 2024", "abstract": "We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for predicting clinical disease and readmission. We utilized quantization and fine-tuned the LLM using \u2026"}, {"title": "Towards Explainable Federated Learning in Healthcare: A Study on Heart Arrhythmia Detection", "link": "https://ceur-ws.org/Vol-3831/paper9.pdf", "details": "SN Zeleke, M Bochicchio - 2024", "abstract": "Advancements in artificial intelligence (AI) hold promise for revolutionizing healthcare, but challenges related to model explainability and data availability persist. Federated learning (FL) offers a privacypreserving solution for health data \u2026"}, {"title": "On the Adversarial Robustness of Instruction-Tuned Large Language Models for Code", "link": "https://arxiv.org/pdf/2411.19508", "details": "MI Hossen, X Hei - arXiv preprint arXiv:2411.19508, 2024", "abstract": "The advent of instruction-tuned Large Language Models designed for coding tasks (Code LLMs) has transformed software engineering practices. However, their robustness against various input challenges remains a critical concern. This study \u2026"}]
