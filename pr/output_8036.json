[{"title": "A federated learning approach for classifying chest diseases from chest X-ray images", "link": "https://www.sciencedirect.com/science/article/pii/S1746809424011650", "details": "SK Satapathy, SB Cho, S Mishra, S Sah, SN Mohanty - \u2026 Signal Processing and \u2026, 2025", "abstract": "A leading global cause of death and morbidity is chest disorders which demand accurate and timely diagnosis for effective management. Chest X-rays serve as a commonly used and widely employed diagnostic tool for detecting these diseases \u2026"}, {"title": "Unleashing the Potential of Vision-Language Pre-Training for 3D Zero-Shot Lesion Segmentation via Mask-Attribute Alignment", "link": "https://arxiv.org/pdf/2410.15744", "details": "Y Jiang, W Lei, X Zhang, S Zhang - arXiv preprint arXiv:2410.15744, 2024", "abstract": "Recent advancements in medical vision-language pre-training models have driven significant progress in zero-shot disease recognition. However, transferring image- level knowledge to pixel-level tasks, such as lesion segmentation in 3D CT scans \u2026"}, {"title": "FAST: A Dual-tier Few-Shot Learning Paradigm for Whole Slide Image Classification", "link": "https://arxiv.org/pdf/2409.19720", "details": "K Fu, X Luo, L Qu, S Wang, Y Xiong, I Maglogiannis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The expensive fine-grained annotation and data scarcity have become the primary obstacles for the widespread adoption of deep learning-based Whole Slide Images (WSI) classification algorithms in clinical practice. Unlike few-shot learning methods \u2026"}, {"title": "SAT-Morph: Unsupervised Deformable Medical Image Registration Using Vision Foundation Models with Anatomically Aware Text Prompt", "link": "https://link.springer.com/chapter/10.1007/978-3-031-73471-7_8", "details": "H Xu, T Xue, D Liu, F Zhang, CF Westin, R Kikinis\u2026 - International Workshop on \u2026, 2024", "abstract": "Current unsupervised deformable medical image registration methods rely on image similarity measures. However, these methods are inherently limited by the difficulty of integrating important anatomy knowledge into registration. The development of \u2026"}, {"title": "SAMU: An Efficient and Promptable Foundation Model for Medical Image Segmentation", "link": "https://link.springer.com/chapter/10.1007/978-3-031-73471-7_14", "details": "J Bae, X Guo, H Yerebakan, Y Shinagawa, S Farhand - International Workshop on \u2026, 2024", "abstract": "Segmentation of 3D medical images is a labor-intensive task with important clinical applications. Recently, foundation models for image segmentation have received significant interest. Specifically, many works have proposed methods for the \u2026"}, {"title": "Taming Mambas for Voxel Level 3D Medical Image Segmentation", "link": "https://arxiv.org/pdf/2410.15496", "details": "L Lumetti, V Pipoli, K Marchesini, E Ficarra, C Grana\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, the field of 3D medical segmentation has been dominated by deep learning models employing Convolutional Neural Networks (CNNs) and Transformer- based architectures, each with their distinctive strengths and limitations. CNNs are \u2026"}, {"title": "Anatomical Embedding-Based Training Method for Medical Image Segmentation Foundation Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-73471-7_15", "details": "M Zhuang, R Xu, Q Zhang, A Liu, X Fan, H Wang - International Workshop on \u2026, 2024", "abstract": "Existing training methods for medical image foundation models primarily focus on tasks such as image restoration, overlooking the potential of harnessing the inherent anatomical knowledge of the human body. The discrepancy between the training \u2026"}]
