[{"title": "Harnessing Language's Fractal Geometry with Recursive Inference Scaling", "link": "https://arxiv.org/pdf/2502.07503", "details": "I Alabdulmohsin, X Zhai - arXiv preprint arXiv:2502.07503, 2025", "abstract": "Recent research in language modeling reveals two scaling effects: the well-known improvement from increased training compute, and a lesser-known boost from applying more sophisticated or computationally intensive inference methods \u2026"}, {"title": "VisBias: Measuring Explicit and Implicit Social Biases in Vision Language Models", "link": "https://arxiv.org/pdf/2503.07575", "details": "J Huang, J Qin, J Zhang, Y Yuan, W Wang, J Zhao - arXiv preprint arXiv:2503.07575, 2025", "abstract": "This research investigates both explicit and implicit social biases exhibited by Vision- Language Models (VLMs). The key distinction between these bias types lies in the level of awareness: explicit bias refers to conscious, intentional biases, while implicit \u2026"}, {"title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models", "link": "https://arxiv.org/pdf/2502.10250%3F", "details": "GK Kumar, I Chaabane, K Wu - arXiv preprint arXiv:2502.10250, 2025", "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved \u2026"}, {"title": "Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG", "link": "https://arxiv.org/pdf/2502.08356", "details": "K Bhushan, Y Nandwani, D Khandelwal, S Gupta\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a prominent method for incorporating domain knowledge into Large Language Models (LLMs). While RAG enhances response relevance by incorporating retrieved domain knowledge in the \u2026"}, {"title": "Evaluating search engines and large language models for answering health questions", "link": "https://www.nature.com/articles/s41746-025-01546-w", "details": "M Fern\u00e1ndez-Pichel, JC Pichel, DE Losada - npj Digital Medicine, 2025", "abstract": "Search engines (SEs) have traditionally been primary tools for information seeking, but the new large language models (LLMs) are emerging as powerful alternatives, particularly for question-answering tasks. This study compares the performance of \u2026"}, {"title": "FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models", "link": "https://arxiv.org/pdf/2502.17924", "details": "H Lin, Y Deng, Y Gu, W Zhang, J Ma, SK Ng, TS Chua - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the \u2026"}, {"title": "Alignment for Efficient Tool Calling of Large Language Models", "link": "https://arxiv.org/pdf/2503.06708", "details": "H Xu, Z Wang, Z Zhu, L Pan, X Chen, L Chen, K Yu - arXiv preprint arXiv:2503.06708, 2025", "abstract": "Recent advancements in tool learning have enabled large language models (LLMs) to integrate external tools, enhancing their task performance by expanding their knowledge boundaries. However, relying on tools often introduces tradeoffs between \u2026"}, {"title": "Franken-Adapter: Cross-Lingual Adaptation of LLMs by Embedding Surgery", "link": "https://arxiv.org/pdf/2502.08037", "details": "F Jiang, H Yu, G Chung, T Cohn - arXiv preprint arXiv:2502.08037, 2025", "abstract": "The capabilities of Large Language Models (LLMs) in low-resource languages lag far behind those in English, making their universal accessibility a significant challenge. To alleviate this, we present $\\textit {Franken-Adapter} $, a modular \u2026"}, {"title": "SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence", "link": "https://arxiv.org/pdf/2502.08767", "details": "Z Liu, RA Amjad, R Adkathimar, T Wei, H Tong - arXiv preprint arXiv:2502.08767, 2025", "abstract": "Providing Language Models (LMs) with relevant evidence in the context (either via retrieval or user-provided) can significantly improve their ability to provide factually correct grounded responses. However, recent studies have found that LMs often \u2026"}]
