[{"title": "Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation", "link": "https://arxiv.org/pdf/2405.13622", "details": "G Guinet, B Omidvar-Tehrani, A Deoras, L Callot - arXiv preprint arXiv:2405.13622, 2024", "abstract": "We propose a new method to measure the task-specific accuracy of Retrieval- Augmented Large Language Models (RAG). Evaluation is performed by scoring the RAG on an automatically-generated synthetic exam composed of multiple choice \u2026"}, {"title": "Small Language Models for Application Interactions: A Case Study", "link": "https://arxiv.org/pdf/2405.20347", "details": "B Li, Y Zhang, S Bubeck, J Pathuri, I Menache - arXiv preprint arXiv:2405.20347, 2024", "abstract": "We study the efficacy of Small Language Models (SLMs) in facilitating application usage through natural language interactions. Our focus here is on a particular internal application used in Microsoft for cloud supply chain fulfilment. Our \u2026"}, {"title": "Noise-Aware Differentially Private Regression via Meta-Learning", "link": "https://arxiv.org/pdf/2406.08569", "details": "O R\u00e4is\u00e4, S Markou, M Ashman, WP Bruinsma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Many high-stakes applications require machine learning models that protect user privacy and provide well-calibrated, accurate predictions. While Differential Privacy (DP) is the gold standard for protecting user privacy, standard DP mechanisms \u2026"}, {"title": "Conformal Counterfactual Inference under Hidden Confounding", "link": "https://arxiv.org/pdf/2405.12387", "details": "Z Chen, R Guo, JF Ton, Y Liu - arXiv preprint arXiv:2405.12387, 2024", "abstract": "Personalized decision making requires the knowledge of potential outcomes under different treatments, and confidence intervals about the potential outcomes further enrich this decision-making process and improve its reliability in high-stakes \u2026"}, {"title": "Mitigating selection bias in counterfactual prediction through self-supervised domain embedding learning with virtual samples", "link": "https://link.springer.com/article/10.1007/s10489-024-05518-7", "details": "Q Zhu, H Sun, B Yang - Applied Intelligence, 2024", "abstract": "Abstract Treatment effect estimation (TEE) is widely adopted in various domains such as machine learning, dvertising and marketing, and medicine. During the TEE, there normally exist selection bias on counterfactual prediction, which results in different \u2026"}, {"title": "Federated Domain-Specific Knowledge Transfer on Large Language Models Using Synthetic Data", "link": "https://arxiv.org/pdf/2405.14212", "details": "H Li, X Zhao, D Guo, H Gu, Z Zeng, Y Han, Y Song\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) demonstrate unparalleled performance and generalization ability, LLMs are widely used and integrated into various applications. When it comes to sensitive domains, as commonly described in federated learning \u2026"}, {"title": "Learning the Meta Feature Transformer for Unsupervised Person Re-Identification", "link": "https://www.mdpi.com/2227-7390/12/12/1812", "details": "Q Li, C Yan, X Peng - Mathematics, 2024", "abstract": "Although unsupervised person re-identification (Re-ID) has drawn increasing research attention, it still faces the challenge of learning discriminative features in the absence of pairwise labels across disjoint camera views. To tackle the issue of label \u2026"}, {"title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2405.18218", "details": "Y Zhang, Y Li, X Wang, Q Shen, B Plank, B Bischl\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Overparametrized transformer networks are the state-of-the-art architecture for Large Language Models (LLMs). However, such models contain billions of parameters making large compute a necessity, while raising environmental concerns. To \u2026"}, {"title": "Nearly Tight Black-Box Auditing of Differentially Private Machine Learning", "link": "https://arxiv.org/pdf/2405.14106", "details": "MSMS Annamalai, E De Cristofaro - arXiv preprint arXiv:2405.14106, 2024", "abstract": "This paper presents a nearly tight audit of the Differentially Private Stochastic Gradient Descent (DP-SGD) algorithm in the black-box model. Our auditing procedure empirically estimates the privacy leakage from DP-SGD using \u2026"}]
