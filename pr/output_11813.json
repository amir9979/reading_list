[{"title": "Few-Shot Adaptation of Training-Free Foundation Model for 3D Medical Image Segmentation", "link": "https://arxiv.org/pdf/2501.09138", "details": "X He, Y Hu, Z Zhou, M Jarraya, F Liu - arXiv preprint arXiv:2501.09138, 2025", "abstract": "Vision foundation models have achieved remarkable progress across various image analysis tasks. In the image segmentation task, foundation models like the Segment Anything Model (SAM) enable generalizable zero-shot segmentation through user \u2026"}, {"title": "Own-background contrastive learning guided by pseudo-label for semi-supervised medical image segmentation", "link": "https://www.sciencedirect.com/science/article/pii/S1568494625000602", "details": "H Fan, J Cao, S Lin, K Polat, J Zhou - Applied Soft Computing, 2025", "abstract": "Although recent works in fully supervised learning has achieved significant success in medical image segmentation, obtaining high-quality pixel-wise expert annotations remains a challenge in medical imaging. Therefore, semi-supervised learning \u2026"}, {"title": "Self Pre-training with Adaptive Mask Autoencoders for Variable-Contrast 3D Medical Imaging", "link": "https://arxiv.org/pdf/2501.09096", "details": "BK Das, G Zhao, H Liu, TJ Re, D Comaniciu, E Gibson\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The Masked Autoencoder (MAE) has recently demonstrated effectiveness in pre- training Vision Transformers (ViT) for analyzing natural images. By reconstructing complete images from partially masked inputs, the ViT encoder gathers contextual \u2026"}]
