[{"title": "Equitable Electronic Health Record Prediction with FAME: Fairness-Aware Multimodal Embedding", "link": "https://arxiv.org/pdf/2506.13104", "details": "N Hooman, Z Wu, EC Larson, M Gupta - arXiv preprint arXiv:2506.13104, 2025", "abstract": "Electronic Health Record (EHR) data encompass diverse modalities--text, images, and medical codes--that are vital for clinical decision-making. To process these complex data, multimodal AI (MAI) has emerged as a powerful approach for fusing \u2026", "entry_id": "http://arxiv.org/abs/2506.13104v1", "updated": "2025-06-16 05:23:42", "published": "2025-06-16 05:23:42", "authors": "Nikkie Hooman;Zhongjie Wu;Eric C. Larson;Mehak Gupta", "summary": "Electronic Health Record (EHR) data encompass diverse modalities -- text,\nimages, and medical codes -- that are vital for clinical decision-making. To\nprocess these complex data, multimodal AI (MAI) has emerged as a powerful\napproach for fusing such information. However, most existing MAI models\noptimize for better prediction performance, potentially reinforcing biases\nacross patient subgroups. Although bias-reduction techniques for multimodal\nmodels have been proposed, the individual strengths of each modality and their\ninterplay in both reducing bias and optimizing performance remain\nunderexplored. In this work, we introduce FAME (Fairness-Aware Multimodal\nEmbeddings), a framework that explicitly weights each modality according to its\nfairness contribution. FAME optimizes both performance and fairness by\nincorporating a combined loss function. We leverage the Error Distribution\nDisparity Index (EDDI) to measure fairness across subgroups and propose a\nsign-agnostic aggregation method to balance fairness across subgroups, ensuring\nequitable model outcomes. We evaluate FAME with BEHRT and BioClinicalBERT,\ncombining structured and unstructured EHR data, and demonstrate its\neffectiveness in terms of performance and fairness compared with other\nbaselines across multiple EHR prediction tasks.", "comment": "21 pages, 3 figures", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.CL", "links": "http://arxiv.org/abs/2506.13104v1;http://arxiv.org/pdf/2506.13104v1", "pdf_url": "http://arxiv.org/pdf/2506.13104v1"}]
