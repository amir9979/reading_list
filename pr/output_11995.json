[{"title": "Optimizing Fine-Tuning in Quantized Language Models: An In-Depth Analysis of Key Variables.", "link": "https://search.ebscohost.com/login.aspx%3Fdirect%3Dtrue%26profile%3Dehost%26scope%3Dsite%26authtype%3Dcrawler%26jrnl%3D15462218%26AN%3D182195836%26h%3DDkM7H%252BNd4BEWKjE7TEkwhwLcnO19xZgFOBIOwZt8r9Fzq0LyL73eEmZznOSwUtStliyGVMcyE3esDPWIq7NApw%253D%253D%26crl%3Dc", "details": "A Shen, Z Lai, D Li, X Hu - Computers, Materials & Continua, 2025", "abstract": "Abstract Large-scale Language Models (LLMs) have achieved significant breakthroughs in Natural Language Processing (NLP), driven by the pre-training and fine-tuning paradigm. While this approach allows models to specialize in specific \u2026"}, {"title": "MotionBench: Benchmarking and Improving Fine-grained Video Motion Understanding for Vision Language Models", "link": "https://arxiv.org/pdf/2501.02955", "details": "W Hong, Y Cheng, Z Yang, W Wang, L Wang, X Gu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In recent years, vision language models (VLMs) have made significant advancements in video understanding. However, a crucial capability-fine-grained motion comprehension-remains under-explored in current benchmarks. To address \u2026"}, {"title": "DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests", "link": "https://arxiv.org/pdf/2501.04671", "details": "C Corbi\u00e8re, S Roburin, S Montariol, A Bosselut, A Alahi - arXiv preprint arXiv \u2026, 2025", "abstract": "Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning. However, due to the modality gap between textual and visual data, they often face significant challenges, such as over \u2026"}, {"title": "ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2501.11175", "details": "Y Bendou, A Ouasfi, V Gripon, A Boukhayma - arXiv preprint arXiv:2501.11175, 2025", "abstract": "The growing popularity of Contrastive Language-Image Pretraining (CLIP) has led to its widespread application in various visual downstream tasks. To enhance CLIP's effectiveness and versatility, efficient few-shot adaptation techniques have been \u2026"}, {"title": "KPL: Training-Free Medical Knowledge Mining of Vision-Language Models", "link": "https://arxiv.org/pdf/2501.11231", "details": "J Liu, T Hu, J Du, R Zhang, JT Zhou, Z Liu - arXiv preprint arXiv:2501.11231, 2025", "abstract": "Visual Language Models such as CLIP excel in image recognition due to extensive image-text pre-training. However, applying the CLIP inference in zero-shot classification, particularly for medical image diagnosis, faces challenges due to: 1) \u2026"}, {"title": "Open-source small language models for personal medical assistant chatbots", "link": "https://www.sciencedirect.com/science/article/pii/S2666521224000644", "details": "M Magnini, G Aguzzi, S Montagna - Intelligence-Based Medicine, 2025", "abstract": "Medical chatbots are becoming essential components of telemedicine applications as tools to assist patients in the self-management of their conditions. This trend is particularly driven by advancements in natural language processing techniques with \u2026"}, {"title": "Towards normalized clinical information extraction in Chinese radiology report with large language models", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002076", "details": "Q Xu, X Xu, C Zhou, Z Liu, F Huang, S Li, L Zhu, Z Bai\u2026 - Expert Systems with \u2026, 2025", "abstract": "Radiology reports serve as a fundamental component within electronic medical records. Converting unstructured free-text reports into structured formats holds paramount importance for the management and utilization of radiology reports. In this \u2026"}, {"title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "link": "https://arxiv.org/pdf/2501.12266", "details": "C Patr\u00edcio, I Rio-Torto, JS Cardoso, LF Teixeira\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The main challenges limiting the adoption of deep learning-based solutions in medical workflows are the availability of annotated data and the lack of interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the latter \u2026"}, {"title": "Vision Language Models as Values Detectors", "link": "https://arxiv.org/pdf/2501.03957", "details": "GA Abbo, T Belpaeme - arXiv preprint arXiv:2501.03957, 2025", "abstract": "Large Language Models integrating textual and visual inputs have introduced new possibilities for interpreting complex data. Despite their remarkable ability to generate coherent and contextually relevant text based on visual stimuli, the \u2026"}]
