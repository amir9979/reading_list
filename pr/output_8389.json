[{"title": "VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks", "link": "https://arxiv.org/pdf/2410.05160%3F", "details": "Z Jiang, R Meng, X Yang, S Yavuz, Y Zhou, W Chen - arXiv preprint arXiv:2410.05160, 2024", "abstract": "Embedding models have been crucial in enabling various downstream tasks such as semantic similarity, information retrieval, and clustering. Recently, there has been a surge of interest in developing universal text embedding models that can generalize \u2026"}, {"title": "Ascle\u2014A Python Natural Language Processing Toolkit for Medical Text Generation: Development and Evaluation Study", "link": "https://www.jmir.org/2024/1/e60601/", "details": "R Yang, Q Zeng, K You, Y Qiao, L Huang, CC Hsieh\u2026 - Journal of Medical Internet \u2026, 2024", "abstract": "Background Medical texts present significant domain-specific challenges, and manually curating these texts is a time-consuming and labor-intensive process. To address this, natural language processing (NLP) algorithms have been developed to \u2026"}, {"title": "MWVOS: Mask-Free Weakly Supervised Video Object Segmentation via promptable foundation model", "link": "https://www.sciencedirect.com/science/article/pii/S0031320324008513", "details": "Z Zhang, S Zhang, Z Dai, Z Dong, S Zhu - Pattern Recognition, 2024", "abstract": "The current state-of-the-art techniques for video object segmentation necessitate extensive training on video datasets with mask annotations, thereby constraining their ability to transfer zero-shot learning to new image distributions and tasks \u2026"}, {"title": "Clinical information extraction for lower-resource languages and domains with few-shot learning using pretrained language models and prompting", "link": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/4596EA36DE0034F9A25D7576C4116BC9/S2977042424000529a.pdf/clinical_information_extraction_for_lowerresource_languages_and_domains_with_fewshot_learning_using_pretrained_language_models_and_prompting.pdf", "details": "P Richter-Pechanski, P Wiesenbach, DM Schwab\u2026 - Natural Language Processing", "abstract": "A vast amount of clinical data are still stored in unstructured text. Automatic extraction of medical information from these data poses several challenges: high costs of clinical expertise, restricted computational resources, strict privacy regulations, and \u2026"}, {"title": "BioMistral-NLU: Towards More Generalizable Medical Language Understanding through Instruction Tuning", "link": "https://arxiv.org/pdf/2410.18955", "details": "YV Fu, GK Ramachandran, N Park, K Lybarger, F Xia\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) such as ChatGPT are fine-tuned on large and diverse instruction-following corpora, and can generalize to new tasks. However, those instruction-tuned LLMs often perform poorly in specialized medical natural \u2026"}, {"title": "SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding", "link": "https://arxiv.org/pdf/2410.11761", "details": "Y Chen, G Wang, Y Ji, Y Li, J Ye, T Li, B Zhang, N Pei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the progress made by multimodal large language models (MLLMs) in computational pathology, they remain limited by a predominant focus on patch-level analysis, missing essential contextual information at the whole-slide level. The lack \u2026"}, {"title": "Automated anonymization of radiology reports: comparison of publicly available natural language processing and large language models", "link": "https://link.springer.com/article/10.1007/s00330-024-11148-x", "details": "MC Langenbach, B Foldyna, I Hadzic, IL Langenbach\u2026 - European Radiology, 2024", "abstract": "Purpose Medical reports, governed by HIPAA regulations, contain personal health information (PHI), restricting secondary data use. Utilizing natural language processing (NLP) and large language models (LLM), we sought to employ publicly \u2026"}]
