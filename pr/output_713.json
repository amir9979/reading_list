'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Northwestern University resource and education develop'
[{"title": "Understanding and Mitigating Bias in Imaging Artificial Intelligence", "link": "https://pubs.rsna.org/doi/pdf/10.1148/rg.230067", "details": "AS Tejani, YS Ng, Y Xi, JC Rayan - RadioGraphics, 2024", "abstract": "Artificial intelligence (AI) algorithms are prone to bias at multiple stages of model development, with potential for exacerbating health disparities. However, bias in imaging AI is a complex topic that encompasses multiple coexisting definitions. Bias \u2026"}, {"title": "Quality of Answers of Generative Large Language Models Versus Peer Users for Interpreting Laboratory Test Results for Lay Patients: Evaluation Study", "link": "https://www.jmir.org/2024/1/e56655/", "details": "Z He, B Bhasuran, Q Jin, S Tian, K Hanna, C Shavor\u2026 - Journal of Medical Internet \u2026, 2024", "abstract": "Background Although patients have easy access to their electronic health records and laboratory test result data through patient portals, laboratory test results are often confusing and hard to understand. Many patients turn to web-based forums or \u2026"}, {"title": "Automatic Prompt Selection for Large Language Models", "link": "https://arxiv.org/pdf/2404.02717", "details": "VT Do, VK Hoang, DH Nguyen, S Sabahi, J Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) can perform various natural language processing tasks with suitable instruction prompts. However, designing effective prompts manually is challenging and time-consuming. Existing methods for automatic prompt \u2026"}, {"title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning", "link": "https://proceedings.mlr.press/v238/e-ildiz24a/e-ildiz24a.pdf", "details": "ME Ildiz, Z Zhao, S Oymak - International Conference on Artificial Intelligence and \u2026, 2024", "abstract": "Large language models exhibit strong multitasking capabilities, however, their learning dynamics as a function of task characteristics, sample size, and model complexity remain mysterious. For instance, it is known that, as the model size grows \u2026"}]
