[{"title": "Self-Comparison for Dataset-Level Membership Inference in Large (Vision-) Language Models", "link": "https://arxiv.org/pdf/2410.13088", "details": "J Ren, K Chen, C Chen, V Sehwag, Y Xing, J Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) and Vision-Language Models (VLMs) have made significant advancements in a wide range of natural language processing and vision- language tasks. Access to large web-scale datasets has been a key factor in their \u2026"}, {"title": "When Attention Sink Emerges in Language Models: An Empirical View", "link": "https://arxiv.org/pdf/2410.10781", "details": "X Gu, T Pang, C Du, Q Liu, F Zhang, C Du, Y Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language Models (LMs) assign significant attention to the first token, even if it is not semantically important, which is known as attention sink. This phenomenon has been widely adopted in applications such as streaming/long context generation, KV \u2026"}, {"title": "Tuning Language Models by Mixture-of-Depths Ensemble", "link": "https://arxiv.org/pdf/2410.13077", "details": "H Luo, L Specia - arXiv preprint arXiv:2410.13077, 2024", "abstract": "Transformer-based Large Language Models (LLMs) traditionally rely on final-layer loss for training and final-layer representations for predictions, potentially overlooking the predictive power embedded in intermediate layers. Surprisingly, we \u2026"}, {"title": "Using a natural language processing toolkit to classify electronic health records by psychiatric diagnosis", "link": "https://journals.sagepub.com/doi/pdf/10.1177/14604582241296411", "details": "A Hutto, TM Zikry, B Bohac, T Rose, J Staebler, J Slay\u2026 - Health Informatics Journal, 2024", "abstract": "Objective: We analyzed a natural language processing (NLP) toolkit's ability to classify unstructured EHR data by psychiatric diagnosis. Expertise can be a barrier to using NLP. We employed an NLP toolkit (CLARK) created to support studies led by \u2026"}, {"title": "CriteriaMapper: establishing the automatic identification of clinical trial cohorts from electronic health records by matching normalized eligibility criteria and patient \u2026", "link": "https://www.nature.com/articles/s41598-024-77447-x", "details": "K Lee, Y Mai, Z Liu, K Raja, T Jun, M Ma, T Wang, L Ai\u2026 - Scientific Reports, 2024", "abstract": "The use of electronic health records (EHRs) holds the potential to enhance clinical trial activities. However, the identification of eligible patients within EHRs presents considerable challenges. We aimed to develop a CriteriaMapper system for \u2026"}, {"title": "Negative-Prompt-driven Alignment for Generative Language Model", "link": "https://arxiv.org/pdf/2410.12194", "details": "S Qiao, N Xv, B Liu, X Geng - arXiv preprint arXiv:2410.12194, 2024", "abstract": "Large language models have achieved remarkable capabilities, but aligning their outputs with human values and preferences remains a significant challenge. Existing alignment methods primarily focus on positive examples while overlooking the \u2026"}, {"title": "Mixture of Experts Made Personalized: Federated Prompt Learning for Vision-Language Models", "link": "https://arxiv.org/pdf/2410.10114", "details": "J Luo, C Chen, S Wu - arXiv preprint arXiv:2410.10114, 2024", "abstract": "Prompt learning for pre-trained Vision-Language Models (VLMs) like CLIP has demonstrated potent applicability across diverse downstream tasks. This lightweight approach has quickly gained traction from federated learning (FL) researchers who \u2026"}, {"title": "Prompt tuning discriminative language models for hierarchical text classification", "link": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/50E5499348A0E72F0C4F3AFC622133A7/S2977042424000517a.pdf/div-class-title-prompt-tuning-discriminative-language-models-for-hierarchical-text-classification-div.pdf", "details": "J du Toit, M Dunaiski - Natural Language Processing", "abstract": "Hierarchical text classification (HTC) is a natural language processing task which aims to categorise a text document into a set of classes from a hierarchical class structure. Recent approaches to solve HTC tasks focus on leveraging pre-trained \u2026"}, {"title": "Axes of Robustness of Neural Language Models", "link": "https://is.muni.cz/th/m805b/PhD_thesis_Michal_Stefanik.pdf", "details": "M \u0160TEF\u00c1NIK", "abstract": "In recent years, language models have emerged into a technology adopted in a wide variety of applications, nowadays largely exceeding traditional natural language processing tasks. Thanks to their versatility and adaptability, modern language \u2026"}]
