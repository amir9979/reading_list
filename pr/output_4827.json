[{"title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education", "link": "https://arxiv.org/pdf/2407.17022", "details": "S Kim, S Kim - arXiv preprint arXiv:2407.17022, 2024", "abstract": "Large language model (LLM)-based evaluation pipelines have demonstrated their capability to robustly evaluate machine-generated text. Extending this methodology to assess human-written text could significantly benefit educational settings by \u2026"}, {"title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "link": "https://arxiv.org/pdf/2407.16667", "details": "H Xu, W Zhang, Z Wang, F Xiao, R Zheng, Y Feng, Z Ba\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, advanced Large Language Models (LLMs) such as GPT-4 have been integrated into many real-world applications like Code Copilot. These applications have significantly expanded the attack surface of LLMs, exposing them to a variety of \u2026"}, {"title": "Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field", "link": "https://arxiv.org/pdf/2407.14076", "details": "T Kerner - arXiv preprint arXiv:2407.14076, 2024", "abstract": "There are many cases where LLMs are used for specific tasks in a single domain. These usually require less general, but more domain-specific knowledge. Highly capable, general-purpose state-of-the-art language models like GPT-4 or Claude-3 \u2026"}, {"title": "Fine-tuning language models for joint rewriting and completion of code with potential bugs", "link": "https://www.amazon.science/publications/fine-tuning-language-models-for-joint-rewriting-and-completion-of-code-with-potential-bugs", "details": "D Wang, J Zhao, H Pei, S Tan, S Zha - 2024", "abstract": "Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs \u2026"}, {"title": "Using Large Language Models for the Interpretation of Building Regulations", "link": "https://arxiv.org/pdf/2407.21060", "details": "S Fuchs, M Witbrock, J Dimyadi, R Amor - arXiv preprint arXiv:2407.21060, 2024", "abstract": "Compliance checking is an essential part of a construction project. The recent rapid uptake of building information models (BIM) in the construction industry has created more opportunities for automated compliance checking (ACC). BIM enables sharing \u2026"}, {"title": "Cool-Fusion: Fuse Large Language Models without Training", "link": "https://arxiv.org/pdf/2407.19807", "details": "C Liu, X Quan, Y Pan, L Lin, W Wu, X Chen - arXiv preprint arXiv:2407.19807, 2024", "abstract": "We focus on the problem of fusing two or more heterogeneous large language models (LLMs) to facilitate their complementary strengths. One of the challenges on model fusion is high computational load, ie to fine-tune or to align vocabularies via \u2026"}, {"title": "Mol2Lang-VLM: Vision-and Text-Guided Generative Pre-trained Language Models for Advancing Molecule Captioning through Multimodal Fusion", "link": "https://openreview.net/pdf%3Fid%3Dax8kYHfkNr", "details": "DT Tran, NT Pham, NDH Nguyen, B Manavalan - ACL 2024 Workshop Language+ \u2026", "abstract": "This paper introduces Mol2Lang-VLM, an enhanced method for refining generative pre-trained language models for molecule captioning using multimodal features to achieve more accurate caption generation. Our approach leverages the encoder and \u2026"}, {"title": "Mobile and Edge Evaluation of Large Language Models", "link": "https://openreview.net/pdf%3Fid%3DaAtCQnCsya", "details": "S Laskaridis, K Katevas, L Minto, H Haddadi - Workshop on Efficient Systems for Foundation \u2026", "abstract": "Transformers have recently revolutionized the machine learning (ML) landscape, gradually making their way into everyday tasks and equipping our computers with\" sparks of intelligence\". However, their runtime requirements have prevented them \u2026"}, {"title": "Do LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models", "link": "https://arxiv.org/pdf/2407.16221", "details": "N Madhusudhan, ST Madhusudhan, V Yadav\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As Large Language Models (LLMs) achieve remarkable performance across various NLP tasks, their reliability becomes essential for widespread adoption. This paper focuses on Abstention Ability (AA), a critical yet under explored aspect of reliability \u2026"}]
