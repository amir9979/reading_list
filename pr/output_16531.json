[{"title": "AICOE at PerAnsSumm 2025: An Ensemble of Large Language Models for Perspective-Aware Healthcare Answer Summarization", "link": "https://aclanthology.org/2025.cl4health-1.36.pdf", "details": "R Rakshith, MS Khan, A Chopra - Proceedings of the Second Workshop on Patient \u2026, 2025", "abstract": "The PerAnsSumm 2024 shared task at the CL4Health workshop focuses on generating structured, perspective-specific summaries to enhance the accessibility of health-related information. Given a Healthcare community QA dataset containing a \u2026"}, {"title": "Grounding-MD: Grounded Video-language Pre-training for Open-World Moment Detection", "link": "https://arxiv.org/pdf/2504.14553", "details": "W Zhuang, Q Li, X Li, M Liu, X Hong, F Gao, F Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Temporal Action Detection and Moment Retrieval constitute two pivotal tasks in video understanding, focusing on precisely localizing temporal segments corresponding to specific actions or events. Recent advancements introduced Moment Detection to \u2026"}, {"title": "Establishing Reliability Metrics for Reward Models in Large Language Models", "link": "https://arxiv.org/pdf/2504.14838", "details": "Y Chen, Y Liu, X Wang, Q Yu, G Huzhang, A Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The reward model (RM) that represents human preferences plays a crucial role in optimizing the outputs of large language models (LLMs), eg, through reinforcement learning from human feedback (RLHF) or rejection sampling. However, a long \u2026"}, {"title": "Beyond maximum-likelihood training: analysis and methods for building robust language generation models", "link": "https://escholarship.mcgill.ca/downloads/d791sp070", "details": "K Arora - 2025", "abstract": "Large language generation models have seen a step change in their capabilities in the last few years, and these models are now being widely deployed in user-facing applications such as search, email, and customer support. Despite these apparent \u2026"}]
