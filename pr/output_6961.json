[{"title": "Attention-enriched deeper UNet (ADU-NET) for disease diagnosis in breast ultrasound and retina fundus images", "link": "https://link.springer.com/article/10.1007/s13748-024-00340-1", "details": "CJ Ejiyi, Z Qin, VK Agbesi, MB Ejiyi, IA Chikwendu\u2026 - Progress in Artificial \u2026, 2024", "abstract": "In image segmentation, effective upsampling plays a pivotal role in recovering lost spatial information during the process of downsampling. Standard skip connections designed to mitigate this and prevalent in most models, often fall short of maintaining \u2026"}, {"title": "Enhancing Efficiency and Innovation with Generative AI", "link": "https://jaiai.org/uploads/archivepdf/36241105.pdf", "details": "X Pan - Journal of Artificial Intelligence and Autonomous \u2026, 2024", "abstract": "Generative AI, powered by Large Language Models (LLMs), has the potential to revolutionize human life by automating tasks, fostering creativity, and improving efficiency. In this work, we highlight recent advancements and related studies in \u2026"}, {"title": "Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in \u2026", "link": "https://arxiv.org/pdf/2409.13902", "details": "A Gilson, X Ai, T Arunachalam, Z Chen, KX Cheong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the potential of Large Language Models (LLMs) in medicine, they may generate responses lacking supporting evidence or based on hallucinated evidence. While Retrieval Augment Generation (RAG) is popular to address this issue, few \u2026"}, {"title": "Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning", "link": "https://arxiv.org/pdf/2409.13641", "details": "DR Cambrin, G Gallipoli, I Benedetto, L Cagliero\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across various tasks. However, current training approaches combine standard cross-entropy loss with extensive data, human feedback, or ad hoc methods to enhance \u2026"}]
