[{"title": "Comparing Commercial and Open-Source Large Language Models for Labeling Chest Radiograph Reports", "link": "https://pubs.rsna.org/doi/abs/10.1148/radiol.241139", "details": "FJ Dorfner, L J\u00fcrgensen, L Donle, F Al Mohamad\u2026 - Radiology, 2024", "abstract": "Background Rapid advances in large language models (LLMs) have led to the development of numerous commercial and open-source models. While recent publications have explored OpenAI's GPT-4 to extract information of interest from \u2026"}, {"title": "Diff-eRank: A Novel Rank-Based Metric for Evaluating Large Language Models", "link": "https://openreview.net/pdf%3Fid%3Dnvn80cscVm", "details": "L Wei, Z Tan, C Li, J Wang, W Huang - The Thirty-eighth Annual Conference on \u2026, 2024", "abstract": "Large Language Models (LLMs) have transformed natural language processing and extended their powerful capabilities to multi-modal domains. As LLMs continue to advance, it is crucial to develop diverse and appropriate metrics for their evaluation \u2026"}, {"title": "Multimodal Large Language Models Make Text-to-Image Generative Models Align Better", "link": "https://openreview.net/pdf%3Fid%3DIRXyPm9IPW", "details": "X Wu, S Huang, G Wang, J Xiong, F Wei - The Thirty-eighth Annual Conference on Neural \u2026", "abstract": "Recent studies have demonstrated the exceptional potentials of leveraging human preference datasets to refine text-to-image generative models, enhancing the alignment between generated images and textual prompts. Despite these advances \u2026"}, {"title": "Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning", "link": "https://arxiv.org/pdf/2411.05193", "details": "J Hong, A Dragan, S Levine - arXiv preprint arXiv:2411.05193, 2024", "abstract": "Value-based reinforcement learning (RL) can in principle learn effective policies for a wide range of multi-turn problems, from games to dialogue to robotic control, including via offline RL from static previously collected datasets. However, despite \u2026"}, {"title": "Reducing Distraction in Long-Context Language Models by Focused Learning", "link": "https://arxiv.org/pdf/2411.05928", "details": "Z Wu, B Liu, R Yan, L Chen, T Delteil - arXiv preprint arXiv:2411.05928, 2024", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly enhanced their capacity to process long contexts. However, effectively utilizing this long context remains a challenge due to the issue of distraction, where irrelevant \u2026"}, {"title": "Generating synthetic clinical text with local large language models to identify misdiagnosed limb fractures in radiology reports", "link": "https://www.sciencedirect.com/science/article/pii/S0933365724002690", "details": "J Liu, B Koopman, NJ Brown, K Chu, A Nguyen - Artificial Intelligence in Medicine, 2024", "abstract": "Large language models (LLMs) demonstrate impressive capabilities in generating human-like content and have much potential to improve the performance and efficiency of healthcare. An important application of LLMs is to generate synthetic \u2026"}, {"title": "Accelerating Blockwise Parallel Language Models with Draft Refinement", "link": "https://openreview.net/pdf%3Fid%3DKT6F5Sw0eg", "details": "T Kim, AT Suresh, KA Papineni, M Riley, S Kumar\u2026 - The Thirty-eighth Annual \u2026", "abstract": "Autoregressive language models have achieved remarkable advancements, yet their potential is often limited by the slow inference speeds associated with sequential token generation. Blockwise parallel decoding (BPD) was proposed by Stern et \u2026"}, {"title": "Axes of Robustness of Neural Language Models", "link": "https://is.muni.cz/th/m805b/PhD_thesis_Michal_Stefanik.pdf", "details": "M \u0160TEF\u00c1NIK", "abstract": "In recent years, language models have emerged into a technology adopted in a wide variety of applications, nowadays largely exceeding traditional natural language processing tasks. Thanks to their versatility and adaptability, modern language \u2026"}, {"title": "BenchX: A Unified Benchmark Framework for Medical Vision-Language Pretraining on Chest X-Rays", "link": "https://arxiv.org/pdf/2410.21969", "details": "Y Zhou, TLH Faith, Y Xu, S Leng, X Xu, Y Liu, RSM Goh - arXiv preprint arXiv \u2026, 2024", "abstract": "Medical Vision-Language Pretraining (MedVLP) shows promise in learning generalizable and transferable visual representations from paired and unpaired medical images and reports. MedVLP can provide useful features to downstream \u2026"}]
