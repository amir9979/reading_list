[{"title": "Position: Bayesian Deep Learning is Needed in the Age of Large-Scale AI", "link": "https://openreview.net/pdf%3Fid%3DPrmxFWI1Fr", "details": "T Papamarkou, M Skoularidou, K Palla, L Aitchison\u2026 - Forty-first International \u2026, 2024", "abstract": "In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of \u2026"}, {"title": "ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification", "link": "https://arxiv.org/pdf/2405.14608", "details": "XM Le, L Luo, U Aickelin, MT Tran - arXiv preprint arXiv:2405.14608, 2024", "abstract": "Multivariate time series classification (MTSC) has attracted significant research attention due to its diverse real-world applications. Recently, exploiting transformers for MTSC has achieved state-of-the-art performance. However, existing methods \u2026"}, {"title": "Disentangled Anomaly Detection For Multivariate Time Series", "link": "https://dl.acm.org/doi/abs/10.1145/3589335.3651492", "details": "X Jie, X Zhou, C Su, Z Zhou, Y Yuan, J Bu, H Wang - \u2026 Proceedings of the ACM on Web \u2026, 2024", "abstract": "Anomaly detection in time series that aims to identify unusual patterns has attracted a lot of attention recently. However, the representation of abnormal and normal data is difffcult to be distinguished because they are usually entangled. Recently \u2026"}, {"title": "Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data", "link": "https://arxiv.org/pdf/2405.07925", "details": "M Morafah, M Reisser, B Lin, C Louizos - arXiv preprint arXiv:2405.07925, 2024", "abstract": "The proliferation of edge devices has brought Federated Learning (FL) to the forefront as a promising paradigm for decentralized and collaborative model training while preserving the privacy of clients' data. However, FL struggles with a significant \u2026"}, {"title": "DGCformer: Deep Graph Clustering Transformer for Multivariate Time Series Forecasting", "link": "https://arxiv.org/pdf/2405.08440", "details": "Q Liu, Y Fang, P Jiang, G Li - arXiv preprint arXiv:2405.08440, 2024", "abstract": "Multivariate time series forecasting tasks are usually conducted in a channel- dependent (CD) way since it can incorporate more variable-relevant information. However, it may also involve a lot of irrelevant variables, and this even leads to \u2026"}, {"title": "UniTST: Effectively Modeling Inter-Series and Intra-Series Dependencies for Multivariate Time Series Forecasting", "link": "https://arxiv.org/pdf/2406.04975", "details": "J Liu, C Liu, G Woo, Y Wang, B Hooi, C Xiong, D Sahoo - arXiv preprint arXiv \u2026, 2024", "abstract": "Transformer-based models have emerged as powerful tools for multivariate time series forecasting (MTSF). However, existing Transformer models often fall short of capturing both intricate dependencies across variate and temporal dimensions in \u2026"}, {"title": "SDformer: Transformer with Spectral Filter and Dynamic Attention for Multivariate Time Series Long-term Forecasting", "link": "https://gengyulyu.github.io/homepage/assets/pdf/SDformer.pdf", "details": "Z Zhou, G Lyu, Y Huang, Z Wang, Z Jia, Z Yang", "abstract": "Transformer has gained widespread adoption in modeling time series due to the exceptional ability of its self-attention mechanism in capturing long-range dependencies. However, when processing time series data with numerous variates \u2026"}]
