[{"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "link": "https://arxiv.org/pdf/2501.04322", "details": "M Rang, Z Bi, C Liu, Y Tang, K Han, Y Wang - arXiv preprint arXiv:2501.04322, 2025", "abstract": "Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are \u2026"}, {"title": "Self-supervised analogical learning using language models", "link": "https://arxiv.org/pdf/2502.00996", "details": "B Zhou, S Jain, Y Zhang, Q Ning, S Wang, Y Benajiba\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models have been shown to suffer from reasoning inconsistency issues. That is, they fail more in situations unfamiliar to the training data, even though exact or very similar reasoning paths exist in more common cases that they can \u2026"}, {"title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "link": "https://arxiv.org/pdf/2501.12266", "details": "C Patr\u00edcio, I Rio-Torto, JS Cardoso, LF Teixeira\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The main challenges limiting the adoption of deep learning-based solutions in medical workflows are the availability of annotated data and the lack of interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the latter \u2026"}, {"title": "Learning with Enriched Inductive Biases for Vision-Language Models", "link": "https://ruyuanzhang.github.io/files/2501_indctbiasVisLangModel_IJCV.pdf", "details": "L Yang, RY Zhang, Q Chen, X Xie - International Journal of Computer Vision, 2025", "abstract": "Abstract Vision-Language Models, pre-trained on large-scale image-text pairs, serve as strong foundation models for transfer learning across a variety of downstream tasks. For few-shot generalization tasks, ie., when the model is trained on few-shot \u2026"}, {"title": "Test-time Loss Landscape Adaptation for Zero-Shot Generalization in Vision-Language Models", "link": "https://arxiv.org/pdf/2501.18864", "details": "A Li, L Zhuang, X Long, M Yao, S Wang - arXiv preprint arXiv:2501.18864, 2025", "abstract": "Test-time adaptation of pre-trained vision-language models has emerged as a technique for tackling distribution shifts during the test time. Although existing methods, especially those based on Test-time Prompt Tuning (TPT), have shown \u2026"}, {"title": "Mordal: Automated Pretrained Model Selection for Vision Language Models", "link": "https://arxiv.org/pdf/2502.00241", "details": "S He, I Jang, M Chowdhury - arXiv preprint arXiv:2502.00241, 2025", "abstract": "Incorporating multiple modalities into large language models (LLMs) is a powerful way to enhance their understanding of non-textual data, enabling them to perform multimodal tasks. Vision language models (VLMs) form the fastest growing category \u2026"}, {"title": "Scaling Laws for Differentially Private Language Models", "link": "https://arxiv.org/pdf/2501.18914", "details": "R McKenna, Y Huang, A Sinha, B Balle, Z Charles\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Scaling laws have emerged as important components of large language model (LLM) training as they can predict performance gains through scale, and provide guidance on important hyper-parameter choices that would otherwise be expensive \u2026"}, {"title": "Scalable Language Models with Posterior Inference of Latent Thought Vectors", "link": "https://arxiv.org/pdf/2502.01567", "details": "D Kong, M Zhao, D Xu, B Pang, S Wang, E Honig, Z Si\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We propose a novel family of language models, Latent-Thought Language Models (LTMs), which incorporate explicit latent thought vectors that follow an explicit prior model in latent space. These latent thought vectors guide the autoregressive \u2026"}, {"title": "Bactrainus: Optimizing Large Language Models for Multi-hop Complex Question Answering Tasks", "link": "https://arxiv.org/pdf/2501.06286", "details": "I Barati, A Ghafouri, B Minaei-Bidgoli - arXiv preprint arXiv:2501.06286, 2025", "abstract": "In recent years, the use of large language models (LLMs) has significantly increased, and these models have demonstrated remarkable performance in a variety of general language tasks. However, the evaluation of their performance in domain \u2026"}]
