[{"title": "More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives", "link": "https://arxiv.org/pdf/2501.04070", "details": "X Zhang, A Lv, Y Liu, F Sung, W Liu, S Shang, X Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) excel at few-shot in-context learning (ICL) without requiring parameter updates. However, as the number of ICL demonstrations increases from a few to many, performance tends to plateau and eventually decline \u2026"}, {"title": "Bias Vector: Mitigating Biases in Language Models with Task Arithmetic Approach", "link": "https://arxiv.org/pdf/2412.11679", "details": "D Shirafuji, M Takenaka, S Taguchi - arXiv preprint arXiv:2412.11679, 2024", "abstract": "The use of language models (LMs) has increased considerably in recent years, and the biases and stereotypes in training data that are reflected in the LM outputs are causing social problems. In this paper, inspired by the task arithmetic, we propose \u2026"}, {"title": "Explicit vs. Implicit: Investigating Social Bias in Large Language Models through Self-Reflection", "link": "https://arxiv.org/pdf/2501.02295", "details": "Y Zhao, B Wang, Y Wang - arXiv preprint arXiv:2501.02295, 2025", "abstract": "Large Language Models (LLMs) have been shown to exhibit various biases and stereotypes in their generated content. While extensive research has investigated bias in LLMs, prior work has predominantly focused on explicit bias, leaving the more \u2026"}, {"title": "Unlearning in Large Language Models: We Are Not There Yet", "link": "https://ieeexplore.ieee.org/iel8/2/10834269/10834279.pdf", "details": "A Blanco-Justicia, J Domingo-Ferrer, NM Jebreel\u2026 - Computer, 2025", "abstract": "Unlearning in Large Language Models: We Are Not There Yet Page 1 ARTIFICIAL INTELLIGENCE/ MACHINE LEARNING EDITOR HSIAO-YING LIN IEEE Member; hsiaoying.lin@gmail.com Large language models (LLMs) have transformed the natural \u2026"}]
