[{"title": "CARE: Aligning Language Models for Regional Cultural Awareness", "link": "https://arxiv.org/pdf/2504.05154%3F", "details": "G Guo, T Naous, H Wakaki, Y Nishimura, Y Mitsufuji\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing language models (LMs) often exhibit a Western-centric bias and struggle to represent diverse cultural knowledge. Previous attempts to address this rely on synthetic data and express cultural knowledge only in English. In this work, we study \u2026"}, {"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}, {"title": "ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports", "link": "https://arxiv.org/pdf/2503.21800", "details": "L Gondara, J Simkin, S Devji, G Arbour, R Ng - arXiv preprint arXiv:2503.21800, 2025", "abstract": "Population-based cancer registries (PBCRs) face a significant bottleneck in manually extracting data from unstructured pathology reports, a process crucial for tasks like tumor group assignment, which can consume 900 person-hours for approximately \u2026"}, {"title": "Generative Large Language Model\u2014Powered Conversational AI App for Personalized Risk Assessment: Case Study in COVID-19", "link": "https://ai.jmir.org/2025/1/e67363/", "details": "MA Roshani, X Zhou, Y Qiang, S Suresh, S Hicks\u2026 - JMIR AI, 2025", "abstract": "Background: Large language models (LLMs) have demonstrated powerful capabilities in natural language tasks and are increasingly being integrated into health care for tasks like disease risk assessment. Traditional machine learning \u2026"}, {"title": "Capybara-OMNI: An Efficient Paradigm for Building Omni-Modal Language Models", "link": "https://arxiv.org/pdf/2504.12315", "details": "X Ji, J Wang, H Zhang, J Zhang, H Zhou, C Sun, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "With the development of Multimodal Large Language Models (MLLMs), numerous outstanding accomplishments have emerged within the open-source community. Due to the complexity of creating and training multimodal data pairs, it is still a \u2026"}, {"title": "VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning", "link": "https://arxiv.org/pdf/2504.08837", "details": "H Wang, C Qu, Z Huang, W Chu, F Lin, W Chen - arXiv preprint arXiv:2504.08837, 2025", "abstract": "Recently, slow-thinking systems like GPT-o1 and DeepSeek-R1 have demonstrated great potential in solving challenging problems through explicit reflection. They significantly outperform the best fast-thinking models, such as GPT-4o, on various \u2026"}, {"title": "A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?", "link": "https://arxiv.org/pdf/2504.05227", "details": "J Silva-Rodr\u00edguez, J Dolz, IB Ayed - arXiv preprint arXiv:2504.05227, 2025", "abstract": "Vision-language pre-training has recently gained popularity as it allows learning rich feature representations using large-scale data sources. This paradigm has quickly made its way into the medical image analysis community. In particular, there is an \u2026"}, {"title": "Foundation Model for Predicting Prognosis and Adjuvant Therapy Benefit From Digital Pathology in GI Cancers", "link": "https://ascopubs.org/doi/abs/10.1200/JCO-24-01501", "details": "X Wang, Y Jiang, S Yang, F Wang, X Zhang, W Wang\u2026 - Journal of Clinical Oncology, 2025", "abstract": "PURPOSE Artificial intelligence (AI) holds significant promise for improving cancer diagnosis and treatment. Here, we present a foundation AI model for prognosis prediction on the basis of standard hematoxylin and eosin\u2013stained histopathology \u2026"}, {"title": "Unlocking language boundaries: AraCLIP-transforming Arabic language and image understanding through cross-lingual models", "link": "https://www.sciencedirect.com/science/article/pii/S0952197625005779", "details": "M Al-Barham, I Afyouni, K Almubarak, A Turky\u2026 - Engineering Applications of \u2026, 2025", "abstract": "In the domain of image retrieval, the integration of text and images has been transformative, facilitating models that transcend language barriers. This paper introduces Arabic Contrastive Language-Image Pre-training (AraCLIP), an extension \u2026"}]
