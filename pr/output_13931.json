[{"title": "CoT2Align: Cross-Chain of Thought Distillation via Optimal Transport Alignment for Language Models with Different Tokenizers", "link": "https://arxiv.org/pdf/2502.16806", "details": "AD Le, T Vu, NL Hai, NTN Diep, LN Van, T Le\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) achieve state-of-the-art performance across various NLP tasks but face deployment challenges due to high computational costs and memory constraints. Knowledge distillation (KD) is a promising solution, transferring \u2026"}, {"title": "Multi-Cue Adaptive Visual Token Pruning for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.08019", "details": "B Luan, W Zhou, H Feng, Z Wang, X Li, H Li - arXiv preprint arXiv:2503.08019, 2025", "abstract": "As the computational needs of Large Vision-Language Models (LVLMs) increase, visual token pruning has proven effective in improving inference speed and memory efficiency. Traditional pruning methods in LVLMs predominantly focus on attention \u2026"}, {"title": "Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones?", "link": "https://arxiv.org/pdf/2502.19557", "details": "Y Zhang, L Wang, M Fang, Y Du, C Huang, J Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Distilling large language models (LLMs) typically involves transferring the teacher model's responses through supervised fine-tuning (SFT). However, this approach neglects the potential to distill both data (output content) and reward signals (quality \u2026"}, {"title": "Mitigating Hallucinations in Large Vision-Language Models by Adaptively Constraining Information Flow", "link": "https://arxiv.org/pdf/2502.20750", "details": "J Bai, H Guo, Z Peng, J Yang, Z Li, M Li, Z Tian - arXiv preprint arXiv:2502.20750, 2025", "abstract": "Large vision-language models show tremendous potential in understanding visual information through human languages. However, they are prone to suffer from object hallucination, ie, the generated image descriptions contain objects that do not exist in \u2026"}, {"title": "Towards Statistical Factuality Guarantee for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.20560", "details": "Z Li, C Yan, NJ Jackson, W Cui, B Li, J Zhang, BA Malin - arXiv preprint arXiv \u2026, 2025", "abstract": "Advancements in Large Vision-Language Models (LVLMs) have demonstrated promising performance in a variety of vision-language tasks involving image- conditioned free-form text generation. However, growing concerns about \u2026"}, {"title": "Process-based Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2503.03746", "details": "S Zhang, X Liu, X Zhang, J Liu, Z Luo, S Huang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' \u2026"}, {"title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models", "link": "https://arxiv.org/pdf/2503.05005", "details": "B Jamialahmadi, P Kavehzadeh, M Rezagholizadeh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deploying large language models (LLMs) in real-world applications is often hindered by strict computational and latency constraints. While dynamic inference offers the flexibility to adjust model behavior based on varying resource budgets, existing \u2026"}, {"title": "Toward Responsible Federated Large Language Models: Leveraging a Safety Filter and Constitutional AI", "link": "https://arxiv.org/pdf/2502.16691", "details": "E Noh, J Baek - arXiv preprint arXiv:2502.16691, 2025", "abstract": "Recent research has increasingly focused on training large language models (LLMs) using federated learning, known as FedLLM. However, responsible AI (RAI), which aims to ensure safe responses, remains underexplored in the context of FedLLM. In \u2026"}, {"title": "LLaVE: Large Language and Vision Embedding Models with Hardness-Weighted Contrastive Learning", "link": "https://arxiv.org/pdf/2503.04812", "details": "Z Lan, L Niu, F Meng, J Zhou, J Su - arXiv preprint arXiv:2503.04812, 2025", "abstract": "Universal multimodal embedding models play a critical role in tasks such as interleaved image-text retrieval, multimodal RAG, and multimodal clustering. However, our empirical results indicate that existing LMM-based embedding models \u2026"}]
