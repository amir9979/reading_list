[{"title": "TriMPL: Masked Multi-Prompt Learning with Knowledge Mixing for Vision-Language Few-shot Learning", "link": "https://dl.acm.org/doi/abs/10.1145/3652583.3658106", "details": "X Liu, Y Shang, Y Chen - Proceedings of the 2024 International Conference on \u2026, 2024", "abstract": "Prompt learning has been proven to be quite an effective technique for adapting large visual-language models (LVLMs) to downstream tasks via few-shot learning. Early methods often rely on a single prompt, which is insufficient for comprehensively \u2026"}, {"title": "Efficient Contrastive Learning for Fast and Accurate Inference on Graphs", "link": "https://openreview.net/pdf%3Fid%3Dvsy21Xodrt", "details": "T Xiao, H Zhu, Z Zhang, Z Guo, CC Aggarwal, S Wang\u2026 - Forty-first International Conference \u2026", "abstract": "Graph contrastive learning has made remarkable advances in settings where there is a scarcity of task-specific labels. Despite these advances, the significant computational overhead for representation inference incurred by existing methods \u2026"}, {"title": "CaseGNN++: Graph Contrastive Learning for Legal Case Retrieval with Graph Augmentation", "link": "https://arxiv.org/pdf/2405.11791", "details": "Y Tang, R Qiu, Y Liu, X Li, Z Huang - arXiv preprint arXiv:2405.11791, 2024", "abstract": "Legal case retrieval (LCR) is a specialised information retrieval task that aims to find relevant cases to a given query case. LCR holds pivotal significance in facilitating legal practitioners in finding precedents. Most of existing LCR methods are based on \u2026"}, {"title": "Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding", "link": "https://arxiv.org/pdf/2405.19763", "details": "K Liao, S Li, M Zhao, L Liu, M Xue, Z Hu, H Han, C Yin - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent strides in large language models (LLMs) have yielded remarkable performance, leveraging reinforcement learning from human feedback (RLHF) to significantly enhance generation and alignment capabilities. However, RLHF \u2026"}, {"title": "Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training", "link": "https://arxiv.org/pdf/2405.19654", "details": "J Yang, B Su, WX Zhao, JR Wen - arXiv preprint arXiv:2405.19654, 2024", "abstract": "Medical vision-language pre-training methods mainly leverage the correspondence between paired medical images and radiological reports. Although multi-view spatial images and temporal sequences of image-report pairs are available in off-the-shelf \u2026"}, {"title": "Calibrating Reasoning in Language Models with Internal Consistency", "link": "https://arxiv.org/pdf/2405.18711", "details": "Z Xie, J Guo, T Yu, S Li - arXiv preprint arXiv:2405.18711, 2024", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various reasoning tasks, aided by techniques like chain-of-thought (CoT) prompting that elicits verbalized reasoning. However, LLMs often generate text with obvious \u2026"}, {"title": "Language Models Need Inductive Biases to Count Inductively", "link": "https://arxiv.org/pdf/2405.20131", "details": "Y Chang, Y Bisk - arXiv preprint arXiv:2405.20131, 2024", "abstract": "Counting is a fundamental example of generalization, whether viewed through the mathematical lens of Peano's axioms defining the natural numbers or the cognitive science literature for children learning to count. The argument holds for both cases \u2026"}, {"title": "Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective", "link": "https://arxiv.org/pdf/2405.16747", "details": "A Tomihari, I Sato - arXiv preprint arXiv:2405.16747, 2024", "abstract": "The two-stage fine-tuning (FT) method, linear probing then fine-tuning (LP-FT), consistently outperforms linear probing (LP) and FT alone in terms of accuracy for both in-distribution (ID) and out-of-distribution (OOD) data. This success is largely \u2026"}, {"title": "TAIA: Large Language Models are Out-of-Distribution Data Learners", "link": "https://arxiv.org/pdf/2405.20192", "details": "S Jiang, Y Liao, Y Zhang, Y Wang, Y Wang - arXiv preprint arXiv:2405.20192, 2024", "abstract": "Fine-tuning on task-specific question-answer pairs is a predominant method for enhancing the performance of instruction-tuned large language models (LLMs) on downstream tasks. However, in certain specialized domains, such as healthcare or \u2026"}]
