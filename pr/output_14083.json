[{"title": "Medvlm-r1: Incentivizing medical reasoning capability of vision-language models (vlms) via reinforcement learning", "link": "https://arxiv.org/pdf/2502.19634", "details": "J Pan, C Liu, J Wu, F Liu, J Zhu, HB Li, C Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning is a critical frontier for advancing medical image analysis, where transparency and trustworthiness play a central role in both clinician trust and regulatory approval. Although Medical Visual Language Models (VLMs) show \u2026"}, {"title": "Few-Shot Whole Slide Pathology Classification with Multi-Granular Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3DnJZtYrOeoV", "details": "AT Nguyen, DMH Nguyen, NT Diep, TQ Nguyen, N Ho\u2026 - \u2026 on Foundation Models in the Wild", "abstract": "In this study, we propose a novel architecture for a large vision-language model adapted with a multi-granular prompt learning method to advance few-shot pathol- ogy classification. Starting with the Prov-GigaPath foundation model-pre-trained on \u2026"}, {"title": "Pathology report generation from whole slide images with knowledge retrieval and multi-level regional feature selection", "link": "https://www.sciencedirect.com/science/article/pii/S016926072500094X", "details": "D Hu, Z Jiang, J Shi, F Xie, K Wu, K Tang, M Cao\u2026 - Computer Methods and \u2026, 2025", "abstract": "Background and objectives: With the development of deep learning techniques, the computer-assisted pathology diagnosis plays a crucial role in clinical diagnosis. An important task within this field is report generation, which provides doctors with text \u2026"}, {"title": "Leveraging Vision-Language Embeddings for Zero-Shot Learning in Histopathology Images", "link": "https://arxiv.org/pdf/2503.10731", "details": "MM Rahaman, EKA Millar, E Meijering - arXiv preprint arXiv:2503.10731, 2025", "abstract": "Zero-shot learning holds tremendous potential for histopathology image analysis by enabling models to generalize to unseen classes without extensive labeled data. Recent advancements in vision-language models (VLMs) have expanded the \u2026"}, {"title": "Multimodal Distillation-Driven Ensemble Learning for Long-Tailed Histopathology Whole Slide Images Analysis", "link": "https://arxiv.org/pdf/2503.00915", "details": "X Ling, Y Ping, J Li, J Peng, Y Chen, M Ouyang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multiple Instance Learning (MIL) plays a significant role in computational pathology, enabling weakly supervised analysis of Whole Slide Image (WSI) datasets. The field of WSI analysis is confronted with a severe long-tailed distribution problem, which \u2026"}, {"title": "Semantic-Clipping: Efficient Vision-Language Modeling with Semantic-Guidedd Visual Selection", "link": "https://arxiv.org/pdf/2503.11794", "details": "B Li, F Wang, W Zhou, N Xu, B Zhou, S Zhang, H Poon\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-Language Models (VLMs) leverage aligned visual encoders to transform images into visual tokens, allowing them to be processed similarly to text by the backbone large language model (LLM). This unified input paradigm enables VLMs to \u2026"}, {"title": "Retinal fundus imaging as biomarker for ADHD using machine learning for screening and visual attention stratification", "link": "https://www.nature.com/articles/s41746-025-01547-9", "details": "H Choi, JS Hong, HG Kang, MH Park, S Ha, J Lee\u2026 - npj Digital Medicine, 2025", "abstract": "Attention-deficit/hyperactivity disorder (ADHD), characterized by diagnostic complexity and symptom heterogeneity, is a prevalent neurodevelopmental disorder. Here, we explored the machine learning (ML) analysis of retinal fundus photographs \u2026"}, {"title": "Development and Evaluation of a Deep Learning Algorithm to Differentiate Between Membranes Attached to the Optic Disc on Ultrasonography", "link": "https://www.tandfonline.com/doi/pdf/10.2147/OPTH.S501316", "details": "VD Bhatt, N Shah, DC Bhatt, S Dabir, J Sheth\u2026 - Clinical Ophthalmology, 2025", "abstract": "Purpose The purpose of this study was to create and test a deep learning algorithm that could identify and distinguish between membranes attached to optic disc [OD; retinal detachment (RD)/posterior vitreous detachment (PVD)] based on ocular \u2026"}, {"title": "Towards Statistical Factuality Guarantee for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.20560", "details": "Z Li, C Yan, NJ Jackson, W Cui, B Li, J Zhang, BA Malin - arXiv preprint arXiv \u2026, 2025", "abstract": "Advancements in Large Vision-Language Models (LVLMs) have demonstrated promising performance in a variety of vision-language tasks involving image- conditioned free-form text generation. However, growing concerns about \u2026"}]
