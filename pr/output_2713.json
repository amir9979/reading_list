[{"title": "Advancing DNA Language Models through Motif-Oriented Pre-Training with MoDNA", "link": "https://www.mdpi.com/2673-7426/4/2/85", "details": "W An, Y Guo, Y Bian, H Ma, J Yang, C Li, J Huang - BioMedInformatics, 2024", "abstract": "Acquiring meaningful representations of gene expression is essential for the accurate prediction of downstream regulatory tasks, such as identifying promoters and transcription factor binding sites. However, the current dependency on \u2026"}, {"title": "VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers", "link": "https://ui.adsabs.harvard.edu/abs/2024arXiv240605370C/abstract", "details": "S Chen, S Liu, L Zhou, Y Liu, X Tan, J Li, S Zhao\u2026 - arXiv e-prints, 2024", "abstract": "This paper introduces VALL-E 2, the latest advancement in neural codec language models that marks a milestone in zero-shot text-to-speech synthesis (TTS), achieving human parity for the first time. Based on its predecessor, VALL-E, the new iteration \u2026"}]
