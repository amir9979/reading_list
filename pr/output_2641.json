[{"title": "Federated Learning via Reweighting Information Bottleneck with Domain Generalization", "link": "https://www.sciencedirect.com/science/article/pii/S0020025524007394", "details": "F Li, X Chen, Z Han, Y Du, H Han - Information Sciences, 2024", "abstract": "Federated learning (FL) plays an important role in collaborative distributed modeling. However, most studies cannot address poor generalization of out-of-distribution (OoD) data. Efforts have been exerted to address data heterogeneity among \u2026"}, {"title": "Why are Visually-Grounded Language Models Bad at Image Classification?", "link": "https://arxiv.org/pdf/2405.18415", "details": "Y Zhang, A Unell, X Wang, D Ghosh, Y Su, L Schmidt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Image classification is one of the most fundamental capabilities of machine vision intelligence. In this work, we revisit the image classification task using visually- grounded language models (VLMs) such as GPT-4V and LLaVA. We find that \u2026"}, {"title": "Discovering and Mitigating Visual Biases through Keyword Explanation", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Discovering_and_Mitigating_Visual_Biases_through_Keyword_Explanation_CVPR_2024_paper.pdf", "details": "Y Kim, S Mo, M Kim, K Lee, J Lee, J Shin - Proceedings of the IEEE/CVF Conference \u2026, 2024", "abstract": "Addressing biases in computer vision models is crucial for real-world AI deployments. However mitigating visual biases is challenging due to their unexplainable nature often identified indirectly through visualization or sample \u2026"}, {"title": "Worldwide Federated Training of Language Models", "link": "https://arxiv.org/pdf/2405.14446", "details": "A Iacob, L Sani, B Marino, P Aleksandrov, ND Lane - arXiv preprint arXiv:2405.14446, 2024", "abstract": "The reliance of language model training on massive amounts of computation and vast datasets scraped from potentially low-quality, copyrighted, or sensitive data has come into question practically, legally, and ethically. Federated learning provides a \u2026"}, {"title": "A fine-grained self-adapting prompt learning approach for few-shot learning with pre-trained language models", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124006026", "details": "X Chen, T Liu, P Fournier-Viger, B Zhang, G Long\u2026 - Knowledge-Based Systems, 2024", "abstract": "Pre-trained language models have demonstrated remarkable performance in few- shot learning through the emergence of \u201cprompt-based learning\u201d methods, where the performance of these tasks highly rely on the quality of prompts. Existing prompt \u2026"}, {"title": "Relationship constraint deep metric learning", "link": "https://link.springer.com/article/10.1007/s10489-024-05425-x", "details": "Y Zhang, T Xiao, Z Wang, X Wang, W Feng, Z Fu\u2026 - Applied Intelligence, 2024", "abstract": "Deep metric learning (DML) models aim to learn semantically meaningful representations in which similar samples are pulled together and dissimilar samples are pushed apart. However, the classification effect is limited due to the high time \u2026"}, {"title": "Potential Field Based Deep Metric Learning", "link": "https://arxiv.org/pdf/2405.18560", "details": "S Bhatnagar, N Ahuja - arXiv preprint arXiv:2405.18560, 2024", "abstract": "Deep metric learning (DML) involves training a network to learn a semantically meaningful representation space. Many current approaches mine n-tuples of examples and model interactions within each tuplets. We present a novel \u2026"}, {"title": "Q-value Regularized Transformer for Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2405.17098", "details": "S Hu, Z Fan, C Huang, L Shen, Y Zhang, Y Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in offline reinforcement learning (RL) have underscored the capabilities of Conditional Sequence Modeling (CSM), a paradigm that learns the action distribution based on history trajectory and target returns for each state \u2026"}, {"title": "HarmoDT: Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2405.18080", "details": "S Hu, Z Fan, L Shen, Y Zhang, Y Wang, D Tao - arXiv preprint arXiv:2405.18080, 2024", "abstract": "The purpose of offline multi-task reinforcement learning (MTRL) is to develop a unified policy applicable to diverse tasks without the need for online environmental interaction. Recent advancements approach this through sequence modeling \u2026"}]
