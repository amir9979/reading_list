'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Source-Aware Training Enables Knowledge Attribution in'
[{"title": "Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks", "link": "https://arxiv.org/pdf/2404.00376", "details": "H Kim, H Hwang, J Lee, S Park, D Kim, T Lee, C Yoon\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While recent advancements in commercial large language models (LM) have shown promising results in medical tasks, their closed-source nature poses significant privacy and security concerns, hindering their widespread use in the medical field \u2026"}, {"title": "From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with Vision-Language Models", "link": "https://arxiv.org/html/2404.00906v1", "details": "R Li, S Zhang, D Lin, K Chen, X He - arXiv preprint arXiv:2404.00906, 2024", "abstract": "Scene graph generation (SGG) aims to parse a visual scene into an intermediate graph representation for downstream reasoning tasks. Despite recent advancements, existing methods struggle to generate scene graphs with novel visual \u2026"}, {"title": "Mining Clinical Notes for Physical Rehabilitation Exercise Information: Natural Language Processing Algorithm Development and Validation Study", "link": "https://medinform.jmir.org/2024/1/e52289/", "details": "S Sivarajkumar, F Gao, P Denny, B Aldhahwani\u2026 - JMIR Medical Informatics, 2024", "abstract": "Background: The rehabilitation of a patient who had a stroke requires precise, personalized treatment plans. Natural language processing (NLP) offers the potential to extract valuable exercise information from clinical notes, aiding in the development \u2026"}, {"title": "Question-answering system extracts information on injection drug use from clinical notes", "link": "https://www.nature.com/articles/s43856-024-00470-6", "details": "M Mahbub, I Goethert, I Danciu, K Knight, S Srinivasan\u2026 - Communications Medicine, 2024", "abstract": "Background Injection drug use (IDU) can increase mortality and morbidity. Therefore, identifying IDU early and initiating harm reduction interventions can benefit individuals at risk. However, extracting IDU behaviors from patients' electronic health \u2026"}, {"title": "Deconstructing In-Context Learning: Understanding Prompts via Corruption", "link": "https://arxiv.org/pdf/2404.02054", "details": "N Shivagunde, V Lialin, S Muckatira, A Rumshisky - arXiv preprint arXiv:2404.02054, 2024", "abstract": "The ability of large language models (LLMs) to\" learn in context\" based on the provided prompt has led to an explosive growth in their use, culminating in the proliferation of AI assistants such as ChatGPT, Claude, and Bard. These AI assistants \u2026"}, {"title": "Scaling Properties of Speech Language Models", "link": "https://arxiv.org/html/2404.00685v1", "details": "S Cuervo, R Marxer - arXiv preprint arXiv:2404.00685, 2024", "abstract": "Speech Language Models (SLMs) aim to learn language from raw audio, without textual resources. Despite significant advances, our current models exhibit weak syntax and semantic abilities. However, if the scaling properties of neural language \u2026"}, {"title": "On-the-fly Definition Augmentation of LLMs for Biomedical NER", "link": "https://arxiv.org/pdf/2404.00152", "details": "M Munnangi, S Feldman, BC Wallace, S Amir, T Hope\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in \u2026"}, {"title": "Token-Efficient Leverage Learning in Large Language Models", "link": "https://arxiv.org/pdf/2404.00914", "details": "Y Zeng, M Wang, Y Wang, Y Shao - arXiv preprint arXiv:2404.00914, 2024", "abstract": "Large Language Models (LLMs) have excelled in various tasks but perform better in high-resource scenarios, which presents challenges in low-resource scenarios. Data scarcity and the inherent difficulty of adapting LLMs to specific tasks compound the \u2026"}, {"title": "Scaling Behavior of Machine Translation with Large Language Models under Prompt Injection Attacks", "link": "https://arxiv.org/pdf/2403.09832", "details": "Z Sun, AV Miceli-Barone - arXiv preprint arXiv:2403.09832, 2024", "abstract": "Large Language Models (LLMs) are increasingly becoming the preferred foundation platforms for many Natural Language Processing tasks such as Machine Translation, owing to their quality often comparable to or better than task-specific models, and the \u2026"}]
