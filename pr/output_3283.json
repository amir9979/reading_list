[{"title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models", "link": "https://arxiv.org/pdf/2406.17092", "details": "Y Zeng, W Sun, TN Huynh, D Song, B Li, R Jia - arXiv preprint arXiv:2406.17092, 2024", "abstract": "Safety backdoor attacks in large language models (LLMs) enable the stealthy triggering of unsafe behaviors while evading detection during normal interactions. The high dimensionality of potential triggers in the token space and the diverse \u2026"}, {"title": "Risk Prediction of Heart Diseases in Breast Cancer Patients: A Deep Learning Approach with Longitudinal Electronic Health Records Data", "link": "https://www.sciencedirect.com/science/article/pii/S2589004224015542/pdf%3Fmd5%3D37c71c6825b3040cbf3cbd88afb5955b%26pid%3D1-s2.0-S2589004224015542-main.pdf", "details": "S Zhou, A Blaes, C Shenoy, J Sun, R Zhang - iScience, 2024", "abstract": "Accurately predicting heart disease risks in breast cancer patients is crucial for clinical decision support and patient safety. This study developed and evaluated predictive models for six heart diseases using real-world electronic health records \u2026"}, {"title": "A Critical Look At Tokenwise Reward-Guided Text Generation", "link": "https://arxiv.org/pdf/2406.07780", "details": "A Rashid, R Wu, J Grosse, A Kristiadi, P Poupart - arXiv preprint arXiv:2406.07780, 2024", "abstract": "Large language models (LLMs) can significantly be improved by aligning to human preferences--the so-called reinforcement learning from human feedback (RLHF). However, the cost of fine-tuning an LLM is prohibitive for many users. Due to their \u2026"}, {"title": "Training Compute-Optimal Protein Language Models", "link": "https://www.biorxiv.org/content/10.1101/2024.06.06.597716.full.pdf", "details": "X Cheng, B Chen, P Li, J Gong, J Tang, L Song - bioRxiv, 2024", "abstract": "We explore optimally training protein language models, an area of significant interest in biological research where guidance on best practices is limited. Most models are trained with extensive compute resources until performance gains plateau, focusing \u2026"}, {"title": "ULTRAFEEDBACK: Boosting Language Models with Scaled AI Feedback", "link": "https://openreview.net/pdf%3Fid%3DBOorDpKHiJ", "details": "G Cui, L Yuan, N Ding, G Yao, B He, W Zhu, Y Ni, G Xie\u2026 - Forty-first International \u2026, 2024", "abstract": "Learning from human feedback has become a pivot technique in aligning large language models (LLMs) with human preferences. However, acquiring vast and premium human feedback is bottlenecked by time, labor, and human capability \u2026"}, {"title": "Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt", "link": "https://arxiv.org/pdf/2406.04031", "details": "Z Ying, A Liu, T Zhang, Z Yu, S Liang, X Liu, D Tao - arXiv preprint arXiv:2406.04031, 2024", "abstract": "In the realm of large vision language models (LVLMs), jailbreak attacks serve as a red-teaming approach to bypass guardrails and uncover safety implications. Existing jailbreaks predominantly focus on the visual modality, perturbing solely visual inputs \u2026"}, {"title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models", "link": "https://aclanthology.org/2024.findings-naacl.18.pdf", "details": "Z Su, Z Lin, B Baixue, H Chen, S Hu, W Zhou, G Ding\u2026 - Findings of the Association \u2026, 2024", "abstract": "Generative language models are usually pre-trained on large text corpus via predicting the next token (ie, sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language \u2026"}, {"title": "Symmetric Dot-Product Attention for Efficient Training of BERT Language Models", "link": "https://arxiv.org/pdf/2406.06366", "details": "M Courtois, M Ostendorff, L Hennig, G Rehm - arXiv preprint arXiv:2406.06366, 2024", "abstract": "Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing \u2026"}, {"title": "Medical Concept Normalization", "link": "https://link.springer.com/chapter/10.1007/978-3-031-55865-8_6", "details": "H Xu, D Demner Fushman, N Hong, K Raja - Natural Language Processing in \u2026, 2024", "abstract": "Medical concept normalization, which maps clinical entities to concepts in standard terminology, is essential for supporting downstream computational applications in clinical settings. This chapter starts with an overview of existing biomedical \u2026"}]
