[{"title": "HLMEA: Unsupervised Entity Alignment Based on Hybrid Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/33294/35449", "details": "X Jin, Z Wang, J Chen, L Yang, B Oh, S Hwang, J Li - Proceedings of the AAAI \u2026, 2025", "abstract": "Entity alignment (EA) is crucial for integrating knowledge graphs (KGs) constructed from diverse sources. Conventional unsupervised EA approaches attempt to eliminate human intervention but often suffer from accuracy limitations. With the rise \u2026"}, {"title": "Overcoming Heterogeneous Data in Federated Medical Vision-Language Pre-training: A Triple-Embedding Model Selector Approach", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32807/34962", "details": "A Wang, Z Zhang, D Wang, F Wang, H Hu, J Guo\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "The scarcity data of medical field brings the collaborative training in medical vision- language pre-training (VLP) cross different clients. Therefore, the collaborative training in medical VLP faces two challenges: First, the medical data requires \u2026"}, {"title": "Integrating Large Language Models and M\u00f6bius Group Transformations for Temporal Knowledge Graph Embedding on the Riemann Sphere", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/33449/35604", "details": "S Zhang, X Liang, S Niu, Z Niu, B Wu, G Hua, L Wang\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "Abstract The significance of Temporal Knowledge Graphs (TKGs) in Artificial Intelligence (AI) lies in their capacity to incorporate time-dimensional information, support complex reasoning and prediction, optimize decision-making processes \u2026"}, {"title": "DeCAP: Context-Adaptive Prompt Generation for Debiasing Zero-shot Question Answering in Large Language Models", "link": "https://arxiv.org/pdf/2503.19426%3F", "details": "S Bae, YS Choi, JH Lee - arXiv preprint arXiv:2503.19426, 2025", "abstract": "While Large Language Models (LLMs) excel in zero-shot Question Answering (QA), they tend to expose biases in their internal knowledge when faced with socially sensitive questions, leading to a degradation in performance. Existing zero-shot \u2026"}, {"title": "Detecting implicit biases of large language models with Bayesian hypothesis testing", "link": "https://www.nature.com/articles/s41598-025-95825-x", "details": "S Si, X Jiang, Q Su, L Carin - Scientific Reports, 2025", "abstract": "Despite the remarkable performance of large language models (LLMs), such as generative pre-trained Transformers (GPTs), across various tasks, they often perpetuate social biases and stereotypes embedded in their training data. In this \u2026"}, {"title": "STAF-LLM: A scalable and task-adaptive fine-tuning framework for large language models in medical domain", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425012047", "details": "T Xu, L Chen, Z Hu, B Li - Expert Systems with Applications, 2025", "abstract": "Recent large language models (LLMs) have demonstrated remarkable performance across various NLP tasks. However, their application in the medical domain is often limited by a lack of specialized medical knowledge, which is crucial for practical \u2026"}]
