[{"title": "Harnessing the Intrinsic Knowledge of Pretrained Language Models for Challenging Text Classification Settings", "link": "https://arxiv.org/pdf/2408.15650", "details": "L Gao - arXiv preprint arXiv:2408.15650, 2024", "abstract": "Text classification is crucial for applications such as sentiment analysis and toxic text filtering, but it still faces challenges due to the complexity and ambiguity of natural language. Recent advancements in deep learning, particularly transformer \u2026"}, {"title": "Enhancing One-shot Pruned Pre-trained Language Models through Sparse-Dense-Sparse Mechanism", "link": "https://arxiv.org/pdf/2408.10473", "details": "G Li, X Zhao, L Liu, Z Li, D Li, L Tian, J He, A Sirasao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained language models (PLMs) are engineered to be robust in contextual understanding and exhibit outstanding performance in various natural language processing tasks. However, their considerable size incurs significant computational \u2026"}, {"title": "Improving Extraction of Clinical Event Contextual Properties from Electronic Health Records: A Comparative Study", "link": "https://arxiv.org/pdf/2408.17181", "details": "S Agarwal, T Searle, M Ratas, A Shek, J Teo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Electronic Health Records are large repositories of valuable clinical data, with a significant portion stored in unstructured text format. This textual data includes clinical events (eg, disorders, symptoms, findings, medications and procedures) in \u2026"}, {"title": "Development and validation of an open-source pipeline for automatic population of case report forms from electronic health records: a pediatric multi-center \u2026", "link": "https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964\\(24\\)00373-6/fulltext", "details": "A Guti\u00e9rrez-Sacrist\u00e1n, S Makwana, A Dionne\u2026 - eBioMedicine, 2024", "abstract": "Background Clinical trials and registry studies are essential for advancing research and developing novel treatments. However, these studies rely on manual entry of thousands of variables for each patient. Repurposing real-world data can \u2026"}, {"title": "SynSUM--Synthetic Benchmark with Structured and Unstructured Medical Records", "link": "https://arxiv.org/pdf/2409.08936", "details": "P Rabaey, H Arno, S Heytens, T Demeester - arXiv preprint arXiv:2409.08936, 2024", "abstract": "We present the SynSUM benchmark, a synthetic dataset linking unstructured clinical notes to structured background variables. The dataset consists of 10,000 artificial patient records containing tabular variables (like symptoms, diagnoses and \u2026"}, {"title": "Toward a Patient-Centered Care Supporting System: Integration of Multidisciplinary Health Records in Breast Cancer Care", "link": "https://pubmed.ncbi.nlm.nih.gov/39176542/", "details": "A Sugiyama, K Utsunomiya, H Okumiya, K Fujimoto\u2026 - Studies in health technology \u2026, 2024", "abstract": "An important paradigm shift within healthcare is the shift toward patient-centered care (PCC). Multidisciplinary team meetings (MDTM) are considered essential for PCC, despite being considered time-consuming and expensive. Patient-centered \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection", "link": "https://arxiv.org/pdf/2409.06072", "details": "J Chakraborty, W Xia, A Majumder, D Ma, W Chaabene\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks. However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further \u2026"}, {"title": "Generating Synthetic Free-text Medical Records with Low Re-identification Risk using Masked Language Modeling", "link": "https://arxiv.org/pdf/2409.09831", "details": "S Belkadi, L Ren, N Micheletti, L Han, G Nenadic - arXiv preprint arXiv:2409.09831, 2024", "abstract": "In this paper, we present a system that generates synthetic free-text medical records, such as discharge summaries, admission notes and doctor correspondences, using Masked Language Modeling (MLM). Our system is designed to preserve the critical \u2026"}]
