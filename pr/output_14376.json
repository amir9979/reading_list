[{"title": "Task-to-Instance Prompt Learning for Vision-Language Models at Test Time", "link": "https://ieeexplore.ieee.org/abstract/document/10925517/", "details": "Z Lu, J Bai, X Li, Z Xiao, X Wang - IEEE Transactions on Image Processing, 2025", "abstract": "Prompt learning has been recently introduced into the adaption of pre-trained vision- language models (VLMs) by tuning a set of trainable tokens to replace hand-crafted text templates. Despite the encouraging results achieved, existing methods largely \u2026"}, {"title": "ST-VLM: Kinematic Instruction Tuning for Spatio-Temporal Reasoning in Vision-Language Models", "link": "https://arxiv.org/pdf/2503.19355", "details": "D Ko, S Kim, Y Suh, M Yoon, M Chandraker, HJ Kim - arXiv preprint arXiv \u2026, 2025", "abstract": "Spatio-temporal reasoning is essential in understanding real-world environments in various fields, eg, autonomous driving and sports analytics. Recent advances have improved the spatial reasoning ability of Vision-Language Models (VLMs) by \u2026"}, {"title": "Neural Antidote: Class-Wise Prompt Tuning for Purifying Backdoors in Pre-trained Vision-Language Models", "link": "https://arxiv.org/pdf/2502.19269%3F", "details": "J Kong, H Fang, S Guo, C Qing, B Chen, B Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "While pre-trained Vision-Language Models (VLMs) such as CLIP exhibit excellent representational capabilities for multimodal data, recent studies have shown that they are vulnerable to backdoor attacks. To alleviate the threat, existing defense \u2026"}, {"title": "fine-CLIP: Enhancing Zero-Shot Fine-Grained Surgical Action Recognition with Vision-Language Models", "link": "https://arxiv.org/pdf/2503.19670", "details": "S Sharma, D Mutter, N Padoy - arXiv preprint arXiv:2503.19670, 2025", "abstract": "While vision-language models like CLIP have advanced zero-shot surgical phase recognition, they struggle with fine-grained surgical activities, especially action triplets. This limitation arises because current CLIP formulations rely on global image \u2026"}, {"title": "CSPO: chain-structured prompt optimisation for large language models", "link": "https://www.inderscienceonline.com/doi/abs/10.1504/IJAHUC.2025.145202", "details": "J Wang, S Lin, X Xue, S Chen, Z Tang - International Journal of Ad Hoc and \u2026, 2025", "abstract": "Large language models (LLMs) show promise in improving content distribution in mobile communication networks, but their performance heavily depends on input prompts. Manually crafting effective prompts for complex tasks is time-consuming \u2026"}]
