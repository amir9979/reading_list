[{"title": "Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios", "link": "https://aclanthology.org/2024.findings-acl.230.pdf", "details": "L Lin, J Fu, P Liu, Q Li, Y Gong, J Wan, F Zhang\u2026 - Findings of the Association \u2026, 2024", "abstract": "Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local \u2026"}, {"title": "Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models", "link": "https://arxiv.org/pdf/2408.01308", "details": "Y Zhang, D Li, M Okumura - arXiv preprint arXiv:2408.01308, 2024", "abstract": "Learning token embeddings based on token co-occurrence statistics has proven effective for both pre-training and fine-tuning in natural language processing. However, recent studies have pointed out the distribution of learned embeddings \u2026"}, {"title": "LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of Relational Knowledge in Language Models", "link": "https://arxiv.org/pdf/2408.15729", "details": "M Ploner, J Wiland, S Pohl, A Akbik - arXiv preprint arXiv:2408.15729, 2024", "abstract": "Knowledge probing evaluates the extent to which a language model (LM) has acquired relational knowledge during its pre-training phase. It provides a cost- effective means of comparing LMs of different sizes and training setups and is useful \u2026"}, {"title": "Multi-task heterogeneous graph learning on electronic health records", "link": "https://arxiv.org/pdf/2408.07569", "details": "TH Chan, G Yin, K Bae, L Yu - Neural Networks, 2024", "abstract": "Learning electronic health records (EHRs) has received emerging attention because of its capability to facilitate accurate medical diagnosis. Since the EHRs contain enriched information specifying complex interactions between entities, modeling \u2026"}, {"title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework", "link": "https://arxiv.org/pdf/2408.02056", "details": "G Kumichev, P Blinov, Y Kuzkina, V Goncharov\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generating synthetic text addresses the challenge of data availability in privacy- sensitive domains such as healthcare. This study explores the applicability of synthetic data in real-world medical settings. We introduce MedSyn, a novel medical \u2026"}, {"title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models", "link": "https://arxiv.org/pdf/2408.15313", "details": "W Zhang, PHS Torr, M Elhoseiny, A Bibi - arXiv preprint arXiv:2408.15313, 2024", "abstract": "Fine-tuning large language models (LLMs) on human preferences, typically through reinforcement learning from human feedback (RLHF), has proven successful in enhancing their capabilities. However, ensuring the safety of LLMs during the fine \u2026"}, {"title": "Making Long-Context Language Models Better Multi-Hop Reasoners", "link": "https://arxiv.org/pdf/2408.03246", "details": "Y Li, S Liang, MR Lyu, L Wang - arXiv preprint arXiv:2408.03246, 2024", "abstract": "Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased \u2026"}, {"title": "Multi-modal Preference Alignment Remedies Degradation of Visual Instruction Tuning on Language Models", "link": "https://aclanthology.org/2024.acl-long.765.pdf", "details": "S Li, R Lin, S Pei - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Multi-modal large language models (MLLMs) are expected to support multi-turn queries of interchanging image and text modalities in production. However, the current MLLMs trained with visual-question-answering (VQA) datasets could suffer \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}]
