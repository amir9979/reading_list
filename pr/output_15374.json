[{"title": "Beyond Patches: Mining Interpretable Part-Prototypes for Explainable AI", "link": "https://arxiv.org/pdf/2504.12197", "details": "M Alehdaghi, R Bhattacharya, P Shamsolmoali\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deep learning has provided considerable advancements for multimedia systems, yet the interpretability of deep models remains a challenge. State-of-the-art post-hoc explainability methods, such as GradCAM, provide visual interpretation based on \u2026"}, {"title": "A Complex-valued SAR Foundation Model Based on Physically Inspired Representation Learning", "link": "https://arxiv.org/pdf/2504.11999", "details": "M Wang, H Bi, Y Feng, L Xin, S Gong, T Wang, Z Yan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision foundation models in remote sensing have been extensively studied due to their superior generalization on various downstream tasks. Synthetic Aperture Radar (SAR) offers all-day, all-weather imaging capabilities, providing significant \u2026"}]
