[{"title": "Towards a holistic framework for multimodal LLM in 3D brain CT radiology report generation", "link": "https://www.nature.com/articles/s41467-025-57426-0", "details": "CY Li, KJ Chang, CF Yang, HY Wu, W Chen, H Bansal\u2026 - Nature Communications, 2025", "abstract": "Multi-modal large language models (MLLMs) have transformed the landscape of modern healthcare, with automated radiology report generation (RRG) emerging as a cutting-edge application. While 2D MLLM-based RRG has been well established \u2026"}, {"title": "Language Model Uncertainty Quantification with Attention Chain", "link": "https://arxiv.org/pdf/2503.19168", "details": "Y Li, R Qiang, L Moukheiber, C Zhang - arXiv preprint arXiv:2503.19168, 2025", "abstract": "Accurately quantifying a large language model's (LLM) predictive uncertainty is crucial for judging the reliability of its answers. While most existing research focuses on short, directly answerable questions with closed-form outputs (eg, multiple \u2026"}, {"title": "Evaluating the Performance of Large Language Models in Identifying Human Facial Emotions: GPT 4o, Gemini 2.0 Experimental, and Claude 3.5 Sonnet", "link": "https://osf.io/pxq5h_v1/download", "details": "B Nelson, A Winbush, S Siddals, J Torous, N Allen\u2026 - 2025", "abstract": "Background. Evaluating the social and emotional capabilities of large language models (LLMs), such as their ability to recognize human facial emotion is critical as their role in human-computer interactions (HCIs) expands, particularly in healthcare \u2026"}]
