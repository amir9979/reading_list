[{"title": "Efficiency and Quality of Generative AI\u2013Assisted Radiograph Reporting", "link": "https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2834943", "details": "J Huang, MT Wittbrodt, CN Teague, E Karl, G Galal\u2026 - JAMA Network Open, 2025", "abstract": "Importance Diagnostic imaging interpretation involves distilling multimodal clinical information into text form, a task well-suited to augmentation by generative artificial intelligence (AI). However, to our knowledge, impacts of AI-based draft radiological \u2026"}, {"title": "Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification", "link": "https://arxiv.org/pdf/2506.04450", "details": "P Bhattacharjee, F Tian, R Tandon, J Lo, H Hanson\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Purpose: This study proposes a framework for fine-tuning large language models (LLMs) with differential privacy (DP) to perform multi-abnormality classification on radiology report text. By injecting calibrated noise during fine-tuning, the framework \u2026", "entry_id": "http://arxiv.org/abs/2506.04450v1", "updated": "2025-06-04 21:11:45", "published": "2025-06-04 21:11:45", "authors": "Payel Bhattacharjee;Fengwei Tian;Ravi Tandon;Joseph Lo;Heidi Hanson;Geoffrey Rubin;Nirav Merchant;John Gounley", "summary": "Purpose: This study proposes a framework for fine-tuning large language\nmodels (LLMs) with differential privacy (DP) to perform multi-abnormality\nclassification on radiology report text. By injecting calibrated noise during\nfine-tuning, the framework seeks to mitigate the privacy risks associated with\nsensitive patient data and protect against data leakage while maintaining\nclassification performance. Materials and Methods: We used 50,232 radiology\nreports from the publicly available MIMIC-CXR chest radiography and CT-RATE\ncomputed tomography datasets, collected between 2011 and 2019. Fine-tuning of\nLLMs was conducted to classify 14 labels from MIMIC-CXR dataset, and 18 labels\nfrom CT-RATE dataset using Differentially Private Low-Rank Adaptation (DP-LoRA)\nin high and moderate privacy regimes (across a range of privacy budgets =\n{0.01, 0.1, 1.0, 10.0}). Model performance was evaluated using weighted F1\nscore across three model architectures: BERT-medium, BERT-small, and\nALBERT-base. Statistical analyses compared model performance across different\nprivacy levels to quantify the privacy-utility trade-off. Results: We observe a\nclear privacy-utility trade-off through our experiments on 2 different datasets\nand 3 different models. Under moderate privacy guarantees the DP fine-tuned\nmodels achieved comparable weighted F1 scores of 0.88 on MIMIC-CXR and 0.59 on\nCT-RATE, compared to non-private LoRA baselines of 0.90 and 0.78, respectively.\nConclusion: Differentially private fine-tuning using LoRA enables effective and\nprivacy-preserving multi-abnormality classification from radiology reports,\naddressing a key challenge in fine-tuning LLMs on sensitive medical data.", "comment": "19 pages, 5 figures, 2 tables", "journal_ref": null, "primary_category": "cs.CR", "categories": "cs.CR;cs.AI;cs.CL;cs.LG", "links": "http://arxiv.org/abs/2506.04450v1;http://arxiv.org/pdf/2506.04450v1", "pdf_url": "http://arxiv.org/pdf/2506.04450v1"}]
