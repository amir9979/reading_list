[{"title": "VLRewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models", "link": "https://arxiv.org/pdf/2411.17451", "details": "L Li, Y Wei, Z Xie, X Yang, Y Song, P Wang, C An, T Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language generative reward models (VL-GenRMs) play a crucial role in aligning and evaluating multimodal AI systems, yet their own evaluation remains under-explored. Current assessment methods primarily rely on AI-annotated \u2026"}, {"title": "Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering", "link": "https://arxiv.org/pdf/2411.16863", "details": "F Cocchi, N Moratelli, M Cornia, L Baraldi, R Cucchiara - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal LLMs (MLLMs) are the natural extension of large language models to handle multimodal inputs, combining text and image data. They have recently garnered attention due to their capability to address complex tasks involving both \u2026"}, {"title": "Pre-trained Molecular Language Models with Random Functional Group Masking", "link": "https://arxiv.org/pdf/2411.01401", "details": "T Peng, Y Li, X Li, J Bian, Z Xie, N Sui, S Mumtaz, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in computational chemistry have leveraged the power of trans- former-based language models, such as MoLFormer, pre-trained using a vast amount of simplified molecular-input line-entry system (SMILES) sequences, to \u2026"}, {"title": "BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices", "link": "https://arxiv.org/pdf/2411.10640", "details": "X Lu, Y Chen, C Chen, H Tan, B Chen, Y Xie, R Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence and growing popularity of multimodal large language models (MLLMs) have significant potential to enhance various aspects of daily life, from improving communication to facilitating learning and problem-solving. Mobile \u2026"}, {"title": "Group Robust Best-of-K Decoding of Language Models for Pluralistic Alignment", "link": "https://openreview.net/pdf%3Fid%3DJI6j4NUGHv", "details": "S Yoon, W Bankes, S Son, A Petrovic, SS Ramesh\u2026 - Pluralistic Alignment Workshop at \u2026", "abstract": "The desirable behaviour of a chat agent can be described with multiple criteria, such as harmlessness, helpfulness, and conciseness, each of which can be scored by a reward model. While each user, or a group of users, may perceive each criterion with \u2026"}, {"title": "Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations", "link": "https://arxiv.org/pdf/2411.07237", "details": "C Malaviya, JC Chang, D Roth, M Iyyer, M Yatskar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model users often issue queries that lack specification, where the context under which a query was issued--such as the user's identity, the query's intent, and the criteria for a response to be useful--is not explicit. For instance, a good response \u2026"}, {"title": "Large Language Models Can Self-Improve in Long-context Reasoning", "link": "https://arxiv.org/pdf/2411.08147", "details": "S Li, C Yang, Z Cheng, L Liu, M Yu, Y Yang, W Lam - arXiv preprint arXiv:2411.08147, 2024", "abstract": "Large language models (LLMs) have achieved substantial progress in processing long contexts but still struggle with long-context reasoning. Existing approaches typically involve fine-tuning LLMs with synthetic data, which depends on annotations \u2026"}, {"title": "Continual Memorization of Factoids in Large Language Models", "link": "https://arxiv.org/pdf/2411.07175", "details": "H Chen, J Geng, A Bhaskar, D Friedman, D Chen - arXiv preprint arXiv:2411.07175, 2024", "abstract": "Large language models can absorb a massive amount of knowledge through pretraining, but pretraining is inefficient for acquiring long-tailed or specialized facts. Therefore, fine-tuning on specialized or new knowledge that reflects changes in the \u2026"}, {"title": "AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant", "link": "https://arxiv.org/pdf/2411.06805", "details": "Y Zhou, Z Liu, Z Dou - arXiv preprint arXiv:2411.06805, 2024", "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced natural language processing, but these models often generate factually incorrect information, known as\" hallucination\". Initial retrieval-augmented generation (RAG) \u2026"}]
