[{"title": "Ce-LLMs: Status and trends of education-specific **large language models** developed in China", "link": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/fer3.70008", "details": "T Xie, Y Zhou, J Yu - Future in Educational Research, 2025", "abstract": "\u2026 The prevalence of AI hallucination in general\u2010purpose **large** **language** **models** (LLMs) poses significant pedagogical challenges, particularly in terms of content credibility and reliability. In response, China has launched the development of education\u2010specific \u2026"}, {"title": "Text as data for **evaluation** : Natural language processing and **large language models** to generate novel insights from unstructured text data", "link": "https://journals.sagepub.com/doi/abs/10.1177/13563890251330911", "details": "T Wencker, J Borst-Graetz, A Niekler - **Evaluation** , 2025", "abstract": "\u2026 , a potential lack of accuracy, explainability, and transparency create ethical concerns and make it necessary to combine natural language processing and human judgment to avoid over-reliance on the capabilities of these methods and, in \u2026"}, {"title": "The Impact of Confidence Ratings on User Trust in **Large Language Models**", "link": "https://dl.acm.org/doi/pdf/10.1145/3708319.3734178", "details": "L Wang, N Friedman, C Zhu, Z Zhu, SJ Mountford - \u2026 of the 33rd ACM Conference on \u2026, 2025", "abstract": "\u2026 We **evaluated** both the confidence rating interface and standard chatbot interface across four key dimensions: trust, user confidence, task effectiveness, and interface usability. Our findings reveal initial trends in differences between the two conditions \u2026"}, {"title": "Simulating Human Opinions with **Large Language Models** : Opportunities and Challenges for Personalized Survey Data Modeling", "link": "https://dl.acm.org/doi/abs/10.1145/3708319.3733685", "details": "C Kaiser, J Kaiser, V Manewitsch, L Rau, R Schallner - Adjunct Proceedings of the \u2026, 2025", "abstract": "\u2026 Recent advances in **large** **language** **models** (LLMs) have sparked interest in generating synthetic survey data, ie, simulated answers \u2026 In this ongoing project, we develop and critically **evaluate** methods for synthetic survey sampling. As an \u2026"}, {"title": "A case study of forensic psychiatry experts' reports analysis through **large language models**", "link": "https://www.sciencedirect.com/science/article/pii/S016025272500055X", "details": "G Petroni, S Alaimo, G Mandarelli, R Catanesi, C Niolu\u2026 - International Journal of Law \u2026, 2025", "abstract": "The integration of artificial intelligence (AI) technologies in forensic psychiatry has gained significant attention due to their potential to enhance tasks such as outcome prediction and decision-making. In this study, we explored the feasibility and \u2026"}, {"title": "Assessing the Suitability of **Large Language Models** in Generating UML Class Diagrams as Conceptual Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-95397-2_13", "details": "M Calamo, M Mecella, M Snoeck - \u2026 Support, International Conference on **Evaluation** \u2026, 2025", "abstract": "\u2026 This work presented a comprehensive **evaluation** of **large** **language** **models** (LLMs) for the task of generating UML class diagrams from textual specifications. Our experiments revealed that the performance of LLMs is highly variable and strongly \u2026"}, {"title": "PHISHING EMAIL DETECTION USING **LARGE LANGUAGE MODELS** (LLMS): A PERFORMANCE **EVALUATION** OF QWEN AND GEMINI", "link": "https://ejournal.cahayailmubangsa.institute/index.php/kohesi/article/view/1867", "details": "AM Nabila, MSA Rahmatullah - Kohesi: Jurnal Sains dan Teknologi, 2025", "abstract": "\u2026 This study evaluates the zero-shot performance of **Large** **Language** **Models** (LLMs) \\- Gemini 2.5 Pro, Gemini 2.5 Flash, and Qwen 3 - in detecting phishing emails in an AIOps environment at Institut Teknologi Sepuluh Nopember (ITS). The findings show \u2026"}, {"title": "Empowering Recommender Systems based on **Large Language Models** through Knowledge Injection Techniques", "link": "https://dl.acm.org/doi/pdf/10.1145/3699682.3728341", "details": "A Petruzzelli, C Musto, M de Gemmis, G Semeraro\u2026 - Proceedings of the 33rd \u2026, 2025", "abstract": "\u2026 In this research line, [28] **evaluated** ChatGPT\u2019s performance on five recommendation tasks using various prompts.Similarly, [14] assessed ChatGPT\u2019s ability to generate recommendation candidates, demonstrating its efficacy across multiple tasks. Such \u2026"}, {"title": "Supporting User Information Processing Through **Large Language Models** Within the Political Sphere", "link": "https://dl.acm.org/doi/abs/10.1145/3699682.3727567", "details": "N Pate - Proceedings of the 33rd ACM Conference on User \u2026, 2025", "abstract": "How do we support information within the political domain? By incorporating personalization and guardrails, large language model (LLM) systems can be leveraged to support navigation through the information ecosystem. In this work, I \u2026"}]
