[{"title": "Navigating Fairness in AI-based Prediction Models: Theoretical Constructs and Practical Applications", "link": "https://www.medrxiv.org/content/medrxiv/early/2025/03/24/2025.03.24.25324500.full.pdf", "details": "SL van der Meijden, Y Wang, MS Arbous, BF Geerts\u2026 - medRxiv, 2025", "abstract": "Artificial Intelligence (AI)-based prediction models, including risk scoring systems and decision support systems, are increasingly adopted in healthcare. Addressing AI fairness is essential to fighting health disparities and achieving equitable \u2026"}, {"title": "Leveraging Large Language Models for Explainable Activity Recognition in Smart Homes: A Critical Evaluation", "link": "https://arxiv.org/pdf/2503.16622", "details": "M Fiori, G Civitarese, P Choudhary, C Bettini - arXiv preprint arXiv:2503.16622, 2025", "abstract": "Explainable Artificial Intelligence (XAI) aims to uncover the inner reasoning of machine learning models. In IoT systems, XAI improves the transparency of models processing sensor data from multiple heterogeneous devices, ensuring end-users \u2026"}, {"title": "Debiasing Multimodal Large Language Models via Noise-Aware Preference Optimization", "link": "https://arxiv.org/pdf/2503.17928", "details": "Z Zhang, H Tang, J Sheng, Z Zhang, Y Ren, Z Li, D Yin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multimodal Large Language Models excel in various tasks, yet often struggle with modality bias, where the model tends to rely heavily on a single modality and overlook critical information in other modalities, which leads to incorrect focus and \u2026"}, {"title": "CoMP: Continual Multimodal Pre-training for Vision Foundation Models", "link": "https://arxiv.org/pdf/2503.18931", "details": "Y Chen, L Meng, W Peng, Z Wu, YG Jiang - arXiv preprint arXiv:2503.18931, 2025", "abstract": "Pre-trained Vision Foundation Models (VFMs) provide strong visual representations for a wide range of applications. In this paper, we continually pre-train prevailing VFMs in a multimodal manner such that they can effortlessly process visual inputs of \u2026"}, {"title": "Does a Rising Tide Lift All Boats? Bias Mitigation for AI-based CMR Segmentation", "link": "https://arxiv.org/pdf/2503.17089", "details": "T Lee, E Puyol-Ant\u00f3n, B Ruijsink, M Shi, AP King - arXiv preprint arXiv:2503.17089, 2025", "abstract": "Artificial intelligence (AI) is increasingly being used for medical imaging tasks. However, there can be biases in the resulting models, particularly when they were trained using imbalanced training datasets. One such example has been the strong \u2026"}, {"title": "Safe RLHF-V: Safe Reinforcement Learning from Human Feedback in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2503.17682", "details": "J Ji, X Chen, R Pan, H Zhu, C Zhang, J Li, D Hong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multimodal large language models (MLLMs) are critical for developing general- purpose AI assistants, yet they face growing safety risks. How can we ensure that MLLMs are safely aligned to prevent undesired behaviors such as discrimination \u2026"}, {"title": "Exploring the Role of CLIP Global Visual Features in Multimodal Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10889200/", "details": "Z Bai, Y Bai - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "The next recognized development direction of large language models (LLMs) is to integrate and enhance multimodal capability. Although current multimodal large language models (MLLMs) have achieved impressive performance by combining the \u2026"}]
