[{"title": "A multimodal multidomain multilingual medical foundation model for zero shot clinical diagnosis", "link": "https://www.nature.com/articles/s41746-024-01339-7", "details": "F Liu, Z Li, Q Yin, J Huang, J Luo, A Thakur, K Branson\u2026 - npj Digital Medicine, 2025", "abstract": "Radiology images are one of the most commonly used in daily clinical diagnosis. Typically, clinical diagnosis using radiology images involves disease reporting and classification, where the former is a multimodal task whereby textual reports are \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "link": "https://arxiv.org/pdf/2502.05142", "details": "Z Yang, X Xu, J Zhang, G Wang, MK Kalra, P Yan - arXiv preprint arXiv:2502.05142, 2025", "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data \u2026"}, {"title": "Correlating and Predicting Human Evaluations of Language Models from Natural Language Processing Benchmarks", "link": "https://arxiv.org/pdf/2502.18339", "details": "R Schaeffer, PS Koura, B Tang, R Subramanian\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The explosion of high-performing conversational language models (LMs) has spurred a shift from classic natural language processing (NLP) benchmarks to expensive, time-consuming and noisy human evaluations-yet the relationship \u2026"}, {"title": "Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment", "link": "https://arxiv.org/pdf/2502.04328%3F", "details": "Z Liu, Y Dong, J Wang, Z Liu, W Hu, J Lu, Y Rao - arXiv preprint arXiv:2502.04328, 2025", "abstract": "Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have \u2026"}, {"title": "MedBot vs RealDoc: efficacy of large language modeling in physician-patient communication for rare diseases", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaf034/8042190", "details": "MT Weber, R Noll, A Marchl, C Facchinello\u2026 - Journal of the American \u2026, 2025", "abstract": "Objectives This study assesses the abilities of 2 large language models (LLMs), GPT- 4 and BioMistral 7B, in responding to patient queries, particularly concerning rare diseases, and compares their performance with that of physicians. Materials and \u2026"}, {"title": "Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective", "link": "https://arxiv.org/pdf/2502.01524%3F", "details": "X Ma, H Xie, SJ Qin - arXiv preprint arXiv:2502.01524, 2025", "abstract": "The integration of vision-language modalities has been a significant focus in multimodal learning, traditionally relying on Vision-Language Pretrained Models. However, with the advent of Large Language Models (LLMs), there has been a \u2026"}, {"title": "Supervised contrastive pre-training models for mammography screening", "link": "https://link.springer.com/article/10.1186/s40537-025-01075-z", "details": "Z Cao, Z Deng, Z Yang, J Ma, L Ma - Journal of Big Data, 2025", "abstract": "Breast cancer is now the most deadly cancer worldwide. Mammography screening is the most effective method for early detection and diagnosis of breast cancer. Due to the lack of labeled mammograms, building an AI system for mammography \u2026"}, {"title": "Comprehensive analysis of transparency and accessibility of chatgpt, deepseek, and other sota large language models", "link": "https://www.preprints.org/frontend/manuscript/1ed0ef5c816d69833a6b6a32ca2dd3bb/download_pub", "details": "R Sapkota, S Raza, M Karkee - Preprints. org DOI, 2025", "abstract": "Despite increasing discussions on open-source Artificial Intelligence (AI), existing research lacks a discussion on the transparency and accessibility of state-of-the-art (SoTA) Large Language Models (LLMs). The Open Source Initiative (OSI) has \u2026"}]
