[{"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "MILE: Memory-Interactive Learning Engine for Neuro-Symbolic Solutions to Mathematical Problems", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10680497.pdf", "details": "Y Wu, H Nakayama - IEEE Access, 2024", "abstract": "Mathematical problem solving is a task that examines the capacity of machine learning systems to perform quantitative and logical reasoning. Existing work employed formulas as intermediate labels in this task to implement a neuro-symbolic \u2026"}, {"title": "From Sparse Dependence to Sparse Attention: Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency", "link": "https://arxiv.org/pdf/2410.05459", "details": "K Wen, H Zhang, H Lin, J Zhang - arXiv preprint arXiv:2410.05459, 2024", "abstract": "Chain-of-thought (CoT) significantly enhances the reasoning performance of large language models (LLM). While current theoretical studies often attribute this improvement to increased expressiveness and computational capacity, we argue \u2026"}, {"title": "TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles", "link": "https://arxiv.org/pdf/2410.05262", "details": "Q Yu, S Song, K Fang, Y Shi, Z Zheng, H Wang, S Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the application of Large Language Models (LLMs) expands, the demand for reliable evaluations increases. Existing LLM evaluation benchmarks primarily rely on static datasets, making it challenging to assess model performance in dynamic \u2026"}, {"title": "Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2409.16635", "details": "S Park, D Choi - arXiv preprint arXiv:2409.16635, 2024", "abstract": "This paper proposes a novel prompt engineering technique called Judgment of Thought (JoT) that is specifically tailored for binary logical reasoning tasks. JoT employs three roles $\\unicode {x2014} $ lawyer, prosecutor, and judge $\\unicode \u2026"}, {"title": "Revisiting In-context Learning Inference Circuit in Large Language Models", "link": "https://arxiv.org/pdf/2410.04468", "details": "H Cho, M Kato, Y Sakai, N Inoue - arXiv preprint arXiv:2410.04468, 2024", "abstract": "In-context Learning (ICL) is an emerging few-shot learning paradigm on Language Models (LMs) with inner mechanisms un-explored. There are already existing works describing the inner processing of ICL, while they struggle to capture all the \u2026"}, {"title": "Instruction Following without Instruction Tuning", "link": "https://arxiv.org/pdf/2409.14254", "details": "J Hewitt, NF Liu, P Liang, CD Manning - arXiv preprint arXiv:2409.14254, 2024", "abstract": "Instruction tuning commonly means finetuning a language model on instruction- response pairs. We discover two forms of adaptation (tuning) that are deficient compared to instruction tuning, yet still yield instruction following; we call this implicit \u2026"}, {"title": "GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion", "link": "https://arxiv.org/pdf/2409.14051", "details": "T Liu, X Wang, W Huang, W Xu, Y Zeng, L Jiang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse NLP tasks. Extensive research has explored how to enhance the logical reasoning abilities such as Chain-of-Thought, Chain-of-Thought \u2026"}, {"title": "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models", "link": "https://arxiv.org/pdf/2409.18943", "details": "J Li, L Zhang, Y Li, Z Liu, R Luo, L Chen, M Yang - arXiv preprint arXiv:2409.18943, 2024", "abstract": "The instruction-following ability of large language models enables humans to interact with AI agents in a natural way. However, when required to generate responses of a specific length, large language models often struggle to meet users' needs due to \u2026"}]
