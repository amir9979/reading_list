[{"title": "Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks", "link": "https://arxiv.org/pdf/2407.20657", "details": "H Yang, J Jeong, KJ Yoon - arXiv preprint arXiv:2407.20657, 2024", "abstract": "Recent vision-language foundation models, such as CLIP, have demonstrated superior capabilities in learning representations that can be transferable across diverse range of downstream tasks and domains. With the emergence of such \u2026"}, {"title": "DDK: Distilling Domain Knowledge for Efficient Large Language Models", "link": "https://arxiv.org/pdf/2407.16154", "details": "J Liu, C Zhang, J Guo, Y Zhang, H Que, K Deng, Z Bai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the advanced intelligence abilities of large language models (LLMs) in various applications, they still face significant computational and storage demands. Knowledge Distillation (KD) has emerged as an effective strategy to improve the \u2026"}, {"title": "The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models", "link": "https://arxiv.org/pdf/2408.07702", "details": "K Maamari, F Abubaker, D Jaroslawicz, A Mhedhbi - arXiv preprint arXiv:2408.07702, 2024", "abstract": "Schema linking is a crucial step in Text-to-SQL pipelines, which translate natural language queries into SQL. The goal of schema linking is to retrieve relevant tables and columns (signal) while disregarding irrelevant ones (noise). However, imperfect \u2026"}, {"title": "Towards Medical Vision-Language Contrastive Pre-training via Study-Oriented Semantic Exploration", "link": "https://openreview.net/pdf%3Fid%3DVIPZtona4Q", "details": "LIU BO, LU ZEXIN, Y Wang - ACM Multimedia 2024", "abstract": "Contrastive vision-language pre-training has shown great promise in representation transfer learning and cross-modality learning in the medical field. However, without fully exploiting the intrinsic properties and correlations of multimodal medical data \u2026"}, {"title": "Large language models as reliable knowledge bases?", "link": "https://arxiv.org/pdf/2407.13578", "details": "D Zheng, M Lapata, JZ Pan - arXiv preprint arXiv:2407.13578, 2024", "abstract": "The NLP community has recently shown a growing interest in leveraging Large Language Models (LLMs) for knowledge-intensive tasks, viewing LLMs as potential knowledge bases (KBs). However, the reliability and extent to which LLMs can \u2026"}, {"title": "Personalized Federated Learning for Cross-City Traffic Prediction", "link": "https://www.ijcai.org/proceedings/2024/0611.pdf", "details": "Y Zhang, H Lu, N Liu, Y Xu, Q Li, L Cui", "abstract": "Traffic prediction plays an important role in urban computing. However, many cities face data scarcity due to low levels of urban development. Although many approaches transfer knowledge from data-rich cities to data-scarce cities, the \u2026"}, {"title": "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching", "link": "https://arxiv.org/pdf/2407.17349", "details": "Y Ding, H Hu, J Zhou, Q Chen, B Jiang, L He - arXiv preprint arXiv:2407.17349, 2024", "abstract": "With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem \u2026"}, {"title": "Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features", "link": "https://arxiv.org/pdf/2408.01394", "details": "M Bu, S Gu, Y Feng - arXiv preprint arXiv:2408.01394, 2024", "abstract": "The many-to-many multilingual neural machine translation can be regarded as the process of integrating semantic features from the source sentences and linguistic features from the target sentences. To enhance zero-shot translation, models need to \u2026"}, {"title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "link": "https://arxiv.org/pdf/2408.01380", "details": "P Mangal, C Mak, T Kanakis, T Donovan, D Braines\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence of Large Language Models (LLMs) have fundamentally altered the way we interact with digital systems and have led to the pursuit of LLM powered AI agents to assist in daily workflows. LLMs, whilst powerful and capable of \u2026"}]
