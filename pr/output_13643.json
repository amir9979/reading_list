[{"title": "A multimodal multidomain multilingual medical foundation model for zero shot clinical diagnosis", "link": "https://www.nature.com/articles/s41746-024-01339-7", "details": "F Liu, Z Li, Q Yin, J Huang, J Luo, A Thakur, K Branson\u2026 - npj Digital Medicine, 2025", "abstract": "Radiology images are one of the most commonly used in daily clinical diagnosis. Typically, clinical diagnosis using radiology images involves disease reporting and classification, where the former is a multimodal task whereby textual reports are \u2026"}, {"title": "Addressing Overprescribing Challenges: Fine-Tuning Large Language Models for Medication Recommendation Tasks", "link": "https://arxiv.org/pdf/2503.03687", "details": "Z Zhao, C Fan, C Gao, F Feng, X He - arXiv preprint arXiv:2503.03687, 2025", "abstract": "Medication recommendation systems have garnered attention within healthcare for their potential to deliver personalized and efficacious drug combinations based on patient's clinical data. However, existing methodologies encounter challenges in \u2026"}, {"title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "link": "https://arxiv.org/pdf/2502.05142", "details": "Z Yang, X Xu, J Zhang, G Wang, MK Kalra, P Yan - arXiv preprint arXiv:2502.05142, 2025", "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data \u2026"}, {"title": "BirdieDNA: Reward-Based Pre-Training for Genomic Sequence Modeling", "link": "https://openreview.net/pdf%3Fid%3DGg0850bgBy", "details": "S Blouir, D Circi, A Moldwin, A Shehu - ICLR 2025 Workshop on Machine Learning for \u2026", "abstract": "Transformer-based language models have shown promise in genomics but face challenges unique to DNA, such as sequence lengths spanning hundreds of millions of base pairs and subtle long-range dependencies. Although next-token prediction \u2026"}, {"title": "Improving Foundation Model for Endoscopy Video Analysis via Representation Learning on Long Sequences", "link": "https://ieeexplore.ieee.org/abstract/document/10885043/", "details": "Z Wang, C Liu, L Zhu, T Wang, S Zhang, Q Dou - IEEE Journal of Biomedical and \u2026, 2025", "abstract": "Recent advancements in endoscopy video analysis have relied on the utilization of relatively short video clips extracted from longer videos or millions of individual frames. However, these approaches tend to neglect the domain-specific \u2026"}, {"title": "Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment", "link": "https://arxiv.org/pdf/2502.04328%3F", "details": "Z Liu, Y Dong, J Wang, Z Liu, W Hu, J Lu, Y Rao - arXiv preprint arXiv:2502.04328, 2025", "abstract": "Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have \u2026"}, {"title": "MedBot vs RealDoc: efficacy of large language modeling in physician-patient communication for rare diseases", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaf034/8042190", "details": "MT Weber, R Noll, A Marchl, C Facchinello\u2026 - Journal of the American \u2026, 2025", "abstract": "Objectives This study assesses the abilities of 2 large language models (LLMs), GPT- 4 and BioMistral 7B, in responding to patient queries, particularly concerning rare diseases, and compares their performance with that of physicians. Materials and \u2026"}, {"title": "Comprehensive analysis of transparency and accessibility of chatgpt, deepseek, and other sota large language models", "link": "https://arxiv.org/pdf/2502.18505", "details": "R Sapkota, S Raza, M Karkee - arXiv preprint arXiv:2502.18505, 2025", "abstract": "Despite increasing discussions on open-source Artificial Intelligence (AI), existing research lacks a discussion on the transparency and accessibility of state-of-the-art (SoTA) Large Language Models (LLMs). The Open Source Initiative (OSI) has \u2026"}, {"title": "Semantic-aware contrastive learning via multi-prompt alignment", "link": "https://link.springer.com/article/10.1007/s10994-024-06665-1", "details": "Z Zhao, H Qin, M Kong, L Chen, D Xie, J Zhu, Q Zhu - Machine Learning, 2025", "abstract": "The role of the sample generation mechanism in contrastive learning is pivotal. It not only determines the pairings of positive and negative samples but also enriches the diversity of the sample pool, thereby substantially affecting the quality of the learned \u2026"}]
