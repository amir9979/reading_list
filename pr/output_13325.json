[{"title": "DuCo-Net: Dual-Contrastive Learning Network for Medical Report Retrieval Leveraging Enhanced Encoders and Augmentations", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10870249.pdf", "details": "ZU Rahman, JH Lee, DT Vu, I Murtza, JY Kim - IEEE Access, 2025", "abstract": "The conventional process of generating medical radiology reports is labor-intensive and time-consuming, requiring radiologists to describe findings meticulously from imaging studies. This manual approach often causes undesirable delays in patient \u2026"}, {"title": "Self-supervised analogical learning using language models", "link": "https://arxiv.org/pdf/2502.00996", "details": "B Zhou, S Jain, Y Zhang, Q Ning, S Wang, Y Benajiba\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models have been shown to suffer from reasoning inconsistency issues. That is, they fail more in situations unfamiliar to the training data, even though exact or very similar reasoning paths exist in more common cases that they can \u2026"}, {"title": "Language Models Prefer What They Know: Relative Confidence Estimation via Confidence Preferences", "link": "https://arxiv.org/pdf/2502.01126", "details": "V Shrivastava, A Kumar, P Liang - arXiv preprint arXiv:2502.01126, 2025", "abstract": "Language models (LMs) should provide reliable confidence estimates to help users detect mistakes in their outputs and defer to human experts when necessary. Asking a language model to assess its confidence (\" Score your confidence from 0-1.\") is a \u2026"}, {"title": "Graph Contrastive Learning for Fusion of Graph Structure and Attribute Information", "link": "https://ieeexplore.ieee.org/abstract/document/10902165/", "details": "Z Liang, L Bai, X Yang, J Liang - IEEE Transactions on Multimedia, 2025", "abstract": "Graph Contrastive Learning (GCL) plays a crucial role in multimedia applications due to its effectiveness in analyzing graph-structured data. Existing GCL methods focus on maximizing the agreement of node representations across different \u2026"}, {"title": "Denoising Multi-Level Cross-Attention and Contrastive Learning for Chest Radiology Report Generation", "link": "https://link.springer.com/article/10.1007/s10278-025-01422-9", "details": "D Zhu, L Liu, X Yang, L Liu, W Peng - Journal of Imaging Informatics in Medicine, 2025", "abstract": "Chest radiology report generation plays a vital role in supporting diagnosis, alleviating physician workload, and reducing the risk of misdiagnosis. However, significant challenges persist:(1) Data bias and background noise in chest images \u2026"}, {"title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra", "link": "https://arxiv.org/pdf/2502.16284", "details": "L Wang, S Liu, Y Rong, D Zhao, Q Liu, S Wu - arXiv preprint arXiv:2502.16284, 2025", "abstract": "Establishing the relationship between 3D structures and the energy states of molecular systems has proven to be a promising approach for learning 3D molecular representations. However, existing methods are limited to modeling the molecular \u2026"}, {"title": "Improving medical machine learning models with generative balancing for equity and excellence", "link": "https://www.nature.com/articles/s41746-025-01438-z", "details": "B Theodorou, B Danek, V Tummala, SP Kumar, B Malin\u2026 - npj Digital Medicine, 2025", "abstract": "Applying machine learning to clinical outcome prediction is challenging due to imbalanced datasets and sensitive tasks that contain rare yet critical outcomes and where equitable treatment across diverse patient groups is essential. Despite \u2026"}, {"title": "Advancing Vision-Language Models with Generative AI", "link": "https://www.preprints.org/frontend/manuscript/10b5ed95bd23954c58eef830d9d74bfa/download_pub", "details": "A Vats, R Raja - 2025", "abstract": "Generative AI within large vision-language models (LVLMs) has revolutionized multimodal learning, enabling machines to understand and generate visual content from textual descriptions with unprecedented accuracy. This paper explores state-of \u2026"}, {"title": "COSDA: Covariance regularized semantic data augmentation for self-supervised visual representation learning", "link": "https://www.sciencedirect.com/science/article/pii/S0950705125001273", "details": "H Chen, Y Ma, J Jiang, N Zheng - Knowledge-Based Systems, 2025", "abstract": "Recent contrastive learning-based self-supervised learning has seen significant improvements through employing an extensive data augmentation strategy, particularly focusing on the generation of positive pairs. However, the current \u2026"}]
