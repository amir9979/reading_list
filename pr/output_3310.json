[{"title": "DB-GPT-Hub: Towards Open Benchmarking Text-to-SQL Empowered by Large Language Models", "link": "https://arxiv.org/pdf/2406.11434", "details": "F Zhou, S Xue, D Qi, W Shi, W Zhao, G Wei, H Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) becomes the dominant paradigm for the challenging task of text-to-SQL. LLM-empowered text-to-SQL methods are typically categorized into prompting-based and tuning approaches. Compared to prompting-based \u2026"}, {"title": "Analyzing & Eliminating Learning Rate Warmup in GPT Pre-Training", "link": "https://openreview.net/pdf%3Fid%3DRveSp5oESA", "details": "A Kosson, B Messmer, M Jaggi - High-dimensional Learning Dynamics 2024: The \u2026", "abstract": "Learning Rate Warmup is a popular heuristic for training neural networks, which downscales early updates relative to later ones. This aids training, suggesting that the initial updates are too large in some sense, but* why and by which criteria \u2026"}, {"title": "MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction", "link": "https://arxiv.org/pdf/2406.12950", "details": "Y Liu, S Ding, S Zhou, W Fan, Q Tan - arXiv preprint arXiv:2406.12950, 2024", "abstract": "Molecular property prediction (MPP) is a fundamental and crucial task in drug discovery. However, prior methods are limited by the requirement for a large number of labeled molecules and their restricted ability to generalize for unseen and new \u2026"}]
