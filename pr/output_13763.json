[{"title": "Words or Vision: Do Vision-Language Models Have Blind Faith in Text?", "link": "https://arxiv.org/pdf/2503.02199", "details": "A Deng, T Cao, Z Chen, B Hooi - arXiv preprint arXiv:2503.02199, 2025", "abstract": "Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual \u2026"}, {"title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models", "link": "https://arxiv.org/pdf/2502.06663", "details": "X Xing, Z Liu, S Xiao, B Gao, Y Liang, W Zhang, H Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge \u2026"}, {"title": "MMSciBench: Benchmarking Language Models on Multimodal Scientific Problems", "link": "https://arxiv.org/pdf/2503.01891", "details": "X Ye, C Li, S Chen, X Tang, W Wei - arXiv preprint arXiv:2503.01891, 2025", "abstract": "Recent advances in large language models (LLMs) and vision-language models (LVLMs) have shown promise across many tasks, yet their scientific reasoning capabilities remain untested, particularly in multimodal settings. We present \u2026"}, {"title": "Multidimensional Consistency Improves Reasoning in Language Models", "link": "https://arxiv.org/pdf/2503.02670", "details": "H Lai, X Zhang, M Nissim - arXiv preprint arXiv:2503.02670, 2025", "abstract": "While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across \u2026"}, {"title": "Detecting LLM Fact-conflicting Hallucinations Enhanced by Temporal-logic-based Reasoning", "link": "https://arxiv.org/pdf/2502.13416", "details": "N Li, Y Song, K Wang, Y Li, L Shi, Y Liu, H Wang - arXiv preprint arXiv:2502.13416, 2025", "abstract": "Large language models (LLMs) face the challenge of hallucinations--outputs that seem coherent but are actually incorrect. A particularly damaging type is fact- conflicting hallucination (FCH), where generated content contradicts established \u2026"}, {"title": "SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models", "link": "https://arxiv.org/pdf/2502.09604", "details": "YS Chuang, B Cohen-Wang, SZ Shen, Z Wu, H Xu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses. Instead of only relying on costly and labor-intensive \u2026"}, {"title": "Self-Training Elicits Concise Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2502.20122", "details": "T Munkhbat, N Ho, S Kim, Y Yang, Y Kim, SY Yun - arXiv preprint arXiv:2502.20122, 2025", "abstract": "Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens \u2026"}, {"title": "Large Language Models as Attribution Regularizers for Efficient Model Training", "link": "https://arxiv.org/pdf/2502.20268", "details": "D Vukadin, M \u0160ili\u0107, G Dela\u010d - arXiv preprint arXiv:2502.20268, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains. However, effectively leveraging their vast knowledge for training smaller downstream models remains an open challenge, especially in domains like \u2026"}, {"title": "From Text to Trust: Empowering AI-assisted Decision Making with Adaptive LLM-powered Analysis", "link": "https://arxiv.org/pdf/2502.11919", "details": "Z Li, H Zhu, Z Lu, Z Xiao, M Yin - arXiv preprint arXiv:2502.11919, 2025", "abstract": "AI-assisted decision making becomes increasingly prevalent, yet individuals often fail to utilize AI-based decision aids appropriately especially when the AI explanations are absent, potentially as they do not% understand reflect on AI's \u2026"}]
