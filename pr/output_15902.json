[{"title": "GroundCocoa: A Benchmark for Evaluating Compositional & Conditional Reasoning in Language Models", "link": "https://aclanthology.org/2025.naacl-long.420.pdf", "details": "H Kohli, S Kumar, H Sun - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their reasoning to \u2026"}, {"title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models", "link": "https://arxiv.org/pdf/2504.05258%3F", "details": "A Bazaga, R Blloshmi, B Byrne, A de Gispert - arXiv preprint arXiv:2504.05258, 2025", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating coherent text, understanding context, and performing reasoning tasks. However, they struggle with temporal reasoning, which requires processing time-related information \u2026"}, {"title": "Atoxia: Red-teaming Large Language Models with Target Toxic Answers", "link": "https://aclanthology.org/2025.findings-naacl.179.pdf", "details": "Y Du, Z Li, P Cheng, X Wan, A Gao - Findings of the Association for Computational \u2026, 2025", "abstract": "Despite the substantial advancements in artificial intelligence, large language models (LLMs) remain being challenged by generation safety. With adversarial jailbreaking prompts, one can effortlessly induce LLMs to output harmful content \u2026"}, {"title": "Biases in Opinion Dynamics in Multi-Agent Systems of Large Language Models: A Case Study on Funding Allocation", "link": "https://aclanthology.org/2025.findings-naacl.101.pdf", "details": "P Cisneros-Velarde - Findings of the Association for Computational \u2026, 2025", "abstract": "We study the evolution of opinions inside a population of interacting large language models (LLMs). Every LLM needs to decide how much funding to allocate to an item with three initial possibilities: full, partial, or no funding. We identify biases that drive \u2026"}, {"title": "UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models", "link": "https://arxiv.org/pdf/2504.21027", "details": "Y Zheng, L Liu, Y Lin, J Feng, G Zhang, D Jin, Y Li - arXiv preprint arXiv:2504.21027, 2025", "abstract": "The advent of Large Language Models (LLMs) holds promise for revolutionizing various fields traditionally dominated by human expertise. Urban planning, a professional discipline that fundamentally shapes our daily surroundings, is one \u2026"}, {"title": "Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2504.21277", "details": "G Zhou, P Qiu, C Chen, J Wang, Z Yang, J Xu, M Qiu - arXiv preprint arXiv \u2026, 2025", "abstract": "The integration of reinforcement learning (RL) into the reasoning capabilities of Multimodal Large Language Models (MLLMs) has rapidly emerged as a transformative research direction. While MLLMs significantly extend Large Language \u2026"}, {"title": "TextArena", "link": "https://arxiv.org/pdf/2504.11442%3F", "details": "L Guertler, B Cheng, S Yu, B Liu, L Choshen, C Tan - arXiv preprint arXiv:2504.11442, 2025", "abstract": "TextArena is an open-source collection of competitive text-based games for training and evaluation of agentic behavior in Large Language Models (LLMs). It spans 57+ unique environments (including single-player, two-player, and multi-player setups) \u2026"}, {"title": "Forest for the Trees: Overarching Prompting Evokes High-Level Reasoning in Large Language Models", "link": "https://aclanthology.org/2025.naacl-long.66.pdf", "details": "H Liao, S Hu, Z Zhu, H He, Y Jin - Proceedings of the 2025 Conference of the Nations \u2026, 2025", "abstract": "Abstract Chain-of-thought (CoT) and subsequent methods adopted a deductive paradigm that decomposes the reasoning process, demonstrating remarkable performances across NLP tasks. However, such a paradigm faces the challenge of \u2026"}, {"title": "Option Symbol Matters: Investigating and Mitigating Multiple-Choice Option Symbol Bias of Large Language Models", "link": "https://aclanthology.org/2025.naacl-long.95.pdf", "details": "Z Yang, P Jian, C Li - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "Abstract Multiple-Choice Question Answering (MCQA) is a widely used task in the evaluation of Large Language Models (LLMs). In this work, we reveal that current LLMs' performance in MCQA could be heavily influenced by the choice of option \u2026"}]
