[{"title": "A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?", "link": "https://arxiv.org/pdf/2504.05227", "details": "J Silva-Rodr\u00edguez, J Dolz, IB Ayed - arXiv preprint arXiv:2504.05227, 2025", "abstract": "Vision-language pre-training has recently gained popularity as it allows learning rich feature representations using large-scale data sources. This paradigm has quickly made its way into the medical image analysis community. In particular, there is an \u2026"}, {"title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models", "link": "https://arxiv.org/pdf/2504.14194", "details": "X Zhuang, J Peng, R Ma, Y Wang, T Bai, X Wei, J Qiu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality, a critical driver of model performance. Current data selection methods, such as natural \u2026"}, {"title": "How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?", "link": "https://arxiv.org/pdf/2504.14391", "details": "R Thapa, A Li, Q Wu, B He, Y Sahashi, C Binder\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Publicly available biomedical videos, such as those on YouTube, serve as valuable educational resources for medical students. Unlike standard machine learning datasets, these videos are designed for human learners, often mixing medical \u2026"}, {"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}, {"title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions", "link": "https://arxiv.org/pdf/2504.05571", "details": "O Ovadia, M Brief, R Lemberg, E Sheetrit - arXiv preprint arXiv:2504.05571, 2025", "abstract": "While Large Language Models (LLMs) acquire vast knowledge during pre-training, they often lack domain-specific, new, or niche information. Continual pre-training (CPT) attempts to address this gap but suffers from catastrophic forgetting and \u2026"}, {"title": "Automated Radiology Report Labeling in Chest X-Ray Pathologies: Development and Evaluation of a Large Language Model Framework", "link": "https://medinform.jmir.org/2025/1/e68618/", "details": "A Abdullah, ST Kim - JMIR Medical Informatics, 2025", "abstract": "Background: Labeling unstructured radiology reports is crucial for creating structured datasets that facilitate downstream tasks, such as training large-scale medical imaging models. Current approaches typically rely on Bidirectional Encoder \u2026"}, {"title": "Achieving GPT-4o level performance in astronomy with a specialized 8B-parameter large language model", "link": "https://www.nature.com/articles/s41598-025-97131-y", "details": "T de Haan, YS Ting, T Ghosal, TD Nguyen\u2026 - Scientific Reports, 2025", "abstract": "Abstract AstroSage-Llama-3.1-8B is a domain-specialized natural-language AI assistant tailored for research in astronomy, astrophysics, cosmology, and astronomical instrumentation. Trained on the complete collection of astronomy \u2026"}, {"title": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "link": "https://arxiv.org/pdf/2504.07416%3F", "details": "J Park, S Kim, B Yoon, K Choi - arXiv preprint arXiv:2504.07416, 2025", "abstract": "Recent advancements in multi-modal models have significantly improved vision- language alignment in radiology. However, existing approaches struggle to effectively utilize complex radiology reports for learning, rely on low-resolution \u2026"}, {"title": "Foundation Model for Predicting Prognosis and Adjuvant Therapy Benefit From Digital Pathology in GI Cancers", "link": "https://ascopubs.org/doi/abs/10.1200/JCO-24-01501", "details": "X Wang, Y Jiang, S Yang, F Wang, X Zhang, W Wang\u2026 - Journal of Clinical Oncology, 2025", "abstract": "PURPOSE Artificial intelligence (AI) holds significant promise for improving cancer diagnosis and treatment. Here, we present a foundation AI model for prognosis prediction on the basis of standard hematoxylin and eosin\u2013stained histopathology \u2026"}]
