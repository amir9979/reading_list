[{"title": "Deliberative alignment: Reasoning enables safer language models", "link": "https://arxiv.org/pdf/2412.16339", "details": "MY Guan, M Joglekar, E Wallace, S Jain, B Barak\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large-scale language models increasingly impact safety-critical domains, ensuring their reliable adherence to well-defined principles remains a fundamental challenge. We introduce Deliberative Alignment, a new paradigm that directly \u2026"}, {"title": "DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators", "link": "https://arxiv.org/pdf/2412.02467%3F", "details": "T Afonja, HP Wang, R Kerkouche, M Fritz - arXiv preprint arXiv:2412.02467, 2024", "abstract": "Generating tabular data under differential privacy (DP) protection ensures theoretical privacy guarantees but poses challenges for training machine learning models, primarily due to the need to capture complex structures under noisy supervision \u2026"}, {"title": "Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over Aligned Large Language Models", "link": "https://arxiv.org/pdf/2412.12865", "details": "Y Fan, Y Hong, Q Wang, J Bao, H Jiang, Y Song - arXiv preprint arXiv:2412.12865, 2024", "abstract": "Alignment, endowing a pre-trained Large language model (LLM) with the ability to follow instructions, is crucial for its real-world applications. Conventional supervised fine-tuning (SFT) methods formalize it as causal language modeling typically with a \u2026"}, {"title": "Grounding Deliberate Reasoning in Multimodal Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-96-2061-6_2", "details": "J Chen, Y Liu, D Li, X An, W Deng, Z Feng, Y Zhao\u2026 - International Conference on \u2026, 2024", "abstract": "Abstract The rise of Multimodal Large Language Models, renowned for their advanced instruction-following and reasoning capabilities, has significantly propelled the field of visual reasoning. However, due to limitations in their image \u2026"}, {"title": "Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization", "link": "https://arxiv.org/pdf/2412.18279%3F", "details": "J Liu, C Wang, CY Liu, L Zeng, R Yan, Y Sun, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The role of reinforcement learning (RL) in enhancing the reasoning of large language models (LLMs) is becoming increasingly significant. Despite the success of RL in many scenarios, there are still many challenges in improving the reasoning of \u2026"}, {"title": "YuLan-Mini: An Open Data-efficient Language Model", "link": "https://arxiv.org/pdf/2412.17743", "details": "Y Hu, H Song, JW JiaDeng, JC KunZhou, JJ YutaoZhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Effective pre-training of large language models (LLMs) has been challenging due to the immense resource demands and the complexity of the technical processes involved. This paper presents a detailed technical report on YuLan-Mini, a highly \u2026"}, {"title": "Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models", "link": "https://arxiv.org/pdf/2412.19450", "details": "H Moon, J Seo, S Lee, C Park, H Lim - arXiv preprint arXiv:2412.19450, 2024", "abstract": "One of the key strengths of Large Language Models (LLMs) is their ability to interact with humans by generating appropriate responses to given instructions. This ability, known as instruction-following capability, has established a foundation for the use of \u2026"}, {"title": "Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation", "link": "https://arxiv.org/pdf/2412.18537%3F", "details": "DXX Li, Z Zhang, Z Lin, Z Zhu, Z Zheng, X Wu, X Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities, yet struggle with hallucination and outdated knowledge when tasked with complex knowledge reasoning, resulting in factually incorrect outputs. Previous studies have attempted to \u2026"}, {"title": "CL-attack: Textual Backdoor Attacks via Cross-Lingual Triggers", "link": "https://arxiv.org/pdf/2412.19037", "details": "J Zheng, T Hu, T Cong, X He - arXiv preprint arXiv:2412.19037, 2024", "abstract": "Backdoor attacks significantly compromise the security of large language models by triggering them to output specific and controlled content. Currently, triggers for textual backdoor attacks fall into two categories: fixed-token triggers and sentence-pattern \u2026"}]
