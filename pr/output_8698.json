[{"title": "Efficient scaling of bayesian neural networks", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10716370.pdf", "details": "JR Epifano, T Duong, RP Ramachandran, G Rasool - IEEE Access, 2024", "abstract": "While Bayesian neural networks (BNNs) have gained popularity for their theoretical guarantees and robustness, they have yet to see a convincing implementation at scale. This study investigates a variational inference-based neural architecture \u2026"}, {"title": "High-Fidelity Transfer of Functional Priors for Wide Bayesian Neural Networks by Learning Activations", "link": "https://arxiv.org/pdf/2410.15777", "details": "M Sendera, A Sorkhei, T Ku\u015bmierczyk - arXiv preprint arXiv:2410.15777, 2024", "abstract": "Function-space priors in Bayesian Neural Networks provide a more intuitive approach to embedding beliefs directly into the model's output, thereby enhancing regularization, uncertainty quantification, and risk-aware decision-making. However \u2026"}, {"title": "On the effectiveness of partially deterministic Bayesian neural networks", "link": "https://link.springer.com/article/10.1007/s00180-024-01561-7", "details": "D Andrade, K Sato - Computational Statistics, 2024", "abstract": "Bayesian neural networks (BNNs) with computationally expensive Hamiltonian Monte Carlo sampling methods are often considered to provide better predictive performance than the maximum a posterior (MAP) solution. Here, as an alternative to \u2026"}, {"title": "Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification", "link": "https://arxiv.org/pdf/2410.18686", "details": "X Tao, T Pan, M Cheng, Y Luo - arXiv preprint arXiv:2410.18686, 2024", "abstract": "Leveraging large language models (LLMs) has garnered increasing attention and introduced novel perspectives in time series classification. However, existing approaches often overlook the crucial dynamic temporal information inherent in time \u2026"}, {"title": "Enhancing Zero-Shot Vision Models by Label-Free Prompt Distribution Learning and Bias Correcting", "link": "https://arxiv.org/pdf/2410.19294", "details": "X Zhu, B Zhu, Y Tan, S Wang, Y Hao, H Zhang - arXiv preprint arXiv:2410.19294, 2024", "abstract": "Vision-language models, such as CLIP, have shown impressive generalization capacities when using appropriate text descriptions. While optimizing prompts on downstream labeled data has proven effective in improving performance, these \u2026"}, {"title": "Federated Heterogeneous Contrastive Distillation for Molecular Representation Learning", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679725", "details": "J Feng, Z Wang, Z Wei, Y Li, B Ding, H Xu - \u2026 of the 33rd ACM International Conference \u2026, 2024", "abstract": "With the increasing application of deep learning to solve scientific problems in biochemistry, molecular federated learning has become popular due to its ability to offer distributed privacy-preserving solutions. However, most existing molecular \u2026"}, {"title": "ContrastSense: Domain-invariant Contrastive Learning for In-the-wild Wearable Sensing", "link": "https://nmsl.kaist.ac.kr/pdf/IMWUT24_ContrastSense.pdf", "details": "G DAI, H XU, H YOON, MO LI, RUI TAN, SJU LEE - 2024", "abstract": "The increasing prevalence of wearable sensing devices, such as smartwatches, smart glasses, activity trackers, augmented/virtual reality headsets, etc., has facilitated the ubiquitous collection of human data, giving rise to numerous sensing \u2026"}, {"title": "Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Deep Learning", "link": "https://www.researchgate.net/profile/Damith-Ranasinghe/publication/382692068_Bayesian_Low-Rank_LeArning_Bella_A_Practical_Approach_to_Bayesian_Neural_Networks/links/66cff64df84dd1716c70168b/Bayesian-Low-Rank-LeArning-Bella-A-Practical-Approach-to-Bayesian-Neural-Networks.pdf", "details": "BG Doan, A Shamsi, XY Guo, A Mohammadi\u2026", "abstract": "Computational complexity of Bayesian learning is impeding its adoption in practical, large-scale tasks, despite demonstrations of significant merits such as improved robustness and resilience to unseen or out-of-distribution inputs over their non \u2026"}, {"title": "VPformer: Multivariate Time Series Forecasting with Variable Correlation and Triple Patch Correlation Transformer", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9434-8_13", "details": "Z Wang, Y Huang, C Zhao, C Zhou - \u2026 on Natural Language Processing and Chinese \u2026, 2024", "abstract": "Time series forecasting is vital in industries like weather and transportation. However, Transformer models may face challenges capturing both variable and temporal correlations in multivariate forecasting, potentially hindering their \u2026"}]
