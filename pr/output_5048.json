[{"title": "MindLLM: Lightweight large language model pre-training, evaluation and domain application", "link": "https://www.sciencedirect.com/science/article/pii/S2666651024000111", "details": "Y Yang, H Sun, J Li, R Liu, Y Li, Y Liu, Y Gao, H Huang - AI Open, 2024", "abstract": "Abstract Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is \u2026"}, {"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.02032", "details": "F Huo, W Xu, Z Zhang, H Wang, Z Chen, P Zhao - arXiv preprint arXiv:2408.02032, 2024", "abstract": "While Large Vision-Language Models (LVLMs) have rapidly advanced in recent years, the prevalent issue known as thehallucination'problem has emerged as a significant bottleneck, hindering their real-world deployments. Existing methods \u2026"}, {"title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability", "link": "https://arxiv.org/pdf/2407.19842", "details": "J Garc\u00eda-Carrasco, A Mat\u00e9, J Trujillo - arXiv preprint arXiv:2407.19842, 2024", "abstract": "Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the \u2026"}, {"title": "Improving Context-Aware Preference Modeling for Language Models", "link": "https://arxiv.org/pdf/2407.14916", "details": "S Pitis, Z Xiao, NL Roux, A Sordoni - arXiv preprint arXiv:2407.14916, 2024", "abstract": "While finetuning language models from pairwise preferences has proven remarkably effective, the underspecified nature of natural language presents critical challenges. Direct preference feedback is uninterpretable, difficult to provide where \u2026"}, {"title": "Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models", "link": "https://arxiv.org/pdf/2408.03907", "details": "SH Kumar, S Sahay, S Mazumder, E Okur\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have excelled at language understanding and generating human-level text. However, even with supervised training and human alignment, these LLMs are susceptible to adversarial attacks where malicious users \u2026"}, {"title": "Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation", "link": "https://arxiv.org/pdf/2408.00555", "details": "X Qu, Q Chen, W Wei, J Sun, J Dong - arXiv preprint arXiv:2408.00555, 2024", "abstract": "Despite the remarkable ability of large vision-language models (LVLMs) in image comprehension, these models frequently generate plausible yet factually incorrect responses, a phenomenon known as hallucination. Recently, in large language \u2026"}, {"title": "Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and Semantically-Rich Vision-Language Models", "link": "https://arxiv.org/pdf/2407.14971", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2407.14971, 2024", "abstract": "Vision-language models (VLMs) have achieved significant strides in recent times specially in multimodal tasks, yet they remain susceptible to adversarial attacks on their vision components. To address this, we propose Sim-CLIP, an unsupervised \u2026"}, {"title": "Is Child-Directed Speech Effective Training Data for Language Models?", "link": "https://arxiv.org/pdf/2408.03617", "details": "SY Feng, ND Goodman, MC Frank - arXiv preprint arXiv:2408.03617, 2024", "abstract": "While high-performing language models are typically trained on hundreds of billions of words, human children become fluent language users with a much smaller amount of data. What are the features of the data they receive, and how do these features \u2026"}]
