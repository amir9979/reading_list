[{"title": "CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning", "link": "https://arxiv.org/pdf/2407.21011", "details": "Y Du, B Chang, NC Dvornek - arXiv preprint arXiv:2407.21011, 2024", "abstract": "Recent advancements in Contrastive Language-Image Pre-training (CLIP) have demonstrated notable success in self-supervised representation learning across various tasks. However, the existing CLIP-like approaches often demand extensive \u2026"}, {"title": "Dataset Distillation for Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2407.20299", "details": "J Light, Y Liu, Z Hu - arXiv preprint arXiv:2407.20299, 2024", "abstract": "Offline reinforcement learning often requires a quality dataset that we can train a policy on. However, in many situations, it is not possible to get such a dataset, nor is it easy to train a policy to perform well in the actual environment given the offline \u2026"}, {"title": "Explainable and interpretable machine learning and data mining", "link": "https://link.springer.com/article/10.1007/s10618-024-01041-y", "details": "M Atzmueller, J F\u00fcrnkranz, T Kliegr, U Schmid - Data Mining and Knowledge \u2026, 2024", "abstract": "The growing number of applications of machine learning and data mining in many domains\u2014from agriculture to business, education, industrial manufacturing, and medicine\u2014gave rise to new requirements for how to inspect and control the learned \u2026"}, {"title": "LLMBox: A Comprehensive Library for Large Language Models", "link": "https://arxiv.org/pdf/2407.05563", "details": "T Tang, Y Hu, B Li, W Luo, Z Qin, H Sun, J Wang, S Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To facilitate the research on large language models (LLMs), this paper presents a comprehensive and unified library, LLMBox, to ease the development, use, and evaluation of LLMs. This library is featured with three main merits:(1) a unified data \u2026"}, {"title": "AI Safety in Generative AI Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2407.18369", "details": "J Chua, Y Li, S Yang, C Wang, L Yao - arXiv preprint arXiv:2407.18369, 2024", "abstract": "Large Language Model (LLMs) such as ChatGPT that exhibit generative AI capabilities are facing accelerated adoption and innovation. The increased presence of Generative AI (GAI) inevitably raises concerns about the risks and safety \u2026"}]
