[{"title": "A Bayesian Belief Network model for the estimation of risk of cardiovascular events in subjects with type 1 diabetes", "link": "https://www.sciencedirect.com/science/article/pii/S001048252500318X", "details": "O Moro, IT Gram, ML L\u00f8chen, MB Veier\u00f8d, AM W\u00e4gner\u2026 - Computers in Biology and \u2026, 2025", "abstract": "Abstract Objectives: Cardiovascular diseases (CVDs) represent a major risk for people with type 1 diabetes (T1D). Our aim here is to develop a new methodology that overcomes some of the problems and limitations of existing risk calculators. First \u2026"}, {"title": "DEEP LEARNING-BASED DIABETIC RETINOPATHY FOR CLASSIFYING RETINAL IMAGES", "link": "https://kitspress.com/journals/IJCBE/Currentissue/IJCBE_V01_02_64_70_25112023.pdf", "details": "J Jency, S Shunmugan", "abstract": "Diabetic retinopathy (DR) is a frequent eye disorder mostly affecting diabetics. It affects millions of individuals worldwide and is the leading cause of blindness and visual impairment in diabetics. DR occurs when excessive blood sugar levels \u2026"}, {"title": "Open-source framework for detecting bias and overfitting for large pathology images", "link": "https://arxiv.org/pdf/2503.01827%3F", "details": "A Sildnes, N Shvetsov, M Tafavvoghi, VNN Tran\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Even foundational models that are trained on datasets with billions of data samples may develop shortcuts that lead to overfitting and bias. Shortcuts are non-relevant patterns in data, such as the background color or color intensity. So, to ensure the \u2026"}, {"title": "A Robust Approach to Early Glaucoma Identification from Retinal Fundus Images using Dirichlet-based Weighted Average Ensemble and Bayesian Optimization", "link": "https://pubmed.ncbi.nlm.nih.gov/40017250/", "details": "M Mouhafid, Y Zhou, C Shan, Z Xiao - Current medical imaging", "abstract": "Objective Glaucoma is a leading cause of irreversible visual impairment and blindness worldwide, primarily linked to increased intraocular pressure (IOP). Early detection is essential to prevent further visual impairment, yet the manual diagnosis \u2026"}, {"title": "MedHEval: Benchmarking Hallucinations and Mitigation Strategies in Medical Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.02157", "details": "A Chang, L Huang, P Bhatia, T Kass-Hout, F Ma\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision Language Models (LVLMs) are becoming increasingly important in the medical domain, yet Medical LVLMs (Med-LVLMs) frequently generate hallucinations due to limited expertise and the complexity of medical applications \u2026"}, {"title": "CoCa-CXR: Contrastive Captioners Learn Strong Temporal Structures for Chest X-Ray Vision-Language Understanding", "link": "https://arxiv.org/pdf/2502.20509", "details": "Y Chen, S Xu, A Sellergren, Y Matias, A Hassidim\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models have proven to be of great benefit for medical image analysis since they learn rich semantics from both images and reports. Prior efforts have focused on better alignment of image and text representations to enhance \u2026"}, {"title": "LLaVA-RadZ: Can Multimodal Large Language Models Effectively Tackle Zero-shot Radiology Recognition?", "link": "https://arxiv.org/pdf/2503.07487", "details": "B Li, W Huang, Y Shen, Y Wang, S Lin, J Lin, L You\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, multimodal large models (MLLMs) have demonstrated exceptional capabilities in visual understanding and reasoning across various vision-language tasks. However, MLLMs usually perform poorly in zero-shot medical disease \u2026"}, {"title": "EyeBench: A Call for More Rigorous Evaluation of Retinal Image Enhancement", "link": "https://arxiv.org/pdf/2502.14260", "details": "W Zhu, X Dong, X Li, Y Xiong, X Chen, P Qiu, VK Vasa\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Over the past decade, generative models have achieved significant success in enhancement fundus images. However, the evaluation of these models still presents a considerable challenge. A comprehensive evaluation benchmark for fundus image \u2026"}, {"title": "Optimizing generative AI by backpropagating language model feedback", "link": "https://www.nature.com/articles/s41586-025-08661-4", "details": "M Yuksekgonul, F Bianchi, J Boen, S Liu, P Lu\u2026 - Nature, 2025", "abstract": "Recent breakthroughs in artificial intelligence (AI) are increasingly driven by systems orchestrating multiple large language models (LLMs) and other specialized tools, such as search engines and simulators. So far, these systems are primarily \u2026"}]
