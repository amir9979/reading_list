'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS By a'
[{"title": "Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo", "link": "https://arxiv.org/pdf/2404.17546", "details": "S Zhao, R Brekelmans, A Makhzani, R Grosse - arXiv preprint arXiv:2404.17546, 2024", "abstract": "Numerous capability and safety techniques of Large Language Models (LLMs), including RLHF, automated red-teaming, prompt engineering, and infilling, can be cast as sampling from an unnormalized target distribution defined by a given reward \u2026"}, {"title": "ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback", "link": "https://arxiv.org/pdf/2404.00934", "details": "Z Hou, Y Niu, Z Du, X Zhang, X Liu, A Zeng, Q Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "ChatGLM is a free-to-use AI service powered by the ChatGLM family of large language models (LLMs). In this paper, we present the ChatGLM-RLHF pipeline--a reinforcement learning from human feedback (RLHF) system--designed to enhance \u2026"}]
