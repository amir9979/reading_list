[{"title": "Choose Your Words Wisely: Domain-adaptive Masking Makes Language Models Learn Faster", "link": "https://aclanthology.org/2025.repl4nlp-1.6.pdf", "details": "VS Kohli, A Monis, R Mamidi - Proceedings of the 10th Workshop on Representation \u2026, 2025", "abstract": "Abstract Foundational Language Models perform significantly better on downstream tasks in specialised domains (such as law, computer science, and medical science) upon being further pre-trained on extensive domain-specific corpora, but this \u2026"}, {"title": "Instruction Fine-Tuning Guidance: How PEFT Methods Impact the Generation of Language Model via Different Attributions", "link": "https://link.springer.com/chapter/10.1007/978-981-96-5123-8_19", "details": "L Jiang, S Shi, C Yang - International Conference on Intelligent Multilingual \u2026, 2025", "abstract": "In this paper, we investigate the impact of different Parameter Efficient Fine-tuning (PEFT) methods on the generation performance of large language models, focusing on how different methods affect the model through various attributes. We evaluate \u2026"}, {"title": "Insightbuddy-ai: Medication extraction and entity linking using pre-trained language models and ensemble learning", "link": "https://aclanthology.org/2025.naacl-srw.2.pdf", "details": "P Romero, L Han, G Nenadic - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "This paper presents our system, InsightBuddy-AI, designed for extracting medication mentions and their associated attributes, and for linking these entities to established clinical terminology resources, including SNOMED-CT, the British National \u2026"}, {"title": "Knowledge-augmented Pre-trained Language Models for Biomedical Relation Extraction", "link": "https://arxiv.org/pdf/2505.00814", "details": "M S\u00e4nger, U Leser - arXiv preprint arXiv:2505.00814, 2025", "abstract": "Automatic relationship extraction (RE) from biomedical literature is critical for managing the vast amount of scientific knowledge produced each year. In recent years, utilizing pre-trained language models (PLMs) has become the prevalent \u2026", "entry_id": "http://arxiv.org/abs/2505.00814v1", "updated": "2025-05-01 19:16:18", "published": "2025-05-01 19:16:18", "authors": "Mario S\u00e4nger;Ulf Leser", "summary": "Automatic relationship extraction (RE) from biomedical literature is critical\nfor managing the vast amount of scientific knowledge produced each year. In\nrecent years, utilizing pre-trained language models (PLMs) has become the\nprevalent approach in RE. Several studies report improved performance when\nincorporating additional context information while fine-tuning PLMs for RE.\nHowever, variations in the PLMs applied, the databases used for augmentation,\nhyper-parameter optimization, and evaluation methods complicate direct\ncomparisons between studies and raise questions about the generalizability of\nthese findings. Our study addresses this research gap by evaluating PLMs\nenhanced with contextual information on five datasets spanning four relation\nscenarios within a consistent evaluation framework. We evaluate three baseline\nPLMs and first conduct extensive hyperparameter optimization. After selecting\nthe top-performing model, we enhance it with additional data, including textual\nentity descriptions, relational information from knowledge graphs, and\nmolecular structure encodings. Our findings illustrate the importance of i) the\nchoice of the underlying language model and ii) a comprehensive hyperparameter\noptimization for achieving strong extraction performance. Although inclusion of\ncontext information yield only minor overall improvements, an ablation study\nreveals substantial benefits for smaller PLMs when such external data was\nincluded during fine-tuning.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.00814v1;http://arxiv.org/pdf/2505.00814v1", "pdf_url": "http://arxiv.org/pdf/2505.00814v1"}, {"title": "Developing safe and responsible large language model: can we balance bias reduction and language understanding?", "link": "https://link.springer.com/article/10.1007/s10994-025-06767-4", "details": "S Raza, O Bamgbose, S Ghuge, F Tavakoli, DJ Reji\u2026 - Machine Learning, 2025", "abstract": "Abstract Large Language Models (LLMs) have advanced various Natural Language Processing (NLP) tasks, such as text generation and translation, among others. However, these models often generate texts that can perpetuate biases. Existing \u2026"}, {"title": "Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering", "link": "https://arxiv.org/pdf/2505.15038", "details": "H Zhao, X Wu, F Yang, B Shen, N Liu, M Du - arXiv preprint arXiv:2505.15038, 2025", "abstract": "Linear Concept Vectors have proven effective for steering large language models (LLMs). While existing approaches like linear probing and difference-in-means derive these vectors from LLM hidden representations, diverse data introduces \u2026", "entry_id": "http://arxiv.org/abs/2505.15038v1", "updated": "2025-05-21 02:45:11", "published": "2025-05-21 02:45:11", "authors": "Haiyan Zhao;Xuansheng Wu;Fan Yang;Bo Shen;Ninghao Liu;Mengnan Du", "summary": "Linear Concept Vectors have proven effective for steering large language\nmodels (LLMs). While existing approaches like linear probing and\ndifference-in-means derive these vectors from LLM hidden representations,\ndiverse data introduces noises (i.e., irrelevant features) that challenge\nsteering robustness. To address this, we propose Sparse Autoencoder-Denoised\nConcept Vectors (SDCV), which uses Sparse Autoencoders to filter out noisy\nfeatures from hidden representations. When applied to linear probing and\ndifference-in-means, our method improves their steering success rates. We\nvalidate our noise hypothesis through counterfactual experiments and feature\nvisualizations.", "comment": "12 pages, 5 figures, 3 tables", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2505.15038v1;http://arxiv.org/pdf/2505.15038v1", "pdf_url": "http://arxiv.org/pdf/2505.15038v1"}, {"title": "Diagnosing our datasets: How does my language model learn clinical information?", "link": "https://arxiv.org/pdf/2505.15024", "details": "F Jia, D Sontag, M Agrawal - arXiv preprint arXiv:2505.15024, 2025", "abstract": "Large language models (LLMs) have performed well across various clinical natural language processing tasks, despite not being directly trained on electronic health record (EHR) data. In this work, we examine how popular open-source LLMs learn \u2026", "entry_id": "http://arxiv.org/abs/2505.15024v1", "updated": "2025-05-21 02:13:24", "published": "2025-05-21 02:13:24", "authors": "Furong Jia;David Sontag;Monica Agrawal", "summary": "Large language models (LLMs) have performed well across various clinical\nnatural language processing tasks, despite not being directly trained on\nelectronic health record (EHR) data. In this work, we examine how popular\nopen-source LLMs learn clinical information from large mined corpora through\ntwo crucial but understudied lenses: (1) their interpretation of clinical\njargon, a foundational ability for understanding real-world clinical notes, and\n(2) their responses to unsupported medical claims. For both use cases, we\ninvestigate the frequency of relevant clinical information in their\ncorresponding pretraining corpora, the relationship between pretraining data\ncomposition and model outputs, and the sources underlying this data. To isolate\nclinical jargon understanding, we evaluate LLMs on a new dataset MedLingo.\nUnsurprisingly, we find that the frequency of clinical jargon mentions across\nmajor pretraining corpora correlates with model performance. However, jargon\nfrequently appearing in clinical notes often rarely appears in pretraining\ncorpora, revealing a mismatch between available data and real-world usage.\nSimilarly, we find that a non-negligible portion of documents support disputed\nclaims that can then be parroted by models. Finally, we classified and analyzed\nthe types of online sources in which clinical jargon and unsupported medical\nclaims appear, with implications for future dataset composition.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.15024v1;http://arxiv.org/pdf/2505.15024v1", "pdf_url": "http://arxiv.org/pdf/2505.15024v1"}, {"title": "MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models", "link": "https://arxiv.org/pdf/2505.11613", "details": "X Li, M Gao, Y Hao, T Li, G Wan, Z Wang, Y Wang - arXiv preprint arXiv:2505.11613, 2025", "abstract": "Clinical guidelines, typically structured as decision trees, are central to evidence- based medical practice and critical for ensuring safe and accurate diagnostic decision-making. However, it remains unclear whether Large Language Models \u2026", "entry_id": "http://arxiv.org/abs/2505.11613v1", "updated": "2025-05-16 18:21:52", "published": "2025-05-16 18:21:52", "authors": "Xiaomin Li;Mingye Gao;Yuexing Hao;Taoran Li;Guangya Wan;Zihan Wang;Yijun Wang", "summary": "Clinical guidelines, typically structured as decision trees, are central to\nevidence-based medical practice and critical for ensuring safe and accurate\ndiagnostic decision-making. However, it remains unclear whether Large Language\nModels (LLMs) can reliably follow such structured protocols. In this work, we\nintroduce MedGUIDE, a new benchmark for evaluating LLMs on their ability to\nmake guideline-consistent clinical decisions. MedGUIDE is constructed from 55\ncurated NCCN decision trees across 17 cancer types and uses clinical scenarios\ngenerated by LLMs to create a large pool of multiple-choice diagnostic\nquestions. We apply a two-stage quality selection process, combining\nexpert-labeled reward models and LLM-as-a-judge ensembles across ten clinical\nand linguistic criteria, to select 7,747 high-quality samples. We evaluate 25\nLLMs spanning general-purpose, open-source, and medically specialized models,\nand find that even domain-specific LLMs often underperform on tasks requiring\nstructured guideline adherence. We also test whether performance can be\nimproved via in-context guideline inclusion or continued pretraining. Our\nfindings underscore the importance of MedGUIDE in assessing whether LLMs can\noperate safely within the procedural frameworks expected in real-world clinical\nsettings.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.11613v1;http://arxiv.org/pdf/2505.11613v1", "pdf_url": "http://arxiv.org/pdf/2505.11613v1"}, {"title": "Model Merging in Pre-training of Large Language Models", "link": "https://arxiv.org/pdf/2505.12082", "details": "Y Li, Y Ma, S Yan, C Zhang, J Liu, J Lu, Z Xu, M Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Model merging has emerged as a promising technique for enhancing large language models, though its application in large-scale pre-training remains relatively unexplored. In this paper, we present a comprehensive investigation of model \u2026", "entry_id": "http://arxiv.org/abs/2505.12082v3", "updated": "2025-05-22 09:35:43", "published": "2025-05-17 16:53:14", "authors": "Yunshui Li;Yiyuan Ma;Shen Yan;Chaoyi Zhang;Jing Liu;Jianqiao Lu;Ziwen Xu;Mengzhao Chen;Minrui Wang;Shiyi Zhan;Jin Ma;Xunhao Lai;Deyi Liu;Yao Luo;Xingyan Bin;Hongbin Ren;Mingji Han;Wenhao Hao;Bairen Yi;LingJun Liu;Bole Ma;Xiaoying Jia;Xun Zhou;Siyuan Qiao;Liang Xiang;Yonghui Wu", "summary": "Model merging has emerged as a promising technique for enhancing large\nlanguage models, though its application in large-scale pre-training remains\nrelatively unexplored. In this paper, we present a comprehensive investigation\nof model merging techniques during the pre-training process. Through extensive\nexperiments with both dense and Mixture-of-Experts (MoE) architectures ranging\nfrom millions to over 100 billion parameters, we demonstrate that merging\ncheckpoints trained with constant learning rates not only achieves significant\nperformance improvements but also enables accurate prediction of annealing\nbehavior. These improvements lead to both more efficient model development and\nsignificantly lower training costs. Our detailed ablation studies on merging\nstrategies and hyperparameters provide new insights into the underlying\nmechanisms while uncovering novel applications. Through comprehensive\nexperimental analysis, we offer the open-source community practical\npre-training guidelines for effective model merging.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.LG", "links": "http://arxiv.org/abs/2505.12082v3;http://arxiv.org/pdf/2505.12082v3", "pdf_url": "http://arxiv.org/pdf/2505.12082v3"}]
