[{"title": "Building trustworthy AI: transparent AI systems via language models, ontologies, and logical reasoning (TranspNet)", "link": "https://link.springer.com/chapter/10.1007/978-3-031-89274-5_3", "details": "F Al Machot, MT Horsch, H Ullah - Designing the Conceptual Landscape for a XAIR \u2026, 2025", "abstract": "Growing concerns over the lack of transparency in AI, particularly in high-stakes fields like healthcare and finance, drive the need for explainable and trustworthy systems. While Large Language Models (LLMs) perform exceptionally well in \u2026"}, {"title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records", "link": "https://arxiv.org/pdf/2505.09435", "details": "Y He, Y Zhu, P Fu, R Yang, T Chen, Z Wang, Q Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Pre-training on image-text colonoscopy records offers substantial potential for improving endoscopic image analysis, but faces challenges including non- informative background images, complex medical terminology, and ambiguous multi \u2026"}, {"title": "CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training", "link": "https://arxiv.org/pdf/2504.13161", "details": "S Diao, Y Yang, Y Fu, X Dong, D Su, M Kliegl, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Pre-training datasets are typically collected from web content and lack inherent domain divisions. For instance, widely used datasets like Common Crawl do not include explicit domain labels, while manually curating labeled datasets such as The \u2026"}, {"title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2505.08971", "details": "Y Chen, H Peng, T Zhang, H Ji - arXiv preprint arXiv:2505.08971, 2025", "abstract": "In standard large vision-language models (LVLMs) pre-training, the model typically maximizes the joint probability of the caption conditioned on the image via next-token prediction (NTP); however, since only a small subset of caption tokens directly \u2026"}, {"title": "Explainable Hallucination Mitigation in Large Language Models: A Survey", "link": "https://www.preprints.org/frontend/manuscript/db02d598971cf15910b6ff42e1227ce1/download_pub", "details": "W Deng, J Li, HY Zhang, J Li, Z Deng, D Cheng, Z Feng - 2025", "abstract": "Hallucinations in large language models (LLMs) pose significant challenges to their reliability, especially in knowledge-intensive and reasoning-oriented tasks. While existing efforts have focused on detecting or correcting such errors, they often lack a \u2026"}, {"title": "KnowEEG: Explainable Knowledge Driven EEG Classification", "link": "https://arxiv.org/pdf/2505.00541", "details": "A Sahota, NM Foumani, R Santos-Rodriguez\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Electroencephalography (EEG) is a method of recording brain activity that shows significant promise in applications ranging from disease classification to emotion detection and brain-computer interfaces. Recent advances in deep learning have \u2026"}]
