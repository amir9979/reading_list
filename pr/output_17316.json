[{"title": "Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems", "link": "https://arxiv.org/pdf/2506.03259", "details": "ME Garcia-Alcoser, M GhojoghNejad, FI Tushar, D Kim\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Purpose: This study aims to evaluate the effectiveness of large language models (LLMs) in automating disease annotation of CT radiology reports. We compare a rule- based algorithm (RBA), RadBERT, and three lightweight open-weight LLMs for multi \u2026", "entry_id": "http://arxiv.org/abs/2506.03259v1", "updated": "2025-06-03 18:00:08", "published": "2025-06-03 18:00:08", "authors": "Michael E. Garcia-Alcoser;Mobina GhojoghNejad;Fakrul Islam Tushar;David Kim;Kyle J. Lafata;Geoffrey D. Rubin;Joseph Y. Lo", "summary": "Purpose: This study aims to evaluate the effectiveness of large language\nmodels (LLMs) in automating disease annotation of CT radiology reports. We\ncompare a rule-based algorithm (RBA), RadBERT, and three lightweight\nopen-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP)\nCT reports.\n  Materials and Methods: This retrospective study analyzed 40,833 CT reports\nfrom 29,540 patients, with 1,789 CAP reports manually annotated across three\norgan systems. External validation was conducted using the CT-RATE dataset.\nThree open-weight LLMs were tested with zero-shot prompting. Performance was\nevaluated using Cohen's Kappa and micro/macro-averaged F1 scores.\n  Results: In 12,197 Duke CAP reports from 8,854 patients, Llama-3.1 8B and\nGemma-3 27B showed the highest agreement ($\\kappa$ median: 0.87). On the\nmanually annotated set, Gemma-3 27B achieved the top macro-F1 (0.82), followed\nby Llama-3.1 8B (0.79), while the RBA scored lowest (0.64). On the CT-RATE\ndataset (lungs/pleura only), Llama-3.1 8B performed best (0.91), with Gemma-3\n27B close behind (0.89). Performance differences were mainly due to differing\nlabeling practices, especially for lung atelectasis.\n  Conclusion: Lightweight LLMs outperform rule-based methods for CT report\nannotation and generalize across organ systems with zero-shot prompting.\nHowever, binary labels alone cannot capture the full nuance of report language.\nLLMs can provide a flexible, efficient solution aligned with clinical judgment\nand user needs.", "comment": "23 pages, 10 figures, to be submitted in Radiology: Artificial\n  Intelligence", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;I.2.7", "links": "http://arxiv.org/abs/2506.03259v1;http://arxiv.org/pdf/2506.03259v1", "pdf_url": "http://arxiv.org/pdf/2506.03259v1"}]
