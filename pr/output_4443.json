[{"title": "Accurate diagnosis achieved via super-resolution whole slide images by pathologists and artificial intelligence", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/07/07/2024.07.05.24310022.full.pdf", "details": "kuansong wang, R LIU, Y chen, ying wang, yanning qiu\u2026 - medRxiv, 2024", "abstract": "Background: Digital pathology significantly improves diagnostic efficiency and accuracy; however, pathological tissue sections are scanned at high resolutions (HR), magnified by 40 times (40X) incurring high data volume, leading to storage \u2026"}, {"title": "Detection of pulmonary nodules in chest radiographs: novel cost function for effective network training with purely synthesized datasets", "link": "https://link.springer.com/article/10.1007/s11548-024-03227-7", "details": "S Hanaoka, Y Nomura, T Yoshikawa, T Nakao\u2026 - International Journal of \u2026, 2024", "abstract": "Purpose Many large radiographic datasets of lung nodules are available, but the small and hard-to-detect nodules are rarely validated by computed tomography. Such difficult nodules are crucial for training nodule detection methods. This lack of \u2026"}, {"title": "AutoTutor meets Large Language Models: A Language Model Tutor with Rich Pedagogy and Guardrails", "link": "https://dl.acm.org/doi/abs/10.1145/3657604.3662041", "details": "S Pal Chowdhury, V Zouhar, M Sachan - \u2026 of the Eleventh ACM Conference on \u2026, 2024", "abstract": "Large Language Models (LLMs) have found several use cases in education, ranging from automatic question generation to essay evaluation. In this paper, we explore the potential of using LLMs to author Intelligent Tutoring Systems. A common pitfall of \u2026"}, {"title": "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models", "link": "https://arxiv.org/pdf/2407.05131", "details": "P Xia, K Zhu, H Li, H Zhu, Y Li, G Li, L Zhang, H Yao - arXiv preprint arXiv:2407.05131, 2024", "abstract": "The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has enhanced medical diagnosis. However, current Med-LVLMs frequently encounter factual issues, often generating responses that do not align with established medical \u2026"}, {"title": "The TRIPOD-LLM Statement: A Targeted Guideline For Reporting Large Language Models Use", "link": "https://www.medrxiv.org/content/10.1101/2024.07.24.24310930.full.pdf", "details": "J Gallifant, M Afshar, S Ameen, Y Aphinyanaphongs\u2026 - medRxiv, 2024", "abstract": "Large Language Models (LLMs) are rapidly being adopted in healthcare, necessitating standardized reporting guidelines. We present TRIPOD-LLM, an extension of the TRIPOD+ AI statement, addressing the unique challenges of LLMs \u2026"}, {"title": "The Art of Saying No: Contextual Noncompliance in Language Models", "link": "https://arxiv.org/pdf/2407.12043", "details": "F Brahman, S Kumar, V Balachandran, P Dasigi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Chat-based language models are designed to be helpful, yet they should not comply with every user request. While most existing work primarily focuses on refusal of\" unsafe\" queries, we posit that the scope of noncompliance should be broadened. We \u2026"}, {"title": "SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training", "link": "https://arxiv.org/pdf/2407.06654", "details": "N He, W Xiong, H Liu, Y Liao, L Ding, K Zhang, G Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The effectiveness of large language models (LLMs) is often hindered by duplicated data in their extensive pre-training datasets. Current approaches primarily focus on detecting and removing duplicates, which risks the loss of valuable information and \u2026"}]
