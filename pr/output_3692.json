[{"title": "Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian", "link": "https://arxiv.org/pdf/2407.06011", "details": "TM Buonocore, S Rancati, E Parimbelli - arXiv preprint arXiv:2407.06011, 2024", "abstract": "The development of domain-specific language models has significantly advanced natural language processing applications in various specialized fields, particularly in biomedicine. However, the focus has largely been on English-language models \u2026"}, {"title": "Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations", "link": "https://arxiv.org/pdf/2407.05690", "details": "B Shen, Z Lin, D Zha, W Liu, J Luan, B Wang, W Wang - arXiv preprint arXiv \u2026, 2024", "abstract": "Structured pruning fundamentally reduces computational and memory overheads of large language models (LLMs) and offers a feasible solution for end-side LLM deployment. Structurally pruned models remain dense and high-precision, highly \u2026"}, {"title": "EM_Mixers at MEDIQA-CORR 2024: Knowledge-Enhanced Few-Shot In-Context Learning for Medical Error Detection and Correction", "link": "https://aclanthology.org/2024.clinicalnlp-1.56.pdf", "details": "S Rajwal, E Agichtein, A Sarker - Proceedings of the 6th Clinical Natural Language \u2026, 2024", "abstract": "This paper describes our submission to MEDIQA-CORR 2024 shared task for automatic identification and correction of medical errors in a given clinical text. We report results from two approaches: the first uses a few-shot in-context learning (ICL) \u2026"}, {"title": "Residual-based Language Models are Free Boosters for Biomedical Imaging Tasks", "link": "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Lai_Residual-based_Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks_CVPRW_2024_paper.pdf", "details": "Z Lai, J Wu, S Chen, Y Zhou, N Hovakimyan - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "In this study we uncover the unexpected efficacy of residual-based large language models (LLMs) as part of encoders for biomedical imaging tasks a domain traditionally devoid of language or textual data. The approach diverges from \u2026"}, {"title": "Advancing Faithfulness of Large Language Models in Goal-Oriented Dialogue Question Answering", "link": "https://dl.acm.org/doi/abs/10.1145/3640794.3665573", "details": "A Sticha, N Braunschweiler, RS Doddipatla, KM Knill - \u2026 of the 6th ACM Conference on \u2026, 2024", "abstract": "Goal-oriented dialogue systems, such as assistant chatbots and conversational AI systems, have gained prominence for their question-answering capabilities, often utilizing large language models (LLMs) as knowledge bases. However, these \u2026"}, {"title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought", "link": "https://arxiv.org/pdf/2406.13940", "details": "Y Zhang, Q Chen, M Li, W Che, L Qin - arXiv preprint arXiv:2406.13940, 2024", "abstract": "Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention. Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning \u2026"}, {"title": "Attribute Prototype-guided Iterative Scene Graph for Explainable Radiology Report Generation", "link": "https://ieeexplore.ieee.org/abstract/document/10587279/", "details": "K Zhang, Y Yang, J Yu, J Fan, H Jiang, Q Huang\u2026 - IEEE Transactions on \u2026, 2024", "abstract": "The potential of automated radiology report generation in alleviating the time- consuming tasks of radiologists is increasingly being recognized in medical practice. Existing report generation methods have evolved from using image-level features to \u2026"}]
