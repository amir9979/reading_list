[{"title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models", "link": "https://arxiv.org/pdf/2406.02224", "details": "T Fan, G Ma, Y Kang, H Gu, L Fan, Q Yang - arXiv preprint arXiv:2406.02224, 2024", "abstract": "Recent research in federated large language models (LLMs) has primarily focused on enabling clients to fine-tune their locally deployed homogeneous LLMs collaboratively or on transferring knowledge from server-based LLMs to small \u2026"}, {"title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment", "link": "https://arxiv.org/pdf/2405.19332", "details": "S Zhang, D Yu, H Sharma, Z Yang, S Wang, H Hassan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed \u2026"}, {"title": "Advancing DNA Language Models through Motif-Oriented Pre-Training with MoDNA", "link": "https://www.mdpi.com/2673-7426/4/2/85", "details": "W An, Y Guo, Y Bian, H Ma, J Yang, C Li, J Huang - BioMedInformatics, 2024", "abstract": "Acquiring meaningful representations of gene expression is essential for the accurate prediction of downstream regulatory tasks, such as identifying promoters and transcription factor binding sites. However, the current dependency on \u2026"}, {"title": "Explainable Graph Neural Networks Under Fire", "link": "https://arxiv.org/pdf/2406.06417", "details": "Z Li, S Geisler, Y Wang, S G\u00fcnnemann\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Predictions made by graph neural networks (GNNs) usually lack interpretability due to their complex computational behavior and the abstract nature of graphs. In an attempt to tackle this, many GNN explanation methods have emerged. Their goal is \u2026"}, {"title": "Few-Shot Learning for Medical Image Segmentation Using 3D U-Net and Model-Agnostic Meta-Learning (MAML)", "link": "https://www.mdpi.com/2075-4418/14/12/1213", "details": "AM Alsaleh, E Albalawi, A Algosaibi, SS Albakheet\u2026 - Diagnostics, 2024", "abstract": "Deep learning has attained state-of-the-art results in general image segmentation problems; however, it requires a substantial number of annotated images to achieve the desired outcomes. In the medical field, the availability of annotated images is \u2026"}, {"title": "Multi-Agent Transfer Learning via Temporal Contrastive Learning", "link": "https://arxiv.org/pdf/2406.01377", "details": "W Zeng, J Campbell, S Stepputtis, K Sycara - arXiv preprint arXiv:2406.01377, 2024", "abstract": "This paper introduces a novel transfer learning framework for deep multi-agent reinforcement learning. The approach automatically combines goal-conditioned policies with temporal contrastive learning to discover meaningful sub-goals. The \u2026"}, {"title": "Exploring Adversarial Robustness of Deep State Space Models", "link": "https://arxiv.org/pdf/2406.05532", "details": "B Qi, Y Luo, J Gao, P Li, K Tian, Z Ma, B Zhou - arXiv preprint arXiv:2406.05532, 2024", "abstract": "Deep State Space Models (SSMs) have proven effective in numerous task scenarios but face significant security challenges due to Adversarial Perturbations (APs) in real- world deployments. Adversarial Training (AT) is a mainstream approach to \u2026"}, {"title": "Probabilistic Perspectives on Error Minimization in Adversarial Reinforcement Learning", "link": "https://arxiv.org/pdf/2406.04724", "details": "R Belaire, A Sinha, P Varakantham - arXiv preprint arXiv:2406.04724, 2024", "abstract": "Deep Reinforcement Learning (DRL) policies are critically vulnerable to adversarial noise in observations, posing severe risks in safety-critical scenarios. For example, a self-driving car receiving manipulated sensory inputs about traffic signs could lead to \u2026"}, {"title": "Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning", "link": "https://openreview.net/pdf%3Fid%3DXwnABAdH5y", "details": "Z Zhang, Y Shi, J Zhu, W Zhou, X Qi, H Li - Forty-first International Conference on Machine \u2026", "abstract": "Trustworthiness is an essential prerequisite for the real-world application of large language models. In this paper, we focus on the trustworthiness of language models with respect to retrieval augmentation. Despite being supported with external \u2026"}]
