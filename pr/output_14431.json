[{"title": "BiasICL: In-Context Learning and Demographic Biases of Vision Language Models", "link": "https://arxiv.org/pdf/2503.02334", "details": "S Xu, J Janizek, Y Jiang, R Daneshjou - arXiv preprint arXiv:2503.02334, 2025", "abstract": "Vision language models (VLMs) show promise in medical diagnosis, but their performance across demographic subgroups when using in-context learning (ICL) remains poorly understood. We examine how the demographic composition of \u2026"}, {"title": "X2CT-CLIP: Enable Multi-Abnormality Detection in Computed Tomography from Chest Radiography via Tri-Modal Contrastive Learning", "link": "https://arxiv.org/pdf/2503.02162", "details": "J You, Y Gao, S Kim, C Mcintosh - arXiv preprint arXiv:2503.02162, 2025", "abstract": "Computed tomography (CT) is a key imaging modality for diagnosis, yet its clinical utility is marred by high radiation exposure and long turnaround times, restricting its use for larger-scale screening. Although chest radiography (CXR) is more accessible \u2026"}, {"title": "Video-Poetry Retrieval with Multimodal Knowledge Graph Guided Unsupervised Pre-training", "link": "https://ieeexplore.ieee.org/abstract/document/10890236/", "details": "X Wei, Y Li, B Wu - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Classical Chinese poetry, with its rich cultural heritage, holds immense artistic value. Recently, research on multi-modal approaches to classical poetry has garnered attention. Current research mainly focuses on poetry and images, but images cannot \u2026"}, {"title": "Med3DVLM: An Efficient Vision-Language Model for 3D Medical Image Analysis", "link": "https://arxiv.org/pdf/2503.20047", "details": "Y Xin, GC Ates, K Gong, W Shao - arXiv preprint arXiv:2503.20047, 2025", "abstract": "Vision-language models (VLMs) have shown promise in 2D medical image analysis, but extending them to 3D remains challenging due to the high computational demands of volumetric data and the difficulty of aligning 3D spatial features with \u2026"}, {"title": "BPQA Dataset: Evaluating How Well Language Models Leverage Blood Pressures to Answer Biomedical Questions", "link": "https://arxiv.org/pdf/2503.04155", "details": "C Hang, R Deng, LY Jiang, Z Yang, A Alyakin, D Alber\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Clinical measurements such as blood pressures and respiration rates are critical in diagnosing and monitoring patient outcomes. It is an important component of biomedical data, which can be used to train transformer-based language models \u2026"}, {"title": "Developing a PET/CT Foundation Model for Cross-Modal Anatomical and Functional Imaging", "link": "https://arxiv.org/pdf/2503.02824%3F", "details": "Y Oh, R Seifert, Y Cao, C Clement, J Ferdinandus\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In oncology, Positron Emission Tomography-Computed Tomography (PET/CT) is widely used in cancer diagnosis, staging, and treatment monitoring, as it combines anatomical details from CT with functional metabolic activity and molecular marker \u2026"}, {"title": "Few-Shot Whole Slide Pathology Classification with Multi-Granular Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3DnJZtYrOeoV", "details": "AT Nguyen, DMH Nguyen, NT Diep, TQ Nguyen, N Ho\u2026 - \u2026 on Foundation Models in the Wild", "abstract": "In this study, we propose a novel architecture for a large vision-language model adapted with a multi-granular prompt learning method to advance few-shot pathol- ogy classification. Starting with the Prov-GigaPath foundation model-pre-trained on \u2026"}, {"title": "Unsupervised Parameter Efficient Source-free Post-pretraining", "link": "https://arxiv.org/pdf/2502.21313%3F", "details": "A Jha, T Tuytelaars, YM Asano - arXiv preprint arXiv:2502.21313, 2025", "abstract": "Following the success in NLP, the best vision models are now in the billion parameter ranges. Adapting these large models to a target distribution has become computationally and economically prohibitive. Addressing this challenge, we \u2026"}, {"title": "Spatio-Temporal and Retrieval-Augmented Modelling for Chest X-Ray Report Generation", "link": "https://ieeexplore.ieee.org/abstract/document/10938723/", "details": "Y Yang, X You, K Zhang, Z Fu, X Wang, J Ding, J Sun\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "Chest X-ray report generation has attracted increasing research attention. However, most existing methods neglect the temporal information and typically generate reports conditioned on a fixed number of images. In this paper, we propose \u2026"}]
