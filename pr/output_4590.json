[{"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "Multi-turn Response Selection with Commonsense-enhanced Language Models", "link": "https://arxiv.org/pdf/2407.18479", "details": "Y Wang, X Ren, T Chen, Y Dong, NQV Hung, J Tang - arXiv preprint arXiv \u2026, 2024", "abstract": "As a branch of advanced artificial intelligence, dialogue systems are prospering. Multi-turn response selection is a general research problem in dialogue systems. With the assistance of background information and pre-trained language models, the \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}, {"title": "Affordable and real-time antimicrobial resistance prediction from multimodal electronic health records", "link": "https://www.nature.com/articles/s41598-024-66812-5", "details": "S Hardan, MA Shaaban, J Abdalla, M Yaqub - Scientific Reports, 2024", "abstract": "The spread of antimicrobial resistance (AMR) leads to challenging complications and losses of human lives plus medical resources, with a high expectancy of deterioration in the future if the problem is not controlled. From a machine learning \u2026"}, {"title": "Can Language Models Safeguard Themselves, Instantly and For Free?", "link": "https://openreview.net/pdf%3Fid%3DALRWSxT1rl", "details": "D Adila, C Shin, Y Zhang, F Sala - ICML 2024 Next Generation of AI Safety Workshop", "abstract": "Aligning pretrained language models (LMs) to handle a new safety scenario is normally difficult and expensive, often requiring access to large amounts of ground- truth preference data and substantial compute. Are these costs necessary? That is, is \u2026"}, {"title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models", "link": "https://arxiv.org/pdf/2407.03160", "details": "Z Yang, M Backes, Y Zhang, A Salem - arXiv preprint arXiv:2407.03160, 2024", "abstract": "Open-source large language models (LLMs) have become increasingly popular among both the general public and industry, as they can be customized, fine-tuned, and freely used. However, some open-source LLMs require approval before usage \u2026"}, {"title": "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale", "link": "https://arxiv.org/pdf/2407.02118", "details": "W Zheng, W Pan, X Xu, L Qin, L Yue, M Zhou - arXiv preprint arXiv:2407.02118, 2024", "abstract": "In recent years, Large Language Models (LLMs) have made significant strides towards Artificial General Intelligence. However, training these models from scratch requires substantial computational resources and vast amounts of text data. In this \u2026"}, {"title": "Towards Effective and Efficient Continual Pre-training of Large Language Models", "link": "https://arxiv.org/pdf/2407.18743", "details": "J Chen, Z Chen, J Wang, K Zhou, Y Zhu, J Jiang, Y Min\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Continual pre-training (CPT) has been an important approach for adapting language models to specific domains or tasks. To make the CPT approach more traceable, this paper presents a technical report for continually pre-training Llama-3 (8B), which \u2026"}, {"title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models", "link": "https://arxiv.org/pdf/2407.02408", "details": "S Wang, P Wang, T Zhou, Y Dong, Z Tan, J Li - arXiv preprint arXiv:2407.02408, 2024", "abstract": "As Large Language Models (LLMs) are increasingly deployed to handle various natural language processing (NLP) tasks, concerns regarding the potential negative societal impacts of LLM-generated content have also arisen. To evaluate the biases \u2026"}]
