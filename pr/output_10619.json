[{"title": "VisionZip: Longer is Better but Not Necessary in Vision Language Models", "link": "https://arxiv.org/pdf/2412.04467", "details": "S Yang, Y Chen, Z Tian, C Wang, J Li, B Yu, J Jia - arXiv preprint arXiv:2412.04467, 2024", "abstract": "Recent advancements in vision-language models have enhanced performance by increasing the length of visual tokens, making them much longer than text tokens and significantly raising computational costs. However, we observe that the visual tokens \u2026"}, {"title": "AdvDreamer Unveils: Are Vision-Language Models Truly Ready for Real-World 3D Variations?", "link": "https://arxiv.org/pdf/2412.03002", "details": "S Ruan, H Liu, Y Huang, X Wang, C Kang, H Su\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision Language Models (VLMs) have exhibited remarkable generalization capabilities, yet their robustness in dynamic real-world scenarios remains largely unexplored. To systematically evaluate VLMs' robustness to real-world 3D variations \u2026"}, {"title": "Exploring Visual Multiple-Choice Question Answering with Pre-trained Vision-Language Models", "link": "https://openaccess.thecvf.com/content/ACCV2024W/LAVA/papers/Tran_Exploring_Visual_Multiple-Choice_Question_Answering_with_Pre-trained_Vision-Language_Models_ACCVW_2024_paper.pdf", "details": "GN Tran, DT Luu - Proceedings of the Asian Conference on Computer \u2026, 2024", "abstract": "Visual question answering is a challenging task in computer vision and natural language processing that involves answering questions about an image using both visual and textual information. This task is more challenging when it comes to the \u2026"}, {"title": "Contrastive concept-phrase pre-training for generating clinically accurate and interpretable chest X-ray reports", "link": "https://link.springer.com/article/10.1007/s00521-024-10640-1", "details": "A Tubaishat, T Zia, D Windridge, M Nawaz, S Razzaq - Neural Computing and \u2026, 2024", "abstract": "Automated radiology report generation is an emerging field for improving patient care and alleviating radiologist workload. However, existing methods face a range of challenges such as limited data availability, clinical metric performance, and \u2026"}, {"title": "Domain Aware Multi-Task Pre-Training of 3D Swin Transformer for Brain MRI", "link": "https://openaccess.thecvf.com/content/ACCV2024/papers/Kim_Domain_Aware_Multi-Task_Pre-Training_of_3D_Swin_Transformer_for_Brain_ACCV_2024_paper.pdf", "details": "J Kim, M Kim, H Park - Proceedings of the Asian Conference on Computer \u2026, 2024", "abstract": "The scarcity of annotated medical images is a major bottleneck in developing learning models for medical image analysis. Hence, recent studies have focused on pretrained models with fewer annotation requirements that can be fine-tuned for \u2026"}, {"title": "The Radiance of Neural Fields: Democratizing Photorealistic and Dynamic Robotic Simulation", "link": "https://arxiv.org/pdf/2411.16940", "details": "G Nuthall, R Bowden, O Mendez - arXiv preprint arXiv:2411.16940, 2024", "abstract": "As robots increasingly coexist with humans, they must navigate complex, dynamic environments rich in visual information and implicit social dynamics, like when to yield or move through crowds. Addressing these challenges requires significant \u2026"}, {"title": "Integrating advanced vision-language models for context recognition in risks assessment", "link": "https://rua.ua.es/dspace/bitstream/10045/150006/1/Rodriguez-Juan_etal_2024_Neurocomputing.pdf", "details": "J Rodriguez-Juan, D Ortiz-Perez, J Garcia-Rodriguez\u2026 - Neurocomputing, 2024", "abstract": "This study proposes an open-environment, multi-label human risk classification framework, capable of identifying possible risks to which individuals appearing on input video data are exposed. The framework consists of an ensemble of models \u2026"}, {"title": "Informed Augmentation Selection Improves Tabular Contrastive Learning", "link": "https://openreview.net/pdf%3Fid%3DGFu8qDtVQa", "details": "A Khoeini, S Peng, M Ester - NeurIPS 2024 Workshop: Self-Supervised Learning \u2026", "abstract": "While contrastive learning (CL) has demonstrated success in image data, its application to tabular data remains relatively unexplored. The effectiveness of CL heavily depends on data augmentations, yet the suitability of tabular augmentation \u2026"}, {"title": "Assessing and Learning Alignment of Unimodal Vision and Language Models", "link": "https://arxiv.org/pdf/2412.04616", "details": "L Zhang, Q Yang, A Agrawal - arXiv preprint arXiv:2412.04616, 2024", "abstract": "How well are unimodal vision and language models aligned? Although prior work have approached answering this question, their assessment methods do not directly translate to how these models are used in practical vision-language tasks. In this \u2026"}]
