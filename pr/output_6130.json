[{"title": "Effective prompt extraction from language models", "link": "https://openreview.net/pdf%3Fid%3D0o95CVdNuz", "details": "Y Zhang, N Carlini, D Ippolito - First Conference on Language Modeling, 2024", "abstract": "The text generated by large language models is commonly controlled by prompting, where a prompt prepended to a user's query guides the model's output. The prompts used by companies to guide their models are often treated as secrets, to be hidden \u2026"}, {"title": "Understanding Defects in Generated Codes by Language Models", "link": "https://arxiv.org/pdf/2408.13372", "details": "AM Esfahani, N Kahani, SA Ajila - arXiv preprint arXiv:2408.13372, 2024", "abstract": "This study investigates the reliability of code generation by Large Language Models (LLMs), focusing on identifying and analyzing defects in the generated code. Despite the advanced capabilities of LLMs in automating code generation, ensuring the \u2026"}, {"title": "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws", "link": "https://arxiv.org/pdf/2408.08310", "details": "R Li, Y Wei, M Zhang, N Yu, H Hu, H Peng - arXiv preprint arXiv:2408.08310, 2024", "abstract": "High-quality data is crucial for the pre-training performance of large language models. Unfortunately, existing quality filtering methods rely on a known high-quality dataset as reference, which can introduce potential bias and compromise diversity. In \u2026"}, {"title": "MobileQuant: Mobile-friendly Quantization for On-device Language Models", "link": "https://arxiv.org/pdf/2408.13933", "details": "F Tan, R Lee, \u0141 Dudziak, SX Hu, S Bhattacharya\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have revolutionized language processing, delivering outstanding results across multiple applications. However, deploying LLMs on edge devices poses several challenges with respect to memory, energy, and compute \u2026"}, {"title": "KnowledgeFMath: A Knowledge-Intensive Math Reasoning Dataset in Finance Domains", "link": "https://aclanthology.org/2024.acl-long.693.pdf", "details": "Y Zhao, H Liu, Y Long, R Zhang, C Zhao, A Cohan - \u2026 of the 62nd Annual Meeting of \u2026, 2024", "abstract": "We introduce KnowledgeFMath, a novel benchmark designed to evaluate LLMs' capabilities in solving knowledge-intensive math reasoning problems. Compared to prior works, this study features three core advancements. First, KnowledgeFMath \u2026"}, {"title": "Persona is a Double-edged Sword: Enhancing the Zero-shot Reasoning by Ensembling the Role-playing and Neutral Prompts", "link": "https://arxiv.org/pdf/2408.08631", "details": "J Kim, N Yang, K Jung - arXiv preprint arXiv:2408.08631, 2024", "abstract": "Recent studies demonstrate that prompting an appropriate role-playing persona to an LLM improves its reasoning capability. However, assigning a proper persona is difficult since an LLM's performance is extremely sensitive to assigned prompts; \u2026"}, {"title": "LLMEmbed: Rethinking Lightweight LLM's Genuine Function in Text Classification", "link": "https://aclanthology.org/2024.acl-long.433.pdf", "details": "CL ChunLiu, H Zhang, K Zhao, X Ju, L Yang - \u2026 of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "With the booming of Large Language Models (LLMs), prompt-learning has become a promising method mainly researched in various research areas. Recently, many attempts based on prompt-learning have been made to improve the performance of \u2026"}, {"title": "Importance Weighting Can Help Large Language Models Self-Improve", "link": "https://arxiv.org/pdf/2408.09849", "details": "C Jiang, C Chan, W Xue, Q Liu, Y Guo - arXiv preprint arXiv:2408.09849, 2024", "abstract": "Large language models (LLMs) have shown remarkable capability in numerous tasks and applications. However, fine-tuning LLMs using high-quality datasets under external supervision remains prohibitively expensive. In response, LLM self \u2026"}, {"title": "Calibration and correctness of language models for code", "link": "https://software-lab.org/publications/icse2025_calibration.pdf", "details": "C Spiess, D Gros, KS Pai, M Pradel, MRI Rabin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Machine learning models are widely used, but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or \u2026"}]
