[{"title": "Channel and Spatial Attention in Chest X-Ray Radiographs: Advancing Person Identification and Verification with Self-Residual Attention Network", "link": "https://www.mdpi.com/2075-4418/14/23/2655", "details": "H Farah, A Bennour, NA Kurdi, S Hammami\u2026 - Diagnostics, 2024", "abstract": "Background/Objectives: In contrast to traditional biometric modalities, such as facial recognition, fingerprints, and iris scans or even DNA, the research orientation towards chest X-ray recognition has been spurred by its remarkable recognition \u2026"}, {"title": "HIST-AID: Leveraging Historical Patient Reports for Enhanced Multi-Modal Automatic Diagnosis", "link": "https://arxiv.org/pdf/2411.10684", "details": "H Huang, CM Deniz, K Cho, S Chopra, D Madaan - arXiv preprint arXiv:2411.10684, 2024", "abstract": "Chest X-ray imaging is a widely accessible and non-invasive diagnostic tool for detecting thoracic abnormalities. While numerous AI models assist radiologists in interpreting these images, most overlook patients' historical data. To bridge this gap \u2026"}, {"title": "Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence", "link": "https://arxiv.org/pdf/2411.16380", "details": "Y Jiang, CM Feng, J Ren, J Wei, Z Zhang, Y Hu, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Ultrasound imaging is widely used in clinical diagnosis due to its non-invasive nature and real-time capabilities. However, conventional ultrasound diagnostics face several limitations, including high dependence on physician expertise and \u2026"}, {"title": "Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2", "link": "https://arxiv.org/pdf/2411.15802", "details": "G M\u00fcller-Franzes, F Khader, R Siepmann, T Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "MRI and CT are essential clinical cross-sectional imaging techniques for diagnosing complex conditions. However, large 3D datasets with annotations for deep learning are scarce. While methods like DINOv2 are encouraging for 2D image analysis \u2026"}, {"title": "Large Language Model with Region-guided Referring and Grounding for CT Report Generation", "link": "https://arxiv.org/pdf/2411.15539", "details": "Z Chen, Y Bie, H Jin, H Chen - arXiv preprint arXiv:2411.15539, 2024", "abstract": "Computed tomography (CT) report generation is crucial to assist radiologists in interpreting CT volumes, which can be time-consuming and labor-intensive. Existing methods primarily only consider the global features of the entire volume, making it \u2026"}, {"title": "Cycle-Constrained Adversarial Denoising Convolutional Network for PET Image Denoising: Multi-Dimensional Validation on Large Datasets with Reader Study and \u2026", "link": "https://arxiv.org/pdf/2410.23628", "details": "Y Hou, F Zhan, X Cheng, C Li, Z Yuan, R Liao, H Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Positron emission tomography (PET) is a critical tool for diagnosing tumors and neurological disorders but poses radiation risks to patients, particularly to sensitive populations. While reducing injected radiation dose mitigates this risk, it often \u2026"}, {"title": "JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging", "link": "https://arxiv.org/pdf/2411.09933", "details": "K Baba, R Yagi, J Takahashi, R Kishikawa, S Kodera - arXiv preprint arXiv \u2026, 2024", "abstract": "With the rapid advancement of large language models (LLMs), foundational models (FMs) have seen significant advancements. Healthcare is one of the most crucial application areas for these FMs, given the significant time and effort required for \u2026"}, {"title": "UltraSam: A Foundation Model for Ultrasound using Large Open-Access Segmentation Datasets", "link": "https://arxiv.org/pdf/2411.16222", "details": "A Meyer, A Murali, D Mutter, N Padoy - arXiv preprint arXiv:2411.16222, 2024", "abstract": "Purpose: Automated ultrasound image analysis is challenging due to anatomical complexity and limited annotated data. To tackle this, we take a data-centric approach, assembling the largest public ultrasound segmentation dataset and \u2026"}]
