[{"title": "Mitigating Hallucinations in Large Vision-Language Models by Adaptively Constraining Information Flow", "link": "https://arxiv.org/pdf/2502.20750", "details": "J Bai, H Guo, Z Peng, J Yang, Z Li, M Li, Z Tian - arXiv preprint arXiv:2502.20750, 2025", "abstract": "Large vision-language models show tremendous potential in understanding visual information through human languages. However, they are prone to suffer from object hallucination, ie, the generated image descriptions contain objects that do not exist in \u2026"}, {"title": "Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones?", "link": "https://arxiv.org/pdf/2502.19557", "details": "Y Zhang, L Wang, M Fang, Y Du, C Huang, J Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Distilling large language models (LLMs) typically involves transferring the teacher model's responses through supervised fine-tuning (SFT). However, this approach neglects the potential to distill both data (output content) and reward signals (quality \u2026"}, {"title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities", "link": "https://arxiv.org/pdf/2502.12025%3F", "details": "F Jiang, Z Xu, Y Li, L Niu, Z Xiang, B Li, BY Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage long chain-of-thought (CoT) reasoning to generate structured intermediate steps, enhancing their reasoning capabilities. However, long CoT does not inherently \u2026"}, {"title": "Modular Prompt Learning Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14125", "details": "Z Huang, T Pedapati, PY Chen, J Gao - arXiv preprint arXiv:2502.14125, 2025", "abstract": "Pre-trained vision-language models are able to interpret visual concepts and language semantics. Prompt learning, a method of constructing prompts for text encoders or image encoders, elicits the potentials of pre-trained models and readily \u2026"}, {"title": "Towards Statistical Factuality Guarantee for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.20560", "details": "Z Li, C Yan, NJ Jackson, W Cui, B Li, J Zhang, BA Malin - arXiv preprint arXiv \u2026, 2025", "abstract": "Advancements in Large Vision-Language Models (LVLMs) have demonstrated promising performance in a variety of vision-language tasks involving image- conditioned free-form text generation. However, growing concerns about \u2026"}, {"title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training", "link": "https://arxiv.org/pdf/2502.11455", "details": "F Weng, J Lou, J Feng, M Huang, W Wang - arXiv preprint arXiv:2502.11455, 2025", "abstract": "Safety alignment is critical in pre-training large language models (LLMs) to generate responses aligned with human values and refuse harmful queries. Unlike LLM, the current safety alignment of VLMs is often achieved with post-hoc safety fine-tuning \u2026"}, {"title": "Language Models Can See Better: Visual Contrastive Decoding For LLM Multimodal Reasoning", "link": "https://arxiv.org/pdf/2502.11751", "details": "Y Pang, B Yang, H Tu, Y Cao, Z Zhang - arXiv preprint arXiv:2502.11751, 2025", "abstract": "Although Large Language Models (LLMs) excel in reasoning and generation for language tasks, they are not specifically designed for multimodal challenges. Training Multimodal Large Language Models (MLLMs), however, is resource \u2026"}, {"title": "Evaluating the Meta-and Object-Level Reasoning of Large Language Models for Question Answering", "link": "https://arxiv.org/pdf/2502.10338%3F", "details": "N Ferguson, L Guillou, A Bundy, K Nuamah - arXiv preprint arXiv:2502.10338, 2025", "abstract": "Large Language Models (LLMs) excel in natural language tasks but still face challenges in Question Answering (QA) tasks requiring complex, multi-step reasoning. We outline the types of reasoning required in some of these tasks, and \u2026"}, {"title": "Transferring Textual Preferences to Vision-Language Understanding through Model Merging", "link": "https://arxiv.org/pdf/2502.13487", "details": "CA Li, TH Lin, YN Chen, H Lee - arXiv preprint arXiv:2502.13487, 2025", "abstract": "Large vision-language models (LVLMs) perform outstandingly across various multimodal tasks. However, their ability to evaluate generated content remains limited, and training vision-language reward models (VLRMs) with preference data is \u2026"}]
