[{"title": "Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones?", "link": "https://arxiv.org/pdf/2502.19557", "details": "Y Zhang, L Wang, M Fang, Y Du, C Huang, J Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Distilling large language models (LLMs) typically involves transferring the teacher model's responses through supervised fine-tuning (SFT). However, this approach neglects the potential to distill both data (output content) and reward signals (quality \u2026"}, {"title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities", "link": "https://arxiv.org/pdf/2502.12025%3F", "details": "F Jiang, Z Xu, Y Li, L Niu, Z Xiang, B Li, BY Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage long chain-of-thought (CoT) reasoning to generate structured intermediate steps, enhancing their reasoning capabilities. However, long CoT does not inherently \u2026"}, {"title": "Modular Prompt Learning Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14125", "details": "Z Huang, T Pedapati, PY Chen, J Gao - arXiv preprint arXiv:2502.14125, 2025", "abstract": "Pre-trained vision-language models are able to interpret visual concepts and language semantics. Prompt learning, a method of constructing prompts for text encoders or image encoders, elicits the potentials of pre-trained models and readily \u2026"}, {"title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training", "link": "https://arxiv.org/pdf/2502.11455", "details": "F Weng, J Lou, J Feng, M Huang, W Wang - arXiv preprint arXiv:2502.11455, 2025", "abstract": "Safety alignment is critical in pre-training large language models (LLMs) to generate responses aligned with human values and refuse harmful queries. Unlike LLM, the current safety alignment of VLMs is often achieved with post-hoc safety fine-tuning \u2026"}, {"title": "Language Models Can See Better: Visual Contrastive Decoding For LLM Multimodal Reasoning", "link": "https://arxiv.org/pdf/2502.11751", "details": "Y Pang, B Yang, H Tu, Y Cao, Z Zhang - arXiv preprint arXiv:2502.11751, 2025", "abstract": "Although Large Language Models (LLMs) excel in reasoning and generation for language tasks, they are not specifically designed for multimodal challenges. Training Multimodal Large Language Models (MLLMs), however, is resource \u2026"}, {"title": "A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations", "link": "https://arxiv.org/pdf/2502.14881", "details": "M Ye, X Rong, W Huang, B Du, N Yu, D Tao - arXiv preprint arXiv:2502.14881, 2025", "abstract": "With the rapid advancement of Large Vision-Language Models (LVLMs), ensuring their safety has emerged as a crucial area of research. This survey provides a comprehensive analysis of LVLM safety, covering key aspects such as attacks \u2026"}, {"title": "Testing the limits of fine-tuning to improve reasoning in vision language models", "link": "https://arxiv.org/pdf/2502.15678", "details": "LMS Buschoff, K Voudouris, E Akata, M Bethge\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Pre-trained vision language models still fall short of human visual cognition. In an effort to improve visual cognition and align models with human behavior, we introduce visual stimuli and human judgments on visual cognition tasks, allowing us \u2026"}, {"title": "Fair-MoE: Fairness-Oriented Mixture of Experts in Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06094", "details": "P Wang, L Tong, J Liu, Z Liu - arXiv preprint arXiv:2502.06094, 2025", "abstract": "Fairness is a fundamental principle in medical ethics. Vision Language Models (VLMs) have shown significant potential in the medical field due to their ability to leverage both visual and linguistic contexts, reducing the need for large datasets and \u2026"}, {"title": "Evaluating the Meta-and Object-Level Reasoning of Large Language Models for Question Answering", "link": "https://arxiv.org/pdf/2502.10338%3F", "details": "N Ferguson, L Guillou, A Bundy, K Nuamah - arXiv preprint arXiv:2502.10338, 2025", "abstract": "Large Language Models (LLMs) excel in natural language tasks but still face challenges in Question Answering (QA) tasks requiring complex, multi-step reasoning. We outline the types of reasoning required in some of these tasks, and \u2026"}]
