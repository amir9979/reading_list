[{"title": "Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization", "link": "https://arxiv.org/pdf/2410.09302", "details": "G Liu, K Ji, R Zheng, Z Wu, C Dun, Q Gu, L Yan - arXiv preprint arXiv:2410.09302, 2024", "abstract": "Reinforcement Learning (RL) plays a crucial role in aligning large language models (LLMs) with human preferences and improving their ability to perform complex tasks. However, current approaches either require significant computational resources due \u2026"}, {"title": "Image2Struct: Benchmarking Structure Extraction for Vision-Language Models", "link": "https://arxiv.org/pdf/2410.22456", "details": "JS Roberts, T Lee, CH Wong, M Yasunaga, Y Mai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce Image2Struct, a benchmark to evaluate vision-language models (VLMs) on extracting structure from images. Our benchmark 1) captures real-world use cases, 2) is fully automatic and does not require human judgment, and 3) is \u2026"}, {"title": "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models", "link": "https://arxiv.org/pdf/2410.22360", "details": "B Newman, Y Lee, A Naik, P Siangliulue, R Fok, J Kim\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "When conducting literature reviews, scientists often create literature review tables- tables whose rows are publications and whose columns constitute a schema, a set of aspects used to compare and contrast the papers. Can we automatically generate \u2026"}, {"title": "Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector", "link": "https://arxiv.org/pdf/2410.22888", "details": "Y Huang, F Zhu, J Tang, P Zhou, W Lei, J Lv, TS Chua - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual Language Models (VLMs) are vulnerable to adversarial attacks, especially those from adversarial images, which is however under-explored in literature. To facilitate research on this critical safety problem, we first construct a new laRge-scale \u2026"}, {"title": "Transformer-based Language Models for Reasoning in the Description Logic ALCQ", "link": "https://arxiv.org/pdf/2410.09613", "details": "A Poulis, E Tsalapati, M Koubarakis - arXiv preprint arXiv:2410.09613, 2024", "abstract": "Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order \u2026"}, {"title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "link": "https://arxiv.org/pdf/2410.05434", "details": "S Choudhury, P Sodhi - arXiv preprint arXiv:2410.05434, 2024", "abstract": "While large language models (LLMs) show impressive decision-making abilities, current methods lack a mechanism for automatic self-improvement from errors during task execution. We propose LEAP, an iterative fine-tuning framework that continually \u2026"}, {"title": "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation", "link": "https://arxiv.org/pdf/2410.05801", "details": "B He, N Chen, X He, L Yan, Z Wei, J Luo, ZH Ling - arXiv preprint arXiv:2410.05801, 2024", "abstract": "Recent Retrieval Augmented Generation (RAG) aims to enhance Large Language Models (LLMs) by incorporating extensive knowledge retrieved from external sources. However, such approach encounters some challenges: Firstly, the original \u2026"}, {"title": "EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations", "link": "https://arxiv.org/pdf/2410.22821", "details": "J Li, G Li, X Zhang, Y Zhao, Y Dong, Z Jin, B Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "How to evaluate Large Language Models (LLMs) in code generation remains an open question. Existing benchmarks have two limitations-data leakage and lack of domain-specific evaluation. The former hurts the fairness of benchmarks, and the \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}]
