[{"title": "MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification", "link": "https://arxiv.org/pdf/2502.07409", "details": "AT Nguyen, DMH Nguyen, NT Diep, TQ Nguyen, N Ho\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Whole slide pathology image classification presents challenges due to gigapixel image sizes and limited annotation labels, hindering model generalization. This paper introduces a prompt learning method to adapt large vision-language models \u2026"}, {"title": "Towards Stable and Explainable Attention Mechanisms", "link": "https://repository.kaust.edu.sa/bitstreams/c7c43386-8199-4977-8aeb-2812958012ce/download", "details": "L Hu, X Wang, Y Liu, N Liu, M Huai, L Sun, D Wang - IEEE Transactions on \u2026, 2025", "abstract": "Currently, attention mechanism has become a standard fixture in most state-of-the-art natural language processing (NLP) models, not only due to the outstanding performance it could gain but also due to plausible innate explanations for the \u2026"}, {"title": "LATTE-CXR: Locally Aligned TexT and imagE, Explainable dataset for Chest X-Rays", "link": "https://physionet.org/content/latte-cxr/", "details": "E Ghelichkhan, T Tasdizen", "abstract": "Local annotation of medical data is both expensive and time-consuming due to the high cost of expert annotators, the precision required for accurate annotation, and the inherent challenges of medical diagnosis. To address these problems, we developed \u2026"}, {"title": "Scaling Pre-training to One Hundred Billion Data for Vision Language Models", "link": "https://arxiv.org/pdf/2502.07617", "details": "X Wang, I Alabdulmohsin, D Salz, Z Li, K Rong, X Zhai - arXiv preprint arXiv \u2026, 2025", "abstract": "We provide an empirical investigation of the potential of pre-training vision-language models on an unprecedented scale: 100 billion examples. We find that model performance tends to saturate at this scale on many common Western-centric \u2026"}, {"title": "ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization", "link": "https://arxiv.org/pdf/2502.05605", "details": "Y Zeng, X Cui, X Jin, G Liu, Z Sun, Q He, D Li, N Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we \u2026"}]
