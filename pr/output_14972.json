[{"title": "OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counterfactual Reasoning", "link": "https://arxiv.org/pdf/2504.04348", "details": "S Wang, Z Yu, X Jiang, S Lan, M Shi, N Chang, J Kautz\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The advances in vision-language models (VLMs) have led to a growing interest in autonomous driving to leverage their strong reasoning capabilities. However, extending these capabilities from 2D to full 3D understanding is crucial for real-world \u2026"}, {"title": "Self-Supervised Graph Representation Learning for Single-Cell Classification", "link": "https://link.springer.com/article/10.1007/s12539-025-00700-y", "details": "Q Dai, W Liu, X Yu, X Duan, Z Liu - Interdisciplinary Sciences: Computational Life \u2026, 2025", "abstract": "Accurately identifying cell types in single-cell RNA sequencing data is critical for understanding cellular differentiation and pathological mechanisms in downstream analysis. As traditional biological approaches are laborious and time-intensive, it is \u2026"}, {"title": "Variational Self-Supervised Learning", "link": "https://arxiv.org/pdf/2504.04318", "details": "MC Yavuz, B Yanikoglu - arXiv preprint arXiv:2504.04318, 2025", "abstract": "We present Variational Self-Supervised Learning (VSSL), a novel framework that combines variational inference with self-supervised learning to enable efficient, decoder-free representation learning. Unlike traditional VAEs that rely on input \u2026"}]
