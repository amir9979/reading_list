[{"title": "Enhancing RWKV-based Language Models for Long-Sequence Text Generation", "link": "https://arxiv.org/pdf/2502.15485", "details": "X Pan - arXiv preprint arXiv:2502.15485, 2025", "abstract": "This paper presents an enhanced RWKV-based language generation model designed to improve long-sequence text processing. We propose an adaptive token shift and gating mechanism to better capture long-range dependencies in text \u2026"}, {"title": "LLM Alignment as Retriever Optimization: An Information Retrieval Perspective", "link": "https://arxiv.org/pdf/2502.03699", "details": "B Jin, J Yoon, Z Qin, Z Wang, W Xiong, Y Meng, J Han\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence with capabilities in reasoning, coding, and communication, driving innovation across industries. Their true potential depends on effective alignment to ensure correct \u2026"}, {"title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization", "link": "https://arxiv.org/pdf/2502.04306%3F", "details": "Y Wang, L Yang, G Li, M Wang, B Aragam - arXiv preprint arXiv:2502.04306, 2025", "abstract": "Recent research has leveraged large language model multi-agent systems for complex problem-solving while trying to reduce the manual effort required to build them, driving the development of automated agent workflow optimization methods \u2026"}, {"title": "Wisdom of the Crowds in Forecasting: Forecast Summarization for Supporting Future Event Prediction", "link": "https://arxiv.org/pdf/2502.08205", "details": "A Saha, A Jatowt - arXiv preprint arXiv:2502.08205, 2025", "abstract": "Future Event Prediction (FEP) is an essential activity whose demand and application range across multiple domains. While traditional methods like simulations, predictive and time-series forecasting have demonstrated promising outcomes, their \u2026"}, {"title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies", "link": "https://arxiv.org/pdf/2502.08554", "details": "SSY Kim, JW Vaughan, QV Liao, T Lombrozo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study \u2026"}, {"title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2501.18099%3F", "details": "S Saha, X Li, M Ghazvininejad, J Weston, T Wang - arXiv preprint arXiv:2501.18099, 2025", "abstract": "LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to capture the step-bystep reasoning process that underlies the final evaluation of a response. However, due to the lack of human annotated CoTs for evaluation, the \u2026"}, {"title": "RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation", "link": "https://arxiv.org/pdf/2502.09183", "details": "C Zhou, X Zhang, D Song, X Chen, W Gu, H Ma, Y Tian\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Code generation has attracted increasing attention with the rise of Large Language Models (LLMs). Many studies have developed powerful code LLMs by synthesizing code-related instruction data and applying supervised fine-tuning. However, these \u2026"}, {"title": "ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization", "link": "https://arxiv.org/pdf/2502.05605", "details": "Y Zeng, X Cui, X Jin, G Liu, Z Sun, Q He, D Li, N Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we \u2026"}, {"title": "HuDEx: Integrating Hallucination Detection and Explainability for Enhancing the Reliability of LLM responses", "link": "https://arxiv.org/pdf/2502.08109", "details": "S Lee, H Lee, S Heo, W Choi - arXiv preprint arXiv:2502.08109, 2025", "abstract": "Recent advances in large language models (LLMs) have shown promising improvements, often surpassing existing methods across a wide range of downstream tasks in natural language processing. However, these models still face \u2026"}]
