'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Autonomous Data Selection with Language Models for Mat'
[{"title": "Continuous patient state attention model for addressing irregularity in electronic health records", "link": "https://link.springer.com/article/10.1186/s12911-024-02514-2", "details": "VK Chauhan, A Thakur, O O'Donoghue, O Rohanian\u2026 - BMC Medical Informatics \u2026, 2024", "abstract": "Background Irregular time series (ITS) are common in healthcare as patient data is recorded in an electronic health record (EHR) system as per clinical guidelines/ requirements but not for research and depends on a patient's health status. Due to \u2026"}, {"title": "GraSAME: Injecting Token-Level Structural Information to Pretrained Language Models via Graph-guided Self-Attention Mechanism", "link": "https://arxiv.org/pdf/2404.06911", "details": "S Yuan, M F\u00e4rber - arXiv preprint arXiv:2404.06911, 2024", "abstract": "Pretrained Language Models (PLMs) benefit from external knowledge stored in graph structures for various downstream tasks. However, bridging the modality gap between graph structures and text remains a significant challenge. Traditional \u2026"}, {"title": "Automatic Generation and Evaluation of Reading Comprehension Test Items with Large Language Models", "link": "https://arxiv.org/pdf/2404.07720", "details": "A S\u00e4uberli, S Clematide - arXiv preprint arXiv:2404.07720, 2024", "abstract": "Reading comprehension tests are used in a variety of applications, reaching from education to assessing the comprehensibility of simplified texts. However, creating such tests manually and ensuring their quality is difficult and time-consuming. In this \u2026"}, {"title": "Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models", "link": "https://arxiv.org/pdf/2404.10209", "details": "S Xue, D Qi, C Jiang, W Shi, F Cheng, K Chen, H Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The recent breakthroughs in large language models (LLMs) are positioned to transition many areas of software. The technologies of interacting with data particularly have an important entanglement with LLMs as efficient and intuitive data \u2026"}, {"title": "Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2405.00175", "details": "A Salemi, H Zamani - arXiv preprint arXiv:2405.00175, 2024", "abstract": "This paper introduces uRAG--a framework with a unified retrieval engine that serves multiple downstream retrieval-augmented generation (RAG) systems. Each RAG system consumes the retrieval results for a unique purpose, such as open-domain \u2026"}, {"title": "Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition", "link": "https://arxiv.org/pdf/2404.08008", "details": "K Feng, K Ding, K Ma, Z Wang, Q Zhang, H Chen - arXiv preprint arXiv:2404.08008, 2024", "abstract": "The past years have witnessed a proliferation of large language models (LLMs). Yet, automated and unbiased evaluation of LLMs is challenging due to the inaccuracy of standard metrics in reflecting human preferences and the inefficiency in sampling \u2026"}, {"title": "Language model-based labeling of German thoracic radiology reports", "link": "https://www.thieme-connect.com/products/ejournals/html/10.1055/a-2287-5054", "details": "A Wollek, P Haitzer, T Sedlmeyr, S Hyska, J Rueckel\u2026 - R\u00f6Fo-Fortschritte auf dem \u2026, 2024", "abstract": "The aim of this study was to explore the potential of weak supervision in a deep learning-based label prediction model. The goal was to use this model to extract labels from German free-text thoracic radiology reports on chest X-ray images and for \u2026"}]
