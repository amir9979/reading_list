'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [A Comparison of Parameter-Efficient ASR Domain Adaptation Me'
[{"title": "Understanding emergent abilities of language models from the loss perspective", "link": "https://arxiv.org/pdf/2403.15796", "details": "Z Du, A Zeng, Y Dong, J Tang - arXiv preprint arXiv:2403.15796, 2024", "abstract": "Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) \u2026"}, {"title": "Improving Language Model Reasoning with Self-motivated Learning", "link": "https://arxiv.org/pdf/2404.07017", "details": "Y Feng, Y Xu, L Qin, Y Wang, W Che - arXiv preprint arXiv:2404.07017, 2024", "abstract": "Large-scale high-quality training data is important for improving the performance of models. After trained with data that has rationales (reasoning steps), models gain reasoning capability. However, the dataset with high-quality rationales is relatively \u2026"}, {"title": "Emergent Abilities in Reduced-Scale Generative Language Models", "link": "https://arxiv.org/pdf/2404.02204", "details": "S Muckatira, V Deshpande, V Lialin, A Rumshisky - arXiv preprint arXiv:2404.02204, 2024", "abstract": "Large language models can solve new tasks without task-specific fine-tuning. This ability, also known as in-context learning (ICL), is considered an emergent ability and is primarily seen in large language models with billions of parameters. This study \u2026"}, {"title": "Grounding and Enhancing Grid-based Models for Neural Fields", "link": "https://arxiv.org/pdf/2403.20002", "details": "Z Zhao, F Fan, W Liao, J Yan - arXiv preprint arXiv:2403.20002, 2024", "abstract": "Many contemporary studies utilize grid-based models for neural field representation, but a systematic analysis of grid-based models is still missing, hindering the improvement of those models. Therefore, this paper introduces a theoretical \u2026"}, {"title": "Comparing Two Model Designs for Clinical Note Generation; Is an LLM a Useful Evaluator of Consistency?", "link": "https://arxiv.org/pdf/2404.06503", "details": "N Brake, T Schaaf - arXiv preprint arXiv:2404.06503, 2024", "abstract": "Following an interaction with a patient, physicians are responsible for the submission of clinical documentation, often organized as a SOAP note. A clinical note is not simply a summary of the conversation but requires the use of appropriate medical \u2026"}, {"title": "Generative Language Models for Personalized Information Understanding", "link": "https://scholarworks.umass.edu/cgi/viewcontent.cgi%3Farticle%3D4123%26context%3Ddissertations_2", "details": "P Cai - 2024", "abstract": "A major challenge in information understanding stems from the diverse nature of the audience, where individuals possess varying preferences, experiences, educational and cultural backgrounds. Consequently, adopting a one-size-fits-all approach to \u2026"}, {"title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies", "link": "https://arxiv.org/pdf/2404.06395", "details": "S Hu, Y Tu, X Han, C He, G Cui, X Long, Z Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This \u2026"}, {"title": "Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models", "link": "https://arxiv.org/pdf/2403.12881", "details": "Z Chen, K Liu, Q Wang, W Zhang, J Liu, D Lin, K Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Open-sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API-based models when acting as agents. How to integrate agent ability into general LLMs becomes a crucial \u2026"}, {"title": "InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD", "link": "https://arxiv.org/pdf/2404.06512", "details": "X Dong, P Zhang, Y Zang, Y Cao, B Wang, L Ouyang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The Large Vision-Language Model (LVLM) field has seen significant advancements, yet its progression has been hindered by challenges in comprehending fine-grained visual content due to limited resolution. Recent efforts have aimed to enhance the \u2026"}]
