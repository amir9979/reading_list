[{"title": "Energy-Based Diffusion Language Models for Text Generation", "link": "https://arxiv.org/pdf/2410.21357", "details": "M Xu, T Geffner, K Kreis, W Nie, Y Xu, J Leskovec\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite remarkable progress in autoregressive language models, alternative generative paradigms beyond left-to-right generation are still being actively explored. Discrete diffusion models, with the capacity for parallel generation, have recently \u2026"}, {"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "Locality Alignment Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2410.11087", "details": "I Covert, T Sun, J Zou, T Hashimoto - arXiv preprint arXiv:2410.11087, 2024", "abstract": "Vision language models (VLMs) have seen growing adoption in recent years, but many still struggle with basic spatial reasoning errors. We hypothesize that this is due to VLMs adopting pre-trained vision backbones, specifically vision transformers \u2026"}, {"title": "Natural Language Inference Improves Compositionality in Vision-Language Models", "link": "https://arxiv.org/pdf/2410.22315", "details": "P Cascante-Bonilla, Y Hou, YT Cao, H Daum\u00e9 III\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Compositional reasoning in Vision-Language Models (VLMs) remains challenging as these models often struggle to relate objects, attributes, and spatial relationships. Recent methods aim to address these limitations by relying on the semantics of the \u2026"}, {"title": "MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation", "link": "https://arxiv.org/pdf/2410.12916", "details": "SK Gorti, I Gofman, Z Liu, J Wu, N Vouitsis, G Yu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Text-to-SQL generation enables non-experts to interact with databases via natural language. Recent advances rely on large closed-source models like GPT-4 that present challenges in accessibility, privacy, and latency. To address these issues, we \u2026"}, {"title": "Tuning Language Models by Mixture-of-Depths Ensemble", "link": "https://arxiv.org/pdf/2410.13077", "details": "H Luo, L Specia - arXiv preprint arXiv:2410.13077, 2024", "abstract": "Transformer-based Large Language Models (LLMs) traditionally rely on final-layer loss for training and final-layer representations for predictions, potentially overlooking the predictive power embedded in intermediate layers. Surprisingly, we \u2026"}, {"title": "Manual Verbalizer Enrichment for Few-Shot Text Classification", "link": "https://arxiv.org/pdf/2410.06173", "details": "QA Nguyen, N Tomeh, M Lebbah, T Charnois, H Azzag\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the continuous development of pre-trained language models, prompt-based training becomes a well-adopted paradigm that drastically improves the exploitation of models for many natural language processing tasks. Prompting also shows great \u2026"}, {"title": "Assessment of treatment effect heterogeneity for multiregional randomized clinical trials", "link": "https://www.tandfonline.com/doi/abs/10.1080/19466315.2024.2421748", "details": "H Zhuang, X Wang, SL George - Statistics in Biopharmaceutical Research, 2024", "abstract": "Multiregional clinical trials (MRCTs) have become increasingly common in recent years. Detecting underlying regional heterogeneity is a critical issue for these trials. Existing methods for assessing treatment effect heterogeneity across regions have \u2026"}, {"title": "Generation Probabilities Are Not Enough: Uncertainty Highlighting in AI Code Completions", "link": "https://dl.acm.org/doi/pdf/10.1145/3702320", "details": "H Vasconcelos, G Bansal, A Fourney, QV Liao\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Large-scale generative models have enabled the development of AI-powered code completion tools to assist programmers in writing code. Like all AI-powered tools, these code completion tools are not always accurate and can introduce bugs or even \u2026"}]
