[{"title": "Metaaligner: Towards generalizable multi-objective alignment of language models", "link": "https://openreview.net/pdf%3Fid%3DdIVb5C0QFf", "details": "K Yang, Z Liu, Q Xie, J Huang, T Zhang, S Ananiadou - The Thirty-eighth Annual \u2026, 2024", "abstract": "Recent advancements in large language models (LLMs) focus on aligning to heterogeneous human expectations and values via multi-objective preference alignment. However, existing methods are dependent on the policy model \u2026"}, {"title": "Reducing Distraction in Long-Context Language Models by Focused Learning", "link": "https://arxiv.org/pdf/2411.05928", "details": "Z Wu, B Liu, R Yan, L Chen, T Delteil - arXiv preprint arXiv:2411.05928, 2024", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly enhanced their capacity to process long contexts. However, effectively utilizing this long context remains a challenge due to the issue of distraction, where irrelevant \u2026"}, {"title": "LLM-IE: A Python Package for Generative Information Extraction with Large Language Models", "link": "https://arxiv.org/pdf/2411.11779", "details": "E Hsu, K Roberts - arXiv preprint arXiv:2411.11779, 2024", "abstract": "Objectives: Despite the recent adoption of large language models (LLMs) for biomedical information extraction, challenges in prompt engineering and algorithms persist, with no dedicated software available. To address this, we developed LLM-IE \u2026"}, {"title": "GPTGAN: Utilizing the GPT language model and GAN to enhance adversarial text generation", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224016369", "details": "O Hajipoor, A Nickabadi, MM Homayounpour - Neurocomputing, 2024", "abstract": "Training generative models that can generate high-quality and diverse text remains a significant challenge in the field of natural language generation (NLG). Recently, the emergence of large language models (LLMs) like GPT has enabled the generation of \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}, {"title": "S $^{2} $ FT: Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity", "link": "https://openreview.net/pdf%3Fid%3DlEUle8S4xQ", "details": "X Yang, J Leng, G Guo, J Zhao, R Nakada, L Zhang\u2026 - The Thirty-eighth Annual \u2026", "abstract": "Current PEFT methods for LLMs can achieve either high quality, efficient training, or scalable serving, but not all three simultaneously. To address this limitation, we investigate sparse fine-tuning and observe a remarkable improvement in \u2026"}, {"title": "Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning", "link": "https://arxiv.org/pdf/2410.19290", "details": "Y Liu, S Chang, T Jaakkola, Y Zhang - arXiv preprint arXiv:2410.19290, 2024", "abstract": "Recent studies have identified one aggravating factor of LLM hallucinations as the knowledge inconsistency between pre-training and fine-tuning, where unfamiliar fine- tuning data mislead the LLM to fabricate plausible but wrong outputs. In this paper \u2026"}, {"title": "Self-Explore: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards", "link": "https://aclanthology.org/2024.findings-emnlp.78.pdf", "details": "H Hwang, D Kim, S Kim, S Ye, M Seo - Findings of the Association for Computational \u2026, 2024", "abstract": "Training on large amounts of rationales (ie, CoT Fine-tuning) has been found effective for improving mathematical reasoning of large language models (LLMs). However, acquiring human-authored solutions or augmenting rationales from \u2026"}, {"title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "link": "https://arxiv.org/pdf/2411.04329", "details": "J Li, H Le, Y Zhou, C Xiong, S Savarese, D Sahoo - arXiv preprint arXiv:2411.04329, 2024", "abstract": "Pre-trained on massive amounts of code and text data, large language models (LLMs) have demonstrated remarkable achievements in performing code generation tasks. With additional execution-based feedback, these models can act as agents \u2026"}]
