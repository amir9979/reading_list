[{"title": "Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models", "link": "https://aclanthology.org/2024.emnlp-main.124.pdf", "details": "Y Yang, J Ko, SY Yun - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Vision-language models (VLMs) like CLIP have demonstrated remarkable applicability across a variety of downstream tasks, including zero-shot image classification. Recently, the use of prompts or adapters for efficient transfer learning \u2026"}, {"title": "Probing Social Bias in Labor Market Text Generation by ChatGPT: A Masked Language Model Approach", "link": "https://openreview.net/pdf%3Fid%3DMP7j58lbWO", "details": "L Ding, Y Hu, N Denier, E Shi, J Zhang, Q Hu\u2026 - The Thirty-eighth Annual \u2026", "abstract": "As generative large language models (LLMs) such as ChatGPT gain widespread adoption in various domains, their potential to propagate and amplify social biases, particularly in high-stakes areas such as the labor market, has become a pressing \u2026"}, {"title": "Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding", "link": "https://aclanthology.org/2024.emnlp-main.870.pdf", "details": "L Tu, S Yavuz, J Qu, J Xu, R Meng, C Xiong, Y Zhou - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) have demonstrated a powerful ability for text generation. However, achieving optimal results with a given prompt or instruction can be challenging, especially for billion-sized models. Additionally, undesired \u2026"}, {"title": "Large Language Models Can Be Contextual Privacy Protection Learners", "link": "https://aclanthology.org/2024.emnlp-main.785.pdf", "details": "Y Xiao, Y Jin, Y Bai, Y Wu, X Yang, X Luo, W Yu\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract The proliferation of Large Language Models (LLMs) has driven considerable interest in fine-tuning them with domain-specific data to create specialized language models. Nevertheless, such domain-specific fine-tuning data \u2026"}, {"title": "Language Model Self-improvement by Reinforcement Learning Contemplation without External Supervision", "link": "https://jingchengpang.github.io/files/pdf/jair_rlc.pdf", "details": "JC Pang, K Li, P Wang, XH Chen, J Xu, Z Zhang, Y Yu", "abstract": "Abstract Language model self-improvement (LMSI) techniques have recently gained significant attention as they improve language models without requiring external supervision. A notable approach is reinforcement learning from AI feedback (RLAIF) \u2026"}, {"title": "Medical large language models are susceptible to targeted misinformation attacks", "link": "https://www.nature.com/articles/s41746-024-01282-7", "details": "T Han, S Nebelung, F Khader, T Wang\u2026 - NPJ Digital Medicine, 2024", "abstract": "Large language models (LLMs) have broad medical knowledge and can reason about medical information across many domains, holding promising potential for diverse medical applications in the near future. In this study, we demonstrate a \u2026"}]
