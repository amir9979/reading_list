[{"title": "Improved swin transformer-based thorax disease classification with optimal feature selection using chest X-ray", "link": "https://journals.plos.org/plosone/article%3Fid%3D10.1371/journal.pone.0327099", "details": "N Rana, Y Coulibaly, A Noor, TH Noor, MI Alam\u2026 - PLOS ONE, 2025", "abstract": "Thoracic diseases, including pneumonia, tuberculosis, lung cancer, and others, pose significant health risks and require timely and accurate diagnosis to ensure proper treatment. Thus, in this research, a model for thorax disease classification using \u2026"}, {"title": "Streamlining the annotation process by radiologists of volumetric medical images with few-shot learning", "link": "https://link.springer.com/article/10.1007/s11548-025-03457-3", "details": "A Ryabtsev, R Lederman, J Sosna, L Joskowicz - International Journal of Computer \u2026, 2025", "abstract": "Purpose Radiologist's manual annotations limit robust deep learning in volumetric medical imaging. While supervised methods excel with large annotated datasets, few- shot learning performs well for large structures but struggles with small ones, such as \u2026"}, {"title": "MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports", "link": "https://arxiv.org/pdf/2506.19217", "details": "S Kyung, H Park, J Seo, J Sung, J Kim, D Kim, W Jo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Computed Tomography (CT) plays a crucial role in clinical diagnosis, but the growing demand for CT examinations has raised concerns about diagnostic errors. While Multimodal Large Language Models (MLLMs) demonstrate promising \u2026", "entry_id": "http://arxiv.org/abs/2506.19217v1", "updated": "2025-06-24 00:51:03", "published": "2025-06-24 00:51:03", "authors": "Sunggu Kyung;Hyungbin Park;Jinyoung Seo;Jimin Sung;Jihyun Kim;Dongyeong Kim;Wooyoung Jo;Yoojin Nam;Sangah Park;Taehee Kwon;Sang Min Lee;Namkug Kim", "summary": "Computed Tomography (CT) plays a crucial role in clinical diagnosis, but the\ngrowing demand for CT examinations has raised concerns about diagnostic errors.\nWhile Multimodal Large Language Models (MLLMs) demonstrate promising\ncomprehension of medical knowledge, their tendency to produce inaccurate\ninformation highlights the need for rigorous validation. However, existing\nmedical visual question answering (VQA) benchmarks primarily focus on simple\nvisual recognition tasks, lacking clinical relevance and failing to assess\nexpert-level knowledge. We introduce MedErr-CT, a novel benchmark for\nevaluating medical MLLMs' ability to identify and correct errors in CT reports\nthrough a VQA framework. The benchmark includes six error categories - four\nvision-centric errors (Omission, Insertion, Direction, Size) and two lexical\nerror types (Unit, Typo) - and is organized into three task levels:\nclassification, detection, and correction. Using this benchmark, we\nquantitatively assess the performance of state-of-the-art 3D medical MLLMs,\nrevealing substantial variation in their capabilities across different error\ntypes. Our benchmark contributes to the development of more reliable and\nclinically applicable MLLMs, ultimately helping reduce diagnostic errors and\nimprove accuracy in clinical practice. The code and datasets are available at\nhttps://github.com/babbu3682/MedErr-CT.", "comment": "14 pages, 5 figures, submitted to CVPR 2025", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.AI", "links": "http://arxiv.org/abs/2506.19217v1;http://arxiv.org/pdf/2506.19217v1", "pdf_url": "http://arxiv.org/pdf/2506.19217v1"}]
