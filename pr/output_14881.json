[{"title": "Found In The Distribution: Utilizing Latent Dirichlet Allocation Improves Long Context Comprehension of Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10890215/", "details": "Z Guan, X Liang, S Zhang - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Large Language Models, even when specifically trained to process long input contexts, struggle to capture relevant information located in the middle of their input. This phenomenon is known as the\" lost-in-the-middle\" problem. In this study, We \u2026"}, {"title": "Enhancing Legal Question Answering with Data Generation and Knowledge Distillation from Large Language Models", "link": "https://cris.unibo.it/handle/11585/1010488", "details": "P Italiani, G Moro, L Ragazzi - ARTIFICIAL INTELLIGENCE AND LAW, 2025", "abstract": "Legal question answering (LQA) relies on supervised methods to automatically handle law-related queries. These solutions require a substantial amount of carefully annotated data for training, which makes the process very costly. Although large \u2026"}]
