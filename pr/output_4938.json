[{"title": "VLG-CBM: Training Concept Bottleneck Models with Vision-Language Guidance", "link": "https://arxiv.org/pdf/2408.01432", "details": "D Srivastava, G Yan, TW Weng - arXiv preprint arXiv:2408.01432, 2024", "abstract": "Concept Bottleneck Models (CBMs) provide interpretable prediction by introducing an intermediate Concept Bottleneck Layer (CBL), which encodes human- understandable concepts to explain models' decision. Recent works proposed to \u2026"}, {"title": "Curriculum learning based pre-training using Multi-Modal Contrastive Masked Autoencoders", "link": "https://arxiv.org/pdf/2408.02245", "details": "MA Jamal, O Mohareri - arXiv preprint arXiv:2408.02245, 2024", "abstract": "In this paper, we propose a new pre-training method for image understanding tasks under Curriculum Learning (CL) paradigm which leverages RGB-D. The method utilizes Multi-Modal Contrastive Masked Autoencoder and Denoising techniques \u2026"}, {"title": "Counterfactual Explanations for Medical Image Classification and Regression using Diffusion Autoencoder", "link": "https://arxiv.org/pdf/2408.01571", "details": "M Atad, D Schinz, H Moeller, R Graf, B Wiestler\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Counterfactual explanations (CEs) aim to enhance the interpretability of machine learning models by illustrating how alterations in input features would affect the resulting predictions. Common CE approaches require an additional model and are \u2026"}, {"title": "AssemAI: Interpretable Image-Based Anomaly Detection for Manufacturing Pipelines", "link": "https://arxiv.org/pdf/2408.02181", "details": "R Prasad, C Shyalika, R Zand, FE Kalach\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Anomaly detection in manufacturing pipelines remains a critical challenge, intensified by the complexity and variability of industrial environments. This paper introduces AssemAI, an interpretable image-based anomaly detection system \u2026"}, {"title": "Unsupervised Representation Learning by Balanced Self Attention Matching", "link": "https://arxiv.org/pdf/2408.02014", "details": "D Shalam, S Korman - arXiv preprint arXiv:2408.02014, 2024", "abstract": "Many leading self-supervised methods for unsupervised representation learning, in particular those for embedding image features, are built on variants of the instance discrimination task, whose optimization is known to be prone to instabilities that can \u2026"}, {"title": "MEDIC: Zero-shot Music Editing with Disentangled Inversion Control", "link": "https://arxiv.org/pdf/2407.13220", "details": "H Liu, J Wang, R Huang, Y Liu, J Xu, Z Zhao - arXiv preprint arXiv:2407.13220, 2024", "abstract": "Text-guided diffusion models catalyze a paradigm shift in audio generation, facilitating the adaptability of source audio to conform to specific textual prompts. Recent advancements introduce inversion techniques, like DDIM inversion, to zero \u2026"}]
