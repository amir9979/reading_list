[{"title": "Language Models Encode the Value of Numbers Linearly", "link": "https://aclanthology.org/2025.coling-main.47.pdf", "details": "F Zhu, D Dai, Z Sui - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have exhibited impressive competence in various tasks, but their internal mechanisms on mathematical problems are still under- explored. In this paper, we study a fundamental question: how language models \u2026"}, {"title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models", "link": "https://arxiv.org/pdf/2501.05752", "details": "S Lee, H Park, J Kim, J Ok - arXiv preprint arXiv:2501.05752, 2025", "abstract": "Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer \u2026"}, {"title": "Factual Knowledge Assessment of Language Models Using Distractors", "link": "https://aclanthology.org/2025.coling-main.537.pdf", "details": "HA Khodja, F Bechet, Q Brabant, A Nasr, G Lecorv\u00e9 - Proceedings of the 31st \u2026, 2025", "abstract": "Abstract Language models encode extensive factual knowledge within their parameters. The accurate assessment of this knowledge is crucial for understanding and improving these models. In the literature, factual knowledge assessment often \u2026"}, {"title": "LASS: A Novel and Economical Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization", "link": "https://aclanthology.org/2025.coling-main.412.pdf", "details": "Y Zhang, P Li, Y Lai, Y He, D Zhou - Proceedings of the 31st International Conference \u2026, 2025", "abstract": "As more than 70% of reviews in the existing opinion summary data set are positive, current opinion summarization approaches are hesitant to generate negative summaries given the input of negative texts. To address such sentiment bias, a direct \u2026"}, {"title": "Development of Numerical Error Detection Tasks to Analyze the Numerical Capabilities of Language Models", "link": "https://aclanthology.org/2025.coling-main.666.pdf", "details": "T Sakamoto, S Sugawara, A Aizawa - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "Numbers are used to describe quantities in various scenarios in daily life; therefore, numerical errors can significantly affect the meaning of the entire sentence, and even a single-letter error can be fatal. Detecting numerical errors often requires a high \u2026"}, {"title": "Distilling Rule-based Knowledge into Large Language Models", "link": "https://aclanthology.org/2025.coling-main.61.pdf", "details": "W Yang, Y Lin, J Zhou, JR Wen - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have shown incredible performance in completing various real-world tasks. The current paradigm of knowledge learning for LLMs is mainly based on learning from examples, in which LLMs learn the internal rule \u2026"}, {"title": "Foundations of Large Language Models", "link": "https://arxiv.org/pdf/2501.09223", "details": "T Xiao, J Zhu - arXiv preprint arXiv:2501.09223, 2025", "abstract": "This is a book about large language models. As indicated by the title, it primarily focuses on foundational concepts rather than comprehensive coverage of all cutting- edge technologies. The book is structured into four main chapters, each exploring a \u2026"}, {"title": "Text-Diffusion Red-Teaming of Large Language Models: Unveiling Harmful Behaviors with Proximity Constraints", "link": "https://arxiv.org/pdf/2501.08246", "details": "J N\u00f6ther, A Singla, G Radanovi\u0107 - arXiv preprint arXiv:2501.08246, 2025", "abstract": "Recent work has proposed automated red-teaming methods for testing the vulnerabilities of a given target large language model (LLM). These methods use red- teaming LLMs to uncover inputs that induce harmful behavior in a target LLM. In this \u2026"}, {"title": "Revisiting Jailbreaking for Large Language Models: A Representation Engineering Perspective", "link": "https://aclanthology.org/2025.coling-main.212.pdf", "details": "T Li, Z Wang, W Liu, M Wu, S Dou, C Lv, X Wang\u2026 - Proceedings of the 31st \u2026, 2025", "abstract": "The recent surge in jailbreaking attacks has revealed significant vulnerabilities in Large Language Models (LLMs) when exposed to malicious inputs. While various defense strategies have been proposed to mitigate these threats, there has been \u2026"}]
