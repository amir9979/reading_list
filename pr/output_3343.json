[{"title": "Media Bias Detection Across Families of Language Models", "link": "https://aclanthology.org/2024.naacl-long.227.pdf", "details": "I Maab, E Marrese-Taylor, S Pad\u00f3, Y Matsuo - Proceedings of the 2024 Conference of \u2026, 2024", "abstract": "Bias in reporting can influence the public's opinion on relevant societal issues. Examples include informational bias (selective presentation of content) and lexical bias (specific framing of content through linguistic choices). The recognition of media \u2026"}, {"title": "Leveraging Vision-Language Models for Improving Domain Generalization in Image Classification", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Addepalli_Leveraging_Vision-Language_Models_for_Improving_Domain_Generalization_in_Image_Classification_CVPR_2024_paper.pdf", "details": "S Addepalli, AR Asokan, L Sharma, RV Babu - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "Abstract Vision-Language Models (VLMs) such as CLIP are trained on large amounts of image-text pairs resulting in remarkable generalization across several data distributions. However in several cases their expensive training and data \u2026"}, {"title": "Molecular Data Programming: Towards Molecule Pseudo-labeling with Systematic Weak Supervision", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Juan_Molecular_Data_Programming_Towards_Molecule_Pseudo-labeling_with_Systematic_Weak_Supervision_CVPR_2024_paper.pdf", "details": "X Juan, K Zhou, N Liu, T Chen, X Wang - Proceedings of the IEEE/CVF Conference \u2026, 2024", "abstract": "The premise for the great advancement of molecular machine learning is dependent on a considerable amount of labeled data. In many real-world scenarios the labeled molecules are limited in quantity or laborious to derive. Recent pseudo-labeling \u2026"}, {"title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models", "link": "https://arxiv.org/pdf/2406.04306", "details": "L Aichberger, K Schweighofer, M Ielanskyi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) can suffer from hallucinations when generating text. These hallucinations impede various applications in society and industry by making LLMs untrustworthy. Current LLMs generate text in an autoregressive fashion by \u2026"}, {"title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models", "link": "https://aclanthology.org/2024.findings-naacl.18.pdf", "details": "Z Su, Z Lin, B Baixue, H Chen, S Hu, W Zhou, G Ding\u2026 - Findings of the Association \u2026, 2024", "abstract": "Generative language models are usually pre-trained on large text corpus via predicting the next token (ie, sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language \u2026"}, {"title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain", "link": "https://arxiv.org/pdf/2406.06435", "details": "B Hu, B Ray, A Leung, A Summerville, D Joy, C Funk\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In difficult decision-making scenarios, it is common to have conflicting opinions among expert human decision-makers as there may not be a single right answer. Such decisions may be guided by different attributes that can be used to characterize \u2026"}, {"title": "Adaptive Rank Selections for Low-Rank Approximation of Language Models", "link": "https://aclanthology.org/2024.naacl-long.13.pdf", "details": "S Gao, T Hua, YC Hsu, Y Shen, H Jin - Proceedings of the 2024 Conference of the \u2026, 2024", "abstract": "Abstract Singular Value Decomposition (SVD) or its weighted variants has significantly progressed in compressing language models. Previous works assume the same importance for all operations and assign the same number of ranks for \u2026"}, {"title": "ACES: Automatic Cohort Extraction System for Event-Stream Datasets", "link": "https://arxiv.org/pdf/2406.19653", "details": "J Xu, J Gallifant, AEW Johnson, M McDermott - arXiv preprint arXiv:2406.19653, 2024", "abstract": "Reproducibility remains a significant challenge in machine learning (ML) for healthcare. In this field, datasets, model pipelines, and even task/cohort definitions are often private, leading to a significant barrier in sharing, iterating, and \u2026"}, {"title": "Benchmarking Children's ASR with Supervised and Self-supervised Speech Foundation Models", "link": "https://arxiv.org/pdf/2406.10507", "details": "R Fan, NB Shankar, A Alwan - arXiv preprint arXiv:2406.10507, 2024", "abstract": "Speech foundation models (SFMs) have achieved state-of-the-art results for various speech tasks in supervised (eg Whisper) or self-supervised systems (eg WavLM). However, the performance of SFMs for child ASR has not been systematically \u2026"}]
