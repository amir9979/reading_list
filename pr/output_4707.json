[{"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "Multi-turn Response Selection with Commonsense-enhanced Language Models", "link": "https://arxiv.org/pdf/2407.18479", "details": "Y Wang, X Ren, T Chen, Y Dong, NQV Hung, J Tang - arXiv preprint arXiv \u2026, 2024", "abstract": "As a branch of advanced artificial intelligence, dialogue systems are prospering. Multi-turn response selection is a general research problem in dialogue systems. With the assistance of background information and pre-trained language models, the \u2026"}, {"title": "LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language Models", "link": "https://arxiv.org/pdf/2407.08966", "details": "Y Zhang, W Zhu, C He, L Zhang - arXiv preprint arXiv:2407.08966, 2024", "abstract": "Out-of-distribution (OOD) detection is crucial for model reliability, as it identifies samples from unknown classes and reduces errors due to unexpected inputs. Vision- Language Models (VLMs) such as CLIP are emerging as powerful tools for OOD \u2026"}, {"title": "Large language models for accurate disease detection in electronic health records", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/07/29/2024.07.27.24311106.full.pdf", "details": "N Burgisser, E Chalot, S Mehouachi, CP Buclin\u2026 - medRxiv, 2024", "abstract": "Importance: The use of large language models (LLMs) in medicine is increasing, with potential applications in electronic health records (EHR) to create patient cohorts or identify patients who meet clinical trial recruitment criteria. However, significant \u2026"}, {"title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering", "link": "https://arxiv.org/pdf/2407.21368", "details": "D Guo, D Terzopoulos - arXiv preprint arXiv:2407.21368, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in recent years, and they have been extended to the medical domain. Although demonstrating satisfactory performance on medical Visual Question Answering (VQA) tasks \u2026"}]
