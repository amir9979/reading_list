[{"title": "Deliberative alignment: Reasoning enables safer language models", "link": "https://arxiv.org/pdf/2412.16339", "details": "MY Guan, M Joglekar, E Wallace, S Jain, B Barak\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large-scale language models increasingly impact safety-critical domains, ensuring their reliable adherence to well-defined principles remains a fundamental challenge. We introduce Deliberative Alignment, a new paradigm that directly \u2026"}, {"title": "LEO: Boosting Mixture of Vision Encoders for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2501.06986", "details": "MN Azadani, J Riddell, S Sedwards, K Czarnecki - arXiv preprint arXiv:2501.06986, 2025", "abstract": "Enhanced visual understanding serves as a cornerstone for multimodal large language models (MLLMs). Recent hybrid MLLMs incorporate a mixture of vision experts to address the limitations of using a single vision encoder and excessively \u2026"}, {"title": "Utility-inspired Reward Transformations Improve Reinforcement Learning Training of Language Models", "link": "https://arxiv.org/pdf/2501.06248", "details": "RR Maura-Rivero, C Nagpal, R Patel, F Visin - arXiv preprint arXiv:2501.06248, 2025", "abstract": "Current methods that train large language models (LLMs) with reinforcement learning feedback, often resort to averaging outputs of multiple rewards functions during training. This overlooks crucial aspects of individual reward dimensions and \u2026"}, {"title": "Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark", "link": "https://arxiv.org/pdf/2501.05444%3F", "details": "Y Hao, J Gu, HW Wang, L Li, Z Yang, L Wang, Y Cheng - arXiv preprint arXiv \u2026, 2025", "abstract": "The ability to organically reason over and with both text and images is a pillar of human intelligence, yet the ability of Multimodal Large Language Models (MLLMs) to perform such multimodal reasoning remains under-explored. Existing benchmarks \u2026"}, {"title": "LLM360 K2: Scaling Up 360-Open-Source Large Language Models", "link": "https://arxiv.org/pdf/2501.07124", "details": "Z Liu, B Tan, H Wang, W Neiswanger, T Tao, H Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We detail the training of the LLM360 K2-65B model, scaling up our 360-degree OPEN SOURCE approach to the largest and most powerful models under project LLM360. While open-source LLMs continue to advance, the answer to\" How are the \u2026"}, {"title": "Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models", "link": "https://arxiv.org/pdf/2501.04945", "details": "Q Ren, J Zeng, Q He, J Liang, Y Xiao, W Zhou, Z Sun\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "It is crucial for large language models (LLMs) to follow instructions that involve multiple constraints. However, soft constraints are semantically related and difficult to verify through automated methods. These constraints remain a significant challenge \u2026"}, {"title": "Dynamic Skill Adaptation for Large Language Models", "link": "https://arxiv.org/pdf/2412.19361%3F", "details": "J Chen, D Yang - arXiv preprint arXiv:2412.19361, 2024", "abstract": "We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework to adapt novel and complex skills to Large Language Models (LLMs). Compared with previous work which learns from human-curated and static data in random orders \u2026"}, {"title": "Incorporating Molecular Knowledge in Large Language Models via Multimodal Modeling", "link": "https://ieeexplore.ieee.org/abstract/document/10838383/", "details": "Z Yang, K Lv, J Shu, Z Li, P Xiao - IEEE Transactions on Computational Social \u2026, 2025", "abstract": "In recent years, large language models (LLMs) represented by GPT-4 have achieved tremendous success in natural language-centered tasks. Nevertheless, LLMs face inherent challenges in tasks involving both natural language and molecular \u2026"}, {"title": "Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions", "link": "https://arxiv.org/pdf/2501.06699", "details": "A Hogan, XL Dong, D Vrande\u010di\u0107, G Weikum - arXiv preprint arXiv:2501.06699, 2025", "abstract": "Much has been discussed about how Large Language Models, Knowledge Graphs and Search Engines can be combined in a synergistic manner. A dimension largely absent from current academic discourse is the user perspective. In particular, there \u2026"}]
