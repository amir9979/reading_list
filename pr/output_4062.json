[{"title": "The ALCHEmist: Automated Labeling 500x CHEaper Than LLM Data Annotators", "link": "https://arxiv.org/pdf/2407.11004", "details": "TH Huang, C Cao, V Bhargava, F Sala - arXiv preprint arXiv:2407.11004, 2024", "abstract": "Large pretrained models can be used as annotators, helping replace or augment crowdworkers and enabling distilling generalist models into smaller specialist models. Unfortunately, this comes at a cost: employing top-of-the-line models often \u2026"}, {"title": "Addressing methodological and logistical challenges of using electronic health record (EHR) data for research", "link": "https://academic.oup.com/jamia/article/31/7/1449/7694014", "details": "S Bakken - Journal of the American Medical Informatics \u2026, 2024", "abstract": "In this editorial, I highlight five papers that focus on methodological and logistical aspects of using electronic health record (EHR) data for research. Using primary care EHR data from> 6 million people with Multiple Long-Term Conditions in England \u2026"}, {"title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs", "link": "https://arxiv.org/pdf/2406.14282", "details": "J Wang, M Chen, B Hu, D Yang, Z Liu, Y Shen, P Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Improving the performance of large language models (LLMs) in complex question- answering (QA) scenarios has always been a research focal point. Recent studies have attempted to enhance LLMs' performance by combining step-wise planning \u2026"}, {"title": "Unlocking Continual Learning Abilities in Language Models", "link": "https://arxiv.org/pdf/2406.17245", "details": "W Du, S Cheng, T Luo, Z Qiu, Z Huang, KC Cheung\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) exhibit impressive performance and generalization capabilities. However, LMs struggle with the persistent challenge of catastrophic forgetting, which undermines their long-term sustainability in continual learning (CL) \u2026"}, {"title": "Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models", "link": "https://arxiv.org/pdf/2406.14091", "details": "D Lee, D Rim, M Choi, J Choo - arXiv preprint arXiv:2406.14091, 2024", "abstract": "Although language models (LMs) demonstrate exceptional capabilities on various tasks, they are potentially vulnerable to extraction attacks, which represent a significant privacy risk. To mitigate the privacy concerns of LMs, machine unlearning \u2026"}, {"title": "Language models, like humans, show content effects on reasoning tasks", "link": "https://academic.oup.com/pnasnexus/article/3/7/pgae233/7712372", "details": "AK Lampinen, I Dasgupta, SCY Chan, HR Sheahan\u2026 - PNAS nexus, 2024", "abstract": "Abstract reasoning is a key ability for an intelligent system. Large language models (LMs) achieve above-chance performance on abstract reasoning tasks but exhibit many imperfections. However, human abstract reasoning is also imperfect. Human \u2026"}, {"title": "Information Guided Regularization for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2406.14005", "details": "M Sharma, N Muralidhar, S Xu, RB Yosuf\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The pretraining-fine-tuning paradigm has been the de facto strategy for transfer learning in modern language modeling. With the understanding that task adaptation in LMs is often a function of parameters shared across tasks, we argue that a more \u2026"}, {"title": "Mitigating Social Biases in Language Models through Unlearning", "link": "https://arxiv.org/pdf/2406.13551", "details": "O Dige, D Singh, TF Yau, Q Zhang, B Bolandraftar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Mitigating bias in language models (LMs) has become a critical problem due to the widespread deployment of LMs. Numerous approaches revolve around data pre- processing and fine-tuning of language models, tasks that can be both time \u2026"}, {"title": "Towards Adversarially Robust Vision-Language Models: Insights from Design Choices and Prompt Formatting Techniques", "link": "https://arxiv.org/pdf/2407.11121", "details": "R Bhagwatkar, S Nayak, R Bayat, A Roger, DZ Kaplan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Models (VLMs) have witnessed a surge in both research and real- world applications. However, as they are becoming increasingly prevalent, ensuring their robustness against adversarial attacks is paramount. This work systematically \u2026"}]
