[{"title": "Enhancing radiology report generation through pre-trained language models", "link": "https://link.springer.com/article/10.1007/s13748-024-00358-5", "details": "G Leonardi, L Portinale, A Santomauro - Progress in Artificial Intelligence, 2024", "abstract": "In the healthcare field, the ability to integrate and process data from various modalities, such as medical images, clinical notes, and patient records, plays a central role in enabling Artificial Intelligence models to provide more informed \u2026"}, {"title": "HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models", "link": "https://arxiv.org/pdf/2412.08378", "details": "S Zhu, W Dong, J Song, Y Guo, B Zheng - arXiv preprint arXiv:2412.08378, 2024", "abstract": "Recently, there has been growing interest in the capability of multimodal large language models (MLLMs) to process high-resolution images. A common approach currently involves dynamically cropping the original high-resolution image into \u2026"}, {"title": "Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation", "link": "https://arxiv.org/pdf/2501.03545", "details": "C Samarinas, A Krubner, A Salemi, Y Kim, H Zamani - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper presents ICAT, an evaluation framework for measuring coverage of diverse factual information in long-form text generation. ICAT breaks down a long output text into a list of atomic claims and not only verifies each claim through \u2026"}, {"title": "MiniGPT-Pancreas: Multimodal Large Language Model for Pancreas Cancer Classification and Detection", "link": "https://arxiv.org/pdf/2412.15925", "details": "A Moglia, EC Nastasio, L Mainardi, P Cerveri - arXiv preprint arXiv:2412.15925, 2024", "abstract": "Problem: Pancreas radiological imaging is challenging due to the small size, blurred boundaries, and variability of shape and position of the organ among patients. Goal: In this work we present MiniGPT-Pancreas, a Multimodal Large Language Model \u2026"}, {"title": "MiniMedGPT: Efficient Large Vision-Language Model for medical Visual Question Answering", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525000017", "details": "AR Alsabbagh, T Mansour, M Al-Kharabsheh\u2026 - Pattern Recognition Letters, 2025", "abstract": "Abstract While Large Vision-Language Models (LVLMs) like GPT-4 and Gemini demonstrate significant potential, their utilization in the medical domain remains largely unexplored. This is due to challenges attributed to prolonged training and \u2026"}, {"title": "Biased or Flawed? Mitigating Stereotypes in Generative Language Models by Addressing Task-Specific Flaws", "link": "https://arxiv.org/pdf/2412.11414%3F", "details": "A Jha, S Kabra, CK Reddy - arXiv preprint arXiv:2412.11414, 2024", "abstract": "Recent studies have shown that generative language models often reflect and amplify societal biases in their outputs. However, these studies frequently conflate observed biases with other task-specific shortcomings, such as comprehension \u2026"}, {"title": "Recalibrated cross-modal alignment network for radiology report generation with weakly supervised contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425000168", "details": "X Hou, X Li, Z Liu, S Sang, M Lu, Y Zhang - Expert Systems with Applications, 2025", "abstract": "Automatic radiology report generation is rapidly becoming an essential method for medical diagnosis and precision medicine, which will help clinical doctors make more informed decisions and achieve better results. Most previous studies mainly \u2026"}, {"title": "HC-LLM: Historical-Constrained Large Language Models for Radiology Report Generation", "link": "https://arxiv.org/pdf/2412.11070", "details": "T Liu, J Wang, Y Hu, M Li, J Yi, X Chang, J Gao, B Yin - arXiv preprint arXiv \u2026, 2024", "abstract": "Radiology report generation (RRG) models typically focus on individual exams, often overlooking the integration of historical visual or textual data, which is crucial for patient follow-ups. Traditional methods usually struggle with long sequence \u2026"}, {"title": "ReFF: Reinforcing Format Faithfulness in Language Models across Varied Tasks", "link": "https://arxiv.org/pdf/2412.09173%3F", "details": "J Yao, H Huang, Z Liu, H Wen, W Su, B Qian, Y Guo - arXiv preprint arXiv:2412.09173, 2024", "abstract": "Following formatting instructions to generate well-structured content is a fundamental yet often unmet capability for large language models (LLMs). To study this capability, which we refer to as format faithfulness, we present FormatBench, a comprehensive \u2026"}]
