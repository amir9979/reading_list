[{"title": "SoftMCL: Soft Momentum Contrastive Learning for Fine-grained Sentiment-aware Pre-training", "link": "https://arxiv.org/pdf/2405.01827", "details": "J Wang, LC Yu, X Zhang - arXiv preprint arXiv:2405.01827, 2024", "abstract": "The pre-training for language models captures general language understanding but fails to distinguish the affective impact of a particular context to a specific word. Recent works have sought to introduce contrastive learning (CL) for sentiment-aware \u2026"}, {"title": "Check for updates Generating Type-Related Instances and Metric Learning to Overcoming Language Priors in VQA", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DP3AJEQAAQBAJ%26oi%3Dfnd%26pg%3DPA310%26ots%3DcmsEAam3dV%26sig%3DTEHTcPAjSWaCNKdDF0MvsjistzA", "details": "C Sun, Y Yang, Z Yu, C Guo, J Zhao - Advances in Brain Inspired Cognitive Systems: 13th \u2026", "abstract": "Visual Question Answering (VQA) is a multimodal task that integrates computer vision and natural language processing. It poses a challenge in the field due to language prior, which is influenced by the dataset and the underlying model \u2026"}]
