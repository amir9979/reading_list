[{"title": "Experience Retrieval-Augmentation with Electronic Health Records Enables Accurate Discharge QA", "link": "https://arxiv.org/pdf/2503.17933", "details": "J Ou, T Huang, Y Zhao, Z Yu, P Lu, R Ying - arXiv preprint arXiv:2503.17933, 2025", "abstract": "To improve the reliability of Large Language Models (LLMs) in clinical applications, retrieval-augmented generation (RAG) is extensively applied to provide factual medical knowledge. However, beyond general medical knowledge from open-ended \u2026"}, {"title": "Process-based self-rewarding language models", "link": "https://arxiv.org/pdf/2503.03746", "details": "S Zhang, X Liu, X Zhang, J Liu, Z Luo, S Huang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' \u2026"}]
