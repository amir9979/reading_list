[{"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}, {"title": "Multi-Sense Embeddings for Language Models and Knowledge Distillation", "link": "https://arxiv.org/pdf/2504.06036", "details": "Q Wang, MJ Zaki, G Kollias, V Kalantzis - arXiv preprint arXiv:2504.06036, 2025", "abstract": "Transformer-based large language models (LLMs) rely on contextual embeddings which generate different (continuous) representations for the same token depending on its surrounding context. Nonetheless, words and tokens typically have a limited \u2026"}, {"title": "Mixture-of-Personas Language Models for Population Simulation", "link": "https://arxiv.org/pdf/2504.05019", "details": "N Bui, HT Nguyen, S Kumar, J Theodore, W Qiu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Advances in Large Language Models (LLMs) paved the way for their emerging applications in various domains, such as human behavior simulations, where LLMs could augment human-generated data in social science research and machine \u2026"}, {"title": "Information-Theoretic Reward Decomposition for Generalizable RLHF", "link": "https://arxiv.org/pdf/2504.06020", "details": "L Mao, H Xu, A Zhang, W Zhang, C Bai - arXiv preprint arXiv:2504.06020, 2025", "abstract": "A generalizable reward model is crucial in Reinforcement Learning from Human Feedback (RLHF) as it enables correctly evaluating unseen prompt-response pairs. However, existing reward models lack this ability, as they are typically trained by \u2026"}, {"title": "V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric Capabilities in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2504.06148", "details": "X Zheng, L Li, Z Yang, P Yu, AJ Wang, R Yan, Y Yao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have led to significant improvements across various multimodal benchmarks. However, as evaluations shift from static datasets to open-world, dynamic environments, current \u2026"}, {"title": "Breach in the Shield: Unveiling the Vulnerabilities of Large Language Models", "link": "https://arxiv.org/pdf/2504.03714", "details": "R Dai, R Yang, F Zhou, H Zhu - arXiv preprint arXiv:2504.03714, 2025", "abstract": "Large Language Models (LLMs) and Vision-Language Models (VLMs) have become essential to general artificial intelligence, exhibiting remarkable capabilities in task understanding and problem-solving. However, the real-world reliability of these \u2026"}, {"title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models", "link": "https://arxiv.org/pdf/2504.06214", "details": "C Xu, W Ping, P Xu, Z Liu, B Wang, M Shoeybi, B Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context learning, and inference-time scaling, all of which require models to process and reason over long sequences of text and \u2026"}, {"title": "Can large language models independently complete tasks? A dynamic evaluation framework for multi-turn task planning and completion", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225008070", "details": "J Gao, J Cui, H Wu, L Xiang, H Zhao, X Li, M Fang\u2026 - Neurocomputing, 2025", "abstract": "Large language models (LLMs) are increasingly relied upon for multi-turn dialogue to conduct complex tasks. However, existing benchmarks mainly evaluate LLMs as agents, overlooking their potential as independent systems to accomplish complex \u2026"}, {"title": "DiaTool-DPO: Multi-Turn Direct Preference Optimization for Tool-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2504.02882", "details": "S Jung, D Lee, S Lee, G Seo, D Lee, B Ko, J Cho\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Tool-Augmented Larage Language Models (TA-LLMs) have shown promise in real- world applications, but face challenges in handling incomplete queries and out-of- scope requests. While existing approaches rely mainly on Supervised Fine-Tuning \u2026"}]
