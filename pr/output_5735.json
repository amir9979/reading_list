[{"title": "XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training", "link": "https://arxiv.org/pdf/2407.19546", "details": "B Wu, Y Xie, Z Zhang, MH Phan, Q Chen, L Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-and-language pretraining (VLP) in the medical field utilizes contrastive learning on image-text pairs to achieve effective transfer across tasks. Yet, current VLP approaches with the masked modelling strategy face two challenges when \u2026"}]
