'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Emergent Abilities in Reduced-Scale Generative Languag'
[{"title": "CodecLM: Aligning Language Models with Tailored Synthetic Data", "link": "https://arxiv.org/pdf/2404.05875", "details": "Z Wang, CL Li, V Perot, LT Le, J Miao, Z Zhang, CY Lee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next- token prediction objective and users' actual goals. To reduce the labor and time cost \u2026"}, {"title": "NeRF-MAE: Masked AutoEncoders for Self Supervised 3D representation Learning for Neural Radiance Fields", "link": "https://arxiv.org/pdf/2404.01300", "details": "MZ Irshad, S Zakahrov, V Guizilini, A Gaidon, Z Kira\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Neural fields excel in computer vision and robotics due to their ability to understand the 3D visual world such as inferring semantics, geometry, and dynamics. Given the capabilities of neural fields in densely representing a 3D scene from 2D images, we \u2026"}, {"title": "Source-Aware Training Enables Knowledge Attribution in Language Models", "link": "https://arxiv.org/pdf/2404.01019", "details": "M Khalifa, D Wadden, E Strubell, H Lee, L Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) learn a vast amount of knowledge during pretraining, but they are often oblivious to the source (s) of such knowledge. We investigate the problem of intrinsic source citation, where LLMs are required to cite the pretraining \u2026"}, {"title": "SERPENT-VLM: Self-Refining Radiology Report Generation Using Vision Language Models", "link": "https://arxiv.org/pdf/2404.17912", "details": "MN Kapadnis, S Patnaik, A Nandy, S Ray, P Goyal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large Language Models (MLLMs) can automate the creation of accurate and coherent radiological reports. Existing methods often hallucinate details in text-based reports \u2026"}, {"title": "BlenderAlchemy: Editing 3D Graphics with Vision-Language Models", "link": "https://arxiv.org/abs/2404.17672", "details": "I Huang, G Yang, L Guibas - arXiv preprint arXiv:2404.17672, 2024", "abstract": "Graphics design is important for various applications, including movie production and game design. To create a high-quality scene, designers usually need to spend hours in software like Blender, in which they might need to interleave and repeat \u2026"}, {"title": "More Room for Language: Investigating the Effect of Retrieval on Language Models", "link": "https://arxiv.org/pdf/2404.10939", "details": "D Samuel, LGG Charpentier, S Wold - arXiv preprint arXiv:2404.10939, 2024", "abstract": "Retrieval-augmented language models pose a promising alternative to standard language modeling. During pretraining, these models search in a corpus of documents for contextually relevant information that could aid the language \u2026"}, {"title": "Medical Vision-Language Pre-Training for Brain Abnormalities", "link": "https://arxiv.org/pdf/2404.17779", "details": "M Monajatipoor, ZY Dou, A Chien, N Peng, KW Chang - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models have become increasingly powerful for tasks that require an understanding of both visual and linguistic elements, bridging the gap between these modalities. In the context of multimodal clinical AI, there is a growing need for models \u2026"}, {"title": "Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library", "link": "https://arxiv.org/pdf/2404.18722", "details": "S Tarride, Y Schneider, M Generali-Lince, M Boillet\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "PyLaia is one of the most popular open-source software for Automatic Text Recognition (ATR), delivering strong performance in terms of speed and accuracy. In this paper, we outline our recent contributions to the PyLaia library, focusing on the \u2026"}, {"title": "ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback", "link": "https://arxiv.org/pdf/2404.00934", "details": "Z Hou, Y Niu, Z Du, X Zhang, X Liu, A Zeng, Q Zheng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "ChatGLM is a free-to-use AI service powered by the ChatGLM family of large language models (LLMs). In this paper, we present the ChatGLM-RLHF pipeline--a reinforcement learning from human feedback (RLHF) system--designed to enhance \u2026"}]
