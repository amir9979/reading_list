[{"title": "Scaling Laws for Linear Complexity Language Models", "link": "https://arxiv.org/pdf/2406.16690", "details": "X Shen, D Li, R Leng, Z Qin, W Sun, Y Zhong - arXiv preprint arXiv:2406.16690, 2024", "abstract": "The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their \u2026"}, {"title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization", "link": "https://arxiv.org/pdf/2406.16743", "details": "Z Zhao, X Zhang, K Xu, X Hu, R Zhang, Z Du, Q Guo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the widespread application of Large Language Models (LLMs), it has become a significant concern to ensure their safety and prevent harmful responses. While current safe-alignment methods based on instruction fine-tuning and Reinforcement \u2026"}, {"title": "Understanding the Role of User Profile in the Personalization of Large Language Models", "link": "https://arxiv.org/pdf/2406.17803", "details": "B Wu, Z Shi, HA Rahmani, V Ramineni, E Yilmaz - arXiv preprint arXiv:2406.17803, 2024", "abstract": "Utilizing user profiles to personalize Large Language Models (LLMs) has been shown to enhance the performance on a wide range of tasks. However, the precise role of user profiles and their effect mechanism on LLMs remains unclear. This study \u2026"}, {"title": "Adversarial Black Box Attacks to Disrupt Large Language Models via Reinforcement Learning", "link": "https://practical-dl.github.io/2024/short_paper/4/CameraReady/4.pdf", "details": "WTJ Le, LJ Sern, YXM Tan", "abstract": "Large Language Models (LLMs) are effective in solving natural language processing (NLP) tasks, ie question answering and text generation. Recent works showed the possibility of generating adversarial suffixes to get valid responses from LLMs to \u2026"}, {"title": "Lifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models", "link": "https://arxiv.org/pdf/2406.18746", "details": "G Tziafas, H Kasaei - arXiv preprint arXiv:2406.18746, 2024", "abstract": "Large Language Models (LLMs) have emerged as a new paradigm for embodied reasoning and control, most recently by generating robot policy code that utilizes a custom library of vision and control primitive skills. However, prior arts fix their skills \u2026"}, {"title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models", "link": "https://arxiv.org/pdf/2406.16783", "details": "R Maheshwary, V Yadav, H Nguyen, K Mahajan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models (LLMs) to follow instructions. Numerous effective IFT datasets have been proposed in the recent past, but most focus on high resource languages such as English. In this work \u2026"}, {"title": "Enhancing Travel Decision-Making: A Contrastive Learning Approach for Personalized Review Rankings in Accommodations", "link": "https://arxiv.org/pdf/2407.00787", "details": "R Igebaria, E Fainman, S Mizrachi, M Beladev, F Wang - arXiv preprint arXiv \u2026, 2024", "abstract": "User-generated reviews significantly influence consumer decisions, particularly in the travel domain when selecting accommodations. This paper contribution comprising two main elements. Firstly, we present a novel dataset of authentic guest \u2026"}, {"title": "Entropy-Based Decoding for Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2406.17519", "details": "Z Qiu, Z Ou, B Wu, J Li, A Liu, I King - arXiv preprint arXiv:2406.17519, 2024", "abstract": "Augmenting Large Language Models (LLMs) with retrieved external knowledge has proven effective for improving the factual accuracy of generated responses. Despite their success, retrieval-augmented LLMs still face the distractibility issue, where the \u2026"}, {"title": "Rethinking Entity-level Unlearning for Large Language Models", "link": "https://arxiv.org/pdf/2406.15796", "details": "W Ma, X Feng, W Zhong, L Huang, Y Ye, B Qin - arXiv preprint arXiv:2406.15796, 2024", "abstract": "Large language model unlearning has gained increasing attention due to its potential to mitigate security and privacy concerns. Current research predominantly focuses on Instance-level unlearning, specifically aiming at forgetting predefined \u2026"}]
