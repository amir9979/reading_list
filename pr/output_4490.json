[{"title": "Evaluating the necessity of the multiple metrics for assessing explainable AI: A critical examination", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224010531", "details": "M Pawlicki, A Pawlicka, F Uccello, S Szelest\u2026 - Neurocomputing, 2024", "abstract": "This paper investigates the specific properties of Explainable Artificial Intelligence (xAI), particularly when implemented in AI/ML models across high-stakes sectors, in this case cybersecurity. The authors execute a comprehensive systematic review of \u2026"}, {"title": "Differential Privacy of Cross-Attention with Provable Guarantee", "link": "https://arxiv.org/pdf/2407.14717", "details": "J Gu, Y Liang, Z Shi, Z Song, Y Zhou - arXiv preprint arXiv:2407.14717, 2024", "abstract": "Cross-attention has become a fundamental module nowadays in many important artificial intelligence applications, eg, retrieval-augmented generation (RAG), system prompt, guided stable diffusion, and many so on. Ensuring cross-attention privacy is \u2026"}, {"title": "Demystifying Verbatim Memorization in Large Language Models", "link": "https://arxiv.org/pdf/2407.17817", "details": "J Huang, D Yang, C Potts - arXiv preprint arXiv:2407.17817, 2024", "abstract": "Large Language Models (LLMs) frequently memorize long sequences verbatim, often with serious legal and privacy implications. Much prior work has studied such verbatim memorization using observational data. To complement such work, we \u2026"}]
