[{"title": "Towards Scalable and Cross-Lingual Specialist Language Models for Oncology", "link": "https://arxiv.org/pdf/2503.08323%3F", "details": "M Rohanian, T Mehra, N Miglino, F Nooralahzadeh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Clinical oncology generates vast, unstructured data that often contain inconsistencies, missing information, and ambiguities, making it difficult to extract reliable insights for data-driven decision-making. General-purpose large language \u2026"}, {"title": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models", "link": "https://arxiv.org/pdf/2503.18923", "details": "M Cao, P Hu, Y Wang, J Gu, H Tang, H Zhao, J Dong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we \u2026"}, {"title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation", "link": "https://arxiv.org/pdf/2504.02438", "details": "C Cheng, J Guan, W Wu, R Yan - arXiv preprint arXiv:2504.02438, 2025", "abstract": "Long-form video processing fundamentally challenges vision-language models (VLMs) due to the high computational costs of handling extended temporal sequences. Existing token pruning and feature merging methods often sacrifice \u2026"}, {"title": "Auditing language models for hidden objectives", "link": "https://arxiv.org/pdf/2503.10965%3F", "details": "S Marks, J Treutlein, T Bricken, J Lindsey, J Marcus\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We study the feasibility of conducting alignment audits: investigations into whether models have undesired objectives. As a testbed, we train a language model with a hidden objective. Our training pipeline first teaches the model about exploitable \u2026"}, {"title": "RoMedFormer: A Rotary-Embedding Transformer Foundation Model for 3D Genito-Pelvic Structure Segmentation in MRI and CT", "link": "https://arxiv.org/pdf/2503.14304", "details": "Y Li, M Hu, RLJ Qiu, M Thor, A Williams, D Marshall\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deep learning-based segmentation of genito-pelvic structures in MRI and CT is crucial for applications such as radiation therapy, surgical planning, and disease diagnosis. However, existing segmentation models often struggle with \u2026"}, {"title": "Map: Evaluation and multi-agent enhancement of large language models for inpatient pathways", "link": "https://arxiv.org/pdf/2503.13205%3F", "details": "Z Chen, Z Peng, X Liang, C Wang, P Liang, L Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited \u2026"}, {"title": "Alignment for Efficient Tool Calling of Large Language Models", "link": "https://arxiv.org/pdf/2503.06708%3F", "details": "H Xu, Z Wang, Z Zhu, L Pan, X Chen, L Chen, K Yu - arXiv preprint arXiv:2503.06708, 2025", "abstract": "Recent advancements in tool learning have enabled large language models (LLMs) to integrate external tools, enhancing their task performance by expanding their knowledge boundaries. However, relying on tools often introduces tradeoffs between \u2026"}, {"title": "Estimating depression severity in narrative clinical notes using large language models", "link": "https://www.sciencedirect.com/science/article/pii/S016503272500566X", "details": "TH McCoy, VM Castro, RH Perlis - Journal of Affective Disorders, 2025", "abstract": "Background Depression treatment guidelines emphasize measurement-based care using patient-reported outcome measures, yet their impact on narrative documentation quality remains underexplored. Methods We sampled 18,000 \u2026"}, {"title": "BioVLM-T: A temporal framework for radiology report generation using pre-trained vision language foundational models", "link": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13410/134100W/BioVLM-T--A-temporal-framework-for-radiology-report-generation/10.1117/12.3047498.short", "details": "A Kasturi, A Vosoughi, N Hadjiyski, A Wism\u00fcller - Medical Imaging 2025: Clinical and \u2026, 2025", "abstract": "In this study, we propose BioVLF-T, a novel automatic radiology report generation framework built on a bio-vision language foundational model (VLF) with a temporal framework. BioVLF-T enhances the contextual understanding of the vision-language \u2026"}]
