[{"title": "Corrections Meet Explanations: A Unified Framework for Explainable Grammatical Error Correction", "link": "https://arxiv.org/pdf/2502.15261", "details": "J Ye, S Qin, Y Li, HT Zheng, S Wang, Q Wen - arXiv preprint arXiv:2502.15261, 2025", "abstract": "Grammatical Error Correction (GEC) faces a critical challenge concerning explainability, notably when GEC systems are designed for language learners. Existing research predominantly focuses on explaining grammatical errors extracted \u2026"}, {"title": "Towards Efficient Automatic Self-Pruning of Large Language Models", "link": "https://arxiv.org/pdf/2502.14413", "details": "W Huang, Y Zhang, X Zheng, F Chao, R Ji - arXiv preprint arXiv:2502.14413, 2025", "abstract": "Despite exceptional capabilities, Large Language Models (LLMs) still face deployment challenges due to their enormous size. Post-training structured pruning is a promising solution that prunes LLMs without the need for retraining, reducing \u2026"}, {"title": "The Relationship Between Reasoning and Performance in Large Language Models--o3 (mini) Thinks Harder, Not Longer", "link": "https://arxiv.org/pdf/2502.15631", "details": "M Ballon, A Algaba, V Ginis - arXiv preprint arXiv:2502.15631, 2025", "abstract": "Large language models have demonstrated remarkable progress in mathematical reasoning, leveraging chain-of-thought and test-time compute scaling. However, many open questions remain regarding the interplay between reasoning token \u2026"}, {"title": "CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning", "link": "https://arxiv.org/pdf/2502.02390%3F", "details": "J Pan, S Deng, S Huang - arXiv preprint arXiv:2502.02390, 2025", "abstract": "Research on LLM technologies is rapidly emerging, with most of them employing a'fast thinking'approach to inference. Most LLMs generate the final result based solely on a single query and LLM's reasoning capabilities. However, with the advent \u2026"}]
