[{"title": "R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning", "link": "https://arxiv.org/pdf/2504.11195", "details": "L Sheng, J Liang, Z Wang, R He - arXiv preprint arXiv:2504.11195, 2025", "abstract": "Vision-language models (VLMs), such as CLIP, have gained significant popularity as foundation models, with numerous fine-tuning methods developed to enhance performance on downstream tasks. However, due to their inherent vulnerability and \u2026"}, {"title": "Automated Grading Through Contrastive Learning: A Gradient Analysis and Feature Ablation Approach", "link": "https://www.mdpi.com/2504-4990/7/2/41", "details": "M Soka\u010d, M Fabijani\u0107, I Mekterovi\u0107, L Mr\u0161i\u0107 - Machine Learning and Knowledge \u2026, 2025", "abstract": "As programming education becomes increasingly complex, grading student code has become a challenging task. Traditional methods, such as dynamic and static analysis, offer foundational approaches but often fail to provide granular insights \u2026"}, {"title": "CLOC: Contrastive Learning for Ordinal Classification with Multi-Margin N-pair Loss", "link": "https://arxiv.org/pdf/2504.17813", "details": "D Pitawela, G Carneiro, HT Chen - arXiv preprint arXiv:2504.17813, 2025", "abstract": "In ordinal classification, misclassifying neighboring ranks is common, yet the consequences of these errors are not the same. For example, misclassifying benign tumor categories is less consequential, compared to an error at the pre-cancerous to \u2026"}, {"title": "MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation", "link": "https://arxiv.org/pdf/2504.16576", "details": "X Guo, T Zhang, F Wang, X Wang, X Zhang, X Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The burgeoning presence of multimodal content-sharing platforms propels the development of personalized recommender systems. Previous works usually suffer from data sparsity and cold-start problems, and may fail to adequately explore \u2026"}, {"title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data", "link": "https://arxiv.org/pdf/2504.09967", "details": "X Zhu, F Mo, Z Zhang, J Wang, Y Shi, M Wu, C Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The emergence of medical generalist foundation models has revolutionized conventional task-specific model development paradigms, aiming to better handle multiple tasks through joint training on large-scale medical datasets. However, recent \u2026"}, {"title": "COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts", "link": "https://arxiv.org/pdf/2504.10158%3F", "details": "J Li, X Zhang, H Zou, Y Guo, R Xu, Y Liu, C Zhu, Y He\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Current object detectors often suffer significant perfor-mance degradation in real- world applications when encountering distributional shifts. Consequently, the out-of- distribution (OOD) generalization capability of object detectors has garnered \u2026"}, {"title": "Event-Based Eye Tracking. 2025 event-based vision workshop", "link": "https://arxiv.org/pdf/2504.18249", "details": "Q Chen, C Gao, M Liu, D Perrone, YR Pei, Z Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This survey serves as a review for the 2025 Event-Based Eye Tracking Challenge organized as part of the 2025 CVPR event-based vision workshop. This challenge focuses on the task of predicting the pupil center by processing event camera \u2026"}, {"title": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "link": "https://arxiv.org/pdf/2505.03401", "details": "S Song, H Tang, H Yang, X Li - arXiv preprint arXiv:2505.03401, 2025", "abstract": "Radiology Report Generation (RRG) automates the creation of radiology reports from medical imaging, enhancing the efficiency of the reporting process. Longitudinal Radiology Report Generation (LRRG) extends RRG by incorporating the ability to \u2026"}, {"title": "A Survey on Hallucination in Large Language and Foundation Models", "link": "https://www.preprints.org/frontend/manuscript/c5f20698cf44a95d88e568ddde2066e0/download_pub", "details": "P Ahadian, Q Guan - 2025", "abstract": "Generative text models, particularly large language models (LLMs) and foundation models, have influenced numerous fields, including high-quality text generation, reasoning, and multimodal synthesis. These models have been widely applied in \u2026"}]
