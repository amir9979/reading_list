[{"title": "TS-TCD: Triplet-Level Cross-Modal Distillation for Time-Series Forecasting Using Large Language Models", "link": "https://arxiv.org/pdf/2409.14978", "details": "P Wang, H Zheng, S Dai, W Yue, W Zhu, X Wang - arXiv preprint arXiv:2409.14978, 2024", "abstract": "In recent years, large language models (LLMs) have shown great potential in time- series analysis by capturing complex dependencies and improving predictive performance. However, existing approaches often struggle with modality alignment \u2026"}, {"title": "Fine-Tuning Personalization in Federated Learning to Mitigate Adversarial Clients", "link": "https://arxiv.org/pdf/2409.20329", "details": "Y Allouah, AE Mrini, R Guerraoui, N Gupta, R Pinot - arXiv preprint arXiv:2409.20329, 2024", "abstract": "Federated learning (FL) is an appealing paradigm that allows a group of machines (aka clients) to learn collectively while keeping their data local. However, due to the heterogeneity between the clients' data distributions, the model obtained through the \u2026"}, {"title": "Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation", "link": "https://ui.adsabs.harvard.edu/abs/2024arXiv241001847K/abstract", "details": "O Kulkarni, R Chandra - arXiv e-prints, 2024", "abstract": "Medical time series datasets feature missing values that need data imputation methods, however, conventional machine learning models fall short due to a lack of uncertainty quantification in predictions. Among these models, the CATSI (Context \u2026"}, {"title": "Online Zero-Shot Classification with CLIP Supplementary", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09976-supp.pdf", "details": "Q Qian, J Hu", "abstract": "Online Zero-Shot Classification with CLIP Supplementary Page 1 Online Zero-Shot Classification with CLIP Supplementary Qi Qian1 \u22c6 and Juhua Hu2 1 Alibaba Group, Bellevue, WA 98004, USA 2 School of Engineering and Technology, University of \u2026"}]
