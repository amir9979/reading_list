'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Addax: Memory-Efficient Fine-Tuning of Language Models'
[{"title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors", "link": "https://arxiv.org/pdf/2404.17807", "details": "G Li, P Wang, J Liu, Y Guo, K Ji, Z Shang, Z Xu - arXiv preprint arXiv:2404.17807, 2024", "abstract": "Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot \u2026"}, {"title": "Tele-FLM Technical Report", "link": "https://arxiv.org/pdf/2404.16645", "details": "X Li, Y Yao, X Jiang, X Fang, C Wang, X Liu, Z Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have showcased profound capabilities in language understanding and generation, facilitating a wide array of applications. However, there is a notable paucity of detailed, open-sourced methodologies on efficiently \u2026"}, {"title": "Temporal Scaling Law for Large Language Models", "link": "https://arxiv.org/pdf/2404.17785", "details": "Y Xiong, X Chen, X Ye, H Chen, Z Lin, H Lian, J Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, Large Language Models (LLMs) are widely adopted in a wide range of tasks, leading to increasing attention towards the research on how scaling LLMs affects their performance. Existing works, termed as Scaling Laws, have discovered \u2026"}, {"title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation", "link": "https://arxiv.org/pdf/2404.11216", "details": "Z He, H Jiang, Z Wang, Y Yang, L Qiu, L Qiu - arXiv preprint arXiv:2404.11216, 2024", "abstract": "The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task \u2026"}, {"title": "TAXI: Evaluating Categorical Knowledge Editing for Language Models", "link": "https://arxiv.org/pdf/2404.15004", "details": "D Powell, W Gerych, T Hartvigsen - arXiv preprint arXiv:2404.15004, 2024", "abstract": "Humans rarely learn one fact in isolation. Instead, learning a new fact induces knowledge of other facts about the world. For example, in learning a korat is a type of cat, you also infer it is a mammal and has claws, ensuring your model of the world is \u2026"}, {"title": "OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework", "link": "https://arxiv.org/pdf/2404.14619%3Ftrk%3Dpublic_post_comment-text", "details": "S Mehta, MH Sekhavat, Q Cao, M Horton, Y Jin, C Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The reproducibility and transparency of large language models are crucial for advancing open research, ensuring the trustworthiness of results, and enabling investigations into data and model biases, as well as potential risks. To this end, we \u2026"}, {"title": "KS-LLM: Knowledge Selection of Large Language Models with Evidence Document for Question Answering", "link": "https://arxiv.org/pdf/2404.15660", "details": "X Zheng, F Che, J Wu, S Zhang, S Nie, K Liu, J Tao - arXiv preprint arXiv:2404.15660, 2024", "abstract": "Large language models (LLMs) suffer from the hallucination problem and face significant challenges when applied to knowledge-intensive tasks. A promising approach is to leverage evidence documents as extra supporting knowledge, which \u2026"}, {"title": "Towards a Holistic Evaluation of LLMs on Factual Knowledge Recall", "link": "https://arxiv.org/pdf/2404.16164", "details": "J Yuan, L Pan, CW Hang, J Guo, J Jiang, B Min, P Ng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have shown remarkable performance on a variety of NLP tasks, and are being rapidly adopted in a wide range of use cases. It is therefore of vital importance to holistically evaluate the factuality of their generated outputs, as \u2026"}, {"title": "Instruction Matters, a Simple yet Effective Task Selection Approach in Instruction Tuning for Specific Tasks", "link": "https://arxiv.org/pdf/2404.16418", "details": "C Lee, J Han, S Ye, SJ Choi, H Lee, K Bae - arXiv preprint arXiv:2404.16418, 2024", "abstract": "Instruction tuning has shown its ability to not only enhance zero-shot generalization across various tasks but also its effectiveness in improving the performance of specific tasks. A crucial aspect in instruction tuning for a particular task is a strategic \u2026"}]
