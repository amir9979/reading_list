[{"title": "Counterfactual and Prototypical Explanations for Tabular Data via Interpretable Latent Space", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10753432.pdf", "details": "S Piaggesi, F Bodria, R Guidotti, F Giannotti\u2026 - IEEE Access, 2024", "abstract": "Artificial Intelligence decision-making systems have dramatically increased their predictive power in recent years, beating humans in many different specific tasks. However, with increased performance has come an increase in the complexity of the \u2026"}, {"title": "UniEmbedding: Learning Universal Multi-Modal Multi-Domain Item Embeddings via User-View Contrastive Learning", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3680098", "details": "B Dai, Z Du, J Zhu, J Xu, D Zou, Q Dai, Z Dong\u2026 - Proceedings of the 33rd \u2026, 2024", "abstract": "Learning high-quality item embeddings is crucial for recommendation tasks such as matching and ranking. However, existing methods often rely on ID-based item embeddings learned end-to-end with downstream recommendation models, which \u2026"}, {"title": "On Training Data Influence of GPT Models", "link": "https://aclanthology.org/2024.emnlp-main.183.pdf", "details": "Y Chai, Q Liu, S Wang, Y Sun, Q Peng, H Wu - \u2026 of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Amidst the rapid advancements in generative language models, the investigation of how training data shapes the performance of GPT models is still emerging. This paper presents GPTfluence, a novel approach that leverages a featurized simulation \u2026"}, {"title": "Hidden in Plain Sight: Vector Embeddings give away Demographic Information", "link": "https://www.researchgate.net/profile/Alessandro-Quarta/publication/385853181_Hidden_in_Plain_Sight_Vector_Embeddings_give_away_Demographic_Information/links/67377c724a70511f07201191/Hidden-in-Plain-Sight-Vector-Embeddings-give-away-Demographic-Information.pdf", "details": "A Quarta, F Santos, A Marzullo, JMC Sousa, SM Vieira\u2026", "abstract": "Purpose: This study investigates the extent to which demographic information (age, gender, ethnicity, and insurance type) is encoded in vector embeddings derived from chest radiographs in the MIMIC-CXR dataset. Materials and Methods: We used three \u2026"}, {"title": "SciInstruct: a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models", "link": "https://openreview.net/pdf%3Fid%3DLC1QAqhePv", "details": "D Zhang, Z Hu, S Zhoubian, Z Du, K Yang, Z Wang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving \u2026"}, {"title": "LLaVA-KD: A Framework of Distilling Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2410.16236", "details": "Y Cai, J Zhang, H He, X He, A Tong, Z Gan, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The success of Large Language Models (LLM) has led researchers to explore Multimodal Large Language Models (MLLM) for unified visual and linguistic understanding. However, the increasing model size and computational complexity of \u2026"}, {"title": "Measuring short-form factuality in large language models", "link": "https://arxiv.org/pdf/2411.04368", "details": "J Wei, N Karina, HW Chung, YJ Jiao, S Papay\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present SimpleQA, a benchmark that evaluates the ability of language models to answer short, fact-seeking questions. We prioritized two properties in designing this eval. First, SimpleQA is challenging, as it is adversarially collected against GPT-4 \u2026"}]
