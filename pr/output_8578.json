[{"title": "RadFlag: A Black-Box Hallucination Detection Method for Medical Vision Language Models", "link": "https://arxiv.org/pdf/2411.00299", "details": "S Sambara, S Zhang, O Banerjee, J Acosta, J Fahrner\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generating accurate radiology reports from medical images is a clinically important but challenging task. While current Vision Language Models (VLMs) show promise, they are prone to generating hallucinations, potentially compromising patient care \u2026"}, {"title": "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models", "link": "https://arxiv.org/pdf/2410.13085", "details": "P Xia, K Zhu, H Li, T Wang, W Shi, S Wang, L Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for \u2026"}, {"title": "ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments", "link": "https://arxiv.org/pdf/2410.06420", "details": "S Ray, K Gupta, S Kundu, PA Kasat, S Aditya, P Goyal - arXiv preprint arXiv \u2026, 2024", "abstract": "The global shortage of healthcare workers has demanded the development of smart healthcare assistants, which can help monitor and alert healthcare workers when necessary. We examine the healthcare knowledge of existing Large Vision \u2026"}, {"title": "Fast Training of Sinusoidal Neural Fields via Scaling Initialization", "link": "https://arxiv.org/pdf/2410.04779", "details": "T Yeom, S Lee, J Lee - arXiv preprint arXiv:2410.04779, 2024", "abstract": "Neural fields are an emerging paradigm that represent data as continuous functions parameterized by neural networks. Despite many advantages, neural fields often have a high training cost, which prevents a broader adoption. In this paper, we focus \u2026"}, {"title": "Understanding the Limits of Vision Language Models Through the Lens of the Binding Problem", "link": "https://arxiv.org/pdf/2411.00238", "details": "D Campbell, S Rane, T Giallanza, N De Sabbata\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent work has documented striking heterogeneity in the performance of state-of- the-art vision language models (VLMs), including both multimodal language models and text-to-image models. These models are able to describe and generate a \u2026"}, {"title": "Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation", "link": "https://arxiv.org/pdf/2410.21037", "details": "S Yuan, HU Unlu, H Huang, C Wen, A Tzes, Y Fang - arXiv preprint arXiv:2410.21037, 2024", "abstract": "In this paper, we present a novel method for reliable frontier selection in Zero-Shot Object Goal Navigation (ZS-OGN), enhancing robotic navigation systems with foundation models to improve commonsense reasoning in indoor environments. Our \u2026"}, {"title": "LLaVA Needs More Knowledge: Retrieval Augmented Natural Language Generation with Knowledge Graph for Explaining Thoracic Pathologies", "link": "https://arxiv.org/pdf/2410.04749", "details": "A Hamza, YH Ahn, S Lee, ST Kim - arXiv preprint arXiv:2410.04749, 2024", "abstract": "Generating Natural Language Explanations (NLEs) for model predictions on medical images, particularly those depicting thoracic pathologies, remains a critical and challenging task. Existing methodologies often struggle due to general models' \u2026"}, {"title": "Aligning Large Language Models for Enhancing Psychiatric Interviews Through Symptom Delineation and Summarization: Pilot Study", "link": "https://formative.jmir.org/2024/1/e58418/", "details": "J So, J Chang, E Kim, J Na, JY Choi, J Sohn, BH Kim\u2026 - JMIR Formative Research, 2024", "abstract": "Background: Recent advancements in large language models (LLMs) have accelerated their use across various domains. Psychiatric interviews, which are goal- oriented and structured, represent a significantly underexplored area where LLMs \u2026"}, {"title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe", "link": "https://arxiv.org/pdf/2410.05248", "details": "Y Xiao, S Zhang, W Zhou, M Ghassemi, S Zhao - arXiv preprint arXiv:2410.05248, 2024", "abstract": "To induce desired behaviors in large language models (LLMs) for interaction-driven tasks, the instruction-tuning stage typically trains LLMs on instruction-response pairs using the next-token prediction (NTP) loss. Previous work aiming to improve \u2026"}]
