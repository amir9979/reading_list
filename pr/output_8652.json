[{"title": "Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization", "link": "https://arxiv.org/pdf/2410.09302", "details": "G Liu, K Ji, R Zheng, Z Wu, C Dun, Q Gu, L Yan - arXiv preprint arXiv:2410.09302, 2024", "abstract": "Reinforcement Learning (RL) plays a crucial role in aligning large language models (LLMs) with human preferences and improving their ability to perform complex tasks. However, current approaches either require significant computational resources due \u2026"}, {"title": "Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?", "link": "https://arxiv.org/pdf/2410.23856", "details": "Z Zhou, R Tao, J Zhu, Y Luo, Z Wang, B Han - arXiv preprint arXiv:2410.23856, 2024", "abstract": "This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We \u2026"}, {"title": "Transformer-based Language Models for Reasoning in the Description Logic ALCQ", "link": "https://arxiv.org/pdf/2410.09613", "details": "A Poulis, E Tsalapati, M Koubarakis - arXiv preprint arXiv:2410.09613, 2024", "abstract": "Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order \u2026"}, {"title": "Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models", "link": "https://arxiv.org/pdf/2411.00257", "details": "G Guo, JJ Kang, RS Shah, H Pfister, S Varma - arXiv preprint arXiv:2411.00257, 2024", "abstract": "Vision Language Models (VLMs) have been successful at many chart comprehension tasks that require attending to both the images of charts and their accompanying textual descriptions. However, it is not well established how VLM \u2026"}, {"title": "Measuring Human-AI Value Alignment in Large Language Models", "link": "https://ojs.aaai.org/index.php/AIES/article/download/31703/33870", "details": "H Norhashim, J Hahn - Proceedings of the AAAI/ACM Conference on AI, Ethics \u2026, 2024", "abstract": "This paper seeks to quantify the human-AI value alignment in large language models. Alignment between humans and AI has become a critical area of research to mitigate potential harm posed by AI. In tandem with this need, developers have \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}, {"title": "Improving Causal Inference of Large Language Models with SCM Tools", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9437-9_1", "details": "Z Hua, S Xing, H Jiang, C Wei, X Wang - CCF International Conference on Natural \u2026, 2025", "abstract": "Many previous studies have shown that Large Language Models (LLMs) are highly competent on many Natural Language Processing (NLP) tasks. However, a recent study showed the poor ability of LLMs to perform causal inference based on causal \u2026"}, {"title": "Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning", "link": "https://arxiv.org/pdf/2410.19290", "details": "Y Liu, S Chang, T Jaakkola, Y Zhang - arXiv preprint arXiv:2410.19290, 2024", "abstract": "Recent studies have identified one aggravating factor of LLM hallucinations as the knowledge inconsistency between pre-training and fine-tuning, where unfamiliar fine- tuning data mislead the LLM to fabricate plausible but wrong outputs. In this paper \u2026"}, {"title": "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models", "link": "https://arxiv.org/pdf/2410.12011", "details": "K Tatariya, V Araujo, T Bauwens, M de Lhoneux - arXiv preprint arXiv:2410.12011, 2024", "abstract": "Pixel-based language models have emerged as a compelling alternative to subword- based language modelling, particularly because they can represent virtually any script. PIXEL, a canonical example of such a model, is a vision transformer that has \u2026"}]
