[{"title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2412.09827", "details": "C Li, C Ding, K Luan, X Di - arXiv preprint arXiv:2412.09827, 2024", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. LoRA is one of the most widely used methods, which assumes that the optimization process is essentially low \u2026"}, {"title": "Large Language Model Ability to Translate CT and MRI Free-Text Radiology Reports Into Multiple Languages", "link": "https://pubs.rsna.org/doi/abs/10.1148/radiol.241736", "details": "A Meddeb, S L\u00fcken, F Busch, L Adams, L Ugga\u2026 - Radiology, 2024", "abstract": "Background High-quality translations of radiology reports are essential for optimal patient care. Because of limited availability of human translators with medical expertise, large language models (LLMs) are a promising solution, but their ability to \u2026"}, {"title": "ACE-$ M^ 3$: Automatic Capability Evaluator for Multimodal Medical Models", "link": "https://arxiv.org/pdf/2412.11453", "details": "X Zhang, S Zheng, L Wang, G de Melo, Z Cao, X Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As multimodal large language models (MLLMs) gain prominence in the medical field, the need for precise evaluation methods to assess their effectiveness has become critical. While benchmarks provide a reliable means to evaluate the capabilities of \u2026"}, {"title": "Text-Guided Zero-Shot 3D Style Transfer of Neural Radiance Fields", "link": "https://link.springer.com/chapter/10.1007/978-3-031-78186-5_9", "details": "W Li, WS Zheng - International Conference on Pattern Recognition, 2024", "abstract": "Abstract 3D style transfer aims to generate novel, stylized views while maintaining multi-view consistency. However, current approaches primarily focus on uniformly stylizing entire 3D scenes, limiting the versatility of 3D style transfer. To address this \u2026"}, {"title": "VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information", "link": "https://arxiv.org/pdf/2412.00947", "details": "R Kamoi, Y Zhang, SSS Das, RH Zhang, R Zhang - arXiv preprint arXiv:2412.00947, 2024", "abstract": "Errors in understanding visual information in images (ie, visual perception errors) remain a major source of mistakes in Large Vision Language Models (LVLMs). While further analysis is essential, there is a deficiency in datasets for evaluating the visual \u2026"}, {"title": "UCDR-Adapter: Exploring Adaptation of Pre-Trained Vision-Language Models for Universal Cross-Domain Retrieval", "link": "https://arxiv.org/pdf/2412.10680", "details": "H Jiang, ZQ Cheng, G Moreira, J Zhu, J Sun, B Ren\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Universal Cross-Domain Retrieval (UCDR) retrieves relevant images from unseen domains and classes without semantic labels, ensuring robust generalization. Existing methods commonly employ prompt tuning with pre-trained vision-language \u2026"}, {"title": "ReVisionLLM: Recursive Vision-Language Model for Temporal Grounding in Hour-Long Videos", "link": "https://arxiv.org/pdf/2411.14901", "details": "T Hannan, MM Islam, J Gu, T Seidl, G Bertasius - arXiv preprint arXiv:2411.14901, 2024", "abstract": "Large language models (LLMs) excel at retrieving information from lengthy text, but their vision-language counterparts (VLMs) face difficulties with hour-long videos, especially for temporal grounding. Specifically, these VLMs are constrained by frame \u2026"}, {"title": "How Private are Language Models in Abstractive Summarization?", "link": "https://arxiv.org/pdf/2412.12040", "details": "A Hughes, N Aletras, N Ma - arXiv preprint arXiv:2412.12040, 2024", "abstract": "Language models (LMs) have shown outstanding performance in text summarization including sensitive domains such as medicine and law. In these settings, it is important that personally identifying information (PII) included in the source \u2026"}, {"title": "GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training", "link": "https://arxiv.org/pdf/2412.11863", "details": "R Xia, M Li, H Ye, W Wu, H Zhou, J Yuan, T Peng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their proficiency in general tasks, Multi-modal Large Language Models (MLLMs) struggle with automatic Geometry Problem Solving (GPS), which demands understanding diagrams, interpreting symbols, and performing complex reasoning \u2026"}]
