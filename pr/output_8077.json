[{"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679722", "details": "Y Shi, Q Tan, X Wu, S Zhong, K Zhou, N Liu - Proceedings of the 33rd ACM \u2026, 2024", "abstract": "Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging \u2026"}, {"title": "MiniPLM: Knowledge Distillation for Pre-Training Language Models", "link": "https://arxiv.org/pdf/2410.17215", "details": "Y Gu, H Zhou, F Meng, J Zhou, M Huang - arXiv preprint arXiv:2410.17215, 2024", "abstract": "Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness \u2026"}, {"title": "LoGra-Med: Long context multi-graph alignment for medical vision-language model", "link": "https://arxiv.org/pdf/2410.02615%3F", "details": "DMH Nguyen, NT Diep, TQ Nguyen, HB Le, T Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "State-of-the-art medical multi-modal large language models (med-MLLM), like LLaVA-Med or BioMedGPT, leverage instruction-following data in pre-training. However, those models primarily focus on scaling the model size and data volume to \u2026"}, {"title": "Advancing Medical Radiograph Representation Learning: A Hybrid Pre-training Paradigm with Multilevel Semantic Granularity", "link": "https://arxiv.org/pdf/2410.00448", "details": "H Jiang, X Hao, Y Huang, C Ma, J Zhang, Y Pan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces an innovative approach to Medical Vision-Language Pre- training (Med-VLP) area in the specialized context of radiograph representation learning. While conventional methods frequently merge textual annotations into \u2026"}, {"title": "The Last Iterate Advantage: Empirical Auditing and Principled Heuristic Analysis of Differentially Private SGD", "link": "https://arxiv.org/pdf/2410.06186", "details": "T Steinke, M Nasr, A Ganesh, B Balle\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We propose a simple heuristic privacy analysis of noisy clipped stochastic gradient descent (DP-SGD) in the setting where only the last iterate is released and the intermediate iterates remain hidden. Namely, our heuristic assumes a linear structure \u2026"}, {"title": "$\\beta $-calibration of Language Model Confidence Scores for Generative QA", "link": "https://arxiv.org/pdf/2410.06615", "details": "P Manggala, A Mastakouri, E Kirschbaum\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim \u2026"}, {"title": "Self-eXplainable AI for Medical Image Analysis: A Survey and New Outlooks", "link": "https://arxiv.org/pdf/2410.02331", "details": "J Hou, S Liu, Y Bie, H Wang, A Tan, L Luo, H Chen - arXiv preprint arXiv:2410.02331, 2024", "abstract": "The increasing demand for transparent and reliable models, particularly in high- stakes decision-making areas such as medical image analysis, has led to the emergence of eXplainable Artificial Intelligence (XAI). Post-hoc XAI techniques \u2026"}, {"title": "SPHINX: A Mixer of Weights, Visual Embeddings and Image Scales for Multi-modal Large Language Models", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07894.pdf", "details": "D Liu, R Zhang12, P Gao, L Qiu23, H Xiao, H Qiu\u2026", "abstract": "We present SPHINX, a versatile multi-modal large language model (MLLM) with a joint mixing of model weights, visual embeddings and image scales. First, for stronger vision-language alignment, we unfreeze the large language model (LLM) \u2026"}]
