[{"title": "Sequential Representation Learning via Static-Dynamic Conditional Disentanglement", "link": "https://arxiv.org/pdf/2408.05599", "details": "MC Simon, P Frossard, C De Vleeschouwer - arXiv preprint arXiv:2408.05599, 2024", "abstract": "This paper explores self-supervised disentangled representation learning within sequential data, focusing on separating time-independent and time-varying factors in videos. We propose a new model that breaks the usual independence assumption \u2026"}, {"title": "Enhancing 3D Transformer Segmentation Model for Medical Image with Token-level Representation Learning", "link": "https://arxiv.org/pdf/2408.05889", "details": "X Hu, D Zeng, Y Wu, X Li, Y Shi - arXiv preprint arXiv:2408.05889, 2024", "abstract": "In the field of medical images, although various works find Swin Transformer has promising effectiveness on pixelwise dense prediction, whether pre-training these models without using extra dataset can further boost the performance for the \u2026"}, {"title": "PersonViT: Large-scale Self-supervised Vision Transformer for Person Re-Identificat", "link": "https://arxiv.org/pdf/2408.05398", "details": "B Hu, X Wang, W Liu - arXiv preprint arXiv:2408.05398, 2024", "abstract": "Person Re-Identification (ReID) aims to retrieve relevant individuals in non- overlapping camera images and has a wide range of applications in the field of public safety. In recent years, with the development of Vision Transformer (ViT) and \u2026"}]
