[{"title": "From EHRs to Patient Pathways: Scalable Modeling of Longitudinal Health Trajectories with LLMs", "link": "https://arxiv.org/pdf/2506.04831", "details": "C Pellegrini, E \u00d6zsoy, D Bani-Harouni, M Keicher\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Healthcare systems face significant challenges in managing and interpreting vast, heterogeneous patient data for personalized care. Existing approaches often focus on narrow use cases with a limited feature space, overlooking the complex \u2026", "entry_id": "http://arxiv.org/abs/2506.04831v1", "updated": "2025-06-05 09:54:01", "published": "2025-06-05 09:54:01", "authors": "Chantal Pellegrini;Ege \u00d6zsoy;David Bani-Harouni;Matthias Keicher;Nassir Navab", "summary": "Healthcare systems face significant challenges in managing and interpreting\nvast, heterogeneous patient data for personalized care. Existing approaches\noften focus on narrow use cases with a limited feature space, overlooking the\ncomplex, longitudinal interactions needed for a holistic understanding of\npatient health. In this work, we propose a novel approach to patient pathway\nmodeling by transforming diverse electronic health record (EHR) data into a\nstructured representation and designing a holistic pathway prediction model,\nEHR2Path, optimized to predict future health trajectories. Further, we\nintroduce a novel summary mechanism that embeds long-term temporal context into\ntopic-specific summary tokens, improving performance over text-only models,\nwhile being much more token-efficient. EHR2Path demonstrates strong performance\nin both next time-step prediction and longitudinal simulation, outperforming\ncompetitive baselines. It enables detailed simulations of patient trajectories,\ninherently targeting diverse evaluation tasks, such as forecasting vital signs,\nlab test results, or length-of-stay, opening a path towards predictive and\npersonalized healthcare.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.CL", "links": "http://arxiv.org/abs/2506.04831v1;http://arxiv.org/pdf/2506.04831v1", "pdf_url": "http://arxiv.org/pdf/2506.04831v1"}, {"title": "Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification", "link": "https://arxiv.org/pdf/2506.04450", "details": "P Bhattacharjee, F Tian, R Tandon, J Lo, H Hanson\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Purpose: This study proposes a framework for fine-tuning large language models (LLMs) with differential privacy (DP) to perform multi-abnormality classification on radiology report text. By injecting calibrated noise during fine-tuning, the framework \u2026", "entry_id": "http://arxiv.org/abs/2506.04450v1", "updated": "2025-06-04 21:11:45", "published": "2025-06-04 21:11:45", "authors": "Payel Bhattacharjee;Fengwei Tian;Ravi Tandon;Joseph Lo;Heidi Hanson;Geoffrey Rubin;Nirav Merchant;John Gounley", "summary": "Purpose: This study proposes a framework for fine-tuning large language\nmodels (LLMs) with differential privacy (DP) to perform multi-abnormality\nclassification on radiology report text. By injecting calibrated noise during\nfine-tuning, the framework seeks to mitigate the privacy risks associated with\nsensitive patient data and protect against data leakage while maintaining\nclassification performance. Materials and Methods: We used 50,232 radiology\nreports from the publicly available MIMIC-CXR chest radiography and CT-RATE\ncomputed tomography datasets, collected between 2011 and 2019. Fine-tuning of\nLLMs was conducted to classify 14 labels from MIMIC-CXR dataset, and 18 labels\nfrom CT-RATE dataset using Differentially Private Low-Rank Adaptation (DP-LoRA)\nin high and moderate privacy regimes (across a range of privacy budgets =\n{0.01, 0.1, 1.0, 10.0}). Model performance was evaluated using weighted F1\nscore across three model architectures: BERT-medium, BERT-small, and\nALBERT-base. Statistical analyses compared model performance across different\nprivacy levels to quantify the privacy-utility trade-off. Results: We observe a\nclear privacy-utility trade-off through our experiments on 2 different datasets\nand 3 different models. Under moderate privacy guarantees the DP fine-tuned\nmodels achieved comparable weighted F1 scores of 0.88 on MIMIC-CXR and 0.59 on\nCT-RATE, compared to non-private LoRA baselines of 0.90 and 0.78, respectively.\nConclusion: Differentially private fine-tuning using LoRA enables effective and\nprivacy-preserving multi-abnormality classification from radiology reports,\naddressing a key challenge in fine-tuning LLMs on sensitive medical data.", "comment": "19 pages, 5 figures, 2 tables", "journal_ref": null, "primary_category": "cs.CR", "categories": "cs.CR;cs.AI;cs.CL;cs.LG", "links": "http://arxiv.org/abs/2506.04450v1;http://arxiv.org/pdf/2506.04450v1", "pdf_url": "http://arxiv.org/pdf/2506.04450v1"}, {"title": "Development and validation of an autonomous artificial intelligence agent for clinical decision-making in oncology", "link": "https://www.nature.com/articles/s43018-025-00991-6", "details": "D Ferber, OSM El Nahhas, G W\u00f6lflein, IC Wiest\u2026 - Nature Cancer, 2025", "abstract": "Clinical decision-making in oncology is complex, requiring the integration of multimodal data and multidomain expertise. We developed and evaluated an autonomous clinical artificial intelligence (AI) agent leveraging GPT-4 with \u2026"}]
