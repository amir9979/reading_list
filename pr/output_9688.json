[{"title": "Training and Evaluating Language Models with Template-based Data Generation", "link": "https://arxiv.org/pdf/2411.18104", "details": "Y Zhang - arXiv preprint arXiv:2411.18104, 2024", "abstract": "The rapid advancement of large language models (LLMs) such as GPT-3, PaLM, and Llama has significantly transformed natural language processing, showcasing remarkable capabilities in understanding and generating language. However, these \u2026"}, {"title": "DA3: A Distribution-Aware Adversarial Attack against Language Models", "link": "https://aclanthology.org/2024.emnlp-main.107.pdf", "details": "Y Wang, X Dong, J Caverlee, SY Philip - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "Abstract Language models can be manipulated by adversarial attacks, which introduce subtle perturbations to input data. While recent attack methods can achieve a relatively high attack success rate (ASR), we've observed that the generated \u2026"}, {"title": "Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2411.14432", "details": "Y Dong, Z Liu, HL Sun, J Yang, W Hu, Y Rao, Z Liu - arXiv preprint arXiv:2411.14432, 2024", "abstract": "Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1. Despite various efforts to improve LLM reasoning, high \u2026"}, {"title": "Evaluating and Advancing Multimodal Large Language Models in Ability Lens", "link": "https://arxiv.org/pdf/2411.14725", "details": "F Chen, C Gou, J Liu, Y Yang, Z Li, J Zhang, Z Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As multimodal large language models (MLLMs) advance rapidly, rigorous evaluation has become essential, providing further guidance for their development. In this work, we focus on a unified and robust evaluation of\\textbf {vision perception} abilities, the \u2026"}, {"title": "PhoneLM: an Efficient and Capable Small Language Model Family through Principled Pre-training", "link": "https://arxiv.org/pdf/2411.05046", "details": "R Yi, X Li, W Xie, Z Lu, C Wang, A Zhou, S Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The interest in developing small language models (SLM) for on-device deployment is fast growing. However, the existing SLM design hardly considers the device hardware characteristics. Instead, this work presents a simple yet effective principle \u2026"}, {"title": "MC-NEST--Enhancing Mathematical Reasoning in Large Language Models with a Monte Carlo Nash Equilibrium Self-Refine Tree", "link": "https://arxiv.org/pdf/2411.15645", "details": "G Rabby, F Keya, P Zamil, S Auer - arXiv preprint arXiv:2411.15645, 2024", "abstract": "Mathematical reasoning has proven to be a critical yet challenging task for large language models (LLMs), as they often struggle with complex multi-step problems. To address these limitations, we introduce the Monte Carlo Nash Equilibrium Self \u2026"}, {"title": "Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training", "link": "https://arxiv.org/pdf/2411.14318%3F", "details": "Z Luo, X Zhang, X Liu, H Li, Y Gong, C Qi, P Cheng - arXiv preprint arXiv:2411.14318, 2024", "abstract": "It is well-known that a diverse corpus is critical for training large language models, which are typically constructed from a mixture of various domains. In general, previous efforts resort to sampling training data from different domains with static \u2026"}, {"title": "Efficient Self-Improvement in Multimodal Large Language Models: A Model-Level Judge-Free Approach", "link": "https://arxiv.org/pdf/2411.17760", "details": "S Deng, W Zhao, YJ Li, K Wan, D Miranda, A Kale\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-improvement in multimodal large language models (MLLMs) is crucial for enhancing their reliability and robustness. However, current methods often rely heavily on MLLMs themselves as judges, leading to high computational costs and \u2026"}, {"title": "A Real-World Benchmark for Evaluating Fine-Grained Issue Solving Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2411.18019", "details": "R Hu, C Peng, J Ren, B Jiang, X Meng, Q Wu, P Gao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Automatically resolving software issues is crucial for software development in practice, impacting the software quality and user experience. The process of resolving real-world issues encompasses tasks such as question-answering (QA) \u2026"}]
