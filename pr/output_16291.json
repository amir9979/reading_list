[{"title": "GroundCocoa: A Benchmark for Evaluating Compositional & Conditional Reasoning in Language Models", "link": "https://aclanthology.org/2025.naacl-long.420.pdf", "details": "H Kohli, S Kumar, H Sun - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their reasoning to \u2026"}, {"title": "Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math", "link": "https://arxiv.org/pdf/2504.21233", "details": "H Xu, B Peng, H Awadalla, D Chen, YC Chen, M Gao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Chain-of-Thought (CoT) significantly enhances formal reasoning capabilities in Large Language Models (LLMs) by training them to explicitly generate intermediate reasoning steps. While LLMs readily benefit from such techniques, improving \u2026"}, {"title": "Efficient Multivariate Time Series Forecasting via Calibrated Language Models with Privileged Knowledge Distillation", "link": "https://arxiv.org/pdf/2505.02138", "details": "C Liu, S Zhou, H Miao, Q Xu, C Long, Z Li, R Zhao - arXiv preprint arXiv:2505.02138, 2025", "abstract": "Multivariate time series forecasting (MTSF) endeavors to predict future observations given historical data, playing a crucial role in time series data management systems. With advancements in large language models (LLMs), recent studies employ textual \u2026"}, {"title": "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models", "link": "https://arxiv.org/pdf/2505.00551%3F", "details": "C Zhang, Y Deng, X Lin, B Wang, D Ng, H Ye, X Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The recent development of reasoning language models (RLMs) represents a novel evolution in large language models. In particular, the recent release of DeepSeek-R1 has generated widespread social impact and sparked enthusiasm in the research \u2026"}, {"title": "Exploring Multimodal Language Models for Sustainability Disclosure Extraction: A Comparative Study", "link": "https://aclanthology.org/2025.insights-1.13.pdf", "details": "T Gupta, T Goel, I Verma - The Sixth Workshop on Insights from Negative Results \u2026, 2025", "abstract": "Sustainability metrics have increasingly become a crucial non-financial criterion in investment decision-making. Organizations worldwide are recognizing the importance of sustainability and are proactively highlighting their efforts through \u2026"}, {"title": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "link": "https://www.biorxiv.org/content/10.1101/2025.04.14.648850.full.pdf", "details": "SA Rizvi, D Levine, A Patel, S Zhang, E Wang, S He\u2026 - bioRxiv, 2025", "abstract": "Single-cell RNA sequencing has transformed our understanding of cellular diversity, yet current single-cell foundation models (scFMs) remain limited in their scalability, flexibility across diverse tasks, and ability to natively integrate textual information. In \u2026"}, {"title": "Few-Shot Vision-Language Action-Incremental Policy Learning", "link": "https://arxiv.org/pdf/2504.15517", "details": "M Song, X Deng, G Zhong, Q Lv, J Wan, Y Li, J Hao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, Transformer-based robotic manipulation methods utilize multi-view spatial representations and language instructions to learn robot motion trajectories by leveraging numerous robot demonstrations. However, the collection of robot data is \u2026"}, {"title": "Developing safe and responsible large language model: can we balance bias reduction and language understanding?", "link": "https://link.springer.com/article/10.1007/s10994-025-06767-4", "details": "S Raza, O Bamgbose, S Ghuge, F Tavakoli, DJ Reji\u2026 - Machine Learning, 2025", "abstract": "Abstract Large Language Models (LLMs) have advanced various Natural Language Processing (NLP) tasks, such as text generation and translation, among others. However, these models often generate texts that can perpetuate biases. Existing \u2026"}, {"title": "Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society", "link": "https://arxiv.org/pdf/2504.17404%3F", "details": "F Zhao, Y Wang, E Lu, D Zhao, B Han, H Tong, Y Liang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Artificial Intelligence (AI) systems are becoming increasingly powerful and autonomous, and may progress to surpass human intelligence levels, namely Artificial Superintelligence (ASI). During the progression from AI to ASI, it may exceed \u2026"}]
