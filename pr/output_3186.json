[{"title": "KU-DMIS at MEDIQA-CORR 2024: Exploring the Reasoning Capabilities of Small Language Models in Medical Error Correction", "link": "https://aclanthology.org/2024.clinicalnlp-1.51.pdf", "details": "H Hwang, T Lee, H Kim, J Kang - Proceedings of the 6th Clinical Natural Language \u2026, 2024", "abstract": "Recent advancements in large language models (LM) like OpenAI's GPT-4 have shown promise in healthcare, particularly in medical question answering and clinical applications. However, their deployment raises privacy concerns and their size limits \u2026"}, {"title": "Evaluating Copyright Takedown Methods for Language Models", "link": "https://arxiv.org/pdf/2406.18664", "details": "B Wei, W Shi, Y Huang, NA Smith, C Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) derive their capabilities from extensive training on diverse data, including potentially copyrighted material. These models can memorize and generate content similar to their training data, posing potential concerns. Therefore \u2026"}, {"title": "Bootstrapping Language Models with DPO Implicit Rewards", "link": "https://arxiv.org/pdf/2406.09760", "details": "C Chen, Z Liu, C Du, T Pang, Q Liu, A Sinha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Human alignment in large language models (LLMs) is an active area of research. A recent groundbreaking work, direct preference optimization (DPO), has greatly simplified the process from past work in reinforcement learning from human feedback \u2026"}, {"title": "Lexicans at Chemotimelines 2024: Chemotimeline Chronicles-Leveraging Large Language Models (LLMs) for Temporal Relations Extraction in Oncological \u2026", "link": "https://aclanthology.org/2024.clinicalnlp-1.38.pdf", "details": "V Sharma, A Fern\u00e1ndez, A Ioanovici, D Talby, F Buijs - Proceedings of the 6th \u2026, 2024", "abstract": "Automatic generation of chemotherapy treatment timelines from electronic health records (EHRs) notes not only streamlines clinical workflows but also promotes better coordination and improvements in cancer treatment and quality of care. This \u2026"}, {"title": "Propensity Weighted federated learning for treatment effect estimation in distributed imbalanced environments", "link": "https://www.sciencedirect.com/science/article/pii/S0010482524008643", "details": "A Almod\u00f3var, J Parras, S Zazo - Computers in Biology and Medicine, 2024", "abstract": "Estimating treatment effects from observational data in medicine using causal inference is a very relevant task due to the abundance of observational data and the ethical and cost implications of conducting randomized experiments or experimental \u2026"}, {"title": "Evaluating machine learning approaches for multi-label classification of unstructured electronic health records with a generative large language model", "link": "https://www.medrxiv.org/content/10.1101/2024.06.24.24309441.full.pdf", "details": "D Vithanage, C Deng, L Wang, M Yin, M Alkhalaf\u2026 - medRxiv, 2024", "abstract": "Multi-label classification of unstructured electronic health records (EHR) poses challenges due to the inherent semantic complexity in textual data. Advances in natural language processing (NLP) using large language models (LLMs) show \u2026"}, {"title": "Large Language Models are Interpretable Learners", "link": "https://arxiv.org/pdf/2406.17224", "details": "R Wang, S Si, F Yu, D Wiesmann, CJ Hsieh, I Dhillon - arXiv preprint arXiv \u2026, 2024", "abstract": "The trade-off between expressiveness and interpretability remains a core challenge when building human-centric predictive models for classification and decision- making. While symbolic rules offer interpretability, they often lack expressiveness \u2026"}, {"title": "Rethinking Entity-level Unlearning for Large Language Models", "link": "https://arxiv.org/pdf/2406.15796", "details": "W Ma, X Feng, W Zhong, L Huang, Y Ye, B Qin - arXiv preprint arXiv:2406.15796, 2024", "abstract": "Large language model unlearning has gained increasing attention due to its potential to mitigate security and privacy concerns. Current research predominantly focuses on Instance-level unlearning, specifically aiming at forgetting predefined \u2026"}, {"title": "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models", "link": "https://arxiv.org/pdf/2406.16635", "details": "Y Akhauri, AF AbouElhamayed, J Dotzel, Z Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The high power consumption and latency-sensitive deployments of large language models (LLMs) have motivated techniques like quantization and sparsity. Contextual sparsity, where the sparsity pattern is input-dependent, is crucial in LLMs because \u2026"}]
