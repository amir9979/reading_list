[{"title": "Modular Prompt Learning Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14125", "details": "Z Huang, T Pedapati, PY Chen, J Gao - arXiv preprint arXiv:2502.14125, 2025", "abstract": "Pre-trained vision-language models are able to interpret visual concepts and language semantics. Prompt learning, a method of constructing prompts for text encoders or image encoders, elicits the potentials of pre-trained models and readily \u2026"}, {"title": "On Benchmarking Human-Like Intelligence in Machines", "link": "https://arxiv.org/pdf/2502.20502", "details": "L Ying, KM Collins, L Wong, I Sucholutsky, R Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent benchmark studies have claimed that AI has approached or even surpassed human-level performances on various cognitive tasks. However, this position paper argues that current AI evaluation paradigms are insufficient for assessing human-like \u2026"}, {"title": "Parallel-Learning of Invariant and Tempo-variant Attributes of Single-Lead Cardiac Signals: PLITA", "link": "https://arxiv.org/pdf/2502.21162", "details": "A Atienza, JE Bardram, S Puthusserypady - arXiv preprint arXiv:2502.21162, 2025", "abstract": "Wearable sensing devices, such as Holter monitors, will play a crucial role in the future of digital health. Unsupervised learning frameworks such as Self-Supervised Learning (SSL) are essential to map these single-lead electrocardiogram (ECG) \u2026"}, {"title": "Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2502.06872", "details": "B Ni, Z Liu, L Wang, Y Lei, Y Zhao, X Cheng, Q Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Retrieval-Augmented Generation (RAG) is an advanced technique designed to address the challenges of Artificial Intelligence-Generated Content (AIGC). By integrating context retrieval into content generation, RAG provides reliable and up-to \u2026"}, {"title": "Assessing and alleviating state anxiety in large language models", "link": "https://www.nature.com/articles/s41746-025-01512-6", "details": "Z Ben-Zion, K Witte, AK Jagadish, O Duek\u2026 - npj Digital Medicine, 2025", "abstract": "Abstract The use of Large Language Models (LLMs) in mental health highlights the need to understand their responses to emotional content. Previous research shows that emotion-inducing prompts can elevate \u201canxiety\u201d in LLMs, affecting behavior and \u2026"}, {"title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling", "link": "https://arxiv.org/pdf/2502.21309", "details": "Y Dong, G Li, X Jiang, Y Tao, K Zhang, H Zhu, H Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Periodicity, as one of the most important basic characteristics, lays the foundation for facilitating structured knowledge acquisition and systematic cognitive processes within human learning paradigms. However, the potential flaws of periodicity \u2026"}, {"title": "Merging Clinical Knowledge into Large Language Models for Medical Research and Applications: A Survey", "link": "https://arxiv.org/pdf/2502.20988", "details": "Q Li, H Liu, C Guo, D Chen, M Wang, F Gao, J Gu - arXiv preprint arXiv:2502.20988, 2025", "abstract": "Clinical knowledge is the collection of information learned from studies on the causes, prognosis, diagnosis, and treatment of diseases. This type of knowledge can improve curing performances, and promote physical health. With the emergence of \u2026"}]
