[{"title": "Enhancing Contrastive Learning on Graphs with Node Similarity", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671898", "details": "H Chi, Y Ma - Proceedings of the 30th ACM SIGKDD Conference on \u2026, 2024", "abstract": "Graph Neural Networks (GNN) have proven successful for graph-related tasks. However, many GNNs methods require labeled data, which is challenging to obtain. To tackle this, graph contrastive learning (GCL) have gained attention. GCL learns by \u2026"}, {"title": "Contrastive Learning Network for Unsupervised Graph Matching", "link": "https://ieeexplore.ieee.org/abstract/document/10671578/", "details": "Y Xie, L Luo, T Cao, B Yu, AK Qin - IEEE Transactions on Circuits and Systems for \u2026, 2024", "abstract": "Graph matching aims to establish node correspondences between graphs, which is a classic combinatorial optimization problem. In recent years,(deep) learning-based methods have emerged as a superior alternative to traditional graph matching \u2026"}, {"title": "Self-Supervised Contrastive Learning for Videos using Differentiable Local Alignment", "link": "https://arxiv.org/pdf/2409.04607", "details": "K Oei, A Gomaa, AM Feit, J Belo - arXiv preprint arXiv:2409.04607, 2024", "abstract": "Robust frame-wise embeddings are essential to perform video analysis and understanding tasks. We present a self-supervised method for representation learning based on aligning temporal video sequences. Our framework uses a \u2026"}, {"title": "Self-supervised Anomaly Detection Pretraining Enhances Long-tail ECG Diagnosis", "link": "https://arxiv.org/pdf/2408.17154", "details": "A Jiang, C Huang, Q Cao, Y Xu, Z Zeng, K Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Current computer-aided ECG diagnostic systems struggle with the underdetection of rare but critical cardiac anomalies due to the imbalanced nature of ECG datasets. This study introduces a novel approach using self-supervised anomaly detection \u2026"}, {"title": "Opportunities for Post-Training Dynamic Layer Sparsity in Large Vision and Language Models", "link": "https://openaccess.thecvf.com/content/CVPR2024W/ELVM/papers/Dotzel_Opportunities_for_Post-Training_Dynamic_Layer_Sparsity_in_Large_Vision_and_CVPRW_2024_paper.pdf", "details": "J Dotzel, C Jiang, M Abdelfattah, Z Zhang - Proceedings of the IEEE/CVF Conference \u2026, 2024", "abstract": "Large language and vision models have recently achieved state-of-the-art performance across various tasks yet due to their large computational requirements they struggle with strict memory latency and power demands. To meet these \u2026"}, {"title": "Cross-modality interaction reasoning for enhancing vision-language pre-training in image-text retrieval", "link": "https://link.springer.com/article/10.1007/s10489-024-05823-1", "details": "T Yao, S Peng, L Wang, Y Li, Y Sun - Applied Intelligence, 2024", "abstract": "Recent days have seen significant improvements in multi-modal learning made by Vision-Language Pre-training (VLP) models. However, most of them employ the coarse-grained global alignment to overcome semantic gap for generating common \u2026"}, {"title": "Interpretable Vision-Language Survival Analysis with Ordinal Inductive Bias for Computational Pathology", "link": "https://arxiv.org/pdf/2409.09369", "details": "P Liu, L Ji, J Gou, B Fu, M Ye - arXiv preprint arXiv:2409.09369, 2024", "abstract": "Histopathology Whole-Slide Images (WSIs) provide an important tool to assess cancer prognosis in computational pathology (CPATH). While existing survival analysis (SA) approaches have made exciting progress, they are generally limited to \u2026"}, {"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task Specific Expert Pruning", "link": "https://arxiv.org/pdf/2409.01483", "details": "S Sarkar, L Lausen, V Cevher, S Zha, T Brox, G Karypis - arXiv preprint arXiv \u2026, 2024", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative to dense models in language modeling. These models use conditionally activated feedforward subnetworks in transformer blocks, allowing for a separation between \u2026"}, {"title": "DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised Vector-LoRA of the Foundation Model", "link": "https://arxiv.org/pdf/2408.17433", "details": "MS Zeinoddin, C Lena, J Qu, L Carlini, M Magro, S Kim\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Robotic-assisted surgery (RAS) relies on accurate depth estimation for 3D reconstruction and visualization. While foundation models like Depth Anything Models (DAM) show promise, directly applying them to surgery often yields \u2026"}]
