[{"title": "Gradient Localization Improves Lifelong Pretraining of Language Models", "link": "https://arxiv.org/pdf/2411.04448", "details": "J Fernandez, Y Bisk, E Strubell - arXiv preprint arXiv:2411.04448, 2024", "abstract": "Large Language Models (LLMs) trained on web-scale text corpora have been shown to capture world knowledge in their parameters. However, the mechanism by which language models store different types of knowledge is poorly understood. In this \u2026"}, {"title": "Working memory identifies reasoning limits in language models", "link": "https://aclanthology.org/2024.emnlp-main.938.pdf", "details": "C Zhang, Y Jian, Z Ouyang, S Vosoughi - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "This study explores the inherent limitations of large language models (LLMs) from a scaling perspective, focusing on the upper bounds of their cognitive capabilities. We integrate insights from cognitive science to quantitatively examine how LLMs perform \u2026"}, {"title": "Joint Vision-Language Social Bias Removal for CLIP", "link": "https://arxiv.org/pdf/2411.12785", "details": "H Zhang, Y Guo, M Kankanhalli - arXiv preprint arXiv:2411.12785, 2024", "abstract": "Vision-Language (VL) pre-trained models such as CLIP show prominent capabilities in various downstream tasks. Despite this promise, VL models are notoriously limited by their inherent social biases. A typical demonstration is that VL models often \u2026"}, {"title": "LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote Sensing Vision-Language Interpretation", "link": "https://arxiv.org/pdf/2411.09301", "details": "Z Li, D Muhtar, F Gu, X Zhang, P Xiao, G He, X Zhu - arXiv preprint arXiv:2411.09301, 2024", "abstract": "Automatically and rapidly understanding Earth's surface is fundamental to our grasp of the living environment and informed decision-making. This underscores the need for a unified system with comprehensive capabilities in analyzing Earth's surface to \u2026"}]
