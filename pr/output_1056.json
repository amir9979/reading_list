'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [Adapting transformer-based language models for heart '
[{"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "Context versus Prior Knowledge in Language Models", "link": "https://arxiv.org/pdf/2404.04633", "details": "K Du, V Sn\u00e6bjarnarson, N Stoehr, JC White, A Schein\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To answer a question, language models often need to integrate prior knowledge learned during pretraining and new information presented in context. We hypothesize that models perform this integration in a predictable way across different \u2026"}, {"title": "Investigating Regularization of Self-Play Language Models", "link": "https://arxiv.org/pdf/2404.04291", "details": "R Alami, A Abubaker, M Achab, MEA Seddik, S Lahlou - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper explores the effects of various forms of regularization in the context of language model alignment via self-play. While both reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) require to collect \u2026"}, {"title": "Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering", "link": "https://arxiv.org/pdf/2404.10193", "details": "Z Khan, Y Fu - arXiv preprint arXiv:2404.10193, 2024", "abstract": "The goal of selective prediction is to allow an a model to abstain when it may not be able to deliver a reliable prediction, which is important in safety-critical contexts. Existing approaches to selective prediction typically require access to the internals of \u2026"}, {"title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "link": "https://arxiv.org/pdf/2405.00402", "details": "L Ranaldi, A Freitas - arXiv preprint arXiv:2405.00402, 2024", "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches \u2026"}, {"title": "IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials", "link": "https://arxiv.org/pdf/2404.04510", "details": "S Mandal, A Modi - arXiv preprint arXiv:2404.04510, 2024", "abstract": "Large Language models (LLMs) have demonstrated state-of-the-art performance in various natural language processing (NLP) tasks across multiple domains, yet they are prone to shortcut learning and factual inconsistencies. This research investigates \u2026"}, {"title": "Dual Modalities of Text: Visual and Textual Generative Pre-training", "link": "https://arxiv.org/pdf/2404.10710", "details": "Y Chai, Q Liu, J Xiao, S Wang, Y Sun, H Wu - arXiv preprint arXiv:2404.10710, 2024", "abstract": "Harnessing visual texts represents a burgeoning frontier in the evolution of language modeling. In this paper, we introduce a novel pre-training framework for a suite of pixel-based autoregressive language models, pre-training on a corpus of over 400 \u2026"}, {"title": "Quality of Answers of Generative Large Language Models Versus Peer Users for Interpreting Laboratory Test Results for Lay Patients: Evaluation Study", "link": "https://www.jmir.org/2024/1/e56655/", "details": "Z He, B Bhasuran, Q Jin, S Tian, K Hanna, C Shavor\u2026 - Journal of Medical Internet \u2026, 2024", "abstract": "Background Although patients have easy access to their electronic health records and laboratory test result data through patient portals, laboratory test results are often confusing and hard to understand. Many patients turn to web-based forums or \u2026"}, {"title": "SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2404.03887", "details": "H Kim, G Gim, Y Kim, J Kim, B Kim, W Lee, C Park - arXiv preprint arXiv:2404.03887, 2024", "abstract": "This study presents a novel learning approach designed to enhance both mathematical reasoning and problem-solving abilities of Large Language Models (LLMs). We focus on integrating the Chain-of-Thought (CoT) and the Program-of \u2026"}]
