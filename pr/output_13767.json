[{"title": "EyeBench: A Call for More Rigorous Evaluation of Retinal Image Enhancement", "link": "https://arxiv.org/pdf/2502.14260", "details": "W Zhu, X Dong, X Li, Y Xiong, X Chen, P Qiu, VK Vasa\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Over the past decade, generative models have achieved significant success in enhancement fundus images. However, the evaluation of these models still presents a considerable challenge. A comprehensive evaluation benchmark for fundus image \u2026"}, {"title": "A Weighted Cross-entropy Loss for Mitigating LLM Hallucinations in Cross-lingual Continual Pretraining", "link": "https://ieeexplore.ieee.org/abstract/document/10888877/", "details": "Y Fan, R Li, G Zhang, C Shi, X Wang - \u2026 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Recently, due to the explosive advances of large language models (LLMs) on English, cross-lingual continual pretraining has been widely applied in obtaining Chinese LLMs. However, previous studies showed that these LLMs have suffered \u2026"}, {"title": "Leveraging large language models for structured information extraction from pathology reports", "link": "https://arxiv.org/pdf/2502.12183", "details": "JB Balasubramanian, D Adams, I Roxanis\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Background: Structured information extraction from unstructured histopathology reports facilitates data accessibility for clinical research. Manual extraction by experts is time-consuming and expensive, limiting scalability. Large language models \u2026"}, {"title": "A Robust Approach to Early Glaucoma Identification from Retinal Fundus Images using Dirichlet-based Weighted Average Ensemble and Bayesian Optimization", "link": "https://pubmed.ncbi.nlm.nih.gov/40017250/", "details": "M Mouhafid, Y Zhou, C Shan, Z Xiao - Current medical imaging", "abstract": "Objective Glaucoma is a leading cause of irreversible visual impairment and blindness worldwide, primarily linked to increased intraocular pressure (IOP). Early detection is essential to prevent further visual impairment, yet the manual diagnosis \u2026"}, {"title": "Modular Prompt Learning Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14125", "details": "Z Huang, T Pedapati, PY Chen, J Gao - arXiv preprint arXiv:2502.14125, 2025", "abstract": "Pre-trained vision-language models are able to interpret visual concepts and language semantics. Prompt learning, a method of constructing prompts for text encoders or image encoders, elicits the potentials of pre-trained models and readily \u2026"}, {"title": "MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.19634", "details": "J Pan, C Liu, J Wu, F Liu, J Zhu, HB Li, C Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning is a critical frontier for advancing medical image analysis, where transparency and trustworthiness play a central role in both clinician trust and regulatory approval. Although Medical Visual Language Models (VLMs) show \u2026"}, {"title": "Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion", "link": "https://arxiv.org/pdf/2502.13509", "details": "S Niu, J Ma, H Lin, L Bai, Z Wang, W Bi, Y Xu, G Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have shown remarkable performance in vision- language tasks, but their application in the medical field remains underexplored, particularly for integrating structured time series data with unstructured clinical notes \u2026"}, {"title": "CoCa-CXR: Contrastive Captioners Learn Strong Temporal Structures for Chest X-Ray Vision-Language Understanding", "link": "https://arxiv.org/pdf/2502.20509", "details": "Y Chen, S Xu, A Sellergren, Y Matias, A Hassidim\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models have proven to be of great benefit for medical image analysis since they learn rich semantics from both images and reports. Prior efforts have focused on better alignment of image and text representations to enhance \u2026"}, {"title": "Big-Math: A Large-Scale, High-Quality Math Dataset for Reinforcement Learning in Language Models", "link": "https://arxiv.org/pdf/2502.17387", "details": "A Albalak, D Phung, N Lile, R Rafailov, K Gandhi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Increasing interest in reasoning models has led math to become a prominent testing ground for algorithmic and methodological improvements. However, existing open math datasets either contain a small collection of high-quality, human-written \u2026"}]
