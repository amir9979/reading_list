[{"title": "Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models' Capability in Reproducing Academic Charts", "link": "https://aclanthology.org/2024.findings-emnlp.485.pdf", "details": "Z Zhang, W Ma, S Vosoughi - Findings of the Association for Computational \u2026, 2024", "abstract": "While effective data visualization is crucial to present complex information in academic research, its creation demands significant expertise in both data management and graphic design. We explore the potential of using Vision \u2026"}, {"title": "LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models", "link": "https://arxiv.org/pdf/2412.02193", "details": "FY Sun, W Liu, S Gu, D Lim, G Bhat, F Tombari, M Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Open-universe 3D layout generation arranges unlabeled 3D assets conditioned on language instruction. Large language models (LLMs) struggle with generating physically plausible 3D scenes and adherence to input instructions, particularly in \u2026"}, {"title": "Exploring Visual Multiple-Choice Question Answering with Pre-trained Vision-Language Models", "link": "https://openaccess.thecvf.com/content/ACCV2024W/LAVA/papers/Tran_Exploring_Visual_Multiple-Choice_Question_Answering_with_Pre-trained_Vision-Language_Models_ACCVW_2024_paper.pdf", "details": "GN Tran, DT Luu - Proceedings of the Asian Conference on Computer \u2026, 2024", "abstract": "Visual question answering is a challenging task in computer vision and natural language processing that involves answering questions about an image using both visual and textual information. This task is more challenging when it comes to the \u2026"}, {"title": "Sneaking Syntax into Transformer Language Models with Tree Regularization", "link": "https://arxiv.org/pdf/2411.18885", "details": "A Nandi, CD Manning, S Murty - arXiv preprint arXiv:2411.18885, 2024", "abstract": "While compositional accounts of human language understanding are based on a hierarchical tree-like process, neural models like transformers lack a direct inductive bias for such tree structures. Introducing syntactic inductive biases could unlock more \u2026"}, {"title": "Concept Bottleneck Language Models For protein design", "link": "https://arxiv.org/pdf/2411.06090", "details": "AA Ismail, T Oikarinen, A Wang, J Adebayo, S Stanton\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce Concept Bottleneck Protein Language Models (CB-pLM), a generative masked language model with a layer where each neuron corresponds to an interpretable concept. Our architecture offers three key benefits: i) Control: We can \u2026"}, {"title": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2411.06869", "details": "J Kim, H Chung, BH Kim - arXiv preprint arXiv:2411.06869, 2024", "abstract": "Category-agnostic pose estimation (CAPE) has traditionally relied on support images with annotated keypoints, a process that is often cumbersome and may fail to fully capture the necessary correspondences across diverse object categories. Recent \u2026"}, {"title": "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "link": "https://aclanthology.org/2024.emnlp-main.1249.pdf", "details": "X Lin, M Li, R Zemel, H Ji, SF Chang - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "Recently, enabling pretrained language models (PLMs) to perform zero-shot crossmodal tasks such as video question answering has been extensively studied. A popular approach is to learn a projection network that projects visual features into the \u2026"}, {"title": "Spider 2.0: Evaluating language models on real-world enterprise text-to-sql workflows", "link": "https://arxiv.org/pdf/2411.07763", "details": "F Lei, J Chen, Y Ye, R Cao, D Shin, H Su, Z Suo, H Gao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Real-world enterprise text-to-SQL workflows often involve complex cloud or local data across various database systems, multiple SQL queries in various dialects, and diverse operations from data transformation to analytics. We introduce Spider 2.0, an \u2026"}, {"title": "RadPhi-3: Small Language Models for Radiology", "link": "https://arxiv.org/pdf/2411.13604", "details": "M Ranjit, S Srivastav, T Ganu - arXiv preprint arXiv:2411.13604, 2024", "abstract": "LLM based copilot assistants are useful in everyday tasks. There is a proliferation in the exploration of AI assistant use cases to support radiology workflows in a reliable manner. In this work, we present RadPhi-3, a Small Language Model instruction \u2026"}]
