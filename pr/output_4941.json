[{"title": "A novel Parallel Cooperative Mean-Teacher framework (PCMT) combined with prediction uncertainty guide and class contrastive learning for semi-supervised polyp \u2026", "link": "https://www.sciencedirect.com/science/article/pii/S095741742401683X", "details": "Y Xia, H Yun, P Liu, M Li - Expert Systems with Applications, 2024", "abstract": "Polyp segmentation technology based on deep learning can quickly and accurately help doctors locate lesions, but its development is limited by pixel-level annotations. The polyp segmentation methods based on semi-supervised learning (SSL) is an \u2026"}, {"title": "Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation", "link": "https://arxiv.org/pdf/2407.18449", "details": "J Ma, Z Guo, F Zhou, Y Wang, Y Xu, Y Cai, Z Zhu, C Jin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Foundation models pretrained on large-scale datasets are revolutionizing the field of computational pathology (CPath). The generalization ability of foundation models is crucial for the success in various downstream clinical tasks. However, current \u2026"}, {"title": "Robust Calibration of Large Vision-Language Adapters", "link": "https://arxiv.org/pdf/2407.13588", "details": "B Murugesan, J Silva-Rodriguez, IB Ayed, J Dolz - arXiv preprint arXiv:2407.13588, 2024", "abstract": "This paper addresses the critical issue of miscalibration in CLIP-based model adaptation, particularly in the challenging scenario of out-of-distribution (OOD) samples, which has been overlooked in the existing literature on CLIP adaptation \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Leveraging Language Models and Automatic Summarization in Online Programming Learning Environments", "link": "https://dl.acm.org/doi/full/10.1145/3653323", "details": "C Areces, L Benotti, F Bulgarelli, E Echeveste, N Finzi - Communications of the ACM", "abstract": "Objective A. Enhance the interaction between tutors, the Mumuki platform, and the group of trainee programmers. By utilizing the stochastic language models of learners' errors in each programming language, training errors in the exercise are \u2026"}, {"title": "Learning Visual Grounding from Generative Vision and Language Model", "link": "https://arxiv.org/pdf/2407.14563", "details": "S Wang, D Kim, A Taalimi, C Sun, W Kuo - arXiv preprint arXiv:2407.14563, 2024", "abstract": "Visual grounding tasks aim to localize image regions based on natural language references. In this work, we explore whether generative VLMs predominantly trained on image-text data could be leveraged to scale up the text annotation of visual \u2026"}, {"title": "Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian", "link": "https://arxiv.org/pdf/2407.20654", "details": "S Auriemma, M Miliani, M Madeddu, A Bondielli\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Addressing the challenge of limited annotated data in specialized fields and low- resource languages is crucial for the effective use of Language Models (LMs). While most Large Language Models (LLMs) are trained on general-purpose English \u2026"}, {"title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)", "link": "https://arxiv.org/pdf/2407.17126", "details": "B Consoli, X Wu, S Wang, X Zhao, Y Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Extracting social determinants of health (SDoH) from unstructured medical notes depends heavily on labor-intensive annotations, which are typically task-specific, hampering reusability and limiting sharing. In this study we introduced SDoH-GPT, a \u2026"}, {"title": "Pretraining of 3D image segmentation models for retinal OCT using denoising-based self-supervised learning", "link": "https://opg.optica.org/viewmedia.cfm%3Furi%3Dboe-15-9-5025%26seq%3D0%26html%3Dtrue", "details": "A Rivail, T Ara\u00fajo, U Schmidt-Erfurth, H Bogunovi\u0107 - Biomedical Optics Express, 2024", "abstract": "Deep learning algorithms have allowed the automation of segmentation for many biomarkers in retinal OCTs, enabling comprehensive clinical research and precise patient monitoring. These segmentation algorithms predominantly rely on supervised \u2026"}]
