[{"title": "Enhancing Job Salary Prediction with Disentangled Composition Effect Modeling: A Neural Prototyping Approach", "link": "https://arxiv.org/pdf/2503.12978", "details": "Y Ji, Y Sun, H Zhu - arXiv preprint arXiv:2503.12978, 2025", "abstract": "In the era of the knowledge economy, understanding how job skills influence salary is crucial for promoting recruitment with competitive salary systems and aligned salary expectations. Despite efforts on salary prediction based on job positions and \u2026"}, {"title": "RL4Med-DDPO: Reinforcement Learning for Controlled Guidance Towards Diverse Medical Image Generation using Vision-Language Foundation Models", "link": "https://arxiv.org/pdf/2503.15784", "details": "P Saremi, A Kumar, M Mohammed, Z TehraniNasab\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-Language Foundation Models (VLFM) have shown a tremendous increase in performance in terms of generating high-resolution, photorealistic natural images. While VLFMs show a rich understanding of semantic content across modalities, they \u2026"}, {"title": "SAUCE: Selective Concept Unlearning in Vision-Language Models with Sparse Autoencoders", "link": "https://arxiv.org/pdf/2503.14530", "details": "Q Li, J Geng, D Zhu, F Cai, C Lyu, F Karray - arXiv preprint arXiv:2503.14530, 2025", "abstract": "Unlearning methods for vision-language models (VLMs) have primarily adapted techniques from large language models (LLMs), relying on weight updates that demand extensive annotated forget sets. Moreover, these methods perform \u2026"}]
