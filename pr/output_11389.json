[{"title": "A vision\u2013language foundation model for precision oncology", "link": "https://www.nature.com/articles/s41586-024-08378-w", "details": "J Xiang, X Wang, X Zhang, Y Xi, F Eweje, Y Chen, Y Li\u2026 - Nature, 2025", "abstract": "Clinical decision-making is driven by multimodal data, including clinical notes and pathological characteristics. Artificial intelligence approaches that can effectively integrate multimodal data hold significant promise in advancing clinical care 1, 2 \u2026"}, {"title": "Histo-Genomic Knowledge Association For Cancer Prognosis From Histopathology Whole Slide Images", "link": "https://ieeexplore.ieee.org/abstract/document/10830530/", "details": "Z Wang, Y Zhang, Y Xu, S Imoto, H Chen, J Song - IEEE Transactions on Medical \u2026, 2025", "abstract": "Histo-genomic multi-modal methods have emerged as a powerful paradigm, demonstrating significant potential for cancer prognosis. However, genome sequencing, unlike histopathology imaging, is still not widely accessible in \u2026"}, {"title": "SurgeryLLM: a retrieval-augmented generation large language model framework for surgical decision support and workflow enhancement", "link": "https://www.nature.com/articles/s41746-024-01391-3", "details": "CS Ong, NT Obey, Y Zheng, A Cohan, EB Schneider - npj Digital Medicine, 2024", "abstract": "SurgeryLLM, a large language model framework using Retrieval Augmented Generation demonstrably incorporated domain-specific knowledge from current evidence-based surgical guidelines when presented with patient-specific data. The \u2026"}, {"title": "Vision Language Models as Values Detectors", "link": "https://arxiv.org/pdf/2501.03957", "details": "GA Abbo, T Belpaeme - arXiv preprint arXiv:2501.03957, 2025", "abstract": "Large Language Models integrating textual and visual inputs have introduced new possibilities for interpreting complex data. Despite their remarkable ability to generate coherent and contextually relevant text based on visual stimuli, the \u2026"}, {"title": "Improving intermediate reasoning in zero-shot chain-of-thought for large language models with filter supervisor-self correction", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224019908", "details": "J Sun, Y Pan, X Yan - Neurocomputing, 2024", "abstract": "Abstract Chain of Thought (CoT) prompting enables Large Language Models (LLMs) to generate detailed intermediate reasoning steps to solve problems, demonstrating excellent performance across various fields. However, when LLMs encounter \u2026"}]
