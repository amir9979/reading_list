[{"title": "Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking", "link": "https://arxiv.org/pdf/2503.04636", "details": "Y Xu, A Liu, X Hu, L Wen, H Xiong - arXiv preprint arXiv:2503.04636, 2025", "abstract": "As open-source large language models (LLMs) like Llama3 become more capable, it is crucial to develop watermarking techniques to detect their potential misuse. Existing watermarking methods either add watermarks during LLM inference, which \u2026"}, {"title": "Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge", "link": "https://arxiv.org/pdf/2503.04036", "details": "X Cui, JTZ Wei, S Swayamdipta, R Jia - arXiv preprint arXiv:2503.04036, 2025", "abstract": "Data watermarking in language models injects traceable signals, such as specific token sequences or stylistic patterns, into copyrighted text, allowing copyright holders to track and verify training data ownership. Previous data watermarking techniques \u2026"}, {"title": "Multidimensional Consistency Improves Reasoning in Language Models", "link": "https://arxiv.org/pdf/2503.02670", "details": "H Lai, X Zhang, M Nissim - arXiv preprint arXiv:2503.02670, 2025", "abstract": "While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across \u2026"}, {"title": "A Chain-of-Thought Subspace Meta-Learning for Few-shot Image Captioning with Large Vision and Language Models", "link": "https://arxiv.org/pdf/2502.13942", "details": "H Huang, S Yuan, Y Hao, C Wen, Y Fang - arXiv preprint arXiv:2502.13942, 2025", "abstract": "A large-scale vision and language model that has been pretrained on massive data encodes visual and linguistic prior, which makes it easier to generate images and language that are more natural and realistic. Despite this, there is still a significant \u2026"}, {"title": "Adding Alignment Control to Language Models", "link": "https://arxiv.org/pdf/2503.04346", "details": "W Zhu, W Zhang, R Wang - arXiv preprint arXiv:2503.04346, 2025", "abstract": "Post-training alignment has increasingly become a crucial factor in enhancing the usability of language models (LMs). However, the strength of alignment varies depending on individual preferences. This paper proposes a method to incorporate \u2026"}, {"title": "The Challenge of Identifying the Origin of Black-Box Large Language Models", "link": "https://arxiv.org/pdf/2503.04332", "details": "Z Yang, Y Wu, Y Shen, W Dai, M Backes, Y Zhang - arXiv preprint arXiv:2503.04332, 2025", "abstract": "The tremendous commercial potential of large language models (LLMs) has heightened concerns about their unauthorized use. Third parties can customize LLMs through fine-tuning and offer only black-box API access, effectively concealing \u2026"}, {"title": "Audio-Reasoner: Improving Reasoning Capability in Large Audio Language Models", "link": "https://arxiv.org/pdf/2503.02318", "details": "Z Xie, M Lin, Z Liu, P Wu, S Yan, C Miao - arXiv preprint arXiv:2503.02318, 2025", "abstract": "Recent advancements in multimodal reasoning have largely overlooked the audio modality. We introduce Audio-Reasoner, a large-scale audio language model for deep reasoning in audio tasks. We meticulously curated a large-scale and diverse \u2026"}, {"title": "On the Acquisition of Shared Grammatical Representations in Bilingual Language Models", "link": "https://arxiv.org/pdf/2503.03962", "details": "C Arnett, TA Chang, JA Michaelov, BK Bergen - arXiv preprint arXiv:2503.03962, 2025", "abstract": "While crosslingual transfer is crucial to contemporary language models' multilingual capabilities, how it occurs is not well understood. In this paper, we ask what happens to a monolingual language model when it begins to be trained on a second \u2026"}, {"title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment", "link": "https://arxiv.org/pdf/2503.04647", "details": "W Yang, J Wu, C Wang, C Zong, J Zhang - arXiv preprint arXiv:2503.04647, 2025", "abstract": "Direct Preference Optimization (DPO) has become a prominent method for aligning Large Language Models (LLMs) with human preferences. While DPO has enabled significant progress in aligning English LLMs, multilingual preference alignment is \u2026"}]
