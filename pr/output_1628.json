'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Beyond Code: Evaluate Thought Steps for Complex Code G'
[{"title": "A Trajectory Perspective on the Role of Data Sampling Techniques in Offline Reinforcement Learning", "link": "https://dl.acm.org/doi/abs/10.5555/3635637.3662980", "details": "J Liu, Y Ma, J Hao, Y Hu, Y Zheng, T Lv, C Fan - Proceedings of the 23rd International \u2026, 2024", "abstract": "In recent years, offline reinforcement learning (RL) algorithms have gained considerable attention. However, the role of data sampling techniques in offline RL has been somewhat overlooked, despite their potential to enhance online RL \u2026"}, {"title": "Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks", "link": "https://dl.acm.org/doi/abs/10.1145/3589334.3645363", "details": "S Xu, L Pang, H Shen, X Cheng, TS Chua - Proceedings of the ACM on Web \u2026, 2024", "abstract": "Making the contents generated by Large Language Model (LLM), accurate, credible and traceable is crucial, especially in complex knowledge-intensive tasks that require multi-step reasoning and each step needs knowledge to solve. Retrieval \u2026"}]
