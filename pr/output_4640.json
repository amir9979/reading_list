[{"title": "Vision-Language Generative Model for View-Specific Chest X-ray Generation", "link": "https://proceedings.mlr.press/v248/lee24a.html", "details": "H Lee, W Kim, JH Kim, T Kim, J Kim, L Sunwoo, E Choi - Conference on Health \u2026, 2024", "abstract": "Synthetic medical data generation has opened up new possibilities in the healthcare domain, offering a powerful tool for simulating clinical scenarios, enhancing diagnostic and treatment quality, gaining granular medical knowledge, and \u2026"}, {"title": "Deep Image Priors for Magnetic Resonance Fingerprinting with pretrained Bloch-consistent denoising autoencoders", "link": "https://arxiv.org/pdf/2407.19866", "details": "P Mayo, M Cencini, K Fatania, CM Pirkl, MI Menzel\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The estimation of multi-parametric quantitative maps from Magnetic Resonance Fingerprinting (MRF) compressed sampled acquisitions, albeit successful, remains a challenge due to the high underspampling rate and artifacts naturally occuring \u2026"}, {"title": "GP-VLS: A general-purpose vision language model for surgery", "link": "https://arxiv.org/pdf/2407.19305", "details": "S Schmidgall, J Cho, C Zakka, W Hiesinger - arXiv preprint arXiv:2407.19305, 2024", "abstract": "Surgery requires comprehensive medical knowledge, visual assessment skills, and procedural expertise. While recent surgical AI models have focused on solving task- specific problems, there is a need for general-purpose systems that can understand \u2026"}, {"title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge", "link": "https://arxiv.org/pdf/2407.19594", "details": "T Wu, W Yuan, O Golovneva, J Xu, Y Tian, J Jiao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains. While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can \u2026"}, {"title": "Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation", "link": "https://arxiv.org/pdf/2407.18449", "details": "J Ma, Z Guo, F Zhou, Y Wang, Y Xu, Y Cai, Z Zhu, C Jin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Foundation models pretrained on large-scale datasets are revolutionizing the field of computational pathology (CPath). The generalization ability of foundation models is crucial for the success in various downstream clinical tasks. However, current \u2026"}, {"title": "Federated Foundation Model for Cardiac CT Imaging", "link": "https://arxiv.org/pdf/2407.07557", "details": "M T\u00f6lle, P Garthe, C Scherer, JM Seliger, A Leha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Federated learning (FL) is a renowned technique for utilizing decentralized data while preserving privacy. However, real-world applications often involve inherent challenges such as partially labeled datasets, where not all clients possess expert \u2026"}, {"title": "Magic3DSketch: Create Colorful 3D Models From Sketch-Based 3D Modeling Guided by Text and Language-Image Pre-Training", "link": "https://arxiv.org/pdf/2407.19225", "details": "Y Zang, Y Han, C Ding, J Zhang, T Chen - arXiv preprint arXiv:2407.19225, 2024", "abstract": "The requirement for 3D content is growing as AR/VR application emerges. At the same time, 3D modelling is only available for skillful experts, because traditional methods like Computer-Aided Design (CAD) are often too labor-intensive and skill \u2026"}, {"title": "UniVoxel: Fast Inverse Rendering by Unified Voxelization of Scene Representation", "link": "https://arxiv.org/pdf/2407.19542", "details": "S Wu, S Tang, G Lu, J Liu, W Pei - arXiv preprint arXiv:2407.19542, 2024", "abstract": "Typical inverse rendering methods focus on learning implicit neural scene representations by modeling the geometry, materials and illumination separately, which entails significant computations for optimization. In this work we design a \u2026"}, {"title": "Towards Effective and Efficient Continual Pre-training of Large Language Models", "link": "https://arxiv.org/pdf/2407.18743", "details": "J Chen, Z Chen, J Wang, K Zhou, Y Zhu, J Jiang, Y Min\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Continual pre-training (CPT) has been an important approach for adapting language models to specific domains or tasks. To make the CPT approach more traceable, this paper presents a technical report for continually pre-training Llama-3 (8B), which \u2026"}]
