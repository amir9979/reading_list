[{"title": "Scalable Multi-Domain Adaptation of Language Models using Modular Experts", "link": "https://arxiv.org/pdf/2410.10181", "details": "P Schafhalter, S Liao, Y Zhou, CK Yeh, A Kandoor\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Domain-specific adaptation is critical to maximizing the performance of pre-trained language models (PLMs) on one or multiple targeted tasks, especially under resource-constrained use cases, such as edge devices. However, existing methods \u2026"}, {"title": "MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.10139", "details": "P Xia, S Han, S Qiu, Y Zhou, Z Wang, W Zheng, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Interleaved multimodal comprehension and generation, enabling models to produce and interpret both images and text in arbitrary sequences, have become a pivotal area in multimodal learning. Despite significant advancements, the evaluation of this \u2026"}, {"title": "Metalic: Meta-Learning In-Context with Protein Language Models", "link": "https://arxiv.org/pdf/2410.08355", "details": "J Beck, S Surana, M McAuliffe, O Bent, TD Barrett\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Predicting the biophysical and functional properties of proteins is essential for in silico protein design. Machine learning has emerged as a promising technique for such prediction tasks. However, the relative scarcity of in vitro annotations means \u2026"}, {"title": "ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains", "link": "https://arxiv.org/pdf/2410.09870", "details": "Y Park, C Yoon, J Park, D Lee, M Jeong, J Kang - arXiv preprint arXiv:2410.09870, 2024", "abstract": "Large language models (LLMs) have significantly impacted many aspects of our lives. However, assessing and ensuring their chronological knowledge remains challenging. Existing approaches fall short in addressing the accumulative nature of \u2026"}, {"title": "SeRA: Self-Reviewing and Alignment of Large Language Models using Implicit Reward Margins", "link": "https://arxiv.org/pdf/2410.09362", "details": "J Ko, S Dingliwal, B Ganesh, S Sengupta, S Bodapati\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Direct alignment algorithms (DAAs), such as direct preference optimization (DPO), have become popular alternatives for Reinforcement Learning from Human Feedback (RLHF) due to their simplicity, efficiency, and stability. However, the \u2026"}, {"title": "Evolutionary Contrastive Distillation for Language Model Alignment", "link": "https://arxiv.org/pdf/2410.07513", "details": "J Katz-Samuels, Z Li, H Yun, P Nigam, Y Xu, V Petricek\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The ability of large language models (LLMs) to execute complex instructions is essential for their real-world applications. However, several recent studies indicate that LLMs struggle with challenging instructions. In this paper, we propose \u2026"}, {"title": "Self-Data Distillation for Recovering Quality in Pruned Large Language Models", "link": "https://arxiv.org/pdf/2410.09982", "details": "V Thangarasa, G Venkatesh, N Sinnadurai, S Lie - arXiv preprint arXiv:2410.09982, 2024", "abstract": "Large language models have driven significant progress in natural language processing, but their deployment requires substantial compute and memory resources. As models scale, compression techniques become essential for \u2026"}, {"title": "Safety-Aware Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2410.10014", "details": "HK Choi, X Du, Y Li - arXiv preprint arXiv:2410.10014, 2024", "abstract": "Fine-tuning Large Language Models (LLMs) has emerged as a common practice for tailoring models to individual needs and preferences. The choice of datasets for fine- tuning can be diverse, introducing safety concerns regarding the potential inclusion \u2026"}, {"title": "Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs", "link": "https://arxiv.org/pdf/2410.10739", "details": "I Jindal, C Badrinath, P Bharti, L Vinay, SD Sharma - arXiv preprint arXiv:2410.10739, 2024", "abstract": "Large Language Models (LLMs) for public use require continuous pre-training to remain up-to-date with the latest data. The models also need to be fine-tuned with specific instructions to maintain their ability to follow instructions accurately. Typically \u2026"}]
