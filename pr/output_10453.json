[{"title": "SAM Helps SSL: Mask-guided Attention Bias for Self-supervised Learning", "link": "https://bmva-archive.org.uk/bmvc/2024/papers/Paper_240/paper.pdf", "details": "K Taguchi, T Kawai, W Imaeda, H Fujiyoshi - 2024", "abstract": "The vision transformer (ViT) and self-supervised learning (SSL) are key technologies for accelerating data scalability, contributing to the emergence of a foundation model in computer vision. In this paper, we focus on the potential of masks generated by the \u2026"}, {"title": "Efficient Object-centric Representation Learning with Pre-trained Geometric Prior", "link": "https://arxiv.org/pdf/2412.12331", "details": "PHL Khac, G Healy, AF Smeaton - arXiv preprint arXiv:2412.12331, 2024", "abstract": "This paper addresses key challenges in object-centric representation learning of video. While existing approaches struggle with complex scenes, we propose a novel weakly-supervised framework that emphasises geometric understanding and \u2026"}, {"title": "AttEntropy: On the Generalization Ability of Supervised Semantic Segmentation Transformers to New Objects in New Domains", "link": "https://bmva-archive.org.uk/bmvc/2024/papers/Paper_215/paper.pdf", "details": "K Lis, M Rottmann, A M\u00fctze, S Honari, P Fua\u2026 - 2024", "abstract": "In addition to impressive performance, vision transformers have demonstrated remarkable abilities to encode information they were not trained to extract. For example, this information can be used to perform segmentation or single-view depth \u2026"}, {"title": "Multi-Modal Information Bottleneck Attribution with Cross-Attention Guidance", "link": "https://bmva-archive.org.uk/bmvc/2024/papers/Paper_64/paper.pdf", "details": "P Bourigault, E Bourigault, DP Mandic - 2024", "abstract": "For the progression of interpretable machine learning, particularly in the intersection of vision and language, ensuring transparency and comprehensibility in model decisions is crucial. This work introduces an enhancement to the Multi-modal \u2026"}, {"title": "Self-supervised learning for radio-astronomy source classification: a benchmark", "link": "https://arxiv.org/pdf/2411.14078", "details": "T Cecconello, S Riggi, U Becciano, F Vitello\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The upcoming Square Kilometer Array (SKA) telescope marks a significant step forward in radio astronomy, presenting new opportunities and challenges for data analysis. Traditional visual models pretrained on optical photography images may \u2026"}, {"title": "PatchRot: Self-Supervised Training of Vision Transformers by Rotation Prediction", "link": "https://bmva-archive.org.uk/bmvc/2024/papers/Paper_391/paper.pdf", "details": "S Chhabra, H Venkateswara, B Li - 2024", "abstract": "Vision transformers require a huge amount of labeled data to outperform convolutional neural networks. However, annotating such a large dataset is an expensive process. Self-supervised learning techniques alleviate this problem by \u2026"}]
