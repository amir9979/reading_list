[{"title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization", "link": "https://arxiv.org/pdf/2407.07880", "details": "J Wu, Y Xie, Z Yang, J Wu, J Chen, J Gao, B Ding\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences. We categorize noise into pointwise noise, which includes low \u2026"}, {"title": "Multimodal Pre-training for Sequential Recommendation via Contrastive Learning", "link": "https://dl.acm.org/doi/pdf/10.1145/3682075", "details": "L Zhang, X Zhou, Z Zeng, Z Shen - ACM Transactions on Recommender Systems, 2024", "abstract": "Sequential recommendation systems often suffer from data sparsity, leading to suboptimal performance. While multimodal content, such as images and text, has been utilized to mitigate this issue, its integration within sequential recommendation \u2026"}, {"title": "Explainable Stock Price Movement Prediction using Contrastive Learning", "link": "https://w.sentic.net/explainable-stock-price-movement-prediction.pdf", "details": "K Du, R Mao, F Xing, E Cambria - 2024", "abstract": "Stock price movement prediction is a high-stakes application that requires persuasion and collaboration with human decision-makers. Explainability is thus a highly desired property for the prediction, despite being overlooked in the recent \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}, {"title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application", "link": "https://arxiv.org/pdf/2407.01885", "details": "C Yang, W Lu, Y Zhu, Y Wang, Q Chen, C Gao, B Yan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in various domains, attracting significant interest from both academia and industry. Despite their impressive performance, the substantial size and computational demands of LLMs \u2026"}, {"title": "Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation", "link": "https://arxiv.org/pdf/2407.18789", "details": "DNL Vu, T Igamberdiev, I Habernal - arXiv preprint arXiv:2407.18789, 2024", "abstract": "Applying differential privacy (DP) by means of the DP-SGD algorithm to protect individual data points during training is becoming increasingly popular in NLP. However, the choice of granularity at which DP is applied is often neglected. For \u2026"}, {"title": "A Data-Centric Perspective on Evaluating Machine Learning Models for Tabular Data", "link": "https://arxiv.org/pdf/2407.02112", "details": "A Tschalzev, S Marton, S L\u00fcdtke, C Bartelt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Tabular data is prevalent in real-world machine learning applications, and new models for supervised learning of tabular data are frequently proposed. Comparative studies assessing the performance of models typically consist of model-centric \u2026"}, {"title": "Towards Effective and Efficient Continual Pre-training of Large Language Models", "link": "https://arxiv.org/pdf/2407.18743", "details": "J Chen, Z Chen, J Wang, K Zhou, Y Zhu, J Jiang, Y Min\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Continual pre-training (CPT) has been an important approach for adapting language models to specific domains or tasks. To make the CPT approach more traceable, this paper presents a technical report for continually pre-training Llama-3 (8B), which \u2026"}, {"title": "The Need for Guardrails with Large Language Models in Medical Safety-Critical Settings: An Artificial Intelligence Application in the Pharmacovigilance Ecosystem", "link": "https://arxiv.org/pdf/2407.18322", "details": "JB Hakim, JL Painter, D Ramcharran, V Kara, G Powell\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) are useful tools with the capacity for performing specific types of knowledge work at an effective scale. However, LLM deployments in high-risk and safety-critical domains pose unique challenges, notably the issue \u2026"}]
