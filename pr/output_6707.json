[{"title": "Understanding Defects in Generated Codes by Language Models", "link": "https://arxiv.org/pdf/2408.13372", "details": "AM Esfahani, N Kahani, SA Ajila - arXiv preprint arXiv:2408.13372, 2024", "abstract": "This study investigates the reliability of code generation by Large Language Models (LLMs), focusing on identifying and analyzing defects in the generated code. Despite the advanced capabilities of LLMs in automating code generation, ensuring the \u2026"}, {"title": "Zero\u2010and few\u2010shot prompting of generative large language models provides weak assessment of risk of bias in clinical trials", "link": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/jrsm.1749", "details": "S \u0160uster, T Baldwin, K Verspoor - Research Synthesis Methods", "abstract": "Existing systems for automating the assessment of risk\u2010of\u2010bias (RoB) in medical studies are supervised approaches that require substantial training data to work well. However, recent revisions to RoB guidelines have resulted in a scarcity of available \u2026"}, {"title": "A New Era in Computational Pathology: A Survey on Foundation and Vision-Language Models", "link": "https://arxiv.org/pdf/2408.14496", "details": "D Chanda, M Aryal, NY Soltani, M Ganji - arXiv preprint arXiv:2408.14496, 2024", "abstract": "Recent advances in deep learning have completely transformed the domain of computational pathology (CPath), which in turn altered the diagnostic workflow of pathologists by integrating foundation models (FMs) and vision-language models \u2026"}, {"title": "PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning", "link": "https://arxiv.org/pdf/2408.16769", "details": "N Hussein, F Shamshad, M Naseer, K Nandakumar - arXiv preprint arXiv:2408.16769, 2024", "abstract": "Medical vision-language models (Med-VLMs) trained on large datasets of medical image-text pairs and later fine-tuned for specific tasks have emerged as a mainstream paradigm in medical image analysis. However, recent studies have \u2026"}, {"title": "Language Models Pre-training", "link": "https://link.springer.com/content/pdf/10.1007/978-3-031-65647-7_2.pdf", "details": "U Kamath, K Keenan, G Somers, S Sorenson - Large Language Models: A Deep Dive \u2026, 2024", "abstract": "Pre-training forms the foundation for LLMs' capabilities. LLMs gain vital language comprehension and generative language skills by using large-scale datasets. The size and quality of these datasets are essential for maximizing LLMs' potential. It is \u2026"}, {"title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection", "link": "https://arxiv.org/pdf/2409.06072", "details": "J Chakraborty, W Xia, A Majumder, D Ma, W Chaabene\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks. However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further \u2026"}, {"title": "Causal-Guided Active Learning for Debiasing Large Language Models", "link": "https://arxiv.org/pdf/2408.12942", "details": "Z Sun, L Du, X Ding, Y Ma, K Qiu, T Liu, B Qin - arXiv preprint arXiv:2408.12942, 2024", "abstract": "Although achieving promising performance, recent analyses show that current generative large language models (LLMs) may still capture dataset biases and utilize them for generation, leading to poor generalizability and harmfulness of LLMs \u2026"}, {"title": "Efficient Detection of Toxic Prompts in Large Language Models", "link": "https://arxiv.org/pdf/2408.11727", "details": "Y Liu, J Yu, H Sun, L Shi, G Deng, Y Chen, Y Liu - arXiv preprint arXiv:2408.11727, 2024", "abstract": "Large language models (LLMs) like ChatGPT and Gemini have significantly advanced natural language processing, enabling various applications such as chatbots and automated content generation. However, these models can be \u2026"}, {"title": "SafetyBench: Evaluating the Safety of Large Language Models", "link": "https://aclanthology.org/2024.acl-long.830.pdf", "details": "Z Zhang, L Lei, L Wu, R Sun, Y Huang, C Long, X Liu\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs \u2026"}]
