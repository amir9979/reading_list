[{"title": "AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine and Healthcare", "link": "https://arxiv.org/pdf/2505.19562", "details": "Y Xiao, J Huang, R He, J Xiao, MR Mousavi, Y Liu, K Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) are reaching expert-level accuracy on medical diagnosis questions, yet their mistakes and the biases behind them pose life-critical risks. Bias linked to race, sex, and socioeconomic status is already well known, but a \u2026", "entry_id": "http://arxiv.org/abs/2505.19562v1", "updated": "2025-05-26 06:24:20", "published": "2025-05-26 06:24:20", "authors": "Ying Xiao;Jie Huang;Ruijuan He;Jing Xiao;Mohammad Reza Mousavi;Yepang Liu;Kezhi Li;Zhenpeng Chen;Jie M. Zhang", "summary": "Large language models (LLMs) are reaching expert-level accuracy on medical\ndiagnosis questions, yet their mistakes and the biases behind them pose\nlife-critical risks. Bias linked to race, sex, and socioeconomic status is\nalready well known, but a consistent and automatic testbed for measuring it is\nmissing. To fill this gap, this paper presents AMQA -- an Adversarial Medical\nQuestion-Answering dataset -- built for automated, large-scale bias evaluation\nof LLMs in medical QA. AMQA includes 4,806 medical QA pairs sourced from the\nUnited States Medical Licensing Examination (USMLE) dataset, generated using a\nmulti-agent framework to create diverse adversarial descriptions and question\npairs. Using AMQA, we benchmark five representative LLMs and find surprisingly\nsubstantial disparities: even GPT-4.1, the least biased model tested, answers\nprivileged-group questions over 10 percentage points more accurately than\nunprivileged ones. Compared with the existing benchmark CPV, AMQA reveals 15%\nlarger accuracy gaps on average between privileged and unprivileged groups. Our\ndataset and code are publicly available at https://github.com/XY-Showing/AMQA\nto support reproducible research and advance trustworthy, bias-aware medical\nAI.", "comment": null, "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI", "links": "http://arxiv.org/abs/2505.19562v1;http://arxiv.org/pdf/2505.19562v1", "pdf_url": "http://arxiv.org/pdf/2505.19562v1"}, {"title": "Applying NLP Methods to Code Functional Performance in Electronic Health Records Using the International Classification of Functioning, Disability, and Health", "link": "https://www.sciencedirect.com/science/article/pii/S1936657425001177", "details": "E Marfeo, M Sacco, JC Maldonado, K Coale, RJ Silva\u2026 - Disability and Health \u2026, 2025", "abstract": "ABSTRACT BACKGROUND Clinical records often provide information on a person's functioning (activities), reflecting their lived experience of health. Automated extraction using clinical natural language processing (cNLP) can assist providers \u2026"}, {"title": "VLM-KG: Multimodal Radiology Knowledge Graph Generation", "link": "https://arxiv.org/pdf/2505.17042", "details": "A Abdullah, ST Kim - arXiv preprint arXiv:2505.17042, 2025", "abstract": "Vision-Language Models (VLMs) have demonstrated remarkable success in natural language generation, excelling at instruction following and structured output generation. Knowledge graphs play a crucial role in radiology, serving as valuable \u2026", "entry_id": "http://arxiv.org/abs/2505.17042v1", "updated": "2025-05-13 06:11:10", "published": "2025-05-13 06:11:10", "authors": "Abdullah Abdullah;Seong Tae Kim", "summary": "Vision-Language Models (VLMs) have demonstrated remarkable success in natural\nlanguage generation, excelling at instruction following and structured output\ngeneration. Knowledge graphs play a crucial role in radiology, serving as\nvaluable sources of factual information and enhancing various downstream tasks.\nHowever, generating radiology-specific knowledge graphs presents significant\nchallenges due to the specialized language of radiology reports and the limited\navailability of domain-specific data. Existing solutions are predominantly\nunimodal, meaning they generate knowledge graphs only from radiology reports\nwhile excluding radiographic images. Additionally, they struggle with long-form\nradiology data due to limited context length. To address these limitations, we\npropose a novel multimodal VLM-based framework for knowledge graph generation\nin radiology. Our approach outperforms previous methods and introduces the\nfirst multimodal solution for radiology knowledge graph generation.", "comment": "10 pages, 2 figures", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.CV;cs.IR;cs.LG", "links": "http://arxiv.org/abs/2505.17042v1;http://arxiv.org/pdf/2505.17042v1", "pdf_url": "http://arxiv.org/pdf/2505.17042v1"}, {"title": "Evaluating Methods for Imputing Race and Ethnicity in Electronic Health Record Data", "link": "https://pubmed.ncbi.nlm.nih.gov/40421571/", "details": "S Conderino, J Divers, JA Dodson, LE Thorpe\u2026 - Health services research", "abstract": "Objective To compare anonymized and non-anonymized approaches for imputing race and ethnicity in descriptive studies of chronic disease burden using electronic health record (EHR)-based datasets. Study setting and design In this New York City \u2026"}, {"title": "Unlocking German Clinical Text Data: Advanced De-Identification for LLM Training", "link": "https://archiv.ub.uni-heidelberg.de/volltextserver/36594/7/Spring_Symposium_MI_2025.pdf%23page%3D43", "details": "M Seiferling, C Lohrb, C Dietericha - 3rd Heidelberg Spring Symposium Medical Informatics", "abstract": "The Medical Informatics Initiative (MII)[1] represents the most comprehensive research program in Germany aimed at integrating clinical patient data across multiple institutions. While initial efforts primarily focused on structured data, the \u2026"}]
