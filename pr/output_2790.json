[{"title": "Is On-Device AI Broken and Exploitable? Assessing the Trust and Ethics in Small Language Models", "link": "https://arxiv.org/pdf/2406.05364", "details": "K Nakka, J Dani, N Saxena - arXiv preprint arXiv:2406.05364, 2024", "abstract": "In this paper, we present a very first study to investigate trust and ethical implications of on-device artificial intelligence (AI), focusing on''small''language models (SLMs) amenable for personal devices like smartphones. While on-device SLMs promise \u2026"}, {"title": "Experiences of Electronic Health Records' and Client Information Systems' Use on a Mobile Device and Factors Associated With Work Time Savings Among Practical \u2026", "link": "https://www.jmir.org/2024/1/e46954/", "details": "S Paatela, M Kyyts\u00f6nen, K Saranto, UM Kinnunen\u2026 - Journal of Medical Internet \u2026, 2024", "abstract": "Background The transmission of clinical information in nursing predominantly occurs through digital solutions, such as computers and mobile devices, in today's era. Various technological systems, including electronic health records (EHRs) and client \u2026"}, {"title": "Characterizing Public Sentiments and Drug Interactions during COVID-19: A Pretrained Language Model and Network Analysis of Social Media Discourse", "link": "https://www.medrxiv.org/content/10.1101/2024.06.06.24308537.full.pdf", "details": "W Li, Y Hua, P Zhou, Z Li, X Xu, J Yang - medRxiv, 2024", "abstract": "Objective: Harnessing drug-related data posted on social media in real time can offer insights into how the pandemic impacts drug use and monitor misinformation. This study developed a natural language processing (NLP) pipeline tailored for the \u2026"}, {"title": "Modeling Comparative Logical Relation with Contrastive Learning for Text Generation", "link": "https://arxiv.org/abs/2406.09095", "details": "Y Dan, J Tian, J Zhou, M Yan, J Zhang, Q Chen, L He - arXiv preprint arXiv \u2026, 2024", "abstract": "Data-to-Text Generation (D2T), a classic natural language generation problem, aims at producing fluent descriptions for structured input data, such as a table. Existing D2T works mainly focus on describing the superficial associative relations among \u2026"}, {"title": "Self-Hint Prompting Improves Zero-shot Reasoning in Large Language Models via Reflective Cycle", "link": "https://escholarship.org/content/qt5ht3f0dt/qt5ht3f0dt_noSplash_508be8c9920e4bd796bec268a73a6b1a.pdf", "details": "J Chen, J Tian, Y Jin - Proceedings of the Annual Meeting of the Cognitive \u2026, 2024", "abstract": "Chain-of-Thought (CoT) has brought a fresh perspective to improve the reasoning ability of large language models (LLMs). To relieve the burden of manual design in CoT, Zero-shot CoT has pioneered a direct interaction with LLMs. Based on it \u2026"}]
