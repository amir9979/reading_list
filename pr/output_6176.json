[{"title": "Vision-Language and Large Language Model Performance in Gastroenterology: GPT, Claude, Llama, Phi, Mistral, Gemma, and Quantized Models", "link": "https://arxiv.org/pdf/2409.00084", "details": "SAA Safavi-Naini, S Ali, O Shahab, Z Shahhoseini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Background and Aims: This study evaluates the medical reasoning performance of large language models (LLMs) and vision language models (VLMs) in gastroenterology. Methods: We used 300 gastroenterology board exam-style \u2026"}, {"title": "Towards Artwork Explanation in Large-scale Vision Language Models", "link": "https://aclanthology.org/2024.acl-short.65.pdf", "details": "K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - Proceedings of the 62nd \u2026, 2024", "abstract": "Abstract Large-scale Vision-Language Models (LVLMs) output text from images and instructions, demonstrating advanced capabilities in text generation and comprehension. However, it has not been clarified to what extent LVLMs understand \u2026"}, {"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "How Does Diverse Interpretability of Textual Prompts Impact Medical Vision-Language Zero-Shot Tasks?", "link": "https://arxiv.org/pdf/2409.00543", "details": "S Wang, C Liu, R Arcucci - arXiv preprint arXiv:2409.00543, 2024", "abstract": "Recent advancements in medical vision-language pre-training (MedVLP) have significantly enhanced zero-shot medical vision tasks such as image classification by leveraging large-scale medical image-text pair pre-training. However, the \u2026"}, {"title": "End-to-End Clustering Enhanced Contrastive Learning for Radiology Reports Generation", "link": "https://ieeexplore.ieee.org/abstract/document/10663478/", "details": "X Liu, J Xin, Q Shen, C Li, Z Huang, Z Wang - IEEE Transactions on Emerging Topics \u2026, 2024", "abstract": "With the rapid growth of medical imaging data, radiologists must dedicate a significant amount of time to report writing. Automated generation of radiology reports not only alleviates the heavy workload of physicians but, more importantly, can \u2026"}, {"title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries", "link": "https://arxiv.org/pdf/2409.00844", "details": "B Yang, F Cui, K Paster, J Ba, P Vaezipoor, S Pitis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid development and dynamic nature of large language models (LLMs) make it difficult for conventional quantitative benchmarks to accurately assess their capabilities. We propose report cards, which are human-interpretable, natural \u2026"}, {"title": "Enhancing Remote Sensing Vision-Language Models for Zero-Shot Scene Classification", "link": "https://arxiv.org/pdf/2409.00698", "details": "KE Khoury, M Zanella, B G\u00e9rin, T Godelaine, B Macq\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Models for remote sensing have shown promising uses thanks to their extensive pretraining. However, their conventional usage in zero-shot scene classification methods still involves dividing large images into patches and making \u2026"}, {"title": "Does Knowledge Localization Hold True? Surprising Differences Between Entity and Relation Perspectives in Language Models", "link": "https://arxiv.org/pdf/2409.00617", "details": "Y Wei, X Yu, Y Weng, H Ma, Y Zhang, J Zhao, K Liu - arXiv preprint arXiv:2409.00617, 2024", "abstract": "Large language models encapsulate knowledge and have demonstrated superior performance on various natural language processing tasks. Recent studies have localized this knowledge to specific model parameters, such as the MLP weights in \u2026"}, {"title": "FlashFlex: Accommodating Large Language Model Training over Heterogeneous Environment", "link": "https://arxiv.org/pdf/2409.01143", "details": "R Yan, Y Jiang, W Tao, X Nie, B Cui, B Yuan - arXiv preprint arXiv:2409.01143, 2024", "abstract": "Training large language model (LLM) is a computationally intensive task, which is typically conducted in data centers with homogeneous high-performance GPUs. This paper explores an alternative approach by deploying the training computation across \u2026"}]
