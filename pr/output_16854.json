[{"title": "Beyond maximum-likelihood training: analysis and methods for building robust language generation models", "link": "https://escholarship.mcgill.ca/downloads/d791sp070", "details": "K Arora - 2025", "abstract": "Large language generation models have seen a step change in their capabilities in the last few years, and these models are now being widely deployed in user-facing applications such as search, email, and customer support. Despite these apparent \u2026"}, {"title": "Clinical Information Extraction with Large Language Models: A Case Study on Organ Procurement", "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12099322/", "details": "H Adam, J Lin, J Lin, H Keenan, A Wilson, M Ghassemi - AMIA Annual Symposium \u2026, 2025", "abstract": "Recent work has demonstrated that large language models (LLMs) are powerful tools for clinical information extraction from unstructured text. However, existing approaches have largely ignored the extraction of numeric information such as \u2026"}, {"title": "Structured Knowledge Base Enhances Effective Use of Large Language Models for Metadata Curation", "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12099408/", "details": "SS Sundaram, B Solomon, A Khatri, A Laumas\u2026 - AMIA Annual Symposium \u2026, 2025", "abstract": "Metadata play a crucial role in ensuring the findability, accessibility, interoperability, and reusability of datasets. This paper investigates the potential of large language models (LLMs), specifically GPT-4, to improve adherence to metadata standards in \u2026"}, {"title": "Modular Methods for Continuous and Efficient Adaptation of Large Language Models", "link": "https://cdr.lib.unc.edu/downloads/6682xk59k", "details": "P Yadav - 2025", "abstract": "This thesis investigates modular methods as alternatives for achieving continuous and efficient adaptation in Large Language Models (LLMs). The immediate goal of this research is to develop and empirically validate novel modular techniques that \u2026"}]
