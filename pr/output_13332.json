[{"title": "Predicting Through Generation: Why Generation Is Better for Prediction", "link": "https://arxiv.org/pdf/2502.17817", "details": "M Kowsher, NJ Prottasha, P Bhat, CN Yu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper argues that generating output tokens is more effective than using pooled representations for prediction tasks because token-level generation retains more mutual information. Since LLMs are trained on massive text corpora using next-token \u2026"}, {"title": "Injury degree appraisal of large language model based on retrieval-augmented generation and deep learning", "link": "https://www.sciencedirect.com/science/article/pii/S0160252725000032", "details": "F Zhang, Y Luo, Z Gao, A Han - International Journal of Law and Psychiatry, 2025", "abstract": "Abstract Large Language Models (LLMs) have shown impressive performance in various natural language processing tasks. However, their application in specialized domains like forensic injury appraisal remains challenging due to the lack of domain \u2026"}, {"title": "LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena", "link": "https://arxiv.org/pdf/2502.17967", "details": "T Ma, J Du, W Huang, W Wang, L Xie, X Zhong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a \u2026"}, {"title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models", "link": "https://arxiv.org/pdf/2502.03199%3F", "details": "J Wu, Y Shen, S Liu, Y Tang, S Song, X Wang, L Cai - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the \u2026"}, {"title": "Stackelberg Game Preference Optimization for Data-Efficient Alignment of Language Models", "link": "https://arxiv.org/pdf/2502.18099", "details": "X Chu, Z Zhang, T Jia, Y Jin - arXiv preprint arXiv:2502.18099, 2025", "abstract": "Aligning language models with human preferences is critical for real-world deployment, but existing methods often require large amounts of high-quality human annotations. Aiming at a data-efficient alignment method, we propose Stackelberg \u2026"}, {"title": "Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective", "link": "https://arxiv.org/pdf/2502.17262", "details": "C Xu, K Chen, X Li, K Shen, C Li - arXiv preprint arXiv:2502.17262, 2025", "abstract": "The rapid advancements in computing dramatically increase the scale and cost of training Large Language Models (LLMs). Accurately predicting downstream task performance prior to model training is crucial for efficient resource allocation, yet \u2026"}, {"title": "Personalization Toolkit: Training Free Personalization of Large Vision Language Models", "link": "https://arxiv.org/pdf/2502.02452%3F", "details": "S Seifi, V Dorovatas, DO Reino, R Aljundi - arXiv preprint arXiv:2502.02452, 2025", "abstract": "Large Vision Language Models (LVLMs) have significant potential to deliver personalized assistance by adapting to individual users' unique needs and preferences. Personalization of LVLMs is an emerging area that involves \u2026"}, {"title": "CALM: Unleashing the Cross-Lingual Self-Aligning Ability of Language Model Question Answering", "link": "https://arxiv.org/pdf/2501.18457%3F", "details": "Y Wang, Z Fan, Q Wang, M Fung, H Ji - arXiv preprint arXiv:2501.18457, 2025", "abstract": "Large Language Models (LLMs) are pretrained on extensive multilingual corpora to acquire both language-specific cultural knowledge and general knowledge. Ideally, while LLMs should provide consistent responses to culture-independent questions \u2026"}, {"title": "FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models", "link": "https://arxiv.org/pdf/2502.17924", "details": "H Lin, Y Deng, Y Gu, W Zhang, J Ma, SK Ng, TS Chua - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the \u2026"}]
