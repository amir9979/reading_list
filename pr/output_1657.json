'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Large Language Models in Healthcare: A Comprehensive B'
[{"title": "Self-Play Preference Optimization for Language Model Alignment", "link": "https://arxiv.org/pdf/2405.00675", "details": "Y Wu, Z Sun, H Yuan, K Ji, Y Yang, Q Gu - arXiv preprint arXiv:2405.00675, 2024", "abstract": "Traditional reinforcement learning from human feedback (RLHF) approaches relying on parametric models like the Bradley-Terry model fall short in capturing the intransitivity and irrationality in human preferences. Recent advancements suggest \u2026"}, {"title": "Systematic synthesis of design prompts for large language models in conceptual design", "link": "https://www.sciencedirect.com/science/article/pii/S000785062400074X", "details": "Y Tian, A Liu, Y Dai, K Nagato, M Nakao - CIRP Annals, 2024", "abstract": "Recent advancements in large language models (LLMs) demonstrate great potential in supporting engineering design, especially conceptual design. Prompt engineering plays an important role in facilitating designer-LLM collaboration in conceptual \u2026"}]
