[{"title": "Safe RLHF-V: Safe Reinforcement Learning from Human Feedback in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2503.17682", "details": "J Ji, X Chen, R Pan, H Zhu, C Zhang, J Li, D Hong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multimodal large language models (MLLMs) are critical for developing general- purpose AI assistants, yet they face growing safety risks. How can we ensure that MLLMs are safely aligned to prevent undesired behaviors such as discrimination \u2026"}, {"title": "CoMP: Continual Multimodal Pre-training for Vision Foundation Models", "link": "https://arxiv.org/pdf/2503.18931", "details": "Y Chen, L Meng, W Peng, Z Wu, YG Jiang - arXiv preprint arXiv:2503.18931, 2025", "abstract": "Pre-trained Vision Foundation Models (VFMs) provide strong visual representations for a wide range of applications. In this paper, we continually pre-train prevailing VFMs in a multimodal manner such that they can effortlessly process visual inputs of \u2026"}, {"title": "R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization", "link": "https://arxiv.org/pdf/2503.12937%3F", "details": "J Zhang, J Huang, H Yao, S Liu, X Zhang, S Lu, D Tao - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent studies generally enhance MLLMs' reasoning capabilities via supervised fine- tuning on high-quality chain-of-thought reasoning data, which often leads models to merely imitate successful reasoning paths without understanding what the wrong \u2026"}, {"title": "Corrective In-Context Learning: Evaluating Self-Correction in Large Language Models", "link": "https://arxiv.org/pdf/2503.16022", "details": "M Sanz-Guerrero, K von der Wense - arXiv preprint arXiv:2503.16022, 2025", "abstract": "In-context learning (ICL) has transformed the use of large language models (LLMs) for NLP tasks, enabling few-shot learning by conditioning on labeled examples without finetuning. Despite its effectiveness, ICL is prone to errors, especially for \u2026"}, {"title": "ViLBench: A Suite for Vision-Language Process Reward Modeling", "link": "https://arxiv.org/pdf/2503.20271", "details": "H Tu, W Feng, H Chen, H Liu, X Tang, C Xie - arXiv preprint arXiv:2503.20271, 2025", "abstract": "Process-supervised reward models serve as a fine-grained function that provides detailed step-wise feedback to model responses, facilitating effective selection of reasoning trajectories for complex tasks. Despite its advantages, evaluation on \u2026"}, {"title": "From Chaos to Order: The Atomic Reasoner Framework for Fine-grained Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2503.15944", "details": "J Liu, Y Zheng, R Cheng, Q Wu, W Guo, F Ni, H Liang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advances in large language models (LLMs) have shown remarkable progress, yet their capacity for logical``slow-thinking''reasoning persists as a critical research frontier. Current inference scaling paradigms suffer from two fundamental \u2026"}, {"title": "PEBench: A Fictitious Dataset to Benchmark Machine Unlearning for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2503.12545", "details": "Z Xu, P Zhou, W Tang, J Ai, W Zhao, X Peng, K Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In recent years, Multimodal Large Language Models (MLLMs) have demonstrated remarkable advancements in tasks such as visual question answering, visual understanding, and reasoning. However, this impressive progress relies on vast \u2026"}, {"title": "SVD-LLM V2: Optimizing Singular Value Truncation for Large Language Model Compression", "link": "https://arxiv.org/pdf/2503.12340%3F", "details": "X Wang, S Alam, Z Wan, H Shen, M Zhang - arXiv preprint arXiv:2503.12340, 2025", "abstract": "Despite significant advancements, the practical deployment of Large Language Models (LLMs) is often hampered by their immense sizes, highlighting the need for effective compression techniques. Singular Value Decomposition (SVD) is a \u2026"}, {"title": "Bayesian Teaching Enables Probabilistic Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2503.17523", "details": "L Qiu, F Sha, K Allen, Y Kim, T Linzen, S van Steenkiste - arXiv preprint arXiv \u2026, 2025", "abstract": "Artificial intelligence systems based on large language models (LLMs) are increasingly used as agents that interact with users and with the world. To do so successfully, LLMs need to construct internal representations of the world and form \u2026"}]
