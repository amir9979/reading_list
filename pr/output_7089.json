[{"title": "Interpreting Deep Neural Network-Based Receiver Under Varying Signal-To-Noise Ratios", "link": "https://arxiv.org/pdf/2409.16768", "details": "M Tuononen, D Korpi, V Hautam\u00e4ki - arXiv preprint arXiv:2409.16768, 2024", "abstract": "We propose a novel method for interpreting neural networks, focusing on convolutional neural network-based receiver model. The method identifies which unit or units of the model contain most (or least) information about the channel parameter \u2026"}, {"title": "RI-MAE: Rotation-Invariant Masked AutoEncoders for Self-Supervised Point Cloud Representation Learning", "link": "https://arxiv.org/pdf/2409.00353", "details": "K Su, Q Wu, P Cai, X Zhu, X Lu, Z Wang, K Hu - arXiv preprint arXiv:2409.00353, 2024", "abstract": "Masked point modeling methods have recently achieved great success in self- supervised learning for point cloud data. However, these methods are sensitive to rotations and often exhibit sharp performance drops when encountering rotational \u2026"}, {"title": "The role of data embedding in quantum autoencoders for improved anomaly detection", "link": "https://arxiv.org/pdf/2409.04519", "details": "JY Araz, M Spannowsky - arXiv preprint arXiv:2409.04519, 2024", "abstract": "The performance of Quantum Autoencoders (QAEs) in anomaly detection tasks is critically dependent on the choice of data embedding and ansatz design. This study explores the effects of three data embedding techniques, data re-uploading, parallel \u2026"}, {"title": "Learning Interpretable Reward Models via Unsupervised Feature Selection", "link": "https://openreview.net/pdf%3Fid%3D2sg4PY1W9d", "details": "D Baimukashev, G Alcan, V Kyrki, KS Luck - 8th Annual Conference on Robot Learning", "abstract": "In complex real-world tasks such as robotic manipulation and autonomous driving, collecting expert demonstrations is often more straightforward than specifying precise learning objectives and task descriptions. Learning from expert data can be \u2026"}, {"title": "Supplementary material of: ViC-MAE: Self-Supervised Representation Learning from Images and Video with Contrastive Masked Autoencoders", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00629-supp.pdf", "details": "J Hernandez, R Villegas, V Ordonez", "abstract": "# V [N, T, C, H, W]-minibatch (T= 1 for images)# tau: temperature coefficient# clambda: contrastive coefficient for V in loader:# Distant sampling f_i, f_j= random_sampling (V)# Patch embeddings and position encodings x_i \u2026"}, {"title": "Semantic-DARTS: Elevating Semantic Learning for Mobile Differentiable Architecture Search", "link": "https://ieeexplore.ieee.org/abstract/document/10694709/", "details": "B Guo, S He, M Shi, K Yu, J Chen, X Shen - IEEE Internet of Things Journal, 2024", "abstract": "Differentiable ARchitecture Search (DARTS) is a prevailing direction in automatic machine learning, but it may suffer from performance collapse and generalization issues. Recent efforts mitigate them by integrating regularization into architectural \u2026"}, {"title": "Interpretable by Design: Wrapper Boxes Combine Neural Performance with Faithful Attribution of Model Decisions to Training Data", "link": "https://openreview.net/pdf%3Fid%3DcRNicP5q20", "details": "Y Su, JJ Li, M Lease - The 7th BlackboxNLP Workshop-ARR Submissions", "abstract": "Can we preserve the accuracy of neural models while also providing faithful explanations of model decisions with respect to training data? We propose \u201cwrapper boxes\u201d: training a neual model as usual and then using its learned feature \u2026"}, {"title": "GRACE: Graph-Based Contextual Debiasing for Fair Visual Question Answering (Supplementary Materials)", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02569-supp.pdf", "details": "Y Zhang, M Jiang, Q Zhao", "abstract": "In our main paper, we have presented GRACE, a novel approach addressing biases in knowledge-based VQA. It surpasses current debiasing methods, which primarily tackle dataset biases but fall short in handling biases within the incontext learning \u2026"}, {"title": "DEVIAS: Learning Disentangled Video Representations of Action and Scene", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08652.pdf", "details": "K Bae, G Ahn, Y Kim, J Choi", "abstract": "Video recognition models often learn scene-biased action representation due to the spurious correlation between actions and scenes in the training data. Such models show poor performance when the test data consists of videos with unseen action \u2026"}]
