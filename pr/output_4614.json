[{"title": "VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks", "link": "https://arxiv.org/pdf/2407.19795", "details": "J Choi, J Kwon, JM Yun, S Yu, YB Kim - arXiv preprint arXiv:2407.19795, 2024", "abstract": "Domain generalizability is a crucial aspect of a deep learning model since it determines the capability of the model to perform well on data from unseen domains. However, research on the domain generalizability of deep learning models for vision \u2026"}, {"title": "On Joint Noise Scaling in Differentially Private Federated Learning with Multiple Local Steps", "link": "https://arxiv.org/pdf/2407.19286", "details": "MA Heikkil\u00e4 - arXiv preprint arXiv:2407.19286, 2024", "abstract": "Federated learning is a distributed learning setting where the main aim is to train machine learning models without having to share raw data but only what is required for learning. To guarantee training data privacy and high-utility models, differential \u2026"}, {"title": "Cross-Lingual Multi-Hop Knowledge Editing--Benchmarks, Analysis and a Simple Contrastive Learning based Approach", "link": "https://arxiv.org/pdf/2407.10275", "details": "A Khandelwal, H Singh, H Gu, T Chen, K Zhou - arXiv preprint arXiv:2407.10275, 2024", "abstract": "Large language models are often expected to constantly adapt to new sources of knowledge and knowledge editing techniques aim to efficiently patch the outdated model knowledge, with minimal modification. Most prior works focus on monolingual \u2026"}, {"title": "Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank", "link": "https://arxiv.org/pdf/2407.19943", "details": "S Gupta, H Oosterhuis, M de Rijke - arXiv preprint arXiv:2407.19943, 2024", "abstract": "Counterfactual learning to rank (CLTR) can be risky; various circumstances can cause it to produce sub-optimal models that hurt performance when deployed. Safe CLTR was introduced to mitigate these risks when using inverse propensity scoring \u2026"}, {"title": "To which reference class do you belong? Measuring racial fairness of reference classes with normative modeling", "link": "https://arxiv.org/pdf/2407.19114", "details": "S Rutherford, T Wolfers, C Fraza, NG Harrnet\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reference classes in healthcare establish healthy norms, such as pediatric growth charts of height and weight, and are used to chart deviations from these norms which represent potential clinical risk. How the demographics of the reference class \u2026"}, {"title": "Vision-Language Generative Model for View-Specific Chest X-ray Generation", "link": "https://proceedings.mlr.press/v248/lee24a.html", "details": "H Lee, W Kim, JH Kim, T Kim, J Kim, L Sunwoo, E Choi - Conference on Health \u2026, 2024", "abstract": "Synthetic medical data generation has opened up new possibilities in the healthcare domain, offering a powerful tool for simulating clinical scenarios, enhancing diagnostic and treatment quality, gaining granular medical knowledge, and \u2026"}, {"title": "IgnitionInnovators at\" Discharge Me!\": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries", "link": "https://arxiv.org/pdf/2407.17636", "details": "AQ Tang, X Zhang, MN Dinh - arXiv preprint arXiv:2407.17636, 2024", "abstract": "This paper presents our proposed approach to the Discharge Me! shared task, collocated with the 23th Workshop on Biomedical Natural Language Processing (BioNLP). In this work, we develop an LLM-based framework for solving the \u2026"}, {"title": "MixPrompt: Enhancing Generalizability and Adversarial Robustness for Vision-Language Models via Prompt Fusion", "link": "https://link.springer.com/chapter/10.1007/978-981-97-5606-3_28", "details": "H Fan, Z Ma, Y Li, R Tian, Y Chen, C Gao - International Conference on Intelligent \u2026, 2024", "abstract": "Abstract Pretrained Vision-Language Models (VLMs) like CLIP have exhibited remarkable capacities across downstream tasks, while their image encoders are vulnerable to adversarial examples. A recently introduced lightweight approach \u2026"}, {"title": "Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models", "link": "https://arxiv.org/pdf/2407.19474", "details": "N Bitton-Guetta, A Slobodkin, A Maimon, E Habba\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Imagine observing someone scratching their arm; to understand why, additional context would be necessary. However, spotting a mosquito nearby would immediately offer a likely explanation for the person's discomfort, thereby alleviating \u2026"}]
