[{"title": "Revisiting the Equivalence of Bayesian Neural Networks and Gaussian Processes: On the Importance of Learning Activations", "link": "https://openreview.net/pdf%3Fid%3DAligBAsYWE", "details": "M Sendera, A Sorkhei, T Ku\u015bmierczyk - The 41st Conference on Uncertainty in Artificial \u2026", "abstract": "Gaussian Processes (GPs) provide a convenient framework for specifying function- space priors, making them a natural choice for modeling uncertainty. In contrast, Bayesian Neural Networks (BNNs) offer greater scalability and extendability but lack \u2026"}, {"title": "Well-Defined Function-Space Variational Inference in Bayesian Neural Networks via Regularized KL-Divergence", "link": "https://openreview.net/pdf%3Fid%3DI3e4DD4dvJ", "details": "T Cinquin, R Bamler - The 41st Conference on Uncertainty in Artificial \u2026", "abstract": "Bayesian neural networks (BNN) promise to combine the predictive performance of neural networks with principled uncertainty modeling crucial for safety-critical systems and decision making. However, posterior uncertainties depend on the \u2026"}, {"title": "Conformal Prediction for Zero-Shot Models", "link": "https://openaccess.thecvf.com/content/CVPR2025/papers/Silva-Rodriguez_Conformal_Prediction_for_Zero-Shot_Models_CVPR_2025_paper.pdf", "details": "J Silva-Rodr\u00edguez, I Ben Ayed, J Dolz - Proceedings of the Computer Vision and \u2026, 2025", "abstract": "Vision-language models pre-trained at large scale have shown unprecedented adaptability and generalization to downstream tasks. Although its discriminative potential has been widely explored, its reliability and uncertainty are still overlooked \u2026"}, {"title": "Adaptive Data Augmentation for Thompson Sampling", "link": "https://arxiv.org/pdf/2506.14479", "details": "W Kim - arXiv preprint arXiv:2506.14479, 2025", "abstract": "In linear contextual bandits, the objective is to select actions that maximize cumulative rewards, modeled as a linear function with unknown parameters. Although Thompson Sampling performs well empirically, it does not achieve optimal \u2026", "entry_id": "http://arxiv.org/abs/2506.14479v1", "updated": "2025-06-17 12:57:33", "published": "2025-06-17 12:57:33", "authors": "Wonyoung Kim", "summary": "In linear contextual bandits, the objective is to select actions that\nmaximize cumulative rewards, modeled as a linear function with unknown\nparameters. Although Thompson Sampling performs well empirically, it does not\nachieve optimal regret bounds. This paper proposes a nearly minimax optimal\nThompson Sampling for linear contextual bandits by developing a novel estimator\nwith the adaptive augmentation and coupling of the hypothetical samples that\nare designed for efficient parameter learning. The proposed estimator\naccurately predicts rewards for all arms without relying on assumptions for the\ncontext distribution. Empirical results show robust performance and significant\nimprovement over existing methods.", "comment": null, "journal_ref": null, "primary_category": "stat.ML", "categories": "stat.ML;cs.LG", "links": "http://arxiv.org/abs/2506.14479v1;http://arxiv.org/pdf/2506.14479v1", "pdf_url": "http://arxiv.org/pdf/2506.14479v1"}, {"title": "Efficient Algorithms for Logistic Contextual Slate Bandits with Bandit Feedback", "link": "https://arxiv.org/pdf/2506.13163", "details": "T Goyal, G Sinha - arXiv preprint arXiv:2506.13163, 2025", "abstract": "We study the Logistic Contextual Slate Bandit problem, where, at each round, an agent selects a slate of $ N $ items from an exponentially large set (of size $2^{\\Omega (N)} $) of candidate slates provided by the environment. A single binary \u2026", "entry_id": "http://arxiv.org/abs/2506.13163v1", "updated": "2025-06-16 07:19:02", "published": "2025-06-16 07:19:02", "authors": "Tanmay Goyal;Gaurav Sinha", "summary": "We study the Logistic Contextual Slate Bandit problem, where, at each round,\nan agent selects a slate of $N$ items from an exponentially large set (of size\n$2^{\\Omega(N)}$) of candidate slates provided by the environment. A single\nbinary reward, determined by a logistic model, is observed for the chosen\nslate. Our objective is to develop algorithms that maximize cumulative reward\nover $T$ rounds while maintaining low per-round computational costs. We propose\ntwo algorithms, Slate-GLM-OFU and Slate-GLM-TS, that accomplish this goal.\nThese algorithms achieve $N^{O(1)}$ per-round time complexity via local\nplanning (independent slot selections), and low regret through global learning\n(joint parameter estimation). We provide theoretical and empirical evidence\nsupporting these claims. Under a well-studied diversity assumption, we prove\nthat Slate-GLM-OFU incurs only $\\tilde{O}(\\sqrt{T})$ regret. Extensive\nexperiments across a wide range of synthetic settings demonstrate that our\nalgorithms consistently outperform state-of-the-art baselines, achieving both\nthe lowest regret and the fastest runtime. Furthermore, we apply our algorithm\nto select in-context examples in prompts of Language Models for solving binary\nclassification tasks such as sentiment analysis. Our approach achieves\ncompetitive test accuracy, making it a viable alternative in practical\nscenarios.", "comment": "Accepted to UAI 2025", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2506.13163v1;http://arxiv.org/pdf/2506.13163v1", "pdf_url": "http://arxiv.org/pdf/2506.13163v1"}, {"title": "Random Conditioning for Diffusion Model Compression with Distillation", "link": "https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Random_Conditioning_for_Diffusion_Model_Compression_with_Distillation_CVPR_2025_paper.pdf", "details": "D Kim, S Park, G Han, SW Kim, PH Seo - Proceedings of the Computer Vision and \u2026, 2025", "abstract": "Diffusion models generate high-quality images through progressive denoising but are computationally intensive due to large model sizes and repeated sampling. Knowledge distillation--transferring knowledge from a complex teacher to a simpler \u2026"}, {"title": "Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models", "link": "https://arxiv.org/pdf/2506.00457", "details": "J Park, H Lee, D Lee, D Gwak, J Choo - arXiv preprint arXiv:2506.00457, 2025", "abstract": "Large Language Models (LLMs) have shown remarkable performance across diverse tasks without domain-specific training, fueling interest in their potential for time-series forecasting. While LLMs have shown potential in zero-shot forecasting \u2026", "entry_id": "http://arxiv.org/abs/2506.00457v1", "updated": "2025-05-31 08:24:01", "published": "2025-05-31 08:24:01", "authors": "Junwoo Park;Hyuck Lee;Dohyun Lee;Daehoon Gwak;Jaegul Choo", "summary": "Large Language Models (LLMs) have shown remarkable performance across diverse\ntasks without domain-specific training, fueling interest in their potential for\ntime-series forecasting. While LLMs have shown potential in zero-shot\nforecasting through prompting alone, recent studies suggest that LLMs lack\ninherent effectiveness in forecasting. Given these conflicting findings, a\nrigorous validation is essential for drawing reliable conclusions. In this\npaper, we evaluate the effectiveness of LLMs as zero-shot forecasters compared\nto state-of-the-art domain-specific models. Our experiments show that LLM-based\nzero-shot forecasters often struggle to achieve high accuracy due to their\nsensitivity to noise, underperforming even simple domain-specific models. We\nhave explored solutions to reduce LLMs' sensitivity to noise in the zero-shot\nsetting, but improving their robustness remains a significant challenge. Our\nfindings suggest that rather than emphasizing zero-shot forecasting, a more\npromising direction would be to focus on fine-tuning LLMs to better process\nnumerical sequences. Our experimental code is available at\nhttps://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster.", "comment": "Annual Meeting of the Association for Computational Linguistics\n  (ACL), 2025, Accepted as Short Paper", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2506.00457v1;http://arxiv.org/pdf/2506.00457v1", "pdf_url": "http://arxiv.org/pdf/2506.00457v1"}, {"title": "Align Your Flow: Scaling Continuous-Time Flow Map Distillation", "link": "https://arxiv.org/pdf/2506.14603", "details": "A Sabour, S Fidler, K Kreis - arXiv preprint arXiv:2506.14603, 2025", "abstract": "Diffusion-and flow-based models have emerged as state-of-the-art generative modeling approaches, but they require many sampling steps. Consistency models can distill these models into efficient one-step generators; however, unlike flow-and \u2026", "entry_id": "http://arxiv.org/abs/2506.14603v1", "updated": "2025-06-17 15:06:07", "published": "2025-06-17 15:06:07", "authors": "Amirmojtaba Sabour;Sanja Fidler;Karsten Kreis", "summary": "Diffusion- and flow-based models have emerged as state-of-the-art generative\nmodeling approaches, but they require many sampling steps. Consistency models\ncan distill these models into efficient one-step generators; however, unlike\nflow- and diffusion-based methods, their performance inevitably degrades when\nincreasing the number of steps, which we show both analytically and\nempirically. Flow maps generalize these approaches by connecting any two noise\nlevels in a single step and remain effective across all step counts. In this\npaper, we introduce two new continuous-time objectives for training flow maps,\nalong with additional novel training techniques, generalizing existing\nconsistency and flow matching objectives. We further demonstrate that\nautoguidance can improve performance, using a low-quality model for guidance\nduring distillation, and an additional boost can be achieved by adversarial\nfinetuning, with minimal loss in sample diversity. We extensively validate our\nflow map models, called Align Your Flow, on challenging image generation\nbenchmarks and achieve state-of-the-art few-step generation performance on both\nImageNet 64x64 and 512x512, using small and efficient neural networks. Finally,\nwe show text-to-image flow map models that outperform all existing\nnon-adversarially trained few-step samplers in text-conditioned synthesis.", "comment": "Project page:\n  https://research.nvidia.com/labs/toronto-ai/AlignYourFlow/", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.LG", "links": "http://arxiv.org/abs/2506.14603v1;http://arxiv.org/pdf/2506.14603v1", "pdf_url": "http://arxiv.org/pdf/2506.14603v1"}, {"title": "Optimizing Data Augmentation through Bayesian Model Selection", "link": "https://arxiv.org/pdf/2505.21813", "details": "M Matymov, BH Tran, M Kampffmeyer, M Heinonen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Data Augmentation (DA) has become an essential tool to improve robustness and generalization of modern machine learning. However, when deciding on DA strategies it is critical to choose parameters carefully, and this can be a daunting task \u2026", "entry_id": "http://arxiv.org/abs/2505.21813v1", "updated": "2025-05-27 22:44:36", "published": "2025-05-27 22:44:36", "authors": "Madi Matymov;Ba-Hien Tran;Michael Kampffmeyer;Markus Heinonen;Maurizio Filippone", "summary": "Data Augmentation (DA) has become an essential tool to improve robustness and\ngeneralization of modern machine learning. However, when deciding on DA\nstrategies it is critical to choose parameters carefully, and this can be a\ndaunting task which is traditionally left to trial-and-error or expensive\noptimization based on validation performance. In this paper, we counter these\nlimitations by proposing a novel framework for optimizing DA. In particular, we\ntake a probabilistic view of DA, which leads to the interpretation of\naugmentation parameters as model (hyper)-parameters, and the optimization of\nthe marginal likelihood with respect to these parameters as a Bayesian model\nselection problem. Due to its intractability, we derive a tractable Evidence\nLower BOund (ELBO), which allows us to optimize augmentation parameters jointly\nwith model parameters. We provide extensive theoretical results on variational\napproximation quality, generalization guarantees, invariance properties, and\nconnections to empirical Bayes. Through experiments on computer vision tasks,\nwe show that our approach improves calibration and yields robust performance\nover fixed or no augmentation. Our work provides a rigorous foundation for\noptimizing DA through Bayesian principles with significant potential for robust\nmachine learning.", "comment": "26 pages, 3 figures", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;stat.ML;62F15, 68T07 (Primary) 62M45, 62C10, 65C60 (Secondary)", "links": "http://arxiv.org/abs/2505.21813v1;http://arxiv.org/pdf/2505.21813v1", "pdf_url": "http://arxiv.org/pdf/2505.21813v1"}]
