[{"title": "A Time Series Self-Supervised Contrastive Pre-Training Method with Data Augmentation using Discrepancy of Reconstruction Information Loss", "link": "https://ieeexplore.ieee.org/abstract/document/10912708/", "details": "Z Zhang, Y Han, B Ma, Z Geng - IEEE Transactions on Instrumentation and \u2026, 2025", "abstract": "Self-supervised pre-training has shown considerable advantages in multiple time series tasks. A widely used class of methods is based on contrastive learning and a key problem is how to construct augmented samples. At present, explicit \u2026"}, {"title": "Fusionformer: A Novel Adversarial Transformer Utilizing Fusion Attention for Multivariate Anomaly Detection", "link": "https://ieeexplore.ieee.org/abstract/document/10922726/", "details": "C Wang, Z Wang, H Dong, S Lauria, W Liu, Y Wang\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "Multivariate time series forecasting (MTSF) is of significant importance in the enhancement and optimization of real-world applications. The task of MTSF poses substantial challenges due to the unpredictability of temporal patterns and the \u2026"}, {"title": "One-Class Classification Constraint in Reconstruction Networks for Multivariate Time Series Anomaly Detection", "link": "https://ieeexplore.ieee.org/abstract/document/10912658/", "details": "J Li, Z Yu, Q Jiang, Z Cao - IEEE Transactions on Instrumentation and \u2026, 2025", "abstract": "Detecting anomalies in multivariate time series (MTS) data is crucial for maintaining the stability of industrial manufacturing processes and biochemical operations. However, current methods often focus on capturing the normal patterns of training \u2026"}, {"title": "AD2T: Multivariate Time Series Anomaly Detection with Association Discrepancy Dual-Decoder Transformer", "link": "https://www.researchgate.net/profile/Zezhong-Li-12/publication/389356933_AD2T_Multivariate_Time_Series_Anomaly_Detection_with_Association_Discrepancy_Dual-Decoder_Transformer/links/67bfbe528311ce680c760f3f/AD2T-Multivariate-Time-Series-Anomaly-Detection-with-Association-Discrepancy-Dual-Decoder-Transformer.pdf", "details": "Z Li, W Guo, J An, Q Wang, Y Mei, R Juan, T Wang, Y Li\u2026 - IEEE Sensors Journal, 2025", "abstract": "Multivariate time series (MTS) anomaly detection is of great importance in both condition monitoring and malfunction identification within multi-sensor systems. Current MTS anomaly detection approaches are typically based on reconstruction \u2026"}, {"title": "Powering up Bayesian neural networks", "link": "https://www.nature.com/articles/s41928-025-01369-3", "details": "M Parker - Nature Electronics, 2025", "abstract": "Bayesian neural networks, which represent weights using the mean and the difference from the mean, can outperform convolutional neural networks in certain tasks, such as image recognition in noisy environments. Compute-in-memory \u2026"}, {"title": "CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation", "link": "https://arxiv.org/pdf/2502.21074%3F", "details": "Z Shen, H Yan, L Zhang, Z Hu, Y Du, Y He - arXiv preprint arXiv:2502.21074, 2025", "abstract": "Chain-of-Thought (CoT) enhances Large Language Models (LLMs) by enabling step- by-step reasoning in natural language. However, the language space may be suboptimal for reasoning. While implicit CoT methods attempt to enable reasoning \u2026"}, {"title": "Tinyr1-32b-preview: Boosting accuracy with branch-merge distillation", "link": "https://arxiv.org/pdf/2503.04872", "details": "L Sun, G Zhao, X Jian, Y Wu, W Lin, Y Zhu, L Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The challenge of reducing the size of Large Language Models (LLMs) while maintaining their performance has gained significant attention. However, existing methods, such as model distillation and transfer learning, often fail to achieve high \u2026"}, {"title": "Contrastive Learning via Randomly Generated Deep Supervision", "link": "https://ieeexplore.ieee.org/abstract/document/10890867/", "details": "S Wang, Z Ma, KH Chan, Y Liu, T Tong, Q Gao, G Zhai\u2026 - ICASSP 2025-2025 IEEE \u2026, 2025", "abstract": "Unsupervised visual representation learning has gained significant attention in the computer vision community, driven by recent advancements in contrastive learning. Most existing contrastive learning frameworks rely on instance discrimination as a \u2026"}, {"title": "TraFlow: Trajectory Distillation on Pre-Trained Rectified Flow", "link": "https://arxiv.org/pdf/2502.16972", "details": "Z Wu, X Fan, H Wu, L Cao - arXiv preprint arXiv:2502.16972, 2025", "abstract": "Majorities of distillation methods on pre-trained diffusion models or on pre-trained rectified flow, focus on either the distillation outputs or the trajectories between random noises and clean images to speed up sample generations from pre-trained \u2026"}]
