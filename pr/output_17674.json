[{"title": "Evaluating Explainability: A Framework for Systematic Assessment and Reporting of Explainable AI Features", "link": "https://arxiv.org/pdf/2506.13917", "details": "MA Lago, G Zamzmi, B Eich, JG Delfino - arXiv preprint arXiv:2506.13917, 2025", "abstract": "Explainability features are intended to provide insight into the internal mechanisms of an AI device, but there is a lack of evaluation techniques for assessing the quality of provided explanations. We propose a framework to assess and report explainable AI \u2026", "entry_id": "http://arxiv.org/abs/2506.13917v1", "updated": "2025-06-16 18:51:46", "published": "2025-06-16 18:51:46", "authors": "Miguel A. Lago;Ghada Zamzmi;Brandon Eich;Jana G. Delfino", "summary": "Explainability features are intended to provide insight into the internal\nmechanisms of an AI device, but there is a lack of evaluation techniques for\nassessing the quality of provided explanations. We propose a framework to\nassess and report explainable AI features. Our evaluation framework for AI\nexplainability is based on four criteria: 1) Consistency quantifies the\nvariability of explanations to similar inputs, 2) Plausibility estimates how\nclose the explanation is to the ground truth, 3) Fidelity assesses the\nalignment between the explanation and the model internal mechanisms, and 4)\nUsefulness evaluates the impact on task performance of the explanation.\nFinally, we developed a scorecard for AI explainability methods that serves as\na complete description and evaluation to accompany this type of algorithm. We\ndescribe these four criteria and give examples on how they can be evaluated. As\na case study, we use Ablation CAM and Eigen CAM to illustrate the evaluation of\nexplanation heatmaps on the detection of breast lesions on synthetic\nmammographies. The first three criteria are evaluated for clinically-relevant\nscenarios. Our proposed framework establishes criteria through which the\nquality of explanations provided by AI models can be evaluated. We intend for\nour framework to spark a dialogue regarding the value provided by\nexplainability features and help improve the development and evaluation of\nAI-based medical devices.", "comment": null, "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI", "links": "http://arxiv.org/abs/2506.13917v1;http://arxiv.org/pdf/2506.13917v1", "pdf_url": "http://arxiv.org/pdf/2506.13917v1"}, {"title": "Automatic Radiology Report Generation Based on State-Space Model", "link": "https://ieeexplore.ieee.org/abstract/document/11037239/", "details": "D Zhang, Y Tan, J Qin, X Xiang - IEEE Journal of Biomedical and Health Informatics, 2025", "abstract": "The objective of radiology report generation is to alleviate the burden on physicians in drafting reports, thereby improving generation efficiency and reducing patient waiting times. In recent years, there has been a growing emphasis on imaging-based \u2026"}]
