[{"title": "Enhancing Privacy in the Early Detection of Sexual Predators Through Federated Learning and Differential Privacy", "link": "https://arxiv.org/pdf/2501.12537", "details": "K Chehbouni, M De Cock, G Caporossi, A Taik\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The increased screen time and isolation caused by the COVID-19 pandemic have led to a significant surge in cases of online grooming, which is the use of strategies by predators to lure children into sexual exploitation. Previous efforts to detect \u2026"}, {"title": "Explainable robo-advisor: An online learning framework for new investors without trading records", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225001353", "details": "X Hu, S Kang, S Xue, S Zhu - Neurocomputing, 2025", "abstract": "Intelligent investment advisors, commonly known as robo-advisors, are extensively utilized in the wealth management industry for the precise design and marketing of financial products. The primary function of robo-advisors is to accurately extract an \u2026"}, {"title": "How Does the Spatial Distribution of Pre-training Data Affect Geospatial Foundation Models?", "link": "https://arxiv.org/pdf/2501.12535", "details": "M Purohit, G Muhawenayo, E Rolf, H Kerner - arXiv preprint arXiv:2501.12535, 2025", "abstract": "Foundation models have made rapid advances in many domains including Earth observation, where Geospatial Foundation Models (GFMs) can help address global challenges such as climate change, agriculture, and disaster response. Previous \u2026"}, {"title": "Vision-BioLLM: Large vision language model for visual dialogue in biomedical imagery", "link": "https://www.sciencedirect.com/science/article/pii/S1746809424014952", "details": "A AlShibli, Y Bazi, MM Al Rahhal, M Zuair - Biomedical Signal Processing and Control, 2025", "abstract": "In this paper, we present a vision-language model tailored for visual dialogue in the biomedical domain, utilizing a LanguageBind transformer as the vision encoder and Llama3-OpenBioLLM as the language decoder. Our training approach involves three \u2026"}]
