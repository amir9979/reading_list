[{"title": "Byte Pair Encoding for Efficient Time Series Forecasting", "link": "https://arxiv.org/pdf/2505.14411", "details": "L G\u00f6tz, M Kollovieh, S G\u00fcnnemann, L Schwinn - arXiv preprint arXiv:2505.14411, 2025", "abstract": "Existing time series tokenization methods predominantly encode a constant number of samples into individual tokens. This inflexible approach can generate excessive tokens for even simple patterns like extended constant values, resulting in \u2026", "entry_id": "http://arxiv.org/abs/2505.14411v1", "updated": "2025-05-20 14:24:49", "published": "2025-05-20 14:24:49", "authors": "Leon G\u00f6tz;Marcel Kollovieh;Stephan G\u00fcnnemann;Leo Schwinn", "summary": "Existing time series tokenization methods predominantly encode a constant\nnumber of samples into individual tokens. This inflexible approach can generate\nexcessive tokens for even simple patterns like extended constant values,\nresulting in substantial computational overhead. Inspired by the success of\nbyte pair encoding, we propose the first pattern-centric tokenization scheme\nfor time series analysis. Based on a discrete vocabulary of frequent motifs,\nour method merges samples with underlying patterns into tokens, compressing\ntime series adaptively. Exploiting our finite set of motifs and the continuous\nproperties of time series, we further introduce conditional decoding as a\nlightweight yet powerful post-hoc optimization method, which requires no\ngradient computation and adds no computational overhead. On recent time series\nfoundation models, our motif-based tokenization improves forecasting\nperformance by 36% and boosts efficiency by 1990% on average. Conditional\ndecoding further reduces MSE by up to 44%. In an extensive analysis, we\ndemonstrate the adaptiveness of our tokenization to diverse temporal patterns,\nits generalization to unseen data, and its meaningful token representations\ncapturing distinct time series properties, including statistical moments and\ntrends.", "comment": "24 pages in total, 17 figures", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2505.14411v1;http://arxiv.org/pdf/2505.14411v1", "pdf_url": "http://arxiv.org/pdf/2505.14411v1"}, {"title": "Variational Regularized Unbalanced Optimal Transport: Single Network, Least Action", "link": "https://arxiv.org/pdf/2505.11823", "details": "Y Sun, Z Zhang, Z Wang, T Li, P Zhou - arXiv preprint arXiv:2505.11823, 2025", "abstract": "Recovering the dynamics from a few snapshots of a high-dimensional system is a challenging task in statistical physics and machine learning, with important applications in computational biology. Many algorithms have been developed to \u2026", "entry_id": "http://arxiv.org/abs/2505.11823v1", "updated": "2025-05-17 04:16:14", "published": "2025-05-17 04:16:14", "authors": "Yuhao Sun;Zhenyi Zhang;Zihan Wang;Tiejun Li;Peijie Zhou", "summary": "Recovering the dynamics from a few snapshots of a high-dimensional system is\na challenging task in statistical physics and machine learning, with important\napplications in computational biology. Many algorithms have been developed to\ntackle this problem, based on frameworks such as optimal transport and the\nSchr\\\"odinger bridge. A notable recent framework is Regularized Unbalanced\nOptimal Transport (RUOT), which integrates both stochastic dynamics and\nunnormalized distributions. However, since many existing methods do not\nexplicitly enforce optimality conditions, their solutions often struggle to\nsatisfy the principle of least action and meet challenges to converge in a\nstable and reliable way. To address these issues, we propose Variational RUOT\n(Var-RUOT), a new framework to solve the RUOT problem. By incorporating the\noptimal necessary conditions for the RUOT problem into both the\nparameterization of the search space and the loss function design, Var-RUOT\nonly needs to learn a scalar field to solve the RUOT problem and can search for\nsolutions with lower action. We also examined the challenge of selecting a\ngrowth penalty function in the widely used Wasserstein-Fisher-Rao metric and\nproposed a solution that better aligns with biological priors in Var-RUOT. We\nvalidated the effectiveness of Var-RUOT on both simulated data and real\nsingle-cell datasets. Compared with existing algorithms, Var-RUOT can find\nsolutions with lower action while exhibiting faster convergence and improved\ntraining stability.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;math.OC;q-bio.QM", "links": "http://arxiv.org/abs/2505.11823v1;http://arxiv.org/pdf/2505.11823v1", "pdf_url": "http://arxiv.org/pdf/2505.11823v1"}, {"title": "Causality-Inspired Robustness for Nonlinear Models via Representation Learning", "link": "https://arxiv.org/pdf/2505.12868", "details": "M \u0160ola, P B\u00fchlmann, X Shen - arXiv preprint arXiv:2505.12868, 2025", "abstract": "Distributional robustness is a central goal of prediction algorithms due to the prevalent distribution shifts in real-world data. The prediction model aims to minimize the worst-case risk among a class of distributions, aka, an uncertainty set. Causality \u2026", "entry_id": "http://arxiv.org/abs/2505.12868v1", "updated": "2025-05-19 08:52:15", "published": "2025-05-19 08:52:15", "authors": "Marin \u0160ola;Peter B\u00fchlmann;Xinwei Shen", "summary": "Distributional robustness is a central goal of prediction algorithms due to\nthe prevalent distribution shifts in real-world data. The prediction model aims\nto minimize the worst-case risk among a class of distributions, a.k.a., an\nuncertainty set. Causality provides a modeling framework with a rigorous\nrobustness guarantee in the above sense, where the uncertainty set is\ndata-driven rather than pre-specified as in traditional distributional\nrobustness optimization. However, current causality-inspired robustness methods\npossess finite-radius robustness guarantees only in the linear settings, where\nthe causal relationships among the covariates and the response are linear. In\nthis work, we propose a nonlinear method under a causal framework by\nincorporating recent developments in identifiable representation learning and\nestablish a distributional robustness guarantee. To our best knowledge, this is\nthe first causality-inspired robustness method with such a finite-radius\nrobustness guarantee in nonlinear settings. Empirical validation of the\ntheoretical findings is conducted on both synthetic data and real-world\nsingle-cell data, also illustrating that finite-radius robustness is crucial.", "comment": null, "journal_ref": null, "primary_category": "stat.ML", "categories": "stat.ML;cs.LG;stat.ME", "links": "http://arxiv.org/abs/2505.12868v1;http://arxiv.org/pdf/2505.12868v1", "pdf_url": "http://arxiv.org/pdf/2505.12868v1"}]
