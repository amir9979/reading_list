[{"title": "PCLmed: Champion Solution for ImageCLEFmedical 2024 Caption Prediction Challenge via Medical Vision-Language Foundation Models", "link": "https://ceur-ws.org/Vol-3740/paper-164.pdf", "details": "B Yang, Y Yu, Y Zou, T Zhang - \u2026 Working Notes, CEUR Workshop Proceedings, CEUR \u2026, 2024", "abstract": "Automatically generating captions and reports for medical images has become increasingly important due to the growing workload of radiologists in hospitals. To tackle this challenging task with limited annotation data, there is a rising interest in \u2026"}, {"title": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference", "link": "https://arxiv.org/pdf/2408.01935", "details": "K Shen, M Kejriwal - arXiv preprint arXiv:2408.01935, 2024", "abstract": "Despite their impressive performance, large language models (LLMs) such as ChatGPT are known to pose important risks. One such set of risks arises from misplaced confidence, whether over-confidence or under-confidence, that the \u2026"}, {"title": "LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models", "link": "https://arxiv.org/pdf/2407.15415", "details": "X Chen, S Zhang, Q Bai, K Chen, S Nakamura - arXiv preprint arXiv:2407.15415, 2024", "abstract": "We introduces LLaST, a framework for building high-performance Large Language model based Speech-to-text Translation systems. We address the limitations of end- to-end speech translation (E2E ST) models by exploring model architecture design \u2026"}, {"title": "High-Throughput Phenotyping of Clinical Text Using Large Language Models", "link": "https://arxiv.org/pdf/2408.01214", "details": "DB Hier, SI Munzir, A Stahlfeld, T Obafemi-Ajayi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "High-throughput phenotyping automates the mapping of patient signs to standardized ontology concepts and is essential for precision medicine. This study evaluates the automation of phenotyping of clinical summaries from the Online \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}, {"title": "Preprocessing Pathology Reports for Vision-Language Model Development", "link": "https://openreview.net/pdf%3Fid%3DSUgnMdiJ2q", "details": "R Lucassen, T van de Luijtgaarden, S Moonemans\u2026 - MICCAI Workshop on \u2026, 2024", "abstract": "Pathology reports are increasingly being used for development of vision-language models. Because the reports often include information that cannot directly be derived from paired images, careful selection of information is required to prevent \u2026"}]
