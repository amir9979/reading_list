[{"title": "On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena", "link": "https://arxiv.org/pdf/2501.04662", "details": "T Naous, W Xu - arXiv preprint arXiv:2501.04662, 2025", "abstract": "Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages. In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by \u2026"}, {"title": "INSNER: A generative instruction-based prompting method for boosting performance in few-shot NER", "link": "https://www.sciencedirect.com/science/article/pii/S0306457324003996", "details": "P Zhao, C Feng, P Li, G Dong, S Wang - Information Processing & Management, 2025", "abstract": "Abstract Most existing Named Entity Recognition (NER) methods require a large scale of labeled data and exhibit poor performance in low-resource scenarios. Thus in this paper, we propose INSNER, a generative INStruction-based prompting \u2026"}, {"title": "Confidence in the Reasoning of Large Language Models", "link": "https://assets.pubpub.org/8ahvoupt/Pawitan%2520%26%2520Holmes%2520\\(2024\\)_Just%2520Accepted-21734387493774.pdf", "details": "Y Pawitan, C Holmes - arXiv preprint arXiv:2412.15296, 2024", "abstract": "There is a growing literature on reasoning by large language models (LLMs), but the discussion on the uncertainty in their responses is still lacking. Our aim is to assess the extent of confidence that LLMs have in their answers and how it correlates with \u2026"}]
