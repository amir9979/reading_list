[{"title": "Making Small Language Models Efficient Reasoners: Intervention, Supervision, Reinforcement", "link": "https://arxiv.org/pdf/2505.07961", "details": "X Zhang, Z Huang, C Ni, Z Xiong, J Chen, S Oymak - arXiv preprint arXiv:2505.07961, 2025", "abstract": "Recent research enhances language model reasoning by scaling test-time compute via longer chain-of-thought traces. This often improves accuracy but also introduces redundancy and high computational cost, especially for small language models \u2026", "entry_id": "http://arxiv.org/abs/2505.07961v3", "updated": "2025-05-23 04:50:59", "published": "2025-05-12 18:04:39", "authors": "Xuechen Zhang;Zijian Huang;Chenshun Ni;Ziyang Xiong;Jiasi Chen;Samet Oymak", "summary": "Recent research enhances language model reasoning by scaling test-time\ncompute via longer chain-of-thought traces. This often improves accuracy but\nalso introduces redundancy and high computational cost, especially for small\nlanguage models distilled with supervised fine-tuning (SFT). In this work, we\npropose new algorithms to improve token-efficient reasoning with small-scale\nmodels by effectively trading off accuracy and computation. We first show that\nthe post-SFT model fails to determine the optimal stopping point of the\nreasoning process, resulting in verbose and repetitive outputs. Verbosity also\nsignificantly varies across wrong vs correct responses. To address these\nissues, we propose two solutions: (1) Temperature scaling (TS) to control the\nstopping point for the thinking phase and thereby trace length, and (2) TLDR: a\nlength-regularized reinforcement learning method based on GRPO that facilitates\nmulti-level trace length control (e.g. short, medium, long reasoning).\nExperiments on four reasoning benchmarks, MATH500, AMC, AIME24 and\nOlympiadBench, demonstrate that TS is highly effective compared to s1's budget\nforcing approach and TLDR significantly improves token efficiency by about 50%\nwith minimal to no accuracy loss over the SFT baseline. Moreover, TLDR also\nfacilitates flexible control over the response length, offering a practical and\neffective solution for token-efficient reasoning in small models. Ultimately,\nour work reveals the importance of stopping time control, highlights\nshortcomings of pure SFT, and provides effective algorithmic recipes.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2505.07961v3;http://arxiv.org/pdf/2505.07961v3", "pdf_url": "http://arxiv.org/pdf/2505.07961v3"}, {"title": "Knowledge-augmented Pre-trained Language Models for Biomedical Relation Extraction", "link": "https://arxiv.org/pdf/2505.00814", "details": "M S\u00e4nger, U Leser - arXiv preprint arXiv:2505.00814, 2025", "abstract": "Automatic relationship extraction (RE) from biomedical literature is critical for managing the vast amount of scientific knowledge produced each year. In recent years, utilizing pre-trained language models (PLMs) has become the prevalent \u2026", "entry_id": "http://arxiv.org/abs/2505.00814v1", "updated": "2025-05-01 19:16:18", "published": "2025-05-01 19:16:18", "authors": "Mario S\u00e4nger;Ulf Leser", "summary": "Automatic relationship extraction (RE) from biomedical literature is critical\nfor managing the vast amount of scientific knowledge produced each year. In\nrecent years, utilizing pre-trained language models (PLMs) has become the\nprevalent approach in RE. Several studies report improved performance when\nincorporating additional context information while fine-tuning PLMs for RE.\nHowever, variations in the PLMs applied, the databases used for augmentation,\nhyper-parameter optimization, and evaluation methods complicate direct\ncomparisons between studies and raise questions about the generalizability of\nthese findings. Our study addresses this research gap by evaluating PLMs\nenhanced with contextual information on five datasets spanning four relation\nscenarios within a consistent evaluation framework. We evaluate three baseline\nPLMs and first conduct extensive hyperparameter optimization. After selecting\nthe top-performing model, we enhance it with additional data, including textual\nentity descriptions, relational information from knowledge graphs, and\nmolecular structure encodings. Our findings illustrate the importance of i) the\nchoice of the underlying language model and ii) a comprehensive hyperparameter\noptimization for achieving strong extraction performance. Although inclusion of\ncontext information yield only minor overall improvements, an ablation study\nreveals substantial benefits for smaller PLMs when such external data was\nincluded during fine-tuning.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.00814v1;http://arxiv.org/pdf/2505.00814v1", "pdf_url": "http://arxiv.org/pdf/2505.00814v1"}, {"title": "Enhancement of Fairness in AI for Chest X-ray Classification", "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12099404/", "details": "NJ Jackson, C Yan, BA Malin - AMIA Annual Symposium Proceedings, 2025", "abstract": "The use of artificial intelligence (AI) in medicine has shown promise to improve the quality of healthcare decisions. However, AI can be biased in a manner that produces unfair predictions for certain demographic subgroups. In MIMIC-CXR, a \u2026"}, {"title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining", "link": "https://arxiv.org/pdf/2505.07608", "details": "B Xia, B Shen, D Zhu, D Zhang, G Wang, H Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing \u2026", "entry_id": "http://arxiv.org/abs/2505.07608v1", "updated": "2025-05-12 14:30:11", "published": "2025-05-12 14:30:11", "authors": "Xiaomi LLM-Core Team;:;Bingquan Xia;Bowen Shen;Cici;Dawei Zhu;Di Zhang;Gang Wang;Hailin Zhang;Huaqiu Liu;Jiebao Xiao;Jinhao Dong;Liang Zhao;Peidian Li;Peng Wang;Shihua Yu;Shimao Chen;Weikun Wang;Wenhan Ma;Xiangwei Deng;Yi Huang;Yifan Song;Zihan Jiang;Bowen Ye;Can Cai;Chenhong He;Dong Zhang;Duo Zhang;Guoan Wang;Hao Tian;Haochen Zhao;Heng Qu;Hongshen Xu;Jun Shi;Kainan Bao;QingKai Fang;Kang Zhou;Kangyang Zhou;Lei Li;Menghang Zhu;Nuo Chen;Qiantong Wang;Shaohui Liu;Shicheng Li;Shuhao Gu;Shuhuai Ren;Shuo Liu;Sirui Deng;Weiji Zhuang;Weiwei Lv;Wenyu Yang;Xin Zhang;Xing Yong;Xing Zhang;Xingchen Song;Xinzhe Xu;Xu Wang;Yihan Yan;Yu Tu;Yuanyuan Tian;Yudong Wang;Yue Yu;Zhenru Lin;Zhichao Song;Zihao Yue", "summary": "We present MiMo-7B, a large language model born for reasoning tasks, with\noptimization across both pre-training and post-training stages. During\npre-training, we enhance the data preprocessing pipeline and employ a\nthree-stage data mixing strategy to strengthen the base model's reasoning\npotential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional\nMulti-Token Prediction objective for enhanced performance and accelerated\ninference speed. During post-training, we curate a dataset of 130K verifiable\nmathematics and programming problems for reinforcement learning, integrating a\ntest-difficulty-driven code-reward scheme to alleviate sparse-reward issues and\nemploying strategic data resampling to stabilize training. Extensive\nevaluations show that MiMo-7B-Base possesses exceptional reasoning potential,\noutperforming even much larger 32B models. The final RL-tuned model,\nMiMo-7B-RL, achieves superior performance on mathematics, code and general\nreasoning tasks, surpassing the performance of OpenAI o1-mini. The model\ncheckpoints are available at https://github.com/xiaomimimo/MiMo.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI;cs.LG", "links": "http://arxiv.org/abs/2505.07608v1;http://arxiv.org/pdf/2505.07608v1", "pdf_url": "http://arxiv.org/pdf/2505.07608v1"}, {"title": "Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory", "link": "https://arxiv.org/pdf/2505.10981", "details": "Y Liu, Z Li, Z Fang, N Xu, R He, T Tan - arXiv preprint arXiv:2505.10981, 2025", "abstract": "Recently, scaling test-time compute on Large Language Models (LLM) has garnered wide attention. However, there has been limited investigation of how various reasoning prompting strategies perform as scaling. In this paper, we focus on a \u2026", "entry_id": "http://arxiv.org/abs/2505.10981v1", "updated": "2025-05-16 08:28:57", "published": "2025-05-16 08:28:57", "authors": "Yexiang Liu;Zekun Li;Zhi Fang;Nan Xu;Ran He;Tieniu Tan", "summary": "Recently, scaling test-time compute on Large Language Models (LLM) has\ngarnered wide attention. However, there has been limited investigation of how\nvarious reasoning prompting strategies perform as scaling. In this paper, we\nfocus on a standard and realistic scaling setting: majority voting. We\nsystematically conduct experiments on 6 LLMs $\\times$ 8 prompting strategies\n$\\times$ 6 benchmarks. Experiment results consistently show that as the\nsampling time and computational overhead increase, complicated prompting\nstrategies with superior initial performance gradually fall behind simple\nChain-of-Thought. We analyze this phenomenon and provide theoretical proofs.\nAdditionally, we propose a method according to probability theory to quickly\nand accurately predict the scaling performance and select the best strategy\nunder large sampling times without extra resource-intensive inference in\npractice. It can serve as the test-time scaling law for majority voting.\nFurthermore, we introduce two ways derived from our theoretical analysis to\nsignificantly improve the scaling performance. We hope that our research can\npromote to re-examine the role of complicated prompting, unleash the potential\nof simple prompting strategies, and provide new insights for enhancing\ntest-time scaling performance.", "comment": "ACL 2025 Main", "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI;cs.CL;cs.LG", "links": "http://arxiv.org/abs/2505.10981v1;http://arxiv.org/pdf/2505.10981v1", "pdf_url": "http://arxiv.org/pdf/2505.10981v1"}, {"title": "Enhancing E-commerce Representation Learning via Hypergraph Contrastive Learning and Interpretable LLM-Driven Analysis", "link": "https://dl.acm.org/doi/pdf/10.1145/3701716.3717579", "details": "Y Qian, S Zhang, L Chen, D Socolinsky, N Sokhandan\u2026 - Companion Proceedings of \u2026, 2025", "abstract": "E-commerce has experienced significant growth recently, generating vast amounts of data on user preferences, interactions, and purchase patterns. Effectively modeling and representing users and products in these online ecosystems is crucial for \u2026"}, {"title": "Ploutos: Towards Explainable Stock Movement Prediction with Financial Large Language Model", "link": "https://dl.acm.org/doi/pdf/10.1145/3701716.3715254", "details": "H Tong, J Li, N Wu, M Gong, D Zhang, Q Zhang - \u2026 Proceedings of the ACM on Web \u2026, 2025", "abstract": "Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical \u2026"}, {"title": "Explainable Hallucination Mitigation in Large Language Models: A Survey", "link": "https://www.preprints.org/frontend/manuscript/db02d598971cf15910b6ff42e1227ce1/download_pub", "details": "W Deng, J Li, HY Zhang, J Li, Z Deng, D Cheng, Z Feng - 2025", "abstract": "Hallucinations in large language models (LLMs) pose significant challenges to their reliability, especially in knowledge-intensive and reasoning-oriented tasks. While existing efforts have focused on detecting or correcting such errors, they often lack a \u2026"}, {"title": "Multi-view contrastive learning and symptom extraction insights for medical report generation", "link": "https://www.nature.com/articles/s41598-025-00570-w", "details": "Q Bai, X Zou, A Alhaskawi, Y Dong, H Zhou, SHA Ezzi\u2026 - Scientific Reports, 2025", "abstract": "The task of generating medical reports automatically is of paramount importance in modern healthcare, offering a substantial reduction in the workload of radiologists and accelerating the processes of clinical diagnosis and treatment. Current \u2026"}]
