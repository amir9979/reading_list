[{"title": "C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing", "link": "https://arxiv.org/pdf/2504.07964", "details": "Z Li, Z Li, T Zhou - arXiv preprint arXiv:2504.07964, 2025", "abstract": "Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely sub- optimal expert pathways-our study reveals that naive expert selection learned from pretraining leaves a surprising 10-20% accuracy gap for improvement. Motivated by \u2026"}, {"title": "ThoughtProbe: Classifier-Guided Thought Space Exploration Leveraging LLM Intrinsic Reasoning", "link": "https://arxiv.org/pdf/2504.06650", "details": "Z Wang, C Xu - arXiv preprint arXiv:2504.06650, 2025", "abstract": "Pre-trained large language models (LLMs) have been demonstrated to possess intrinsic reasoning capabilities that can emerge naturally when expanding the response space. However, the neural representation mechanisms underlying these \u2026"}, {"title": "Inferring Event Descriptions from Time Series with Language Models", "link": "https://arxiv.org/pdf/2503.14190", "details": "M Tan, MA Merrill, Z Gottesman, T Althoff, D Evans\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Time series data measure how environments change over time and drive decision- making in critical domains like finance and healthcare. When analyzing time series, we often seek to understand the underlying events occurring in the measured \u2026"}, {"title": "Empirical Calibration and Metric Differential Privacy in Language Models", "link": "https://arxiv.org/pdf/2503.13872", "details": "P Faustini, N Fernandes, A McIver, M Dras - arXiv preprint arXiv:2503.13872, 2025", "abstract": "NLP models trained with differential privacy (DP) usually adopt the DP-SGD framework, and privacy guarantees are often reported in terms of the privacy budget $\\epsilon $. However, $\\epsilon $ does not have any intrinsic meaning, and it is \u2026"}, {"title": "Efficient Tuning of Large Language Models for Knowledge-Grounded Dialogue Generation", "link": "https://arxiv.org/pdf/2504.07754", "details": "B Zhang, H Ma, D Li, J Ding, J Wang, B Xu, HF Lin - arXiv preprint arXiv:2504.07754, 2025", "abstract": "Large language models (LLMs) demonstrate remarkable text comprehension and generation capabilities but often lack the ability to utilize up-to-date or domain- specific knowledge not included in their training data. To address this gap, we \u2026"}, {"title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark", "link": "https://arxiv.org/pdf/2504.07749", "details": "V Mikhailov, T Enstad, D Samuel, HC Farseth\u00e5s\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces NorEval, a new and comprehensive evaluation suite for large- scale standardized benchmarking of Norwegian generative language models (LMs). NorEval consists of 24 high-quality human-created datasets--of which five are \u2026"}, {"title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2504.07887", "details": "R Cantini, A Orsino, M Ruggiero, D Talia - arXiv preprint arXiv:2504.07887, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, driving advancements in machine translation, summarization, and conversational agents. However, their increasing integration into critical societal domains has raised \u2026"}, {"title": "Exploring Human-Like Thinking in Search Simulations with Large Language Models", "link": "https://arxiv.org/pdf/2504.07570", "details": "E Zhang, X Wang, P Gong, Z Yang, J Mao - arXiv preprint arXiv:2504.07570, 2025", "abstract": "Simulating user search behavior is a critical task in information retrieval, which can be employed for user behavior modeling, data augmentation, and system evaluation. Recent advancements in large language models (LLMs) have opened up new \u2026"}]
