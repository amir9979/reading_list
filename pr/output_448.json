'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Bridging Different Language Models and Generative Visi'
[{"title": "Synth $^ 2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings", "link": "https://arxiv.org/pdf/2403.07750", "details": "S Sharifzadeh, C Kaplanis, S Pathak, D Kumaran, A Ilic\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The creation of high-quality human-labeled image-caption datasets presents a significant bottleneck in the development of Visual-Language Models (VLMs). We propose a novel approach that leverages the strengths of Large Language Models \u2026"}, {"title": "Aligning Large and Small Language Models via Chain-of-Thought Reasoning", "link": "https://aclanthology.org/2024.eacl-long.109.pdf", "details": "L Ranaldi, A Freitas - Proceedings of the 18th Conference of the European \u2026, 2024", "abstract": "Abstract Chain-of-Thought (CoT) prompting empowersthe reasoning abilities of Large Language Models (LLMs), eliciting them to solve complexreasoning tasks in a step-wise manner. However, these capabilities appear only in models with billions of \u2026"}, {"title": "Emergent Abilities in Reduced-Scale Generative Language Models", "link": "https://arxiv.org/html/2404.02204v1", "details": "S Muckatira, V Deshpande, V Lialin, A Rumshisky - arXiv preprint arXiv:2404.02204, 2024", "abstract": "Large language models can solve new tasks without task-specific fine-tuning. This ability, also known as in-context learning (ICL), is considered an emergent ability and is primarily seen in large language models with billions of parameters. This study \u2026"}, {"title": "BEnQA: A Question Answering and Reasoning Benchmark for Bengali and English", "link": "https://arxiv.org/pdf/2403.10900", "details": "S Shafayat, HM Hasan, MRC Mahim, RA Putri\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with \u2026"}, {"title": "VLRM: Vision-Language Models act as Reward Models for Image Captioning", "link": "https://arxiv.org/html/2404.01911v1", "details": "M Dzabraev, A Kunitsyn, A Ivaniuta - arXiv preprint arXiv:2404.01911, 2024", "abstract": "In this work, we present an unsupervised method for enhancing an image captioning model (in our case, BLIP2) using reinforcement learning and vision-language models like CLIP and BLIP2-ITM as reward models. The RL-tuned model is able to \u2026"}, {"title": "$\\mathbf {(N, K)} $-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model", "link": "https://arxiv.org/html/2403.07191v1", "details": "Y Zhang, L Chen, B Liu, Y Yang, Q Cui, Y Tao, H Yang - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in reinforcement learning (RL) algorithms aim to enhance the performance of language models at scale. Yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these \u2026"}, {"title": "What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases", "link": "https://arxiv.org/pdf/2404.02415", "details": "AMH Tiong, J Zhao, B Li, J Li, SCH Hoi, C Xiong - arXiv preprint arXiv:2404.02415, 2024", "abstract": "Vision-language (VL) models, pretrained on colossal image-text datasets, have attained broad VL competence that is difficult to evaluate. A common belief is that a small number of VL skills underlie the variety of VL tests. In this paper, we perform a \u2026"}, {"title": "Enhancing Data Quality in Federated Fine-Tuning of Foundation Models", "link": "https://arxiv.org/pdf/2403.04529", "details": "W Zhao, Y Du, ND Lane, S Chen, Y Wang - arXiv preprint arXiv:2403.04529, 2024", "abstract": "In the current landscape of foundation model training, there is a significant reliance on public domain data, which is nearing exhaustion according to recent research. To further scale up, it is crucial to incorporate collaboration among multiple specialized \u2026"}, {"title": "On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL", "link": "https://arxiv.org/pdf/2404.02389", "details": "Y Shao, N Nakashole - arXiv preprint arXiv:2404.02389, 2024", "abstract": "Structured data, prevalent in tables, databases, and knowledge graphs, poses a significant challenge in its representation. With the advent of large language models (LLMs), there has been a shift towards linearization-based methods, which process \u2026"}]
