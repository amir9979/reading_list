[{"title": "Sentiment works in small-cap stocks: Japanese stock's sentiment with language models", "link": "https://www.sciencedirect.com/science/article/pii/S2667096824001071", "details": "M Suzuki, Y Ishikawa, M Teraguchi, H Sakaji - International Journal of Information \u2026, 2025", "abstract": "We calculate sentiment from the Japanese Company Handbook, which contains a compact overview of Japanese companies' business situation and financial data, using multiple methods, including large language models. Language models such \u2026"}, {"title": "Lightweight Safety Classification Using Pruned Language Models", "link": "https://arxiv.org/pdf/2412.13435", "details": "M Sawtell, T Masterman, S Besen, J Brown - arXiv preprint arXiv:2412.13435, 2024", "abstract": "In this paper, we introduce a novel technique for content safety and prompt injection classification for Large Language Models. Our technique, Layer Enhanced Classification (LEC), trains a Penalized Logistic Regression (PLR) classifier on the \u2026"}, {"title": "From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs", "link": "https://arxiv.org/pdf/2412.18672", "details": "RK Joshi, S Sengupta, A Ekbal - arXiv preprint arXiv:2412.18672, 2024", "abstract": "Hallucination, a persistent challenge plaguing language models, undermines their efficacy and trustworthiness in various natural language processing endeavors by generating responses that deviate from factual accuracy or coherence. This paper \u2026"}, {"title": "Grounding Deliberate Reasoning in Multimodal Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-96-2061-6_2", "details": "J Chen, Y Liu, D Li, X An, W Deng, Z Feng, Y Zhao\u2026 - International Conference on \u2026, 2024", "abstract": "Abstract The rise of Multimodal Large Language Models, renowned for their advanced instruction-following and reasoning capabilities, has significantly propelled the field of visual reasoning. However, due to limitations in their image \u2026"}, {"title": "Text-Diffusion Red-Teaming of Large Language Models: Unveiling Harmful Behaviors with Proximity Constraints", "link": "https://arxiv.org/pdf/2501.08246", "details": "J N\u00f6ther, A Singla, G Radanovi\u0107 - arXiv preprint arXiv:2501.08246, 2025", "abstract": "Recent work has proposed automated red-teaming methods for testing the vulnerabilities of a given target large language model (LLM). These methods use red- teaming LLMs to uncover inputs that induce harmful behavior in a target LLM. In this \u2026"}, {"title": "LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models", "link": "https://arxiv.org/pdf/2501.00055", "details": "M Yu, J Fang, Y Zhou, X Fan, K Wang, S Pan, Q Wen - arXiv preprint arXiv \u2026, 2024", "abstract": "While safety-aligned large language models (LLMs) are increasingly used as the cornerstone for powerful systems such as multi-agent frameworks to solve complex real-world problems, they still suffer from potential adversarial queries, such as \u2026"}, {"title": "Aligning Crowd-Sourced Human Feedback for Reinforcement Learning on Code Generation by Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10818581/", "details": "MF Wong, CW Tan - IEEE Transactions on Big Data, 2024", "abstract": "This paper studies how AI-assisted programming and large language models (LLM) improve software developers' ability via AI tools (LLM agents) like Github Copilot and Amazon CodeWhisperer, while integrating human feedback to enhance \u2026"}, {"title": "Cascaded Self-Evaluation Augmented Training for Efficient Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2501.05662", "details": "Z Lv, W Wang, J Wang, S Zhang, F Wu - arXiv preprint arXiv:2501.05662, 2025", "abstract": "Efficient Multimodal Large Language Models (EMLLMs) have rapidly advanced recently. Incorporating Chain-of-Thought (CoT) reasoning and step-by-step self- evaluation has improved their performance. However, limited parameters often \u2026"}, {"title": "SKEWACT: Red Teaming Large Language Models via Activation-Skewed Adversarial Prompt Optimization", "link": "https://openreview.net/pdf%3Fid%3DQPdVqbcBgi", "details": "H Guo, S Cheng, G Tao, G Shen, Z Zhang, S An\u2026", "abstract": "Abstract Large Language Models (LLMs) have become increasingly impactful across various domains, including coding and data analysis. However, their widespread adoption has raised concerns about misuse, particularly in generating harmful or \u2026"}]
