[{"title": "MMCOMPOSITION: Revisiting the Compositionality of Pre-trained Vision-Language Models", "link": "https://arxiv.org/pdf/2410.09733", "details": "H Hua, Y Tang, Z Zeng, L Cao, Z Yang, H He, C Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The advent of large Vision-Language Models (VLMs) has significantly advanced multimodal understanding, enabling more sophisticated and accurate integration of visual and textual information across various tasks, including image and video \u2026"}, {"title": "AnyAttack: Towards Large-scale Self-supervised Generation of Targeted Adversarial Examples for Vision-Language Models", "link": "https://arxiv.org/pdf/2410.05346", "details": "J Zhang, J Ye, X Ma, Y Li, Y Yang, J Sang, DY Yeung - arXiv preprint arXiv \u2026, 2024", "abstract": "Due to their multimodal capabilities, Vision-Language Models (VLMs) have found numerous impactful applications in real-world scenarios. However, recent studies have revealed that VLMs are vulnerable to image-based adversarial attacks \u2026"}, {"title": "WsiCaption: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images", "link": "https://papers.miccai.org/miccai-2024/paper/0761_paper.pdf", "details": "P Chen, H Li, C Zhu, S Zheng, Z Shui, L Yang - International Conference on Medical \u2026, 2024", "abstract": "Whole slide images are the foundation of digital pathology for the diagnosis and treatment of carcinomas. Writing pathology reports is laborious and error-prone for inexperienced pathologists. To reduce the workload and improve clinical automation \u2026"}, {"title": "From One to Zero: RAG-IM Adapts Language Models for Interpretable Zero-Shot Predictions on Clinical Tabular Data", "link": "https://openreview.net/pdf%3Fid%3DBnKvIn8JKl", "details": "S Mahbub, C Ellington, S Alinejad, K Wen, Y Luo\u2026 - NeurIPS 2024 Third Table \u2026", "abstract": "Clinical machine learning models, often learned from tabular data, must adapt to new settings such as different hospitals, clinicians, or patient populations. These differing environments present related but subtly distinct tasks, where diseases and medical \u2026"}, {"title": "MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.10139", "details": "P Xia, S Han, S Qiu, Y Zhou, Z Wang, W Zheng, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Interleaved multimodal comprehension and generation, enabling models to produce and interpret both images and text in arbitrary sequences, have become a pivotal area in multimodal learning. Despite significant advancements, the evaluation of this \u2026"}, {"title": "VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment", "link": "https://arxiv.org/pdf/2410.09421", "details": "L Li, Z Xie, M Li, S Chen, P Wang, L Chen, Y Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large vision-language models (LVLMs) evolve rapidly, the demand for high- quality and diverse data to align these models becomes increasingly crucial. However, the creation of such data with human supervision proves costly and time \u2026"}, {"title": "Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies", "link": "https://arxiv.org/pdf/2409.15163", "details": "S Myers, TA Miller, Y Gao, MM Churpek\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Objective: Applying large language models (LLMs) to the clinical domain is challenging due to the context-heavy nature of processing medical records. Retrieval- augmented generation (RAG) offers a solution by facilitating reasoning over large \u2026"}, {"title": "Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning", "link": "https://arxiv.org/pdf/2410.10144", "details": "H Yuan, S Liu, K Cho, K Liao, A Pereira, T Cai - arXiv preprint arXiv:2410.10144, 2024", "abstract": "We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a framework designed to bridge genetic and biomedical knowledge bases. What sets GENEREL apart is its ability to fine-tune language models to infuse \u2026"}]
