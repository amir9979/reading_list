[{"title": "Ensembling disentangled domain-specific prompts for domain generalization", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124009924", "details": "F Xu, S Deng, T Jia, X Yu, D Chen - Knowledge-Based Systems, 2024", "abstract": "Abstract Domain generalization (DG) is a challenging problem because we cannot access any unseen target domain data during training. Recent emergence of vision- language models (VLMs) has inspired researchers to improve the DG performance \u2026"}, {"title": "Cross-Lingual Multi-Hop Knowledge Editing--Benchmarks, Analysis and a Simple Contrastive Learning based Approach", "link": "https://arxiv.org/pdf/2407.10275", "details": "A Khandelwal, H Singh, H Gu, T Chen, K Zhou - arXiv preprint arXiv:2407.10275, 2024", "abstract": "Large language models are often expected to constantly adapt to new sources of knowledge and knowledge editing techniques aim to efficiently patch the outdated model knowledge, with minimal modification. Most prior works focus on monolingual \u2026"}, {"title": "Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank", "link": "https://arxiv.org/pdf/2407.19943", "details": "S Gupta, H Oosterhuis, M de Rijke - arXiv preprint arXiv:2407.19943, 2024", "abstract": "Counterfactual learning to rank (CLTR) can be risky; various circumstances can cause it to produce sub-optimal models that hurt performance when deployed. Safe CLTR was introduced to mitigate these risks when using inverse propensity scoring \u2026"}, {"title": "A Systematic Evaluation of GPT-4V's Multimodal Capability for Chest X-ray Image Analysis", "link": "https://www.sciencedirect.com/science/article/pii/S2950162824000535", "details": "Y Liu, Y Li, Z Wang, X Liang, L Liu, L Wang, L Cui, Z Tu\u2026 - Meta-Radiology, 2024", "abstract": "This work evaluates GPT-4V's multimodal capability for medical image analysis, focusing on three representative tasks radiology report generation, medical visual question answering, and medical visual grounding. For the evaluation, a set of \u2026"}, {"title": "EVLM: An Efficient Vision-Language Model for Visual Understanding", "link": "https://arxiv.org/pdf/2407.14177", "details": "K Chen, D Shen, H Zhong, H Zhong, K Xia, D Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the field of multi-modal language models, the majority of methods are built on an architecture similar to LLaVA. These models use a single-layer ViT feature as a visual prompt, directly feeding it into the language models alongside textual tokens \u2026"}, {"title": "Generation and Evaluation of Synthetic Endoscopy Free-Text Reports with Differential Privacy", "link": "https://aclanthology.org/2024.bionlp-1.2.pdf", "details": "A Zecevic, X Zhang, S Zeki, A Roberts - Proceedings of the 23rd Workshop on \u2026, 2024", "abstract": "The development of NLP models in the healthcare sector faces important challenges due to the limited availability of patient data, mainly driven by privacy concerns. This study proposes the generation of synthetic free-text medical reports, specifically \u2026"}, {"title": "Artificial Intelligence in Healthcare: Clinical Decision Support and Modeling", "link": "https://www.degruyter.com/document/isbn/9781501521539/html", "details": "D Etli - Artificial Intelligence in Healthcare", "abstract": "The field of healthcare is being transformed by artificial intelligence (AI). Professionals need to comprehend the potential impact of AI on clinical decision support and epidemiological modeling. This comprehensive guide helps bridge the \u2026"}, {"title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education", "link": "https://arxiv.org/pdf/2407.17022", "details": "S Kim, S Kim - arXiv preprint arXiv:2407.17022, 2024", "abstract": "Large language model (LLM)-based evaluation pipelines have demonstrated their capability to robustly evaluate machine-generated text. Extending this methodology to assess human-written text could significantly benefit educational settings by \u2026"}, {"title": "AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization", "link": "https://arxiv.org/pdf/2407.11591", "details": "A Afzal, R Chalumattu, F Matthes, LM Espuny - arXiv preprint arXiv:2407.11591, 2024", "abstract": "Despite the advances in the abstractive summarization task using Large Language Models (LLM), there is a lack of research that asses their abilities to easily adapt to different domains. We evaluate the domain adaptation abilities of a wide range of \u2026"}]
