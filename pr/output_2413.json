[{"title": "Enhancing adversarial robustness for deep metric learning via neural discrete adversarial training", "link": "https://www.sciencedirect.com/science/article/pii/S0167404824002013", "details": "C Li, Z Zhu, R Niu, Y Zhao - Computers & Security, 2024", "abstract": "Due to the security concerns arising from adversarial vulnerability in deep metric learning models, it is essential to enhance their adversarial robustness for secure neural network software development. Existing defense strategies utilize adversarial \u2026"}, {"title": "Federated Learning via Reweighting Information Bottleneck with Domain Generalization", "link": "https://www.sciencedirect.com/science/article/pii/S0020025524007394", "details": "F Li, X Chen, Z Han, Y Du, H Han - Information Sciences, 2024", "abstract": "Federated learning (FL) plays an important role in collaborative distributed modeling. However, most studies cannot address poor generalization of out-of-distribution (OoD) data. Efforts have been exerted to address data heterogeneity among \u2026"}, {"title": "Relationship constraint deep metric learning", "link": "https://link.springer.com/article/10.1007/s10489-024-05425-x", "details": "Y Zhang, T Xiao, Z Wang, X Wang, W Feng, Z Fu\u2026 - Applied Intelligence, 2024", "abstract": "Deep metric learning (DML) models aim to learn semantically meaningful representations in which similar samples are pulled together and dissimilar samples are pushed apart. However, the classification effect is limited due to the high time \u2026"}, {"title": "Potential Field Based Deep Metric Learning", "link": "https://arxiv.org/pdf/2405.18560", "details": "S Bhatnagar, N Ahuja - arXiv preprint arXiv:2405.18560, 2024", "abstract": "Deep metric learning (DML) involves training a network to learn a semantically meaningful representation space. Many current approaches mine n-tuples of examples and model interactions within each tuplets. We present a novel \u2026"}, {"title": "Q-value Regularized Transformer for Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2405.17098", "details": "S Hu, Z Fan, C Huang, L Shen, Y Zhang, Y Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in offline reinforcement learning (RL) have underscored the capabilities of Conditional Sequence Modeling (CSM), a paradigm that learns the action distribution based on history trajectory and target returns for each state \u2026"}, {"title": "Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients", "link": "https://arxiv.org/pdf/2405.16304", "details": "F Pourpanah, M Molahasani, M Soltany, M Greenspan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We address the problem of federated domain generalization in an unsupervised setting for the first time. We first theoretically establish a connection between domain shift and alignment of gradients in unsupervised federated learning and show that \u2026"}, {"title": "Domain generalization person re-identification via style adaptation learning", "link": "https://link.springer.com/article/10.1007/s13042-024-02188-2", "details": "Y Guo, X Dou, Y Zhu, X Wang - International Journal of Machine Learning and \u2026, 2024", "abstract": "Abstract Domain generalization person re-identification (DG Re-ID) aims to deploy a Re-ID model trained on multiple source domains to unseen domains without adaptation, which is a practical and challenging problem. Due to the significant drop \u2026"}, {"title": "GTA: Generative Trajectory Augmentation with Guidance for Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2405.16907", "details": "J Lee, S Yun, T Yun, J Park - arXiv preprint arXiv:2405.16907, 2024", "abstract": "Offline Reinforcement Learning (Offline RL) presents challenges of learning effective decision-making policies from static datasets without any online interactions. Data augmentation techniques, such as noise injection and data synthesizing, aim to \u2026"}, {"title": "BAFFLE: Hiding Backdoors in Offline Reinforcement Learning Datasets", "link": "https://www.computer.org/csdl/proceedings-article/sp/2024/313000a218/1WPcYJ8kPNm", "details": "C Gong, Z Yang, Y Bai, J Shi, J He, K Li, B Xu\u2026 - 2024 IEEE Symposium on \u2026, 2024", "abstract": "Reinforcement learning (RL) makes an agent learn from trial-and-error experiences gathered during the interaction with the environment. Recently, offline RL has become a popular RL paradigm because it saves the interactions with environments \u2026"}]
