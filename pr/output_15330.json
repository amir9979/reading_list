[{"title": "Multilingual Retrieval-Augmented Generation for Knowledge-Intensive Task", "link": "https://arxiv.org/pdf/2504.03616", "details": "L Ranaldi, B Haddow, A Birch - arXiv preprint arXiv:2504.03616, 2025", "abstract": "Retrieval-augmented generation (RAG) has become a cornerstone of contemporary NLP, enhancing large language models (LLMs) by allowing them to access richer factual contexts through in-context retrieval. While effective in monolingual settings \u2026"}, {"title": "A Survey on Hallucination in Large Language and Foundation Models", "link": "https://www.preprints.org/frontend/manuscript/c5f20698cf44a95d88e568ddde2066e0/download_pub", "details": "P Ahadian, Q Guan - 2025", "abstract": "Generative text models, particularly large language models (LLMs) and foundation models, have influenced numerous fields, including high-quality text generation, reasoning, and multimodal synthesis. These models have been widely applied in \u2026"}]
