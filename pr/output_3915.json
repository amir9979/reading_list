[{"title": "KU-DMIS at MEDIQA-CORR 2024: Exploring the Reasoning Capabilities of Small Language Models in Medical Error Correction", "link": "https://aclanthology.org/2024.clinicalnlp-1.51.pdf", "details": "H Hwang, T Lee, H Kim, J Kang - Proceedings of the 6th Clinical Natural Language \u2026, 2024", "abstract": "Recent advancements in large language models (LM) like OpenAI's GPT-4 have shown promise in healthcare, particularly in medical question answering and clinical applications. However, their deployment raises privacy concerns and their size limits \u2026"}, {"title": "MemDPT: Differential Privacy for Memory Efficient Language Models", "link": "https://arxiv.org/pdf/2406.11087", "details": "Y Liu, X Peng, J Cao, Y Zhang, C Ma, S Deng, M Fu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models have consistently demonstrated remarkable performance across a wide spectrum of applications. Nonetheless, the deployment of these models can inadvertently expose user privacy to potential risks. The substantial \u2026"}, {"title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?", "link": "https://arxiv.org/pdf/2406.16316", "details": "Y Jinnai - arXiv preprint arXiv:2406.16316, 2024", "abstract": "Alignment of the language model with human preferences is a common approach to making a language model useful to end users. However, most alignment work is done in English, and human preference datasets are dominated by English \u2026"}, {"title": "ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models", "link": "https://arxiv.org/pdf/2406.13342", "details": "H Jo, H Lee, T Park - arXiv preprint arXiv:2406.13342, 2024", "abstract": "The recent advancements in large language models (LLMs) have brought significant progress in solving NLP tasks. Notably, in-context learning (ICL) is the key enabling mechanism for LLMs to understand specific tasks and grasping nuances. In this \u2026"}, {"title": "A Survey on Human Preference Learning for Large Language Models", "link": "https://arxiv.org/pdf/2406.11191", "details": "R Jiang, K Chen, X Bai, Z He, J Li, M Yang, T Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The recent surge of versatile large language models (LLMs) largely depends on aligning increasingly capable foundation models with human intentions by preference learning, enhancing LLMs with excellent applicability and effectiveness in \u2026"}, {"title": "Evaluating machine learning approaches for multi-label classification of unstructured electronic health records with a generative large language model", "link": "https://www.medrxiv.org/content/10.1101/2024.06.24.24309441.full.pdf", "details": "D Vithanage, C Deng, L Wang, M Yin, M Alkhalaf\u2026 - medRxiv, 2024", "abstract": "Multi-label classification of unstructured electronic health records (EHR) poses challenges due to the inherent semantic complexity in textual data. Advances in natural language processing (NLP) using large language models (LLMs) show \u2026"}, {"title": "Large Language Models are Interpretable Learners", "link": "https://arxiv.org/pdf/2406.17224", "details": "R Wang, S Si, F Yu, D Wiesmann, CJ Hsieh, I Dhillon - arXiv preprint arXiv \u2026, 2024", "abstract": "The trade-off between expressiveness and interpretability remains a core challenge when building human-centric predictive models for classification and decision- making. While symbolic rules offer interpretability, they often lack expressiveness \u2026"}, {"title": "Rethinking Entity-level Unlearning for Large Language Models", "link": "https://arxiv.org/pdf/2406.15796", "details": "W Ma, X Feng, W Zhong, L Huang, Y Ye, B Qin - arXiv preprint arXiv:2406.15796, 2024", "abstract": "Large language model unlearning has gained increasing attention due to its potential to mitigate security and privacy concerns. Current research predominantly focuses on Instance-level unlearning, specifically aiming at forgetting predefined \u2026"}, {"title": "Adversarial Attacks on Large Language Models in Medicine", "link": "https://arxiv.org/pdf/2406.12259", "details": "Y Yang, Q Jin, F Huang, Z Lu - arXiv preprint arXiv:2406.12259, 2024", "abstract": "The integration of Large Language Models (LLMs) into healthcare applications offers promising advancements in medical diagnostics, treatment recommendations, and patient care. However, the susceptibility of LLMs to adversarial attacks poses a \u2026"}]
