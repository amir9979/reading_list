[{"title": "Style over Substance: Distilled Language Models Reason Via Stylistic Replication", "link": "https://arxiv.org/pdf/2504.01738", "details": "P Lippmann, J Yang - arXiv preprint arXiv:2504.01738, 2025", "abstract": "Specialized reasoning language models (RLMs) have demonstrated that scaling test- time computation through detailed reasoning traces significantly enhances performance. Although these traces effectively facilitate knowledge distillation into \u2026"}, {"title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge", "link": "https://arxiv.org/pdf/2504.07887", "details": "R Cantini, A Orsino, M Ruggiero, D Talia - arXiv preprint arXiv:2504.07887, 2025", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, driving advancements in machine translation, summarization, and conversational agents. However, their increasing integration into critical societal domains has raised \u2026"}, {"title": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models", "link": "https://arxiv.org/pdf/2503.18923", "details": "M Cao, P Hu, Y Wang, J Gu, H Tang, H Zhao, J Dong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we \u2026"}, {"title": "Mixture-of-Personas Language Models for Population Simulation", "link": "https://arxiv.org/pdf/2504.05019", "details": "N Bui, HT Nguyen, S Kumar, J Theodore, W Qiu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Advances in Large Language Models (LLMs) paved the way for their emerging applications in various domains, such as human behavior simulations, where LLMs could augment human-generated data in social science research and machine \u2026"}, {"title": "V-MAGE: A Game Evaluation Framework for Assessing Visual-Centric Capabilities in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2504.06148", "details": "X Zheng, L Li, Z Yang, P Yu, AJ Wang, R Yan, Y Yao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have led to significant improvements across various multimodal benchmarks. However, as evaluations shift from static datasets to open-world, dynamic environments, current \u2026"}, {"title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models", "link": "https://arxiv.org/pdf/2504.06214", "details": "C Xu, W Ping, P Xu, Z Liu, B Wang, M Shoeybi, B Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context learning, and inference-time scaling, all of which require models to process and reason over long sequences of text and \u2026"}, {"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2504.00869%3F", "details": "X Huang, J Wu, H Liu, X Tang, Y Zhou - arXiv preprint arXiv:2504.00869, 2025", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from \u2026"}, {"title": "Modality Plug-and-Play: Runtime Modality Adaptation in LLM-Driven Autonomous Mobile Systems", "link": "https://sites.pitt.edu/~weigao/publications/mobicom25_mpnp.pdf", "details": "K Huang, X Yin, H Huang, W Gao - ACM MobiCom, 2025", "abstract": "Multimodal reasoning by LLMs is critical to autonomous mobile systems, but the growing diversity of input data modalities prevents incorporating all modalities into LLMs. Instead, only the useful modalities should be adaptively involved at runtime \u2026"}, {"title": "A Neuro-inspired Interpretation of Unlearning in Large Language Models through Sample-level Unlearning Difficulty", "link": "https://arxiv.org/pdf/2504.06658", "details": "X Feng, Y Li, C Wang, J Liu, L Zhang, C Chen - arXiv preprint arXiv:2504.06658, 2025", "abstract": "Driven by privacy protection laws and regulations, unlearning in Large Language Models (LLMs) is gaining increasing attention. However, current research often neglects the interpretability of the unlearning process, particularly concerning sample \u2026"}]
