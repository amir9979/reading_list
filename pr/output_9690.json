[{"title": "Guided Knowledge Generation with Language Models for Commonsense Reasoning", "link": "https://aclanthology.org/2024.findings-emnlp.61.pdf", "details": "X Wei, H Chen, H Yu, H Fei, Q Liu - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) have achieved notable success in commonsense reasoning tasks, benefiting from their extensive world knowledge acquired through extensive pretraining. While approaches like Chain-of-Thought \u2026"}, {"title": "Can Language Models Learn to Skip Steps?", "link": "https://arxiv.org/pdf/2411.01855%3F", "details": "T Liu, Q Guo, X Hu, C Jiayang, Y Zhang, X Qiu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Trained on vast corpora of human language, language models demonstrate emergent human-like reasoning abilities. Yet they are still far from true intelligence, which opens up intriguing opportunities to explore the parallels of humans and \u2026"}, {"title": "LM2: A Simple Society of Language Models Solves Complex Reasoning", "link": "https://aclanthology.org/2024.emnlp-main.920.pdf", "details": "G Juneja, S Dutta, T Chakraborty - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Despite demonstrating emergent reasoning abilities, Large Language Models (LLMS) often lose track of complex, multi-step reasoning. Existing studies show that providing guidance via decomposing the original question into multiple subproblems \u2026"}, {"title": "Causal Inference and Prediction for Network Data", "link": "https://www.birs.ca/workshops/2024/24w5244/report24w5244.pdf", "details": "E Kolaczyk, E Levina, T Li, E Ogburn", "abstract": "The swift evolution of data collection technologies has yielded an abundance of network data across diverse fields such as social sciences, biology, neuroscience, and engineering. These networks represent complex systems where nodes (eg \u2026"}, {"title": "Rethinking the Role of Proxy Rewards in Language Model Alignment", "link": "https://aclanthology.org/2024.emnlp-main.1150.pdf", "details": "S Kim, M Seo - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Learning from human feedback via proxy reward modeling has been studied to align Large Language Models (LLMs) with human values. However, achieving reliable training through that proxy reward model (RM) is not a trivial problem, and its \u2026"}, {"title": "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning", "link": "https://aclanthology.org/2024.emnlp-main.313.pdf", "details": "M Xu, Y Li, K Sun, T Qian - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Large language models (LLMs) have shown excellent capability for solving reasoning problems. Existing approaches do not differentiate the question difficulty when designing prompting methods for them. Clearly, a simple method cannot elicit \u2026"}, {"title": "Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention", "link": "https://arxiv.org/pdf/2411.02063", "details": "X Lv, N Ding, K Zhang, E Hua, G Cui, B Zhou - arXiv preprint arXiv:2411.02063, 2024", "abstract": "Improving the effectiveness and efficiency of large language models (LLMs) simultaneously is a critical yet challenging research goal. In this paper, we find that low-rank pre-training, normally considered as efficient methods that will compromise \u2026"}, {"title": "A Novel Instruction Tuning Method for Vietnamese Mathematical Reasoning using Trainable Open-Source Large Language Models", "link": "https://aclanthology.org/2024.conll-1.20.pdf", "details": "N Vinh, TD Nguyen, V Nguyen, N Bui - Proceedings of the 28th Conference on \u2026, 2024", "abstract": "Abstract This study introduces Simple Reasoning with Code (SiRC), a novel instruction fine-tuning method for solving mathematical reasoning problems, particularly effective for Vietnamese, which is considered a low-resource language \u2026"}]
