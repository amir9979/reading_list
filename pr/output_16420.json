[{"title": "Deep anomaly detection with partition contrastive learning for tabular data", "link": "https://link.springer.com/article/10.1007/s10618-025-01102-w", "details": "Y Li, Y Wang, H Xu, B Li, X Zhou - Data Mining and Knowledge Discovery, 2025", "abstract": "Self-supervised anomaly detection (AD) methods define transformations and surrogate tasks to deeply learn data \u201cnormality\u201d, presenting superior performance. Different from most existing work designed for images, this paper considers self \u2026"}, {"title": "GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data", "link": "https://arxiv.org/pdf/2505.03233", "details": "S Deng, M Yan, S Wei, H Ma, Y Yang, J Chen, Z Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Embodied foundation models are gaining increasing attention for their zero-shot generalization, scalability, and adaptability to new tasks through few-shot post- training. However, existing models rely heavily on real-world data, which is costly \u2026"}, {"title": "Vision Foundation Model Embedding-Based Semantic Anomaly Detection", "link": "https://arxiv.org/pdf/2505.07998", "details": "MP Ronecker, M Foutter, A Elhafsi, D Gammelli\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Semantic anomalies are contextually invalid or unusual combinations of familiar visual elements that can cause undefined behavior and failures in system-level reasoning for autonomous systems. This work explores semantic anomaly detection \u2026"}, {"title": "Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders", "link": "https://arxiv.org/pdf/2505.08080", "details": "D Shu, X Wu, H Zhao, M Du, N Liu - arXiv preprint arXiv:2505.08080, 2025", "abstract": "Sparse Autoencoders (SAEs) have recently emerged as powerful tools for interpreting and steering the internal representations of large language models (LLMs). However, conventional approaches to analyzing SAEs typically rely solely \u2026"}, {"title": "Self-Supervised Trajectory Representation Learning with Multi-Scale Spatio-Temporal Feature Exploration", "link": "https://www.computer.org/csdl/proceedings-article/icde/2025/360300a779/26FZzwKY6nm", "details": "H Xia, X Zhang, Y Cao, L Cao, Y Yu, J Dong - 2025 IEEE 41st International \u2026, 2025", "abstract": "Trajectory representation learning transforms the complex spatio-temporal features of trajectories into a dense, low-dimensional embedding, which supports various downstream analytics tasks such as trajectory classification, travel time estimation \u2026"}, {"title": "MotionCrafter: Plug-and-Play Motion Guidance for Diffusion Models", "link": "https://ieeexplore.ieee.org/abstract/document/10999055/", "details": "Y Zhang, W Dong, F Tang, N Huang, H Huang, C Ma\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "The essence of a video lies in the dynamic motions. While text-to-video generative diffusion models have made significant strides in creating diverse content, effectively controlling specific motions through text prompts remains a challenge. By utilizing \u2026"}]
