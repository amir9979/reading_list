[{"title": "Show, Don't Tell: Aligning Language Models with Demonstrated Feedback", "link": "https://arxiv.org/pdf/2406.00888", "details": "O Shaikh, M Lam, J Hejna, Y Shao, M Bernstein\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models are aligned to emulate the collective voice of many, resulting in outputs that align with no one in particular. Steering LLMs away from generic output is possible through supervised finetuning or RLHF, but requires prohibitively large \u2026"}, {"title": "Probing Language Models for Pre-training Data Detection", "link": "https://arxiv.org/pdf/2406.01333", "details": "Z Liu, T Zhu, C Tan, H Lu, B Liu, W Chen - arXiv preprint arXiv:2406.01333, 2024", "abstract": "Large Language Models (LLMs) have shown their impressive capabilities, while also raising concerns about the data contamination problems due to privacy issues and leakage of benchmark datasets in the pre-training phase. Therefore, it is vital to \u2026"}, {"title": "FuRL: Visual-Language Models as Fuzzy Rewards for Reinforcement Learning", "link": "https://arxiv.org/pdf/2406.00645", "details": "Y Fu, H Zhang, D Wu, W Xu, B Boulet - arXiv preprint arXiv:2406.00645, 2024", "abstract": "In this work, we investigate how to leverage pre-trained visual-language models (VLM) for online Reinforcement Learning (RL). In particular, we focus on sparse reward tasks with pre-defined textual task descriptions. We first identify the problem \u2026"}, {"title": "BLSP-Emo: Towards Empathetic Large Speech-Language Models", "link": "https://arxiv.org/pdf/2406.03872", "details": "C Wang, M Liao, Z Huang, J Wu, C Zong, J Zhang - arXiv preprint arXiv:2406.03872, 2024", "abstract": "The recent release of GPT-4o showcased the potential of end-to-end multimodal models, not just in terms of low latency but also in their ability to understand and generate expressive speech with rich emotions. While the details are unknown to the \u2026"}, {"title": "Code Pretraining Improves Entity Tracking Abilities of Language Models", "link": "https://arxiv.org/pdf/2405.21068", "details": "N Kim, S Schuster, S Toshniwal - arXiv preprint arXiv:2405.21068, 2024", "abstract": "Recent work has provided indirect evidence that pretraining language models on code improves the ability of models to track state changes of discourse entities expressed in natural language. In this work, we systematically test this claim by \u2026"}, {"title": "Automatic Instruction Evolving for Large Language Models", "link": "https://arxiv.org/pdf/2406.00770", "details": "W Zeng, C Xu, Y Zhao, JG Lou, W Chen - arXiv preprint arXiv:2406.00770, 2024", "abstract": "Fine-tuning large pre-trained language models with Evol-Instruct has achieved encouraging results across a wide range of tasks. However, designing effective evolving methods for instruction evolution requires substantial human expertise. This \u2026"}, {"title": "Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark", "link": "https://arxiv.org/pdf/2405.20574", "details": "C Park, H Kim, D Kim, S Cho, S Kim, S Lee, Y Kim\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as vital tools for evaluating Large Language Models (LLMs) in Korean. Incorporating private test sets while mirroring the English Open LLM Leaderboard, we establish a \u2026"}, {"title": "Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models", "link": "https://arxiv.org/pdf/2406.02061", "details": "M Nezhurina, L Cipolina-Kun, M Cherti, J Jitsev - arXiv preprint arXiv:2406.02061, 2024", "abstract": "Large Language Models (LLMs) are often described as being instances of foundation models-that is, models that transfer strongly across various tasks and conditions in few-show or zero-shot manner, while exhibiting scaling laws that \u2026"}, {"title": "Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2405.20680", "details": "M Li, X Li, Y Chen, W Xuan, W Zhang - arXiv preprint arXiv:2405.20680, 2024", "abstract": "Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their superiority in terms of factuality, they do not consistently outperform the original retrieval-free Language Models (LMs). Our experiments reveal that this example \u2026"}]
