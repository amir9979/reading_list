[{"title": "Class imbalance on medical image classification: towards better evaluation practices for discrimination and calibration performance", "link": "https://link.springer.com/article/10.1007/s00330-024-10834-0", "details": "C Mosquera, L Ferrer, DH Milone, D Luna, E Ferrante - European Radiology, 2024", "abstract": "Purpose This work aims to assess standard evaluation practices used by the research community for evaluating medical imaging classifiers, with a specific focus on the implications of class imbalance. The analysis is performed on chest X-rays as \u2026"}, {"title": "Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models", "link": "https://arxiv.org/pdf/2405.14715", "details": "YK Jang, S Lim - arXiv preprint arXiv:2405.14715, 2024", "abstract": "Modern retrieval systems often struggle with upgrading to new and more powerful models due to the incompatibility of embeddings between the old and new models. This necessitates a costly process known as backfilling, which involves re-computing \u2026"}, {"title": "Residual-based Language Models are Free Boosters for Biomedical Imaging Tasks", "link": "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Lai_Residual-based_Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks_CVPRW_2024_paper.pdf", "details": "Z Lai, J Wu, S Chen, Y Zhou, N Hovakimyan - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "In this study we uncover the unexpected efficacy of residual-based large language models (LLMs) as part of encoders for biomedical imaging tasks a domain traditionally devoid of language or textual data. The approach diverges from \u2026"}, {"title": "Multi-Agent Transfer Learning via Temporal Contrastive Learning", "link": "https://arxiv.org/pdf/2406.01377", "details": "W Zeng, J Campbell, S Stepputtis, K Sycara - arXiv preprint arXiv:2406.01377, 2024", "abstract": "This paper introduces a novel transfer learning framework for deep multi-agent reinforcement learning. The approach automatically combines goal-conditioned policies with temporal contrastive learning to discover meaningful sub-goals. The \u2026"}, {"title": "RefAI: a GPT-powered retrieval-augmented generative tool for biomedical literature recommendation and summarization", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae129/7690757", "details": "Y Li, J Zhao, M Li, Y Dang, E Yu, J Li, Z Sun, U Hussein\u2026 - Journal of the American \u2026, 2024", "abstract": "Objectives Precise literature recommendation and summarization are crucial for biomedical professionals. While the latest iteration of generative pretrained transformer (GPT) incorporates 2 distinct modes\u2014real-time search and pretrained \u2026"}, {"title": "Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Bu_Instance-level_Expert_Knowledge_and_Aggregate_Discriminative_Attention_for_Radiology_Report_CVPR_2024_paper.pdf", "details": "S Bu, T Li, Y Yang, Z Dai - Proceedings of the IEEE/CVF Conference on Computer \u2026, 2024", "abstract": "Automatic radiology report generation can provide substantial advantages to clinical physicians by effectively reducing their workload and improving efficiency. Despite the promising potential of current methods challenges persist in effectively extracting \u2026"}, {"title": "CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models", "link": "https://arxiv.org/pdf/2406.06007", "details": "P Xia, Z Chen, J Tian, Y Gong, R Hou, Y Xu, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Artificial intelligence has significantly impacted medical applications, particularly with the advent of Medical Large Vision Language Models (Med-LVLMs), sparking optimism for the future of automated and personalized healthcare. However, the \u2026"}, {"title": "Symmetric Dot-Product Attention for Efficient Training of BERT Language Models", "link": "https://arxiv.org/pdf/2406.06366", "details": "M Courtois, M Ostendorff, L Hennig, G Rehm - arXiv preprint arXiv:2406.06366, 2024", "abstract": "Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing \u2026"}, {"title": "Show Think and Tell: Thought-Augmented Fine-Tuning of Large Language Models for Video Captioning", "link": "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/papers/Kim_Show_Think_and_Tell_Thought-Augmented_Fine-Tuning_of_Large_Language_Models_CVPRW_2024_paper.pdf", "details": "B Kim, D Hwang, S Cho, Y Jang, H Lee, M Lee - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "Large language models (LLMs) have achieved a great success in natural language processing and have a significant potential for multi-modal applications. Despite the surprising zero-shot or few-shot ability it is also required to effectively fine-tune pre \u2026"}]
