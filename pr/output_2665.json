[{"title": "Observational Scaling Laws and the Predictability of Language Model Performance", "link": "https://arxiv.org/pdf/2405.10938", "details": "Y Ruan, CJ Maddison, T Hashimoto - arXiv preprint arXiv:2405.10938, 2024", "abstract": "Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different \u2026"}, {"title": "X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions", "link": "https://arxiv.org/pdf/2405.19744", "details": "C Li, W Yang, J Zhang, J Lu, S Wang, C Zong - arXiv preprint arXiv:2405.19744, 2024", "abstract": "Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples \u2026"}, {"title": "Analyzing Chain-of-thought Prompting in Black-Box Large Language Models via Estimated V-information", "link": "https://aclanthology.org/2024.lrec-main.81.pdf", "details": "Z Wang, C Li, Z Yang, Q Liu, Y Hao, X Chen, D Chu\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Chain-of-Thought (CoT) prompting combined with large language models (LLM) has shown great potential in improving performance on challenging reasoning tasks. While understanding why CoT prompting is effective is crucial for the \u2026"}, {"title": "Privacy-Aware Visual Language Models", "link": "https://arxiv.org/pdf/2405.17423", "details": "L Samson, N Barazani, S Ghebreab, YM Asano - arXiv preprint arXiv:2405.17423, 2024", "abstract": "This paper aims to advance our understanding of how Visual Language Models (VLMs) handle privacy-sensitive information, a crucial concern as these technologies become integral to everyday life. To this end, we introduce a new benchmark \u2026"}, {"title": "Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional Chaining", "link": "https://arxiv.org/pdf/2406.06586", "details": "S Liu, B He, L Song - arXiv preprint arXiv:2406.06586, 2024", "abstract": "Large Language Models (LLMs) have shown human-like reasoning abilities but still face challenges in solving complex logical problems. Existing unidirectional chaining methods, such as forward chaining and backward chaining, suffer from issues like \u2026"}, {"title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2405.18218", "details": "Y Zhang, Y Li, X Wang, Q Shen, B Plank, B Bischl\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Overparametrized transformer networks are the state-of-the-art architecture for Large Language Models (LLMs). However, such models contain billions of parameters making large compute a necessity, while raising environmental concerns. To \u2026"}, {"title": "TAIA: Large Language Models are Out-of-Distribution Data Learners", "link": "https://arxiv.org/pdf/2405.20192", "details": "S Jiang, Y Liao, Y Zhang, Y Wang, Y Wang - arXiv preprint arXiv:2405.20192, 2024", "abstract": "Fine-tuning on task-specific question-answer pairs is a predominant method for enhancing the performance of instruction-tuned large language models (LLMs) on downstream tasks. However, in certain specialized domains, such as healthcare or \u2026"}, {"title": "Scaling Laws for Discriminative Classification in Large Language Models", "link": "https://arxiv.org/pdf/2405.15765", "details": "D Wyatte, F Tahmasbi, M Li, T Markovich - arXiv preprint arXiv:2405.15765, 2024", "abstract": "Modern large language models (LLMs) represent a paradigm shift in what can plausibly be expected of machine learning models. The fact that LLMs can effectively generate sensible answers to a diverse range of queries suggests that they would be \u2026"}, {"title": "Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models", "link": "https://arxiv.org/pdf/2405.16282", "details": "A Kumar, R Morabito, S Umbet, J Kabbara, A Emami - arXiv preprint arXiv \u2026, 2024", "abstract": "As the use of Large Language Models (LLMs) becomes more widespread, understanding their self-evaluation of confidence in generated responses becomes increasingly important as it is integral to the reliability of the output of these models \u2026"}]
