[{"title": "MarvelOVD: Marrying Object Recognition and Vision-Language Models for Robust Open-Vocabulary Object Detection", "link": "https://arxiv.org/pdf/2407.21465", "details": "K Wang, L Cheng, W Chen, P Zhang, L Lin, F Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Learning from pseudo-labels that generated with VLMs~(Vision Language Models) has been shown as a promising solution to assist open vocabulary detection (OVD) in recent studies. However, due to the domain gap between VLM and vision \u2026"}, {"title": "LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language Models", "link": "https://arxiv.org/pdf/2407.08966", "details": "Y Zhang, W Zhu, C He, L Zhang - arXiv preprint arXiv:2407.08966, 2024", "abstract": "Out-of-distribution (OOD) detection is crucial for model reliability, as it identifies samples from unknown classes and reduces errors due to unexpected inputs. Vision- Language Models (VLMs) such as CLIP are emerging as powerful tools for OOD \u2026"}, {"title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey", "link": "https://arxiv.org/pdf/2407.21794", "details": "A Miyai, J Yang, J Zhang, Y Ming, Y Lin, Q Yu, G Irie\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly \u2026"}, {"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "3D Weakly Supervised Semantic Segmentation with 2D Vision-Language Guidance", "link": "https://arxiv.org/pdf/2407.09826", "details": "X Xu, Y Yuan, J Li, Q Zhang, Z Jie, L Ma, H Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper, we propose 3DSS-VLG, a weakly supervised approach for 3D Semantic Segmentation with 2D Vision-Language Guidance, an alternative approach that a 3D model predicts dense-embedding for each point which is co \u2026"}, {"title": "Understanding the Interplay of Scale, Data, and Bias in Language Models: A Case Study with BERT", "link": "https://arxiv.org/pdf/2407.21058", "details": "M Ali, S Panda, Q Shen, M Wick, A Kobren - arXiv preprint arXiv:2407.21058, 2024", "abstract": "In the current landscape of language model research, larger models, larger datasets and more compute seems to be the only way to advance towards intelligence. While there have been extensive studies of scaling laws and models' scaling behaviors, the \u2026"}, {"title": "ALFREDO: Active Learning with FeatuRe disEntangelement and DOmain adaptation for medical image classification", "link": "https://www.sciencedirect.com/science/article/pii/S1361841524001865", "details": "D Mahapatra, R Tennakoon, Y George, S Roy\u2026 - Medical image analysis, 2024", "abstract": "State-of-the-art deep learning models often fail to generalize in the presence of distribution shifts between training (source) data and test (target) data. Domain adaptation methods are designed to address this issue using labeled samples \u2026"}, {"title": "Forecasting Future Videos from Novel Views via Disentangled 3D Scene Representation", "link": "https://arxiv.org/pdf/2407.21450", "details": "S Yarram, J Yuan - arXiv preprint arXiv:2407.21450, 2024", "abstract": "Video extrapolation in space and time (VEST) enables viewers to forecast a 3D scene into the future and view it from novel viewpoints. Recent methods propose to learn an entangled representation, aiming to model layered scene geometry, motion \u2026"}, {"title": "Addressing Gender Bias in Generative Large Language Models", "link": "https://www.researchsquare.com/article/rs-4670889/latest.pdf", "details": "H Zhou, D Inkpen, B Kantarci - 2024", "abstract": "The examination of gender bias, alongside other demographic biases like race, nationality, and religion, within generative large language models (LLMs), is increasingly capturing the attention of both the scientific community and industry \u2026"}]
