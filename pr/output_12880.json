[{"title": "Parameters vs flops: Scaling laws for optimal sparsity for mixture-of-experts language models", "link": "https://arxiv.org/pdf/2501.12370", "details": "S Abnar, H Shah, D Busbridge, AME Ali, J Susskind\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Scaling the capacity of language models has consistently proven to be a reliable approach for improving performance and unlocking new capabilities. Capacity can be primarily defined by two dimensions: the number of model parameters and the \u2026"}, {"title": "Cost-Efficient Domain-Adaptive Pretraining of Language Models for Optoelectronics Applications", "link": "https://pubs.acs.org/doi/full/10.1021/acs.jcim.4c02029", "details": "D Huang, JM Cole - Journal of Chemical Information and Modeling, 2025", "abstract": "Pretrained language models have demonstrated strong capability and versatility in natural language processing (NLP) tasks, and they have important applications in optoelectronics research, such as data mining and topic modeling. Many language \u2026"}, {"title": "Hierarchical Autoregressive Transformers: Combining Byte-and Word-Level Processing for Robust, Adaptable Language Models", "link": "https://arxiv.org/pdf/2501.10322", "details": "P Neitemeier, B Deiseroth, C Eichenberg, L Balles - arXiv preprint arXiv:2501.10322, 2025", "abstract": "Tokenization is a fundamental step in natural language processing, breaking text into units that computational models can process. While learned subword tokenizers have become the de-facto standard, they present challenges such as large \u2026"}, {"title": "Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers", "link": "https://arxiv.org/pdf/2501.18237", "details": "M T\u00f6lle, M Scharaf, S Fischer, C Reich, S Zeid\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "A patient undergoes multiple examinations in each hospital stay, where each provides different facets of the health status. These assessments include temporal data with varying sampling rates, discrete single-point measurements, therapeutic \u2026"}, {"title": "3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography", "link": "https://arxiv.org/pdf/2502.02779", "details": "W Zhu, H Huang, H Tang, R Musthyala, B Yu, L Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Head computed tomography (CT) imaging is a widely-used imaging modality with multitudes of medical indications, particularly in assessing pathology of the brain, skull, and cerebrovascular system. It is commonly the first-line imaging in neurologic \u2026"}, {"title": "Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval", "link": "https://arxiv.org/pdf/2501.09134", "details": "D Deanda, YP Masupalli, J Yang, Y Lee, Z Cao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical images and reports offer invaluable insights into patient health. The heterogeneity and complexity of these data hinder effective analysis. To bridge this gap, we investigate contrastive learning models for cross-domain retrieval, which \u2026"}, {"title": "Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision", "link": "https://arxiv.org/pdf/2501.07886", "details": "Y Ye, C Laidlaw, J Steinhardt - arXiv preprint arXiv:2501.07886, 2025", "abstract": "Language model (LM) post-training relies on two stages of human supervision: task demonstrations for supervised finetuning (SFT), followed by preference comparisons for reinforcement learning from human feedback (RLHF). As LMs become more \u2026"}, {"title": "Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models", "link": "https://arxiv.org/pdf/2501.17420", "details": "Y Li, H Shirado, S Das - arXiv preprint arXiv:2501.17420, 2025", "abstract": "While advances in fairness and alignment have helped mitigate overt biases exhibited by large language models (LLMs) when explicitly prompted, we hypothesize that these models may still exhibit implicit biases when simulating \u2026"}, {"title": "HiMix: Reducing Computational Complexity in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2501.10318%3F", "details": "X Zhang, D Li, B Liu, Z Bao, Y Zhou, B Yang, Z Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Benefiting from recent advancements in large language models and modality alignment techniques, existing Large Vision-Language Models (LVLMs) have achieved prominent performance across a wide range of scenarios. However, the \u2026"}]
