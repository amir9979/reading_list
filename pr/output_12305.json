[{"title": "Eagle 2: Building Post-Training Data Strategies from Scratch for Frontier Vision-Language Models", "link": "https://arxiv.org/pdf/2501.14818", "details": "Z Li, G Chen, S Liu, S Wang, V VS, Y Ji, S Lan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, promising progress has been made by open-source vision-language models (VLMs) in bringing their capabilities closer to those of proprietary frontier models. However, most open-source models only publish their final model weights \u2026"}, {"title": "Baichuan-Omni-1.5 Technical Report", "link": "https://arxiv.org/pdf/2501.15368", "details": "Y Li, J Liu, T Zhang, S Chen, T Li, Z Li, L Liu, L Ming\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce Baichuan-Omni-1.5, an omni-modal model that not only has omni- modal understanding capabilities but also provides end-to-end audio generation capabilities. To achieve fluent and high-quality interaction across modalities without \u2026"}, {"title": "MME-Industry: A Cross-Industry Multimodal Evaluation Benchmark", "link": "https://arxiv.org/pdf/2501.16688", "details": "D Yi, G Zhu, C Ding, Z Li, D Yi, J Wang - arXiv preprint arXiv:2501.16688, 2025", "abstract": "With the rapid advancement of Multimodal Large Language Models (MLLMs), numerous evaluation benchmarks have emerged. However, comprehensive assessments of their performance across diverse industrial applications remain \u2026"}, {"title": "C-HDNet: A Fast Hyperdimensional Computing Based Method for Causal Effect Estimation from Networked Observational Data", "link": "https://arxiv.org/pdf/2501.16562", "details": "A Dalvi, N Ashtekar, V Honavar - arXiv preprint arXiv:2501.16562, 2025", "abstract": "We consider the problem of estimating causal effects from observational data in the presence of network confounding. In this context, an individual's treatment assignment and outcomes may be affected by their neighbors within the network. We \u2026"}, {"title": "How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks before and after Fine-tuning", "link": "https://arxiv.org/pdf/2501.17501", "details": "F Salerno, A Al-Kaswan, M Izadi - arXiv preprint arXiv:2501.17501, 2025", "abstract": "Code language models, while widely popular, are often trained on unsanitized source code gathered from across the Internet. Previous work revealed that pre- trained models can remember the content of their training data and regurgitate them \u2026"}, {"title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "link": "https://arxiv.org/pdf/2501.16961", "details": "M Raza, N Milic-Frayling - arXiv preprint arXiv:2501.16961, 2025", "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that \u2026"}, {"title": "Adapter-Enhanced Hierarchical Cross-Modal Pre-training for Lightweight Medical Report Generation", "link": "https://ieeexplore.ieee.org/abstract/document/10856362/", "details": "T Yu, W Lu, Y Yang, W Han, Q Huang, J Yu, K Zhang - IEEE Journal of Biomedical \u2026, 2025", "abstract": "Automatic medical report generation is an emerging field that aims to transform medical images into descriptive, clinically relevant narratives, potentially reducing the workload for radiologists significantly. Despite substantial progress, the \u2026"}, {"title": "RelCAT: Advancing Extraction of Clinical Inter-Entity Relationships from Unstructured Electronic Health Records", "link": "https://arxiv.org/pdf/2501.16077", "details": "S Agarwal, V Dinu, T Searle, M Ratas, A Shek, DF Stein\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This study introduces RelCAT (Relation Concept Annotation Toolkit), an interactive tool, library, and workflow designed to classify relations between entities extracted from clinical narratives. Building upon the CogStack MedCAT framework, RelCAT \u2026"}, {"title": "Ocean-OCR: Towards General OCR Application via a Vision-Language Model", "link": "https://arxiv.org/pdf/2501.15558", "details": "S Chen, X Guo, Y Li, T Zhang, M Lin, D Kuang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multimodal large language models (MLLMs) have shown impressive capabilities across various domains, excelling in processing and understanding information from multiple modalities. Despite the rapid progress made previously, insufficient OCR \u2026"}]
