[{"title": "LLaVA-o1: Let Vision Language Models Reason Step-by-Step", "link": "https://arxiv.org/pdf/2411.10440%3F", "details": "G Xu, P Jin, L Hao, Y Song, L Sun, L Yuan - arXiv preprint arXiv:2411.10440, 2024", "abstract": "Large language models have demonstrated substantial advancements in reasoning capabilities, particularly through inference-time scaling, as illustrated by models such as OpenAI's o1. However, current Vision-Language Models (VLMs) often struggle to \u2026"}, {"title": "Training-free Deep Concept Injection Enables Language Models for Video Question Answering", "link": "https://aclanthology.org/2024.emnlp-main.1249.pdf", "details": "X Lin, M Li, R Zemel, H Ji, SF Chang - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "Recently, enabling pretrained language models (PLMs) to perform zero-shot crossmodal tasks such as video question answering has been extensively studied. A popular approach is to learn a projection network that projects visual features into the \u2026"}, {"title": "Libra: Leveraging Temporal Images for Biomedical Radiology Analysis", "link": "https://arxiv.org/pdf/2411.19378", "details": "X Zhang, Z Meng, J Lever, ESL Ho - arXiv preprint arXiv:2411.19378, 2024", "abstract": "Radiology report generation (RRG) is a challenging task, as it requires a thorough understanding of medical images, integration of multiple temporal inputs, and accurate report generation. Effective interpretation of medical images, such as chest \u2026"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2411.03313%3F", "details": "H Zilong, Y Qinghao, K Bingyi, F Jiashi, F Haoqi - arXiv preprint arXiv:2411.03313, 2024", "abstract": "We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised \u2026"}, {"title": "Multimodal Whole Slide Foundation Model for Pathology", "link": "https://arxiv.org/pdf/2411.19666", "details": "T Ding, SJ Wagner, AH Song, RJ Chen, MY Lu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The field of computational pathology has been transformed with recent advances in foundation models that encode histopathology region-of-interests (ROIs) into versatile and transferable feature representations via self-supervised learning (SSL) \u2026"}, {"title": "Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning", "link": "https://arxiv.org/pdf/2411.05193", "details": "J Hong, A Dragan, S Levine - arXiv preprint arXiv:2411.05193, 2024", "abstract": "Value-based reinforcement learning (RL) can in principle learn effective policies for a wide range of multi-turn problems, from games to dialogue to robotic control, including via offline RL from static previously collected datasets. However, despite \u2026"}, {"title": "Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering", "link": "https://aclanthology.org/2024.emnlp-main.110.pdf", "details": "D Hao, Q Wang, L Guo, J Jiang, J Liu - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "While large pre-trained visual-language models have shown promising results on traditional visual question answering benchmarks, it is still challenging for them to answer complex VQA problems which requires diverse world knowledge. Motivated \u2026"}, {"title": "Empowering multi-step reasoning across languages via program-aided language models", "link": "https://aclanthology.org/2024.emnlp-main.678.pdf", "details": "L Ranaldi, G Pucci, B Haddow, A Birch - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "In-context learning methods are popular inference strategies where Large Language Models (LLMs) are elicited to solve a task using provided demonstrations without parameter updates. Among these approaches are the reasoning methods, best \u2026"}, {"title": "Improving Referring Ability for Biomedical Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.375.pdf", "details": "J Jiang, F Cheng, A Aizawa - Findings of the Association for Computational \u2026, 2024", "abstract": "Existing auto-regressive large language models (LLMs) are primarily trained using documents from general domains. In the biomedical domain, continual pre-training is a prevalent method for domain adaptation to inject professional knowledge into \u2026"}]
