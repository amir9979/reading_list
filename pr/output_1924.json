[{"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "link": "https://arxiv.org/pdf/2405.00402", "details": "L Ranaldi, A Freitas - arXiv preprint arXiv:2405.00402, 2024", "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches \u2026"}, {"title": "Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents", "link": "https://arxiv.org/pdf/2405.02732", "details": "S Singhania, S Razniewski, G Weikum - arXiv preprint arXiv:2405.02732, 2024", "abstract": "Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be \u2026"}, {"title": "Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "link": "https://arxiv.org/pdf/2405.10431", "details": "S Furniturewala, S Jandial, A Java, P Banerjee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing debiasing techniques are typically training-based or require access to the model's internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine \u2026"}, {"title": "Infusing internalized knowledge of language models into hybrid prompts for knowledgeable dialogue generation", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124005082", "details": "J Bai, Z Yan, S Zhang, J Yang, H Guo, Z Li - Knowledge-Based Systems, 2024", "abstract": "Existing knowledge-grounded dialogue (KGD) systems access the knowledge from an external knowledge base, then generate the context-coherent response accordingly. However, the knowledge access capability is constrained to the scale of \u2026"}, {"title": "Analyzing Chain-of-thought Prompting in Black-Box Large Language Models via Estimated V-information", "link": "https://aclanthology.org/2024.lrec-main.81.pdf", "details": "Z Wang, C Li, Z Yang, Q Liu, Y Hao, X Chen, D Chu\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Chain-of-Thought (CoT) prompting combined with large language models (LLM) has shown great potential in improving performance on challenging reasoning tasks. While understanding why CoT prompting is effective is crucial for the \u2026"}, {"title": "HFT: Half Fine-Tuning for Large Language Models", "link": "https://arxiv.org/pdf/2404.18466", "details": "T Hui, Z Zhang, S Wang, W Xu, Y Sun, H Wu - arXiv preprint arXiv:2404.18466, 2024", "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of \u2026"}, {"title": "General Purpose Verification for Chain of Thought Prompting", "link": "https://arxiv.org/pdf/2405.00204", "details": "R Vacareanu, A Pratik, E Spiliopoulou, Z Qi, G Paolini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Many of the recent capabilities demonstrated by Large Language Models (LLMs) arise primarily from their ability to exploit contextual information. In this paper, we explore ways to improve reasoning capabilities of LLMs through (1) exploration of \u2026"}, {"title": "NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli", "link": "https://arxiv.org/pdf/2405.02814", "details": "X Wang, C Li, Y Chang, J Wang, Y Wu - arXiv preprint arXiv:2405.02814, 2024", "abstract": "Large Language Models (LLMs) have become integral to a wide spectrum of applications, ranging from traditional computing tasks to advanced artificial intelligence (AI) applications. This widespread adoption has spurred extensive \u2026"}]
