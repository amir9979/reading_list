[{"title": "Language Models Prefer What They Know: Relative Confidence Estimation via Confidence Preferences", "link": "https://arxiv.org/pdf/2502.01126", "details": "V Shrivastava, A Kumar, P Liang - arXiv preprint arXiv:2502.01126, 2025", "abstract": "Language models (LMs) should provide reliable confidence estimates to help users detect mistakes in their outputs and defer to human experts when necessary. Asking a language model to assess its confidence (\" Score your confidence from 0-1.\") is a \u2026"}, {"title": "CE-LoRA: Computation-Efficient LoRA Fine-Tuning for Language Models", "link": "https://arxiv.org/pdf/2502.01378", "details": "G Chen, Y He, Y Hu, K Yuan, B Yuan - arXiv preprint arXiv:2502.01378, 2025", "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across various tasks but demand substantial computational resources even for fine-tuning computation. Although Low-Rank Adaptation (LoRA) significantly alleviates memory \u2026"}, {"title": "Self-supervised analogical learning using language models", "link": "https://arxiv.org/pdf/2502.00996", "details": "B Zhou, S Jain, Y Zhang, Q Ning, S Wang, Y Benajiba\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models have been shown to suffer from reasoning inconsistency issues. That is, they fail more in situations unfamiliar to the training data, even though exact or very similar reasoning paths exist in more common cases that they can \u2026"}, {"title": "EHealth: A Chinese Biomedical Language Model Built via Multi-Level Text Discrimination", "link": "https://ieeexplore.ieee.org/abstract/document/10857372/", "details": "Q Wang, S Dai, B Xu, Y Lyu, H Wu, H Wang - IEEE Transactions on Audio, Speech \u2026, 2025", "abstract": "Pre-trained language models (PLMs) have recently revolutionized the field of natural language processing, impacting not only the general domain but also the biomedical domain. Most previous studies on constructing biomedical PLMs relied simply on \u2026"}, {"title": "Unsupervised Topic Models are Data Mixers for Pre-training Language Models", "link": "https://arxiv.org/pdf/2502.16802", "details": "J Peng, X Zhuang, Q Jiantao, R Ma, J Yu, T Bai, C He - arXiv preprint arXiv \u2026, 2025", "abstract": "The performance of large language models (LLMs) is significantly affected by the quality and composition of their pre-training data, which is inherently diverse, spanning various domains, sources, and topics. Effectively integrating these \u2026"}, {"title": "A Close Look at Decomposition-based XAI-Methods for Transformer Language Models", "link": "https://arxiv.org/pdf/2502.15886", "details": "L Arras, B Puri, P Kahardipraja, S Lapuschkin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Various XAI attribution methods have been recently proposed for the transformer architecture, allowing for insights into the decision-making process of large language models by assigning importance scores to input tokens and intermediate \u2026"}, {"title": "How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks before and after Fine-tuning", "link": "https://arxiv.org/pdf/2501.17501", "details": "F Salerno, A Al-Kaswan, M Izadi - arXiv preprint arXiv:2501.17501, 2025", "abstract": "Code language models, while widely popular, are often trained on unsanitized source code gathered from across the Internet. Previous work revealed that pre- trained models can remember the content of their training data and regurgitate them \u2026"}, {"title": "Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models", "link": "https://arxiv.org/pdf/2501.17420", "details": "Y Li, H Shirado, S Das - arXiv preprint arXiv:2501.17420, 2025", "abstract": "While advances in fairness and alignment have helped mitigate overt biases exhibited by large language models (LLMs) when explicitly prompted, we hypothesize that these models may still exhibit implicit biases when simulating \u2026"}, {"title": "Unraveling the Capabilities of Language Models in News Summarization", "link": "https://arxiv.org/pdf/2501.18128", "details": "A Odaba\u015f\u0131, G Biricik - arXiv preprint arXiv:2501.18128, 2025", "abstract": "Given the recent introduction of multiple language models and the ongoing demand for improved Natural Language Processing tasks, particularly summarization, this work provides a comprehensive benchmarking of 20 recent language models \u2026"}]
