'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Observational Scaling Laws and the Predictability of L'
[{"title": "Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "link": "https://arxiv.org/pdf/2405.10431", "details": "S Furniturewala, S Jandial, A Java, P Banerjee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing debiasing techniques are typically training-based or require access to the model's internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine \u2026"}, {"title": "MarkLLM: An Open-Source Toolkit for LLM Watermarking", "link": "https://arxiv.org/pdf/2405.10051", "details": "L Pan, A Liu, Z He, Z Gao, X Zhao, Y Lu, B Zhou, S Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "LLM watermarking, which embeds imperceptible yet algorithmically detectable signals in model outputs to identify LLM-generated text, has become crucial in mitigating the potential misuse of large language models. However, the abundance \u2026"}, {"title": "A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks", "link": "https://arxiv.org/pdf/2405.10251", "details": "X Ni, P Li - arXiv preprint arXiv:2405.10251, 2024", "abstract": "Recent efforts have evaluated large language models (LLMs) in areas such as commonsense reasoning, mathematical reasoning, and code generation. However, to the best of our knowledge, no work has specifically investigated the performance \u2026"}, {"title": "MHPP: Exploring the Capabilities and Limitations of Language Models Beyond Basic Code Generation", "link": "https://arxiv.org/pdf/2405.11430", "details": "J Dai, J Lu, Y Feng, R Ruan, M Cheng, H Tan, Z Guo - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in large language models (LLMs) have greatly improved code generation, specifically at the function level. For instance, GPT-4 has achieved an 88.4% pass rate on HumanEval. However, this draws into question the adequacy of \u2026"}, {"title": "Using Pre-Trained Language Models in an End-to-End Pipeline for Antithesis Detection", "link": "https://aclanthology.org/2024.lrec-main.1502.pdf", "details": "R K\u00fchn, K Saadi, J Mitrovi\u0107, M Granitzer - Proceedings of the 2024 Joint International \u2026, 2024", "abstract": "Rhetorical figures play an important role in influencing readers and listeners. Some of these word constructs that deviate from the usual language structure are known to be persuasive\u2013antithesis is one of them. This figure combines parallel phrases with \u2026"}, {"title": "Specialising and Analysing Instruction-Tuned and Byte-Level Language Models for Organic Reaction Prediction", "link": "https://arxiv.org/pdf/2405.10625", "details": "J Pang, I Vuli\u0107 - arXiv preprint arXiv:2405.10625, 2024", "abstract": "Transformer-based encoder-decoder models have demonstrated impressive results in chemical reaction prediction tasks. However, these models typically rely on pretraining using tens of millions of unlabelled molecules, which can be time \u2026"}, {"title": "SecureLLM: Using Compositionality to Build Provably Secure Language Models for Private, Sensitive, and Secret Data", "link": "https://arxiv.org/pdf/2405.09805", "details": "A Alabdulakreem, CM Arnold, Y Lee, PM Feenstra\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Traditional security mechanisms isolate resources from users who should not access them. We reflect the compositional nature of such security mechanisms back into the structure of LLMs to build a provably secure LLM; that we term SecureLLM. Other \u2026"}, {"title": "Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization", "link": "https://arxiv.org/pdf/2405.10616", "details": "Y Ji, Y Xiang, J Li, W Chen, Z Liu, K Chen, M Zhang - arXiv preprint arXiv:2405.10616, 2024", "abstract": "In recent years, large language models (LLMs) have driven advances in natural language processing. Still, their growing scale has increased the computational burden, necessitating a balance between efficiency and performance. Low-rank \u2026"}, {"title": "UniRAG: Universal Retrieval Augmentation for Multi-Modal Large Language Models", "link": "https://arxiv.org/pdf/2405.10311", "details": "S Sharifymoghaddam, S Upadhyay, W Chen, J Lin - arXiv preprint arXiv:2405.10311, 2024", "abstract": "Recently, Multi-Modal (MM) Large Language Models (LLMs) have unlocked many complex use-cases that require MM understanding (eg, image captioning or visual question answering) and MM generation (eg, text-guided image generation or \u2026"}]
