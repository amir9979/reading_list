[{"title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models", "link": "https://arxiv.org/pdf/2406.17092", "details": "Y Zeng, W Sun, TN Huynh, D Song, B Li, R Jia - arXiv preprint arXiv:2406.17092, 2024", "abstract": "Safety backdoor attacks in large language models (LLMs) enable the stealthy triggering of unsafe behaviors while evading detection during normal interactions. The high dimensionality of potential triggers in the token space and the diverse \u2026"}, {"title": "Measuring cognitive effort using tabular transformer-based language models of electronic health record-based audit log action sequences", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae171/7713267", "details": "S Kim, BC Warner, D Lew, SS Lou, T Kannampallil - Journal of the American Medical \u2026, 2024", "abstract": "Objectives To develop and validate a novel measure, action entropy, for assessing the cognitive effort associated with electronic health record (EHR)-based work activities. Materials and Methods EHR-based audit logs of attending physicians and \u2026"}, {"title": "Fuzzy Multi-view Graph Learning on Sparse Electronic Health Records", "link": "https://ieeexplore.ieee.org/abstract/document/10572354/", "details": "T Tang, Z Han, S Yu, A Bagirov, Q Zhang - IEEE Transactions on Fuzzy Systems, 2024", "abstract": "Extracting latent disease patterns from electronic health records (EHRs) is a crucial solution for disease analysis, significantly facilitating healthcare decision-making. Multiview learning presents itself as a promising approach that offers a \u2026"}, {"title": "Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination", "link": "https://ieeecai.org/2024/wp-content/pdfs/540900a486/540900a486.pdf", "details": "X Zhong, K Batmanghelich, L Sun", "abstract": "Vision-language models pre-trained on large scale of unlabeled biomedical images and associated reports learn generalizable semantic representations. These multi- modal representations can benefit various downstream tasks in the biomedical \u2026"}, {"title": "Mental Modeling of Reinforcement Learning Agents by Language Models", "link": "https://arxiv.org/pdf/2406.18505", "details": "W Lu, X Zhao, J Spisak, JH Lee, S Wermter - arXiv preprint arXiv:2406.18505, 2024", "abstract": "Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it \u2026"}, {"title": "Efficient Expert Pruning for Sparse Mixture-of-Experts Language Models: Enhancing Performance and Reducing Inference Costs", "link": "https://arxiv.org/pdf/2407.00945", "details": "E Liu, J Zhu, Z Lin, X Ning, MB Blaschko, S Yan, G Dai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large language models (LLMs) has led to architectures with billions to trillions of parameters, posing significant deployment challenges due to their substantial demands on memory, processing power, and energy \u2026"}, {"title": "Pretrained Language Models for Semantics-Aware Data Harmonisation of Observational Clinical Studies in the Era of Big Data", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/07/12/2024.07.12.24310136.full.pdf", "details": "JJ Dylag, Z Zlatev, M Boniface - medRxiv, 2024", "abstract": "In clinical research, there is a strong drive to leverage big data from population cohort studies and routine electronic healthcare records to design new interventions, improve health outcomes and increase efficiency of healthcare delivery. Yet \u2026"}, {"title": "Panacea: A foundation model for clinical trial search, summarization, design, and recruitment", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/06/27/2024.06.26.24309548.full.pdf", "details": "J Lin, H Xu, Z Wang, S Wang, J Sun - medRxiv, 2024", "abstract": "Clinical trials are fundamental in developing new drugs, medical devices, and treatments. However, they are often time-consuming and have low success rates. Although there have been initial attempts to create large language models (LLMs) for \u2026"}, {"title": "Large Language Models in the Clinic: A Comprehensive Benchmark", "link": "https://www.researchgate.net/profile/Fenglin-Liu-2/publication/381732507_Large_Language_Models_in_the_Clinic_A_Comprehensive_Benchmark/links/667c54891dec0c3c6fa5bee9/Large-Language-Models-in-the-Clinic-A-Comprehensive-Benchmark.pdf", "details": "F Liu, H Zhou, Y Hua, O Rohanian, A Thakur, L Clifton\u2026", "abstract": "The adoption of large language models (LLMs) to assist clinicians has attracted remarkable attention. Existing works mainly adopt the closeended question- answering (QA) task with answer options for evaluation. However, many clinical \u2026"}]
