[{"title": "A multimodal multidomain multilingual medical foundation model for zero shot clinical diagnosis", "link": "https://www.nature.com/articles/s41746-024-01339-7", "details": "F Liu, Z Li, Q Yin, J Huang, J Luo, A Thakur, K Branson\u2026 - npj Digital Medicine, 2025", "abstract": "Radiology images are one of the most commonly used in daily clinical diagnosis. Typically, clinical diagnosis using radiology images involves disease reporting and classification, where the former is a multimodal task whereby textual reports are \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "link": "https://arxiv.org/pdf/2502.05142", "details": "Z Yang, X Xu, J Zhang, G Wang, MK Kalra, P Yan - arXiv preprint arXiv:2502.05142, 2025", "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data \u2026"}, {"title": "Multi-Agent Credit Assignment with Pretrained Language Models", "link": "https://openreview.net/forum%3Fid%3D2kIYWdFU0x", "details": "W Li, D Qiao, B Wang, X Wang, H Shen, B Jin, H Zha - The 28th International Conference \u2026", "abstract": "The difficulty of appropriately assigning credit is particularly heightened in cooperative MARL with sparse reward, due to the concurrent time and structural scales involved. Automatic subgoal generation (ASG) has recently emerged as a \u2026"}, {"title": "Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment", "link": "https://arxiv.org/pdf/2502.04328%3F", "details": "Z Liu, Y Dong, J Wang, Z Liu, W Hu, J Lu, Y Rao - arXiv preprint arXiv:2502.04328, 2025", "abstract": "Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have \u2026"}, {"title": "Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective", "link": "https://arxiv.org/pdf/2502.01524%3F", "details": "X Ma, H Xie, SJ Qin - arXiv preprint arXiv:2502.01524, 2025", "abstract": "The integration of vision-language modalities has been a significant focus in multimodal learning, traditionally relying on Vision-Language Pretrained Models. However, with the advent of Large Language Models (LLMs), there has been a \u2026"}, {"title": "Merging Clinical Knowledge into Large Language Models for Medical Research and Applications: A Survey", "link": "https://arxiv.org/pdf/2502.20988", "details": "Q Li, H Liu, C Guo, D Chen, M Wang, F Gao, J Gu - arXiv preprint arXiv:2502.20988, 2025", "abstract": "Clinical knowledge is the collection of information learned from studies on the causes, prognosis, diagnosis, and treatment of diseases. This type of knowledge can improve curing performances, and promote physical health. With the emergence of \u2026"}, {"title": "Supervised contrastive pre-training models for mammography screening", "link": "https://link.springer.com/article/10.1186/s40537-025-01075-z", "details": "Z Cao, Z Deng, Z Yang, J Ma, L Ma - Journal of Big Data, 2025", "abstract": "Breast cancer is now the most deadly cancer worldwide. Mammography screening is the most effective method for early detection and diagnosis of breast cancer. Due to the lack of labeled mammograms, building an AI system for mammography \u2026"}, {"title": "Comprehensive analysis of transparency and accessibility of chatgpt, deepseek, and other sota large language models", "link": "https://arxiv.org/pdf/2502.18505", "details": "R Sapkota, S Raza, M Karkee - arXiv preprint arXiv:2502.18505, 2025", "abstract": "Despite increasing discussions on open-source Artificial Intelligence (AI), existing research lacks a discussion on the transparency and accessibility of state-of-the-art (SoTA) Large Language Models (LLMs). The Open Source Initiative (OSI) has \u2026"}]
