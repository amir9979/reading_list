[{"title": "LG-CAV: Train Any Concept Activation Vector with Language Guidance", "link": "https://arxiv.org/pdf/2410.10308", "details": "Q Huang, J Song, M Xue, H Zhang, B Hu, H Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Concept activation vector (CAV) has attracted broad research interest in explainable AI, by elegantly attributing model predictions to specific concepts. However, the training of CAV often necessitates a large number of high-quality images, which are \u2026"}, {"title": "HyperPg--Prototypical Gaussians on the Hypersphere for Interpretable Deep Learning", "link": "https://arxiv.org/pdf/2410.08925", "details": "MX Li, KF Rudolf, N Blank, R Lioutikov - arXiv preprint arXiv:2410.08925, 2024", "abstract": "Prototype Learning methods provide an interpretable alternative to black-box deep learning models. Approaches such as ProtoPNet learn, which part of a test image\" look like\" known prototypical parts from training images, combining predictive power \u2026"}, {"title": "Exploring Behavior-Relevant and Disentangled Neural Dynamics with Generative Diffusion Models", "link": "https://arxiv.org/pdf/2410.09614", "details": "Y Wang, C Li, W Li, A Wu - arXiv preprint arXiv:2410.09614, 2024", "abstract": "Understanding the neural basis of behavior is a fundamental goal in neuroscience. Current research in large-scale neuro-behavioral data analysis often relies on decoding models, which quantify behavioral information in neural data but lack \u2026"}, {"title": "Multi-view representation for pathological image classification via contrastive learning", "link": "https://link.springer.com/article/10.1007/s13042-024-02391-1", "details": "K Chen, S Sun, J Zhao, F Wang, Q Zhang - International Journal of Machine Learning \u2026, 2024", "abstract": "Pathological images have become indispensable in clinical practice, but their complexity and blurred tissue structures pose challenges for accurate classification. To overcome this, it is crucial to combine the color view and edge view, as the \u2026"}, {"title": "LoRD: Adapting Differentiable Driving Policies to Distribution Shifts", "link": "https://arxiv.org/pdf/2410.09681", "details": "C Diehl, P Karkus, S Veer, M Pavone, T Bertram - arXiv preprint arXiv:2410.09681, 2024", "abstract": "Distribution shifts between operational domains can severely affect the performance of learned models in self-driving vehicles (SDVs). While this is a well-established problem, prior work has mostly explored naive solutions such as fine-tuning, focusing \u2026"}, {"title": "Decorrelation-based Self-Supervised Visual Representation Learning for Writer Identification", "link": "https://arxiv.org/pdf/2410.01441", "details": "A Maitra, S Mitra, S Manna, S Bhattacharya, U Pal - arXiv preprint arXiv:2410.01441, 2024", "abstract": "Self-supervised learning has developed rapidly over the last decade and has been applied in many areas of computer vision. Decorrelation-based self-supervised pretraining has shown great promise among non-contrastive algorithms, yielding \u2026"}, {"title": "From One to Zero: RAG-IM Adapts Language Models for Interpretable Zero-Shot Predictions on Clinical Tabular Data", "link": "https://openreview.net/pdf%3Fid%3DBnKvIn8JKl", "details": "S Mahbub, C Ellington, S Alinejad, K Wen, Y Luo\u2026 - NeurIPS 2024 Third Table \u2026", "abstract": "Clinical machine learning models, often learned from tabular data, must adapt to new settings such as different hospitals, clinicians, or patient populations. These differing environments present related but subtly distinct tasks, where diseases and medical \u2026"}, {"title": "Calibrated Cache Model for Few-Shot Vision-Language Model Adaptation", "link": "https://arxiv.org/pdf/2410.08895", "details": "K Ding, Q Yu, H Zhang, G Meng, S Xiang - arXiv preprint arXiv:2410.08895, 2024", "abstract": "Cache-based approaches stand out as both effective and efficient for adapting vision- language models (VLMs). Nonetheless, the existing cache model overlooks three crucial aspects. 1) Pre-trained VLMs are mainly optimized for image-text similarity \u2026"}, {"title": "EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models", "link": "https://arxiv.org/pdf/2410.09802", "details": "E Lee, S Jeong, K Sohn - arXiv preprint arXiv:2410.09802, 2024", "abstract": "Exemplar-guided image translation, synthesizing photo-realistic images that conform to both structural control and style exemplars, is attracting attention due to its ability to enhance user control over style manipulation. Previous methodologies have \u2026"}]
