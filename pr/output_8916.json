[{"title": "SPE-YOLO: A deep learning model focusing on small pulmonary embolism detection", "link": "https://www.sciencedirect.com/science/article/pii/S0010482524014872", "details": "H Wu, Q Xu, X He, H Xu, Y Wang, L Guo - Computers in Biology and Medicine, 2025", "abstract": "Objectives By developing the deep learning model SPE-YOLO, the detection of small pulmonary embolism has been improved, leading to more accurate identification of this condition. This advancement aims to better serve medical diagnosis and \u2026"}, {"title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models", "link": "https://arxiv.org/pdf/2410.18252", "details": "M Noukhovitch, S Huang, S Xhonneux, A Hosseini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously generating from the large language model (LLM) policy, labelling with a reward model, and learning using feedback on the LLM's own outputs. While performant, this \u2026"}, {"title": "Survival models and longitudinal medical events for hospital readmission forecasting", "link": "https://link.springer.com/article/10.1186/s12913-024-11771-w", "details": "S Davis, R Greiner - BMC Health Services Research, 2024", "abstract": "Background The rate of 30-day all-cause hospital readmissions can affect the funding a hospital receives. An accurate and reliable readmission prediction model could save money and increase quality-of-care. Few projects have explored \u2026"}, {"title": "Multisource representation learning for pediatric knowledge extraction from electronic health records", "link": "https://www.nature.com/articles/s41746-024-01320-4", "details": "M Li, X Li, K Pan, A Geva, D Yang, SM Sweet\u2026 - npj Digital Medicine, 2024", "abstract": "Abstract Electronic Health Record (EHR) systems are particularly valuable in pediatrics due to high barriers in clinical studies, but pediatric EHR data often suffer from low content density. Existing EHR code embeddings tailored for the general \u2026"}, {"title": "Shareable artificial intelligence to extract cancer outcomes from electronic health records for precision oncology research", "link": "https://www.nature.com/articles/s41467-024-54071-x", "details": "KL Kehl, J Jee, K Pichotta, MA Paul, P Trukhanov\u2026 - Nature Communications, 2024", "abstract": "Databases that link molecular data to clinical outcomes can inform precision cancer research into novel prognostic and predictive biomarkers. However, outside of clinical trials, cancer outcomes are typically recorded only in text form within \u2026"}, {"title": "Thinking Fast and Slow", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9251-1_3", "details": "T Marwala - The Balancing Problem in the Governance of Artificial \u2026, 2024", "abstract": "Artificial Intelligence (AI) systems can be classified into two functional modes according to Daniel Kahneman's dual-process theory: fast thinking (System 1) and slow thinking (System 2). AI's ability to think quickly allows it to carry out rapid \u2026"}, {"title": "Evaluation of a task specific self-supervised learning framework in digital pathology relative to transfer learning approaches and existing foundation models", "link": "https://www.modernpathology.org/article/S0893-3952\\(24\\)00216-3/fulltext", "details": "T Rahman, AS Baras, R Chellappa - Modern Pathology, 2024", "abstract": "An integral stage in typical digital pathology workflows involves deriving specific features from tiles extracted from a tessellated whole slide image. Notably, various computer vision neural network architectures, particularly the ImageNet pre-trained \u2026"}, {"title": "Comparing Commercial and Open-Source Large Language Models for Labeling Chest Radiograph Reports", "link": "https://pubs.rsna.org/doi/abs/10.1148/radiol.241139", "details": "FJ Dorfner, L J\u00fcrgensen, L Donle, F Al Mohamad\u2026 - Radiology, 2024", "abstract": "Background Rapid advances in large language models (LLMs) have led to the development of numerous commercial and open-source models. While recent publications have explored OpenAI's GPT-4 to extract information of interest from \u2026"}, {"title": "Prompt Learning for Few-Shot Question Answering via Self-Context Data Augmentation", "link": "https://ieeexplore.ieee.org/abstract/document/10723112/", "details": "JQ Qiu, CY Zhang, CLP Chen - IEEE Transactions on Artificial Intelligence, 2024", "abstract": "Pre-trained language models (PLMs) have shown remarkable performance on question answering (QA) tasks, but they usually require fine-tuning that depends on a substantial quantity of QA pairs. Therefore, improving the performance of PLMs in \u2026"}]
