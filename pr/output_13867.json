[{"title": "Enhancing Multi-hop Reasoning in Vision-Language Models via Self-Distillation with Multi-Prompt Ensembling", "link": "https://arxiv.org/pdf/2503.01754%3F", "details": "G Wu, H Song, Y Wang, Q Yan, Y Tian, LL Cheong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multi-modal large language models have seen rapid advancement alongside large language models. However, while language models can effectively leverage chain- of-thought prompting for zero or few-shot learning, similar prompting strategies are \u2026"}, {"title": "Zero-shot Medical Event Prediction Using a Generative Pre-trained Transformer on Electronic Health Records", "link": "https://arxiv.org/pdf/2503.05893", "details": "E Redekop, Z Wang, R Kulkarni, M Pleasure, A Chin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Longitudinal data in electronic health records (EHRs) represent an individuals clinical history through a sequence of codified concepts, including diagnoses, procedures, medications, and laboratory tests. Foundational models, such as \u2026"}, {"title": "Alignment for Efficient Tool Calling of Large Language Models", "link": "https://arxiv.org/pdf/2503.06708", "details": "H Xu, Z Wang, Z Zhu, L Pan, X Chen, L Chen, K Yu - arXiv preprint arXiv:2503.06708, 2025", "abstract": "Recent advancements in tool learning have enabled large language models (LLMs) to integrate external tools, enhancing their task performance by expanding their knowledge boundaries. However, relying on tools often introduces tradeoffs between \u2026"}]
