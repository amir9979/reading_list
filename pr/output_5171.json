[{"title": "The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study", "link": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500\\(24\\)00097-9/fulltext", "details": "DM Levine, R Tuwani, B Kompa, A Varma\u2026 - The Lancet Digital Health, 2024", "abstract": "Background Artificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general \u2026"}, {"title": "Steering Language Models with Game-Theoretic Solvers", "link": "https://openreview.net/pdf%3Fid%3D5QLtIodDmu", "details": "I Gemp, R Patel, Y Bachrach, M Lanctot, V Dasagi\u2026 - Agentic Markets Workshop at ICML \u2026", "abstract": "Mathematical models of strategic interactions among rational agents have long been studied in game theory. However the interactions studied are often over a small set of discrete actions which is very different from how humans communicate in natural \u2026"}, {"title": "Cognitive Assessment of Language Models", "link": "https://openreview.net/pdf%3Fid%3DpxRh1meUvN", "details": "D McDuff, D Munday, X Liu, I Galatzer-Levy - ICML 2024 Workshop on LLMs and Cognition", "abstract": "Large language models (LLMs) are a subclass of generative artificial intelligence that can interpret language inputs to generate novel responses. These capabilities are conceptualized as a significant step forward in artificial intelligence because the \u2026"}, {"title": "Evaluating Large Language Models with fmeval", "link": "https://arxiv.org/pdf/2407.12872", "details": "P Schw\u00f6bel, L Franceschi, MB Zafar, K Vasist\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "fmeval is an open source library to evaluate large language models (LLMs) in a range of tasks. It helps practitioners evaluate their model for task performance and along multiple responsible AI dimensions. This paper presents the library and \u2026"}, {"title": "DECIDER: Leveraging Foundation Model Priors for Improved Model Failure Detection and Explanation", "link": "https://arxiv.org/pdf/2408.00331", "details": "R Subramanyam, K Thopalli, V Narayanaswamy\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reliably detecting when a deployed machine learning model is likely to fail on a given input is crucial for ensuring safe operation. In this work, we propose DECIDER (Debiasing Classifiers to Identify Errors Reliably), a novel approach that leverages \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}, {"title": "SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models", "link": "https://arxiv.org/pdf/2408.00655", "details": "H An, Y Chen, X Qiao, Z Sun, X Li - arXiv preprint arXiv:2408.00655, 2024", "abstract": "Contemporary large language models (LLMs) predominantly utilize a next-token prediction method for inference, which significantly impedes their processing speed. In this paper, we introduce a novel inference methodology termed next-sentence \u2026"}, {"title": "A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks", "link": "https://arxiv.org/pdf/2407.12994%3Ftrk%3Dpublic_post_comment-text", "details": "S Vatsal, H Dubey - arXiv preprint arXiv:2407.12994, 2024", "abstract": "Large language models (LLMs) have shown remarkable performance on many different Natural Language Processing (NLP) tasks. Prompt engineering plays a key role in adding more to the already existing abilities of LLMs to achieve significant \u2026"}]
