[{"title": "Insect-Foundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding", "link": "https://arxiv.org/pdf/2502.09906", "details": "TD Truong, HQ Nguyen, XB Nguyen, A Dowling, X Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multimodal conversational generative AI has shown impressive capabilities in various vision and language understanding through learning massive text-image data. However, current conversational models still lack knowledge about visual \u2026"}, {"title": "Interpretable Few-Shot Retinal Disease Diagnosis with Concept-Guided Prompting of Vision-Language Models", "link": "https://arxiv.org/pdf/2503.02917", "details": "D Mehta, Y Jiang, CL Jan, M He, K Jadhav, Z Ge - arXiv preprint arXiv:2503.02917, 2025", "abstract": "Recent advancements in deep learning have shown significant potential for classifying retinal diseases using color fundus images. However, existing works predominantly rely exclusively on image data, lack interpretability in their diagnostic \u2026"}, {"title": "GAMMIL: A graph attention-guided multi-scale fusion multiple instance learning model for the WHO grading of meningioma in whole slide images", "link": "https://www.sciencedirect.com/science/article/pii/S1746809425001636", "details": "G Tu, W Li, Y Lin, Z Xu, J He, B Fu, P Huang, R Wang\u2026 - \u2026 Signal Processing and \u2026, 2025", "abstract": "Background and objective The WHO grading of meningioma is closely linked to patient treatment and prognosis, making the development of an accurate deep learning model based on whole slide images (WSI) of significant clinical importance \u2026"}, {"title": "DCFormer: Efficient 3D Vision-Language Modeling with Decomposed Convolutions", "link": "https://arxiv.org/pdf/2502.05091%3F", "details": "GC Ates, K Gong, W Shao - arXiv preprint arXiv:2502.05091, 2025", "abstract": "Vision-language models (VLMs) align visual and textual representations, enabling high-performance zero-shot classification and image-text retrieval in 2D medical imaging. However, extending VLMs to 3D medical imaging remains computationally \u2026"}, {"title": "Reexamine the link between retinal layer thickness and cognitive function after correction of axial length: the Beijing Eye Study 2011", "link": "https://link.springer.com/article/10.1007/s00417-025-06777-x", "details": "Z Pan, Z Li, H Xie, Y Huang, CC Xue, X Wu, TY Wong\u2026 - Graefe's Archive for Clinical \u2026, 2025", "abstract": "Purpose To investigate the relationship between retinal layer thickness and cognitive function in elderly Chinese, accounting for the influence of axial length. Methods The participants of the Beijing Eye Study 2011 which is a population-based cross \u2026"}, {"title": "MammoVLM: A generative large vision-language model for mammography-related diagnostic assistance", "link": "https://www.sciencedirect.com/science/article/pii/S1566253525000715", "details": "Z Cao, Z Deng, J Ma, J Hu, L Ma - Information Fusion, 2025", "abstract": "Inspired by the recent success of large language models (LLMs) in the general domain, many large multimodal models, such as vision-language models, have been developed to tackle problems across modalities. In the realm of breast cancer, which \u2026"}, {"title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models", "link": "https://arxiv.org/pdf/2502.10250%3F", "details": "GK Kumar, I Chaabane, K Wu - arXiv preprint arXiv:2502.10250, 2025", "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved \u2026"}, {"title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models", "link": "https://arxiv.org/pdf/2502.06663", "details": "X Xing, Z Liu, S Xiao, B Gao, Y Liang, W Zhang, H Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge \u2026"}, {"title": "Language Models Can Predict Their Own Behavior", "link": "https://arxiv.org/pdf/2502.13329", "details": "D Ashok, J May - arXiv preprint arXiv:2502.13329, 2025", "abstract": "Autoregressive Language Models output text by sequentially predicting the next token to generate, with modern methods like Chain-of-Thought (CoT) prompting achieving state-of-the-art reasoning capabilities by scaling the number of generated \u2026"}]
