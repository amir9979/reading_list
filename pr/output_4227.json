[{"title": "The Oscars of AI Theater: A Survey on Role-Playing with Language Models", "link": "https://arxiv.org/pdf/2407.11484", "details": "N Chen, Y Wang, Y Deng, J Li - arXiv preprint arXiv:2407.11484, 2024", "abstract": "This survey explores the burgeoning field of role-playing with language models, focusing on their development from early persona-based models to advanced character-driven simulations facilitated by Large Language Models (LLMs). Initially \u2026"}, {"title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization", "link": "https://arxiv.org/pdf/2407.07880", "details": "J Wu, Y Xie, Z Yang, J Wu, J Chen, J Gao, B Ding\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences. We categorize noise into pointwise noise, which includes low \u2026"}, {"title": "MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2407.11681", "details": "H Cheng, M Zhang, JQ Shi - arXiv preprint arXiv:2407.11681, 2024", "abstract": "As Large Language Models (LLMs) grow dramatically in size, there is an increasing trend in compressing and speeding up these models. Previous studies have highlighted the usefulness of gradients for importance scoring in neural network \u2026"}, {"title": "PAG-LLM: Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors", "link": "https://dl.acm.org/doi/pdf/10.1145/3626772.3657959", "details": "V Yadav, Z Tang, V Srinivasan - Proceedings of the 47th International ACM SIGIR \u2026, 2024", "abstract": "Large language models (LLM) have achieved remarkable success in natural language generation but lesser focus has been given to their applicability in key tasks such as intent-classification. We show that LLMs like LLaMa can achieve high \u2026"}, {"title": "Cross-Lingual Multi-Hop Knowledge Editing--Benchmarks, Analysis and a Simple Contrastive Learning based Approach", "link": "https://arxiv.org/pdf/2407.10275", "details": "A Khandelwal, H Singh, H Gu, T Chen, K Zhou - arXiv preprint arXiv:2407.10275, 2024", "abstract": "Large language models are often expected to constantly adapt to new sources of knowledge and knowledge editing techniques aim to efficiently patch the outdated model knowledge, with minimal modification. Most prior works focus on monolingual \u2026"}, {"title": "Self-Improving Teacher Cultivates Better Student: Distillation Calibration for Multimodal Large Language Models", "link": "https://dl.acm.org/doi/abs/10.1145/3626772.3657692", "details": "X Li, L Lin, S Wang, C Qian - Proceedings of the 47th International ACM SIGIR \u2026, 2024", "abstract": "Multimodal content generation, which leverages visual information to enhance the comprehension of cross-modal understanding, plays a critical role in Multimodal Information Retrieval. With the development of large language models (LLMs), recent \u2026"}, {"title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models", "link": "https://arxiv.org/pdf/2407.07086", "details": "L Cross, V Xiang, A Bhatia, DLK Yamins, N Haber - arXiv preprint arXiv:2407.07086, 2024", "abstract": "Multi-agent reinforcement learning (MARL) methods struggle with the non- stationarity of multi-agent systems and fail to adaptively learn online when tested with novel agents. Here, we leverage large language models (LLMs) to create an \u2026"}, {"title": "Large Language Models as Reliable Knowledge Bases?", "link": "https://arxiv.org/pdf/2407.13578", "details": "D Zheng, M Lapata, JZ Pan - arXiv preprint arXiv:2407.13578, 2024", "abstract": "The NLP community has recently shown a growing interest in leveraging Large Language Models (LLMs) for knowledge-intensive tasks, viewing LLMs as potential knowledge bases (KBs). However, the reliability and extent to which LLMs can \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}]
