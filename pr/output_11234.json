[{"title": "B-AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Black-box Adversarial Visual-Instructions", "link": "https://ieeexplore.ieee.org/abstract/document/10816024/", "details": "H Zhang, W Shao, H Liu, Y Ma, P Luo, Y Qiao, N Zheng\u2026 - IEEE Transactions on \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have shown significant progress in responding well to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent \u2026"}, {"title": "Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual Language Models from Southeast Asia", "link": "https://arxiv.org/pdf/2412.07303", "details": "LCL Gamboa, M Lee - arXiv preprint arXiv:2412.07303, 2024", "abstract": "Bias studies on multilingual models confirm the presence of gender-related stereotypes in masked models processing languages with high NLP resources. We expand on this line of research by introducing Filipino CrowS-Pairs and Filipino \u2026"}, {"title": "DnDScore: Decontextualization and Decomposition for Factuality Verification in Long-Form Text Generation", "link": "https://arxiv.org/pdf/2412.13175", "details": "M Wanner, B Van Durme, M Dredze - arXiv preprint arXiv:2412.13175, 2024", "abstract": "The decompose-then-verify strategy for verification of Large Language Model (LLM) generations decomposes claims that are then independently verified. Decontextualization augments text (claims) to ensure it can be verified outside of the \u2026"}, {"title": "ConceptEdit: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning", "link": "https://arxiv.org/pdf/2412.11418", "details": "L Zhang, W Wang, T Fang, Y Song - arXiv preprint arXiv:2412.11418, 2024", "abstract": "Knowledge Editing (KE) aims to adjust a Large Language Model's (LLM) internal representations and parameters to correct inaccuracies and improve output consistency without incurring the computational expense of re-training the entire \u2026"}, {"title": "Towards Compatible Fine-tuning for Vision-Language Model Updates", "link": "https://arxiv.org/pdf/2412.20895", "details": "Z Wang, J Liang, L Sheng, R He, Z Wang, T Tan - arXiv preprint arXiv:2412.20895, 2024", "abstract": "So far, efficient fine-tuning has become a popular strategy for enhancing the capabilities of foundation models on downstream tasks by learning plug-and-play modules. However, existing methods overlook a crucial issue: if the underlying \u2026"}, {"title": "ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models", "link": "https://arxiv.org/pdf/2412.12848", "details": "Y Sun, W Gao, J Ma, H Lin, Z Luo, W Zhang - arXiv preprint arXiv:2412.12848, 2024", "abstract": "With the rise and widespread use of Large Language Models (LLMs), ensuring their safety is crucial to prevent harm to humans and promote ethical behaviors. However, directly assessing value valence (ie, support or oppose) by leveraging large-scale \u2026"}, {"title": "GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2412.21036", "details": "S Xing, C Xiang, Y Han, Y Yue, Z Wu, X Liu, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal large language models (MLLMs) have achieved significant advancements in integrating visual and linguistic understanding. While existing benchmarks evaluate these models in context-rich, real-life scenarios, they often \u2026"}]
