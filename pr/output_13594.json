[{"title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models", "link": "https://arxiv.org/pdf/2502.06663", "details": "X Xing, Z Liu, S Xiao, B Gao, Y Liang, W Zhang, H Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge \u2026"}, {"title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "link": "https://arxiv.org/pdf/2503.01743", "details": "A Abouelenin, A Ashfaq, A Atkinson, H Awadalla\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality web and synthetic data, significantly outperforming recent \u2026"}, {"title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models", "link": "https://arxiv.org/pdf/2503.01464", "details": "B Nazarov, D Frolova, Y Lubarsky, A Gaissinski\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed on domain-specific data has shown significant promise. However, commercial use of such LLMs is limited by the high computational cost required for their deployment at \u2026"}, {"title": "Compromising Honesty and Harmlessness in Language Models via Deception Attacks", "link": "https://arxiv.org/pdf/2502.08301", "details": "L\u00c3\u013b Vaugrante, F Carlon, M Menke, T Hagendorff - arXiv preprint arXiv:2502.08301, 2025", "abstract": "Recent research on large language models (LLMs) has demonstrated their ability to understand and employ deceptive behavior, even without explicit prompting. However, such behavior has only been observed in rare, specialized cases and has \u2026"}, {"title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities", "link": "https://arxiv.org/pdf/2502.12025%3F", "details": "F Jiang, Z Xu, Y Li, L Niu, Z Xiang, B Li, BY Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage long chain-of-thought (CoT) reasoning to generate structured intermediate steps, enhancing their reasoning capabilities. However, long CoT does not inherently \u2026"}, {"title": "Bridging vision language model (VLM) evaluation gaps with a framework for scalable and cost-effective benchmark generation", "link": "https://arxiv.org/pdf/2502.15563", "details": "T R\u00e4dsch, L Mayer, S Pavicic, AE Kavur, M Knopp\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reliable evaluation of AI models is critical for scientific progress and practical application. While existing VLM benchmarks provide general insights into model capabilities, their heterogeneous designs and limited focus on a few imaging \u2026"}, {"title": "Explainable Multi-modal Time Series Prediction with LLM-in-the-Loop", "link": "https://arxiv.org/pdf/2503.01013", "details": "Y Jiang, W Yu, G Lee, D Song, K Shin, W Cheng, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Time series analysis provides essential insights for real-world system dynamics and informs downstream decision-making, yet most existing methods often overlook the rich contextual signals present in auxiliary modalities. To bridge this gap, we \u2026"}, {"title": "Physician clinical decision modification and bias assessment in a randomized controlled trial of AI assistance", "link": "https://www.nature.com/articles/s43856-025-00781-2", "details": "E Goh, B Bunning, EC Khoong, RJ Gallo, A Milstein\u2026 - Communications Medicine, 2025", "abstract": "Background Artificial intelligence assistance in clinical decision making shows promise, but concerns exist about potential exacerbation of demographic biases in healthcare. This study aims to evaluate how physician clinical decisions and biases \u2026"}, {"title": "AnnoCaseLaw: A Richly-Annotated Dataset For Benchmarking Explainable Legal Judgment Prediction", "link": "https://arxiv.org/pdf/2503.00128", "details": "M Sesodia, A Petrova, J Armour, T Lukasiewicz\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Legal systems worldwide continue to struggle with overwhelming caseloads, limited judicial resources, and growing complexities in legal proceedings. Artificial intelligence (AI) offers a promising solution, with Legal Judgment Prediction (LJP) \u2026"}]
