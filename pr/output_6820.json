[{"title": "RAG-Modulo: Solving Sequential Tasks using Experience, Critics, and Language Models", "link": "https://arxiv.org/pdf/2409.12294", "details": "A Jain, C Jermaine, V Unhelkar - arXiv preprint arXiv:2409.12294, 2024", "abstract": "Large language models (LLMs) have recently emerged as promising tools for solving challenging robotic tasks, even in the presence of action and observation uncertainties. Recent LLM-based decision-making methods (also referred to as LLM \u2026"}, {"title": "Exploring and Enhancing the Transfer of Distribution in Knowledge Distillation for Autoregressive Language Models", "link": "https://arxiv.org/pdf/2409.12512", "details": "J Rao, X Liu, Z Lin, L Ding, J Li, D Tao - arXiv preprint arXiv:2409.12512, 2024", "abstract": "Knowledge distillation (KD) is a technique that compresses large teacher models by training smaller student models to mimic them. The success of KD in auto-regressive language models mainly relies on Reverse KL for mode-seeking and student \u2026"}, {"title": "Improving the Efficiency of Visually Augmented Language Models", "link": "https://arxiv.org/pdf/2409.11148", "details": "P Ontalvilla, A Ormazabal, G Azkune - arXiv preprint arXiv:2409.11148, 2024", "abstract": "Despite the impressive performance of autoregressive Language Models (LM) it has been shown that due to reporting bias, LMs lack visual knowledge, ie they do not know much about the visual world and its properties. To augment LMs with visual \u2026"}, {"title": "RAD-Bench: Evaluating Large Language Models Capabilities in Retrieval Augmented Dialogues", "link": "https://arxiv.org/pdf/2409.12558", "details": "TL Kuo, FT Liao, MW Hsieh, FC Chang, PC Hsu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In real-world applications with Large Language Models (LLMs), external retrieval mechanisms-such as Search-Augmented Generation (SAG), tool utilization, and Retrieval-Augmented Generation (RAG)-are often employed to enhance the quality \u2026"}, {"title": "Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data", "link": "https://arxiv.org/pdf/2409.12437", "details": "J Zhou, A Ghaddar, G Zhang, L Ma, Y Hu, S Pal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite recent advances in training and prompting strategies for Large Language Models (LLMs), these models continue to face challenges with complex logical reasoning tasks that involve long reasoning chains. In this work, we explore the \u2026"}, {"title": "Towards a Unified View of Preference Learning for Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2409.02795", "details": "B Gao, F Song, Y Miao, Z Cai, Z Yang, L Chen, H Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to \u2026"}, {"title": "A Comprehensive Evaluation of Quantized Instruction-Tuned Large Language Models: An Experimental Analysis up to 405B", "link": "https://arxiv.org/pdf/2409.11055", "details": "J Lee, S Park, J Kwon, J Oh, Y Kwon - arXiv preprint arXiv:2409.11055, 2024", "abstract": "Prior research works have evaluated quantized LLMs using limited metrics such as perplexity or a few basic knowledge tasks and old datasets. Additionally, recent large- scale models such as Llama 3.1 with up to 405B have not been thoroughly \u2026"}, {"title": "Cross-prompt Pre-finetuning of Language Models for Short Answer Scoring", "link": "https://www.researchsquare.com/article/rs-4929687/latest.pdf", "details": "H Funayama, Y Matsubayashi, Y Asazuma, T Mizumoto\u2026 - 2024", "abstract": "Abstract Automated Short Answer Scoring (SAS) is the task of automatically scoring a given input to a prompt based on rubrics and reference answers. Although SAS is useful in real-world applications, both rubrics and reference answers differ between \u2026"}, {"title": "Booster: Tackling Harmful Fine-tuing for Large Language Models via Attenuating Harmful Perturbation", "link": "https://arxiv.org/pdf/2409.01586", "details": "T Huang, S Hu, F Ilhan, SF Tekin, L Liu - arXiv preprint arXiv:2409.01586, 2024", "abstract": "Harmful fine-tuning issue\\citep {qi2023fine} poses serious safety concerns for Large language models' fine-tuning-as-a-service. While existing defenses\\citep {huang2024vaccine, rosati2024representation} have been proposed to mitigate the \u2026"}]
