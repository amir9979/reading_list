[{"title": "Prompt injection attacks on vision language models in oncology", "link": "https://www.nature.com/articles/s41467-024-55631-x", "details": "J Clusmann, D Ferber, IC Wiest, CV Schneider\u2026 - Nature Communications, 2025", "abstract": "Vision-language artificial intelligence models (VLMs) possess medical knowledge and can be employed in healthcare in numerous ways, including as image interpreters, virtual scribes, and general decision support systems. However, here \u2026"}, {"title": "Efficiency and safety of automated label cleaning on multimodal retinal images", "link": "https://www.nature.com/articles/s41746-024-01424-x", "details": "T Lin, M Wang, A Lin, X Mai, H Liang, YC Tham\u2026 - npj Digital Medicine, 2025", "abstract": "Label noise is a common and important issue that would affect the model's performance in artificial intelligence. This study assessed the effectiveness and potential risks of automated label cleaning using an open-source framework \u2026"}, {"title": "Systemic Predictors of Diabetic Retinopathy and Diabetic Macular Edema in an Adult Veteran Population", "link": "https://www.tandfonline.com/doi/pdf/10.2147/OPTH.S487047", "details": "EM Tran, NZ Gregori, A Rachitskaya, A Nandan\u2026 - Clinical Ophthalmology, 2025", "abstract": "Purpose To investigate the influence of systemic and serum measures and hypoglycemic medications on the initial presentation and ongoing development of diabetic retinopathy (DR) and diabetic macular edema (DME). Design Using \u2026"}, {"title": "Histo-Genomic Knowledge Association For Cancer Prognosis From Histopathology Whole Slide Images", "link": "https://ieeexplore.ieee.org/abstract/document/10830530/", "details": "Z Wang, Y Zhang, Y Xu, S Imoto, H Chen, J Song - IEEE Transactions on Medical \u2026, 2025", "abstract": "Histo-genomic multi-modal methods have emerged as a powerful paradigm, demonstrating significant potential for cancer prognosis. However, genome sequencing, unlike histopathology imaging, is still not widely accessible in \u2026"}, {"title": "Characterization of Macular Fundus Autofluorescence Changes in Patients with Retinitis Pigmentosa", "link": "https://karger.com/ore/article-pdf/doi/10.1159/000543082/4329969/000543082.pdf", "details": "MJ Khan, Z Rustam, FB Aamir, MC Miranda, I Shaikh\u2026 - Ophthalmic Research, 2025", "abstract": "Introduction: To characterize fundus autofluorescence (AF) changes that occur in the macula of patients with retinitis pigmentosa (RP). Methods: We conducted a case series on ninety-nine patients with RP. Features seen on fundus AF images were \u2026"}, {"title": "Texture analysis of optical coherence tomography retinal images: Its potential use for the early diagnosis of diabetic retinopathy", "link": "https://onlinelibrary.wiley.com/doi/abs/10.1111/aos.17352", "details": "AF Ambr\u00f3sio, S Oliveira, P Guimar\u00e3es, EJ Campos\u2026 - Acta Ophthalmologica, 2025", "abstract": "Aims/Purpose: Diabetic retinopathy (DR) is usually diagnosed many years after diabetes onset. The early diagnosis of DR remains challenging, and identifying novel biomarkers is crucial. We aim to identify novel early biomarkers for DR, based on \u2026"}, {"title": "DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests", "link": "https://arxiv.org/pdf/2501.04671", "details": "C Corbi\u00e8re, S Roburin, S Montariol, A Bosselut, A Alahi - arXiv preprint arXiv \u2026, 2025", "abstract": "Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning. However, due to the modality gap between textual and visual data, they often face significant challenges, such as over \u2026"}, {"title": "Efficient Architectures for High Resolution Vision-Language Models", "link": "https://arxiv.org/pdf/2501.02584", "details": "M Carvalho, B Martins - arXiv preprint arXiv:2501.02584, 2025", "abstract": "Vision-Language Models (VLMs) have recently experienced significant advancements. However, challenges persist in the accurate recognition of fine details within high resolution images, which limits performance in multiple tasks. This \u2026"}, {"title": "Efficient GPT-4V Level Multimodal Large Language Model for Deployment on Edge Devices", "link": "https://www.researchsquare.com/article/rs-5830327/latest.pdf", "details": "Y Yao, T Yu, A Zhang, C Wang, J Cui, H Zhu, T Cai\u2026 - 2025", "abstract": "The recent surge of Multimodal Large Language Models (MLLMs) has fundamentally reshaped the landscape of AI research and industry, shedding light on a promising path toward the next AI milestone. However, significant challenges remain \u2026"}]
