[{"title": "Concise and Precise Context Compression for Tool-Using Language Models", "link": "https://arxiv.org/pdf/2407.02043", "details": "Y Xu, Y Feng, H Mu, Y Hou, Y Li, X Wang, W Zhong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Through reading the documentation in the context, tool-using language models can dynamically extend their capability using external tools. The cost is that we have to input lengthy documentation every time the model needs to use the tool, occupying \u2026"}, {"title": "Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models", "link": "https://arxiv.org/pdf/2407.07263", "details": "J Parmar, S Satheesh, M Patwary, M Shoeybi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As language models have scaled both their number of parameters and pretraining dataset sizes, the computational cost for pretraining has become intractable except for the most well-resourced teams. This increasing cost makes it ever more important \u2026"}, {"title": "Aligning Language Models with the Human World", "link": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi%3Farticle%3D1241%26context%3Ddissertations", "details": "R LIU - 2024", "abstract": "Abstract The field of Natural Language Processing (NLP) has undergone a significant transformation with the emergence of large language models (LMs). These models have enabled the development of human-like conversational \u2026"}, {"title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization", "link": "https://arxiv.org/pdf/2407.07880", "details": "J Wu, Y Xie, Z Yang, J Wu, J Chen, J Gao, B Ding\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences. We categorize noise into pointwise noise, which includes low \u2026"}, {"title": "Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts", "link": "https://arxiv.org/pdf/2406.12034", "details": "J Kang, L Karlinsky, H Luo, Z Wang, J Hansen, J Glass\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present Self-MoE, an approach that transforms a monolithic LLM into a compositional, modular system of self-specialized experts, named MiXSE (MiXture of Self-specialized Experts). Our approach leverages self-specialization, which \u2026"}, {"title": "LMCK: pre-trained language models enhanced with contextual knowledge for Vietnamese natural language inference", "link": "https://link.springer.com/article/10.1007/s11042-024-19671-1", "details": "NLT Nguyen, KTK Phan, TV Huynh, KV Nguyen - Multimedia Tools and Applications, 2024", "abstract": "Abstract Natural Language Inference (NLI) has gathered significant attention in recent years due to its application. However, to apply to other downstream tasks, the NLI task should be extended its boundaries by adopting prominent approaches such \u2026"}, {"title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models", "link": "https://arxiv.org/pdf/2407.02408", "details": "S Wang, P Wang, T Zhou, Y Dong, Z Tan, J Li - arXiv preprint arXiv:2407.02408, 2024", "abstract": "As Large Language Models (LLMs) are increasingly deployed to handle various natural language processing (NLP) tasks, concerns regarding the potential negative societal impacts of LLM-generated content have also arisen. To evaluate the biases \u2026"}, {"title": "PAG-LLM: Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors", "link": "https://dl.acm.org/doi/pdf/10.1145/3626772.3657959", "details": "V Yadav, Z Tang, V Srinivasan - Proceedings of the 47th International ACM SIGIR \u2026, 2024", "abstract": "Large language models (LLM) have achieved remarkable success in natural language generation but lesser focus has been given to their applicability in key tasks such as intent-classification. We show that LLMs like LLaMa can achieve high \u2026"}, {"title": "Banishing LLM Hallucinations Requires Rethinking Generalization", "link": "https://arxiv.org/pdf/2406.17642", "details": "J Li, S Consul, E Zhou, J Wong, N Farooqui, Y Ye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their powerful chat, coding, and reasoning abilities, Large Language Models (LLMs) frequently hallucinate. Conventional wisdom suggests that hallucinations are a consequence of a balance between creativity and factuality, which can be \u2026"}]
