[{"title": "\" See the World, Discover Knowledge\": A Chinese Factuality Evaluation for Large Vision Language Models", "link": "https://arxiv.org/pdf/2502.11718", "details": "J Gu, Y Wang, P Bu, C Wang, Z Wang, T Song, D Wei\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The evaluation of factual accuracy in large vision language models (LVLMs) has lagged behind their rapid development, making it challenging to fully reflect these models' knowledge capacity and reliability. In this paper, we introduce the first \u2026"}, {"title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models", "link": "https://arxiv.org/pdf/2502.10250%3F", "details": "GK Kumar, I Chaabane, K Wu - arXiv preprint arXiv:2502.10250, 2025", "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved \u2026"}, {"title": "Investigating the Robustness of Deductive Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2502.04352", "details": "F Hoppe, F Ilievski, JC Kalo - arXiv preprint arXiv:2502.04352, 2025", "abstract": "Large Language Models (LLMs) have been shown to achieve impressive results for many reasoning-based Natural Language Processing (NLP) tasks, suggesting a degree of deductive reasoning capability. However, it remains unclear to which \u2026"}, {"title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models", "link": "https://arxiv.org/pdf/2502.09956", "details": "B Mo, K Yu, J Kazdan, P Mpala, L Yu, C Cundy\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent interest in building foundation models for KGs has highlighted a fundamental challenge: knowledge-graph data is relatively scarce. The best-known KGs are primarily human-labeled, created by pattern-matching, or extracted using early NLP \u2026"}, {"title": "Explaining Context Length Scaling and Bounds for Language Models", "link": "https://arxiv.org/pdf/2502.01481", "details": "J Shi, Q Ma, H Liu, H Zhao, JN Hwang, S Belongie, L Li - arXiv preprint arXiv \u2026, 2025", "abstract": "Long Context Language Models have drawn great attention in the past few years. There has been work discussing the impact of long context on Language Model performance: some find that long irrelevant context could harm performance, while \u2026"}, {"title": "Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG", "link": "https://arxiv.org/pdf/2502.08356", "details": "K Bhushan, Y Nandwani, D Khandelwal, S Gupta\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a prominent method for incorporating domain knowledge into Large Language Models (LLMs). While RAG enhances response relevance by incorporating retrieved domain knowledge in the \u2026"}, {"title": "Hierarchical Prompting Taxonomy: A Universal Evaluation Framework for Large Language Models Aligned with Human Cognitive Principles", "link": "https://www.researchgate.net/profile/Devichand-Budagam/publication/381517001_Hierarchical_Prompting_Taxonomy_A_Universal_Evaluation_Framework_for_Large_Language_Models_Aligned_with_Human_Cognitive_Principles/links/67b88a29207c0c20fa9109be/Hierarchical-Prompting-Taxonomy-A-Universal-Evaluation-Framework-for-Large-Language-Models-Aligned-with-Human-Cognitive-Principles.pdf", "details": "D Budagam, A Kumar, M Khoshnoodi, S KJ, V Jain\u2026 - 2025", "abstract": "Assessing the effectiveness of large language models (LLMs) in performing different tasks is crucial for understanding their strengths and weaknesses. This paper presents Hierarchical Prompting Taxonomy (HPT), grounded on human cognitive \u2026"}, {"title": "Can Large Language Models Be Query Optimizer for Relational Databases?", "link": "https://arxiv.org/pdf/2502.05562", "details": "J Tan, K Zhao, R Li, JX Yu, C Piao, H Cheng, H Meng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Query optimization, which finds the optimized execution plan for a given query, is a complex planning and decision-making problem within the exponentially growing plan space in database management systems (DBMS). Traditional optimizers heavily \u2026"}, {"title": "SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence", "link": "https://arxiv.org/pdf/2502.08767", "details": "Z Liu, RA Amjad, R Adkathimar, T Wei, H Tong - arXiv preprint arXiv:2502.08767, 2025", "abstract": "Providing Language Models (LMs) with relevant evidence in the context (either via retrieval or user-provided) can significantly improve their ability to provide factually correct grounded responses. However, recent studies have found that LMs often \u2026"}]
