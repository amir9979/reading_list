[{"title": "RelCon: Relative Contrastive Learning for a Motion Foundation Model for Wearable Data", "link": "https://arxiv.org/pdf/2411.18822", "details": "MA Xu, J Narain, G Darnell, H Hallgrimsson, H Jeong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present RelCon, a novel self-supervised\\textit {Rel} ative\\textit {Con} trastive learning approach that uses a learnable distance measure in combination with a softened contrastive loss for training an motion foundation model from wearable \u2026"}, {"title": "Federated fine-tuning of large language models under heterogeneous tasks and client resources", "link": "https://openreview.net/pdf%3Fid%3DgkOzoHBXUw", "details": "J Bai, D Chen, B Qian, L Yao, Y Li - The Thirty-eighth Annual Conference on Neural \u2026, 2024", "abstract": "Federated Learning (FL) has recently been applied to the parameter-efficient fine- tuning of Large Language Models (LLMs). While promising, it raises significant challenges due to the heterogeneous resources and data distributions of clients. This \u2026"}, {"title": "PPLqa: An Unsupervised Information-Theoretic Quality Metric for Comparing Generative Large Language Models", "link": "https://arxiv.org/pdf/2411.15320", "details": "G Friedland, X Huang, Y Cui, V Kapoor, A Khetan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We propose PPLqa, an easy to compute, language independent, information- theoretic metric to measure the quality of responses of generative Large Language Models (LLMs) in an unsupervised way, without requiring ground truth annotations or \u2026"}, {"title": "Scalable Out-of-distribution Robustness in the Presence of Unobserved Confounders", "link": "https://arxiv.org/pdf/2411.19923", "details": "P Prashant, SB Khatami, B Ribeiro, B Salimi - arXiv preprint arXiv:2411.19923, 2024", "abstract": "We consider the task of out-of-distribution (OOD) generalization, where the distribution shift is due to an unobserved confounder ($ Z $) affecting both the covariates ($ X $) and the labels ($ Y $). In this setting, traditional assumptions of \u2026"}]
