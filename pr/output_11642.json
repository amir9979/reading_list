[{"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "link": "https://arxiv.org/pdf/2501.04322", "details": "M Rang, Z Bi, C Liu, Y Tang, K Han, Y Wang - arXiv preprint arXiv:2501.04322, 2025", "abstract": "Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are \u2026"}, {"title": "DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests", "link": "https://arxiv.org/pdf/2501.04671", "details": "C Corbi\u00e8re, S Roburin, S Montariol, A Bosselut, A Alahi - arXiv preprint arXiv \u2026, 2025", "abstract": "Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning. However, due to the modality gap between textual and visual data, they often face significant challenges, such as over \u2026"}, {"title": "Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models", "link": "https://arxiv.org/pdf/2412.18609%3F", "details": "J Yi, ST Wasim, Y Luo, M Naseer, J Gall - arXiv preprint arXiv:2412.18609, 2024", "abstract": "We present an efficient encoder-free approach for video-language understanding that achieves competitive performance while significantly reducing computational overhead. Current video-language models typically rely on heavyweight image \u2026"}, {"title": "LungDiag: Empowering artificial intelligence for respiratory diseases diagnosis based on electronic health records, a multicenter study", "link": "https://onlinelibrary.wiley.com/doi/full/10.1002/mco2.70043", "details": "H Liang, T Yang, Z Liu, W Jian, Y Chen, B Li, Z Yan\u2026 - MedComm, 2025", "abstract": "Respiratory diseases pose a significant global health burden, with challenges in early and accurate diagnosis due to overlapping clinical symptoms, which often leads to misdiagnosis or delayed treatment. To address this issue, we developed \u2026"}, {"title": "Knowledge Enhanced Language Model for Biomedical Natural Language Processing: Introducing a New Language Model for BioNLP", "link": "https://ieeexplore.ieee.org/abstract/document/10836827/", "details": "U Naseem, Q Zhang, L Hu, S Hussain, S Wang - IEEE Systems, Man, and \u2026, 2025", "abstract": "Following the success of pre-trained language models (PLMs), the biomedical research community has presented various domain-specific PLMs trained on a large biomedical and clinical corpus for biomedical natural language processing (BioNLP) \u2026"}, {"title": "MBQ: Modality-Balanced Quantization for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.19509", "details": "S Li, Y Hu, X Ning, X Liu, K Hong, X Jia, X Li, Y Yan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Models (VLMs) have enabled a variety of real-world applications. The large parameter size of VLMs brings large memory and computation overhead which poses significant challenges for deployment. Post-Training Quantization (PTQ) \u2026"}, {"title": "PLPP: Prompt Learning with Perplexity Is Self-Distillation for Vision-Language Models", "link": "https://arxiv.org/pdf/2412.15277", "details": "B Liu, W Fang, X Wu, Y Zheng, Z Hu, B Yuan - arXiv preprint arXiv:2412.15277, 2024", "abstract": "Pre-trained Vision-Language (VL) models such as CLIP have demonstrated their excellent performance across numerous downstream tasks. A recent method, Context Optimization (CoOp), further improves the performance of VL models on \u2026"}, {"title": "Privacy-ensuring open-weights large language models are competitive with closed-weights GPT-4o in extracting chest radiography findings from free-text reports", "link": "https://pubs.rsna.org/doi/pdf/10.1148/radiol.240895", "details": "S Nowak, B Wulff, YC Layer, M Theis, A Isaak, B Salam\u2026 - Radiology, 2025", "abstract": "Background Large-scale secondary use of clinical databases requires automated tools for retrospective extraction of structured content from free-text radiology reports. Purpose To share data and insights on the application of privacy-preserving open \u2026"}, {"title": "YuLan-Mini: An Open Data-efficient Language Model", "link": "https://arxiv.org/pdf/2412.17743", "details": "Y Hu, H Song, J Deng, J Wang, J Chen, K Zhou, Y Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Effective pre-training of large language models (LLMs) has been challenging due to the immense resource demands and the complexity of the technical processes involved. This paper presents a detailed technical report on YuLan-Mini, a highly \u2026"}]
