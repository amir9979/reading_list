[{"title": "RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical Diagnostic Reports", "link": "https://arxiv.org/pdf/2405.14137", "details": "J Du, J Guo, W Zhang, S Yang, H Liu, H Li, N Wang - arXiv preprint arXiv:2405.14137, 2024", "abstract": "The Vision-Language Foundation model is increasingly investigated in the fields of computer vision and natural language processing, yet its exploration in ophthalmology and broader medical applications remains limited. The challenge is \u2026"}, {"title": "Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding", "link": "https://arxiv.org/pdf/2405.19567", "details": "S Sun, GM Goldgof, A Schubert, Z Sun, T Hartvigsen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-Language Models (VLM) can support clinicians by analyzing medical images and engaging in natural language interactions to assist in diagnostic and treatment tasks. However, VLMs often exhibit\" hallucinogenic\" behavior, generating textual \u2026"}, {"title": "A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis", "link": "https://arxiv.org/pdf/2405.14839", "details": "Y Yang, M Gandhi, Y Wang, Y Wu, MS Yao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While deep networks have achieved broad success in analyzing natural images, when applied to medical scans, they often fail in unexcepted situations. We investigate this challenge and focus on model sensitivity to domain shifts, such as \u2026"}, {"title": "Pseudo-Prompt Generating in Pre-trained Vision-Language Models for Multi-Label Medical Image Classification", "link": "https://arxiv.org/pdf/2405.06468", "details": "Y Ye, J Zhang, H Shi - arXiv preprint arXiv:2405.06468, 2024", "abstract": "The task of medical image recognition is notably complicated by the presence of varied and multiple pathological indications, presenting a unique challenge in multi- label classification with unseen labels. This complexity underlines the need for \u2026"}]
