[{"title": "Interpretable Biomedical Reasoning via Deep Fusion of Knowledge Graph and Pre-trained Language Models", "link": "https://search.proquest.com/openview/2974f00898e8421191bcce2b279deef7/1%3Fpq-origsite%3Dgscholar%26cbl%3D2048897", "details": "X Yinxin, Y Zongbao, L Yuchen, H Jinlong, D Shoubin - Beijing Da Xue Xue Bao, 2024", "abstract": "Joint inference based on pre-trained language model (LM) and knowledge graph (KG) has not achieved better results in the biomedical domain due to its diverse terminology representation, semantic ambiguity and the presence of large amount of \u2026"}, {"title": "Probing Fundamental Visual Comprehend Capabilities on Vision Language Models via Visual Phrases from Structural Data", "link": "https://link.springer.com/article/10.1007/s12559-024-10351-8", "details": "P Xie, B Liu - Cognitive Computation, 2024", "abstract": "Does the model demonstrate exceptional proficiency in \u201citem counting,\u201d\u201ccolor recognition,\u201d or other Fundamental Visual Comprehension Capability (FVCC)? There have been remarkable advancements in the field of multimodal, the pretrained \u2026"}, {"title": "Few-shot Adaptation of Medical Vision-Language Models", "link": "https://arxiv.org/pdf/2409.03868", "details": "F Shakeri, Y Huang, J Silva-Rodr\u00edguez, H Bahig\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Integrating image and text data through multi-modal learning has emerged as a new approach in medical imaging research, following its successful deployment in computer vision. While considerable efforts have been dedicated to establishing \u2026"}, {"title": "Do Pre-trained Vision-Language Models Encode Object States?", "link": "https://arxiv.org/pdf/2409.10488", "details": "K Newman, S Wang, Y Zang, D Heffren, C Sun - arXiv preprint arXiv:2409.10488, 2024", "abstract": "For a vision-language model (VLM) to understand the physical world, such as cause and effect, a first step is to capture the temporal dynamics of the visual world, for example how the physical states of objects evolve over time (eg a whole apple into a \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "Aligning vision language models with contrastive learning", "link": "https://www.amazon.science/publications/aligning-vision-language-models-with-contrastive-learning", "details": "KE Ak, J Mohta, D Dimitriadis, S Manchanda, Y Xu\u2026 - 2024", "abstract": "In recent years, Vision Language Models (VLMs) have achieved significant advancements due to the success of large language models. The common strategy for aligning vision and language models involves a two-step process: an alignment \u2026"}, {"title": "CoDi: Conversational Distillation for Grounded Question Answering", "link": "https://arxiv.org/pdf/2408.11219", "details": "P Huber, A Einolghozati, R Conway, K Narang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Distilling conversational skills into Small Language Models (SLMs) with approximately 1 billion parameters presents significant challenges. Firstly, SLMs have limited capacity in their model parameters to learn extensive knowledge \u2026"}, {"title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection", "link": "https://arxiv.org/pdf/2409.06072", "details": "J Chakraborty, W Xia, A Majumder, D Ma, W Chaabene\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks. However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further \u2026"}, {"title": "Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation", "link": "https://arxiv.org/pdf/2408.13586", "details": "Y Zhou, M Keuper, M Fritz - arXiv preprint arXiv:2408.13586, 2024", "abstract": "Sampling-based decoding strategies have been widely adopted for Large Language Models (LLMs) in numerous applications, which target a balance between diversity and quality via temperature tuning and tail truncation (eg, top-k and top-p sampling) \u2026"}]
