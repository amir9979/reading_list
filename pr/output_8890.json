[{"title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.17637", "details": "Z Liu, Y Zang, X Dong, P Zhang, Y Cao, H Duan, C He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing \u2026"}, {"title": "Can Language Models Learn to Skip Steps?", "link": "https://arxiv.org/pdf/2411.01855%3F", "details": "T Liu, Q Guo, X Hu, C Jiayang, Y Zhang, X Qiu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Trained on vast corpora of human language, language models demonstrate emergent human-like reasoning abilities. Yet they are still far from true intelligence, which opens up intriguing opportunities to explore the parallels of humans and \u2026"}, {"title": "Stratified Prediction-Powered Inference for Effective Hybrid Evaluation of Language Models", "link": "https://openreview.net/pdf%3Fid%3D8CBcdDQFDQ", "details": "A Fisch, J Maynez, RA Hofer, B Dhingra, A Globerson\u2026 - The Thirty-eighth Annual \u2026", "abstract": "Prediction-powered inference (PPI) is a method that improves statistical estimates based on limited human-labeled data. PPI achieves this by combining small amounts of human-labeled data with larger amounts of data labeled by a reasonably accurate \u2026"}, {"title": "Few-shot In-Context Preference Learning Using Large Language Models", "link": "https://arxiv.org/pdf/2410.17233%3F", "details": "C Yu, H Lu, J Gao, Q Tan, X Yang, Y Wang, Y Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Designing reward functions is a core component of reinforcement learning but can be challenging for truly complex behavior. Reinforcement Learning from Human Feedback (RLHF) has been used to alleviate this challenge by replacing a hand \u2026"}, {"title": "Large language models enabled multiagent ensemble method for efficient EHR data labeling", "link": "https://arxiv.org/pdf/2410.16543", "details": "J Huang, K Nezafati, I Villanueva-Miranda, Z Gu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This study introduces a novel multiagent ensemble method powered by LLMs to address a key challenge in ML-data labeling, particularly in large-scale EHR datasets. Manual labeling of such datasets requires domain expertise and is labor \u2026"}, {"title": "Dual Risk Minimization: Towards Next-Level Robustness in Fine-tuning Zero-Shot Models", "link": "https://openreview.net/pdf%3Fid%3Dp50Dyqk0GX", "details": "K Li, W Xie, Y Huang, D Deng, H Lanqing, Z Li, R Silva\u2026 - The Thirty-eighth Annual \u2026, 2024", "abstract": "Fine-tuning foundation models often compromises their robustness to distribution shifts. To remedy this, most robust fine-tuning methods aim to preserve the pre- trained features. However, not all pre-trained features are robust and those methods \u2026"}, {"title": "Retrieval In Decoder benefits generative models for explainable complex question answering", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024007573", "details": "J Feng, Q Wang, H Qiu, L Liu - Neural Networks, 2024", "abstract": "Abstract Large-scale Language Models (LLMs) utilizing the Chain-of-Thought prompting demonstrate exceptional performance in a variety of tasks. However, the persistence of factual hallucinations remains a significant challenge in practical \u2026"}, {"title": "Model Reconstruction Using Counterfactual Explanations: A Perspective From Polytope Theory", "link": "https://openreview.net/pdf%3Fid%3D9uolDxbYLm", "details": "P Dissanayake, S Dutta - The Thirty-eighth Annual Conference on Neural \u2026, 2024", "abstract": "Counterfactual explanations provide ways of achieving a favorable model outcome with minimum input perturbation. However, counterfactual explanations can also be leveraged to reconstruct the model by strategically training a surrogate model to give \u2026"}, {"title": "Learning Counterfactual Explanations with Intervals for Time-series Classification", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679952", "details": "A Yamaguchi, K Ueno, R Shingaki, H Kashima - Proceedings of the 33rd ACM \u2026, 2024", "abstract": "The need for explainability in time-series classification models has been increasing. Counterfactual explanations recommend how to modify the features of an original instance so that the prediction by a given classifier flips to the desired class. Since \u2026"}]
