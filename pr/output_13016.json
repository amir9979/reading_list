[{"title": "Reasoning Language Models: A Blueprint", "link": "https://arxiv.org/pdf/2501.11223%3F", "details": "M Besta, J Barth, E Schreiber, A Kubicek, A Catarino\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning language models (RLMs), also known as Large Reasoning Models (LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have redefined AI's problem-solving capabilities by extending large language models \u2026"}, {"title": "Language models encode the value of numbers linearly", "link": "https://aclanthology.org/2025.coling-main.47.pdf", "details": "F Zhu, D Dai, Z Sui - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have exhibited impressive competence in various tasks, but their internal mechanisms on mathematical problems are still under- explored. In this paper, we study a fundamental question: how language models \u2026"}, {"title": "When Evolution Strategy Meets Language Models Tuning", "link": "https://aclanthology.org/2025.coling-main.357.pdf", "details": "B Huang, Y Jiang, M Chen, Y Wang, H Chen, W Wang - Proceedings of the 31st \u2026, 2025", "abstract": "Supervised Fine-tuning has been pivotal in training autoregressive language models, yet it introduces exposure bias. To mitigate this, Post Fine-tuning, including on-policy and off-policy methods, has emerged as a solution to enhance models \u2026"}, {"title": "Embedding-Driven Diversity Sampling to Improve Few-Shot Synthetic Data Generation", "link": "https://arxiv.org/pdf/2501.11199", "details": "I Lopez, FN Haredasht, K Caoili, JH Chen, A Chaudhari - arXiv preprint arXiv \u2026, 2025", "abstract": "Accurate classification of clinical text often requires fine-tuning pre-trained language models, a process that is costly and time-consuming due to the need for high-quality data and expert annotators. Synthetic data generation offers an alternative, though \u2026"}, {"title": "A Training Data Recipe to Accelerate A* Search with Large Language Models", "link": "http://www.boyangli.org/paper/Gupta-EMNLP-2024.pdf", "details": "D Gupta, B Li", "abstract": "Abstract Combining Large Language Models (LLMs) with heuristic search algorithms like A* holds the promise of enhanced LLM reasoning and scalable inference. To accelerate training and reduce computational demands, we investigate the coreset \u2026"}, {"title": "META-LORA: Memory-Efficient Sample Reweighting for Fine-Tuning Large Language Models", "link": "https://aclanthology.org/2025.coling-main.568.pdf", "details": "W Li, L Zou, M Tang, Q Yu, W Li, C Li - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "Supervised fine-tuning (SFT) is widely adopted for tailoring large language models (LLMs) to specific downstream tasks. However, the substantial computational demands of LLMs hinder iterative exploration of fine-tuning datasets and accurate \u2026"}, {"title": "Topology-of-Question-Decomposition: Enhancing Large Language Models with Information Retrieval for Knowledge-Intensive Tasks", "link": "https://aclanthology.org/2025.coling-main.191.pdf", "details": "W Li, J Wang, LC Yu, X Zhang - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) are increasingly deployed for general problem- solving across various domains yet remain constrained to chaining immediate reasoning steps and depending solely on parametric knowledge. Integrating an \u2026"}, {"title": "Error Classification of Large Language Models on Math Word Problems: A Dynamically Adaptive Framework", "link": "https://arxiv.org/pdf/2501.15581", "details": "Y Sun, Z Yin, X Huang, X Qiu, H Zhao - arXiv preprint arXiv:2501.15581, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains. Math Word Problems (MWPs) serve as a crucial benchmark for evaluating LLMs' reasoning abilities. While most research primarily focuses on \u2026"}, {"title": "LLM-based Affective Text Generation Quality Based on Different Quantization Values", "link": "https://arxiv.org/pdf/2501.19317%3F", "details": "YM Resendiz, R Klinger - arXiv preprint arXiv:2501.19317, 2025", "abstract": "Large language models exhibit a remarkable capacity in language generation and comprehension. These advances enable AI systems to produce more human-like and emotionally engaging text. However, these models rely on a large number of \u2026"}]
