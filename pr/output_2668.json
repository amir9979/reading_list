[{"title": "The BiGGen Bench: A Principled Benchmark for Fine-grained Evaluation of Language Models with Language Models", "link": "https://arxiv.org/pdf/2406.05761", "details": "S Kim, J Suk, JY Cho, S Longpre, C Kim, D Yoon\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As language models (LMs) become capable of handling a wide range of tasks, their evaluation is becoming as challenging as their development. Most generation benchmarks currently assess LMs using abstract evaluation criteria like helpfulness \u2026"}, {"title": "Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2405.18729", "details": "T Zhang, J Guan, L Zhao, Y Li, D Li, Z Zeng, L Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Offline reinforcement learning (RL) aims to learn optimal policies from previously collected datasets. Recently, due to their powerful representational capabilities, diffusion models have shown significant potential as policy models for offline RL \u2026"}, {"title": "DiNADO: Norm-Disentangled Neurally-Decomposed Oracles for Controlling Language Models", "link": "https://openreview.net/forum%3Fid%3Dpvg1OdUtDQ", "details": "S Lu, W Zhao, C Tao, A Gupta, S Wu, T Chung, N Peng - Forty-first International Conference \u2026", "abstract": "NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable generation with large language models. It is designed to avoid catastrophic forgetting while achieving guaranteed convergence to an entropy-maximized closed-form \u2026"}, {"title": "Regularized joint self-training: A cross-domain generalization method for image classification", "link": "https://www.sciencedirect.com/science/article/pii/S0952197624008650", "details": "C Chen, Y Yang, M Liu, Z Rong, S Shu - Engineering Applications of Artificial \u2026, 2024", "abstract": "Unsupervised domain adaptive (UDA) is a widely used approach in machine learning strategies that helps move information from a source domain with rich supervised data to a target domain with limited supervised data. In recent years, self \u2026"}, {"title": "Few-Shot Learning for Medical Image Segmentation Using 3D U-Net and Model-Agnostic Meta-Learning (MAML)", "link": "https://www.mdpi.com/2075-4418/14/12/1213", "details": "AM Alsaleh, E Albalawi, A Algosaibi, SS Albakheet\u2026 - Diagnostics, 2024", "abstract": "Deep learning has attained state-of-the-art results in general image segmentation problems; however, it requires a substantial number of annotated images to achieve the desired outcomes. In the medical field, the availability of annotated images is \u2026"}, {"title": "Causal Action Influence Aware Counterfactual Data Augmentation", "link": "https://arxiv.org/pdf/2405.18917", "details": "NA Urp\u00ed, M Bagatella, M Vlastelica, G Martius - arXiv preprint arXiv:2405.18917, 2024", "abstract": "Offline data are both valuable and practical resources for teaching robots complex behaviors. Ideally, learning agents should not be constrained by the scarcity of available demonstrations, but rather generalize beyond the training distribution \u2026"}, {"title": "Differentially Private No-regret Exploration in Adversarial Markov Decision Processes", "link": "https://openreview.net/pdf%3Fid%3DfoNKGt20YE", "details": "S Bai, L Zeng, C Zhao, X Duan, MS Talebi, P Cheng\u2026 - The 40th Conference on \u2026", "abstract": "We study learning adversarial Markov decision process (MDP) in the episodic setting under the constraint of differential privacy (DP). This is motivated by the widespread applications of reinforcement learning (RL) in non-stationary and even adversarial \u2026"}, {"title": "On Minimizing Adversarial Counterfactual Error in Adversarial Reinforcement Learning", "link": "https://www.researchgate.net/profile/Roman-Belaire-2/publication/381231593_On_Minimizing_Adversarial_Counterfactual_Error_in_Adversarial_Reinforcement_Learning/links/6662c340a54c5f0b9451d457/On-Minimizing-Adversarial-Counterfactual-Error-in-Adversarial-Reinforcement-Learning.pdf", "details": "R Belaire, A Sinha, P Varakantham", "abstract": "Abstract Deep Reinforcement Learning (DRL) policies are critically vulnerable to adversarial noise in observations, posing severe risks in safety-critical scenarios. For example, a self-driving car receiving manipulated sensory inputs about traffic signs \u2026"}, {"title": "Exploring Adversarial Robustness of Deep State Space Models", "link": "https://arxiv.org/pdf/2406.05532", "details": "B Qi, Y Luo, J Gao, P Li, K Tian, Z Ma, B Zhou - arXiv preprint arXiv:2406.05532, 2024", "abstract": "Deep State Space Models (SSMs) have proven effective in numerous task scenarios but face significant security challenges due to Adversarial Perturbations (APs) in real- world deployments. Adversarial Training (AT) is a mainstream approach to \u2026"}]
