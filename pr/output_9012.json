[{"title": "Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models", "link": "https://aclanthology.org/2024.emnlp-main.566.pdf", "details": "XH Feng, C Chen, Y Li, Z Lin - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Pre-trained language models acquire knowledge from vast amounts of text data, which can inadvertently contain sensitive information. To mitigate the presence of undesirable knowledge, the task of knowledge unlearning becomes crucial for \u2026"}, {"title": "ConvBench: A Multi-Turn Conversation Evaluation Benchmark with Hierarchical Ablation Capability for Large Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3DPyTf2jj0SH", "details": "S Liu, K Ying, H Zhang, Y Yang, Y Lin, T Zhang, C Li\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Multi-turn visual conversation is an important ability of real-world AI assistants. However, the related evaluation benchmark is missed. This paper presents ConvBench, a multi-turn conversation benchmark with hierarchical capabilities \u2026"}, {"title": "Visual cot: Advancing multi-modal language models with a comprehensive dataset and benchmark for chain-of-thought reasoning", "link": "https://openreview.net/pdf%3Fid%3DaXeiCbMFFJ", "details": "H Shao, S Qian, H Xiao, G Song, Z Zong, L Wang, Y Liu\u2026 - The Thirty-eight Conference \u2026, 2024", "abstract": "Multi-Modal Large Language Models (MLLMs) have demonstrated impressive performance in various VQA tasks. However, they often lack interpretability and struggle with complex visual inputs, especially when the resolution of the input image \u2026"}, {"title": "BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions", "link": "https://arxiv.org/pdf/2411.07461", "details": "A Awadalla, L Xue, M Shu, A Yan, J Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce BLIP3-KALE, a dataset of 218 million image-text pairs that bridges the gap between descriptive synthetic captions and factual web-scale alt-text. KALE augments synthetic dense image captions with web-scale alt-text to generate \u2026"}, {"title": "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models", "link": "https://aclanthology.org/2024.emnlp-main.128.pdf", "details": "Y Wan, W Wang, Y Yang, Y Yuan, J Huang, P He\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "We introduce LogicAsker, a novel approach for evaluating and enhancing the logical reasoning capabilities of large language models (LLMs) such as ChatGPT and GPT- 4\\. Despite LLMs' prowess in tasks like writing assistance, code generation, and \u2026"}, {"title": "Skills-in-Context: Unlocking Compositionality in Large Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.812.pdf", "details": "J Chen, X Pan, D Yu, K Song, X Wang, D Yu, J Chen - Findings of the Association for \u2026, 2024", "abstract": "We investigate how to elicit compositional generalization capabilities in large language models (LLMs). Compositional generalization empowers LLMs to solve complex problems by combining foundational skills, a critical reasoning ability akin to \u2026"}, {"title": "A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models", "link": "https://aclanthology.org/2024.emnlp-main.210.pdf", "details": "J Wang, F Mo, W Ma, P Sun, M Zhang, JY Nie - \u2026 of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Large language models (LLMs) are essential tools that users employ across various scenarios, so evaluating their performance and guiding users in selecting the suitable service is important. Although many benchmarks exist, they mainly focus on \u2026"}, {"title": "Guided Profile Generation Improves Personalization with Large Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.231.pdf", "details": "J Zhang - Findings of the Association for Computational \u2026, 2024", "abstract": "In modern commercial systems, including Recommendation, Ranking, and E- Commerce platforms, there is a trend towards improving customer experiences by incorporating Personalization context as input into Large Language Models (LLM) \u2026"}, {"title": "PhoneLM: an Efficient and Capable Small Language Model Family through Principled Pre-training", "link": "https://arxiv.org/pdf/2411.05046", "details": "R Yi, X Li, W Xie, Z Lu, C Wang, A Zhou, S Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The interest in developing small language models (SLM) for on-device deployment is fast growing. However, the existing SLM design hardly considers the device hardware characteristics. Instead, this work presents a simple yet effective principle \u2026"}]
