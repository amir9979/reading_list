[{"title": "Margin-aware optimized contrastive learning for enhanced self-supervised histopathological image classification", "link": "https://link.springer.com/article/10.1007/s13755-024-00316-4", "details": "E Gupta, V Gupta - Health Information Science and Systems, 2025", "abstract": "Histopathological images, characterized by their high resolution and intricate cellular structures, present unique challenges for automated analysis. Traditional supervised learning-based methods often rely on extensive labeled datasets, which are labour \u2026"}, {"title": "Generalized Deep Learning for Histopathology Image Classification Using Supervised Contrastive Learning", "link": "https://www.sciencedirect.com/science/article/pii/S2090123224005320", "details": "MM Rahaman, EKA Millar, E Meijering - Journal of Advanced Research, 2024", "abstract": "Introduction: Cancer is a leading cause of death worldwide, necessitating effective diagnostic tools for early detection and treatment. Histopathological image analysis is crucial for cancer diagnosis but is often hindered by human error and variability \u2026"}, {"title": "Improving Discriminative Capability of Reward Models in RLHF Using Contrastive Learning", "link": "https://aclanthology.org/2024.emnlp-main.852.pdf", "details": "L Chen, R Zheng, B Wang, S Jin, C Huang, J Ye\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Reinforcement Learning from Human Feedback (RLHF) is a crucial approach to aligning language models with human values and intentions. A fundamental challenge in this method lies in ensuring that the reward model \u2026"}, {"title": "Micro-Bench: A Microscopy Benchmark for Vision-Language Understanding", "link": "https://openreview.net/pdf%3Fid%3DeRleg6vy0Y", "details": "A Lozano, JJ Nirschl, J Burgess, SR Gupte, Y Zhang\u2026 - The Thirty-eight Conference on \u2026", "abstract": "Recent advances in microscopy have enabled the rapid generation of terabytes of image data in cell biology and biomedical research. Vision-language models (VLMs) offer a promising solution for large-scale biological image analysis, enhancing \u2026"}, {"title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "link": "https://arxiv.org/pdf/2411.08733%3F", "details": "S Singla, Z Wang, T Liu, A Ashfaq, Z Hu, EP Xing - arXiv preprint arXiv:2411.08733, 2024", "abstract": "Aligning Large Language Models (LLMs) traditionally relies on costly training and human preference annotations. Self-alignment seeks to reduce these expenses by enabling models to align themselves. To further lower costs and achieve alignment \u2026"}, {"title": "Gradient Localization Improves Lifelong Pretraining of Language Models", "link": "https://arxiv.org/pdf/2411.04448", "details": "J Fernandez, Y Bisk, E Strubell - arXiv preprint arXiv:2411.04448, 2024", "abstract": "Large Language Models (LLMs) trained on web-scale text corpora have been shown to capture world knowledge in their parameters. However, the mechanism by which language models store different types of knowledge is poorly understood. In this \u2026"}, {"title": "Uni-Mlip: Unified Self-supervision for Medical Vision Language Pre-training", "link": "https://arxiv.org/pdf/2411.15207", "details": "A Bawazir, K Wu, W Li - arXiv preprint arXiv:2411.15207, 2024", "abstract": "Recent advancements in vision-language pre-training via contrastive learning have significantly improved performance across computer vision tasks. However, in the medical domain, obtaining multimodal data is often costly and challenging due to \u2026"}, {"title": "Automated Radiology Report Generation from Chest X-ray Scans Using Deep Learning", "link": "https://link.springer.com/chapter/10.1007/978-981-97-7862-1_38", "details": "VD Veer, SB Priya, M Tamilselvi - \u2026 International Conference on Recent Innovations in \u2026, 2024", "abstract": "A chest X-ray is a common diagnostic tool for many thoracic illnesses. Interpreting these images and coming up with accurate diagnostic results is a difficult and time- consuming task for radiologists. Recent results using deep learning approaches to \u2026"}, {"title": "BendVLM: Test-Time Debiasing of Vision-Language Embeddings", "link": "https://arxiv.org/pdf/2411.04420", "details": "W Gerych, H Zhang, K Hamidieh, E Pan, M Sharma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language model (VLM) embeddings have been shown to encode biases present in their training data, such as societal biases that prescribe negative characteristics to members of various racial and gender identities. VLMs are being \u2026"}]
