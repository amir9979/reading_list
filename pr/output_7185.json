[{"title": "Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2409.17539", "details": "T Liu, W Xu, W Huang, X Wang, J Wang, H Yang, J Li - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks but their performance in complex logical reasoning tasks remains unsatisfactory. Although some prompting methods, such as Chain-of-Thought, can \u2026"}, {"title": "Target-Aware Language Modeling via Granular Data Sampling", "link": "https://arxiv.org/pdf/2409.14705", "details": "E Chang, PJ Lin, Y Li, C Zhao, D Kim, R Rabatin, Z Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model pretraining generally targets a broad range of use cases and incorporates data from diverse sources. However, there are instances where we desire a model that excels in specific areas without markedly compromising \u2026"}, {"title": "Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models", "link": "https://arxiv.org/pdf/2409.05486", "details": "C Thorne, C Druckenbrodt, K Szarkowska, D Goyal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The quality and capabilities of large language models cannot be currently fully assessed with automated, benchmark evaluations. Instead, human evaluations that expand on traditional qualitative techniques from natural language generation \u2026"}]
