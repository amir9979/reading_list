[{"title": "InDeed: Interpretable image deep decomposition with guaranteed generalizability", "link": "https://arxiv.org/pdf/2501.01127", "details": "S Wang, S Gao, F Wu, X Zhuang - arXiv preprint arXiv:2501.01127, 2025", "abstract": "Image decomposition aims to analyze an image into elementary components, which is essential for numerous downstream tasks and also by nature provides certain interpretability to the analysis. Deep learning can be powerful for such tasks, but \u2026"}, {"title": "The Gaps between Fine Tuning and In-context Learning in Bias Evaluation and Debiasing", "link": "https://aclanthology.org/2025.coling-main.187.pdf", "details": "M Kaneko, D Bollegala, T Baldwin - Proceedings of the 31st International Conference \u2026, 2025", "abstract": "The output tendencies of PLMs vary markedly before and after FT due to the updates to the model parameters. These divergences in output tendencies result in a gap in the social biases of PLMs. For example, there exits a low correlation between \u2026"}, {"title": "Temporal Adaptive Attention Map Guidance for Text-to-Image Diffusion Models", "link": "https://www.mdpi.com/2079-9292/14/3/412", "details": "S Jung, YS Heo - Electronics, 2025", "abstract": "Text-to-image generation aims to create visually compelling images aligned with input prompts, but challenges such as subject mixing and subject neglect, often caused by semantic leakage during the generation process, remain, particularly in \u2026"}, {"title": "T2I-CompBench++: An Enhanced and Comprehensive Benchmark for Compositional Text-to-Image Generation", "link": "https://ieeexplore.ieee.org/iel8/34/4359286/10847875.pdf", "details": "K Huang, C Duan, K Sun, E Xie, Z Li, X Liu - IEEE Transactions on Pattern Analysis \u2026, 2025", "abstract": "Despite the impressive advances in text-to-image models, they often struggle to effectively compose complex scenes with multiple objects, displaying various attributes and relationships. To address this challenge, we present T2I \u2026"}]
