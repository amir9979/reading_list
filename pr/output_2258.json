[{"title": "XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples", "link": "https://arxiv.org/pdf/2405.05116", "details": "P Lin, AFT Martins, H Sch\u00fctze - arXiv preprint arXiv:2405.05116, 2024", "abstract": "Recent studies have shown that leveraging off-the-shelf or fine-tuned retrievers, capable of retrieving high-quality in-context examples, significantly improves in- context learning of English. However, adapting these methods to other languages \u2026"}, {"title": "Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots", "link": "https://arxiv.org/pdf/2405.07990", "details": "C Wu, Y Ge, Q Guo, J Wang, Z Liang, Z Lu, Y Shan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The remarkable progress of Multi-modal Large Language Models (MLLMs) has attracted significant attention due to their superior performance in visual contexts. However, their capabilities in turning visual figure to executable code, have not been \u2026"}]
