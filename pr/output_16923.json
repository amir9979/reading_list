[{"title": "SLearnLLM: A Self-Learning Framework for Efficient Domain-Specific Adaptation of Large Language Models", "link": "https://arxiv.org/pdf/2505.17470", "details": "X Liu, Z Liu, P Wang, K Wang, H Hu, K Wang, S Lian - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 By leveraging the strong logical reasoning and deep contextual understanding of **large** **language** **models** (LLMs), we design a Chain of Thought (CoT) prompt to facilitate a self-check process. As illustrated in Figure 3, the self-check CoT workflow \u2026", "entry_id": "http://arxiv.org/abs/2505.17470v1", "updated": "2025-05-23 04:50:54", "published": "2025-05-23 04:50:54", "authors": "Xiang Liu;Zhaoxiang Liu;Peng Wang;Kohou Wang;Huan Hu;Kai Wang;Shiguo Lian", "summary": "When using supervised fine-tuning (SFT) to adapt large language models (LLMs)\nto specific domains, a significant challenge arises: should we use the entire\nSFT dataset for fine-tuning? Common practice often involves fine-tuning\ndirectly on the entire dataset due to limited information on the LLM's past\ntraining data. However, if the SFT dataset largely overlaps with the model's\nexisting knowledge, the performance gains are minimal, leading to wasted\ncomputational resources. Identifying the unknown knowledge within the SFT\ndataset and using it to fine-tune the model could substantially improve the\ntraining efficiency. To address this challenge, we propose a self-learning\nframework for LLMs inspired by human learning pattern. This framework takes a\nfine-tuning (SFT) dataset in a specific domain as input. First, the LLMs answer\nthe questions in the SFT dataset. The LLMs then objectively grade the responses\nand filter out the incorrectly answered QA pairs. Finally, we fine-tune the\nLLMs based on this filtered QA set. Experimental results in the fields of\nagriculture and medicine demonstrate that our method substantially reduces\ntraining time while achieving comparable improvements to those attained with\nfull dataset fine-tuning. By concentrating on the unknown knowledge within the\nSFT dataset, our approach enhances the efficiency of fine-tuning LLMs.", "comment": "12 pages, 5 figures", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2505.17470v1;http://arxiv.org/pdf/2505.17470v1", "pdf_url": "http://arxiv.org/pdf/2505.17470v1"}, {"title": "Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL", "link": "https://arxiv.org/pdf/2505.17952", "details": "C Liu, H Wang, J Pan, Z Wan, Y Dai, F Lin, W Bai\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 Improving performance on complex tasks and enabling interpretable decision making in **large** **language** **models** (LLMs), especially for **clinical** \u2026 **questions** from Indian **medical** entrance exams (AIIMS, NEET). PubMedQA [34] focuses on \u2026", "entry_id": "http://arxiv.org/abs/2505.17952v1", "updated": "2025-05-23 14:27:37", "published": "2025-05-23 14:27:37", "authors": "Che Liu;Haozhe Wang;Jiazhen Pan;Zhongwei Wan;Yong Dai;Fangzhen Lin;Wenjia Bai;Daniel Rueckert;Rossella Arcucci", "summary": "Improving performance on complex tasks and enabling interpretable decision\nmaking in large language models (LLMs), especially for clinical applications,\nrequires effective reasoning. Yet this remains challenging without supervised\nfine-tuning (SFT) on costly chain-of-thought (CoT) data distilled from\nclosed-source models (e.g., GPT-4o). In this work, we present AlphaMed, the\nfirst medical LLM to show that reasoning capability can emerge purely through\nreinforcement learning (RL), using minimalist rule-based rewards on public\nmultiple-choice QA datasets, without relying on SFT or distilled CoT data.\nAlphaMed achieves state-of-the-art results on six medical QA benchmarks,\noutperforming models trained with conventional SFT+RL pipelines. On challenging\nbenchmarks (e.g., MedXpert), AlphaMed even surpasses larger or closed-source\nmodels such as DeepSeek-V3-671B and Claude-3.5-Sonnet. To understand the\nfactors behind this success, we conduct a comprehensive data-centric analysis\nguided by three questions: (i) Can minimalist rule-based RL incentivize\nreasoning without distilled CoT supervision? (ii) How do dataset quantity and\ndiversity impact reasoning? (iii) How does question difficulty shape the\nemergence and generalization of reasoning? Our findings show that dataset\ninformativeness is a key driver of reasoning performance, and that minimalist\nRL on informative, multiple-choice QA data is effective at inducing reasoning\nwithout CoT supervision. We also observe divergent trends across benchmarks,\nunderscoring limitations in current evaluation and the need for more\nchallenging, reasoning-oriented medical QA benchmarks.", "comment": "Under Review", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2505.17952v1;http://arxiv.org/pdf/2505.17952v1", "pdf_url": "http://arxiv.org/pdf/2505.17952v1"}, {"title": "MEDMKG: Benchmarking Medical Knowledge Exploitation with Multimodal Knowledge Graph", "link": "https://arxiv.org/pdf/2505.17214", "details": "X Wang, Y Zhong, L Zhang, L Dai, T Wang, F Ma - arXiv preprint arXiv:2505.17214, 2025", "abstract": "\u2026 the contextual reasoning capabilities of **large** **language** **models** (LLMs), enabling precise extraction of **clinical** concepts and their relationships. \u2026 To benchmark current knowledge-augmented visual **question** **answering** methods with our \u2026", "entry_id": "http://arxiv.org/abs/2505.17214v1", "updated": "2025-05-22 18:41:46", "published": "2025-05-22 18:41:46", "authors": "Xiaochen Wang;Yuan Zhong;Lingwei Zhang;Lisong Dai;Ting Wang;Fenglong Ma", "summary": "Medical deep learning models depend heavily on domain-specific knowledge to\nperform well on knowledge-intensive clinical tasks. Prior work has primarily\nleveraged unimodal knowledge graphs, such as the Unified Medical Language\nSystem (UMLS), to enhance model performance. However, integrating multimodal\nmedical knowledge graphs remains largely underexplored, mainly due to the lack\nof resources linking imaging data with clinical concepts. To address this gap,\nwe propose MEDMKG, a Medical Multimodal Knowledge Graph that unifies visual and\ntextual medical information through a multi-stage construction pipeline. MEDMKG\nfuses the rich multimodal data from MIMIC-CXR with the structured clinical\nknowledge from UMLS, utilizing both rule-based tools and large language models\nfor accurate concept extraction and relationship modeling. To ensure graph\nquality and compactness, we introduce Neighbor-aware Filtering (NaF), a novel\nfiltering algorithm tailored for multimodal knowledge graphs. We evaluate\nMEDMKG across three tasks under two experimental settings, benchmarking\ntwenty-four baseline methods and four state-of-the-art vision-language\nbackbones on six datasets. Results show that MEDMKG not only improves\nperformance in downstream medical tasks but also offers a strong foundation for\ndeveloping adaptive and robust strategies for multimodal knowledge integration\nin medical artificial intelligence.", "comment": "Submitted to Neurips 2025", "journal_ref": null, "primary_category": "cs.AI", "categories": "cs.AI", "links": "http://arxiv.org/abs/2505.17214v1;http://arxiv.org/pdf/2505.17214v1", "pdf_url": "http://arxiv.org/pdf/2505.17214v1"}, {"title": "Factual Knowledge-Enhanced **Question Answering** in Dynamic Environments", "link": "https://search.proquest.com/openview/b2506b9fd9016ccd8804ff2f724dff3e/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy", "details": "S Shaier - 2025", "abstract": "\u2026 This thesis explores the realm of **question** **answering** (QA) systems, with a focus on those \u2026 leverage internal and external knowledge when **answering** **questions** , shedding light on their \u2026 As a result, **large** **language** **models** (LLMs) are often \u2026"}, {"title": "Duke & Chen Institute Joint Boot Camp for AI & AI Accelerated **Medical** Research 2025 Course Note", "link": "https://patriciaxiao.github.io/www/files/Duke_AI_Boot_Camp_2025_Course_Note.pdf", "details": "P Xiao - 2025", "abstract": "\u2026 The lack of trust on **clinicians** prevents a wide adoption of AI models in real-world **clinical** trials, cuz we need to implement the following steps to \u2026 [89], there comes a lot more larger language models based on the transformer architecture, which we \u2026"}]
