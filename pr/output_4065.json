[{"title": "Explanation is All You Need in Distillation: Mitigating Bias and Shortcut Learning", "link": "https://arxiv.org/pdf/2407.09788", "details": "PRAS Bassi, A Cavalli, S Decherchi - arXiv preprint arXiv:2407.09788, 2024", "abstract": "Bias and spurious correlations in data can cause shortcut learning, undermining out- of-distribution (OOD) generalization in deep neural networks. Most methods require unbiased data during training (and/or hyper-parameter tuning) to counteract shortcut \u2026"}, {"title": "Investigating Low-Rank Training in Transformer Language Models: Efficiency and Scaling Analysis", "link": "https://arxiv.org/pdf/2407.09835", "details": "X Wei, S Moalla, R Pascanu, C Gulcehre - arXiv preprint arXiv:2407.09835, 2024", "abstract": "State-of-the-art LLMs often rely on scale with high computational costs, which has sparked a research agenda to reduce parameter counts and costs without significantly impacting performance. Our study focuses on Transformer-based LLMs \u2026"}, {"title": "Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models", "link": "https://arxiv.org/pdf/2406.14091", "details": "D Lee, D Rim, M Choi, J Choo - arXiv preprint arXiv:2406.14091, 2024", "abstract": "Although language models (LMs) demonstrate exceptional capabilities on various tasks, they are potentially vulnerable to extraction attacks, which represent a significant privacy risk. To mitigate the privacy concerns of LMs, machine unlearning \u2026"}, {"title": "Was it Slander? Towards Exact Inversion of Generative Language Models", "link": "https://arxiv.org/pdf/2407.11059", "details": "A Skapars, E Manino, Y Sun, LC Cordeiro - arXiv preprint arXiv:2407.11059, 2024", "abstract": "Training large language models (LLMs) requires a substantial investment of time and money. To get a good return on investment, the developers spend considerable effort ensuring that the model never produces harmful and offensive outputs. However \u2026"}, {"title": "Cross-Lingual Multi-Hop Knowledge Editing--Benchmarks, Analysis and a Simple Contrastive Learning based Approach", "link": "https://arxiv.org/pdf/2407.10275", "details": "A Khandelwal, H Singh, H Gu, T Chen, K Zhou - arXiv preprint arXiv:2407.10275, 2024", "abstract": "Large language models are often expected to constantly adapt to new sources of knowledge and knowledge editing techniques aim to efficiently patch the outdated model knowledge, with minimal modification. Most prior works focus on monolingual \u2026"}, {"title": "RegMix: Data Mixture as Regression for Language Model Pre-training", "link": "https://arxiv.org/pdf/2407.01492", "details": "Q Liu, X Zheng, N Muennighoff, G Zeng, L Dou, T Pang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The data mixture for large language model pre-training significantly impacts performance, yet how to determine an effective mixture remains unclear. We propose RegMix to automatically identify a high-performing data mixture by formulating it as a \u2026"}, {"title": "Hybrid Explanatory Interactive Machine Learning for Medical Diagnosis", "link": "https://link.springer.com/chapter/10.1007/978-3-031-63211-2_9", "details": "E Slany, S Scheele, U Schmid - IFIP International Conference on Artificial Intelligence \u2026, 2024", "abstract": "Abstract Machine learning (ML) models can be an effective assistance in medical diagnosis if they allow physicians to project their knowledge into model's internal mechanism. Using model-agnostic explanatory interactive ML (XIML), physicians \u2026"}, {"title": "AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization", "link": "https://arxiv.org/pdf/2407.11591", "details": "A Afzal, R Chalumattu, F Matthes, LM Espuny - arXiv preprint arXiv:2407.11591, 2024", "abstract": "Despite the advances in the abstractive summarization task using Large Language Models (LLM), there is a lack of research that asses their abilities to easily adapt to different domains. We evaluate the domain adaptation abilities of a wide range of \u2026"}, {"title": "Uncovering Latent Memories: Assessing Data Leakage and Memorization Patterns in Large Language Models", "link": "https://arxiv.org/pdf/2406.14549", "details": "S Duan, M Khona, A Iyer, R Schaeffer, IR Fiete - arXiv preprint arXiv:2406.14549, 2024", "abstract": "The proliferation of large language models has revolutionized natural language processing tasks, yet it raises profound concerns regarding data privacy and security. Language models are trained on extensive corpora including potentially sensitive or \u2026"}]
