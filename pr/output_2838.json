[{"title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models", "link": "https://arxiv.org/pdf/2406.04344", "details": "TZ Xiao, R Bamler, B Sch\u00f6lkopf, W Liu - arXiv preprint arXiv:2406.04344, 2024", "abstract": "Motivated by the large progress made by large language models (LLMs), we introduce the framework of verbalized machine learning (VML). In contrast to conventional machine learning models that are typically optimized over a continuous \u2026"}, {"title": "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice", "link": "https://arxiv.org/pdf/2405.19313", "details": "JQ Zhu, H Yan, TL Griffiths - arXiv preprint arXiv:2405.19313, 2024", "abstract": "The observed similarities in the behavior of humans and Large Language Models (LLMs) have prompted researchers to consider the potential of using LLMs as models of human cognition. However, several significant challenges must be \u2026"}, {"title": "Supplementary Material VILA: On Pre-training for Visual Language Models", "link": "https://openaccess.thecvf.com/content/CVPR2024/supplemental/Lin_VILA_On_Pre-training_CVPR_2024_supplemental.pdf", "details": "J Lin, H Yin, W Ping, P Molchanov, M Shoeybi, S Han", "abstract": "We used an in-house data blend for supervised finetuning/instruction tuning during the ablation study. We followed [5] to build the FLAN-style instructions from the training set of 18 visual language datasets, as shown in Table 1. We may see that \u2026"}, {"title": "On Trojans in Refined Language Models", "link": "https://arxiv.org/pdf/2406.07778", "details": "J Raghuram, G Kesidis, DJ Miller - arXiv preprint arXiv:2406.07778, 2024", "abstract": "A Trojan in a language model can be inserted when the model is refined for a particular application such as determining the sentiment of product reviews. In this paper, we clarify and empirically explore variations of the data-poisoning threat \u2026"}, {"title": "Accelerating Iterative Retrieval-augmented Language Model Serving with Speculation", "link": "https://openreview.net/pdf%3Fid%3DCDnv4vg02f", "details": "Z Zhang, A Zhu, L Yang, Y Xu, L Li, PM Phothilimthana\u2026 - Forty-first International Conference \u2026", "abstract": "This paper introduces RaLMSpec, a framework that accelerates iterative retrieval- augmented language model (RaLM) with* speculative retrieval* and* batched verification*. RaLMSpec further introduces several important systems optimizations \u2026"}, {"title": "Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models", "link": "https://arxiv.org/pdf/2406.03009", "details": "SL Wei, CK Wu, HH Huang, HH Chen - arXiv preprint arXiv:2406.03009, 2024", "abstract": "In this paper, we investigate the phenomena of\" selection biases\" in Large Language Models (LLMs), focusing on problems where models are tasked with choosing the optimal option from an ordered sequence. We delve into biases related to option \u2026"}, {"title": "Are Large Language Models Actually Good at Text Style Transfer?", "link": "https://arxiv.org/pdf/2406.05885", "details": "S Mukherjee, AK Ojha, O Du\u0161ek - arXiv preprint arXiv:2406.05885, 2024", "abstract": "We analyze the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. Text Style Transfer involves modifying the \u2026"}, {"title": "Aligning Large Language Models via Fine-grained Supervision", "link": "https://arxiv.org/pdf/2406.02756", "details": "D Xu, L Qiu, M Kim, F Ladhak, J Do - arXiv e-prints, 2024", "abstract": "Pre-trained large-scale language models (LLMs) excel at producing coherent articles, yet their outputs may be untruthful, toxic, or fail to align with user expectations. Current approaches focus on using reinforcement learning with human \u2026"}, {"title": "MAFA: Managing False Negatives for Vision-Language Pre-training", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Byun_MAFA_Managing_False_Negatives_for_Vision-Language_Pre-training_CVPR_2024_paper.pdf", "details": "J Byun, D Kim, T Moon - Proceedings of the IEEE/CVF Conference on Computer \u2026, 2024", "abstract": "We consider a critical issue of false negatives in Vision-Language Pre-training (VLP) a challenge that arises from the inherent many-to-many correspondence of image- text pairs in large-scale web-crawled datasets. The presence of false negatives can \u2026"}]
