[{"title": "Clinicalagent: Clinical trial multi-agent system with large language model-based reasoning", "link": "https://dl.acm.org/doi/abs/10.1145/3698587.3701359", "details": "L Yue, S Xing, J Chen, T Fu - Proceedings of the 15th ACM International Conference \u2026, 2024", "abstract": "Large Language Models (LLMs) and multi-agent systems have shown impressive capabilities in natural language tasks but face challenges in clinical trial applications, primarily due to limited access to external knowledge. Recognizing the potential of \u2026"}, {"title": "CPath-Omni: A Unified Multimodal Foundation Model for Patch and Whole Slide Image Analysis in Computational Pathology", "link": "https://arxiv.org/pdf/2412.12077", "details": "Y Sun, Y Si, C Zhu, X Gong, K Zhang, P Chen, Y Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence of large multimodal models (LMMs) has brought significant advancements to pathology. Previous research has primarily focused on separately training patch-level and whole-slide image (WSI)-level models, limiting the \u2026"}, {"title": "MFMF: Multiple Foundation Model Fusion Networks for Whole Slide Image Classification", "link": "https://dl.acm.org/doi/pdf/10.1145/3698587.3701372", "details": "TM Dang, Y Guo, H Ma, Q Zhou, S Na, J Gao, J Huang - Proceedings of the 15th ACM \u2026, 2024", "abstract": "Tumor detection and subtyping remain a significant challenge in histopathology image analysis. As digital pathology progresses, the applications of deep learning become essential. Whole Slide Image (WSI) classification has emerged as a crucial \u2026"}, {"title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2412.09827", "details": "C Li, C Ding, K Luan, X Di - arXiv preprint arXiv:2412.09827, 2024", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. LoRA is one of the most widely used methods, which assumes that the optimization process is essentially low \u2026"}, {"title": "Can Language Models Rival Mathematics Students? Evaluating Mathematical Reasoning through Textual Manipulation and Human Experiments", "link": "https://arxiv.org/pdf/2412.11908", "details": "A Nikolaiev, Y Stathopoulos, S Teufel - arXiv preprint arXiv:2412.11908, 2024", "abstract": "In this paper we look at the ability of recent large language models (LLMs) at solving mathematical problems in combinatorics. We compare models LLaMA-2, LLaMA-3.1, GPT-4, and Mixtral against each other and against human pupils and \u2026"}, {"title": "SEW: Self-calibration Enhanced Whole Slide Pathology Image Analysis", "link": "https://arxiv.org/pdf/2412.10853", "details": "H Luo, X Yu, S Zhang, J Xia, Y Jian, Y Sun, L Xue\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "arXiv:2412.10853v1 [cs.CV] 14 Dec 2024 Page 1 SEW: Self-calibration Enhanced Whole Slide Pathology Image Analysis Haoming Luo Department of Software Zhejiang University haoming luo@zju.edu.cn Xiaotian Yu Department of Computer Science and \u2026"}]
