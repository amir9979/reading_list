[{"title": "Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.06663", "details": "K Sun, M Dredze - arXiv preprint arXiv:2408.06663, 2024", "abstract": "The development of large language models leads to the formation of a pre-train-then- align paradigm, in which the model is typically pre-trained on a large text corpus and undergoes a tuning stage to align the model with human preference or downstream \u2026"}, {"title": "SpectralGaussians: Semantic, spectral 3D Gaussian splatting for multi-spectral scene representation, visualization and analysis", "link": "https://arxiv.org/pdf/2408.06975", "details": "SN Sinha, H Graf, M Weinmann - arXiv preprint arXiv:2408.06975, 2024", "abstract": "We propose a novel cross-spectral rendering framework based on 3D Gaussian Splatting (3DGS) that generates realistic and semantically meaningful splats from registered multi-view spectrum and segmentation maps. This extension enhances \u2026"}]
