[{"title": "Vision Language Model is NOT All You Need: Augmentation Strategies for Molecule Language Models", "link": "https://dl.acm.org/doi/pdf/10.1145/3627673.3679607", "details": "N Lee, S Laghuvarapu, C Park, J Sun - Proceedings of the 33rd ACM International \u2026, 2024", "abstract": "Recently, there has been a growing interest among researchers in understanding molecules and their textual descriptions through molecule language models (MoLM). However, despite some early promising developments, the advancement of MoLM \u2026"}, {"title": "How to Train Long-Context Language Models (Effectively)", "link": "https://arxiv.org/pdf/2410.02660%3F", "details": "T Gao, A Wettig, H Yen, D Chen - arXiv preprint arXiv:2410.02660, 2024", "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development--Instead of perplexity or simple \u2026"}, {"title": "Are Expert-Level Language Models Expert-Level Annotators?", "link": "https://arxiv.org/pdf/2410.03254", "details": "YM Tseng, WL Chen, CC Chen, HH Chen - arXiv preprint arXiv:2410.03254, 2024", "abstract": "Data annotation refers to the labeling or tagging of textual data with relevant information. A large body of works have reported positive results on leveraging LLMs as an alternative to human annotators. However, existing studies focus on classic \u2026"}, {"title": "Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL", "link": "https://arxiv.org/pdf/2410.11371", "details": "Q Zhong, K Chen, L Ding, J Liu, B Du, D Tao - arXiv preprint arXiv:2410.11371, 2024", "abstract": "Large Language Models (LLMs) have shown promising performance in text-to-SQL, which involves translating natural language questions into SQL queries. However, current text-to-SQL LLMs are computationally expensive and challenging to deploy \u2026"}, {"title": "LoGra-Med: Long context multi-graph alignment for medical vision-language model", "link": "https://arxiv.org/pdf/2410.02615%3F", "details": "DMH Nguyen, NT Diep, TQ Nguyen, HB Le, T Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "State-of-the-art medical multi-modal large language models (med-MLLM), like LLaVA-Med or BioMedGPT, leverage instruction-following data in pre-training. However, those models primarily focus on scaling the model size and data volume to \u2026"}, {"title": "Federated Heterogeneous Contrastive Distillation for Molecular Representation Learning", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679725", "details": "J Feng, Z Wang, Z Wei, Y Li, B Ding, H Xu - \u2026 of the 33rd ACM International Conference \u2026, 2024", "abstract": "With the increasing application of deep learning to solve scientific problems in biochemistry, molecular federated learning has become popular due to its ability to offer distributed privacy-preserving solutions. However, most existing molecular \u2026"}, {"title": "Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning", "link": "https://arxiv.org/pdf/2410.14390", "details": "B Zhang, D Liu, O Simeone, G Wang, D Pezaros, G Zhu - arXiv preprint arXiv \u2026, 2024", "abstract": "To support real-world decision-making, it is crucial for models to be well-calibrated, ie, to assign reliable confidence estimates to their predictions. Uncertainty quantification is particularly important in personalized federated learning (PFL), as \u2026"}, {"title": "Effective Guidance for Model Attention with Simple Yes-no Annotations", "link": "https://arxiv.org/pdf/2410.22312", "details": "S Lee, A Payani, D Horng - arXiv preprint arXiv:2410.22312, 2024", "abstract": "Modern deep learning models often make predictions by focusing on irrelevant areas, leading to biased performance and limited generalization. Existing methods aimed at rectifying model attention require explicit labels for irrelevant areas or \u2026"}, {"title": "Simulating clinical features on chest radiographs for medical image exploration and CNN explainability using a style-based generative adversarial autoencoder", "link": "https://www.nature.com/articles/s41598-024-75886-0", "details": "KA Hasenstab, L Hahn, N Chao, A Hsiao - Scientific Reports, 2024", "abstract": "Explainability of convolutional neural networks (CNNs) is integral for their adoption into radiological practice. Commonly used attribution methods localize image areas important for CNN prediction but do not characterize relevant imaging features \u2026"}]
