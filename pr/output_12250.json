[{"title": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment", "link": "https://arxiv.org/pdf/2501.07525", "details": "D Gu, Y Gao, Y Zhou, M Zhou, D Metaxas - arXiv preprint arXiv:2501.07525, 2025", "abstract": "Automated chest radiographs interpretation requires both accurate disease classification and detailed radiology report generation, presenting a significant challenge in the clinical workflow. Current approaches either focus on classification \u2026"}, {"title": "MotionBench: Benchmarking and Improving Fine-grained Video Motion Understanding for Vision Language Models", "link": "https://arxiv.org/pdf/2501.02955", "details": "W Hong, Y Cheng, Z Yang, W Wang, L Wang, X Gu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In recent years, vision language models (VLMs) have made significant advancements in video understanding. However, a crucial capability-fine-grained motion comprehension-remains under-explored in current benchmarks. To address \u2026"}, {"title": "DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests", "link": "https://arxiv.org/pdf/2501.04671", "details": "C Corbi\u00e8re, S Roburin, S Montariol, A Bosselut, A Alahi - arXiv preprint arXiv \u2026, 2025", "abstract": "Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning. However, due to the modality gap between textual and visual data, they often face significant challenges, such as over \u2026"}, {"title": "Open-source small language models for personal medical assistant chatbots", "link": "https://www.sciencedirect.com/science/article/pii/S2666521224000644", "details": "M Magnini, G Aguzzi, S Montagna - Intelligence-Based Medicine, 2025", "abstract": "Medical chatbots are becoming essential components of telemedicine applications as tools to assist patients in the self-management of their conditions. This trend is particularly driven by advancements in natural language processing techniques with \u2026"}, {"title": "Momentum Augmented Contrastive Learning for Vision-Language Pretraining on Chest X-ray", "link": "https://openreview.net/forum%3Fid%3DAwSbBfJx5b", "details": "P Pham, N Pham, NQ Ly - Medical Imaging with Deep Learning", "abstract": "In medical healthcare, obtaining data with detailed annotations is often challenging, highlighting the benefits of a robust medical Vision-Language Model (VLM). Leveraging a pretrained VLM allows fine-tuning on smaller datasets or using zero \u2026"}, {"title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models", "link": "https://arxiv.org/pdf/2501.05752", "details": "S Lee, H Park, J Kim, J Ok - arXiv preprint arXiv:2501.05752, 2025", "abstract": "Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer \u2026"}, {"title": "Mee-SLAM: Memory efficient endoscopic RGB SLAM with implicit scene representation", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424031026", "details": "Y Zhou, T Li, Y Dai, J Zhang - Expert Systems with Applications, 2025", "abstract": "Endoscopic dense simultaneous localization and mapping (SLAM) plays a critical role in robot assisted surgery. Recently, SLAM systems based on neural implicit representation have demonstrated superior localization and real-time mapping \u2026"}, {"title": "Expanding the generality of neural fields", "link": "https://dr.ntu.edu.sg/bitstream/10356/182229/2/yslan-thesis-final-copy.pdf", "details": "Y Lan - 2025", "abstract": "Neural fields have emerged as a groundbreaking approach to representing 3D shapes, garnering significant attention due to their compatibility with modern deep- learning techniques. Neural fields, which parameterize physical properties of scenes \u2026"}, {"title": "MedFILIP: Medical Fine-Grained Language-Image Pre-Training", "link": "https://ieeexplore.ieee.org/abstract/document/10836674/", "details": "X Liang, X Li, F Li, J Jiang, Q Dong, W Wang, K Wang\u2026 - IEEE Journal of Biomedical \u2026, 2025", "abstract": "Medical vision-language pretraining (VLP) that leverages naturally-paired medical image-report data is crucial for medical image analysis. However, existing methods struggle to accurately characterize associations between images and diseases \u2026"}]
