[{"title": "LZ Penalty: An information-theoretic repetition penalty for autoregressive language models", "link": "https://arxiv.org/pdf/2504.20131", "details": "AA Ginart, N Kodali, J Lee, C Xiong, S Savarese\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce the LZ penalty, a penalty specialized for reducing degenerate repetitions in autoregressive language models without loss of capability. The penalty is based on the codelengths in the LZ77 universal lossless compression algorithm \u2026"}, {"title": "Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction", "link": "https://aclanthology.org/2025.findings-naacl.365.pdf", "details": "SY ShengbinYue, T Huang, Z Jia, S Wang, S Liu\u2026 - Findings of the Association \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) have significantly advanced legal intelligence, but the scarcity of scenario data impedes the progress toward interactive legal scenarios. This paper introduces a Multi-agent Legal Simulation Driver \u2026"}, {"title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation", "link": "https://arxiv.org/pdf/2504.20859", "details": "G Hadad, H Roitman, Y Eshel, B Shapira, L Rokach - arXiv preprint arXiv:2504.20859, 2025", "abstract": "As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents``X-Cross''--a novel cross-domain sequential-recommendation model \u2026"}, {"title": "STP: Special token prompt for parameter-efficient tuning of pre-trained language models", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425012874", "details": "Y Yan, H Yu, D Wang, J Ye, F Liu, W Xu - Expert Systems with Applications, 2025", "abstract": "Fine-tuning has become the standard method for using large pre-trained language models to accomplish specific downstream tasks. However, full fine-tuning requires updating all model parameters, which is not only computationally expensive but also \u2026"}, {"title": "Prejudge-Before-Think: Enhancing Large Language Models at Test-Time by Process Prejudge Reasoning", "link": "https://arxiv.org/pdf/2504.13500%3F", "details": "J Wang, J Jiang, Y Liu, M Zhang, X Cai - arXiv preprint arXiv:2504.13500, 2025", "abstract": "In this paper, we introduce a new\\emph {process prejudge} strategy in LLM reasoning to demonstrate that bootstrapping with process prejudge allows the LLM to adaptively anticipate the errors encountered when advancing the subsequent \u2026"}, {"title": "Evaluating Multi-Hop Reasoning in Large Language Models: A Chemistry-Centric Case Study", "link": "https://arxiv.org/pdf/2504.16414", "details": "M Khodadad, AS Kasmaee, M Astaraki, N Sherck\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In this study, we introduced a new benchmark consisting of a curated dataset and a defined evaluation process to assess the compositional reasoning capabilities of large language models within the chemistry domain. We designed and validated a \u2026"}, {"title": "Towards Explainable Fake Image Detection with Multi-Modal Large Language Models", "link": "https://arxiv.org/pdf/2504.14245", "details": "Y Ji, Y Hong, J Zhan, H Chen, H Zhu, W Wang, L Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Progress in image generation raises significant public security concerns. We argue that fake image detection should not operate as a\" black box\". Instead, an ideal approach must ensure both strong generalization and transparency. Recent \u2026"}, {"title": "Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training", "link": "https://arxiv.org/pdf/2504.20484", "details": "L Wu, H Wei, H Lin, T Li, B Yang, W Lu - arXiv preprint arXiv:2504.20484, 2025", "abstract": "Large language models (LLMs) exhibit remarkable multilingual capabilities despite English-dominated pre-training, attributed to cross-lingual mechanisms during pre- training. Existing methods for enhancing cross-lingual transfer remain constrained by \u2026"}, {"title": "VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models", "link": "https://arxiv.org/pdf/2504.15279", "details": "W Xu, J Wang, W Wang, Z Chen, W Zhou, A Yang, L Lu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Visual reasoning is a core component of human intelligence and a critical capability for advanced multimodal models. Yet current reasoning evaluations of multimodal large language models (MLLMs) often rely on text descriptions and allow language \u2026"}]
