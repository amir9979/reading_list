[{"title": "NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli", "link": "https://arxiv.org/pdf/2405.02814", "details": "X Wang, C Li, Y Chang, J Wang, Y Wu - arXiv preprint arXiv:2405.02814, 2024", "abstract": "Large Language Models (LLMs) have become integral to a wide spectrum of applications, ranging from traditional computing tasks to advanced artificial intelligence (AI) applications. This widespread adoption has spurred extensive \u2026"}, {"title": "Generation and human-expert evaluation of interesting research ideas using knowledge graphs and large language models", "link": "https://arxiv.org/pdf/2405.17044", "details": "X Gu, M Krenn - arXiv preprint arXiv:2405.17044, 2024", "abstract": "Advanced artificial intelligence (AI) systems with access to millions of research papers could inspire new research ideas that may not be conceived by humans alone. However, how interesting are these AI-generated ideas, and how can we \u2026"}, {"title": "RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical Diagnostic Reports", "link": "https://arxiv.org/pdf/2405.14137", "details": "J Du, J Guo, W Zhang, S Yang, H Liu, H Li, N Wang - arXiv preprint arXiv:2405.14137, 2024", "abstract": "The Vision-Language Foundation model is increasingly investigated in the fields of computer vision and natural language processing, yet its exploration in ophthalmology and broader medical applications remains limited. The challenge is \u2026"}, {"title": "IT5: Text-to-text Pretraining for Italian Language Understanding and Generation", "link": "https://aclanthology.org/2024.lrec-main.823.pdf", "details": "G Sarti, M Nissim - Proceedings of the 2024 Joint International Conference \u2026, 2024", "abstract": "We introduce IT5, the first family of encoder-decoder transformer models pretrained specifically on Italian. We document and perform a thorough cleaning procedure for a large Italian corpus and use it to pretrain four IT5 model sizes. We then introduce \u2026"}, {"title": "Exploring Frequencies via Feature Mixing and Meta-Learning for Improving Adversarial Transferability", "link": "https://arxiv.org/pdf/2405.03193", "details": "J Weng, Z Luo, S Li - arXiv preprint arXiv:2405.03193, 2024", "abstract": "Recent studies have shown that Deep Neural Networks (DNNs) are susceptible to adversarial attacks, with frequency-domain analysis underscoring the significance of high-frequency components in influencing model predictions. Conversely, targeting \u2026"}, {"title": "Few-shot biomedical relation extraction using data augmentation and domain information", "link": "https://www.sciencedirect.com/science/article/pii/S0925231224006520", "details": "B Guo, D Zhao, X Dong, J Meng, H Lin - Neurocomputing, 2024", "abstract": "Relation extraction (RE) plays a pivotal role in biomedical information extraction. However, traditional approaches are often limited by high data annotation costs and extensive time investments. To address this challenge, this study proposes an \u2026"}]
