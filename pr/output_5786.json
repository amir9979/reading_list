[{"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Language Models Don't Learn the Physical Manifestation of Language", "link": "https://aclanthology.org/2024.acl-long.195.pdf", "details": "B Lee, J Lim - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "We argue that language-only models don't learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test. These tasks highlight a \u2026"}, {"title": "Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models", "link": "https://arxiv.org/pdf/2408.01308", "details": "Y Zhang, D Li, M Okumura - arXiv preprint arXiv:2408.01308, 2024", "abstract": "Learning token embeddings based on token co-occurrence statistics has proven effective for both pre-training and fine-tuning in natural language processing. However, recent studies have pointed out the distribution of learned embeddings \u2026"}, {"title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "link": "https://arxiv.org/pdf/2408.02103", "details": "P Wang, X Wang, C Lou, S Mao, P Xie, Y Jiang - arXiv preprint arXiv:2408.02103, 2024", "abstract": "In-context learning (ICL) is a few-shot learning paradigm that involves learning mappings through input-output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language \u2026"}, {"title": "Evaluating Language Models for Efficient Code Generation", "link": "https://arxiv.org/pdf/2408.06450", "details": "J Liu, S Xie, J Wang, Y Wei, Y Ding, L Zhang - arXiv preprint arXiv:2408.06450, 2024", "abstract": "We introduce Differential Performance Evaluation (DPE), a framework designed to reliably evaluate Large Language Models (LLMs) for efficient code generation. Traditional coding benchmarks often fail to provide reliable insights into code \u2026"}, {"title": "Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs", "link": "https://aclanthology.org/2024.findings-acl.938.pdf", "details": "D Wang, J Zhao, H Pei, S Tan, S Zha - Findings of the Association for Computational \u2026, 2024", "abstract": "Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs \u2026"}, {"title": "Using Large Language Models to Evaluate Biomedical Query-Focused Summarisation", "link": "https://aclanthology.org/2024.bionlp-1.18.pdf", "details": "H Hijazi, D Molla, V Nguyen, S Karimi - Proceedings of the 23rd Workshop on \u2026, 2024", "abstract": "Biomedical question-answering systems remain popular for biomedical experts interacting with the literature to answer their medical questions. However, these systems are difficult to evaluate in the absence of costly human experts. Therefore \u2026"}, {"title": "UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling", "link": "https://arxiv.org/pdf/2408.04810", "details": "H Al-Tahan, Q Garrido, R Balestriero, D Bouchacourt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Significant research efforts have been made to scale and improve vision-language model (VLM) training approaches. Yet, with an ever-growing number of benchmarks, researchers are tasked with the heavy burden of implementing each protocol \u2026"}, {"title": "Chain of Condition: Construct, Verify and Solve Conditions for Conditional Question Answering", "link": "https://arxiv.org/pdf/2408.05442", "details": "J Lin, Y Lai, Y Feng - arXiv preprint arXiv:2408.05442, 2024", "abstract": "Conditional question answering (CQA) is an important task that aims to find probable answers and identify conditions that need to be satisfied to support the answer. Existing approaches struggle with CQA due to two main challenges:(1) precisely \u2026"}]
