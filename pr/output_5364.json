[{"title": "Fairness Definitions in Language Models Explained", "link": "https://arxiv.org/pdf/2407.18454", "details": "TV Doan, Z Chu, Z Wang, W Zhang - arXiv preprint arXiv:2407.18454, 2024", "abstract": "Language Models (LMs) have demonstrated exceptional performance across various Natural Language Processing (NLP) tasks. Despite these advancements, LMs can inherit and amplify societal biases related to sensitive attributes such as \u2026"}, {"title": "Do Language Models Have a Critical Period for Language Acquisition?", "link": "https://arxiv.org/pdf/2407.19325", "details": "I Constantinescu, T Pimentel, R Cotterell, A Warstadt - arXiv preprint arXiv \u2026, 2024", "abstract": "Humans appear to have a critical period (CP) for language acquisition: Second language (L2) acquisition becomes harder after early childhood, and ceasing exposure to a first language (L1) after this period (but not before) typically does not \u2026"}, {"title": "Assessing the Ability of a Large Language Model to Score Free-Text Medical Student Clinical Notes: Quantitative Study", "link": "https://mededu.jmir.org/2024/1/e56342", "details": "HB Burke, A Hoang, JO Lopreiato, H King, P Hemmer\u2026 - JMIR Medical Education, 2024", "abstract": "Background Teaching medical students the skills required to acquire, interpret, apply, and communicate clinical information is an integral part of medical education. A crucial aspect of this process involves providing students with feedback regarding \u2026"}, {"title": "Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs", "link": "https://aclanthology.org/2024.findings-acl.938.pdf", "details": "D Wang, J Zhao, H Pei, S Tan, S Zha - Findings of the Association for Computational \u2026, 2024", "abstract": "Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs \u2026"}, {"title": "Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian", "link": "https://arxiv.org/pdf/2407.20654", "details": "S Auriemma, M Miliani, M Madeddu, A Bondielli\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Addressing the challenge of limited annotated data in specialized fields and low- resource languages is crucial for the effective use of Language Models (LMs). While most Large Language Models (LLMs) are trained on general-purpose English \u2026"}, {"title": "Large Language Models Prompting With Episodic Memory", "link": "https://arxiv.org/pdf/2408.07465", "details": "D Do, Q Tran, S Venkatesh, H Le - arXiv preprint arXiv:2408.07465, 2024", "abstract": "Prompt optimization is essential for enhancing the performance of Large Language Models (LLMs) in a range of Natural Language Processing (NLP) tasks, particularly in scenarios of few-shot learning where training examples are incorporated directly \u2026"}, {"title": "Heterogeneous-Graph Reasoning with Context Paraphrase for Commonsense Question Answering", "link": "https://ieeexplore.ieee.org/abstract/document/10612243/", "details": "Y Wang, H Zhang, J Liang, R Li - IEEE/ACM Transactions on Audio, Speech, and \u2026, 2024", "abstract": "Commonsense question answering (CQA) generally means that the machine uses its mastered commonsense to answer questions without relevant background material, which is a challenging task in natural language processing. Existing \u2026"}, {"title": "Position Paper: Dual-System Language Models via Next-Action Prediction", "link": "https://openreview.net/pdf%3Fid%3D9ZVfz8DGC8", "details": "Z Du, WJ Su - ICML 2024 Workshop on LLMs and Cognition", "abstract": "In current Large Language Model (LLM) practices, each token is appended sequentially to the output. In contrast, humans are capable of revising and correcting what we write. Inspired by this gap, in this position paper, we propose a dual-system \u2026"}, {"title": "Prompt Based CVAE Data Augmentation for Few-Shot Intention Detection", "link": "https://link.springer.com/chapter/10.1007/978-981-97-5498-4_24", "details": "J Xue, C Yin, C Li, J Bai, H Chen, W Rong - International Conference on Knowledge \u2026, 2024", "abstract": "Intent detection is an important task for AI assistants when communicating with users. However, in real life, the number of intents that need to be recognized in the intent recognition task continues to increase. It is often difficult to manually label new \u2026"}]
