'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Photo-Realistic Image Restoration in the Wild with Con'
[{"title": "ORacle: Large Vision-Language Models for Knowledge-Guided Holistic OR Domain Modeling", "link": "https://arxiv.org/pdf/2404.07031", "details": "E \u00d6zsoy, C Pellegrini, M Keicher, N Navab - arXiv preprint arXiv:2404.07031, 2024", "abstract": "Every day, countless surgeries are performed worldwide, each within the distinct settings of operating rooms (ORs) that vary not only in their setups but also in the personnel, tools, and equipment used. This inherent diversity poses a substantial \u2026"}, {"title": "MoE-TinyMed: Mixture of Experts for Tiny Medical Large Vision-Language Models", "link": "https://arxiv.org/pdf/2404.10237", "details": "S Jiang, T Zheng, Y Zhang, Y Jin, Z Liu - arXiv preprint arXiv:2404.10237, 2024", "abstract": "Mixture of Expert Tuning (MoE-Tuning) has effectively enhanced the performance of general MLLMs with fewer parameters, yet its application in resource-limited medical settings has not been fully explored. To address this gap, we developed MoE \u2026"}, {"title": "Vision-Language Models for Feature Detection of Macular Diseases on Optical Coherence Tomography", "link": "https://jamanetwork.com/journals/jamaophthalmology/article-abstract/2818270", "details": "F Antaki, R Chopra, PA Keane - JAMA ophthalmology", "abstract": "Importance Vision-language models (VLMs) are a novel artificial intelligence technology capable of processing image and text inputs. While demonstrating strong generalist capabilities, their performance in ophthalmology has not been extensively \u2026"}, {"title": "Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think", "link": "https://arxiv.org/pdf/2404.08382", "details": "X Wang, C Hu, B Ma, P R\u00f6ttger, B Plank - arXiv preprint arXiv:2404.08382, 2024", "abstract": "Multiple choice questions (MCQs) are commonly used to evaluate the capabilities of large language models (LLMs). One common way to evaluate the model response is to rank the candidate answers based on the log probability of the first token \u2026"}, {"title": "Pre-training Small Base LMs with Fewer Tokens", "link": "https://arxiv.org/pdf/2404.08634", "details": "S Sanyal, S Sanghavi, AG Dimakis - arXiv preprint arXiv:2404.08634, 2024", "abstract": "We study the effectiveness of a simple approach to develop a small base language model (LM) starting from an existing large base LM: first inherit a few transformer blocks from the larger LM, and then train this smaller model on a very small subset \u2026"}, {"title": "Post-Semantic-Thinking: A Robust Strategy to Distill Reasoning Capacity from Large Language Models", "link": "https://arxiv.org/pdf/2404.09170", "details": "X Chen, S Zhou, K Liang, X Liu - arXiv preprint arXiv:2404.09170, 2024", "abstract": "Chain of thought finetuning aims to endow small student models with reasoning capacity to improve their performance towards a specific task by allowing them to imitate the reasoning procedure of large language models (LLMs) beyond simply \u2026"}]
