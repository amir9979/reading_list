[{"title": "Abstraction-of-Thought Makes Language Models Better Reasoners", "link": "https://arxiv.org/pdf/2406.12442", "details": "R Hong, H Zhang, X Pan, D Yu, C Zhang - arXiv preprint arXiv:2406.12442, 2024", "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks \u2026"}, {"title": "Language Models can be Deductive Solvers", "link": "https://aclanthology.org/2024.findings-naacl.254.pdf", "details": "J Feng, R Xu, J Hao, H Sharma, Y Shen, D Zhao\u2026 - Findings of the Association \u2026, 2024", "abstract": "Logical reasoning is a fundamental aspect of human intelligence and a key component of tasks like problem-solving and decision-making. Recent advancements have enabled Large Language Models (LLMs) to potentially exhibit \u2026"}, {"title": "ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models", "link": "https://aclanthology.org/2024.findings-naacl.261.pdf", "details": "MN Tran, PV Nguyen, L Nguyen, D Dien - Findings of the Association for \u2026, 2024", "abstract": "As the number of language models has increased, various benchmarks have been suggested to assess the proficiency of the models in natural language understanding. However, there is a lack of such a benchmark in Vietnamese due to \u2026"}, {"title": "AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2406.13233", "details": "Z Zeng, Y Miao, H Gao, H Zhang, Z Deng - arXiv preprint arXiv:2406.13233, 2024", "abstract": "Mixture of experts (MoE) has become the standard for constructing production-level large language models (LLMs) due to its promise to boost model capacity without causing significant overheads. Nevertheless, existing MoE methods usually enforce \u2026"}, {"title": "Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations", "link": "https://arxiv.org/pdf/2406.11801", "details": "R Hazra, S Layek, S Banerjee, S Poria - arXiv preprint arXiv:2406.11801, 2024", "abstract": "Ensuring the safe alignment of large language models (LLMs) with human values is critical as they become integral to applications like translation and question answering. Current alignment methods struggle with dynamic user intentions and \u2026"}, {"title": "Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications", "link": "https://aclanthology.org/2024.naacl-long.198.pdf", "details": "Y Liu, S Gautam, J Ma, H Lakkaraju - Proceedings of the 2024 Conference of the \u2026, 2024", "abstract": "Recent literature has suggested the potential of using large language models (LLMs) to make classifications for tabular tasks. However, LLMs have been shown to exhibit harmful social biases that reflect the stereotypes and inequalities present in society \u2026"}, {"title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought", "link": "https://arxiv.org/pdf/2406.13940", "details": "Y Zhang, Q Chen, M Li, W Che, L Qin - arXiv preprint arXiv:2406.13940, 2024", "abstract": "Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention. Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning \u2026"}, {"title": "Strings from the Library of Babel: Random Sampling as a Strong Baseline for Prompt Optimisation", "link": "https://aclanthology.org/2024.naacl-long.122.pdf", "details": "Y Lu, J Wang, R Tang, S Riedel, P Stenetorp - Proceedings of the 2024 Conference of \u2026, 2024", "abstract": "Recent prompt optimisation approaches use the generative nature of language models to produce prompts\u2013even rivaling the performance of human-curated prompts. In this paper, we demonstrate that randomly sampling tokens from the \u2026"}, {"title": "SeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots", "link": "https://arxiv.org/pdf/2406.14208", "details": "W Wang, H Yang, C Meinel - arXiv preprint arXiv:2406.14208, 2024", "abstract": "Previous studies have shown that demonstrations can significantly help Large Language Models (LLMs) perform better on the given tasks. However, this so-called In-Context Learning (ICL) ability is very sensitive to the presenting context, and often \u2026"}]
