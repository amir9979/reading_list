[{"title": "OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision Encoders for Multimodal Learning", "link": "https://arxiv.org/pdf/2505.04601", "details": "X Li, Y Liu, H Tu, H Zhu, C Xie - arXiv preprint arXiv:2505.04601, 2025", "abstract": "OpenAI's CLIP, released in early 2021, have long been the go-to choice of vision encoder for building multimodal foundation models. Although recent alternatives such as SigLIP have begun to challenge this status quo, to our knowledge none are \u2026"}, {"title": "Leveraging Generative Pre-trained Transformer (GPT) Large Language Models (LLMs) For Interstitial Lung Diseases (ILD) Clinical Research", "link": "https://www.atsjournals.org/doi/abs/10.1164/ajrccm.2025.211.Abstracts.A2086", "details": "S Chen, MV Maddali, C Bluethgen, CP Langlotz, R Raj - American Journal of \u2026, 2025", "abstract": "Rationale: The majority of clinically relevant data is contained in unstructured text such as clinical notes. ILD notes are particularly prone to verbosity and imprecision, making structured data extraction a major bottleneck for clinical research and a costly \u2026"}, {"title": "Benchmark for Measuring Intersectional Bias in Race and Gender of Large Language Models Using Synthetic Data", "link": "https://koreascience.kr/article/JAKO202511236003787.pdf", "details": "H Bae - The Transactions of the Korea Information Processing \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) are generative AI systems trained on vast datasets, capable of producing human-like text and widely used across industries. However, LLMs risk generating biased outputs by internalizing stereotypes related to \u2026"}]
