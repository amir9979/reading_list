[{"title": "Soft Prompts Go Hard: Steering Visual Language Models with Hidden Meta-Instructions", "link": "https://arxiv.org/pdf/2407.08970", "details": "T Zhang, C Zhang, JX Morris, E Bagdasaryan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce a new type of indirect injection vulnerabilities in language models that operate on images: hidden\" meta-instructions\" that influence how the model interprets the image and steer the model's outputs to express an adversary-chosen \u2026"}]
