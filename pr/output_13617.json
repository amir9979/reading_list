[{"title": "Medical foundation large language models for comprehensive text analysis and beyond", "link": "https://www.nature.com/articles/s41746-025-01533-1", "details": "Q Xie, Q Chen, A Chen, C Peng, Y Hu, F Lin, X Peng\u2026 - npj Digital Medicine, 2025", "abstract": "Recent advancements in large language models (LLMs) show significant potential in medical applications but are hindered by limited specialized medical knowledge. We present Me-LLaMA, a family of open-source medical LLMs integrating extensive \u2026"}, {"title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities", "link": "https://arxiv.org/pdf/2502.12025%3F", "details": "F Jiang, Z Xu, Y Li, L Niu, Z Xiang, B Li, BY Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage long chain-of-thought (CoT) reasoning to generate structured intermediate steps, enhancing their reasoning capabilities. However, long CoT does not inherently \u2026"}, {"title": "Mitigating Hallucinations in Large Vision-Language Models by Adaptively Constraining Information Flow", "link": "https://arxiv.org/pdf/2502.20750", "details": "J Bai, H Guo, Z Peng, J Yang, Z Li, M Li, Z Tian - arXiv preprint arXiv:2502.20750, 2025", "abstract": "Large vision-language models show tremendous potential in understanding visual information through human languages. However, they are prone to suffer from object hallucination, ie, the generated image descriptions contain objects that do not exist in \u2026"}, {"title": "Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones?", "link": "https://arxiv.org/pdf/2502.19557", "details": "Y Zhang, L Wang, M Fang, Y Du, C Huang, J Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Distilling large language models (LLMs) typically involves transferring the teacher model's responses through supervised fine-tuning (SFT). However, this approach neglects the potential to distill both data (output content) and reward signals (quality \u2026"}, {"title": "Modular Prompt Learning Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14125", "details": "Z Huang, T Pedapati, PY Chen, J Gao - arXiv preprint arXiv:2502.14125, 2025", "abstract": "Pre-trained vision-language models are able to interpret visual concepts and language semantics. Prompt learning, a method of constructing prompts for text encoders or image encoders, elicits the potentials of pre-trained models and readily \u2026"}, {"title": "Towards Statistical Factuality Guarantee for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.20560", "details": "Z Li, C Yan, NJ Jackson, W Cui, B Li, J Zhang, BA Malin - arXiv preprint arXiv \u2026, 2025", "abstract": "Advancements in Large Vision-Language Models (LVLMs) have demonstrated promising performance in a variety of vision-language tasks involving image- conditioned free-form text generation. However, growing concerns about \u2026"}, {"title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training", "link": "https://arxiv.org/pdf/2502.11455", "details": "F Weng, J Lou, J Feng, M Huang, W Wang - arXiv preprint arXiv:2502.11455, 2025", "abstract": "Safety alignment is critical in pre-training large language models (LLMs) to generate responses aligned with human values and refuse harmful queries. Unlike LLM, the current safety alignment of VLMs is often achieved with post-hoc safety fine-tuning \u2026"}, {"title": "Process-based Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2503.03746", "details": "S Zhang, X Liu, X Zhang, J Liu, Z Luo, S Huang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' \u2026"}, {"title": "Addressing Overprescribing Challenges: Fine-Tuning Large Language Models for Medication Recommendation Tasks", "link": "https://arxiv.org/pdf/2503.03687", "details": "Z Zhao, C Fan, C Gao, F Feng, X He - arXiv preprint arXiv:2503.03687, 2025", "abstract": "Medication recommendation systems have garnered attention within healthcare for their potential to deliver personalized and efficacious drug combinations based on patient's clinical data. However, existing methodologies encounter challenges in \u2026"}]
