[{"title": "Multivariate Time Series Anomaly Detection based on Pre-trained Models with Dual-Attention Mechanism", "link": "https://nkcs.iops.ai/wp-content/uploads/2024/08/ISSRE24-DualLMAD.pdf", "details": "Y Sun, Y Guo, M Liang, X Wen, J Kuang, S Zhang, H Li\u2026", "abstract": "In major tech companies, monitoring server performance data with anomaly detection algorithms is crucial for assessing operational status. Existing models often require separate training or fine-tuning for each server due to generalization \u2026"}, {"title": "General Time Transformer: an Encoder-only Foundation Model for Zero-Shot Multivariate Time Series Forecasting", "link": "https://cfeng783.github.io/pubs/CIKM24_GTT.pdf", "details": "C Feng, L Huang, D Krompass - 2024", "abstract": "Abstract We present General Time Transformer (GTT), an encoder-only style foundation model for zero-shot multivariate time series forecasting. GTT is pretrained on a large dataset of 200M high-quality time series samples spanning diverse \u2026"}, {"title": "Model Debiasing by Learnable Data Augmentation", "link": "https://arxiv.org/pdf/2408.04955", "details": "P Morerio, R Ragonesi, V Murino - arXiv preprint arXiv:2408.04955, 2024", "abstract": "Deep Neural Networks are well known for efficiently fitting training data, yet experiencing poor generalization capabilities whenever some kind of bias dominates over the actual task labels, resulting in models learning\" shortcuts\". In essence, such \u2026"}]
