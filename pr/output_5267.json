[{"title": "PT-HMC: Optimization-based Pre-Training with Hamiltonian Monte-Carlo Sampling for Driver Intention Recognition", "link": "https://dl.acm.org/doi/pdf/10.1145/3688573", "details": "K Vellenga, A Karlsson, HJ Steinhauer, G Falkman\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Driver intention recognition (DIR) methods mostly rely on deep neural networks (DNNs). To use DNNs in a safety-critical real-world environment it is essential to quantify how confident the model is about the produced predictions. Therefore, this \u2026"}, {"title": "MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation", "link": "https://arxiv.org/pdf/2408.05740", "details": "J Zhou, J Li, G Zheng, X Wang, C Zhou - arXiv preprint arXiv:2408.05740, 2024", "abstract": "Missing values are prevalent in multivariate time series, compromising the integrity of analyses and degrading the performance of downstream tasks. Consequently, research has focused on multivariate time series imputation, aiming to accurately \u2026"}, {"title": "Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models", "link": "https://arxiv.org/pdf/2408.04718", "details": "D Shu, AB Farimani - arXiv preprint arXiv:2408.04718, 2024", "abstract": "The success of diffusion probabilistic models in generative tasks, such as text-to- image generation, has motivated the exploration of their application to regression problems commonly encountered in scientific computing and various other domains \u2026"}, {"title": "Self-Supervised Learning-Based Time Series Classification via Hierarchical Sparse Convolutional Masked-Autoencoder", "link": "https://ieeexplore.ieee.org/iel8/8782710/9006934/10614789.pdf", "details": "T Yu, K Xu, X Wang, B Ding, D Feng - IEEE Open Journal of Signal Processing, 2024", "abstract": "In recent years, the use of time series analysis has become widespread, prompting researchers to explore methods to improve classification. Time series self-supervised learning has emerged as a significant area of study, aiming to uncover patterns in \u2026"}, {"title": "Towards Robustness Prompt Tuning with Fully Test-Time Adaptation for CLIP's Zero-Shot Generalization", "link": "https://openreview.net/pdf%3Fid%3DBVFAVis7ui", "details": "R Wang, H Zuo, Z Fang, J Lu - ACM Multimedia 2024", "abstract": "In the field of Vision-Language Models (VLM), the Contrastive Language-Image Pretraining (CLIP) model has yielded outstanding performance on many downstream tasks through prompt tuning. By integrating image and text representations, CLIP \u2026"}, {"title": "Multi-view Self-Supervised Contrastive Learning for Multivariate Time Series", "link": "https://openreview.net/pdf%3Fid%3DBgjLy3chju", "details": "Y Wu, X Meng, Y He, J Zhang, H Zhang, Y Dong, D Lu - ACM Multimedia 2024", "abstract": "Learning semantic-rich representations from unlabeled time series data with intricate dynamics is a notable challenge. Traditional contrastive learning techniques predominantly focus on segment-level augmentations through time slicing, a practice \u2026"}, {"title": "Towards Zero-Shot Generalization in Offline Reinforcement Learning", "link": "https://openreview.net/pdf%3Fid%3DnHcw4Z5VDd", "details": "Z Wang, C Yang, JCS Lui, D Zhou - ICML 2024 Workshop: Aligning Reinforcement \u2026", "abstract": "In this work, we study offline reinforcement learning (RL) with zero-shot generalization property (ZSG), where the agent has access to an offline dataset including experiences from different environments, and the goal of the agent is to \u2026"}, {"title": "FMamba: Mamba based on Fast-attention for Multivariate Time-series Forecasting", "link": "https://arxiv.org/pdf/2407.14814", "details": "S Ma, Y Kang, P Bai, YB Zhao - arXiv preprint arXiv:2407.14814, 2024", "abstract": "In multivariate time-series forecasting (MTSF), extracting the temporal correlations of the input sequences is crucial. While popular Transformer-based predictive models can perform well, their quadratic computational complexity results in inefficiency and \u2026"}]
