[{"title": "Process-based self-rewarding language models", "link": "https://arxiv.org/pdf/2503.03746", "details": "S Zhang, X Liu, X Zhang, J Liu, Z Luo, S Huang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' \u2026"}, {"title": "Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving", "link": "https://arxiv.org/pdf/2503.06497", "details": "E Zhang, P Gong, X Dai, Y Lv, Q Miao - arXiv preprint arXiv:2503.06497, 2025", "abstract": "Assessing the safety of vision-language models (VLMs) in autonomous driving is particularly important; however, existing work mainly focuses on traditional benchmark evaluations. As interactive components within autonomous driving \u2026"}, {"title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models", "link": "https://arxiv.org/pdf/2503.05005", "details": "B Jamialahmadi, P Kavehzadeh, M Rezagholizadeh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deploying large language models (LLMs) in real-world applications is often hindered by strict computational and latency constraints. While dynamic inference offers the flexibility to adjust model behavior based on varying resource budgets, existing \u2026"}, {"title": "Multi-Cue Adaptive Visual Token Pruning for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.08019", "details": "B Luan, W Zhou, H Feng, Z Wang, X Li, H Li - arXiv preprint arXiv:2503.08019, 2025", "abstract": "As the computational needs of Large Vision-Language Models (LVLMs) increase, visual token pruning has proven effective in improving inference speed and memory efficiency. Traditional pruning methods in LVLMs predominantly focus on attention \u2026"}, {"title": "Multidimensional Consistency Improves Reasoning in Language Models", "link": "https://arxiv.org/pdf/2503.02670", "details": "H Lai, X Zhang, M Nissim - arXiv preprint arXiv:2503.02670, 2025", "abstract": "While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across \u2026"}, {"title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models", "link": "https://arxiv.org/pdf/2503.01464", "details": "B Nazarov, D Frolova, Y Lubarsky, A Gaissinski\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed on domain-specific data has shown significant promise. However, commercial use of such LLMs is limited by the high computational cost required for their deployment at \u2026"}, {"title": "Enhanced Continual Learning of Vision-Language Models with Model Fusion", "link": "https://arxiv.org/pdf/2503.10705", "details": "H Gao, Z Zhang, Y Wei, L Zhao, G Li, Y Li, L Kong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-Language Models (VLMs) represent a breakthrough in artificial intelligence by integrating visual and textual modalities to achieve impressive zero-shot capabilities. However, VLMs are susceptible to catastrophic forgetting when sequentially fine \u2026"}, {"title": "From Captions to Rewards (CAREVL): Leveraging Large Language Model Experts for Enhanced Reward Modeling in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.06260", "details": "M Dai, J Sun, Z Zhao, S Liu, R Li, J Gao, X Li - arXiv preprint arXiv:2503.06260, 2025", "abstract": "Aligning large vision-language models (LVLMs) with human preferences is challenging due to the scarcity of fine-grained, high-quality, and multimodal preference data without human annotations. Existing methods relying on direct \u2026"}, {"title": "Can Memory-Augmented Language Models Generalize on Reasoning-in-a-Haystack Tasks?", "link": "https://arxiv.org/pdf/2503.07903", "details": "P Das, CY Ko, S Dai, G Kollias, S Chaudhury\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models often expose their brittleness in reasoning tasks, especially while executing long chains of reasoning over context. We propose MemReasoner, a new and simple memory-augmented LLM architecture, in which the memory learns \u2026"}]
