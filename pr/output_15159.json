[{"title": "STAF-LLM: A scalable and task-adaptive fine-tuning framework for large language models in medical domain", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425012047", "details": "T Xu, L Chen, Z Hu, B Li - Expert Systems with Applications, 2025", "abstract": "Recent large language models (LLMs) have demonstrated remarkable performance across various NLP tasks. However, their application in the medical domain is often limited by a lack of specialized medical knowledge, which is crucial for practical \u2026"}, {"title": "Distilling Structured Rationale from Large Language Models to Small Language Models for Abstractive Summarization", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34727/36882", "details": "L Wang, L Wu, S Song, Y Wang, C Gao, K Wang - \u2026 of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) have permeated various Natural Language Processing (NLP) tasks. For the summarization tasks, LLMs can generate well- structured rationales, which consist of Essential Aspects (EA), Associated Sentences \u2026"}, {"title": "Language Model Uncertainty Quantification with Attention Chain", "link": "https://arxiv.org/pdf/2503.19168", "details": "Y Li, R Qiang, L Moukheiber, C Zhang - arXiv preprint arXiv:2503.19168, 2025", "abstract": "Accurately quantifying a large language model's (LLM) predictive uncertainty is crucial for judging the reliability of its answers. While most existing research focuses on short, directly answerable questions with closed-form outputs (eg, multiple \u2026"}, {"title": "EvdCLIP: Improving Vision-Language Retrieval with Entity Visual Descriptions from Large Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/32655/34810", "details": "GH Meng, S He, J Wang, T Dai, L Zhang, J Zhu, Q Li\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "Vision-language retrieval (VLR) has attracted significant attention in both academia and industry, which involves using text (or images) as queries to retrieve corresponding images (or text). However, existing methods often neglect the rich \u2026"}, {"title": "CoMP: Continual Multimodal Pre-training for Vision Foundation Models", "link": "https://arxiv.org/pdf/2503.18931", "details": "Y Chen, L Meng, W Peng, Z Wu, YG Jiang - arXiv preprint arXiv:2503.18931, 2025", "abstract": "Pre-trained Vision Foundation Models (VFMs) provide strong visual representations for a wide range of applications. In this paper, we continually pre-train prevailing VFMs in a multimodal manner such that they can effortlessly process visual inputs of \u2026"}, {"title": "Breaking the Encoder Barrier for Seamless Video-Language Understanding", "link": "https://arxiv.org/pdf/2503.18422", "details": "H Li, Y Zhang, L Guo, X Yue, J Liu - arXiv preprint arXiv:2503.18422, 2025", "abstract": "Most Video-Large Language Models (Video-LLMs) adopt an encoder-decoder framework, where a vision encoder extracts frame-wise features for processing by a language model. However, this approach incurs high computational costs \u2026"}, {"title": "BiMAC: Bidirectional Multimodal Alignment in Contrastive Learning", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34384/36539", "details": "M Zareapoor, P Shamsolmoali, Y Lu - Proceedings of the AAAI Conference on \u2026, 2025", "abstract": "Achieving robust performance in vision-language tasks requires strong multimodal alignment, where textual and visual data interact seamlessly. Existing frameworks often combine contrastive learning with image captioning to unify visual and textual \u2026"}, {"title": "Map: Evaluation and multi-agent enhancement of large language models for inpatient pathways", "link": "https://arxiv.org/pdf/2503.13205%3F", "details": "Z Chen, Z Peng, X Liang, C Wang, P Liang, L Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited \u2026"}, {"title": "Privacy-Preserving Large Language Model for Matching Findings and Tracking Interval Changes in Longitudinal Radiology Reports", "link": "https://link.springer.com/article/10.1007/s10278-025-01478-7", "details": "TS Mathai, B Kim, OM Stroie, RM Summers - Journal of Imaging Informatics in \u2026, 2025", "abstract": "In current radiology practice, radiologists identify a finding in the current imaging exam, manually match it against the description from the prior exam report and assess interval changes. Large Language Models (LLMs) can identify report \u2026"}]
