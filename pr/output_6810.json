[{"title": "LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of Relational Knowledge in Language Models", "link": "https://arxiv.org/pdf/2408.15729", "details": "M Ploner, J Wiland, S Pohl, A Akbik - arXiv preprint arXiv:2408.15729, 2024", "abstract": "Knowledge probing evaluates the extent to which a language model (LM) has acquired relational knowledge during its pre-training phase. It provides a cost- effective means of comparing LMs of different sizes and training setups and is useful \u2026"}, {"title": "Promptriever: Instruction-Trained Retrievers Can Be Prompted Like Language Models", "link": "https://arxiv.org/pdf/2409.11136", "details": "O Weller, B Van Durme, D Lawrie, A Paranjape\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction-tuned language models (LM) are able to respond to imperative commands, providing a more natural user interface compared to their base counterparts. In this work, we present Promptriever, the first retrieval model able to be \u2026"}, {"title": "Exploring and Enhancing the Transfer of Distribution in Knowledge Distillation for Autoregressive Language Models", "link": "https://arxiv.org/pdf/2409.12512", "details": "J Rao, X Liu, Z Lin, L Ding, J Li, D Tao - arXiv preprint arXiv:2409.12512, 2024", "abstract": "Knowledge distillation (KD) is a technique that compresses large teacher models by training smaller student models to mimic them. The success of KD in auto-regressive language models mainly relies on Reverse KL for mode-seeking and student \u2026"}, {"title": "Improving the Efficiency of Visually Augmented Language Models", "link": "https://arxiv.org/pdf/2409.11148", "details": "P Ontalvilla, A Ormazabal, G Azkune - arXiv preprint arXiv:2409.11148, 2024", "abstract": "Despite the impressive performance of autoregressive Language Models (LM) it has been shown that due to reporting bias, LMs lack visual knowledge, ie they do not know much about the visual world and its properties. To augment LMs with visual \u2026"}, {"title": "Detecting AI Flaws: Target-Driven Attacks on Internal Faults in Language Models", "link": "https://arxiv.org/pdf/2408.14853", "details": "Y Du, Z Li, P Cheng, X Wan, A Gao - arXiv preprint arXiv:2408.14853, 2024", "abstract": "Large Language Models (LLMs) have become a focal point in the rapidly evolving field of artificial intelligence. However, a critical concern is the presence of toxic content within the pre-training corpus of these models, which can lead to the \u2026"}, {"title": "Language Models Learn to Mislead Humans via RLHF", "link": "https://arxiv.org/pdf/2409.12822", "details": "J Wen, R Zhong, A Khan, E Perez, J Steinhardt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) can produce errors that are hard to detect for humans, especially when the task is complex. RLHF, the most popular post-training method, may exacerbate this problem: to achieve higher rewards, LMs might get better at \u2026"}, {"title": "VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images", "link": "https://arxiv.org/pdf/2408.16176", "details": "M Maruf, A Daw, KS Mehrab, HB Manogaran, A Neog\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Images are increasingly becoming the currency for documenting biodiversity on the planet, providing novel opportunities for accelerating scientific discoveries in the field of organismal biology, especially with the advent of large vision-language models \u2026"}, {"title": "A Gradient Analysis Framework for Rewarding Good and Penalizing Bad Examples in Language Models", "link": "https://arxiv.org/pdf/2408.16751", "details": "YL Tuan, WY Wang - arXiv preprint arXiv:2408.16751, 2024", "abstract": "Beyond maximum likelihood estimation (MLE), the standard objective of a language model (LM) that optimizes good examples probabilities, many studies have explored ways that also penalize bad examples for enhancing the quality of output distribution \u2026"}, {"title": "Look, Compare, Decide: Alleviating Hallucination in Large Vision-Language Models via Multi-View Multi-Path Reasoning", "link": "https://arxiv.org/pdf/2408.17150", "details": "X Qu, J Sun, W Wei, Y Cheng - arXiv preprint arXiv:2408.17150, 2024", "abstract": "Recently, Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities in multi-modal context comprehension. However, they still suffer from hallucination problems referring to generating inconsistent outputs with the image \u2026"}]
