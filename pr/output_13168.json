[{"title": "Minerva: A Programmable Memory Test Benchmark for Language Models", "link": "https://arxiv.org/pdf/2502.03358%3F", "details": "M Xia, V Ruehle, S Rajmohan, R Shokri - arXiv preprint arXiv:2502.03358, 2025", "abstract": "How effectively can LLM-based AI assistants utilize their memory (context) to perform various tasks? Traditional data benchmarks, which are often manually crafted, suffer from several limitations: they are static, susceptible to overfitting, difficult to interpret \u2026"}, {"title": "CER: Confidence Enhanced Reasoning in LLMs", "link": "https://arxiv.org/pdf/2502.14634", "details": "A Razghandi, SMH Hosseini, MS Baghshah - arXiv preprint arXiv:2502.14634, 2025", "abstract": "Ensuring the reliability of Large Language Models (LLMs) in complex reasoning tasks remains a formidable challenge, particularly in scenarios that demand precise mathematical calculations and knowledge-intensive open-domain generation. In this \u2026"}, {"title": "Tool Learning in the Wild: Empowering Language Models as Automatic Tool Agents", "link": "https://openreview.net/pdf%3Fid%3DT4wMdeFEjX", "details": "Z Shi, S Gao, L Yan, Y Feng, X Chen, Z Chen, D Yin\u2026 - THE WEB CONFERENCE 2025", "abstract": "Augmenting large language models (LLMs) with external tools has emerged as a promising approach to extend their utility, enabling them to solve practical tasks. Previous methods manually parse tool documentation and create in-context \u2026"}, {"title": "Personalization Toolkit: Training Free Personalization of Large Vision Language Models", "link": "https://arxiv.org/pdf/2502.02452%3F", "details": "S Seifi, V Dorovatas, DO Reino, R Aljundi - arXiv preprint arXiv:2502.02452, 2025", "abstract": "Large Vision Language Models (LVLMs) have significant potential to deliver personalized assistance by adapting to individual users' unique needs and preferences. Personalization of LVLMs is an emerging area that involves \u2026"}, {"title": "Detecting LLM Fact-conflicting Hallucinations Enhanced by Temporal-logic-based Reasoning", "link": "https://arxiv.org/pdf/2502.13416", "details": "N Li, Y Song, K Wang, Y Li, L Shi, Y Liu, H Wang - arXiv preprint arXiv:2502.13416, 2025", "abstract": "Large language models (LLMs) face the challenge of hallucinations--outputs that seem coherent but are actually incorrect. A particularly damaging type is fact- conflicting hallucination (FCH), where generated content contradicts established \u2026"}, {"title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models", "link": "https://arxiv.org/pdf/2502.03199%3F", "details": "J Wu, Y Shen, S Liu, Y Tang, S Song, X Wang, L Cai - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the \u2026"}, {"title": "Reasoning with Reinforced Functional Token Tuning", "link": "https://arxiv.org/pdf/2502.13389", "details": "K Zhang, Q Yao, B Lai, J Huang, W Fang, D Tao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In this work, we propose Reinforced Functional Token Tuning (RFTT), a novel reinforced fine-tuning framework that empowers Large Language Models (LLMs) with self-play learn-to-reason capabilities. Unlike prior prompt-driven reasoning \u2026"}, {"title": "CALM: Unleashing the Cross-Lingual Self-Aligning Ability of Language Model Question Answering", "link": "https://arxiv.org/pdf/2501.18457%3F", "details": "Y Wang, Z Fan, Q Wang, M Fung, H Ji - arXiv preprint arXiv:2501.18457, 2025", "abstract": "Large Language Models (LLMs) are pretrained on extensive multilingual corpora to acquire both language-specific cultural knowledge and general knowledge. Ideally, while LLMs should provide consistent responses to culture-independent questions \u2026"}, {"title": "Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs", "link": "https://arxiv.org/pdf/2502.14645", "details": "Y Wu, L Ding, L Shen, D Tao - arXiv preprint arXiv:2502.14645, 2025", "abstract": "Knowledge editing allows for efficient adaptation of large language models (LLMs) to new information or corrections without requiring full retraining. However, prior methods typically focus on either single-language editing or basic multilingual \u2026"}]
