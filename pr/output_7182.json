[{"title": "In Defense of RAG in the Era of Long-Context Language Models", "link": "https://arxiv.org/pdf/2409.01666", "details": "T Yu, A Xu, R Akkiraju - arXiv preprint arXiv:2409.01666, 2024", "abstract": "Overcoming the limited context limitations in early-generation LLMs, retrieval- augmented generation (RAG) has been a reliable solution for context-based answer generation in the past. Recently, the emergence of long-context LLMs allows the \u2026"}, {"title": "OLMoE: Open Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2409.02060", "details": "N Muennighoff, L Soldaini, D Groeneveld, K Lo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce OLMoE, a fully open, state-of-the-art language model leveraging sparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but uses only 1B per input token. We pretrain it on 5 trillion tokens and further adapt it to \u2026"}, {"title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries", "link": "https://arxiv.org/pdf/2409.00844", "details": "B Yang, F Cui, K Paster, J Ba, P Vaezipoor, S Pitis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid development and dynamic nature of large language models (LLMs) make it difficult for conventional quantitative benchmarks to accurately assess their capabilities. We propose report cards, which are human-interpretable, natural \u2026"}, {"title": "Health professionals' perceptions of electronic health records system: a mixed method study in Ghana", "link": "https://link.springer.com/article/10.1186/s12911-024-02672-3", "details": "NK Mensah, G Adzakpah, J Kissi, K Abdulai\u2026 - BMC Medical Informatics \u2026, 2024", "abstract": "Abstract Background Electronic Health Record systems (EHRs) offer significant benefits and have transformed healthcare in developed countries. However, their implementation and adoption in low-and middle-income countries (LMICs) remains \u2026"}, {"title": "Assessing Electronic Health Records for Describing Racial and Ethnic Health Disparities: A Research Note", "link": "https://read.dukeupress.edu/demography/article-pdf/doi/10.1215/00703370-11582088/2147349/11582088.pdf", "details": "A Limburg, J Young, TS Carey, PR Chelminski\u2026 - Demography, 2024", "abstract": "The use of data derived from electronic health records (EHRs) to describe racial and ethnic health disparities is increasingly common, but there are challenges. While the number of patients covered by EHRs can be quite large, such patients may not be \u2026"}, {"title": "Extracting lung cancer staging descriptors from pathology reports: A generative language model approach", "link": "https://www.sciencedirect.com/science/article/pii/S1532046424001382", "details": "H Cho, S Yoo, B Kim, S Jang, L Sunwoo, S Kim, D Lee\u2026 - Journal of Biomedical \u2026, 2024", "abstract": "Background In oncology, electronic health records contain textual key information for the diagnosis, staging, and treatment planning of patients with cancer. However, text data processing requires a lot of time and effort, which limits the utilization of these \u2026"}, {"title": "Training Language Models to Self-Correct via Reinforcement Learning", "link": "https://arxiv.org/pdf/2409.12917", "details": "A Kumar, V Zhuang, R Agarwal, Y Su, JD Co-Reyes\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-correction is a highly desirable capability of large language models (LLMs), yet it has consistently been found to be largely ineffective in modern LLMs. Existing approaches for training self-correction either require multiple models or rely on a \u2026"}, {"title": "Instruct-Tuning Pretrained Causal Language Models for Ancient Greek Papyrology and Epigraphy", "link": "https://arxiv.org/pdf/2409.13870", "details": "E Cullhed - arXiv preprint arXiv:2409.13870, 2024", "abstract": "This article presents an experiment in fine-tuning a pretrained causal language model (Meta's Llama 3.1 8B Instruct) for aiding in three fundamental tasks of philological research: chronological and geographic attribution as well as text \u2026"}, {"title": "How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model?", "link": "https://arxiv.org/pdf/2409.02253", "details": "SA Taghanaki, J Lambourne, A Mongkhounsavath - arXiv preprint arXiv:2409.02253, 2024", "abstract": "Large foundation models have revolutionized the field, yet challenges remain in optimizing multi-modal models for specialized visual tasks. We propose a novel, generalizable methodology to identify preferred image distributions for black-box \u2026"}]
