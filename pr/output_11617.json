[{"title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models", "link": "https://arxiv.org/pdf/2501.05752", "details": "S Lee, H Park, J Kim, J Ok - arXiv preprint arXiv:2501.05752, 2025", "abstract": "Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer \u2026"}, {"title": "Exploring scalable medical image encoders beyond text supervision", "link": "https://www.nature.com/articles/s42256-024-00965-w", "details": "F P\u00e9rez-Garc\u00eda, H Sharma, S Bond-Taylor, K Bouzid\u2026 - Nature Machine Intelligence, 2025", "abstract": "Abstract Language-supervised pretraining has proven to be a valuable method for extracting semantically meaningful features from images, serving as a foundational element in multimodal systems within the computer vision and medical imaging \u2026"}, {"title": "Using Large Language Models to Promote Health Equity", "link": "https://ai.nejm.org/doi/full/10.1056/AIp2400889", "details": "E Pierson, D Shanmugam, R Movva, J Kleinberg\u2026 - NEJM AI, 2025", "abstract": "While the discussion about the effects of large language models (LLMs) on health equity has been largely cautionary, LLMs also present significant opportunities for improving health equity. We highlight three such opportunities: improving the \u2026"}, {"title": "ChartAdapter: Large Vision-Language Model for Chart Summarization", "link": "https://arxiv.org/pdf/2412.20715", "details": "P Xu, Y Ding, W Fan - arXiv preprint arXiv:2412.20715, 2024", "abstract": "Chart summarization, which focuses on extracting key information from charts and interpreting it in natural language, is crucial for generating and delivering insights through effective and accessible data analysis. Traditional methods for chart \u2026"}]
