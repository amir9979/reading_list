[{"title": "Disentangled Prompt Representation for Domain Generalization", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Cheng_Disentangled_Prompt_Representation_for_Domain_Generalization_CVPR_2024_paper.pdf", "details": "D Cheng, Z Xu, X Jiang, N Wang, D Li, X Gao - \u2026 of the IEEE/CVF Conference on \u2026, 2024", "abstract": "Abstract Domain Generalization (DG) aims to develop a versatile model capable of performing well on unseen target domains. Recent advancements in pre-trained Visual Foundation Models (VFMs) such as CLIP show significant potential in \u2026"}, {"title": "AUTOLYCUS: Exploiting Explainable Artificial Intelligence (XAI) for Model Extraction Attacks against Interpretable Models", "link": "https://petsymposium.org/popets/2024/popets-2024-0137.pdf", "details": "AC Oksuz, A Halimi, E Ayday - Proceedings on Privacy Enhancing Technologies, 2024", "abstract": "ABSTRACT Explainable Artificial Intelligence (XAI) aims to uncover the decisionmaking processes of AI models. However, the data used for such explanations can pose security and privacy risks. Existing literature identifies attacks \u2026"}, {"title": "ConcVAE: Conceptual Representation Learning", "link": "https://ieeexplore.ieee.org/iel8/5962385/6104215/10584324.pdf", "details": "R Togo, N Nakagawa, T Ogawa, M Haseyama - IEEE Transactions on Neural \u2026, 2024", "abstract": "Disentangled representation learning aims at obtaining an independent latent representation without supervisory signals. However, the independence of a representation does not guarantee interpretability to match human intuition in the \u2026"}]
