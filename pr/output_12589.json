[{"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "RadVLM: A Multitask Conversational Vision-Language Model for Radiology", "link": "https://arxiv.org/pdf/2502.03333", "details": "N Deperrois, H Matsuo, S Ruip\u00e9rez-Campillo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The widespread use of chest X-rays (CXRs), coupled with a shortage of radiologists, has driven growing interest in automated CXR analysis and AI-assisted reporting. While existing vision-language models (VLMs) show promise in specific tasks such \u2026"}, {"title": "Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment", "link": "https://arxiv.org/pdf/2502.02438", "details": "Y Shen, Z Zhuang, K Yuan, MI Nicolae, N Navab\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical multimodal large language models (MLLMs) are becoming an instrumental part of healthcare systems, assisting medical personnel with decision making and results analysis. Models for radiology report generation are able to interpret medical \u2026"}, {"title": "A multimodal multidomain multilingual medical foundation model for zero shot clinical diagnosis", "link": "https://www.nature.com/articles/s41746-024-01339-7", "details": "F Liu, Z Li, Q Yin, J Huang, J Luo, A Thakur, K Branson\u2026 - npj Digital Medicine, 2025", "abstract": "Radiology images are one of the most commonly used in daily clinical diagnosis. Typically, clinical diagnosis using radiology images involves disease reporting and classification, where the former is a multimodal task whereby textual reports are \u2026"}, {"title": "Vision-Language Model Dialog Games for Self-Improvement", "link": "https://arxiv.org/pdf/2502.02740", "details": "K Konyushkova, C Kaplanis, S Cabi, M Denil - arXiv preprint arXiv:2502.02740, 2025", "abstract": "The increasing demand for high-quality, diverse training data poses a significant bottleneck in advancing vision-language models (VLMs). This paper presents VLM Dialog Games, a novel and scalable self-improvement framework for VLMs. Our \u2026"}, {"title": "Efficient Vision Language Model Fine-tuning for Text-based Person Anomaly Search", "link": "https://arxiv.org/pdf/2502.03230", "details": "J He, S Tang, A Liu, L Cheng, J Wu, Y Wei - arXiv preprint arXiv:2502.03230, 2025", "abstract": "This paper presents the HFUT-LMC team's solution to the WWW 2025 challenge on Text-based Person Anomaly Search (TPAS). The primary objective of this challenge is to accurately identify pedestrians exhibiting either normal or abnormal behavior \u2026"}]
