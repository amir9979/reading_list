[{"title": "The Art of Saying No: Contextual Noncompliance in Language Models", "link": "https://arxiv.org/pdf/2407.12043", "details": "F Brahman, S Kumar, V Balachandran, P Dasigi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Chat-based language models are designed to be helpful, yet they should not comply with every user request. While most existing work primarily focuses on refusal of\" unsafe\" queries, we posit that the scope of noncompliance should be broadened. We \u2026"}, {"title": "Confidence Regulation Neurons in Language Models", "link": "https://arxiv.org/pdf/2406.16254", "details": "A Stolfo, B Wu, W Gurnee, Y Belinkov, X Song\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their widespread use, the mechanisms by which large language models (LLMs) represent and regulate uncertainty in next-token predictions remain largely unexplored. This study investigates two critical components believed to influence this \u2026"}, {"title": "OQA: A question-answering dataset on orthodontic literature", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/07/07/2024.07.05.24309412.full.pdf", "details": "M Rousseau, A Zouaq, N Huynh - medRxiv, 2024", "abstract": "Background The near-exponential increase in the number of publications in orthodontics poses a challenge for efficient literature appraisal and evidence-based practice. Language models (LM) have the potential, through their question \u2026"}, {"title": "E5-V: Universal Embeddings with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2407.12580", "details": "T Jiang, M Song, Z Zhang, H Huang, W Deng, F Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal large language models (MLLMs) have shown promising advancements in general visual and language understanding. However, the representation of multimodal information using MLLMs remains largely unexplored. In this work, we \u2026"}, {"title": "A Training Data Recipe to Accelerate A* Search with Language Models", "link": "https://arxiv.org/pdf/2407.09985", "details": "D Gupta, B Li - arXiv preprint arXiv:2407.09985, 2024", "abstract": "Recent works in AI planning have proposed to combine LLMs with iterative tree- search algorithms like A* and MCTS, where LLMs are typically used to calculate the heuristic, guiding the planner towards the goal. However, combining these \u2026"}, {"title": "GPT-4V Cannot Generate Radiology Reports Yet", "link": "https://arxiv.org/pdf/2407.12176", "details": "Y Jiang, C Chen, D Nguyen, BM Mervak, C Tan - arXiv preprint arXiv:2407.12176, 2024", "abstract": "GPT-4V's purported strong multimodal abilities raise interests in using it to automate radiology report writing, but there lacks thorough evaluations. In this work, we perform a systematic evaluation of GPT-4V in generating radiology reports on two \u2026"}, {"title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought", "link": "https://arxiv.org/pdf/2406.13940", "details": "Y Zhang, Q Chen, M Li, W Che, L Qin - arXiv preprint arXiv:2406.13940, 2024", "abstract": "Cross-lingual chain-of-thought can effectively complete reasoning tasks across languages, which gains increasing attention. Recently, dominant approaches in the literature improve cross-lingual alignment capabilities by integrating reasoning \u2026"}, {"title": "Pseudo-triplet Guided Few-shot Composed Image Retrieval", "link": "https://arxiv.org/pdf/2407.06001", "details": "B Hou, H Lin, H Wen, M Liu, X Song - arXiv preprint arXiv:2407.06001, 2024", "abstract": "Composed Image Retrieval (CIR) is a challenging task that aims to retrieve the target image based on a multimodal query, ie, a reference image and its corresponding modification text. While previous supervised or zero-shot learning paradigms all fail \u2026"}, {"title": "Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary", "link": "https://arxiv.org/pdf/2406.14500", "details": "X Zhao, T Wang, A Rios - arXiv preprint arXiv:2406.14500, 2024", "abstract": "Radiology report summarization (RRS) is crucial for patient care, requiring concise\" Impressions\" from detailed\" Findings.\" This paper introduces a novel prompting strategy to enhance RRS by first generating a layperson summary. This approach \u2026"}]
