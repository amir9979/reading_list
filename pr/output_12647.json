[{"title": "ELAINE-medLLM: Lightweight English Japanese Chinese Trilingual Large Language Model for Bio-medical Domain", "link": "https://aclanthology.org/2025.coling-main.313.pdf", "details": "K Yano, Z Luo, J Huang, Q Xie, M Asada, C Yuan\u2026 - Proceedings of the 31st \u2026, 2025", "abstract": "Abstract We propose ELAINE (EngLish-jApanese-chINesE)-medLLM, a trilingual (English, Japanese, Chinese) large language model adapted for the bio-medical domain based on Llama-3-8B. The training dataset was carefully curated in terms of \u2026"}, {"title": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment", "link": "https://arxiv.org/pdf/2501.07525", "details": "D Gu, Y Gao, Y Zhou, M Zhou, D Metaxas - arXiv preprint arXiv:2501.07525, 2025", "abstract": "Automated chest radiographs interpretation requires both accurate disease classification and detailed radiology report generation, presenting a significant challenge in the clinical workflow. Current approaches either focus on classification \u2026"}, {"title": "MedS $^ 3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking", "link": "https://arxiv.org/pdf/2501.12051%3F", "details": "S Jiang, Y Liao, Z Chen, Y Zhang, Y Wang, Y Wang - arXiv preprint arXiv:2501.12051, 2025", "abstract": "Medical language models (MLMs) have become pivotal in advancing medical natural language processing. However, prior models that rely on pre-training or supervised fine-tuning often exhibit low data efficiency and limited practicality in real \u2026"}, {"title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models", "link": "https://arxiv.org/pdf/2501.05752", "details": "S Lee, H Park, J Kim, J Ok - arXiv preprint arXiv:2501.05752, 2025", "abstract": "Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer \u2026"}, {"title": "Hierarchical Autoregressive Transformers: Combining Byte-and Word-Level Processing for Robust, Adaptable Language Models", "link": "https://arxiv.org/pdf/2501.10322", "details": "P Neitemeier, B Deiseroth, C Eichenberg, L Balles - arXiv preprint arXiv:2501.10322, 2025", "abstract": "Tokenization is a fundamental step in natural language processing, breaking text into units that computational models can process. While learned subword tokenizers have become the de-facto standard, they present challenges such as large \u2026"}, {"title": "How to Bridge the Gap between Modalities: Survey on Multimodal Large Language Model", "link": "https://ieeexplore.ieee.org/abstract/document/10841938/", "details": "S Song, X Li, S Li, S Zhao, J Yu, J Ma, X Mao, W Zhang\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "We explore Multimodal Large Language Models (MLLMs), which integrate LLMs like GPT-4 to handle multimodal data, including text, images, audio, and more. MLLMs demonstrate capabilities such as generating image captions and answering image \u2026"}, {"title": "Decoding substance use disorder severity from clinical notes using a large language model", "link": "https://www.nature.com/articles/s44184-024-00114-6", "details": "M Mahbub, GM Dams, S Srinivasan, C Rizy, I Danciu\u2026 - npj Mental Health Research, 2025", "abstract": "Substance use disorder (SUD) poses a major concern due to its detrimental effects on health and society. SUD identification and treatment depend on a variety of factors such as severity, co-determinants (eg, withdrawal symptoms), and social \u2026"}, {"title": "FDAC: Federated Domain Adaptation via Dual Contrastive Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10870286/", "details": "H Chen, Y Zhang, Y Xu, Y Zhou, L Cui, H Yu - \u2026 on Circuits and Systems for Video \u2026, 2025", "abstract": "Federated domain adaptation (FDA) aims to transfer knowledge collaboratively from multiple source domains to related but different unlabelled target domains. The data of each domain are locally maintained, and various domain gaps exist among them \u2026"}, {"title": "DuCo-Net: Dual-Contrastive Learning Network for Medical Report Retrieval Leveraging Enhanced Encoders and Augmentations", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10870249.pdf", "details": "ZU Rahman, JH Lee, DT Vu, I Murtza, JY Kim - IEEE Access, 2025", "abstract": "The conventional process of generating medical radiology reports is labor-intensive and time-consuming, requiring radiologists to describe findings meticulously from imaging studies. This manual approach often causes undesirable delays in patient \u2026"}]
