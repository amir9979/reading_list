[{"title": "RAG-Modulo: Solving Sequential Tasks using Experience, Critics, and Language Models", "link": "https://arxiv.org/pdf/2409.12294", "details": "A Jain, C Jermaine, V Unhelkar - arXiv preprint arXiv:2409.12294, 2024", "abstract": "Large language models (LLMs) have recently emerged as promising tools for solving challenging robotic tasks, even in the presence of action and observation uncertainties. Recent LLM-based decision-making methods (also referred to as LLM \u2026"}, {"title": "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models", "link": "https://arxiv.org/pdf/2409.17455", "details": "Y Zhou, R Tang, Z Yao, Z Zhu - arXiv preprint arXiv:2409.17455, 2024", "abstract": "Language models (LMs), despite their advances, often depend on spurious correlations, undermining their accuracy and generalizability. This study addresses the overlooked impact of subtler, more complex shortcuts that compromise model \u2026"}, {"title": "Gauging, enriching and applying geography knowledge in Pre-trained Language Models", "link": "https://www.sciencedirect.com/science/article/pii/S0306457324002516", "details": "N Ramrakhiyani, V Varma, GK Palshikar, S Pawar - Information Processing & \u2026, 2025", "abstract": "Abstract To employ Pre-trained Language Models (PLMs) as knowledge containers in niche domains it is important to gauge the knowledge of these PLMs about facts in these domains. It is also an important pre-requisite to know how much enrichment \u2026"}, {"title": "Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies", "link": "https://arxiv.org/pdf/2409.17216", "details": "R Gupta, L Walker, R Corona, S Fu, S Petryk\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Current regulations on powerful AI capabilities are narrowly focused on\" foundation\" or\" frontier\" models. However, these terms are vague and inconsistently defined, leading to an unstable foundation for governance efforts. Critically, policy debates \u2026"}, {"title": "Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data", "link": "https://arxiv.org/pdf/2409.12437", "details": "J Zhou, A Ghaddar, G Zhang, L Ma, Y Hu, S Pal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite recent advances in training and prompting strategies for Large Language Models (LLMs), these models continue to face challenges with complex logical reasoning tasks that involve long reasoning chains. In this work, we explore the \u2026"}, {"title": "HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows", "link": "https://arxiv.org/pdf/2409.17433", "details": "W Yao, H Mi, D Yu - arXiv preprint arXiv:2409.17433, 2024", "abstract": "Despite recent advancements in large language models (LLMs), their performance on complex reasoning problems requiring multi-step thinking and combining various skills is still limited. To address this, we propose a novel framework HDFlow for \u2026"}, {"title": "Inference-Time Language Model Alignment via Integrated Value Guidance", "link": "https://arxiv.org/pdf/2409.17819", "details": "Z Liu, Z Zhou, Y Wang, C Yang, Y Qiao - arXiv preprint arXiv:2409.17819, 2024", "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce $\\textit {Integrated Value Guidance} $(IVG), a method that uses implicit and \u2026"}, {"title": "Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness", "link": "https://arxiv.org/pdf/2409.17791", "details": "J Li, H Huang, Y Zhang, P Xu, X Chen, R Song, L Shi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, there has been significant interest in replacing the reward model in Reinforcement Learning with Human Feedback (RLHF) methods for Large Language Models (LLMs), such as Direct Preference Optimization (DPO) and its \u2026"}, {"title": "SpecEval: Evaluating Code Comprehension in Large Language Models via Program Specifications", "link": "https://arxiv.org/pdf/2409.12866", "details": "L Ma, S Liu, L Bu, S Li, Y Wang, Y Liu - arXiv preprint arXiv:2409.12866, 2024", "abstract": "Large Language models have achieved impressive performance in automated software engineering. Extensive efforts have been made to evaluate the abilities of code LLMs in various aspects, with an increasing number of benchmarks and \u2026"}]
