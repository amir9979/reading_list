[{"title": "A MapReduce Approach to Effectively Utilize Long Context Information in Retrieval Augmented Language Models", "link": "https://arxiv.org/pdf/2412.15271", "details": "G Zhang, Z Xu, Q Jin, F Chen, Y Fang, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While holding great promise for improving and facilitating healthcare, large language models (LLMs) struggle to produce up-to-date responses on evolving topics due to outdated knowledge or hallucination. Retrieval-augmented generation (RAG) is a \u2026"}, {"title": "HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding", "link": "https://arxiv.org/pdf/2412.16158", "details": "C Tao, S Su, X Zhu, C Zhang, Z Chen, J Liu, W Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advance of Large Language Models (LLMs) has catalyzed the development of Vision-Language Models (VLMs). Monolithic VLMs, which avoid modality-specific encoders, offer a promising alternative to the compositional ones \u2026"}, {"title": "Large language models for extracting histopathologic diagnoses from electronic health records", "link": "https://www.medrxiv.org/content/10.1101/2024.11.27.24318083.full.pdf", "details": "B Johnson, T Bath, X Huang, M Lamm, A Earles\u2026 - medRxiv, 2024", "abstract": "Background & Aims Accurate data resources are essential for impactful medical research. To date, most large-scale studies have relied on structured sources, such as International Classification of Diseases codes, to determine patient diagnoses \u2026"}, {"title": "Preparing for future pandemics: Automated intensive care electronic health record data extraction to accelerate clinical insights", "link": "https://www.sciencedirect.com/science/article/pii/S2667100X24001051", "details": "L Lijovi\u0107, HJ de Grooth, P Thoral, L Bos, Z Feng\u2026 - Journal of Intensive \u2026, 2024", "abstract": "Background Manual data abstraction from electronic health records (EHRs) for research on intensive care patients is time-intensive and challenging, especially during high-pressure periods such as pandemics. Automated data extraction is a \u2026"}, {"title": "Multimodal Whole Slide Foundation Model for Pathology", "link": "https://arxiv.org/pdf/2411.19666", "details": "T Ding, SJ Wagner, AH Song, RJ Chen, MY Lu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The field of computational pathology has been transformed with recent advances in foundation models that encode histopathology region-of-interests (ROIs) into versatile and transferable feature representations via self-supervised learning (SSL) \u2026"}, {"title": "Training Agents with Weakly Supervised Feedback from Large Language Models", "link": "https://arxiv.org/pdf/2411.19547", "details": "D Gong, P Lu, Z Wang, M Zhou, X He - arXiv preprint arXiv:2411.19547, 2024", "abstract": "Large Language Models (LLMs) offer a promising basis for creating agents that can tackle complex tasks through iterative environmental interaction. Existing methods either require these agents to mimic expert-provided trajectories or rely on definitive \u2026"}, {"title": "Frequency Is What You Need: Word-frequency Masking Benefits Vision-Language Model Pre-training", "link": "https://arxiv.org/pdf/2412.16148", "details": "M Liang, M Larson - arXiv preprint arXiv:2412.16148, 2024", "abstract": "Vision Language Models (VLMs) can be trained more efficiently if training sets can be reduced in size. Recent work has shown the benefits of masking text during VLM training using a variety of approaches: truncation, random masking, block masking \u2026"}, {"title": "DnDScore: Decontextualization and Decomposition for Factuality Verification in Long-Form Text Generation", "link": "https://arxiv.org/pdf/2412.13175", "details": "M Wanner, B Van Durme, M Dredze - arXiv preprint arXiv:2412.13175, 2024", "abstract": "The decompose-then-verify strategy for verification of Large Language Model (LLM) generations decomposes claims that are then independently verified. Decontextualization augments text (claims) to ensure it can be verified outside of the \u2026"}, {"title": "OG-RAG: Ontology-Grounded Retrieval-Augmented Generation For Large Language Models", "link": "https://arxiv.org/pdf/2412.15235", "details": "K Sharma, P Kumar, Y Li - arXiv preprint arXiv:2412.15235, 2024", "abstract": "This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented Generation method designed to enhance LLM-generated responses by anchoring retrieval processes in domain-specific ontologies. While LLMs are widely used for \u2026"}]
