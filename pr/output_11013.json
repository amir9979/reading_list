[{"title": "GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2412.21036", "details": "S Xing, C Xiang, Y Han, Y Yue, Z Wu, X Liu, Z Wu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal large language models (MLLMs) have achieved significant advancements in integrating visual and linguistic understanding. While existing benchmarks evaluate these models in context-rich, real-life scenarios, they often \u2026"}, {"title": "MetaRuleGPT: Recursive Numerical Reasoning of Language Models Trained with Simple Rules", "link": "https://arxiv.org/pdf/2412.13536", "details": "K Chen, L Wang, Q Zhang, R Xu - arXiv preprint arXiv:2412.13536, 2024", "abstract": "Recent studies have highlighted the limitations of large language models in mathematical reasoning, particularly their inability to capture the underlying logic. Inspired by meta-learning, we propose that models should acquire not only task \u2026"}, {"title": "Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge Distillation on Language Models", "link": "https://arxiv.org/pdf/2412.14528", "details": "X Cui, M Zhu, Y Qin, L Xie, W Zhou, H Li - arXiv preprint arXiv:2412.14528, 2024", "abstract": "Knowledge distillation (KD) has become a prevalent technique for compressing large language models (LLMs). Existing KD methods are constrained by the need for identical tokenizers (ie, vocabularies) between teacher and student models, limiting \u2026"}, {"title": "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces", "link": "https://arxiv.org/pdf/2412.14171%3F", "details": "J Yang, S Yang, AW Gupta, R Han, L Fei-Fei, S Xie - arXiv preprint arXiv:2412.14171, 2024", "abstract": "Humans possess the visual-spatial intelligence to remember spaces from sequential visual observations. However, can Multimodal Large Language Models (MLLMs) trained on million-scale video datasets also``think in space''from videos? We present \u2026"}, {"title": "Smoothed Embeddings for Robust Language Models", "link": "https://www.merl.com/publications/docs/TR2024-170.pdf", "details": "H Ryo, MRU Rashid, A Lewis, J Liu, T Koike-Akino\u2026", "abstract": "Improving the safety and reliability of large language models (LLMs) is a crucial aspect of realizing trustworthy AI systems. Although alignment methods aim to suppress harmful content generation, LLMs are often still vulnerable to jail-breaking \u2026"}, {"title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models", "link": "https://arxiv.org/pdf/2412.15287", "details": "Y Chow, G Tennenholtz, I Gur, V Zhuang, B Dai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent studies have indicated that effectively utilizing inference-time compute is crucial for attaining better performance from large language models (LLMs). In this work, we propose a novel inference-aware fine-tuning paradigm, in which the model \u2026"}, {"title": "OG-RAG: Ontology-Grounded Retrieval-Augmented Generation For Large Language Models", "link": "https://arxiv.org/pdf/2412.15235", "details": "K Sharma, P Kumar, Y Li - arXiv preprint arXiv:2412.15235, 2024", "abstract": "This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented Generation method designed to enhance LLM-generated responses by anchoring retrieval processes in domain-specific ontologies. While LLMs are widely used for \u2026"}, {"title": "KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation", "link": "https://arxiv.org/pdf/2412.20995", "details": "S Fang, K Ma, T Zheng, X Du, N Lu, G Zhang, Q Tang - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) demonstrate exceptional performance across a variety of tasks, yet they are often affected by hallucinations and the timeliness of knowledge. Leveraging knowledge graphs (KGs) as external knowledge sources \u2026"}, {"title": "CareBot: A Pioneering Full-Process Open-Source Medical Language Model", "link": "https://arxiv.org/pdf/2412.15236", "details": "L Zhao, W Zeng, X Shi, H Zhou - arXiv preprint arXiv:2412.15236, 2024", "abstract": "Recently, both closed-source LLMs and open-source communities have made significant strides, outperforming humans in various general domains. However, their performance in specific professional domains such as medicine, especially within the \u2026"}]
