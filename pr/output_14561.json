[{"title": "BiasICL: In-Context Learning and Demographic Biases of Vision Language Models", "link": "https://arxiv.org/pdf/2503.02334", "details": "S Xu, J Janizek, Y Jiang, R Daneshjou - arXiv preprint arXiv:2503.02334, 2025", "abstract": "Vision language models (VLMs) show promise in medical diagnosis, but their performance across demographic subgroups when using in-context learning (ICL) remains poorly understood. We examine how the demographic composition of \u2026"}, {"title": "X2CT-CLIP: Enable Multi-Abnormality Detection in Computed Tomography from Chest Radiography via Tri-Modal Contrastive Learning", "link": "https://arxiv.org/pdf/2503.02162", "details": "J You, Y Gao, S Kim, C Mcintosh - arXiv preprint arXiv:2503.02162, 2025", "abstract": "Computed tomography (CT) is a key imaging modality for diagnosis, yet its clinical utility is marred by high radiation exposure and long turnaround times, restricting its use for larger-scale screening. Although chest radiography (CXR) is more accessible \u2026"}, {"title": "Applying Realist Retroduction to EHR-Based Clinical Decision Support Tool Development", "link": "https://journals.sagepub.com/doi/full/10.1177/16094069251326415", "details": "S Morrissey, A Bunce, J Donovan, B McGrath\u2026 - International Journal of \u2026, 2025", "abstract": "The application of realist-informed approaches to implementation research can produce answers to why, for whom and under what circumstances social determinants of health interventions work. In the context of a study to develop and \u2026"}, {"title": "BPQA Dataset: Evaluating How Well Language Models Leverage Blood Pressures to Answer Biomedical Questions", "link": "https://arxiv.org/pdf/2503.04155", "details": "C Hang, R Deng, LY Jiang, Z Yang, A Alyakin, D Alber\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Clinical measurements such as blood pressures and respiration rates are critical in diagnosing and monitoring patient outcomes. It is an important component of biomedical data, which can be used to train transformer-based language models \u2026"}, {"title": "LEVERAGING VISUAL FOUNDATION MODEL FOR ECHOCARDIOGRAPHY WORKFLOW ENHANCEMENT", "link": "https://www.jacc.org/doi/full/10.1016/S0735-1097%252825%252903068-2", "details": "CJ Chao, Y Gu, W Kumar, T Xiang, L Appari, J Farina\u2026 - Journal of the American \u2026, 2025", "abstract": "Background The vision foundation model,\u201cSegment Anything (SAM),\u201d promises to segment any objects in images. However, the performance of SAM on clinical echocardiography images has yet to be investigated and compared against the state \u2026"}, {"title": "Few-Shot Whole Slide Pathology Classification with Multi-Granular Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3DnJZtYrOeoV", "details": "AT Nguyen, DMH Nguyen, NT Diep, TQ Nguyen, N Ho\u2026 - \u2026 on Foundation Models in the Wild", "abstract": "In this study, we propose a novel architecture for a large vision-language model adapted with a multi-granular prompt learning method to advance few-shot pathol- ogy classification. Starting with the Prov-GigaPath foundation model-pre-trained on \u2026"}, {"title": "MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems", "link": "https://arxiv.org/pdf/2503.03686", "details": "R Ye, S Tang, R Ge, Y Du, Z Yin, S Chen, J Shao - arXiv preprint arXiv:2503.03686, 2025", "abstract": "LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks. However, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability \u2026"}, {"title": "Towards a holistic framework for multimodal LLM in 3D brain CT radiology report generation", "link": "https://www.nature.com/articles/s41467-025-57426-0", "details": "CY Li, KJ Chang, CF Yang, HY Wu, W Chen, H Bansal\u2026 - Nature Communications, 2025", "abstract": "Multi-modal large language models (MLLMs) have transformed the landscape of modern healthcare, with automated radiology report generation (RRG) emerging as a cutting-edge application. While 2D MLLM-based RRG has been well established \u2026"}]
