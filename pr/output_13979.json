[{"title": "MindGYM: Enhancing Vision-Language Models via Synthetic Self-Challenging Questions", "link": "https://arxiv.org/pdf/2503.09499", "details": "Z Xu, D Chen, Z Ling, Y Li, Y Shen - arXiv preprint arXiv:2503.09499, 2025", "abstract": "Large vision-language models (VLMs) face challenges in achieving robust, transferable reasoning abilities due to reliance on labor-intensive manual instruction datasets or computationally expensive self-supervised methods. To address these \u2026"}, {"title": "Words or Vision: Do Vision-Language Models Have Blind Faith in Text?", "link": "https://arxiv.org/pdf/2503.02199", "details": "A Deng, T Cao, Z Chen, B Hooi - arXiv preprint arXiv:2503.02199, 2025", "abstract": "Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual \u2026"}, {"title": "Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving", "link": "https://arxiv.org/pdf/2503.06497", "details": "E Zhang, P Gong, X Dai, Y Lv, Q Miao - arXiv preprint arXiv:2503.06497, 2025", "abstract": "Assessing the safety of vision-language models (VLMs) in autonomous driving is particularly important; however, existing work mainly focuses on traditional benchmark evaluations. As interactive components within autonomous driving \u2026"}, {"title": "Boosting the Generalization and Reasoning of Vision Language Models with Curriculum Reinforcement Learning", "link": "https://arxiv.org/pdf/2503.07065", "details": "H Deng, D Zou, R Ma, H Luo, Y Cao, Y Kang - arXiv preprint arXiv:2503.07065, 2025", "abstract": "While state-of-the-art vision-language models (VLMs) have demonstrated remarkable capabilities in complex visual-text tasks, their success heavily relies on massive model scaling, limiting their practical deployment. Small-scale VLMs offer a \u2026"}, {"title": "UrbanVideo-Bench: Benchmarking Vision-Language Models on Embodied Intelligence with Video Data in Urban Spaces", "link": "https://arxiv.org/pdf/2503.06157", "details": "B Zhao, J Fang, Z Dai, Z Wang, J Zha, W Zhang, C Gao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large multimodal models exhibit remarkable intelligence, yet their embodied cognitive abilities during motion in open-ended urban 3D space remain to be explored. We introduce a benchmark to evaluate whether video-large language \u2026"}, {"title": "From Captions to Rewards (CAREVL): Leveraging Large Language Model Experts for Enhanced Reward Modeling in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.06260", "details": "M Dai, J Sun, Z Zhao, S Liu, R Li, J Gao, X Li - arXiv preprint arXiv:2503.06260, 2025", "abstract": "Aligning large vision-language models (LVLMs) with human preferences is challenging due to the scarcity of fine-grained, high-quality, and multimodal preference data without human annotations. Existing methods relying on direct \u2026"}, {"title": "LLaVA-RadZ: Can Multimodal Large Language Models Effectively Tackle Zero-shot Radiology Recognition?", "link": "https://arxiv.org/pdf/2503.07487", "details": "B Li, W Huang, Y Shen, Y Wang, S Lin, J Lin, L You\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, multimodal large models (MLLMs) have demonstrated exceptional capabilities in visual understanding and reasoning across various vision-language tasks. However, MLLMs usually perform poorly in zero-shot medical disease \u2026"}, {"title": "Few-Shot Whole Slide Pathology Classification with Multi-Granular Vision-Language Models", "link": "https://openreview.net/pdf%3Fid%3DnJZtYrOeoV", "details": "AT Nguyen, DMH Nguyen, NT Diep, TQ Nguyen, N Ho\u2026 - \u2026 on Foundation Models in the Wild", "abstract": "In this study, we propose a novel architecture for a large vision-language model adapted with a multi-granular prompt learning method to advance few-shot pathol- ogy classification. Starting with the Prov-GigaPath foundation model-pre-trained on \u2026"}, {"title": "Tradeoffs Between Alignment and Helpfulness in Language Models with Steering Methods", "link": "https://openreview.net/pdf%3Fid%3DAoTFSkUfLp", "details": "Y Wolf, N Wies, D Shteyman, B Rothberg, Y Levine\u2026 - \u2026 on Foundation Models in the Wild", "abstract": "Language model alignment has become an important component of AI safety, allowing safe interactions between humans and language models, by enhancing desired behaviors and inhibiting undesired ones. It is often done by tuning the model \u2026"}]
