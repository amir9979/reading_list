[{"title": "Pathology report generation from whole slide images with knowledge retrieval and multi-level regional feature selection", "link": "https://www.sciencedirect.com/science/article/pii/S016926072500094X", "details": "D Hu, Z Jiang, J Shi, F Xie, K Wu, K Tang, M Cao\u2026 - Computer Methods and \u2026, 2025", "abstract": "Background and objectives: With the development of deep learning techniques, the computer-assisted pathology diagnosis plays a crucial role in clinical diagnosis. An important task within this field is report generation, which provides doctors with text \u2026"}, {"title": "Application of unified health large language model evaluation framework to In-Basket message replies: bridging qualitative and quantitative assessments", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaf023/8068783", "details": "C Hong, A Chowdhury, AD Sorrentino, H Wang\u2026 - Journal of the American \u2026, 2025", "abstract": "Abstract Objectives Large language models (LLMs) are increasingly utilized in healthcare, transforming medical practice through advanced language processing capabilities. However, the evaluation of LLMs predominantly relies on human \u2026"}, {"title": "Exploring patient and health care provider perspectives on barriers to diabetic retinopathy screening in public health facilities in North India", "link": "https://www.nature.com/articles/s41598-025-92795-y", "details": "A Chauhan, M Duggal, A Kankaria, V Gupta, S Dhiman\u2026 - Scientific Reports, 2025", "abstract": "Diabetic retinopathy (DR), a prevalent microvascular complication of diabetes mellitus (DM), can be prevented with early detection and timely intervention. DR is asymptomatic in its early stages, highlighting the importance of screening for \u2026"}, {"title": "In-context learning for data-efficient classification of diabetic retinopathy with multimodal foundation models", "link": "https://www.medrxiv.org/content/medrxiv/early/2025/03/10/2025.03.09.25323618.full.pdf", "details": "MS Ayhan, AY Ong, E Ruffell, SK Wagner, DA Merle\u2026 - medRxiv, 2025", "abstract": "Importance: In-context learning, a prompt-based learning mechanism that enables multimodal foundation models to adapt to new tasks, can eliminate the need for retraining or large annotated datasets. We use diabetic retinopathy detection as an \u2026"}, {"title": "EyeBench: A Call for More Rigorous Evaluation of Retinal Image Enhancement", "link": "https://arxiv.org/pdf/2502.14260", "details": "W Zhu, X Dong, X Li, Y Xiong, X Chen, P Qiu, VK Vasa\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Over the past decade, generative models have achieved significant success in enhancement fundus images. However, the evaluation of these models still presents a considerable challenge. A comprehensive evaluation benchmark for fundus image \u2026"}, {"title": "Leveraging large language models for structured information extraction from pathology reports", "link": "https://arxiv.org/pdf/2502.12183", "details": "JB Balasubramanian, D Adams, I Roxanis\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Background: Structured information extraction from unstructured histopathology reports facilitates data accessibility for clinical research. Manual extraction by experts is time-consuming and expensive, limiting scalability. Large language models \u2026"}, {"title": "Modular Prompt Learning Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14125", "details": "Z Huang, T Pedapati, PY Chen, J Gao - \u2026 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Pre-trained vision-language models are able to interpret visual concepts and language semantics. Prompt learning, a method of constructing prompts for text encoders or image encoders, elicits the potentials of pre-trained models and readily \u2026"}, {"title": "MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.19634", "details": "J Pan, C Liu, J Wu, F Liu, J Zhu, HB Li, C Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning is a critical frontier for advancing medical image analysis, where transparency and trustworthiness play a central role in both clinician trust and regulatory approval. Although Medical Visual Language Models (VLMs) show \u2026"}, {"title": "Towards Statistical Factuality Guarantee for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.20560", "details": "Z Li, C Yan, NJ Jackson, W Cui, B Li, J Zhang, BA Malin - arXiv preprint arXiv \u2026, 2025", "abstract": "Advancements in Large Vision-Language Models (LVLMs) have demonstrated promising performance in a variety of vision-language tasks involving image- conditioned free-form text generation. However, growing concerns about \u2026"}]
