'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [MIDGARD: Self-Consistency Using Minimum Description Le'
[{"title": "SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs", "link": "https://arxiv.org/pdf/2404.13081", "details": "J Kim, J Nam, S Mo, J Park, SW Lee, M Seo, JW Ha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have made significant advancements in various natural language processing tasks, including question answering (QA) tasks. While incorporating new information with the retrieval of relevant passages is a promising \u2026"}, {"title": "Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks", "link": "https://dl.acm.org/doi/abs/10.1145/3589334.3645363", "details": "S Xu, L Pang, H Shen, X Cheng, TS Chua - Proceedings of the ACM on Web \u2026, 2024", "abstract": "Making the contents generated by Large Language Model (LLM), accurate, credible and traceable is crucial, especially in complex knowledge-intensive tasks that require multi-step reasoning and each step needs knowledge to solve. Retrieval \u2026"}, {"title": "Enhancing Confidence Expression in Large Language Models Through Learning from Past Experience", "link": "https://arxiv.org/pdf/2404.10315", "details": "H Han, T Li, S Chen, J Shi, C Du, Y Xiao, J Liang, X Lin - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have exhibited remarkable performance across various downstream tasks, but they may generate inaccurate or false information with a confident tone. One of the possible solutions is to empower the LLM confidence \u2026"}, {"title": "MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems", "link": "https://arxiv.org/pdf/2404.09486", "details": "K Li, Y Tian, Q Hu, Z Luo, J Ma - arXiv preprint arXiv:2404.09486, 2024", "abstract": "Programming often involves converting detailed and complex specifications into code, a process during which developers typically utilize visual aids to more effectively convey concepts. While recent developments in Large Multimodal Models \u2026"}, {"title": "Zero-shot LLM-guided Counterfactual Generation for Text", "link": "https://arxiv.org/pdf/2405.04793", "details": "A Bhattacharjee, R Moraffah, J Garland, H Liu - arXiv preprint arXiv:2405.04793, 2024", "abstract": "Counterfactual examples are frequently used for model development and evaluation in many natural language processing (NLP) tasks. Although methods for automated counterfactual generation have been explored, such methods depend on models \u2026"}, {"title": "LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet?): A Comprehensive Evaluation, Framework, and Benchmarks", "link": "https://seclab.bu.edu/people/gianluca/papers/llm-oakland2024.pdf", "details": "S Ullah, M Han, S Pujar, H Pearce, A Coskun\u2026 - IEEE Symposium on \u2026, 2024", "abstract": "Large Language Models (LLMs) have been suggested for use in automated vulnerability repair, but benchmarks showing they can consistently identify security- related bugs are lacking. We thus develop SecLLMHolmes, a fully automated \u2026"}, {"title": "Chain of Thoughtlessness: An Analysis of CoT in Planning", "link": "https://arxiv.org/pdf/2405.04776", "details": "K Stechly, K Valmeekam, S Kambhampati - arXiv preprint arXiv:2405.04776, 2024", "abstract": "Large language model (LLM) performance on reasoning problems typically does not generalize out of distribution. Previous work has claimed that this can be mitigated by modifying prompts to include examples with chains of thought--demonstrations of \u2026"}, {"title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation", "link": "https://arxiv.org/pdf/2404.11216", "details": "Z He, H Jiang, Z Wang, Y Yang, L Qiu, L Qiu - arXiv preprint arXiv:2404.11216, 2024", "abstract": "The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task \u2026"}, {"title": "On the Empirical Complexity of Reasoning and Planning in LLMs", "link": "https://arxiv.org/pdf/2404.11041", "details": "L Kang, Z Zhao, D Hsu, WS Lee - arXiv preprint arXiv:2404.11041, 2024", "abstract": "Large Language Models (LLMs) work surprisingly well for some complex reasoning problems via chain-of-thought (CoT) or tree-of-thought (ToT), but the underlying reasons remain unclear. We seek to understand the performance of these methods \u2026"}]
