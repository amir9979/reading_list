[{"title": "GroundCocoa: A Benchmark for Evaluating Compositional & Conditional Reasoning in Language Models", "link": "https://aclanthology.org/2025.naacl-long.420.pdf", "details": "H Kohli, S Kumar, H Sun - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their reasoning to \u2026"}, {"title": "Language Models of Code are Few-Shot Planners and Reasoners for Multi-Document Summarization with Attribution", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34676/36831", "details": "A Nandy, S Bandyopadhyay - Proceedings of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Document summarization has greatly benefited from advances in large language models (LLMs). In real-world situations, summaries often need to be generated from multiple documents with diverse sources and authors, lacking a clear information \u2026"}, {"title": "Atoxia: Red-teaming Large Language Models with Target Toxic Answers", "link": "https://aclanthology.org/2025.findings-naacl.179.pdf", "details": "Y Du, Z Li, P Cheng, X Wan, A Gao - Findings of the Association for Computational \u2026, 2025", "abstract": "Despite the substantial advancements in artificial intelligence, large language models (LLMs) remain being challenged by generation safety. With adversarial jailbreaking prompts, one can effortlessly induce LLMs to output harmful content \u2026"}, {"title": "Summarizing Online Patient Conversations Using Generative Language Models: Experimental and Comparative Study", "link": "https://medinform.jmir.org/2025/1/e62909/", "details": "RAS Nair, M Hartung, P Heinisch, J Jaskolski\u2026 - JMIR Medical Informatics, 2025", "abstract": "Background: Social media is acknowledged by regulatory bodies (eg, the Food and Drug Administration) as an important source of patient experience data to learn about patients' unmet needs, priorities, and preferences. However, current methods \u2026"}, {"title": "NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks", "link": "https://arxiv.org/pdf/2504.19854", "details": "CY Hung, Q Sun, P Hong, A Zadeh, C Li, U Tan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing Visual-Language-Action (VLA) models have shown promising performance in zero-shot scenarios, demonstrating impressive task execution and reasoning capabilities. However, a significant challenge arises from the limitations of visual \u2026"}, {"title": "Biases in Opinion Dynamics in Multi-Agent Systems of Large Language Models: A Case Study on Funding Allocation", "link": "https://aclanthology.org/2025.findings-naacl.101.pdf", "details": "P Cisneros-Velarde - Findings of the Association for Computational \u2026, 2025", "abstract": "We study the evolution of opinions inside a population of interacting large language models (LLMs). Every LLM needs to decide how much funding to allocate to an item with three initial possibilities: full, partial, or no funding. We identify biases that drive \u2026"}, {"title": "UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models", "link": "https://arxiv.org/pdf/2504.21027", "details": "Y Zheng, L Liu, Y Lin, J Feng, G Zhang, D Jin, Y Li - arXiv preprint arXiv:2504.21027, 2025", "abstract": "The advent of Large Language Models (LLMs) holds promise for revolutionizing various fields traditionally dominated by human expertise. Urban planning, a professional discipline that fundamentally shapes our daily surroundings, is one \u2026"}, {"title": "Analyzing and Improving Coherence of Large Language Models in Question Answering", "link": "https://aclanthology.org/2025.naacl-long.588.pdf", "details": "I Lauriola, S Campese, A Moschitti - Proceedings of the 2025 Conference of the \u2026, 2025", "abstract": "Large language models (LLMs) have recently revolutionized natural language processing. These models, however, often suffer from instability or lack of coherence, that is the ability of the models to generate semantically equivalent outputs when \u2026"}, {"title": "Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2504.21277", "details": "G Zhou, P Qiu, C Chen, J Wang, Z Yang, J Xu, M Qiu - arXiv preprint arXiv \u2026, 2025", "abstract": "The integration of reinforcement learning (RL) into the reasoning capabilities of Multimodal Large Language Models (MLLMs) has rapidly emerged as a transformative research direction. While MLLMs significantly extend Large Language \u2026"}]
