[{"title": "FINDVER: Explainable Claim Verification over Long and Hybrid-Content Financial Documents", "link": "https://arxiv.org/pdf/2411.05764", "details": "Y Zhao, Y Long, Y Jiang, C Wang, W Chen, H Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce FinDVer, a comprehensive benchmark specifically designed to evaluate the explainable claim verification capabilities of LLMs in the context of understanding and analyzing long, hybrid-content financial documents. FinDVer \u2026"}, {"title": "Extracting key insights from earnings call transcript via information-theoretic contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0306457324003571", "details": "Y Huang, W Tai, F Zhou, Q Gao, T Zhong, K Zhang - Information Processing & \u2026, 2025", "abstract": "Earnings conference calls provide critical insights into a company's financial health, future outlook, and strategic direction. Traditionally, analysts manually analyze these lengthy transcripts to extract key information, a process that is both time-consuming \u2026"}, {"title": "Medsafetybench: Evaluating and improving the medical safety of large language models", "link": "https://openreview.net/pdf%3Fid%3DcFyagd2Yh4", "details": "T Han, A Kumar, C Agarwal, H Lakkaraju - The Thirty-eight Conference on Neural \u2026, 2024", "abstract": "As large language models (LLMs) develop increasingly sophisticated capabilities and find applications in medical settings, it becomes important to assess their medical safety due to their far-reaching implications for personal and public health \u2026"}]
