[{"title": "Large language models improve transferability of electronic health record-based predictions across countries and coding systems", "link": "https://www.medrxiv.org/content/medrxiv/early/2025/02/04/2025.02.03.25321597.full.pdf", "details": "M Kirchler, M Ferro, V Lorenzini, FinnGen, C Lippert\u2026 - medRxiv, 2025", "abstract": "Variation in medical practices and reporting standards across healthcare systems limits the transferability of prediction models based on structured electronic health record (EHR) data. We introduce GRASP, a novel transformer-based architecture \u2026"}, {"title": "A multimodal multidomain multilingual medical foundation model for zero shot clinical diagnosis", "link": "https://www.nature.com/articles/s41746-024-01339-7", "details": "F Liu, Z Li, Q Yin, J Huang, J Luo, A Thakur, K Branson\u2026 - npj Digital Medicine, 2025", "abstract": "Radiology images are one of the most commonly used in daily clinical diagnosis. Typically, clinical diagnosis using radiology images involves disease reporting and classification, where the former is a multimodal task whereby textual reports are \u2026"}, {"title": "RadVLM: A Multitask Conversational Vision-Language Model for Radiology", "link": "https://arxiv.org/pdf/2502.03333", "details": "N Deperrois, H Matsuo, S Ruip\u00e9rez-Campillo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The widespread use of chest X-rays (CXRs), coupled with a shortage of radiologists, has driven growing interest in automated CXR analysis and AI-assisted reporting. While existing vision-language models (VLMs) show promise in specific tasks such \u2026"}, {"title": "HKRG: Hierarchical knowledge integration for radiology report generation", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002441", "details": "B Wang, P Teng, H Zhang, F Yang, Z Wang, X Yi\u2026 - Expert Systems with \u2026, 2025", "abstract": "Radiology report generation aims to automatically produce coherent, free-text reports that describe the clinical observations of radiographs. Most existing approaches align visual features with full report features to bridge the gap between medical \u2026"}, {"title": "Conformal Uncertainty Indicator for Continual Test-Time Adaptation", "link": "https://arxiv.org/pdf/2502.02998", "details": "F Lyu, H Zhao, Z Shi, Y Liu, F Hu, Z Zhang, L Wang - arXiv preprint arXiv:2502.02998, 2025", "abstract": "Continual Test-Time Adaptation (CTTA) aims to adapt models to sequentially changing domains during testing, relying on pseudo-labels for self-adaptation. However, incorrect pseudo-labels can accumulate, leading to performance \u2026"}]
