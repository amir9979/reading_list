[{"title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "link": "https://arxiv.org/pdf/2501.16961%3F", "details": "M Raza, N Milic-Frayling - arXiv preprint arXiv:2501.16961, 2025", "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that \u2026"}, {"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "link": "https://arxiv.org/pdf/2501.04322", "details": "M Rang, Z Bi, C Liu, Y Tang, K Han, Y Wang - arXiv preprint arXiv:2501.04322, 2025", "abstract": "Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are \u2026"}, {"title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "link": "https://arxiv.org/pdf/2501.12266", "details": "C Patr\u00edcio, I Rio-Torto, JS Cardoso, LF Teixeira\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The main challenges limiting the adoption of deep learning-based solutions in medical workflows are the availability of annotated data and the lack of interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the latter \u2026"}, {"title": "Learning with Enriched Inductive Biases for Vision-Language Models", "link": "https://ruyuanzhang.github.io/files/2501_indctbiasVisLangModel_IJCV.pdf", "details": "L Yang, RY Zhang, Q Chen, X Xie - International Journal of Computer Vision, 2025", "abstract": "Abstract Vision-Language Models, pre-trained on large-scale image-text pairs, serve as strong foundation models for transfer learning across a variety of downstream tasks. For few-shot generalization tasks, ie., when the model is trained on few-shot \u2026"}, {"title": "Reasoning Language Models: A Blueprint", "link": "https://arxiv.org/pdf/2501.11223%3F", "details": "M Besta, J Barth, E Schreiber, A Kubicek, A Catarino\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning language models (RLMs), also known as Large Reasoning Models (LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have redefined AI's problem-solving capabilities by extending large language models \u2026"}, {"title": "Bactrainus: Optimizing Large Language Models for Multi-hop Complex Question Answering Tasks", "link": "https://arxiv.org/pdf/2501.06286", "details": "I Barati, A Ghafouri, B Minaei-Bidgoli - arXiv preprint arXiv:2501.06286, 2025", "abstract": "In recent years, the use of large language models (LLMs) has significantly increased, and these models have demonstrated remarkable performance in a variety of general language tasks. However, the evaluation of their performance in domain \u2026"}, {"title": "A Collection of Question Answering Datasets for Norwegian", "link": "https://arxiv.org/pdf/2501.11128", "details": "V Mikhailov, P M\u00e6hlum, VOC Lang\u00f8, E Velldal\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces a new suite of question answering datasets for Norwegian; NorOpenBookQA, NorCommonSenseQA, NorTruthfulQA, and NRK-Quiz-QA. The data covers a wide range of skills and knowledge domains, including world \u2026"}, {"title": "Double Visual Defense: Adversarial Pre-training and Instruction Tuning for Improving Vision-Language Model Robustness", "link": "https://arxiv.org/pdf/2501.09446", "details": "Z Wang, C Xie, B Bartoldson, B Kailkhura - arXiv preprint arXiv:2501.09446, 2025", "abstract": "This paper investigates the robustness of vision-language models against adversarial visual perturbations and introduces a novel``double visual defense\" to enhance this robustness. Unlike previous approaches that resort to lightweight \u2026"}, {"title": "Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL", "link": "https://arxiv.org/pdf/2501.12372", "details": "Y Chung, GT Kakkar, Y Gan, B Milne, F Ozcan - arXiv preprint arXiv:2501.12372, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across a range of natural language processing tasks. In particular, improvements in reasoning abilities and the expansion of context windows have opened new avenues for \u2026"}]
