[{"title": "The Latent Space Hypothesis: Toward Universal Medical Representation Learning", "link": "https://arxiv.org/pdf/2506.04515", "details": "S Patel - arXiv preprint arXiv:2506.04515, 2025", "abstract": "Medical data range from genomic sequences and retinal photographs to structured laboratory results and unstructured clinical narratives. Although these modalities appear disparate, many encode convergent information about a single underlying \u2026", "entry_id": "http://arxiv.org/abs/2506.04515v1", "updated": "2025-06-04 23:37:33", "published": "2025-06-04 23:37:33", "authors": "Salil Patel", "summary": "Medical data range from genomic sequences and retinal photographs to\nstructured laboratory results and unstructured clinical narratives. Although\nthese modalities appear disparate, many encode convergent information about a\nsingle underlying physiological state. The Latent Space Hypothesis frames each\nobservation as a projection of a unified, hierarchically organized manifold --\nmuch like shadows cast by the same three-dimensional object. Within this\nlearned geometric representation, an individual's health status occupies a\npoint, disease progression traces a trajectory, and therapeutic intervention\ncorresponds to a directed vector. Interpreting heterogeneous evidence in a\nshared space provides a principled way to re-examine eponymous conditions --\nsuch as Parkinson's or Crohn's -- that often mask multiple pathophysiological\nentities and involve broader anatomical domains than once believed. By\nrevealing sub-trajectories and patient-specific directions of change, the\nframework supplies a quantitative rationale for personalised diagnosis,\nlongitudinal monitoring, and tailored treatment, moving clinical practice away\nfrom grouping by potentially misleading labels toward navigation of each\nperson's unique trajectory. Challenges remain -- bias amplification, data\nscarcity for rare disorders, privacy, and the correlation-causation divide --\nbut scale-aware encoders, continual learning on longitudinal data streams, and\nperturbation-based validation offer plausible paths forward.", "comment": "51 pages, 12 figures. A position paper examining the latent space\n  hypothesis - the proposition that diverse medical data can be represented in\n  shared latent spaces reflecting fundamental biological processes. The paper\n  discusses theoretical foundations, reviews supporting evidence, and considers\n  potential implications for medical AI and representation learning", "journal_ref": null, "primary_category": "q-bio.QM", "categories": "q-bio.QM;cs.AI;cs.LG", "links": "http://arxiv.org/abs/2506.04515v1;http://arxiv.org/pdf/2506.04515v1", "pdf_url": "http://arxiv.org/pdf/2506.04515v1"}, {"title": "Efficiency and Quality of Generative AI\u2013Assisted Radiograph Reporting", "link": "https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2834943", "details": "J Huang, MT Wittbrodt, CN Teague, E Karl, G Galal\u2026 - JAMA Network Open, 2025", "abstract": "Importance Diagnostic imaging interpretation involves distilling multimodal clinical information into text form, a task well-suited to augmentation by generative artificial intelligence (AI). However, to our knowledge, impacts of AI-based draft radiological \u2026"}, {"title": "Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification", "link": "https://arxiv.org/pdf/2506.04450", "details": "P Bhattacharjee, F Tian, R Tandon, J Lo, H Hanson\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Purpose: This study proposes a framework for fine-tuning large language models (LLMs) with differential privacy (DP) to perform multi-abnormality classification on radiology report text. By injecting calibrated noise during fine-tuning, the framework \u2026", "entry_id": "http://arxiv.org/abs/2506.04450v1", "updated": "2025-06-04 21:11:45", "published": "2025-06-04 21:11:45", "authors": "Payel Bhattacharjee;Fengwei Tian;Ravi Tandon;Joseph Lo;Heidi Hanson;Geoffrey Rubin;Nirav Merchant;John Gounley", "summary": "Purpose: This study proposes a framework for fine-tuning large language\nmodels (LLMs) with differential privacy (DP) to perform multi-abnormality\nclassification on radiology report text. By injecting calibrated noise during\nfine-tuning, the framework seeks to mitigate the privacy risks associated with\nsensitive patient data and protect against data leakage while maintaining\nclassification performance. Materials and Methods: We used 50,232 radiology\nreports from the publicly available MIMIC-CXR chest radiography and CT-RATE\ncomputed tomography datasets, collected between 2011 and 2019. Fine-tuning of\nLLMs was conducted to classify 14 labels from MIMIC-CXR dataset, and 18 labels\nfrom CT-RATE dataset using Differentially Private Low-Rank Adaptation (DP-LoRA)\nin high and moderate privacy regimes (across a range of privacy budgets =\n{0.01, 0.1, 1.0, 10.0}). Model performance was evaluated using weighted F1\nscore across three model architectures: BERT-medium, BERT-small, and\nALBERT-base. Statistical analyses compared model performance across different\nprivacy levels to quantify the privacy-utility trade-off. Results: We observe a\nclear privacy-utility trade-off through our experiments on 2 different datasets\nand 3 different models. Under moderate privacy guarantees the DP fine-tuned\nmodels achieved comparable weighted F1 scores of 0.88 on MIMIC-CXR and 0.59 on\nCT-RATE, compared to non-private LoRA baselines of 0.90 and 0.78, respectively.\nConclusion: Differentially private fine-tuning using LoRA enables effective and\nprivacy-preserving multi-abnormality classification from radiology reports,\naddressing a key challenge in fine-tuning LLMs on sensitive medical data.", "comment": "19 pages, 5 figures, 2 tables", "journal_ref": null, "primary_category": "cs.CR", "categories": "cs.CR;cs.AI;cs.CL;cs.LG", "links": "http://arxiv.org/abs/2506.04450v1;http://arxiv.org/pdf/2506.04450v1", "pdf_url": "http://arxiv.org/pdf/2506.04450v1"}, {"title": "Diagnosis of Pneumonia from Chest X-Ray Images Using Federated Learning", "link": "https://link.springer.com/chapter/10.1007/978-981-96-1188-1_3", "details": "A Srinivasulu, S Kumar, R Chowdhury, R Mahto\u2026 - International Conference on \u2026, 2025", "abstract": "Pneumonia is a substantial risk for global health. The prompt and precise diagnosis is important and very crucial. This study centers on the diagnosis of pneumonia through the analysis of chest X-ray images using sophisticated deep learning models \u2026"}, {"title": "FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation", "link": "https://arxiv.org/pdf/2506.04956", "details": "H Wang, Z Yang, H Zhang, D Zhao, B Wei, Y Xu - arXiv preprint arXiv:2506.04956, 2025", "abstract": "Synthesizing high-quality dynamic medical videos remains a significant challenge due to the need for modeling both spatial consistency and temporal dynamics. Existing Transformer-based approaches face critical limitations, including insufficient \u2026", "entry_id": "http://arxiv.org/abs/2506.04956v1", "updated": "2025-06-05 12:31:02", "published": "2025-06-05 12:31:02", "authors": "Huihan Wang;Zhiwen Yang;Hui Zhang;Dan Zhao;Bingzheng Wei;Yan Xu", "summary": "Synthesizing high-quality dynamic medical videos remains a significant\nchallenge due to the need for modeling both spatial consistency and temporal\ndynamics. Existing Transformer-based approaches face critical limitations,\nincluding insufficient channel interactions, high computational complexity from\nself-attention, and coarse denoising guidance from timestep embeddings when\nhandling varying noise levels. In this work, we propose FEAT, a\nfull-dimensional efficient attention Transformer, which addresses these issues\nthrough three key innovations: (1) a unified paradigm with sequential\nspatial-temporal-channel attention mechanisms to capture global dependencies\nacross all dimensions, (2) a linear-complexity design for attention mechanisms\nin each dimension, utilizing weighted key-value attention and global channel\nattention, and (3) a residual value guidance module that provides fine-grained\npixel-level guidance to adapt to different noise levels. We evaluate FEAT on\nstandard benchmarks and downstream tasks, demonstrating that FEAT-S, with only\n23\\% of the parameters of the state-of-the-art model Endora, achieves\ncomparable or even superior performance. Furthermore, FEAT-L surpasses all\ncomparison methods across multiple datasets, showcasing both superior\neffectiveness and scalability. Code is available at\nhttps://github.com/Yaziwel/FEAT.", "comment": "This paper has been early accepted by MICCAI 2025", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2506.04956v1;http://arxiv.org/pdf/2506.04956v1", "pdf_url": "http://arxiv.org/pdf/2506.04956v1"}]
