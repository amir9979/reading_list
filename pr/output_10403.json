[{"title": "A Comparison of Representation Learning Methods for Medical Concepts in EHR Databases", "link": "https://dl.acm.org/doi/abs/10.1145/3698587.3701491", "details": "Z Liu, X Wu, Y Yang, DA Clifton - Proceedings of the 15th ACM International \u2026, 2024", "abstract": "This study evaluates four NLP models---LDA, Word2Vec, GloVe, and BERT---for representing medical concepts in Electronic Health Records (EHR) databases using MIMIC-IV and eICU-CRD datasets. EHR contains detailed and coded information on \u2026"}, {"title": "Cognitive Bias in Large Language Models: Implications for Research and Practice", "link": "https://ai.nejm.org/doi/abs/10.1056/AIe2400961", "details": "L Zwaan - NEJM AI, 2024", "abstract": "The use of large language models (LLMs) such as ChatGPT in clinical settings is growing, but concerns about their susceptibility to cognitive biases persist. Wang and Redelmeier's study reveals that LLMs are prone to biases, raising important \u2026"}]
