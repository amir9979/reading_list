[{"title": "Explainable Fake News Detection With Large Language Model via Defense Among Competing Wisdom", "link": "https://arxiv.org/pdf/2405.03371", "details": "B Wang, J Ma, H Lin, Z Yang, R Yang, Y Tian, Y Chang - Proceedings of the ACM on \u2026, 2024", "abstract": "Most fake news detection methods learn latent feature representations based on neural networks, which makes them black boxes to classify a piece of news without giving any justification. Existing explainable systems generate veracity justifications \u2026"}, {"title": "Counterfactual condition diffusion with continuous prior adaptive correction for anomaly detection in multimodal brain MRI", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424011618", "details": "X Chen, Y Peng - Expert Systems with Applications, 2024", "abstract": "Pixel-level prediction of early lesions is important for disease treatment and saving patients' lives. Owing to the heterogeneity of pathological brain structures and the complexity of brain imaging, automatic anomaly detection in brain MRIs is one of the \u2026"}, {"title": "CBDMoE: Consistent-but-Diverse Mixture of Experts for Domain Generalization", "link": "https://ieeexplore.ieee.org/abstract/document/10528872/", "details": "F Xu, D Chen, T Jia, S Deng, H Wang - IEEE Transactions on Multimedia, 2024", "abstract": "Machine learning models often suffer from severe performance degradation due to distributional shifts between testing and training data. To address this issue, researchers have focused on domain generalization (DG), which aims to generalize \u2026"}, {"title": "Pseudo-Prompt Generating in Pre-trained Vision-Language Models for Multi-Label Medical Image Classification", "link": "https://arxiv.org/pdf/2405.06468", "details": "Y Ye, J Zhang, H Shi - arXiv preprint arXiv:2405.06468, 2024", "abstract": "The task of medical image recognition is notably complicated by the presence of varied and multiple pathological indications, presenting a unique challenge in multi- label classification with unseen labels. This complexity underlines the need for \u2026"}, {"title": "Continual Observation of Joins under Differential Privacy", "link": "https://dl.acm.org/doi/pdf/10.1145/3654931", "details": "W Dong, Z Chen, Q Luo, E Shi, K Yi - Proceedings of the ACM on Management of \u2026, 2024", "abstract": "The problem of continual observation under differential privacy has been studied extensively in the literature. However, all existing works, with the exception of [28, 51], have only studied the simple counting query and its derivatives. Join queries \u2026"}, {"title": "Libra: Building Decoupled Vision System on Large Language Models", "link": "https://arxiv.org/pdf/2405.10140", "details": "Y Xu, X Yang, Y Song, C Xu - arXiv preprint arXiv:2405.10140, 2024", "abstract": "In this work, we introduce Libra, a prototype model with a decoupled vision system on a large language model (LLM). The decoupled vision system decouples inner- modal modeling and cross-modal interaction, yielding unique visual information \u2026"}, {"title": "Crafting Interpretable Embeddings by Asking LLMs Questions", "link": "https://arxiv.org/abs/2405.16714", "details": "V Benara, C Singh, JX Morris, R Antonello, I Stoica\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have rapidly improved text embeddings for a growing array of natural-language processing tasks. However, their opaqueness and proliferation into scientific domains such as neuroscience have created a growing \u2026"}, {"title": "RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical Diagnostic Reports", "link": "https://arxiv.org/pdf/2405.14137", "details": "J Du, J Guo, W Zhang, S Yang, H Liu, H Li, N Wang - arXiv preprint arXiv:2405.14137, 2024", "abstract": "The Vision-Language Foundation model is increasingly investigated in the fields of computer vision and natural language processing, yet its exploration in ophthalmology and broader medical applications remains limited. The challenge is \u2026"}, {"title": "LLM Tuning and Interpretable CoT: KIS Team in COLIEE 2024", "link": "https://link.springer.com/chapter/10.1007/978-981-97-3076-6_10", "details": "M Fujita, T Onaga, Y Kano - JSAI International Symposium on Artificial Intelligence, 2024", "abstract": "Focusing on the recently advanced Large Language Models (LLMs), we studied two key areas: LLM tuning and Chain-of-Thought (CoT) interpretability, which are crucial in legal tasks. Regarding LLM tuning, we conducted experiments comparing multiple \u2026"}]
