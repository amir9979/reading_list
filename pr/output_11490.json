[{"title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2412.09827", "details": "C Li, C Ding, K Luan, X Di - arXiv preprint arXiv:2412.09827, 2024", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. LoRA is one of the most widely used methods, which assumes that the optimization process is essentially low \u2026"}, {"title": "Enhancing radiology report generation through pre-trained language models", "link": "https://link.springer.com/article/10.1007/s13748-024-00358-5", "details": "G Leonardi, L Portinale, A Santomauro - Progress in Artificial Intelligence, 2024", "abstract": "In the healthcare field, the ability to integrate and process data from various modalities, such as medical images, clinical notes, and patient records, plays a central role in enabling Artificial Intelligence models to provide more informed \u2026"}, {"title": "APOVIS: Automated pixel-level open-vocabulary instance segmentation through integration of pre-trained vision-language models and foundational segmentation \u2026", "link": "https://www.sciencedirect.com/science/article/pii/S026288562400489X", "details": "Q Ma, S Yang, L Zhang, Q Lan, D Yang, H Chen, Y Tan - Image and Vision \u2026, 2024", "abstract": "In recent years, substantial advancements have been achieved in vision-language integration and image segmentation, particularly through the use of pre-trained models like BERT and Vision Transformer (ViT). Within the domain of open \u2026"}, {"title": "MiniGPT-Pancreas: Multimodal Large Language Model for Pancreas Cancer Classification and Detection", "link": "https://arxiv.org/pdf/2412.15925", "details": "A Moglia, EC Nastasio, L Mainardi, P Cerveri - arXiv preprint arXiv:2412.15925, 2024", "abstract": "Problem: Pancreas radiological imaging is challenging due to the small size, blurred boundaries, and variability of shape and position of the organ among patients. Goal: In this work we present MiniGPT-Pancreas, a Multimodal Large Language Model \u2026"}, {"title": "Unleash the Power of Vision-Language Models by Visual Attention Prompt and Multi-modal Interaction", "link": "https://ieeexplore.ieee.org/abstract/document/10814093/", "details": "W Zhang, L Wu, Z Zhang, T Yu, C Ma, X Jin, X Yang\u2026 - IEEE Transactions on \u2026, 2024", "abstract": "Pre-trained vision-language models (VLMs) like CLIP [1], equipped with parameter- efficient tuning (PET) methods like prompting [2], have shown impressive knowledge transferability on new downstream tasks, but they are still prone to be limited by \u2026"}, {"title": "On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena", "link": "https://arxiv.org/pdf/2501.04662", "details": "T Naous, W Xu - arXiv preprint arXiv:2501.04662, 2025", "abstract": "Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages. In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by \u2026"}, {"title": "Vinci: A Real-time Embodied Smart Assistant based on Egocentric Vision-Language Model", "link": "https://arxiv.org/pdf/2412.21080%3F", "details": "Y Huang, J Xu, B Pei, Y He, G Chen, L Yang, X Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce Vinci, a real-time embodied smart assistant built upon an egocentric vision-language model. Designed for deployment on portable devices such as smartphones and wearable cameras, Vinci operates in an\" always on\" mode \u2026"}, {"title": "Biased or Flawed? Mitigating Stereotypes in Generative Language Models by Addressing Task-Specific Flaws", "link": "https://arxiv.org/pdf/2412.11414%3F", "details": "A Jha, S Kabra, CK Reddy - arXiv preprint arXiv:2412.11414, 2024", "abstract": "Recent studies have shown that generative language models often reflect and amplify societal biases in their outputs. However, these studies frequently conflate observed biases with other task-specific shortcomings, such as comprehension \u2026"}, {"title": "HC-LLM: Historical-Constrained Large Language Models for Radiology Report Generation", "link": "https://arxiv.org/pdf/2412.11070", "details": "T Liu, J Wang, Y Hu, M Li, J Yi, X Chang, J Gao, B Yin - arXiv preprint arXiv \u2026, 2024", "abstract": "Radiology report generation (RRG) models typically focus on individual exams, often overlooking the integration of historical visual or textual data, which is crucial for patient follow-ups. Traditional methods usually struggle with long sequence \u2026"}]
