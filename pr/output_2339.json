[{"title": "FuRL: Visual-Language Models as Fuzzy Rewards for Reinforcement Learning", "link": "https://arxiv.org/pdf/2406.00645", "details": "Y Fu, H Zhang, D Wu, W Xu, B Boulet - arXiv preprint arXiv:2406.00645, 2024", "abstract": "In this work, we investigate how to leverage pre-trained visual-language models (VLM) for online Reinforcement Learning (RL). In particular, we focus on sparse reward tasks with pre-defined textual task descriptions. We first identify the problem \u2026"}, {"title": "A Systematic Analysis on the Temporal Generalization of Language Models in Social Media", "link": "https://arxiv.org/pdf/2405.13017", "details": "A Ushio, J Camacho-Collados - arXiv preprint arXiv:2405.13017, 2024", "abstract": "In machine learning, temporal shifts occur when there are differences between training and test splits in terms of time. For streaming data such as news or social media, models are commonly trained on a fixed corpus from a certain period of time \u2026"}, {"title": "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning? An Extensive Investigation into the Capabilities and Limitations of \u2026", "link": "https://arxiv.org/pdf/2406.00257", "details": "MS Islam, R Rahman, A Masry, MTR Laskar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Natural language is a powerful complementary modality of communication for data visualizations, such as bar and line charts. To facilitate chart-based reasoning using natural language, various downstream tasks have been introduced recently such as \u2026"}, {"title": "Small Language Models for Application Interactions: A Case Study", "link": "https://arxiv.org/pdf/2405.20347", "details": "B Li, Y Zhang, S Bubeck, J Pathuri, I Menache - arXiv preprint arXiv:2405.20347, 2024", "abstract": "We study the efficacy of Small Language Models (SLMs) in facilitating application usage through natural language interactions. Our focus here is on a particular internal application used in Microsoft for cloud supply chain fulfilment. Our \u2026"}, {"title": "Benchmarking the Communication Competence of Code Generation for LLMs and LLM Agent", "link": "https://arxiv.org/pdf/2406.00215", "details": "JJW Wu, FH Fard - arXiv preprint arXiv:2406.00215, 2024", "abstract": "Large language models (LLMs) have significantly improved their ability to perform tasks in the field of code generation. However, there is still a gap between LLMs being capable coders and being top-tier software engineers. Based on the \u2026"}, {"title": "EHR-SeqSQL: A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records", "link": "https://arxiv.org/pdf/2406.00019", "details": "J Ryu, S Cho, G Lee, E Choi - arXiv preprint arXiv:2406.00019, 2024", "abstract": "In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL dataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to address critical yet underexplored aspects in text-to-SQL parsing: interactivity \u2026"}, {"title": "MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning", "link": "https://arxiv.org/pdf/2405.05189", "details": "I Nair, L Wang - arXiv preprint arXiv:2405.05189, 2024", "abstract": "We study the task of conducting structured reasoning as generating a reasoning graph from natural language input using large language models (LLMs). Previous approaches have explored various prompting schemes, yet they suffer from error \u2026"}, {"title": "Relational multi-scale metric learning for few-shot knowledge graph completion", "link": "https://link.springer.com/article/10.1007/s10115-024-02083-w", "details": "Y Song, M Gui, K Zhang, Z Xu, D Dai, D Kong - Knowledge and Information Systems, 2024", "abstract": "Few-shot knowledge graph completion (FKGC) refers to the task of inferring missing facts in a knowledge graph by utilizing a limited number of reference entities. Most FKGC methods assume a single similarity metric, which leads to a single feature \u2026"}, {"title": "Zero-shot LLM-guided Counterfactual Generation for Text", "link": "https://arxiv.org/pdf/2405.04793", "details": "A Bhattacharjee, R Moraffah, J Garland, H Liu - arXiv preprint arXiv:2405.04793, 2024", "abstract": "Counterfactual examples are frequently used for model development and evaluation in many natural language processing (NLP) tasks. Although methods for automated counterfactual generation have been explored, such methods depend on models \u2026"}]
