[{"title": "MDEval: Evaluating and Enhancing Markdown Awareness in Large Language Models", "link": "https://arxiv.org/pdf/2501.15000", "details": "Z Chen, Y Liu, L Shi, ZJ Wang, X Chen, Y Zhao, F Ren - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) are expected to offer structured Markdown responses for the sake of readability in web chatbots (eg, ChatGPT). Although there are a myriad of metrics to evaluate LLMs, they fail to evaluate the readability from the \u2026"}, {"title": "Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack", "link": "https://ui.adsabs.harvard.edu/abs/2025arXiv250108454A/abstract", "details": "S Antebi, E Habler, A Shabtai, Y Elovici - arXiv e-prints, 2025", "abstract": "Large language models (LLMs) have become essential digital task assistance tools. Their training relies heavily on the collection of vast amounts of data, which may include copyright-protected or sensitive information. Recent studies on the detection \u2026"}]
