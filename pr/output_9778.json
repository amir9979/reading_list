[{"title": "Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning", "link": "https://arxiv.org/pdf/2411.05193", "details": "J Hong, A Dragan, S Levine - arXiv preprint arXiv:2411.05193, 2024", "abstract": "Value-based reinforcement learning (RL) can in principle learn effective policies for a wide range of multi-turn problems, from games to dialogue to robotic control, including via offline RL from static previously collected datasets. However, despite \u2026"}, {"title": "Diff-eRank: A Novel Rank-Based Metric for Evaluating Large Language Models", "link": "https://openreview.net/pdf%3Fid%3Dnvn80cscVm", "details": "L Wei, Z Tan, C Li, J Wang, W Huang - The Thirty-eighth Annual Conference on \u2026, 2024", "abstract": "Large Language Models (LLMs) have transformed natural language processing and extended their powerful capabilities to multi-modal domains. As LLMs continue to advance, it is crucial to develop diverse and appropriate metrics for their evaluation \u2026"}, {"title": "Mixed Distillation Helps Smaller Language Models Reason Better", "link": "https://aclanthology.org/2024.findings-emnlp.91.pdf", "details": "L Chenglin, Q Chen, L Li, C Wang, F Tao, Y Li, Z Chen\u2026 - Findings of the Association \u2026, 2024", "abstract": "As large language models (LLMs) have demonstrated impressive multiple step-by- step reasoning capabilities in recent natural language processing (NLP) reasoning tasks, many studies are interested in distilling reasoning abilities into smaller \u2026"}, {"title": "Accelerating Blockwise Parallel Language Models with Draft Refinement", "link": "https://openreview.net/pdf%3Fid%3DKT6F5Sw0eg", "details": "T Kim, AT Suresh, KA Papineni, M Riley, S Kumar\u2026 - The Thirty-eighth Annual \u2026", "abstract": "Autoregressive language models have achieved remarkable advancements, yet their potential is often limited by the slow inference speeds associated with sequential token generation. Blockwise parallel decoding (BPD) was proposed by Stern et \u2026"}, {"title": "Multimodal Large Language Models Make Text-to-Image Generative Models Align Better", "link": "https://openreview.net/pdf%3Fid%3DIRXyPm9IPW", "details": "X Wu, S Huang, G Wang, J Xiong, F Wei - The Thirty-eighth Annual Conference on Neural \u2026", "abstract": "Recent studies have demonstrated the exceptional potentials of leveraging human preference datasets to refine text-to-image generative models, enhancing the alignment between generated images and textual prompts. Despite these advances \u2026"}, {"title": "Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective", "link": "https://arxiv.org/pdf/2412.00554", "details": "Y Zhou, B Di Eugenio, L Cheng - arXiv preprint arXiv:2412.00554, 2024", "abstract": "This paper studies the performance of large language models (LLMs), particularly regarding demographic fairness, in solving real-world healthcare tasks. We evaluate state-of-the-art LLMs with three prevalent learning frameworks across six diverse \u2026"}, {"title": "General Geospatial Inference with a Population Dynamics Foundation Model", "link": "https://arxiv.org/pdf/2411.07207%3F", "details": "M Agarwal, M Sun, C Kamath, A Muslim, P Sarker\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Supporting the health and well-being of dynamic populations around the world requires governmental agencies, organizations and researchers to understand and reason over complex relationships between human behavior and local contexts in \u2026"}]
