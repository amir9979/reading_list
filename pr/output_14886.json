[{"title": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models", "link": "https://arxiv.org/pdf/2503.18923", "details": "M Cao, P Hu, Y Wang, J Gu, H Tang, H Zhao, J Dong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we \u2026"}, {"title": "Unveiling the mist over 3d vision-language understanding: Object-centric evaluation with chain-of-analysis", "link": "https://arxiv.org/pdf/2503.22420", "details": "J Huang, B Jia, Y Wang, Z Zhu, X Linghu, Q Li, SC Zhu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing 3D vision-language (3D-VL) benchmarks fall short in evaluating 3D-VL models, creating a\" mist\" that obscures rigorous insights into model capabilities and 3D-VL tasks. This mist persists due to three key limitations. First, flawed test data, like \u2026"}, {"title": "GPBench: A Comprehensive and Fine-Grained Benchmark for Evaluating Large Language Models as General Practitioners", "link": "https://arxiv.org/pdf/2503.17599", "details": "Z Li, Y Yang, J Lang, W Jiang, Y Zhao, S Li, D Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "General practitioners (GPs) serve as the cornerstone of primary healthcare systems by providing continuous and comprehensive medical services. However, due to community-oriented nature of their practice, uneven training and resource gaps, the \u2026"}, {"title": "Map: Evaluation and multi-agent enhancement of large language models for inpatient pathways", "link": "https://arxiv.org/pdf/2503.13205%3F", "details": "Z Chen, Z Peng, X Liang, C Wang, P Liang, L Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited \u2026"}, {"title": "Summarization Metrics for Spanish and Basque: Do Automatic Scores and LLM-Judges Correlate with Humans?", "link": "https://arxiv.org/pdf/2503.17039", "details": "J Barnes, N Perez, A Bonet-Jover, B Altuna - arXiv preprint arXiv:2503.17039, 2025", "abstract": "Studies on evaluation metrics and LLM-as-a-Judge models for automatic text summarization have largely been focused on English, limiting our understanding of their effectiveness in other languages. Through our new dataset BASSE (BAsque \u2026"}, {"title": "V2P-Bench: Evaluating Video-Language Understanding with Visual Prompts for Better Human-Model Interaction", "link": "https://arxiv.org/pdf/2503.17736%3F", "details": "Y Zhao, Y Zeng, Y Qi, YY Liu, L Chen, Z Chen, X Bao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) have made significant progress in the field of video understanding recently. However, current benchmarks uniformly lean on text prompts for evaluation, which often necessitate complex referential language and fail \u2026"}, {"title": "Alignment for Efficient Tool Calling of Large Language Models", "link": "https://arxiv.org/pdf/2503.06708%3F", "details": "H Xu, Z Wang, Z Zhu, L Pan, X Chen, L Chen, K Yu - arXiv preprint arXiv:2503.06708, 2025", "abstract": "Recent advancements in tool learning have enabled large language models (LLMs) to integrate external tools, enhancing their task performance by expanding their knowledge boundaries. However, relying on tools often introduces tradeoffs between \u2026"}, {"title": "How Good is my Histopathology Vision-Language Foundation Model? A Holistic Benchmark", "link": "https://arxiv.org/pdf/2503.12990", "details": "RA Majzoub, H Malik, M Naseer, Z Zaheer, T Mahmood\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, histopathology vision-language foundation models (VLMs) have gained popularity due to their enhanced performance and generalizability across different downstream tasks. However, most existing histopathology benchmarks are either \u2026"}, {"title": "Enhancing 3D Medical Image Understanding with 2D Multimodal Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10889731/", "details": "Q Chen, X Yao, H Ye, Y Hong - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Understanding medical image volumes is crucial in healthcare, yet most current models for classification and segmentation often focus narrowly on task-specific features without capturing the broader medical context. To address this, we introduce \u2026"}]
