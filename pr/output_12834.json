[{"title": "FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups", "link": "https://arxiv.org/pdf/2502.06695", "details": "G Nanfack, E Belilovsky - arXiv preprint arXiv:2502.06695, 2025", "abstract": "Deep learning models frequently exploit spurious features in training data to achieve low training error, often resulting in poor generalization when faced with shifted testing distributions. To address this issue, various methods from imbalanced \u2026"}, {"title": "FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training", "link": "https://arxiv.org/pdf/2502.00761", "details": "L Xu, X Zhang, F Duan, S Wang, J Wang, X Cai - arXiv preprint arXiv:2502.00761, 2025", "abstract": "Selecting high-quality data can significantly improve the pre-training efficiency of large language models (LLMs). Existing methods often rely on heuristic techniques and single quality signals, limiting their ability to comprehensively evaluate data \u2026"}, {"title": "Handwritten Character Image Generation for Effective Data Augmentation", "link": "https://www.jstage.jst.go.jp/article/transinf/advpub/0/advpub_2024EDP7201/_pdf", "details": "CS LEOW, T KITAGAWA, H YAJIMA, H NISHIZAKI - IEICE Transactions on Information \u2026, 2025", "abstract": "This study introduces data augmentation techniques to enhance training datasets for a Japanese handwritten character classification model, addressing the high cost of collecting extensive handwritten character data. A novel method is proposed to \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation", "link": "https://arxiv.org/pdf/2502.06563", "details": "C Qi, R Ma, B Li, H Du, B Hui, J Wu, Y Laili, C He - arXiv preprint arXiv:2502.06563, 2025", "abstract": "First-order logic (FOL) reasoning, which involves sequential deduction, is pivotal for intelligent systems and serves as a valuable task for evaluating reasoning capabilities, particularly in chain-of-thought (CoT) contexts. Existing benchmarks \u2026"}]
