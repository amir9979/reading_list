[{"title": "Should we pre-train a decoder in contrastive learning for dense prediction tasks?", "link": "https://arxiv.org/pdf/2503.17526", "details": "S Quetin, T Ghosh, F Maleki - arXiv preprint arXiv:2503.17526, 2025", "abstract": "Contrastive learning in self-supervised settings primarily focuses on pre-training encoders, while decoders are typically introduced and trained separately for downstream dense prediction tasks. This conventional approach, however \u2026"}, {"title": "SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language Model Interpretability", "link": "https://arxiv.org/pdf/2503.09532", "details": "A Karvonen, C Rager, J Lin, C Tigges, J Bloom\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Sparse autoencoders (SAEs) are a popular technique for interpreting language model activations, and there is extensive recent work on improving SAE effectiveness. However, most prior work evaluates progress using unsupervised \u2026"}, {"title": "SceneSplat: Gaussian Splatting-based Scene Understanding with Vision-Language Pretraining", "link": "https://arxiv.org/pdf/2503.18052", "details": "Y Li, Q Ma, R Yang, H Li, M Ma, B Ren, N Popovic\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recognizing arbitrary or previously unseen categories is essential for comprehensive real-world 3D scene understanding. Currently, all existing methods rely on 2D or textual modalities during training, or together at inference. This \u2026"}, {"title": "Interpretable Feature Interaction via Statistical Self-supervised Learning on Tabular Data", "link": "https://arxiv.org/pdf/2503.18048", "details": "X Zhang, H Xiong - arXiv preprint arXiv:2503.18048, 2025", "abstract": "In high-dimensional and high-stakes contexts, ensuring both rigorous statistical guarantees and interpretability in feature extraction from complex tabular data remains a formidable challenge. Traditional methods such as Principal Component \u2026"}, {"title": "Feature-Level Insights into Artificial Text Detection with Sparse Autoencoders", "link": "https://arxiv.org/pdf/2503.03601", "details": "K Kuznetsov, L Kushnareva, P Druzhinina\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Artificial Text Detection (ATD) is becoming increasingly important with the rise of advanced Large Language Models (LLMs). Despite numerous efforts, no single algorithm performs consistently well across different types of unseen text or \u2026"}, {"title": "Explaining Domain Shifts in Language: Concept erasing for Interpretable Image Classification", "link": "https://arxiv.org/pdf/2503.18483", "details": "Z Zeng, Y Su, J Sun, T Wen, H Zhang, Z Wang, B Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Concept-based models can map black-box representations to human- understandable concepts, which makes the decision-making process more transparent and then allows users to understand the reason behind predictions \u2026"}, {"title": "A Statistical Theory of Contrastive Learning via Approximate Sufficient Statistics", "link": "https://arxiv.org/pdf/2503.17538", "details": "L Lin, S Mei - arXiv preprint arXiv:2503.17538, 2025", "abstract": "Contrastive learning--a modern approach to extract useful representations from unlabeled data by training models to distinguish similar samples from dissimilar ones- -has driven significant progress in foundation models. In this work, we develop a new \u2026"}]
