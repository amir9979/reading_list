[{"title": "Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models", "link": "https://arxiv.org/pdf/2502.08922", "details": "X Zhou, Y Guo, R Ma, T Gui, Q Zhang, X Huang - arXiv preprint arXiv:2502.08922, 2025", "abstract": "Aligning Large Language Models (LLMs) with human preferences is crucial for their deployment in real-world applications. Recent advancements in Self-Rewarding Language Models suggest that an LLM can use its internal reward models (such as \u2026"}, {"title": "Personality Editing for Language Models through Relevant Knowledge Editing", "link": "https://arxiv.org/pdf/2502.11789", "details": "S Hwang, Y Kim, B Kim, H Lee - arXiv preprint arXiv:2502.11789, 2025", "abstract": "Large Language Models (LLMs) play a vital role in applications like conversational agents and content creation, where controlling a model's personality is crucial for maintaining tone, consistency, and engagement. However, traditional prompt-based \u2026"}, {"title": "EHR-Protect: A Steganographic Framework Based on Data-transformation to Protect Electronic Health Records", "link": "https://www.sciencedirect.com/science/article/pii/S2667305325000195", "details": "AWC D'Layla, NJ De La Croix, T Ahmad, F Han - Intelligent Systems with Applications, 2025", "abstract": "The increasing digitization of healthcare systems and the shift to Electronic Health Records (EHRs) have introduced critical security challenges, including unauthorized access, data breaches, and confidentiality risks. For example, the rapid exchange of \u2026"}, {"title": "Physician clinical decision modification and bias assessment in a randomized controlled trial of AI assistance", "link": "https://www.nature.com/articles/s43856-025-00781-2", "details": "E Goh, B Bunning, EC Khoong, RJ Gallo, A Milstein\u2026 - Communications Medicine, 2025", "abstract": "Background Artificial intelligence assistance in clinical decision making shows promise, but concerns exist about potential exacerbation of demographic biases in healthcare. This study aims to evaluate how physician clinical decisions and biases \u2026"}, {"title": "PsychBench: A comprehensive and professional benchmark for evaluating the performance of LLM-assisted psychiatric clinical practice", "link": "https://arxiv.org/pdf/2503.01903", "details": "R Wang, S Liu, L Zhang, X Zhu, R Yang, X Zhou, F Wu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The advent of Large Language Models (LLMs) offers potential solutions to address problems such as shortage of medical resources and low diagnostic consistency in psychiatric clinical practice. Despite this potential, a robust and comprehensive \u2026"}, {"title": "InfEHR: Resolving Clinical Uncertainty through Deep Geometric Learning on Electronic Health Records", "link": "https://www.researchsquare.com/article/rs-5953885/latest", "details": "G Nadkarni, J Kauffman, E Holmes, A Vaid, A Charney\u2026 - 2025", "abstract": "Electronic health records (EHRs) contain multimodal data that can inform diagnostic and prognostic clinical decisions but are often unsuited for advanced machine learning (ML)\u2013based patient-specific analyses. ML models and clinical heuristics \u2026"}, {"title": "If a Tree Falls?: Using the Electronic Medical Record to Understand How Patients Self-Advocate for Their Health and Quality of Life", "link": "https://www.liebertpub.com/doi/full/10.1089/jpm.2024.0548", "details": "S Padamati, TH Thomas - Journal of Palliative Medicine, 2025", "abstract": "(EHRs) have led to efforts to facilitate patient engagement. 1 Yet EHRs are infrequently designed to support recognition and support of patients, needs and priorities. 2, 3 For patients with serious illness, clinicians need to understand \u2026"}, {"title": "Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt Aggregation Framework", "link": "https://arxiv.org/pdf/2503.02863", "details": "Z Zhou, T Jin, J Shi, Q Li - arXiv preprint arXiv:2503.02863, 2025", "abstract": "Large Language Models (LLMs) often exhibit misaligned confidence scores, usually overestimating the reliability of their predictions. While verbalized confidence in Large Language Models (LLMs) has gained attention, prior work remains divided on \u2026"}, {"title": "MedEthicEval: Evaluating Large Language Models Based on Chinese Medical Ethics", "link": "https://arxiv.org/pdf/2503.02374", "details": "H Jin, J Shi, H Xu, KQ Zhu, M Wu - arXiv preprint arXiv:2503.02374, 2025", "abstract": "Large language models (LLMs) demonstrate significant potential in advancing medical applications, yet their capabilities in addressing medical ethics challenges remain underexplored. This paper introduces MedEthicEval, a novel benchmark \u2026"}]
