[{"title": "Consistent Amortized Clustering via Generative Flow Networks", "link": "https://arxiv.org/pdf/2502.19337", "details": "I Chelly, R Uziel, O Freifeld, A Pakman - arXiv preprint arXiv:2502.19337, 2025", "abstract": "Neural models for amortized probabilistic clustering yield samples of cluster labels given a set-structured input, while avoiding lengthy Markov chain runs and the need for explicit data likelihoods. Existing methods which label each data point \u2026"}, {"title": "GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models", "link": "https://arxiv.org/pdf/2502.01406", "details": "J Drechsel, S Herbold - arXiv preprint arXiv:2502.01406, 2025", "abstract": "AI systems frequently exhibit and amplify social biases, including gender bias, leading to harmful consequences in critical areas. This study introduces a novel encoder-decoder approach that leverages model gradients to learn a single \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}]
