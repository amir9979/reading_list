[{"title": "$\\texttt {MoE-RBench} $: Towards Building Reliable Language Models with Sparse Mixture-of-Experts", "link": "https://arxiv.org/pdf/2406.11353", "details": "G Chen, X Zhao, T Chen, Y Cheng - arXiv preprint arXiv:2406.11353, 2024", "abstract": "Mixture-of-Experts (MoE) has gained increasing popularity as a promising framework for scaling up large language models (LLMs). However, the reliability assessment of MoE lags behind its surging applications. Moreover, when transferred to new \u2026"}, {"title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models", "link": "https://aclanthology.org/2024.findings-naacl.18.pdf", "details": "Z Su, Z Lin, B Baixue, H Chen, S Hu, W Zhou, G Ding\u2026 - Findings of the Association \u2026, 2024", "abstract": "Generative language models are usually pre-trained on large text corpus via predicting the next token (ie, sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language \u2026"}, {"title": "Word Embeddings Are Steers for Language Models", "link": "https://blender.cs.illinois.edu/paper/lmsteer2024.pdf", "details": "C Han, J Xu, M Li, Y Fung, C Sun, N Jiang\u2026", "abstract": "Abstract Language models (LMs) automatically learn word embeddings during pre- training on language corpora. Although word embeddings are usually interpreted as feature vectors for individual words, their roles in language model generation remain \u2026"}, {"title": "Impact of response bias in three surveys on primary care providers' experiences with electronic health records", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae148/7695999", "details": "N Hendrix, N Maisel, J Everson, V Patel, A Bazemore\u2026 - Journal of the American \u2026, 2024", "abstract": "Objective To identify impacts of different survey methodologies assessing primary care physicians'(PCPs') experiences with electronic health records (EHRs), we compared three surveys: the 2022 Continuous Certification Questionnaire (CCQ) \u2026"}, {"title": "An Empirical Study of Mamba-based Language Models", "link": "https://arxiv.org/pdf/2406.07887", "details": "R Waleffe, W Byeon, D Riach, B Norick, V Korthikanti\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Selective state-space models (SSMs) like Mamba overcome some of the shortcomings of Transformers, such as quadratic computational complexity with sequence length and large inference-time memory requirements from the key-value \u2026"}, {"title": "Adaptive Rank Selections for Low-Rank Approximation of Language Models", "link": "https://aclanthology.org/2024.naacl-long.13.pdf", "details": "S Gao, T Hua, YC Hsu, Y Shen, H Jin - Proceedings of the 2024 Conference of the \u2026, 2024", "abstract": "Abstract Singular Value Decomposition (SVD) or its weighted variants has significantly progressed in compressing language models. Previous works assume the same importance for all operations and assign the same number of ranks for \u2026"}, {"title": "Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding", "link": "https://arxiv.org/pdf/2406.12295", "details": "K Zhang, J Wang, N Ding, B Qi, E Hua, X Lv, B Zhou - arXiv preprint arXiv:2406.12295, 2024", "abstract": "Large Language Models (LLMs) demonstrate impressive performance in diverse applications, yet they face significant drawbacks, including high inference latency, expensive training cost, and generation of hallucination. Collaborative decoding \u2026"}, {"title": "REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space", "link": "https://arxiv.org/pdf/2406.09325", "details": "T Ashuach, M Tutek, Y Belinkov - arXiv preprint arXiv:2406.09325, 2024", "abstract": "Large language models (LLMs) risk inadvertently memorizing and divulging sensitive or personally identifiable information (PII) seen in training data, causing privacy concerns. Current approaches to address this issue involve costly dataset \u2026"}, {"title": "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2406.12050", "details": "Z Zhang, Z Liang, W Yu, D Yu, M Jia, D Yu, M Jiang - arXiv preprint arXiv:2406.12050, 2024", "abstract": "Supervised fine-tuning enhances the problem-solving abilities of language models across various mathematical reasoning tasks. To maximize such benefits, existing research focuses on broadening the training set with various data augmentation \u2026"}]
