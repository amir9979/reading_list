[{"title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models", "link": "https://arxiv.org/pdf/2503.05005", "details": "B Jamialahmadi, P Kavehzadeh, M Rezagholizadeh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deploying large language models (LLMs) in real-world applications is often hindered by strict computational and latency constraints. While dynamic inference offers the flexibility to adjust model behavior based on varying resource budgets, existing \u2026"}, {"title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models", "link": "https://arxiv.org/pdf/2503.01464", "details": "B Nazarov, D Frolova, Y Lubarsky, A Gaissinski\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed on domain-specific data has shown significant promise. However, commercial use of such LLMs is limited by the high computational cost required for their deployment at \u2026"}, {"title": "TINY LongProLIP: A Probabilistic Vision-Language Model with Long Context Text", "link": "https://openreview.net/pdf%3Fid%3DjfwxBVBCiD", "details": "S Chun, S Yun - \u2026 Workshop: Quantify Uncertainty and Hallucination in \u2026", "abstract": "Recently, Probabilistic Language-Image Pre-Training (ProLIP) has been proposed to tackle the multiplicity issue of vision-language (VL) tasks. Despite their success in probabilistic representation learning at a scale, the ProLIP models cannot handle \u2026"}, {"title": "Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning", "link": "https://arxiv.org/pdf/2502.18080", "details": "W Yang, S Ma, Y Lin, F Wei - arXiv preprint arXiv:2502.18080, 2025", "abstract": "Recent studies have shown that making a model spend more time thinking through longer Chain of Thoughts (CoTs) enables it to gain significant improvements in complex reasoning tasks. While current researches continue to explore the benefits \u2026"}, {"title": "Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety", "link": "https://arxiv.org/pdf/2503.05021", "details": "Y Zhang, M Li, W Han, Y Yao, Z Cen, D Zhao - arXiv preprint arXiv:2503.05021, 2025", "abstract": "Large Language Models (LLMs) are vulnerable to jailbreak attacks that exploit weaknesses in traditional safety alignment, which often relies on rigid refusal heuristics or representation engineering to block harmful outputs. While they are \u2026"}, {"title": "PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection", "link": "https://arxiv.org/pdf/2502.12119", "details": "J Bi, Y Wang, D Yan, X Xiao, A Hecker, V Tresp, Y Ma - arXiv preprint arXiv \u2026, 2025", "abstract": "Visual instruction tuning refines pre-trained Multimodal Large Language Models (MLLMs) to enhance their real-world task performance. However, the rapid expansion of visual instruction datasets introduces significant data redundancy \u2026"}, {"title": "Reducing Hallucinations of Medical Multimodal Large Language Models with Visual Retrieval-Augmented Generation", "link": "https://arxiv.org/pdf/2502.15040", "details": "YW Chu, K Zhang, C Malon, MR Min - arXiv preprint arXiv:2502.15040, 2025", "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive performance in vision and text tasks. However, hallucination remains a major challenge, especially in fields like healthcare where details are critical. In this work, we show \u2026"}, {"title": "Analyzing patient perspectives with large language models: a cross-sectional study of sentiment and thematic classification on exception from informed consent", "link": "https://www.nature.com/articles/s41598-025-89996-w", "details": "AE Kornblith, C Singh, JC Innes, TP Chang\u2026 - Scientific reports, 2025", "abstract": "Large language models (LLMs) can improve text analysis efficiency in healthcare. This study explores the application of LLMs to analyze patient perspectives within the exception from informed consent (EFIC) process, which waives consent in \u2026"}, {"title": "Liger: Linearizing Large Language Models to Gated Recurrent Structures", "link": "https://arxiv.org/pdf/2503.01496", "details": "D Lan, W Sun, J Hu, J Du, Y Cheng - arXiv preprint arXiv:2503.01496, 2025", "abstract": "Transformers with linear recurrent modeling offer linear-time training and constant- memory inference. Despite their demonstrated efficiency and performance, pretraining such non-standard architectures from scratch remains costly and risky \u2026"}]
