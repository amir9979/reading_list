[{"title": "Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement", "link": "https://arxiv.org/pdf/2405.15973", "details": "X Wang, J Chen, Z Wang, Y Zhou, Y Zhou, H Yao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large vision-language models (LVLMs) have achieved impressive results in various visual question-answering and reasoning tasks through vision instruction tuning on specific datasets. However, there is still significant room for improvement in the \u2026"}, {"title": "DiNADO: Norm-Disentangled Neurally-Decomposed Oracles for Controlling Language Models", "link": "https://openreview.net/pdf%3Fid%3Dpvg1OdUtDQ", "details": "S Lu, W Zhao, C Tao, A Gupta, S Wu, T Chung, N Peng - Forty-first International Conference \u2026", "abstract": "NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable generation with large language models. It is designed to avoid catastrophic forgetting while achieving guaranteed convergence to an entropy-maximized closed-form \u2026"}, {"title": "ULTRAFEEDBACK: Boosting Language Models with Scaled AI Feedback", "link": "https://openreview.net/pdf%3Fid%3DBOorDpKHiJ", "details": "G Cui, L Yuan, N Ding, G Yao, B He, W Zhu, Y Ni, G Xie\u2026 - Forty-first International Conference \u2026", "abstract": "Learning from human feedback has become a pivot technique in aligning large language models (LLMs) with human preferences. However, acquiring vast and premium human feedback is bottlenecked by time, labor, and human capability \u2026"}, {"title": "Impact of high-quality, mixed-domain data on the performance of medical language models", "link": "https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae120/7680487", "details": "M Griot, C Hemptinne, J Vanderdonckt, D Yuksel - Journal of the American Medical \u2026, 2024", "abstract": "Objective To optimize the training strategy of large language models for medical applications, focusing on creating clinically relevant systems that efficiently integrate into healthcare settings, while ensuring high standards of accuracy and reliability \u2026"}, {"title": "Label Propagation for Zero-shot Classification with Vision-Language Models", "link": "https://openaccess.thecvf.com/content/CVPR2024/papers/Stojni_Label_Propagation_for_Zero-shot_Classification_with_Vision-Language_Models_CVPR_2024_paper.pdf", "details": "Y Kalantidis, G Tolias - Proceedings of the IEEE/CVF Conference on Computer \u2026, 2024", "abstract": "Abstract Vision-Language Models (VLMs) have demonstrated impressive performance on zero-shot classification ie classification when provided merely with a list of class names. In this paper we tackle the case of zero-shot classification in the \u2026"}, {"title": "Super Tiny Language Models", "link": "https://arxiv.org/pdf/2405.14159", "details": "D Hillier, L Guertler, C Tan, P Agrawal, C Ruirui\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large language models (LLMs) has led to significant improvements in natural language processing but also poses challenges due to their high computational and energy demands. This paper introduces a series of research \u2026"}, {"title": "Refining Skewed Perceptions in Vision-Language Models through Visual Representations", "link": "https://arxiv.org/pdf/2405.14030", "details": "H Dai, S Joshi - arXiv preprint arXiv:2405.14030, 2024", "abstract": "Large vision-language models (VLMs), such as CLIP, have become foundational, demonstrating remarkable success across a variety of downstream tasks. Despite their advantages, these models, akin to other foundational systems, inherit biases \u2026"}, {"title": "Repurposing Language Models into Embedding Models: Finding the Compute-Optimal Recipe", "link": "https://arxiv.org/pdf/2406.04165", "details": "A Ziarko, AQ Jiang, B Piotrowski, W Li, M Jamnik\u2026 - arXiv e-prints, 2024", "abstract": "Text embeddings are essential for many tasks, such as document retrieval, clustering, and semantic similarity assessment. In this paper, we study how to contrastively train text embedding models in a compute-optimal fashion, given a suite \u2026"}, {"title": "DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for Unconventional Reasoning", "link": "https://arxiv.org/pdf/2405.11559", "details": "SV Mathur, AR Jindal, M Shrivastava - arXiv preprint arXiv:2405.11559, 2024", "abstract": "While significant work has been done in the field of NLP on vertical thinking, which involves primarily logical thinking, little work has been done towards lateral thinking, which involves looking at problems from an unconventional perspective and defying \u2026"}]
