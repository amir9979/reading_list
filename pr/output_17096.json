[{"title": "Refining Labeling Functions with Limited Labeled Data", "link": "https://arxiv.org/pdf/2505.23470", "details": "C Li, A Gilad, B Glavic, Z Miao, S Roy - arXiv preprint arXiv:2505.23470, 2025", "abstract": "Programmatic weak supervision (PWS) significantly reduces human effort for labeling data by combining the outputs of user-provided labeling functions (LFs) on unlabeled datapoints. However, the quality of the generated labels depends directly \u2026", "entry_id": "http://arxiv.org/abs/2505.23470v1", "updated": "2025-05-29 14:26:11", "published": "2025-05-29 14:26:11", "authors": "Chenjie Li;Amir Gilad;Boris Glavic;Zhengjie Miao;Sudeepa Roy", "summary": "Programmatic weak supervision (PWS) significantly reduces human effort for\nlabeling data by combining the outputs of user-provided labeling functions\n(LFs) on unlabeled datapoints. However, the quality of the generated labels\ndepends directly on the accuracy of the LFs. In this work, we study the problem\nof fixing LFs based on a small set of labeled examples. Towards this goal, we\ndevelop novel techniques for repairing a set of LFs by minimally changing their\nresults on the labeled examples such that the fixed LFs ensure that (i) there\nis sufficient evidence for the correct label of each labeled datapoint and (ii)\nthe accuracy of each repaired LF is sufficiently high. We model LFs as\nconditional rules which enables us to refine them, i.e., to selectively change\ntheir output for some inputs. We demonstrate experimentally that our system\nimproves the quality of LFs based on surprisingly small sets of labeled\ndatapoints.", "comment": "techreport", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.IT;math.IT", "links": "http://arxiv.org/abs/2505.23470v1;http://arxiv.org/pdf/2505.23470v1", "pdf_url": "http://arxiv.org/pdf/2505.23470v1"}, {"title": "Extracting social determinants of health from dental clinical notes", "link": "https://www.thieme-connect.com/products/ejournals/abstract/10.1055/a-2616-9858", "details": "F Pethani, A Chapman, M Conway, X Dai, D Bishay\u2026 - Applied Clinical Informatics, 2025", "abstract": "Objective In dentistry, social determinants of health (SDoH) are potentially recorded in the clinical notes of Electronic Dental Records (EDRs). The objective of this study was to examine the availability of SDoH data in dental clinical notes and evaluate \u2026"}, {"title": "Exploring Scaling Laws for EHR Foundation Models", "link": "https://arxiv.org/pdf/2505.22964", "details": "S Zhang, Q Liu, N Usuyama, C Wong, T Naumann\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The emergence of scaling laws has profoundly shaped the development of large language models (LLMs), enabling predictable performance gains through systematic increases in model size, dataset volume, and compute. Yet, these \u2026", "entry_id": "http://arxiv.org/abs/2505.22964v1", "updated": "2025-05-29 01:05:11", "published": "2025-05-29 01:05:11", "authors": "Sheng Zhang;Qin Liu;Naoto Usuyama;Cliff Wong;Tristan Naumann;Hoifung Poon", "summary": "The emergence of scaling laws has profoundly shaped the development of large\nlanguage models (LLMs), enabling predictable performance gains through\nsystematic increases in model size, dataset volume, and compute. Yet, these\nprinciples remain largely unexplored in the context of electronic health\nrecords (EHRs) -- a rich, sequential, and globally abundant data source that\ndiffers structurally from natural language. In this work, we present the first\nempirical investigation of scaling laws for EHR foundation models. By training\ntransformer architectures on patient timeline data from the MIMIC-IV database\nacross varying model sizes and compute budgets, we identify consistent scaling\npatterns, including parabolic IsoFLOPs curves and power-law relationships\nbetween compute, model parameters, data size, and clinical utility. These\nfindings demonstrate that EHR models exhibit scaling behavior analogous to\nLLMs, offering predictive insights into resource-efficient training strategies.\nOur results lay the groundwork for developing powerful EHR foundation models\ncapable of transforming clinical prediction tasks and advancing personalized\nhealthcare.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI;cs.LG", "links": "http://arxiv.org/abs/2505.22964v1;http://arxiv.org/pdf/2505.22964v1", "pdf_url": "http://arxiv.org/pdf/2505.22964v1"}]
