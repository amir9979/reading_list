[{"title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning", "link": "https://arxiv.org/pdf/2412.09906", "details": "J Bi, Y Wu, W Xing, Z Wei - arXiv preprint arXiv:2412.09906, 2024", "abstract": "Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks. Advances in prompt engineering and fine-tuning techniques have further enhanced their ability to address complex reasoning challenges \u2026"}, {"title": "Scaling dense representations for single cell with transcriptome-scale context", "link": "https://www.biorxiv.org/content/10.1101/2024.11.28.625303.full.pdf", "details": "N Ho, CN Ellington, J Hou, S Addagudi, S Mo, T Tao\u2026 - bioRxiv, 2024", "abstract": "Developing a unified model of cellular systems is a canonical challenge in biology. Recently, a wealth of public single-cell RNA sequencing data as well as rapid scaling of self-supervised learning methods have provided new avenues to address \u2026"}, {"title": "Label-template based Few-Shot Text Classification with Contrastive Learning", "link": "https://arxiv.org/pdf/2412.10110", "details": "G Hou, S Cao, D Ouyang, N Wang - arXiv preprint arXiv:2412.10110, 2024", "abstract": "As an algorithmic framework for learning to learn, meta-learning provides a promising solution for few-shot text classification. However, most existing research fail to give enough attention to class labels. Traditional basic framework building \u2026"}, {"title": "Large language models: game-changers in the healthcare industry", "link": "https://pubmed.ncbi.nlm.nih.gov/39674769/", "details": "B Dong, L Zhang, J Yuan, Y Chen, Q Li, L Shen - Science bulletin, 2024", "abstract": "Large language models: game-changers in the healthcare industry Large language models: game-changers in the healthcare industry Sci Bull (Beijing). 2024 Nov 26:S2095-9273(24)00847-8. doi: 10.1016/j.scib.2024.11.031. Online ahead of print. Authors Bin Dong 1 , Li Zhang \u2026"}, {"title": "Detecting LLM Hallucination Through Layer-wise Information Deficiency: Analysis of Unanswerable Questions and Ambiguous Prompts", "link": "https://arxiv.org/pdf/2412.10246", "details": "H Kim, A Bibi, P Torr, Y Gal - arXiv preprint arXiv:2412.10246, 2024", "abstract": "Large language models (LLMs) frequently generate confident yet inaccurate responses, introducing significant risks for deployment in safety-critical domains. We present a novel approach to detecting model hallucination through systematic \u2026"}]
