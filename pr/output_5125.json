[{"title": "AutoCTS++: zero-shot joint neural architecture and hyperparameter search for correlated time series forecasting", "link": "https://vbn.aau.dk/files/730426496/AutoCTS_.pdf", "details": "X Wu, X Wu, B Yang, L Zhou, C Guo, X Qiu, J Hu\u2026 - The VLDB Journal, 2024", "abstract": "Sensors in cyber-physical systems often capture interconnected processes and thus emit correlated time series (CTS), the forecasting of which enables important applications. Recent deep learning based forecasting methods show strong \u2026"}, {"title": "Relation-Preserving Masked Modeling for Semi-Supervised Time-Series Classification", "link": "https://www.sciencedirect.com/science/article/pii/S0020025524011277", "details": "S Lee, C Choi, Y Son - Information Sciences, 2024", "abstract": "In this study, we address the challenge of label sparsity in time-series classification using semi-supervised learning that effectively leverages numerous unlabeled instances. Our approach introduces a pioneering framework for semi-supervised \u2026"}, {"title": "Multivariate Time Series Anomaly Detection based on Pre-trained Models with Dual-Attention Mechanism", "link": "https://nkcs.iops.ai/wp-content/uploads/2024/08/ISSRE24-DualLMAD.pdf", "details": "Y Sun, Y Guo, M Liang, X Wen, J Kuang, S Zhang, H Li\u2026", "abstract": "In major tech companies, monitoring server performance data with anomaly detection algorithms is crucial for assessing operational status. Existing models often require separate training or fine-tuning for each server due to generalization \u2026"}, {"title": "Revisiting Attention for Multivariate Time Series Forecasting", "link": "https://arxiv.org/pdf/2407.13806", "details": "H Wu - arXiv preprint arXiv:2407.13806, 2024", "abstract": "Current Transformer methods for Multivariate Time-Series Forecasting (MTSF) are all based on the conventional attention mechanism. They involve sequence embedding and performing a linear projection of Q, K, and V, and then computing attention within \u2026"}]
