'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Navigating Brain Language Representations: A Comparati'
[{"title": "Transparent deep learning to identify autism spectrum disorders (ASD) in EHR using clinical notes", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae080/7646767%3Fitm_medium%3Dsidebar%26itm_source%3Dtrendmd-widget%26itm_campaign%3DJournal_of_the_American_Medical_Informatics_Association%26itm_content%3DJournal_of_the_American_Medical_Informatics_Association_0", "details": "G Leroy, JG Andrews, M KeAlohi-Preece, A Jaswani\u2026 - Journal of the American \u2026, 2024", "abstract": "Objective Machine learning (ML) is increasingly employed to diagnose medical conditions, with algorithms trained to assign a single label using a black-box approach. We created an ML approach using deep learning that generates \u2026"}, {"title": "SpaceByte: Towards Deleting Tokenization from Large Language Modeling", "link": "https://arxiv.org/pdf/2404.14408", "details": "K Slagle - arXiv preprint arXiv:2404.14408, 2024", "abstract": "Tokenization is widely used in large language models because it significantly improves performance. However, tokenization imposes several disadvantages, such as performance biases, increased adversarial vulnerability, decreased character \u2026"}, {"title": "Dissecting Paraphrases: The Impact of Prompt Syntax and supplementary Information on Knowledge Retrieval from Pretrained Language Models", "link": "https://arxiv.org/pdf/2404.01992", "details": "S Linzbach, D Dimitrov, L Kallmeyer, K Evang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Pre-trained Language Models (PLMs) are known to contain various kinds of knowledge. One method to infer relational knowledge is through the use of cloze- style prompts, where a model is tasked to predict missing subjects or objects \u2026"}]
