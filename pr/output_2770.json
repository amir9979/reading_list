[{"title": "Self-Contrastive Weakly Supervised Learning Framework for Prognostic Prediction Using Whole Slide Images", "link": "https://arxiv.org/pdf/2405.15264", "details": "S Fuster, F Khoraminia, J Silva-Rodr\u00edguez, U Kiraz\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present a pioneering investigation into the application of deep learning techniques to analyze histopathological images for addressing the substantial challenge of automated prognostic prediction. Prognostic prediction poses a unique \u2026"}, {"title": "Benchmarking Hierarchical Image Pyramid Transformer for the classification of colon biopsies and polyps in histopathology images", "link": "https://arxiv.org/pdf/2405.15127", "details": "NSL Contreras, M D'Amato, F Ciompi, C Grisi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Training neural networks with high-quality pixel-level annotation in histopathology whole-slide images (WSI) is an expensive process due to gigapixel resolution of WSIs. However, recent advances in self-supervised learning have shown that highly \u2026"}, {"title": "The value of apparent diffusion coefficient values in predicting Gleason grading of low to intermediate-risk prostate cancer", "link": "https://link.springer.com/article/10.1186/s13244-024-01684-x", "details": "X Yan, K Ma, L Zhu, Y Pan, Y Wang, J Shi, X Mai - Insights into Imaging, 2024", "abstract": "Objectives To investigate the diagnostic performance of the apparent diffusion coefficient (ADC) for low to intermediate-risk prostate cancer (PCa), as well as its correlation with the prognostic Gleason score (GS). Materials and methods \u2026"}, {"title": "Combining Graph Neural Network and Mamba to Capture Local and Global Tissue Spatial Relationships in Whole Slide Images", "link": "https://arxiv.org/pdf/2406.04377", "details": "R Ding, KD Luong, E Rodriguez, ACAL da Silva, W Hsu - arXiv preprint arXiv \u2026, 2024", "abstract": "In computational pathology, extracting spatial features from gigapixel whole slide images (WSIs) is a fundamental task, but due to their large size, WSIs are typically segmented into smaller tiles. A critical aspect of this analysis is aggregating \u2026"}, {"title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models", "link": "https://arxiv.org/pdf/2406.02224", "details": "T Fan, G Ma, Y Kang, H Gu, L Fan, Q Yang - arXiv preprint arXiv:2406.02224, 2024", "abstract": "Recent research in federated large language models (LLMs) has primarily focused on enabling clients to fine-tune their locally deployed homogeneous LLMs collaboratively or on transferring knowledge from server-based LLMs to small \u2026"}, {"title": "Is On-Device AI Broken and Exploitable? Assessing the Trust and Ethics in Small Language Models", "link": "https://arxiv.org/pdf/2406.05364", "details": "K Nakka, J Dani, N Saxena - arXiv preprint arXiv:2406.05364, 2024", "abstract": "In this paper, we present a very first study to investigate trust and ethical implications of on-device artificial intelligence (AI), focusing on''small''language models (SLMs) amenable for personal devices like smartphones. While on-device SLMs promise \u2026"}, {"title": "Probe Then Retrieve and Reason: Distilling Probing and Reasoning Capabilities into Smaller Language Models", "link": "https://aclanthology.org/2024.lrec-main.1140.pdf", "details": "Y Zhao, S Zhou, H Zhu - Proceedings of the 2024 Joint International Conference \u2026, 2024", "abstract": "Step-by-step reasoning methods, such as the Chain-of-Thought (CoT), have been demonstrated to be highly effective in harnessing the reasoning capabilities of Large Language Models (LLMs). Recent research efforts have sought to distill LLMs into \u2026"}]
