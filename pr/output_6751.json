[{"title": "MobileQuant: Mobile-friendly Quantization for On-device Language Models", "link": "https://arxiv.org/pdf/2408.13933", "details": "F Tan, R Lee, \u0141 Dudziak, SX Hu, S Bhattacharya\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) have revolutionized language processing, delivering outstanding results across multiple applications. However, deploying LLMs on edge devices poses several challenges with respect to memory, energy, and compute \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "Egalitarian Language Representation in Language Models: It All Begins with Tokenizers", "link": "https://arxiv.org/pdf/2409.11501", "details": "M Velayuthan, K Sarveswaran - arXiv preprint arXiv:2409.11501, 2024", "abstract": "Tokenizers act as a bridge between human language and the latent space of language models, influencing how language is represented in these models. Due to the immense popularity of English-Centric Large Language Models (LLMs), efforts \u2026"}, {"title": "Designing Retrieval-Augmented Language Models for Clinical Decision", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DWcMbEQAAQBAJ%26oi%3Dfnd%26pg%3DPA159%26ots%3DtCwYq-XKbl%26sig%3DkTPnvJoqPQcSXkSWgIglQ6whKFw", "details": "K Quigley, T Koker, J Taylor, V Mancuso - AI for Health Equity and Fairness: Leveraging AI to \u2026", "abstract": "Ever-increasing demands for physician expertise drive the need for trust-worthy point- of-care tools that can help aid decision-making in all clinical settings. Retrieval- augmented language models carry potential to relieve the information burden on \u2026"}, {"title": "Enhanced Prompt Learning for Few-shot Text Classification Method", "link": "https://search.proquest.com/openview/58909c856764791ee70d5ec9bee01321/1%3Fpq-origsite%3Dgscholar%26cbl%3D2048897", "details": "L Ruifan, W Zhiyu, F Yuantao, Y Shuqin, Z Guangwei - Beijing Da Xue Xue Bao, 2024", "abstract": "An enhanced prompt learning method (EPL4FTC) for few-shot text classification task is proposed. This algorithm first converts the text classification task into the form of prompt learning based on natural language inference. Thus, the implicit data \u2026"}, {"title": "Scaling Pre-training Data and Language Models for African Languages", "link": "https://uwspace.uwaterloo.ca/bitstreams/0eb3cf2b-5660-492e-8be6-6f4d4e82f5e1/download", "details": "A Oladipo - 2024", "abstract": "Recent advancements in language models, particularly for high-resource languages, have not been paralleled in low-resource languages spoken across Africa. This thesis addresses this gap by scaling pre-training data and developing improved \u2026"}, {"title": "Cross-lingual Natural Language Processing on Limited Annotated Case/Radiology Reports in English and Japanese: Insights from the Real-MedNLP Workshop", "link": "https://www.thieme-connect.com/products/ejournals/pdf/10.1055/a-2405-2489.pdf", "details": "S Yada, Y Nakamura, S Wakamiya, E Aramaki - Methods of Information in Medicine, 2024", "abstract": "Background: Textual datasets (corpora) are crucial for the application of natural language processing (NLP) models. However, corpus creation in the medical field is challenging, primarily because of privacy issues with raw clinical data such as health \u2026"}, {"title": "Generating colloquial radiology reports with large language models", "link": "https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae223/7740004", "details": "CC Tang, S Nagesh, DA Fussell, J Glavis-Bloom\u2026 - Journal of the American \u2026, 2024", "abstract": "Objectives Patients are increasingly being given direct access to their medical records. However, radiology reports are written for clinicians and typically contain medical jargon, which can be confusing. One solution is for radiologists to provide a \u2026"}, {"title": "Low-Hanging Fruit: Knowledge Distillation from Noisy Teachers for Open Domain Spoken Language Understanding", "link": "https://link.springer.com/chapter/10.1007/978-3-031-70359-1_7", "details": "C Chen, B Xing, IW Tsang - Joint European Conference on Machine Learning and \u2026, 2024", "abstract": "Abstract Spoken Language Understanding (SLU) plays an integral role in dialogue systems. However, conventional SLU relies heavily on manually annotated datasets, which are impractical for open-domain SLU, given the wide variety of topics that must \u2026"}]
