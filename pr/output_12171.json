[{"title": "Dynamically Scaled Temperature in Self-Supervised Contrastive Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10820841/", "details": "S Manna, S Chattopadhyay, R Dey, U Pal\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples of different classes is primarily affected by the presence of \u2026"}, {"title": "CLE-SMOTE: Addressing Imbalanced Chest X-Ray Classification with Contrastive Learning-Enhanced SMOTE", "link": "https://openreview.net/forum%3Fid%3DrvkUvOEuBc", "details": "Z Nabulsi, C Lee, R Yun, A Kan, C Kan, F Nabulsi\u2026 - Medical Imaging with Deep \u2026", "abstract": "Class imbalance is a prevalent issue in many healthcare tasks, where diseases of interest are exceedingly rare in datasets. This issue is especially relevant in chest X- ray classification, where specific subconditions appear significantly less frequently \u2026"}, {"title": "CmEAA: Cross-modal Enhancement and Alignment Adapter for Radiology Report Generation", "link": "https://aclanthology.org/2025.coling-main.571.pdf", "details": "X Huang, Y Han, L Yx, R Li, P Wu, K Zhang - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "Automatic radiology report generation is pivotal in reducing the workload of radiologists, while simultaneously improving diagnostic accuracy and operational efficiency. Current methods face significant challenges, including the effective \u2026"}, {"title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "link": "https://arxiv.org/pdf/2501.12266", "details": "C Patr\u00edcio, I Rio-Torto, JS Cardoso, LF Teixeira\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The main challenges limiting the adoption of deep learning-based solutions in medical workflows are the availability of annotated data and the lack of interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the latter \u2026"}, {"title": "WeakSupCon: Weakly Supervised Contrastive Learning for Encoder Pre-training", "link": "https://openreview.net/forum%3Fid%3DfZknaOJUh5", "details": "B Zhang, H Manoochehri, B Knudsen, T Tasdizen - Medical Imaging with Deep Learning", "abstract": "Weakly supervised multiple instance learning (MIL) is a challenging task given that only bag-level labels are provided, while each bag typically contains multiple instances. This topic has been extensively studied in histopathological image \u2026"}, {"title": "SHYI: Action Support for Contrastive Learning in High-Fidelity Text-to-Image Generation", "link": "https://arxiv.org/abs/2501.09055", "details": "T Xia, L Xiao, Y Montorfani, F Pavia, E Simsar\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In this project, we address the issue of infidelity in text-to-image generation, particularly for actions involving multiple objects. For this we build on top of the CONFORM framework which uses Contrastive Learning to improve the accuracy of \u2026"}, {"title": "Synthetic Feature Augmentation Improves Generalization Performance of Language Models", "link": "https://arxiv.org/pdf/2501.06434", "details": "A Choudhary, C Thiels, H Salehinejad - arXiv preprint arXiv:2501.06434, 2025", "abstract": "Training and fine-tuning deep learning models, especially large language models (LLMs), on limited and imbalanced datasets poses substantial challenges. These issues often result in poor generalization, where models overfit to dominant classes \u2026"}, {"title": "A simple aerial detection baseline of multimodal language models", "link": "https://arxiv.org/pdf/2501.09720", "details": "Q Li, Y Chen, X Shu, D Chen, X He, Y Yu, X Yang - arXiv preprint arXiv:2501.09720, 2025", "abstract": "The multimodal language models (MLMs) based on generative pre-trained Transformer are considered powerful candidates for unifying various domains and tasks. MLMs developed for remote sensing (RS) have demonstrated outstanding \u2026"}, {"title": "Supervision-free Vision-Language Alignment", "link": "https://arxiv.org/pdf/2501.04568%3F", "details": "G Giannone, R Li, Q Feng, E Perevodchikov, R Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation \u2026"}]
