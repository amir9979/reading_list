[{"title": "Image2Struct: Benchmarking Structure Extraction for Vision-Language Models", "link": "https://arxiv.org/pdf/2410.22456", "details": "JS Roberts, T Lee, CH Wong, M Yasunaga, Y Mai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce Image2Struct, a benchmark to evaluate vision-language models (VLMs) on extracting structure from images. Our benchmark 1) captures real-world use cases, 2) is fully automatic and does not require human judgment, and 3) is \u2026"}, {"title": "Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines", "link": "https://arxiv.org/pdf/2410.21220", "details": "Z Zhang, Y Zhang, X Ding, X Yue - arXiv preprint arXiv:2410.21220, 2024", "abstract": "Search engines enable the retrieval of unknown information with texts. However, traditional methods fall short when it comes to understanding unfamiliar visual content, such as identifying an object that the model has never seen before. This \u2026"}, {"title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.17637", "details": "Z Liu, Y Zang, X Dong, P Zhang, Y Cao, H Duan, C He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing \u2026"}, {"title": "Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector", "link": "https://arxiv.org/pdf/2410.22888", "details": "Y Huang, F Zhu, J Tang, P Zhou, W Lei, J Lv, TS Chua - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual Language Models (VLMs) are vulnerable to adversarial attacks, especially those from adversarial images, which is however under-explored in literature. To facilitate research on this critical safety problem, we first construct a new laRge-scale \u2026"}, {"title": "RuleRAG: Rule-guided retrieval-augmented generation with language models for question answering", "link": "https://arxiv.org/pdf/2410.22353", "details": "Z Chen, C Xu, D Wang, Z Huang, Y Dou, J Guo - arXiv preprint arXiv:2410.22353, 2024", "abstract": "Retrieval-augmented generation (RAG) framework has shown promising potential in knowledge-intensive question answering (QA) by retrieving external corpus and generating based on augmented context. However, existing approaches only \u2026"}, {"title": "LanFL: Differentially Private Federated Learning with Large Language Models using Synthetic Samples", "link": "https://arxiv.org/pdf/2410.19114", "details": "H Wu, D Klabjan - arXiv preprint arXiv:2410.19114, 2024", "abstract": "Federated Learning (FL) is a collaborative, privacy-preserving machine learning framework that enables multiple participants to train a single global model. However, the recent advent of powerful Large Language Models (LLMs) with tens to hundreds \u2026"}, {"title": "Transformer-based Language Models for Reasoning in the Description Logic ALCQ", "link": "https://arxiv.org/pdf/2410.09613", "details": "A Poulis, E Tsalapati, M Koubarakis - arXiv preprint arXiv:2410.09613, 2024", "abstract": "Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order \u2026"}, {"title": "SimpsonsVQA: Enhancing Inquiry-Based Learning with a Tailored Dataset", "link": "https://arxiv.org/pdf/2410.22648", "details": "ND Huynh, MR Bouadjenek, S Aryal, I Razzak, H Hacid - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual Question Answering (VQA) has emerged as a promising area of research to develop AI-based systems for enabling interactive and immersive learning. Numerous VQA datasets have been introduced to facilitate various tasks, such as \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}]
