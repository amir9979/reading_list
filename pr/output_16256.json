[{"title": "CSPLADE: Learned Sparse Retrieval with Causal Language Models", "link": "https://arxiv.org/pdf/2504.10816", "details": "Z Xu, A Feng, Y Tian, H Ding, LL Cheong - arXiv preprint arXiv:2504.10816, 2025", "abstract": "In recent years, dense retrieval has been the focus of information retrieval (IR) research. While effective, dense retrieval produces uninterpretable dense vectors, and suffers from the drawback of large index size. Learned sparse retrieval (LSR) \u2026"}, {"title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "link": "https://arxiv.org/pdf/2505.04847", "details": "MS Tamber, FS Bao, C Xu, G Luo, S Kazi, M Bae, M Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce hallucinations by grounding responses in contexts. However, even when provided context, LLMs still frequently introduce unsupported information or contradictions \u2026"}, {"title": "DICE: A Framework for Dimensional and Contextual Evaluation of Language Models", "link": "https://arxiv.org/pdf/2504.10359%3F", "details": "A Shrivastava, PA Aoyagui - arXiv preprint arXiv:2504.10359, 2025", "abstract": "Language models (LMs) are increasingly being integrated into a wide range of applications, yet the modern evaluation paradigm does not sufficiently reflect how they are actually being used. Current evaluations rely on benchmarks that often lack \u2026"}, {"title": "On the Effectiveness of Prompt Stealing Attacks on In-The-Wild Prompts", "link": "https://xinyueshen.me/papers/SP25-PromptStealingInTheWild.pdf", "details": "Y Tan, X Shen, Y Shen, M Backes, Y Zhang - world, 2025", "abstract": "Large Language Models (LLMs) have increased demand for high-quality prompts, which are now considered valuable commodities in prompt marketplaces. However, this demand has also led to the emergence of prompt stealing attacks, where the \u2026"}, {"title": "Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure", "link": "https://arxiv.org/pdf/2504.10049%3F", "details": "T Gigant, C Guinaudeau, F Dufaux - arXiv preprint arXiv:2504.10049, 2025", "abstract": "Vision-Language Models (VLMs) can process visual and textual information in multiple formats: texts, images, interleaved texts and images, or even hour-long videos. In this work, we conduct fine-grained quantitative and qualitative analyses of \u2026"}, {"title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark", "link": "https://arxiv.org/pdf/2504.07749%3F", "details": "V Mikhailov, T Enstad, D Samuel, HC Farseth\u00e5s\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper introduces NorEval, a new and comprehensive evaluation suite for large- scale standardized benchmarking of Norwegian generative language models (LMs). NorEval consists of 24 high-quality human-created datasets--of which five are \u2026"}, {"title": "Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2504.09910", "details": "Y Wang, H Zhang, L Pang, Y Tong, B Guo, H Zheng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Retrieval-Augmented Generation (RAG) is a promising technique for applying LLMs to proprietary domains. However, retrieved documents may contain sensitive knowledge, posing risks of privacy leakage in generative results. Thus, effectively \u2026"}, {"title": "Racing Thoughts: Explaining Contextualization Errors in Large Language Models", "link": "https://aclanthology.org/2025.naacl-long.155.pdf", "details": "MA Lepori, MC Mozer, A Ghandeharioun - Proceedings of the 2025 Conference of the \u2026, 2025", "abstract": "The profound success of transformer-based language models can largely be attributed to their ability to integrate relevant contextual information from an input sequence in order to generate a response or complete a task. However, we know \u2026"}, {"title": "Large language models could be rote learners", "link": "https://arxiv.org/pdf/2504.08300", "details": "Y Xu, R Hu, H Ying, J Wu, X Shi, W Lin - arXiv preprint arXiv:2504.08300, 2025", "abstract": "Multiple-choice question (MCQ) benchmarks are widely used for evaluating Large Language Models (LLMs), yet their reliability is undermined by benchmark contamination. In this study, we reframe contamination as an inherent aspect of \u2026"}]
