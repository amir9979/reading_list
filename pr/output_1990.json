[{"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "A Study on Developer Behaviors for Validating and Repairing LLM-Generated Code Using Eye Tracking and IDE Actions", "link": "https://arxiv.org/pdf/2405.16081", "details": "N Tang, M Chen, Z Ning, A Bansal, Y Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The increasing use of large language model (LLM)-powered code generation tools, such as GitHub Copilot, is transforming software engineering practices. This paper investigates how developers validate and repair code generated by Copilot and \u2026"}, {"title": "Processing of clinical notes for efficient diagnosis with feedback attention\u2013based BiLSTM", "link": "https://link.springer.com/article/10.1007/s11517-024-03126-8", "details": "NR Kolukula, S Puli, C Babi, RP Kalapala, G Ongole\u2026 - Medical & Biological \u2026, 2024", "abstract": "Predicting a patient's future health state through the analysis of their clinical records is an emerging area in the field of intelligent medicine. It has the potential to assist healthcare professionals in prescribing treatments safely, making more accurate \u2026"}, {"title": "SNOBERT: A Benchmark for clinical notes entity linking in the SNOMED CT clinical terminology", "link": "https://arxiv.org/pdf/2405.16115", "details": "M Kulyabin, G Sokolov, A Galaida, A Maier\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The extraction and analysis of insights from medical data, primarily stored in free-text formats by healthcare workers, presents significant challenges due to its unstructured nature. Medical coding, a crucial process in healthcare, remains minimally \u2026"}, {"title": "Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment", "link": "https://arxiv.org/pdf/2405.15624", "details": "H Sun, M van der Schaar - arXiv preprint arXiv:2405.15624, 2024", "abstract": "Aligning Large Language Models (LLMs) is crucial for enhancing their safety and utility. However, existing methods, primarily based on preference datasets, face challenges such as noisy labels, high annotation costs, and privacy concerns. In this \u2026"}, {"title": "Coactive Learning for Large Language Models using Implicit User Feedback", "link": "https://openreview.net/pdf%3Fid%3DQ7cwVnRWAs", "details": "AD Tucker, K Brantley, A Cahall, T Joachims - 2024", "abstract": "We propose coactive learning as a model and feedback mechanism for training large language models (LLMs). The key insight is that users provide implicit feedback whenever they edit the text $ y $ proposed by an LLM. While the edited text $\\bar y \u2026"}, {"title": "Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting", "link": "https://arxiv.org/pdf/2405.16133", "details": "T Ye, Y Du, T Ma, L Wu, X Zhang, S Ji, W Wang - arXiv preprint arXiv:2405.16133, 2024", "abstract": "Large Language Models (LLMs) have exhibited remarkable proficiency in generating code. However, the misuse of LLM-generated (Synthetic) code has prompted concerns within both educational and industrial domains, highlighting the imperative \u2026"}, {"title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?", "link": "https://arxiv.org/pdf/2405.16908", "details": "G Yona, R Aharoni, M Geva - arXiv preprint arXiv:2405.16908, 2024", "abstract": "We posit that large language models (LLMs) should be capable of expressing their intrinsic uncertainty in natural language. For example, if the LLM is equally likely to output two contradicting answers to the same question, then its generated response \u2026"}, {"title": "BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation", "link": "https://arxiv.org/pdf/2405.17039", "details": "C Jia, P Wang, Z Li, YC Li, Z Zhang, N Tang, Y Yu - arXiv preprint arXiv:2405.17039, 2024", "abstract": "Large language models (LLMs) have catalyzed a paradigm shift in natural language processing, yet their limited controllability poses a significant challenge for downstream applications. We aim to address this by drawing inspiration from the \u2026"}]
