[{"title": "An Unclear Partnership: Key Questions about Physician and Advanced Practice Provider Collaboration in Primary Care", "link": "https://academic.oup.com/healthaffairsscholar/advance-article-pdf/doi/10.1093/haschl/qxaf006/61475944/qxaf006.pdf", "details": "E Martin, B Landon, J Spetz, S Edgman Levitan-PA\u2026 - Health Affairs Scholar, 2025", "abstract": "More than 83 million people in the United States live in primary care shortage areas. As the US healthcare system faces a contracting primary care physician workforce, advanced practice providers are playing an increasingly important role in the \u2026"}, {"title": "ABDN-NLP at CoMeDi Shared Task: Predicting the aggregated human judgment via weighted few-shot prompting", "link": "https://aclanthology.org/2025.comedi-1.12.pdf", "details": "YX Loke, D Schlechtweg, W Zhao - Proceedings of Context and Meaning: Navigating \u2026, 2025", "abstract": "Human annotation is notorious for being subjective and expensive. Recently,(CITATION) introduced the CoMeDi shared task aiming to address this issue by predicting human annotations on the semantic proximity between word \u2026"}, {"title": "Selective Self-to-Supervised Fine-Tuning for Generalization in Large Language Models", "link": "https://arxiv.org/pdf/2502.08130", "details": "S Gupta, Y Nandwani, A Yehudai, D Khandelwal\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Fine-tuning Large Language Models (LLMs) on specific datasets is a common practice to improve performance on target tasks. However, this performance gain often leads to overfitting, where the model becomes too specialized in either the task \u2026"}, {"title": "Teaching Large Language Models Number-Focused Headline Generation With Key Element Rationales", "link": "https://arxiv.org/pdf/2502.03129", "details": "Z Qian, X Zhang, X Xu, F Xia - arXiv preprint arXiv:2502.03129, 2025", "abstract": "Number-focused headline generation is a summarization task requiring both high textual quality and precise numerical accuracy, which poses a unique challenge for Large Language Models (LLMs). Existing studies in the literature focus only on either \u2026"}]
