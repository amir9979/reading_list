[{"title": "Unified Knowledge Maintenance Pruning and Progressive Recovery with Weight Recalling for Large Vision-Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/32923/35078", "details": "Z Wu, J Chen, Y Wang - Proceedings of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Abstract Large Vision-Language Model (LVLM), leveraging Large Language Model (LLM) as the cognitive core, has recently become one of the most representative multimodal model paradigms. However, with the expansion of unimodal \u2026"}, {"title": "QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models", "link": "https://arxiv.org/pdf/2504.11038", "details": "Y Zhang, R Xie, J Chen, X Sun, Z Kang, Y Wang - arXiv preprint arXiv:2504.11038, 2025", "abstract": "In typical multimodal tasks, such as Visual Question Answering (VQA), adversarial attacks targeting a specific image and question can lead large vision-language models (LVLMs) to provide incorrect answers. However, it is common for a single \u2026"}, {"title": "VLMT: Vision-Language Multimodal Transformer for Multimodal Multi-hop Question Answering", "link": "https://arxiv.org/pdf/2504.08269", "details": "QZ Lim, CP Lee, KM Lim, KSM Anbananthen - arXiv preprint arXiv:2504.08269, 2025", "abstract": "The increasing availability of multimodal data across text, tables, and images presents new challenges for developing models capable of complex cross-modal reasoning. Existing methods for Multimodal Multi-hop Question Answering (MMQA) \u2026"}, {"title": "Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?", "link": "https://arxiv.org/pdf/2504.00509", "details": "K Yan, Y Xu, Z Du, X Yao, Z Wang, X Guo, J Chen - arXiv preprint arXiv:2504.00509, 2025", "abstract": "The rapid escalation from elementary school-level to frontier problems of the difficulty for LLM benchmarks in recent years have weaved a miracle for researchers that we are only inches away from surpassing human intelligence. However, is the LLMs' \u2026"}, {"title": "Explore What LLM Does Not Know in Complex Question Answering", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/34638/36793", "details": "X Lin, Z Huang, Z Zhang, J Zhou, E Chen - Proceedings of the AAAI Conference on \u2026, 2025", "abstract": "Complex question answering (QA) is a challenging task in artificial intelligence research which requires reasoning based on related knowledge. The retrieval- augmented generation (RAG) based on large language models (LLMs) have \u2026"}, {"title": "Overcoming Heterogeneous Data in Federated Medical Vision-Language Pre-training: A Triple-Embedding Model Selector Approach", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32807/34962", "details": "A Wang, Z Zhang, D Wang, F Wang, H Hu, J Guo\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "The scarcity data of medical field brings the collaborative training in medical vision- language pre-training (VLP) cross different clients. Therefore, the collaborative training in medical VLP faces two challenges: First, the medical data requires \u2026"}, {"title": "Union Is Strength! Unite the Power of LLMs and MLLMs for Chart Question Answering", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32584/34739", "details": "J Liu, L Li, S Rao, X Gao, W Guan, B Li, C Ma - \u2026 of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Abstract Chart Question Answering (CQA) requires models to perform chart perception and reasoning. Recent studies driven by Large Language Models (LLMs) have dominated CQA. These include employing more cognitively capable LLMs for \u2026"}, {"title": "When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning", "link": "https://arxiv.org/pdf/2504.01005", "details": "N Singhi, H Bansal, A Hosseini, A Grover, KW Chang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Scaling test-time compute has emerged as a key strategy for enhancing the reasoning capabilities of large language models (LLMs), particularly in tasks like mathematical problem-solving. A traditional approach, Self-Consistency (SC) \u2026"}, {"title": "Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization", "link": "https://arxiv.org/pdf/2504.05812", "details": "Q Zhang, H Wu, C Zhang, P Zhao, Y Bian - arXiv preprint arXiv:2504.05812, 2025", "abstract": "While large language models (LLMs) have demonstrated exceptional capabilities in challenging tasks such as mathematical reasoning, existing methods to enhance reasoning ability predominantly rely on supervised fine-tuning (SFT) followed by \u2026"}]
