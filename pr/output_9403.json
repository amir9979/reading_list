[{"title": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs", "link": "https://arxiv.org/pdf/2411.14133", "details": "AR Basani, X Zhang - arXiv preprint arXiv:2411.14133, 2024", "abstract": "Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs \u2026"}]
