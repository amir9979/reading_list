[{"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "link": "https://arxiv.org/pdf/2405.00402", "details": "L Ranaldi, A Freitas - arXiv preprint arXiv:2405.00402, 2024", "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches \u2026"}, {"title": "Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents", "link": "https://arxiv.org/pdf/2405.02732", "details": "S Singhania, S Razniewski, G Weikum - arXiv preprint arXiv:2405.02732, 2024", "abstract": "Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be \u2026"}, {"title": "Achieving> 97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners", "link": "https://arxiv.org/pdf/2404.14963", "details": "Q Zhong, K Wang, Z Xu, J Liu, L Ding, B Du, D Tao - arXiv preprint arXiv:2404.14963, 2024", "abstract": "Chain of Thought prompting strategy has enhanced the performance of Large Language Models (LLMs) across various NLP tasks. However, it still has shortcomings when dealing with complex reasoning tasks, following~\\citet {cot_wei} \u2026"}, {"title": "Infusing internalized knowledge of language models into hybrid prompts for knowledgeable dialogue generation", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124005082", "details": "J Bai, Z Yan, S Zhang, J Yang, H Guo, Z Li - Knowledge-Based Systems, 2024", "abstract": "Existing knowledge-grounded dialogue (KGD) systems access the knowledge from an external knowledge base, then generate the context-coherent response accordingly. However, the knowledge access capability is constrained to the scale of \u2026"}, {"title": "General Purpose Verification for Chain of Thought Prompting", "link": "https://arxiv.org/pdf/2405.00204", "details": "R Vacareanu, A Pratik, E Spiliopoulou, Z Qi, G Paolini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Many of the recent capabilities demonstrated by Large Language Models (LLMs) arise primarily from their ability to exploit contextual information. In this paper, we explore ways to improve reasoning capabilities of LLMs through (1) exploration of \u2026"}, {"title": "HFT: Half Fine-Tuning for Large Language Models", "link": "https://arxiv.org/pdf/2404.18466", "details": "T Hui, Z Zhang, S Wang, W Xu, Y Sun, H Wu - arXiv preprint arXiv:2404.18466, 2024", "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of \u2026"}, {"title": "NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli", "link": "https://arxiv.org/pdf/2405.02814", "details": "X Wang, C Li, Y Chang, J Wang, Y Wu - arXiv preprint arXiv:2405.02814, 2024", "abstract": "Large Language Models (LLMs) have become integral to a wide spectrum of applications, ranging from traditional computing tasks to advanced artificial intelligence (AI) applications. This widespread adoption has spurred extensive \u2026"}, {"title": "A comparison of chain-of-thought reasoning strategies across datasets and models", "link": "https://peerj.com/articles/cs-1999/", "details": "K Hebenstreit, R Praas, LP Kiesewetter, M Samwald - PeerJ Computer Science, 2024", "abstract": "Emergent chain-of-thought (CoT) reasoning capabilities promise to improve the performance and explainability of large language models (LLMs). However, uncertainties remain about how reasoning strategies formulated for previous model \u2026"}]
