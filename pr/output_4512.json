[{"title": "Report-Concept Textual-Prompt Learning for Enhancing X-ray Diagnosis", "link": "https://openreview.net/pdf%3Fid%3Dfgy59cM8X6", "details": "X Zhao, ZY Liu, F Liu, G Li, Y Dou, S Peng - ACM Multimedia 2024", "abstract": "Despite significant advances in image-text medical visual language modeling, the high cost of fine-grained annotation of images to align radiology reports has led current approaches to focus primarily on semantic alignment between the image and \u2026"}, {"title": "Zero-Shot Embeddings Inform Learning and Forgetting with Vision-Language Encoders", "link": "https://arxiv.org/pdf/2407.15731", "details": "L Niss, K Vogt-Lowell, T Tsiligkaridis - arXiv preprint arXiv:2407.15731, 2024", "abstract": "Despite the proliferation of large vision-language foundation models, estimation of the learning and forgetting outcomes following fine-tuning of these models remains largely unexplored. Inspired by work highlighting the significance of the modality gap \u2026"}, {"title": "The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study", "link": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500\\(24\\)00097-9/fulltext", "details": "DM Levine, R Tuwani, B Kompa, A Varma\u2026 - The Lancet Digital Health, 2024", "abstract": "Background Artificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general \u2026"}, {"title": "A novel Parallel Cooperative Mean-Teacher framework (PCMT) combined with prediction uncertainty guide and class contrastive learning for semi-supervised polyp \u2026", "link": "https://www.sciencedirect.com/science/article/pii/S095741742401683X", "details": "Y Xia, H Yun, P Liu, M Li - Expert Systems with Applications, 2024", "abstract": "Polyp segmentation technology based on deep learning can quickly and accurately help doctors locate lesions, but its development is limited by pixel-level annotations. The polyp segmentation methods based on semi-supervised learning (SSL) is an \u2026"}, {"title": "MUSE: Machine Unlearning Six-Way Evaluation for Language Models", "link": "https://arxiv.org/pdf/2407.06460", "details": "W Shi, J Lee, Y Huang, S Malladi, J Zhao, A Holtzman\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LMs) are trained on vast amounts of text data, which may include private and copyrighted content. Data owners may request the removal of their data from a trained model due to privacy or copyright concerns. However, exactly \u2026"}, {"title": "e-Health CSIRO at\" Discharge Me!\" 2024: Generating Discharge Summary Sections with Fine-tuned Language Models", "link": "https://arxiv.org/pdf/2407.02723", "details": "J Liu, A Nicolson, J Dowling, B Koopman, A Nguyen - arXiv preprint arXiv:2407.02723, 2024", "abstract": "Clinical documentation is an important aspect of clinicians' daily work and often demands a significant amount of time. The BioNLP 2024 Shared Task on Streamlining Discharge Documentation (Discharge Me!) aims to alleviate this \u2026"}, {"title": "Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation", "link": "https://arxiv.org/pdf/2407.05890", "details": "J Chen, B Lin, X Liu, X Liang, KYK Wong - arXiv preprint arXiv:2407.05890, 2024", "abstract": "LLM-based agents have demonstrated impressive zero-shot performance in the vision-language navigation (VLN) task. However, these zero-shot methods focus only on solving high-level task planning by selecting nodes in predefined navigation \u2026"}, {"title": "LIONs: An Empirically Optimized Approach to Align Language Models", "link": "https://arxiv.org/pdf/2407.06542", "details": "X Yu, Q Wu, Y Li, Z Yu - arXiv preprint arXiv:2407.06542, 2024", "abstract": "Alignment is a crucial step to enhance the instruction-following and conversational abilities of language models. Despite many recent work proposing new algorithms, datasets, and training pipelines, there is a lack of comprehensive studies measuring \u2026"}, {"title": "Robust Calibration of Large Vision-Language Adapters", "link": "https://arxiv.org/pdf/2407.13588", "details": "B Murugesan, J Silva-Rodriguez, IB Ayed, J Dolz - arXiv preprint arXiv:2407.13588, 2024", "abstract": "This paper addresses the critical issue of miscalibration in CLIP-based model adaptation, particularly in the challenging scenario of out-of-distribution (OOD) samples, which has been overlooked in the existing literature on CLIP adaptation \u2026"}]
