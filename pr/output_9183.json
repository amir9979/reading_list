[{"title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization", "link": "https://arxiv.org/pdf/2411.10442", "details": "W Wang, Z Chen, W Wang, Y Cao, Y Liu, Z Gao, J Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing open-source multimodal large language models (MLLMs) generally follow a training process involving pre-training and supervised fine-tuning. However, these models suffer from distribution shifts, which limit their multimodal reasoning \u2026"}, {"title": "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models", "link": "https://aclanthology.org/2024.emnlp-main.128.pdf", "details": "Y Wan, W Wang, Y Yang, Y Yuan, J Huang, P He\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "We introduce LogicAsker, a novel approach for evaluating and enhancing the logical reasoning capabilities of large language models (LLMs) such as ChatGPT and GPT- 4\\. Despite LLMs' prowess in tasks like writing assistance, code generation, and \u2026"}, {"title": "Measuring Non-Adversarial Reproduction of Training Data in Large Language Models", "link": "https://arxiv.org/pdf/2411.10242", "details": "M Aerni, J Rando, E Debenedetti, N Carlini, D Ippolito\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models memorize parts of their training data. Memorizing short snippets and facts is required to answer questions about the world and to be fluent in any language. But models have also been shown to reproduce long verbatim \u2026"}, {"title": "Large Language Models Can Self-Improve in Long-context Reasoning", "link": "https://arxiv.org/pdf/2411.08147", "details": "S Li, C Yang, Z Cheng, L Liu, M Yu, Y Yang, W Lam - arXiv preprint arXiv:2411.08147, 2024", "abstract": "Large language models (LLMs) have achieved substantial progress in processing long contexts but still struggle with long-context reasoning. Existing approaches typically involve fine-tuning LLMs with synthetic data, which depends on annotations \u2026"}, {"title": "Text-to-SQL Systems in the Era of Advanced Large Language Models", "link": "https://era.library.ualberta.ca/items/3db9c207-9248-4760-8f82-0f6f308ff3ff/download/d817de66-5fe8-47fb-b065-1e5cf7644244", "details": "M Pourreza - 2024", "abstract": "Text-to-SQL conversion, the process of transforming natural language queries into executable SQL commands, stands at the forefront of bridging human linguistic capabilities with the structured logic of databases. This dissertation embarks on a \u2026"}, {"title": "Membership Inference Attacks against Large Language Models via Self-prompt Calibration", "link": "https://fi.ee.tsinghua.edu.cn/~gaochen/papers/NeurIPS2024-SPV-MIA.pdf", "details": "W Fu, H Wang, G Liu, Y Li, T Jiang", "abstract": "Abstract Membership Inference Attacks (MIA) aim to infer whether a target data record has been utilized for model training or not. Existing MIAs designed for large language models (LLMs) can be bifurcated into two types: reference-free and \u2026"}, {"title": "METEOR: Evolutionary Journey of Large Language Models from Guidance to Self-Growth", "link": "https://arxiv.org/pdf/2411.11933", "details": "J Li, C Feng, Y Gao - arXiv preprint arXiv:2411.11933, 2024", "abstract": "Model evolution enables learning from feedback to refine experiences and update skills, transforming models from having no domain knowledge to becoming domain experts. However, there is currently no unified and effective method for guiding this \u2026"}, {"title": "Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance", "link": "https://aclanthology.org/2024.findings-emnlp.554.pdf", "details": "I Cho, G Kwon, J Hockenmaier - Findings of the Association for Computational \u2026, 2024", "abstract": "There has been a growing body of work focusing on the in-context learning (ICL) abilities of large language models (LLMs). However, it is an open question how effective ICL can be. This paper presents Tutor-ICL, a simple prompting method for \u2026"}, {"title": "Efficient Alignment of Large Language Models via Data Sampling", "link": "https://arxiv.org/pdf/2411.10545", "details": "A Khera, R Ghosh, D Dutta - arXiv preprint arXiv:2411.10545, 2024", "abstract": "LLM alignment ensures that large language models behave safely and effectively by aligning their outputs with human values, goals, and intentions. Aligning LLMs employ huge amounts of data, computation, and time. Moreover, curating data with \u2026"}]
