[{"title": "Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models", "link": "https://arxiv.org/pdf/2405.16413", "details": "J Wang, S Ahn, T Dalal, X Zhang, W Pan, Q Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Alzheimer's disease (AD) is the fifth-leading cause of death among Americans aged 65 and older. Screening and early detection of AD and related dementias (ADRD) are critical for timely intervention and for identifying clinical trial participants. The \u2026"}, {"title": "Would I Lie To You? Inference Time Alignment of Language Models using Direct Preference Heads", "link": "https://arxiv.org/pdf/2405.20053", "details": "AA Hadji-Kyriacou, O Arandjelovic - arXiv preprint arXiv:2405.20053, 2024", "abstract": "Pre-trained Language Models (LMs) exhibit strong zero-shot and in-context learning capabilities; however, their behaviors are often difficult to control. By utilizing Reinforcement Learning from Human Feedback (RLHF), it is possible to fine-tune \u2026"}, {"title": "Prompting-based Synthetic Data Generation for Few-Shot Question Answering", "link": "https://arxiv.org/pdf/2405.09335", "details": "M Schmidt, A Bartezzaghi, NT Vu - arXiv preprint arXiv:2405.09335, 2024", "abstract": "Although language models (LMs) have boosted the performance of Question Answering, they still need plenty of data. Data annotation, in contrast, is a time- consuming process. This especially applies to Question Answering, where possibly \u2026"}, {"title": "SNOBERT: A Benchmark for clinical notes entity linking in the SNOMED CT clinical terminology", "link": "https://arxiv.org/pdf/2405.16115", "details": "M Kulyabin, G Sokolov, A Galaida, A Maier\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The extraction and analysis of insights from medical data, primarily stored in free-text formats by healthcare workers, presents significant challenges due to its unstructured nature. Medical coding, a crucial process in healthcare, remains minimally \u2026"}, {"title": "Human-Centered Evaluation and Auditing of Language Models", "link": "https://dl.acm.org/doi/abs/10.1145/3613905.3636302", "details": "Z Xiao, WH Deng, MS Lam, M Eslami, J Kim, M Lee\u2026 - Extended Abstracts of the \u2026, 2024", "abstract": "The recent advancements in Large Language Models (LLMs) have significantly impacted numerous, and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues \u2026"}, {"title": "From Deep Neural Language Models to LLMs", "link": "https://link.springer.com/chapter/10.1007/978-3-031-54827-7_1", "details": "A Kucharavy - Large Language Models in Cybersecurity, 2024", "abstract": "Abstract Large Language Models (LLMs) are scaled-up instances of Deep Neural Language Models\u2014a type of Natural Language Processing (NLP) tools trained with Machine Learning (ML). To best understand how LLMs work, we must dive into what \u2026"}, {"title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions", "link": "https://arxiv.org/pdf/2406.03712", "details": "L Liu, X Yang, J Lei, X Liu, Y Shen, Z Zhang, P Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs), such as GPT series models, have received substantial attention due to their impressive capabilities for generating and understanding human-level language. More recently, LLMs have emerged as an \u2026"}, {"title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2405.07551", "details": "S Yin, W You, Z Ji, G Zhong, J Bai - arXiv preprint arXiv:2405.07551, 2024", "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math \u2026"}]
