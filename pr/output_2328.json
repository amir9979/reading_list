[{"title": "Pathophysiological Features in Electronic Medical Records Sustain Model Performance under Temporal Dataset Shift", "link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11141811/", "details": "R Brosula, CK Corbin, JH Chen - AMIA Summits on Translational Science \u2026, 2024", "abstract": "Access to real-world data streams like electronic medical records (EMRs) has accelerated the development of supervised machine learning (ML) models for clinical applications. However, few studies investigate the differential impact of \u2026"}, {"title": "Examining Linguistic Differences in Electronic Health Records for Diverse Patients With Diabetes: Natural Language Processing Analysis", "link": "https://medinform.jmir.org/2024/1/e50428/", "details": "I Bilotta, S Tonidandel, WR Liaw, E King, DN Carvajal\u2026 - JMIR Medical Informatics, 2024", "abstract": "Background: Individuals from minoritized racial and ethnic backgrounds experience pernicious and pervasive health disparities that have emerged, in part, from clinician bias. Objective: We used a natural language processing approach to examine \u2026"}, {"title": "UniRaG: Unification, Retrieval, and Generation for Multimodal Question Answering With Pre-Trained Language Models", "link": "https://ieeexplore.ieee.org/iel7/6287639/6514899/10535103.pdf", "details": "QZ Lim, CP Lee, KM Lim, AK Samingan - IEEE Access, 2024", "abstract": "Multimodal Question Answering (MMQA) has emerged as a challenging frontier at the intersection of natural language processing (NLP) and computer vision, demanding the integration of diverse modalities for effective comprehension and \u2026"}, {"title": "Code Pretraining Improves Entity Tracking Abilities of Language Models", "link": "https://arxiv.org/pdf/2405.21068", "details": "N Kim, S Schuster, S Toshniwal - arXiv preprint arXiv:2405.21068, 2024", "abstract": "Recent work has provided indirect evidence that pretraining language models on code improves the ability of models to track state changes of discourse entities expressed in natural language. In this work, we systematically test this claim by \u2026"}, {"title": "Evaluation of large language model performance on the Biomedical Language Understanding and Reasoning Benchmark", "link": "https://www.medrxiv.org/content/10.1101/2024.05.17.24307411.full.pdf", "details": "H Feng, F Ronzano, J LaFleur, M Garber, R de Oliveira\u2026 - medRxiv, 2024", "abstract": "Background: The ability of large language models (LLMs) to interpret and generate human-like text has been accompanied with speculation about their application in medicine and clinical research. There is limited data available to inform evidence \u2026"}]
