[{"title": "When Phrases Meet Probabilities: Enabling Open Relation Extraction with Cooperating Large Language Models", "link": "https://aclanthology.org/2024.acl-long.709.pdf", "details": "J Wang, L Zhang, WS Lee, Y Zhong, L Kang, J Liu - \u2026 of the 62nd Annual Meeting of \u2026, 2024", "abstract": "Current clustering-based open relation extraction (OpenRE) methods usually apply clustering algorithms on top of pre-trained language models. However, this practice has three drawbacks. First, embeddings from language models are high-dimensional \u2026"}, {"title": "SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training", "link": "https://arxiv.org/pdf/2408.08295", "details": "G Zhang, L Wang, G Kang, L Chen, Y Wei - arXiv preprint arXiv:2408.08295, 2024", "abstract": "In recent years, continual learning with pre-training (CLPT) has received widespread interest, instead of its traditional focus of training from scratch. The use of strong pre- trained models (PTMs) can greatly facilitate knowledge transfer and alleviate \u2026"}, {"title": "On the role of the UMLS in supporting diagnosis generation differential diagnoses proposed by Large Language Models", "link": "https://www.sciencedirect.com/science/article/pii/S1532046424001254", "details": "M Afshar, Y Gao, D Gupta, E Croxford\u2026 - Journal of Biomedical \u2026, 2024", "abstract": "Objective: Traditional knowledge-based and machine learning diagnostic decision support systems have benefited from integrating the medical domain knowledge encoded in the Unified Medical Language System (UMLS). The emergence of Large \u2026"}, {"title": "Large Language Models Can Learn Representation in Natural Language", "link": "https://aclanthology.org/2024.findings-acl.542.pdf", "details": "Y Guo, Y Liang, D Zhao, N Duan - Findings of the Association for Computational \u2026, 2024", "abstract": "One major challenge for Large Language Models (LLMs) is completing complex tasks involving multiple entities, such as tool APIs. To tackle this, one approach is to retrieve relevant entities to enhance LLMs in task completion. A crucial issue here is \u2026"}, {"title": "Analysis of Plan-based Retrieval for Grounded Text Generation", "link": "https://arxiv.org/pdf/2408.10490", "details": "A Godbole, N Monath, S Kim, AS Rawat, A McCallum\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In text generation, hallucinations refer to the generation of seemingly coherent text that contradicts established knowledge. One compelling hypothesis is that hallucinations occur when a language model is given a generation task outside its \u2026"}, {"title": "SICAR at RRG2024: GPU Poor's Guide to Radiology Report Generation", "link": "https://aclanthology.org/2024.bionlp-1.55.pdf", "details": "K Udomlapsakul, P Pengpun, T Saengja\u2026 - Proceedings of the 23rd \u2026, 2024", "abstract": "Radiology report generation (RRG) aims to create free-text radiology reports from clinical imaging. Our solution employs a lightweight multimodal language model (MLLM) enhanced with a two-stage post-processing strategy, utilizing a Large \u2026"}, {"title": "UIT-2Q2T at ImageCLEFmedical 2024 Caption: Multimodal medical image captioning using Bootstrapping Language-Image Pre-training", "link": "https://ceur-ws.org/Vol-3740/paper-159.pdf", "details": "TV Phan, TK Nguyen, QADD Hoang, QT Phan\u2026 - 2024", "abstract": "Introduction: Medical image captioning is an important AI task in healthcare, automating the generation of text descriptions to support the management and interpretation of medical images. Our team, UIT-2Q2T, participated in the second task \u2026"}, {"title": "Contrastive Multitask Transformer for Hospital Mortality and Length-of-Stay Prediction", "link": "https://link.springer.com/chapter/10.1007/978-3-031-67278-1_11", "details": "F Pick, X Xie, LY Wu - International Conference on AI in Healthcare, 2024", "abstract": "Motivated by the performance on clinical prediction tasks of a transformer-based model (STraTS), we propose a multitask training scheme to exploit information in multiple labels with the goal of improving generalisation, alongside a novel \u2026"}]
