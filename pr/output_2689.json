[{"title": "Calibrating Reasoning in Language Models with Internal Consistency", "link": "https://arxiv.org/pdf/2405.18711", "details": "Z Xie, J Guo, T Yu, S Li - arXiv preprint arXiv:2405.18711, 2024", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various reasoning tasks, aided by techniques like chain-of-thought (CoT) prompting that elicits verbalized reasoning. However, LLMs often generate text with obvious \u2026"}, {"title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment", "link": "https://arxiv.org/pdf/2405.19332", "details": "S Zhang, D Yu, H Sharma, Z Yang, S Wang, H Hassan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed \u2026"}, {"title": "Why are Visually-Grounded Language Models Bad at Image Classification?", "link": "https://arxiv.org/pdf/2405.18415", "details": "Y Zhang, A Unell, X Wang, D Ghosh, Y Su, L Schmidt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Image classification is one of the most fundamental capabilities of machine vision intelligence. In this work, we revisit the image classification task using visually- grounded language models (VLMs) such as GPT-4V and LLaVA. We find that \u2026"}, {"title": "Exploiting Human-AI Dependence for Learning to Defer", "link": "https://openreview.net/pdf%3Fid%3Daiz79FxjaI", "details": "Z Wei, Y Cao, L Feng - Forty-first International Conference on Machine \u2026", "abstract": "The learning to defer (L2D) framework allows models to defer their decisions to human experts. For L2D, the Bayes optimality is the basic requirement of theoretical guarantees for the design of consistent surrogate loss functions, which requires the \u2026"}, {"title": "FuRL: Visual-Language Models as Fuzzy Rewards for Reinforcement Learning", "link": "https://arxiv.org/pdf/2406.00645", "details": "Y Fu, H Zhang, D Wu, W Xu, B Boulet - arXiv preprint arXiv:2406.00645, 2024", "abstract": "In this work, we investigate how to leverage pre-trained visual-language models (VLM) for online Reinforcement Learning (RL). In particular, we focus on sparse reward tasks with pre-defined textual task descriptions. We first identify the problem \u2026"}, {"title": "Language Models Need Inductive Biases to Count Inductively", "link": "https://arxiv.org/pdf/2405.20131", "details": "Y Chang, Y Bisk - arXiv preprint arXiv:2405.20131, 2024", "abstract": "Counting is a fundamental example of generalization, whether viewed through the mathematical lens of Peano's axioms defining the natural numbers or the cognitive science literature for children learning to count. The argument holds for both cases \u2026"}, {"title": "What Makes Good Few-shot Examples for Vision-Language Models?", "link": "https://arxiv.org/pdf/2405.13532", "details": "Z Guo, J Lu, X Liu, R Zhao, ZX Qian, F Tan - arXiv preprint arXiv:2405.13532, 2024", "abstract": "Despite the notable advancements achieved by leveraging pre-trained vision- language (VL) models through few-shot tuning for downstream tasks, our detailed empirical study highlights a significant dependence of few-shot learning outcomes \u2026"}, {"title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2405.18218", "details": "Y Zhang, Y Li, X Wang, Q Shen, B Plank, B Bischl\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Overparametrized transformer networks are the state-of-the-art architecture for Large Language Models (LLMs). However, such models contain billions of parameters making large compute a necessity, while raising environmental concerns. To \u2026"}, {"title": "Towards Causal Foundation Model: on Duality between Optimal Balancing and Attention", "link": "https://openreview.net/pdf%3Fid%3DcFDaYtZR4u", "details": "J Zhang, J Jennings, A Hilmkil, N Pawlowski, C Zhang\u2026 - Forty-first International Conference \u2026", "abstract": "Foundation models have brought changes to the landscape of machine learning, demonstrating sparks of human-level intelligence across a diverse array of tasks. However, a gap persists in complex tasks such as causal inference, primarily due to \u2026"}]
