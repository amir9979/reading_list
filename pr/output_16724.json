[{"title": "MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports", "link": "https://arxiv.org/pdf/2505.11733", "details": "K Wu, E Wu, R Thapa, K Wei, A Zhang, A Suresh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Doctors and patients alike increasingly use Large Language Models (LLMs) to diagnose clinical cases. However, unlike domains such as math or coding, where correctness can be objectively defined by the final answer, medical diagnosis \u2026", "entry_id": "http://arxiv.org/abs/2505.11733v2", "updated": "2025-05-20 15:56:52", "published": "2025-05-16 22:34:36", "authors": "Kevin Wu;Eric Wu;Rahul Thapa;Kevin Wei;Angela Zhang;Arvind Suresh;Jacqueline J. Tao;Min Woo Sun;Alejandro Lozano;James Zou", "summary": "Doctors and patients alike increasingly use Large Language Models (LLMs) to\ndiagnose clinical cases. However, unlike domains such as math or coding, where\ncorrectness can be objectively defined by the final answer, medical diagnosis\nrequires both the outcome and the reasoning process to be accurate. Currently,\nwidely used medical benchmarks like MedQA and MMLU assess only accuracy in the\nfinal answer, overlooking the quality and faithfulness of the clinical\nreasoning process. To address this limitation, we introduce MedCaseReasoning,\nthe first open-access dataset for evaluating LLMs on their ability to align\nwith clinician-authored diagnostic reasoning. The dataset includes 14,489\ndiagnostic question-and-answer cases, each paired with detailed reasoning\nstatements derived from open-access medical case reports. We evaluate\nstate-of-the-art reasoning LLMs on MedCaseReasoning and find significant\nshortcomings in their diagnoses and reasoning: for instance, the top-performing\nopen-source model, DeepSeek-R1, achieves only 48% 10-shot diagnostic accuracy\nand mentions only 64% of the clinician reasoning statements (recall). However,\nwe demonstrate that fine-tuning LLMs on the reasoning traces derived from\nMedCaseReasoning significantly improves diagnostic accuracy and clinical\nreasoning recall by an average relative gain of 29% and 41%, respectively. The\nopen-source dataset, code, and models are available at\nhttps://github.com/kevinwu23/Stanford-MedCaseReasoning.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.11733v2;http://arxiv.org/pdf/2505.11733v2", "pdf_url": "http://arxiv.org/pdf/2505.11733v2"}, {"title": "Large Language Models in Medical Image Understanding", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3D1pVeEQAAQBAJ%26oi%3Dfnd%26pg%3DPA139%26ots%3DuCvuKwVZes%26sig%3D6G0sHPfQn223J43MWfIixLwwuCk", "details": "G Khoriba, M Nouman, EA Rashed - Cutting-Edge Artificial Intelligence Advances and \u2026, 2025", "abstract": "Medical image analysis involves a series of tasks to assist physicians in qualitative and quantitative analyses of lesions or anatomical structures. These tasks can significantly improve the accuracy and reliability of medical diag-noses and \u2026"}, {"title": "Online Iterative Self-Alignment for Radiology Report Generation", "link": "https://arxiv.org/pdf/2505.11983", "details": "T Xiao, L Shi, Y Zhang, HF Yang, Z Wang, C Bai - arXiv preprint arXiv:2505.11983, 2025", "abstract": "Radiology Report Generation (RRG) is an important research topic for relieving radiologist'heavy workload. Existing RRG models mainly rely on supervised fine- tuning (SFT) based on different model architectures using data pairs of radiological \u2026", "entry_id": "http://arxiv.org/abs/2505.11983v2", "updated": "2025-05-20 14:49:41", "published": "2025-05-17 12:31:12", "authors": "Ting Xiao;Lei Shi;Yang Zhang;HaoFeng Yang;Zhe Wang;Chenjia Bai", "summary": "Radiology Report Generation (RRG) is an important research topic for\nrelieving radiologist' heavy workload. Existing RRG models mainly rely on\nsupervised fine-tuning (SFT) based on different model architectures using data\npairs of radiological images and corresponding radiologist-annotated reports.\nRecent research has shifted focus to post-training improvements, aligning RRG\nmodel outputs with human preferences using reinforcement learning (RL).\nHowever, the limited data coverage of high-quality annotated data poses risks\nof overfitting and generalization. This paper proposes a novel Online Iterative\nSelf-Alignment (OISA) method for RRG that consists of four stages:\nself-generation of diverse data, self-evaluation for multi-objective preference\ndata,self-alignment for multi-objective optimization and self-iteration for\nfurther improvement. Our approach allows for generating varied reports tailored\nto specific clinical objectives, enhancing the overall performance of the RRG\nmodel iteratively. Unlike existing methods, our frame-work significantly\nincreases data quality and optimizes performance through iterative\nmulti-objective optimization. Experimental results demonstrate that our method\nsurpasses previous approaches, achieving state-of-the-art performance across\nmultiple evaluation metrics.", "comment": "Accepted by ACL 2025 Main", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.AI", "links": "http://arxiv.org/abs/2505.11983v2;http://arxiv.org/pdf/2505.11983v2", "pdf_url": "http://arxiv.org/pdf/2505.11983v2"}]
