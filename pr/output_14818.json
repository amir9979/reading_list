[{"title": "Federated Koopman-Reservoir Learning for Large-Scale Multivariate Time-Series Anomaly Detection", "link": "https://arxiv.org/pdf/2503.11255", "details": "LT Le, TA Nguyen, H Shu, S Seneviratne, CS Hong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The proliferation of edge devices has dramatically increased the generation of multivariate time-series (MVTS) data, essential for applications from healthcare to smart cities. Such data streams, however, are vulnerable to anomalies that signal \u2026"}, {"title": "Contrastive Learning via Randomly Generated Deep Supervision", "link": "https://ieeexplore.ieee.org/abstract/document/10890867/", "details": "S Wang, Z Ma, KH Chan, Y Liu, T Tong, Q Gao, G Zhai\u2026 - ICASSP 2025-2025 IEEE \u2026, 2025", "abstract": "Unsupervised visual representation learning has gained significant attention in the computer vision community, driven by recent advancements in contrastive learning. Most existing contrastive learning frameworks rely on instance discrimination as a \u2026"}, {"title": "Fusionformer: A Novel Adversarial Transformer Utilizing Fusion Attention for Multivariate Anomaly Detection", "link": "https://ieeexplore.ieee.org/abstract/document/10922726/", "details": "C Wang, Z Wang, H Dong, S Lauria, W Liu, Y Wang\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "Multivariate time series forecasting (MTSF) is of significant importance in the enhancement and optimization of real-world applications. The task of MTSF poses substantial challenges due to the unpredictability of temporal patterns and the \u2026"}, {"title": "Series clustering and dynamic periodic patching-based transformer for multivariate time series forecasting", "link": "https://www.sciencedirect.com/science/article/pii/S1568494625002911", "details": "Y Wang, X Wu, J Zhang, W Wang, L Zheng, J Shang - Applied Soft Computing, 2025", "abstract": "Multivariate time series forecasting (MTSF) is widely employed in research-intensive domains, such as weather forecasting. Recently, Transformer-based models have outstanding ability to achieve SOTA performance, benefiting from its self-attention \u2026"}, {"title": "Dual-Space Contrastive Learning for Open-World Semi-Supervised Classification", "link": "https://ieeexplore.ieee.org/abstract/document/10934981/", "details": "Y Qu, Y Tang, C Zhang, X Cai, X Yuan, W Zhang - IEEE Transactions on Neural \u2026, 2025", "abstract": "Despite recent progress in semi-supervised learning (SSL), its scalability remains limited in realistic scenarios where unseen classes may appear in the unlabeled data. To address this challenge, open-world SSL (OWSSL) is proposed in recent \u2026"}, {"title": "Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models", "link": "https://arxiv.org/pdf/2503.20492", "details": "F Zeng, Z Cheng, F Zhu, XY Zhang - arXiv preprint arXiv:2503.20492, 2025", "abstract": "Reliable prediction by classifiers is crucial for their deployment in high security and dynamically changing situations. However, modern neural networks often exhibit overconfidence for misclassified predictions, highlighting the need for confidence \u2026"}, {"title": "Robust Classification in Bayesian Neural Networks", "link": "https://www.researchgate.net/profile/Vu-Linh-Nguyen/publication/390347093_Robust_Classification_in_Bayesian_Neural_Networks/links/67ee522795231d5ba5ae552a/Robust-Classification-in-Bayesian-Neural-Networks.pdf", "details": "KD Tran, XT Hoang, VL Nguyen, S Destercke\u2026", "abstract": "Bayesian neural networks (BNNs) are competitive multiclass classifiers with reasonably sound probabilistic characteristics. In this paper, we consider BNNs as classifier ensembles obtained through sampling, and define the inference problem in \u2026"}, {"title": "Recepies for Bayesian Deep Learning", "link": "https://www.dept.aueb.gr/sites/default/files/stat/seminars/2425/dimitris_milios_slides_aueb.pdf", "details": "D Milios", "abstract": "Recepies for Bayesian Deep Learning Page 1 Machine Learning Overview Sampling with Stochastic Gradient MCMC Adjusting Neural Network Priors Bayesian Model Selection for Autoencoders Recepies for Bayesian Deep Learning Dimitrios Milios Seminar for \u2026"}, {"title": "TLAC: Two-stage LMM Augmented CLIP for Zero-Shot Classification", "link": "https://arxiv.org/pdf/2503.12206", "details": "A Munir, FZ Qureshi, MH Khan, M Ali - arXiv preprint arXiv:2503.12206, 2025", "abstract": "Contrastive Language-Image Pretraining (CLIP) has shown impressive zero-shot performance on image classification. However, state-of-the-art methods often rely on fine-tuning techniques like prompt learning and adapter-based tuning to optimize \u2026"}]
