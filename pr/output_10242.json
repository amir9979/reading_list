[{"title": "MAPLE: A Framework for Active Preference Learning Guided by Large Language Models", "link": "https://arxiv.org/pdf/2412.07207", "details": "S Mahmud, M Nakamura, S Zilberstein - arXiv preprint arXiv:2412.07207, 2024", "abstract": "The advent of large language models (LLMs) has sparked significant interest in using natural language for preference learning. However, existing methods often suffer from high computational burdens, taxing human supervision, and lack of \u2026"}, {"title": "Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models", "link": "https://arxiv.org/pdf/2412.08615", "details": "J Li, Y Hao, H Xu, X Wang, Y Hong - arXiv preprint arXiv:2412.08615, 2024", "abstract": "Despite the advancements in training Large Language Models (LLMs) with alignment techniques to enhance the safety of generated content, these models remain susceptible to jailbreak, an adversarial attack method that exposes security \u2026"}]
