[{"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "Effective prompt extraction from language models", "link": "https://openreview.net/forum%3Fid%3D0o95CVdNuz", "details": "Y Zhang, N Carlini, D Ippolito - First Conference on Language Modeling, 2024", "abstract": "The text generated by large language models is commonly controlled by prompting, where a prompt prepended to a user's query guides the model's output. The prompts used by companies to guide their models are often treated as secrets, to be hidden \u2026"}, {"title": "Making Long-Context Language Models Better Multi-Hop Reasoners", "link": "https://arxiv.org/pdf/2408.03246", "details": "Y Li, S Liang, MR Lyu, L Wang - arXiv preprint arXiv:2408.03246, 2024", "abstract": "Recent advancements in long-context modeling have enhanced language models (LMs) for complex tasks across multiple NLP applications. Despite this progress, we find that these models struggle with multi-hop reasoning and exhibit decreased \u2026"}, {"title": "Sociotechnical Cross-Country Analysis of Contextual Factors That Impact Patients' Access to Electronic Health Records in 4 European Countries: Framework \u2026", "link": "https://www.jmir.org/2024/1/e55752/", "details": "J Moll, I Scandurra, A B\u00e4rk\u00e5s, C Blease, M H\u00e4gglund\u2026 - Journal of Medical Internet \u2026, 2024", "abstract": "Background The NORDeHEALTH project studies patient-accessible electronic health records (PAEHRs) in Estonia, Finland, Norway, and Sweden. Such country comparisons require an analysis of the sociotechnical context of these services \u2026"}, {"title": "Multi-head CRF classifier for biomedical multi-class named entity recognition on Spanish clinical notes", "link": "https://academic.oup.com/database/article/doi/10.1093/database/baae068/7724924", "details": "RAA Jonker, T Almeida, R Antunes, JR Almeida\u2026 - Database, 2024", "abstract": "The identification of medical concepts from clinical narratives has a large interest in the biomedical scientific community due to its importance in treatment improvements or drug development research. Biomedical named entity recognition (NER) in clinical \u2026"}, {"title": "Optimizing Clinical Trial Eligibility Design Using Natural Language Processing Models and Real-World Data: Algorithm Development and Validation", "link": "https://ai.jmir.org/2024/1/e50800", "details": "K Lee, Z Liu, Y Mai, T Jun, M Ma, T Wang, L Ai, E Calay\u2026 - JMIR AI, 2024", "abstract": "Background Clinical trials are vital for developing new therapies but can also delay drug development. Efficient trial data management, optimized trial protocol, and accurate patient identification are critical for reducing trial timelines. Natural \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios", "link": "https://aclanthology.org/2024.findings-acl.230.pdf", "details": "L Lin, J Fu, P Liu, Q Li, Y Gong, J Wan, F Zhang\u2026 - Findings of the Association \u2026, 2024", "abstract": "Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local \u2026"}, {"title": "GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models", "link": "https://arxiv.org/pdf/2407.21001", "details": "A Abdollahi, M Ghaznavi, MRK Nejad, AM Oriyad\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models (VLMs) are intensively used in many downstream tasks, including those requiring assessments of individuals appearing in the images. While VLMs perform well in simple single-person scenarios, in real-world applications, we \u2026"}]
