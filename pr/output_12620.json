[{"title": "Efficient Few-Shot Continual Learning in Vision-Language Models", "link": "https://arxiv.org/pdf/2502.04098", "details": "A Panos, R Aljundi, DO Reino, RE Turner - arXiv preprint arXiv:2502.04098, 2025", "abstract": "Vision-language models (VLMs) excel in tasks such as visual question answering and image captioning. However, VLMs are often limited by their use of pretrained image encoders, like CLIP, leading to image understanding errors that hinder overall \u2026"}, {"title": "MedS $^ 3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking", "link": "https://arxiv.org/pdf/2501.12051%3F", "details": "S Jiang, Y Liao, Z Chen, Y Zhang, Y Wang, Y Wang - arXiv preprint arXiv:2501.12051, 2025", "abstract": "Medical language models (MLMs) have become pivotal in advancing medical natural language processing. However, prior models that rely on pre-training or supervised fine-tuning often exhibit low data efficiency and limited practicality in real \u2026"}, {"title": "Decoding substance use disorder severity from clinical notes using a large language model", "link": "https://www.nature.com/articles/s44184-024-00114-6", "details": "M Mahbub, GM Dams, S Srinivasan, C Rizy, I Danciu\u2026 - npj Mental Health Research, 2025", "abstract": "Substance use disorder (SUD) poses a major concern due to its detrimental effects on health and society. SUD identification and treatment depend on a variety of factors such as severity, co-determinants (eg, withdrawal symptoms), and social \u2026"}, {"title": "Reflection-Window Decoding: Text Generation with Selective Refinement", "link": "https://arxiv.org/pdf/2502.03678", "details": "Z Tang, Z Chen, L Li, X Song, Y Deng, Y Shen, G Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The autoregressive decoding for text generation in large language models (LLMs), while widely used, is inherently suboptimal due to the lack of a built-in mechanism to perform refinement and/or correction of the generated content. In this paper, we \u2026"}, {"title": "Research Frontier]", "link": "https://ieeexplore.ieee.org/abstract/document/10844367/", "details": "S Latif, M Usama, MI Malik, BW Schuller - IEEE Computational Intelligence Magazine, 2025", "abstract": "Despite recent advancements in speech emotion recognition (SER) models, state-of- the-art deep learning (DL) approaches face the challenge of the limited availability of annotated data. The advent of large language models (LLMs) has revolutionised our \u2026"}]
