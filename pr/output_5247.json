[{"title": "RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records", "link": "https://arxiv.org/pdf/2408.05074", "details": "S Park, CW Wee, SH Choi, KH Kim, JS Chang, HI Yoon\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Accurate patient selection is critical in radiotherapy (RT) to prevent ineffective treatments. Traditional survival prediction models, relying on structured data, often lack precision. This study explores the potential of large language models (LLMs) to \u2026"}, {"title": "The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study", "link": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500\\(24\\)00097-9/fulltext", "details": "DM Levine, R Tuwani, B Kompa, A Varma\u2026 - The Lancet Digital Health, 2024", "abstract": "Background Artificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general \u2026"}, {"title": "Multi-modal Concept Alignment Pre-training for Generative Medical Visual Question Answering", "link": "https://aclanthology.org/2024.findings-acl.319.pdf", "details": "Q Yan, J Duan, J Wang - Findings of the Association for Computational \u2026, 2024", "abstract": "Abstract Medical Visual Question Answering (Med-VQA) seeks to accurately respond to queries regarding medical images, a task particularly challenging for open-ended questions. This study unveils the Multi-modal Concept Alignment Pre-training \u2026"}, {"title": "Stacked Reflective Reasoning in Large Neural Language Models", "link": "https://ceur-ws.org/Vol-3740/paper-121.pdf", "details": "K Villarreal-Haro, F S\u00e1nchez-Vega, A Rosales-P\u00e9rez\u2026 - Working Notes of CLEF, 2024", "abstract": "Sexism, far from being merely a conceptual issue, is a concerning and pervasive social health problem that negatively impacts individuals' well-being and perception. In today's digital era, as sexism permeates online platforms, the creation of systems \u2026"}, {"title": "Mitigating Multilingual Hallucination in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.00550", "details": "X Qu, M Song, W Wei, J Dong, Y Cheng - arXiv preprint arXiv:2408.00550, 2024", "abstract": "While Large Vision-Language Models (LVLMs) have exhibited remarkable capabilities across a wide range of tasks, they suffer from hallucination problems, where models generate plausible yet incorrect answers given the input image-query \u2026"}, {"title": "Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models", "link": "https://aclanthology.org/2024.acl-srw.30.pdf", "details": "Y Kim - Proceedings of the 62nd Annual Meeting of the \u2026, 2024", "abstract": "Transformer model has been a de-facto standard in natural language processing. Its adaptations in other fields such as computer vision showed promising results that this architecture is a powerful neural network in representation learning regardless of \u2026"}, {"title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering", "link": "https://arxiv.org/pdf/2407.21368", "details": "D Guo, D Terzopoulos - arXiv preprint arXiv:2407.21368, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in recent years, and they have been extended to the medical domain. Although demonstrating satisfactory performance on medical Visual Question Answering (VQA) tasks \u2026"}, {"title": "Just Ask One More Time! Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios", "link": "https://aclanthology.org/2024.findings-acl.230.pdf", "details": "L Lin, J Fu, P Liu, Q Li, Y Gong, J Wan, F Zhang\u2026 - Findings of the Association \u2026, 2024", "abstract": "Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local \u2026"}]
