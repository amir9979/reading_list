[{"title": "Unlocking language boundaries: AraCLIP-transforming Arabic language and image understanding through cross-lingual models", "link": "https://www.sciencedirect.com/science/article/pii/S0952197625005779", "details": "M Al-Barham, I Afyouni, K Almubarak, A Turky\u2026 - Engineering Applications of \u2026, 2025", "abstract": "In the domain of image retrieval, the integration of text and images has been transformative, facilitating models that transcend language barriers. This paper introduces Arabic Contrastive Language-Image Pre-training (AraCLIP), an extension \u2026"}, {"title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions", "link": "https://arxiv.org/pdf/2504.05571", "details": "O Ovadia, M Brief, R Lemberg, E Sheetrit - arXiv preprint arXiv:2504.05571, 2025", "abstract": "While Large Language Models (LLMs) acquire vast knowledge during pre-training, they often lack domain-specific, new, or niche information. Continual pre-training (CPT) attempts to address this gap but suffers from catastrophic forgetting and \u2026"}]
