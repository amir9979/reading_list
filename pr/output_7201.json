[{"title": "Attention Prompting on Image for Large Vision-Language Models", "link": "https://arxiv.org/pdf/2409.17143", "details": "R Yu, W Yu, X Wang - arXiv preprint arXiv:2409.17143, 2024", "abstract": "Compared with Large Language Models (LLMs), Large Vision-Language Models (LVLMs) can also accept images as input, thus showcasing more interesting emergent capabilities and demonstrating impressive performance on various vision \u2026"}, {"title": "Language Models for Fall Risk Assessment in Children with Cerebral Palsy using Electronic Medical Records", "link": "https://openreview.net/pdf%3Fid%3DPtqLTSZyKa", "details": "T Tabashum, SJ Wang, JJ Krzak, KM Kruger, A Graf\u2026 - IEEE-EMBS International \u2026", "abstract": "Children with Cerebral Palsy (CP) face a heightened risk of falls, complicating treatment outcomes. Traditional manual scoring methods like the Cummings Fall Assessment Score are subjective and labor-intensive due to the diverse \u2026"}, {"title": "Leveraging interpretable machine learning in intensive care", "link": "https://link.springer.com/article/10.1007/s10479-024-06226-8", "details": "L Bohlen, J Rosenberger, P Zschech, M Kraus - Annals of Operations Research, 2024", "abstract": "In healthcare, especially within intensive care units (ICU), informed decision-making by medical professionals is crucial due to the complexity of medical data. Healthcare analytics seeks to support these decisions by generating accurate predictions \u2026"}, {"title": "ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogue", "link": "https://arxiv.org/pdf/2409.17610", "details": "Z Li, C Zou, S Ma, Z Yang, C Du, Y Tang, Z Cao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rocketing prosperity of large language models (LLMs) in recent years has boosted the prevalence of vision-language models (VLMs) in the medical sector. In our online medical consultation scenario, a doctor responds to the texts and images \u2026"}, {"title": "IvRA: A Framework to Enhance Attention-Based Explanations for Language Models with Interpretability-Driven Training", "link": "https://openreview.net/pdf%3Fid%3D7kW6cxAQeu", "details": "S Xie, S Vosoughi, S Hassanpour - The 7th BlackboxNLP Workshop", "abstract": "Attention has long served as a foundational technique for generating explanations. With the recent developments made in Explainable AI (XAI), the multi-faceted nature of interpretability has become more apparent. Can attention, as an explanation \u2026"}]
