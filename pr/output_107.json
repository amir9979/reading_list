'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Quantized Embedding Vectors for Controllable Diffusion'
[{"title": "MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric", "link": "https://arxiv.org/html/2403.07839v1", "details": "H Lin, H Bai, Z Liu, L Hou, M Sun, L Song, Y Wei, Z Sun - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language pre-trained models have achieved impressive performance on various downstream tasks. However, their large model sizes hinder their utilization on platforms with limited computational resources. We find that directly using smaller \u2026"}, {"title": "Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation", "link": "https://arxiv.org/pdf/2403.07860", "details": "S Zhao, S Hao, B Zi, H Xu, KYK Wong - arXiv preprint arXiv:2403.07860, 2024", "abstract": "Text-to-image generation has made significant advancements with the introduction of text-to-image diffusion models. These models typically consist of a language model that interprets user prompts and a vision model that generates corresponding \u2026"}, {"title": "A Language Model's Guide Through Latent Space", "link": "https://arxiv.org/pdf/2402.14433", "details": "D von R\u00fctte, S Anagnostidis, G Bachmann, T Hofmann - arXiv preprint arXiv \u2026, 2024", "abstract": "Concept guidance has emerged as a cheap and simple way to control the behavior of language models by probing their hidden representations for concept vectors and using them to perturb activations at inference time. While the focus of previous work \u2026"}, {"title": "ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes", "link": "https://arxiv.org/pdf/2403.05795", "details": "Z Yang, A Mitra, S Kwon, H Yu - arXiv preprint arXiv:2403.05795, 2024", "abstract": "The advancement of natural language processing (NLP) systems in healthcare hinges on language model ability to interpret the intricate information contained within clinical notes. This process often requires integrating information from various \u2026"}, {"title": "MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding", "link": "https://arxiv.org/html/2403.06611v1", "details": "J Wu, X Wu, Y Zheng, J Yang - arXiv preprint arXiv:2403.06611, 2024", "abstract": "With appropriate data selection and training techniques, Large Language Models (LLMs) have demonstrated exceptional success in various medical examinations and multiple-choice questions. However, the application of LLMs in medical dialogue \u2026"}, {"title": "$\\mathbf {(N, K)} $-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model", "link": "https://arxiv.org/html/2403.07191v1", "details": "Y Zhang, L Chen, B Liu, Y Yang, Q Cui, Y Tao, H Yang - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in reinforcement learning (RL) algorithms aim to enhance the performance of language models at scale. Yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these \u2026"}, {"title": "MM-NeRF: Large-Scale Scene Representation with Multi-Resolution Hash Grid and Multi-View Priors Features", "link": "https://www.mdpi.com/2079-9292/13/5/844", "details": "B Dong, K Chen, Z Wang, M Yan, J Gu, X Sun - Electronics, 2024", "abstract": "Reconstructing large-scale scenes using Neural Radiance Fields (NeRFs) is a research hotspot in 3D computer vision. Existing MLP (multi-layer perception)-based methods often suffer from issues of underfitting and a lack of fine details in rendering \u2026"}, {"title": "Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving", "link": "https://arxiv.org/html/2403.05907v1", "details": "J Cao, Z Li, N Wang, C Ma - arXiv preprint arXiv:2403.05907, 2024", "abstract": "Recent studies have highlighted the promising application of NeRF in autonomous driving contexts. However, the complexity of outdoor environments, combined with the restricted viewpoints in driving scenarios, complicates the task of precisely \u2026"}, {"title": "Single image super-resolution with denoising diffusion GANS", "link": "https://www.nature.com/articles/s41598-024-52370-3", "details": "H Xiao, X Wang, J Wang, JY Cai, JH Deng, JK Yan\u2026 - Scientific Reports, 2024", "abstract": "Single image super-resolution (SISR) refers to the reconstruction from the corresponding low-resolution (LR) image input to a high-resolution (HR) image. However, since a single low-resolution image corresponds to multiple high \u2026"}]
