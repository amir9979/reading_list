[{"title": "Paying Alignment Tax with Contrastive Learning", "link": "https://arxiv.org/pdf/2505.19327", "details": "BS Korkmaz, R Nair, EM Daly, AR Chanona - arXiv preprint arXiv:2505.19327, 2025", "abstract": "Current debiasing approaches often result a degradation in model capabilities such as factual accuracy and knowledge retention. Through systematic evaluation across multiple benchmarks, we demonstrate that existing debiasing methods face \u2026", "entry_id": "http://arxiv.org/abs/2505.19327v1", "updated": "2025-05-25 21:26:18", "published": "2025-05-25 21:26:18", "authors": "Buse Sibel Korkmaz;Rahul Nair;Elizabeth M. Daly;Antonio del Rio Chanona", "summary": "Current debiasing approaches often result a degradation in model capabilities\nsuch as factual accuracy and knowledge retention. Through systematic evaluation\nacross multiple benchmarks, we demonstrate that existing debiasing methods face\nfundamental trade-offs, particularly in smaller models, leading to reduced\ntruthfulness, knowledge loss, or unintelligible outputs. To address these\nlimitations, we propose a contrastive learning framework that learns through\ncarefully constructed positive and negative examples. Our approach introduces\ncontrast computation and dynamic loss scaling to balance bias mitigation with\nfaithfulness preservation. Experimental results across multiple model scales\ndemonstrate that our method achieves substantial improvements in both toxicity\nreduction and faithfulness preservation. Most importantly, we show that our\nframework is the first to consistently improve both metrics simultaneously,\navoiding the capability degradation characteristic of existing approaches.\nThese results suggest that explicit modeling of both positive and negative\nexamples through contrastive learning could be a promising direction for\nreducing the alignment tax in language model debiasing.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2505.19327v1;http://arxiv.org/pdf/2505.19327v1", "pdf_url": "http://arxiv.org/pdf/2505.19327v1"}, {"title": "MBLSTM is a contextual interaction refined method for time series prediction", "link": "https://www.nature.com/articles/s41598-025-03243-w", "details": "W Qiu, F Zhu, T Hao, M Wang, R Huang - Scientific Reports, 2025", "abstract": "Time series prediction has been widely used in the medical field to predict patient recurrence or physiological fluctuations. However, the adequacy of the existing methods for contextual information interaction is still insufficient when dealing with a \u2026"}, {"title": "Benchmarking Radiology Report Generation From Noisy Free-Texts", "link": "https://ieeexplore.ieee.org/abstract/document/11002452/", "details": "Y Yuan, Y Zheng, L Qu - IEEE Journal of Biomedical and Health Informatics, 2025", "abstract": "Automatic radiology report generation can enhance diagnostic efficiency and accuracy. However, clean open-source imaging scan-report pairs are limited in scale and variety. Moreover, the vast amount of radiological texts available online is often \u2026"}]
