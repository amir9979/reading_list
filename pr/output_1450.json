'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [BANF: Band-limited Neural Fields for Levels of Detail '
[{"title": "Generative Modelling with High-Order Langevin Dynamics", "link": "https://arxiv.org/pdf/2404.12814", "details": "Z Shi, R Liu - arXiv preprint arXiv:2404.12814, 2024", "abstract": "Diffusion generative modelling (DGM) based on stochastic differential equations (SDEs) with score matching has achieved unprecedented results in data generation. In this paper, we propose a novel fast high-quality generative modelling method \u2026"}, {"title": "Texture preserving low dose CT image denoising using Pearson divergence", "link": "https://iopscience.iop.org/article/10.1088/1361-6560/ad45a4/meta", "details": "J Oh, D Wu, B Hong, D Lee, M Kang, Q Li, K Kim - Physics in Medicine and Biology, 2024", "abstract": "Objective: The mean squared error (MSE), also known as L_2 loss, has been widely used as a loss function to optimize image denoising models due to its strong performance as a mean estimator of the Gaussian noise model. Recently, various \u2026"}, {"title": "FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom", "link": "https://arxiv.org/pdf/2404.12273", "details": "Y He, Y Kang, L Fan, Q Yang - arXiv preprint arXiv:2404.12273, 2024", "abstract": "Federated Learning (FL) has emerged as a promising solution for collaborative training of large language models (LLMs). However, the integration of LLMs into FL introduces new challenges, particularly concerning the evaluation of LLMs \u2026"}, {"title": "EfficientGS: Streamlining Gaussian Splatting for Large-Scale High-Resolution Scene Representation", "link": "https://arxiv.org/pdf/2404.12777", "details": "W Liu, T Guan, B Zhu, L Ju, Z Song, D Li, Y Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the domain of 3D scene representation, 3D Gaussian Splatting (3DGS) has emerged as a pivotal technology. However, its application to large-scale, high- resolution scenes (exceeding 4k $\\times $4 k pixels) is hindered by the excessive \u2026"}, {"title": "Benchmarking Benchmark Leakage in Large Language Models", "link": "https://arxiv.org/pdf/2404.18824%3Ftrk%3Dpublic_post_comment-text", "details": "R Xu, Z Wang, RZ Fan, P Liu - arXiv preprint arXiv:2404.18824, 2024", "abstract": "Amid the expanding use of pre-training data, the phenomenon of benchmark dataset leakage has become increasingly prominent, exacerbated by opaque training processes and the often undisclosed inclusion of supervised data in contemporary \u2026"}, {"title": "A systematic literature review of deep learning-based text summarization: Techniques, input representation, training strategies, mechanisms, datasets, evaluation, and \u2026", "link": "https://www.sciencedirect.com/science/article/pii/S0957417424010194", "details": "ME Saleh, YM Wazery, AA Ali - Expert Systems with Applications, 2024", "abstract": "Abstract Automatic Text Summarization (ATS) involves estimating the salience of information and creating coherent summaries that include all relevant and important information from the original text. Extensive research has been carried out on ATS \u2026"}]
