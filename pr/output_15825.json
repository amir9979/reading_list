[{"title": "Towards trustworthy and reliable language models", "link": "https://dr.ntu.edu.sg/bitstream/10356/184392/2/Amended%2520Thesis.pdf", "details": "R Zhao - 2025", "abstract": "This thesis addresses the critical challenge of developing trustworthy and reliable Natural Language Processing (NLP) systems, specifically the newly emerged Large Language Models (LLMs). As LLMs become increasingly prevalent in various \u2026"}, {"title": "Chain of Evidences and Evidence to Generate: Prompting for Context Grounded and Retrieval Augmented Reasoning", "link": "https://aclanthology.org/2025.knowledgenlp-1.21.pdf", "details": "MR Parvez - Proceedings of the 4th International Workshop on \u2026, 2025", "abstract": "While chain-of-thoughts (CoT) prompting has revolutionized how LLMs perform reasoning tasks, its current methods and variations (eg, Self-consistency, ReACT, Reflexion, Tree-of-Thoughts (ToT), Cumulative Reasoning (CR) etc.,) suffer from \u2026"}, {"title": "Pointwise Mutual Information as a Performance Gauge for Retrieval-Augmented Generation", "link": "https://aclanthology.org/2025.naacl-long.78.pdf", "details": "T Liu, J Qi, P He, A Bisazza, M Sachan, R Cotterell - \u2026 of the 2025 Conference of the \u2026, 2025", "abstract": "Recent work suggests that large language models enhanced with retrieval- augmented generation are easily influenced by the order in which the retrieved documents are presented to the model when solving tasks such as question \u2026"}, {"title": "Forest for the Trees: Overarching Prompting Evokes High-Level Reasoning in Large Language Models", "link": "https://aclanthology.org/2025.naacl-long.66.pdf", "details": "H Liao, S Hu, Z Zhu, H He, Y Jin - Proceedings of the 2025 Conference of the Nations \u2026, 2025", "abstract": "Abstract Chain-of-thought (CoT) and subsequent methods adopted a deductive paradigm that decomposes the reasoning process, demonstrating remarkable performances across NLP tasks. However, such a paradigm faces the challenge of \u2026"}, {"title": "Toward Generalizable Evaluation in the LLM Era: A Survey Beyond Benchmarks", "link": "https://arxiv.org/pdf/2504.18838", "details": "Y Cao, S Hong, X Li, J Ying, Y Ma, H Liang, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) are advancing at an amazing speed and have become indispensable across academia, industry, and daily applications. To keep pace with the status quo, this survey probes the core challenges that the rise of LLMs \u2026"}, {"title": "Adapting LLM Agents with Universal Communication Feedback", "link": "https://aclanthology.org/2025.findings-naacl.339.pdf", "details": "K Wang, Y Lu, M Santacroce, Y Gong, C Zhang\u2026 - Findings of the Association \u2026, 2025", "abstract": "Recent advances in large language models (LLMs) have demonstrated potential for LLM agents. To facilitate the training for these agents with both linguistic feedback and non-linguistic reward signals, we introduce Learning through Communication \u2026"}, {"title": "LOFT: Scalable and More Realistic Long-Context Evaluation", "link": "https://aclanthology.org/2025.findings-naacl.374.pdf", "details": "J Lee, A Chen, Z Dai, D Dua, DS Sachan, M Boratko\u2026 - Findings of the Association \u2026, 2025", "abstract": "Long-context language models (LCLMs) have the potential to revolutionize our approach to tasks traditionally reliant on external tools like retrieval systems or databases. Leveraging LCLMs' ability to natively ingest and process entire corpora of \u2026"}, {"title": "NAT: Enhancing Agent Tuning with Negative Samples", "link": "https://aclanthology.org/2025.naacl-long.378.pdf", "details": "R Wang, X Han, Y Zhang, T Baldwin, H Li - Proceedings of the 2025 Conference of \u2026, 2025", "abstract": "Interaction trajectories between agents and environments have proven effective in tuning LLMs into task-specific agents. However, constructing these trajectories, especially successful trajectories, is often computationally and time intensive due to \u2026"}, {"title": "UniRAG: Universal Retrieval Augmentation for Large Vision Language Models", "link": "https://aclanthology.org/2025.findings-naacl.108.pdf", "details": "S Sharifymoghaddam, S Upadhyay, W Chen, J Lin - Findings of the Association for \u2026, 2025", "abstract": "Abstract Recently, Large Vision Language Models (LVLMs) have unlocked many complex use cases that require Multi-Modal (MM) understanding (eg, image captioning or visual question answering) and MM generation (eg, text-guided image \u2026"}]
