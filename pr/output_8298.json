[{"title": "Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines", "link": "https://arxiv.org/pdf/2410.21220", "details": "Z Zhang, Y Zhang, X Ding, X Yue - arXiv preprint arXiv:2410.21220, 2024", "abstract": "Search engines enable the retrieval of unknown information with texts. However, traditional methods fall short when it comes to understanding unfamiliar visual content, such as identifying an object that the model has never seen before. This \u2026"}, {"title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models", "link": "https://arxiv.org/pdf/2410.17637", "details": "Z Liu, Y Zang, X Dong, P Zhang, Y Cao, H Duan, C He\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing \u2026"}, {"title": "Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models", "link": "https://arxiv.org/pdf/2410.09047%3F", "details": "Q Liu, C Shang, L Liu, N Pappas, J Ma, NA John\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The safety alignment ability of Vision-Language Models (VLMs) is prone to be degraded by the integration of the vision module compared to its LLM backbone. We investigate this phenomenon, dubbed as''safety alignment degradation''in this paper \u2026"}, {"title": "LanFL: Differentially Private Federated Learning with Large Language Models using Synthetic Samples", "link": "https://arxiv.org/pdf/2410.19114", "details": "H Wu, D Klabjan - arXiv preprint arXiv:2410.19114, 2024", "abstract": "Federated Learning (FL) is a collaborative, privacy-preserving machine learning framework that enables multiple participants to train a single global model. However, the recent advent of powerful Large Language Models (LLMs) with tens to hundreds \u2026"}, {"title": "Transformer-based Language Models for Reasoning in the Description Logic ALCQ", "link": "https://arxiv.org/pdf/2410.09613", "details": "A Poulis, E Tsalapati, M Koubarakis - arXiv preprint arXiv:2410.09613, 2024", "abstract": "Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order \u2026"}, {"title": "Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment", "link": "https://arxiv.org/pdf/2410.14148", "details": "C Cui, A Zhang, Y Zhou, Z Chen, G Deng, H Yao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The recent advancements in large language models (LLMs) and pre-trained vision models have accelerated the development of vision-language large models (VLLMs), enhancing the interaction between visual and linguistic modalities. Despite \u2026"}, {"title": "DISP-LLM: Dimension-Independent Structural Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2410.11988", "details": "S Gao, CH Lin, T Hua, T Zheng, Y Shen, H Jin, YC Hsu - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have achieved remarkable success in various natural language processing tasks, including language modeling, understanding, and generation. However, the increased memory and computational costs \u2026"}, {"title": "MMAD: The First-Ever Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection", "link": "https://arxiv.org/pdf/2410.09453", "details": "X Jiang, J Li, H Deng, Y Liu, BB Gao, Y Zhou, J Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the field of industrial inspection, Multimodal Large Language Models (MLLMs) have a high potential to renew the paradigms in practical applications due to their robust language capabilities and generalization abilities. However, despite their \u2026"}, {"title": "Negative-Prompt-driven Alignment for Generative Language Model", "link": "https://arxiv.org/pdf/2410.12194", "details": "S Qiao, N Xv, B Liu, X Geng - arXiv preprint arXiv:2410.12194, 2024", "abstract": "Large language models have achieved remarkable capabilities, but aligning their outputs with human values and preferences remains a significant challenge. Existing alignment methods primarily focus on positive examples while overlooking the \u2026"}]
