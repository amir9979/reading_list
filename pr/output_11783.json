[{"title": "Vision-Language Models Do Not Understand Negation", "link": "https://arxiv.org/pdf/2501.09425", "details": "K Alhamoud, S Alshammari, Y Tian, G Li, P Torr, Y Kim\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Many practical vision-language applications require models that understand negation, eg, when using natural language to retrieve images which contain certain objects but not others. Despite advancements in vision-language models (VLMs) \u2026"}, {"title": "From Histopathology Images to Cell Clouds: Learning Slide Representations with Hierarchical Cell Transformer", "link": "https://arxiv.org/pdf/2412.16715", "details": "Z Yang, Z Qiu, T Lin, H Chao, W Chang, Y Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "It is clinically crucial and potentially very beneficial to be able to analyze and model directly the spatial distributions of cells in histopathology whole slide images (WSI). However, most existing WSI datasets lack cell-level annotations, owing to the \u2026"}, {"title": "Decoding Biases: An Analysis of Automated Methods and Metrics for Gender Bias Detection in Language Models", "link": "https://openreview.net/pdf%3Fid%3DtIYMiYz6Bf", "details": "SH Kumar, S Sahay, S Mazumder, E Okur\u2026 - \u2026 GenAI: What Can We Learn from \u2026", "abstract": "Large Language Models (LLMs) have excelled at language understanding and generating human-level text. However, even with supervised training and human alignment, these LLMs are susceptible to adversarial attacks where malicious users \u2026"}]
