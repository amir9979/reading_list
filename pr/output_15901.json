[{"title": "DICE: A Framework for Dimensional and Contextual Evaluation of Language Models", "link": "https://arxiv.org/pdf/2504.10359%3F", "details": "A Shrivastava, PA Aoyagui - arXiv preprint arXiv:2504.10359, 2025", "abstract": "Language models (LMs) are increasingly being integrated into a wide range of applications, yet the modern evaluation paradigm does not sufficiently reflect how they are actually being used. Current evaluations rely on benchmarks that often lack \u2026"}, {"title": "Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure", "link": "https://arxiv.org/pdf/2504.10049%3F", "details": "T Gigant, C Guinaudeau, F Dufaux - arXiv preprint arXiv:2504.10049, 2025", "abstract": "Vision-Language Models (VLMs) can process visual and textual information in multiple formats: texts, images, interleaved texts and images, or even hour-long videos. In this work, we conduct fine-grained quantitative and qualitative analyses of \u2026"}, {"title": "Pre-Trained Language Models for Mental Health: An Empirical Study on Arabic Q&A Classification", "link": "https://www.mdpi.com/2227-9032/13/9/985", "details": "H Alhuzali, A Alasmari - Healthcare, 2025", "abstract": "Background: Pre-Trained Language Models hold significant promise for revolutionizing mental health care by delivering accessible and culturally sensitive resources. Despite this potential, their efficacy in mental health applications \u2026"}, {"title": "RAISE: Reinforenced Adaptive Instruction Selection For Large Language Models", "link": "https://arxiv.org/pdf/2504.07282", "details": "L Qingsong, Y Li, Z Lan, Z Xu, J Tang, Y Li, W Jiang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In the instruction fine-tuning of large language models (LLMs), it has become a consensus that a few high-quality instructions are superior to a large number of low- quality instructions. At present, many instruction selection methods have been \u2026"}, {"title": "Reasoning Under 1 Billion: Memory-Augmented Reinforcement Learning for Large Language Models", "link": "https://arxiv.org/pdf/2504.02273%3F", "details": "H Le, D Do, D Nguyen, S Venkatesh - arXiv preprint arXiv:2504.02273, 2025", "abstract": "Recent advances in fine-tuning large language models (LLMs) with reinforcement learning (RL) have shown promising improvements in complex reasoning tasks, particularly when paired with chain-of-thought (CoT) prompting. However, these \u2026"}, {"title": "Can large language models independently complete tasks? A dynamic evaluation framework for multi-turn task planning and completion", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225008070", "details": "J Gao, J Cui, H Wu, L Xiang, H Zhao, X Li, M Fang\u2026 - Neurocomputing, 2025", "abstract": "Large language models (LLMs) are increasingly relied upon for multi-turn dialogue to conduct complex tasks. However, existing benchmarks mainly evaluate LLMs as agents, overlooking their potential as independent systems to accomplish complex \u2026"}, {"title": "Advancing Egocentric Video Question Answering with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2504.04550%3F", "details": "A Patel, V Chitalia, Y Yang - arXiv preprint arXiv:2504.04550, 2025", "abstract": "Egocentric Video Question Answering (QA) requires models to handle long-horizon temporal reasoning, first-person perspectives, and specialized challenges like frequent camera movement. This paper systematically evaluates both proprietary \u2026"}]
