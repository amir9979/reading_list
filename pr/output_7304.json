[{"title": "Finetuning Language Models to Emit Linguistic Expressions of Uncertainty", "link": "https://arxiv.org/pdf/2409.12180", "details": "A Chaudhry, S Thiagarajan, D Gorur - arXiv preprint arXiv:2409.12180, 2024", "abstract": "Large language models (LLMs) are increasingly employed in information-seeking and decision-making tasks. Despite their broad utility, LLMs tend to generate information that conflicts with real-world facts, and their persuasive style can make \u2026"}, {"title": "Mutual Prompt Leaning for Vision Language Models", "link": "https://link.springer.com/article/10.1007/s11263-024-02243-z", "details": "S Long, Z Zhao, J Yuan, Z Tan, J Liu, J Feng, S Wang\u2026 - International Journal of \u2026, 2024", "abstract": "Large pre-trained vision language models (VLMs) have demonstrated impressive representation learning capabilities, but their transferability across various downstream tasks heavily relies on prompt learning. Since VLMs consist of text and \u2026"}, {"title": "Comparative Analysis of Large Language Models in Chinese Medical Named Entity Recognition", "link": "https://www.mdpi.com/2306-5354/11/10/982", "details": "Z Zhu, Q Zhao, J Li, Y Ge, X Ding, T Gu, J Zou, S Lv\u2026 - Bioengineering, 2024", "abstract": "The emergence of large language models (LLMs) has provided robust support for application tasks across various domains, such as name entity recognition (NER) in the general domain. However, due to the particularity of the medical domain, the \u2026"}, {"title": "EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions", "link": "https://arxiv.org/pdf/2409.18042", "details": "K Chen, Y Gou, R Huang, Z Liu, D Tan, J Xu, C Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "GPT-4o, an omni-modal model that enables vocal conversations with diverse emotions and tones, marks a milestone for omni-modal foundation models. However, empowering Large Language Models to perceive and generate images, texts, and \u2026"}, {"title": "Inference-Time Language Model Alignment via Integrated Value Guidance", "link": "https://arxiv.org/pdf/2409.17819", "details": "Z Liu, Z Zhou, Y Wang, C Yang, Y Qiao - arXiv preprint arXiv:2409.17819, 2024", "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce $\\textit {Integrated Value Guidance} $(IVG), a method that uses implicit and \u2026"}, {"title": "Geometry of Textual Data Augmentation: Insights from Large Language Models", "link": "https://www.mdpi.com/2079-9292/13/18/3781", "details": "SJH Feng, EMK Lai, W Li - Electronics, 2024", "abstract": "Data augmentation is crucial for enhancing the performance of text classification models when labelled training data are scarce. For natural language processing (NLP) tasks, large language models (LLMs) are able to generate high-quality \u2026"}, {"title": "Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models", "link": "https://arxiv.org/pdf/2409.09510", "details": "A Salemi, H Zamani - arXiv preprint arXiv:2409.09510, 2024", "abstract": "Privacy-preserving methods for personalizing large language models (LLMs) are relatively under-explored. There are two schools of thought on this topic:(1) generating personalized outputs by personalizing the input prompt through retrieval \u2026"}, {"title": "ComAlign: Compositional Alignment in Vision-Language Models", "link": "https://arxiv.org/pdf/2409.08206", "details": "A Abdollah, A Izadi, A Saghafian, R Vahidimajd\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Vision-language models (VLMs) like CLIP have showcased a remarkable ability to extract transferable features for downstream tasks. Nonetheless, the training process of these models is usually based on a coarse-grained contrastive loss between the \u2026"}, {"title": "Tuning Vision-Language Models with Multiple Prototypes Clustering", "link": "https://ieeexplore.ieee.org/abstract/document/10679902/", "details": "MH Guo, Y Zhang, TJ Mu, SX Huang, SM Hu - IEEE Transactions on Pattern Analysis \u2026, 2024", "abstract": "Benefiting from advances in large-scale pre-training, foundation models, have demonstrated remarkable capability in the fields of natural language processing, computer vision, among others. However, to achieve expert-level performance in \u2026"}]
