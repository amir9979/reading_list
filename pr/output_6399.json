[{"title": "Zero-Shot Visual Reasoning by Vision-Language Models: Benchmarking and Analysis", "link": "https://arxiv.org/pdf/2409.00106", "details": "A Nagar, S Jaiswal, C Tan - arXiv preprint arXiv:2409.00106, 2024", "abstract": "Vision-language models (VLMs) have shown impressive zero-and few-shot performance on real-world visual question answering (VQA) benchmarks, alluding to their capabilities as visual reasoning engines. However, the benchmarks being used \u2026"}, {"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "CLIP-DPO: Vision-Language Models as a Source of Preference for Fixing Hallucinations in LVLMs", "link": "https://arxiv.org/pdf/2408.10433", "details": "Y Ouali, A Bulat, B Martinez, G Tzimiropoulos - arXiv preprint arXiv:2408.10433, 2024", "abstract": "Despite recent successes, LVLMs or Large Vision Language Models are prone to hallucinating details like objects and their properties or relations, limiting their real- world deployment. To address this and improve their robustness, we present CLIP \u2026"}, {"title": "PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions", "link": "https://arxiv.org/pdf/2409.05076", "details": "Y Zhang, R Xie, J Chen, X Sun, Y Wang - arXiv preprint arXiv:2409.05076, 2024", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated their powerful multimodal capabilities. However, they also face serious safety problems, as adversaries can induce robustness issues in LVLMs through the use of well \u2026"}, {"title": "ARC: A Layer Replacement Compression Method Based on Fine-Grained Self-Attention Distillation for Compressing Pre-Trained Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10663832/", "details": "D Yu, L Qiu - IEEE Transactions on Emerging Topics in \u2026, 2024", "abstract": "The primary objective of model compression is to maintain the performance of the original model while reducing its size as much as possible. Knowledge distillation has become the mainstream method in the field of model compression due to its \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task Specific Expert Pruning", "link": "https://arxiv.org/pdf/2409.01483", "details": "S Sarkar, L Lausen, V Cevher, S Zha, T Brox, G Karypis - arXiv preprint arXiv \u2026, 2024", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative to dense models in language modeling. These models use conditionally activated feedforward subnetworks in transformer blocks, allowing for a separation between \u2026"}, {"title": "Exploiting Pre-trained Language Models for Black-box Attack against Knowledge Graph Embeddings", "link": "https://dl.acm.org/doi/pdf/10.1145/3688850", "details": "G Yang, L Zhang, Y Liu, H Xie, Z Mao - ACM Transactions on Knowledge Discovery \u2026, 2024", "abstract": "Despite the emerging research on adversarial attacks against Knowledge Graph Embedding (KGE) models, most of them focus on white-box attack settings. However, white-box attacks are difficult to apply in practice compared to black-box attacks \u2026"}, {"title": "CoDi: Conversational Distillation for Grounded Question Answering", "link": "https://arxiv.org/pdf/2408.11219", "details": "P Huber, A Einolghozati, R Conway, K Narang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Distilling conversational skills into Small Language Models (SLMs) with approximately 1 billion parameters presents significant challenges. Firstly, SLMs have limited capacity in their model parameters to learn extensive knowledge \u2026"}]
