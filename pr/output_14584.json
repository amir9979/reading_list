[{"title": "LLaVE: Large Language and Vision Embedding Models with Hardness-Weighted Contrastive Learning", "link": "https://arxiv.org/pdf/2503.04812", "details": "Z Lan, L Niu, F Meng, J Zhou, J Su - arXiv preprint arXiv:2503.04812, 2025", "abstract": "Universal multimodal embedding models play a critical role in tasks such as interleaved image-text retrieval, multimodal RAG, and multimodal clustering. However, our empirical results indicate that existing LMM-based embedding models \u2026"}, {"title": "Neural Fields for Multimedia Applications (Part-2): Trends in Volumetric Videos and 3D Objects", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3DFQxMEQAAQBAJ%26oi%3Dfnd%26pg%3DPA280%26ots%3DixaDgrmw1G%26sig%3DR931Aft__ds26u-VJctQYEckyYM", "details": "A Choudhury, GM Su - Smart Multimedia: 4th International Conference, ICSM \u2026", "abstract": "This survey explores the integration of neural fields in 3D multimedia applications including virtual reality, augmented reality and gaming. The paper reviews methodologies, architectures, and applications providing insights into the efficiency \u2026"}, {"title": "MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways", "link": "https://arxiv.org/pdf/2503.13205%3F", "details": "Z Chen, Z Peng, X Liang, C Wang, P Liang, L Zeng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited \u2026"}, {"title": "EFGCLS: A Cross-Lingual Summarization method based on Element Fact-relationship Generation", "link": "https://www.jstage.jst.go.jp/article/transinf/advpub/0/advpub_2024EDP7274/_pdf", "details": "Y HUANG, J MA, T LI, Z YU, Y XIAN, Y XIANG - IEICE Transactions on Information and \u2026, 2025", "abstract": "Cross-lingual summarization (CLS) simplifies obtaining information across languages by generating summaries in the target language from source documents in another. State-of-the-art neural summarization models typically rely on training or \u2026"}, {"title": "Bigger But Not Better: Small Neural Language Models Outperform Large Language Models in Detection of Thought Disorder", "link": "https://arxiv.org/pdf/2503.20103", "details": "C Li, W Xu, S Pakhomov, E Bradley, D Ben-Zeev\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Disorganized thinking is a key diagnostic indicator of schizophrenia-spectrum disorders. Recently, clinical estimates of the severity of disorganized thinking have been shown to correlate with measures of how difficult speech transcripts would be \u2026"}, {"title": "How Good is my Histopathology Vision-Language Foundation Model? A Holistic Benchmark", "link": "https://arxiv.org/pdf/2503.12990", "details": "RA Majzoub, H Malik, M Naseer, Z Zaheer, T Mahmood\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, histopathology vision-language foundation models (VLMs) have gained popularity due to their enhanced performance and generalizability across different downstream tasks. However, most existing histopathology benchmarks are either \u2026"}, {"title": "Alignment for Efficient Tool Calling of Large Language Models", "link": "https://arxiv.org/pdf/2503.06708%3F", "details": "H Xu, Z Wang, Z Zhu, L Pan, X Chen, L Chen, K Yu - arXiv preprint arXiv:2503.06708, 2025", "abstract": "Recent advancements in tool learning have enabled large language models (LLMs) to integrate external tools, enhancing their task performance by expanding their knowledge boundaries. However, relying on tools often introduces tradeoffs between \u2026"}, {"title": "Enhancing 3D Medical Image Understanding with 2D Multimodal Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10889731/", "details": "Q Chen, X Yao, H Ye, Y Hong - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Understanding medical image volumes is crucial in healthcare, yet most current models for classification and segmentation often focus narrowly on task-specific features without capturing the broader medical context. To address this, we introduce \u2026"}, {"title": "FaVChat: Unlocking Fine-Grained Facail Video Understanding with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2503.09158", "details": "F Zhao, M Li, L Xu, W Jiang, J Gao, D Yan - arXiv preprint arXiv:2503.09158, 2025", "abstract": "Video-based multimodal large language models (VMLLMs) have demonstrated remarkable potential in cross-modal video understanding. However, their abilities in fine-grained face comprehension remain largely underexplored. Given its pivotal role \u2026"}]
