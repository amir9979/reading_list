[{"title": "LAILab at Chemotimelines 2024: Finetuning sequence-to-sequence language models for temporal relation extraction towards cancer patient undergoing \u2026", "link": "https://aclanthology.org/2024.clinicalnlp-1.37.pdf", "details": "S Haddadan, TD Le, T Duong, T Thieu - Proceedings of the 6th Clinical Natural \u2026, 2024", "abstract": "In this paper, we report our effort to tackle the challenge of extracting chemotimelines from EHR notes across a dataset of three cancer types. We focus on the two subtasks: 1) detection and classification of temporal relations given the annotated \u2026"}, {"title": "Liuqing Chen", "link": "https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/146/12/121401/7352503/md_146_12_121401.pdf", "details": "H Zuo, Z Cai, Y Yin, Y Zhang, L Sun - Journal of Mechanical Design, 2024", "abstract": "Recent research in the field of design engineering is primarily focusing on using AI technologies such as Large Language Models (LLMs) to assist early-stage design. The engineer or designer can use LLMs to explore, validate, and compare \u2026"}, {"title": "EchoSight: Advancing Visual-Language Models with Wiki Knowledge", "link": "https://arxiv.org/pdf/2407.12735", "details": "Y Yan, W Xie - arXiv preprint arXiv:2407.12735, 2024", "abstract": "Knowledge-based Visual Question Answering (KVQA) tasks require answering questions about images using extensive background knowledge. Despite significant advancements, generative models often struggle with these tasks due to the limited \u2026"}, {"title": "Steering Language Models with Game-Theoretic Solvers", "link": "https://openreview.net/pdf%3Fid%3D5QLtIodDmu", "details": "I Gemp, R Patel, Y Bachrach, M Lanctot, V Dasagi\u2026 - Agentic Markets Workshop at ICML \u2026", "abstract": "Mathematical models of strategic interactions among rational agents have long been studied in game theory. However the interactions studied are often over a small set of discrete actions which is very different from how humans communicate in natural \u2026"}, {"title": "PFPs: Prompt-guided Flexible Pathological Segmentation for Diverse Potential Outcomes Using Large Vision and Language Models", "link": "https://arxiv.org/pdf/2407.09979", "details": "C Cui, R Deng, J Guo, Q Liu, T Yao, H Yang, Y Huo - arXiv preprint arXiv:2407.09979, 2024", "abstract": "The Vision Foundation Model has recently gained attention in medical image analysis. Its zero-shot learning capabilities accelerate AI deployment and enhance the generalizability of clinical applications. However, segmenting pathological \u2026"}, {"title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models", "link": "https://arxiv.org/pdf/2406.16783", "details": "R Maheshwary, V Yadav, H Nguyen, K Mahajan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models (LLMs) to follow instructions. Numerous effective IFT datasets have been proposed in the recent past, but most focus on high resource languages such as English. In this work \u2026"}, {"title": "Large Language Models are Interpretable Learners", "link": "https://arxiv.org/pdf/2406.17224", "details": "R Wang, S Si, F Yu, D Wiesmann, CJ Hsieh, I Dhillon - arXiv preprint arXiv \u2026, 2024", "abstract": "The trade-off between expressiveness and interpretability remains a core challenge when building human-centric predictive models for classification and decision- making. While symbolic rules offer interpretability, they often lack expressiveness \u2026"}]
