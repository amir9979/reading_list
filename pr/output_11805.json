[{"title": "On Linear Representations and Pretraining Data Frequency in Language Models", "link": "https://openreview.net/pdf%3Fid%3D90tmmXyaaV", "details": "J Merullo, NA Smith, S Wiegreffe, Y Elazar", "abstract": "Pretraining data has a direct impact on the behaviors and quality of language models (LMs), but we only understand the most basic principles of this relationship. While most work focuses on pretraining data and downstream task behavior, we look at the \u2026"}, {"title": "LLaVA-RE: Binary image-text relevancy evaluation with multimodal large language model", "link": "https://www.amazon.science/publications/llava-re-binary-image-text-relevancy-evaluation-with-multimodal-large-language-model", "details": "T Sun, O Liu, JJ Li, L Ma - 2025", "abstract": "Multimodal generative AI usually involves generating image or text responses given inputs in another modality. The evaluation of image-text relevancy is essential for measuring response quality or ranking candidate responses. In particular, binary \u2026"}, {"title": "Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval", "link": "https://arxiv.org/pdf/2501.09134", "details": "D Deanda, YP Masupalli, J Yang, Y Lee, Z Cao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical images and reports offer invaluable insights into patient health. The heterogeneity and complexity of these data hinder effective analysis. To bridge this gap, we investigate contrastive learning models for cross-domain retrieval, which \u2026"}, {"title": "Bactrainus: Optimizing Large Language Models for Multi-hop Complex Question Answering Tasks", "link": "https://arxiv.org/pdf/2501.06286", "details": "I Barati, A Ghafouri, B Minaei-Bidgoli - arXiv preprint arXiv:2501.06286, 2025", "abstract": "In recent years, the use of large language models (LLMs) has significantly increased, and these models have demonstrated remarkable performance in a variety of general language tasks. However, the evaluation of their performance in domain \u2026"}, {"title": "Few-Shot Adaptation of Training-Free Foundation Model for 3D Medical Image Segmentation", "link": "https://arxiv.org/pdf/2501.09138", "details": "X He, Y Hu, Z Zhou, M Jarraya, F Liu - arXiv preprint arXiv:2501.09138, 2025", "abstract": "Vision foundation models have achieved remarkable progress across various image analysis tasks. In the image segmentation task, foundation models like the Segment Anything Model (SAM) enable generalizable zero-shot segmentation through user \u2026"}]
