[{"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "Layer by Layer: Uncovering Hidden Representations in Language Models", "link": "https://arxiv.org/pdf/2502.02013", "details": "O Skean, MR Arefin, D Zhao, N Patel, J Naghiyev\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "From extracting features to generating text, the outputs of large language models (LLMs) typically rely on their final layers, following the conventional wisdom that earlier layers capture only low-level cues. However, our analysis shows that \u2026"}, {"title": "Advancing Math Reasoning in Language Models: The Impact of Problem-Solving Data, Data Synthesis Methods, and Training Stages", "link": "https://arxiv.org/pdf/2501.14002", "details": "Z Chen, T Liu, M Tian, Q Tong, W Luo, Z Liu - arXiv preprint arXiv:2501.14002, 2025", "abstract": "Advancements in LLMs have significantly expanded their capabilities across various domains. However, mathematical reasoning remains a challenging area, prompting the development of math-specific LLMs. These models typically follow a two-stage \u2026"}, {"title": "Exploring the Reliability of Large Language Models as Customized Evaluators for Diverse NLP Tasks", "link": "https://aclanthology.org/2025.coling-main.688.pdf", "details": "Q Li, L Cui, L Kong, W Bi - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Previous work adopts large language models (LLMs) as evaluators to evaluate natural language process (NLP) tasks. However, certain shortcomings, eg, fairness, scope, and accuracy, persist for current LLM evaluators. To analyze whether LLMs \u2026"}, {"title": "Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration", "link": "https://arxiv.org/pdf/2502.01969", "details": "Y Zhu, L Tao, M Dong, C Xu - arXiv preprint arXiv:2502.01969, 2025", "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning capabilities but remain highly susceptible to object hallucination, where models generate responses that are not factually aligned with the visual content. Recent \u2026"}, {"title": "Dynamic link prediction: Using language models and graph structures for temporal knowledge graph completion with emerging entities and relations", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002702", "details": "R Ong, J Sun, YK Guo, O Serban - Expert Systems with Applications, 2025", "abstract": "Abstract Knowledge graphs (KGs) represent real-world facts through entities and relations. However, static KGs fail to capture continuously emerging entities and relations over time. Temporal knowledge graphs address this by incorporating time \u2026"}, {"title": "Supervision-free Vision-Language Alignment", "link": "https://arxiv.org/pdf/2501.04568%3F", "details": "G Giannone, R Li, Q Feng, E Perevodchikov, R Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation \u2026"}, {"title": "Can Many-Shot In-Context Learning Help LLMs as Evaluators? A Preliminary Empirical Study", "link": "https://aclanthology.org/2025.coling-main.548.pdf", "details": "M Song, M Zheng, X Luo - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Abstract Utilizing Large Language Models (LLMs) as evaluators to assess the performance of other LLMs has garnered attention. However, this evaluation approach is affected by potential biases within LLMs, raising concerns about the \u2026"}, {"title": "Redundancy Principles for MLLMs Benchmarks", "link": "https://arxiv.org/pdf/2501.13953", "details": "Z Zhang, X Zhao, X Fang, C Li, X Liu, X Min, H Duan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "With the rapid iteration of Multi-modality Large Language Models (MLLMs) and the evolving demands of the field, the number of benchmarks produced annually has surged into the hundreds. The rapid growth has inevitably led to significant \u2026"}]
