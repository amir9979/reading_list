[{"title": "Evaluating Multi-Hop Reasoning in Large Language Models: A Chemistry-Centric Case Study", "link": "https://arxiv.org/pdf/2504.16414", "details": "M Khodadad, AS Kasmaee, M Astaraki, N Sherck\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In this study, we introduced a new benchmark consisting of a curated dataset and a defined evaluation process to assess the compositional reasoning capabilities of large language models within the chemistry domain. We designed and validated a \u2026", "entry_id": "http://arxiv.org/abs/2504.16414v1", "updated": "2025-04-23 04:36:19", "published": "2025-04-23 04:36:19", "authors": "Mohammad Khodadad;Ali Shiraee Kasmaee;Mahdi Astaraki;Nicholas Sherck;Hamidreza Mahyar;Soheila Samiee", "summary": "In this study, we introduced a new benchmark consisting of a curated dataset\nand a defined evaluation process to assess the compositional reasoning\ncapabilities of large language models within the chemistry domain. We designed\nand validated a fully automated pipeline, verified by subject matter experts,\nto facilitate this task. Our approach integrates OpenAI reasoning models with\nnamed entity recognition (NER) systems to extract chemical entities from recent\nliterature, which are then augmented with external knowledge bases to form a\ncomprehensive knowledge graph. By generating multi-hop questions across these\ngraphs, we assess LLM performance in both context-augmented and non-context\naugmented settings. Our experiments reveal that even state-of-the-art models\nface significant challenges in multi-hop compositional reasoning. The results\nreflect the importance of augmenting LLMs with document retrieval, which can\nhave a substantial impact on improving their performance. However, even perfect\nretrieval accuracy with full context does not eliminate reasoning errors,\nunderscoring the complexity of compositional reasoning. This work not only\nbenchmarks and highlights the limitations of current LLMs but also presents a\nnovel data generation pipeline capable of producing challenging reasoning\ndatasets across various domains. Overall, this research advances our\nunderstanding of reasoning in computational linguistics.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2504.16414v1;http://arxiv.org/pdf/2504.16414v1", "pdf_url": "http://arxiv.org/pdf/2504.16414v1"}, {"title": "Enhancing E-Recruitment Recommendations Through Text Summarization Techniques", "link": "https://www.mdpi.com/2078-2489/16/4/333", "details": "RH El-Deeb, W Abdelmoez, N El-Bendary - Information, 2025", "abstract": "This research aims to enhance e-recruitment systems using text summarization techniques and pretrained large language models (LLMs). A job recommender system is built with integrated text summarization. The text summarization techniques \u2026"}, {"title": "CTINEXUS: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models", "link": "https://www.researchgate.net/profile/Yutong-Cheng-2/publication/385318537_CTINexus_Automatic_Cyber_Threat_Intelligence_Knowledge_Graph_Construction_Using_Large_Language_Models/links/681a13c5d1054b0207ea9370/CTINexus-Automatic-Cyber-Threat-Intelligence-Knowledge-Graph-Construction-Using-Large-Language-Models.pdf", "details": "Y Cheng, O Bajaber, SA Tsegai, D Song, P Gao", "abstract": "Textual descriptions in cyber threat intelligence (CTI) reports, such as security articles and news, are rich sources of knowledge about cyber threats, crucial for organizations to stay informed about the rapidly evolving threat landscape. However \u2026"}]
