[{"title": "Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?", "link": "https://arxiv.org/pdf/2410.23856", "details": "Z Zhou, R Tao, J Zhu, Y Luo, Z Wang, B Han - arXiv preprint arXiv:2410.23856, 2024", "abstract": "This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We \u2026"}, {"title": "Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines", "link": "https://arxiv.org/pdf/2410.21220", "details": "Z Zhang, Y Zhang, X Ding, X Yue - arXiv preprint arXiv:2410.21220, 2024", "abstract": "Search engines enable the retrieval of unknown information with texts. However, traditional methods fall short when it comes to understanding unfamiliar visual content, such as identifying an object that the model has never seen before. This \u2026"}, {"title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality", "link": "https://arxiv.org/pdf/2411.11531", "details": "V Chekalina, A Razzigaev, E Goncharova, A Kuznetsov - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper we present an approach to reduce hallucinations in Large Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional modality. Our method involves transforming input text into a set of KG embeddings and using \u2026"}, {"title": "MPLite: Multi-Aspect Pretraining for Mining Clinical Health Records", "link": "https://arxiv.org/pdf/2411.11161", "details": "E Yang, P Hu, X Han, Y Ning - arXiv preprint arXiv:2411.11161, 2024", "abstract": "The adoption of digital systems in healthcare has resulted in the accumulation of vast electronic health records (EHRs), offering valuable data for machine learning methods to predict patient health outcomes. However, single-visit records of patients \u2026"}, {"title": "Text2Afford: Probing Object Affordance Prediction abilities of Language Models solely from Text", "link": "https://aclanthology.org/2024.conll-1.27.pdf", "details": "S Adak, D Agrawal, A Mukherjee, S Aditya - Proceedings of the 28th Conference on \u2026, 2024", "abstract": "We investigate the knowledge of object affordances in pre-trained language models (LMs) and pre-trained Vision-Language models (VLMs). A growing body of literature shows that PTLMs fail inconsistently and non-intuitively, demonstrating a lack of \u2026"}, {"title": "LL\\\" aMmlein: Compact and Competitive German-Only Language Models from Scratch", "link": "https://arxiv.org/pdf/2411.11171", "details": "J Pfister, J Wunderle, A Hotho - arXiv preprint arXiv:2411.11171, 2024", "abstract": "We create two German-only decoder models, LL\\\" aMmlein 120M and 1B, transparently from scratch and publish them, along with the training data, for the German NLP research community to use. The model training involved several key \u2026"}, {"title": "A Survey of Small Language Models", "link": "https://arxiv.org/abs/2410.20011", "details": "C Van Nguyen, X Shen, R Aponte, Y Xia, S Basu, Z Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Small Language Models (SLMs) have become increasingly important due to their efficiency and performance to perform various language tasks with minimal computational resources, making them ideal for various settings including on-device \u2026"}, {"title": "Axes of Robustness of Neural Language Models", "link": "https://is.muni.cz/th/m805b/PhD_thesis_Michal_Stefanik.pdf", "details": "M \u0160TEF\u00c1NIK", "abstract": "In recent years, language models have emerged into a technology adopted in a wide variety of applications, nowadays largely exceeding traditional natural language processing tasks. Thanks to their versatility and adaptability, modern language \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}]
