[{"title": "Learning local discrete features in explainable-by-design convolutional neural networks", "link": "https://arxiv.org/pdf/2411.00139", "details": "PI Kaplanoglou, K Diamantaras - arXiv preprint arXiv:2411.00139, 2024", "abstract": "Our proposed framework attempts to break the trade-off between performance and explainability by introducing an explainable-by-design convolutional neural network (CNN) based on the lateral inhibition mechanism. The ExplaiNet model consists of \u2026"}, {"title": "InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders", "link": "https://www.biorxiv.org/content/biorxiv/early/2024/11/15/2024.11.14.623630.full.pdf", "details": "E Simon, J Zou - bioRxiv, 2024", "abstract": "Protein language models (PLMs) have demonstrated remarkable success in protein modeling and design, yet their internal mechanisms for predicting structure and function remain poorly understood. Here we present a systematic approach to extract \u2026"}, {"title": "Efficient Vision-Language pre-training via domain-specific learning for human activities", "link": "https://aclanthology.org/2024.emnlp-main.454.pdf", "details": "A Bulat, Y Ouali, R Guerrero, B Martinez\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Current Vision-Language (VL) models owe their success to large-scale pre- training on web-collected data, which in turn requires high-capacity architectures and large compute resources for training. We posit that when the downstream tasks are \u2026"}, {"title": "CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense", "link": "https://arxiv.org/pdf/2410.23091", "details": "M Zhang, K Bi, W Chen, Q Chen, J Guo, X Cheng - arXiv preprint arXiv:2410.23091, 2024", "abstract": "Despite ongoing efforts to defend neural classifiers from adversarial attacks, they remain vulnerable, especially to unseen attacks. In contrast, humans are difficult to be cheated by subtle manipulations, since we make judgments only based on \u2026"}, {"title": "Explainability and Interpretability of an Ensemble Multi-agent System for Supervised Learning", "link": "https://link.springer.com/chapter/10.1007/978-3-031-77367-9_26", "details": "C Blanco-Volle, N Verstaevel, S Combettes\u2026 - International Conference on \u2026, 2024", "abstract": "We present a multi-agent ensemble learning approach for supervised learning and evaluate its performance on a task of nonlinear function approximation. This approach relies on a set of learning agents that self-organize according to \u2026"}, {"title": "Evolved Hierarchical Masking for Self-Supervised Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10742293/", "details": "Z Feng, S Zhang - IEEE Transactions on Pattern Analysis and Machine \u2026, 2024", "abstract": "Existing Masked Image Modeling methods apply fixed mask patterns to guide the self- supervised training. As those mask patterns resort to different criteria to depict image contents, sticking to a fixed pattern leads to a limited vision cues modeling capability \u2026"}, {"title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning", "link": "https://arxiv.org/pdf/2410.19560", "details": "S Mo, S Tong - arXiv preprint arXiv:2410.19560, 2024", "abstract": "In recent advancements in unsupervised visual representation learning, the Joint- Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabeled imagery through an innovative masking \u2026"}]
