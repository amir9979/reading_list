'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [A Comparison of Parameter-Efficient ASR Domain Adaptation Me'
[{"title": "Can only LLMs do Reasoning?: Potential of Small Language Models in Task Planning", "link": "https://arxiv.org/pdf/2404.03891", "details": "G Choi, H Ahn - arXiv preprint arXiv:2404.03891, 2024", "abstract": "In robotics, the use of Large Language Models (LLMs) is becoming prevalent, especially for understanding human commands. In particular, LLMs are utilized as domain-agnostic task planners for high-level human commands. LLMs are capable \u2026"}, {"title": "Pre-trained Vision-Language Models Learn Discoverable Visual Concepts", "link": "https://arxiv.org/pdf/2404.12652", "details": "Y Zang, T Yun, H Tan, T Bui, C Sun - arXiv preprint arXiv:2404.12652, 2024", "abstract": "Do vision-language models (VLMs) pre-trained to caption an image of a\" durian\" learn visual concepts such as\" brown\"(color) and\" spiky\"(texture) at the same time? We aim to answer this question as visual concepts learned\" for free\" would enable \u2026"}, {"title": "VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models", "link": "https://arxiv.org/pdf/2404.13874", "details": "H Qiu, W Hu, ZY Dou, N Peng - arXiv preprint arXiv:2404.13874, 2024", "abstract": "Large Vision-Language Models (LVLMs) suffer from hallucination issues, wherein the models generate plausible-sounding but factually incorrect outputs, undermining their reliability. A comprehensive quantitative evaluation is necessary to identify and \u2026"}, {"title": "Investigating Regularization of Self-Play Language Models", "link": "https://arxiv.org/pdf/2404.04291", "details": "R Alami, A Abubaker, M Achab, MEA Seddik, S Lahlou - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper explores the effects of various forms of regularization in the context of language model alignment via self-play. While both reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) require to collect \u2026"}, {"title": "Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs", "link": "https://arxiv.org/pdf/2404.13033", "details": "B Guo, H Wang, W Xiao, H Chen, Z Lee, S Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the burgeoning field of Large Language Models (LLMs) like ChatGPT and LLaMA, Prompt Engineering (PE) is renowned for boosting zero-shot or in-context learning (ICL) through prompt modifications. Yet, the realm of the sample design for \u2026"}, {"title": "Impact of Preference Noise on the Alignment Performance of Generative Language Models", "link": "https://arxiv.org/pdf/2404.09824", "details": "Y Gao, D Alon, D Metzler - arXiv preprint arXiv:2404.09824, 2024", "abstract": "A key requirement in developing Generative Language Models (GLMs) is to have their values aligned with human values. Preference-based alignment is a widely used paradigm for this purpose, in which preferences over generation pairs are first \u2026"}, {"title": "Grounding and Enhancing Grid-based Models for Neural Fields", "link": "https://arxiv.org/pdf/2403.20002", "details": "Z Zhao, F Fan, W Liao, J Yan - arXiv preprint arXiv:2403.20002, 2024", "abstract": "Many contemporary studies utilize grid-based models for neural field representation, but a systematic analysis of grid-based models is still missing, hindering the improvement of those models. Therefore, this paper introduces a theoretical \u2026"}, {"title": "Unified Scene Representation and Reconstruction for 3D Large Language Models", "link": "https://arxiv.org/pdf/2404.13044", "details": "T Chu, P Zhang, X Dong, Y Zang, Q Liu, J Wang - arXiv preprint arXiv:2404.13044, 2024", "abstract": "Enabling Large Language Models (LLMs) to interact with 3D environments is challenging. Existing approaches extract point clouds either from ground truth (GT) geometry or 3D scenes reconstructed by auxiliary models. Text-image aligned 2D \u2026"}, {"title": "Generative Language Models for Personalized Information Understanding", "link": "https://scholarworks.umass.edu/cgi/viewcontent.cgi%3Farticle%3D4123%26context%3Ddissertations_2", "details": "P Cai - 2024", "abstract": "A major challenge in information understanding stems from the diverse nature of the audience, where individuals possess varying preferences, experiences, educational and cultural backgrounds. Consequently, adopting a one-size-fits-all approach to \u2026"}]
