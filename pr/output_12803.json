[{"title": "Risk-aware distributional intervention policies for language models", "link": "https://arxiv.org/pdf/2501.15758", "details": "B Nguyen, B Nguyen, D Nguyen, VA Nguyen - arXiv preprint arXiv:2501.15758, 2025", "abstract": "Language models are prone to occasionally undesirable generations, such as harmful or toxic content, despite their impressive capability to produce texts that appear accurate and coherent. This paper presents a new two-stage approach to \u2026"}, {"title": "EVEv2: Improved Baselines for Encoder-Free Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06788", "details": "H Diao, X Li, Y Cui, Y Wang, H Deng, T Pan, W Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing encoder-free vision-language models (VLMs) are rapidly narrowing the performance gap with their encoder-based counterparts, highlighting the promising potential for unified multimodal systems with structural simplicity and efficient \u2026"}, {"title": "MedS $^ 3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking", "link": "https://arxiv.org/pdf/2501.12051%3F", "details": "S Jiang, Y Liao, Z Chen, Y Zhang, Y Wang, Y Wang - arXiv preprint arXiv:2501.12051, 2025", "abstract": "Medical language models (MLMs) have become pivotal in advancing medical natural language processing. However, prior models that rely on pre-training or supervised fine-tuning often exhibit low data efficiency and limited practicality in real \u2026"}, {"title": "Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06130", "details": "C Zhang, Z Wan, Z Kan, MQ Ma, S Stepputtis\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "While recent Large Vision-Language Models (LVLMs) have shown remarkable performance in multi-modal tasks, they are prone to generating hallucinatory text responses that do not align with the given visual input, which restricts their practical \u2026"}, {"title": "Evaluating Entity Retrieval in Electronic Health Records: a Semantic Gap Perspective", "link": "https://arxiv.org/pdf/2502.06252", "details": "Z Zhao, H Yuan, J Liu, H Chen, H Ying, S Zhou, S Yu - arXiv preprint arXiv \u2026, 2025", "abstract": "Entity retrieval plays a crucial role in the utilization of Electronic Health Records (EHRs) and is applied across a wide range of clinical practices. However, a comprehensive evaluation of this task is lacking due to the absence of a public \u2026"}, {"title": "An Unclear Partnership: Key Questions about Physician and Advanced Practice Provider Collaboration in Primary Care", "link": "https://academic.oup.com/healthaffairsscholar/advance-article-pdf/doi/10.1093/haschl/qxaf006/61475944/qxaf006.pdf", "details": "E Martin, B Landon, J Spetz, S Edgman Levitan-PA\u2026 - Health Affairs Scholar, 2025", "abstract": "More than 83 million people in the United States live in primary care shortage areas. As the US healthcare system faces a contracting primary care physician workforce, advanced practice providers are playing an increasingly important role in the \u2026"}, {"title": "Noise is an Efficient Learner for Zero-Shot Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06019", "details": "R Imam, A Hanif, J Zhang, KW Dawoud\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, test-time adaptation has garnered attention as a method for tuning models without labeled data. The conventional modus operandi for adapting pre-trained vision-language models (VLMs) during test-time primarily focuses on tuning \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "Use of ChatGPT Large Language Models to Extract Details of Recommendations for Additional Imaging From Free-Text Impressions of Radiology Reports", "link": "https://ajronline.org/doi/abs/10.2214/AJR.24.32341", "details": "KW Li, R Lacson, JP Guenette, PJ DiPiro, KS Burk\u2026 - American Journal of \u2026, 2025", "abstract": "Background: Automated extraction of actionable details of recommendations for additional imaging (RAIs) from radiology reports could facilitate tracking and timely completion of clinically necessary RAIs and thereby potentially reduce diagnostic \u2026"}]
