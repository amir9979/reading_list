'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Adaptive Prompt Routing for Arbitrary Text Style Trans'
[{"title": "Few-Shot Adversarial Prompt Learning on Vision-Language Models", "link": "https://arxiv.org/html/2403.14774v1", "details": "Y Zhou, X Xia, Z Lin, B Han, T Liu - arXiv preprint arXiv:2403.14774, 2024", "abstract": "The vulnerability of deep neural networks to imperceptible adversarial perturbations has attracted widespread attention. Inspired by the success of vision-language foundation models, previous efforts achieved zero-shot adversarial robustness by \u2026"}, {"title": "Trade-Offs in Fine-Tuned Diffusion Models between Accuracy and Interpretability", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/30095/31930", "details": "M Dombrowski, H Reynaud, JP M\u00fcller, M Baugh\u2026 - Proceedings of the AAAI \u2026, 2024", "abstract": "Recent advancements in diffusion models have significantly impacted the trajectory of generative machine learning re-search, with many adopting the strategy of fine- tuning pre-trained models using domain-specific text-to-image datasets. Notably, this \u2026"}, {"title": "A Novel Sentence Transformer-based Natural Language Processing Approach for Schema Mapping of Electronic Health Records to the OMOP Common Data Model", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/03/24/2024.03.21.24304616.full.pdf", "details": "X Zhou, LS Dhingra, A Aminorroaya, P Adejumo\u2026 - medRxiv, 2024", "abstract": "Mapping electronic health records (EHR) data to common data models (CDMs) enables the standardization of clinical records, enhancing interoperability and enabling large-scale, multi-centered clinical investigations. Using 2 large publicly \u2026"}, {"title": "Understanding Emergent Abilities of Language Models from the Loss Perspective", "link": "https://arxiv.org/pdf/2403.15796", "details": "Z Du, A Zeng, Y Dong, J Tang - arXiv preprint arXiv:2403.15796, 2024", "abstract": "Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) \u2026"}, {"title": "Contrastive Learning on Multimodal Analysis of Electronic Health Records", "link": "https://arxiv.org/html/2403.14926v1", "details": "T Cai, F Huang, R Nakada, L Zhang, D Zhou - arXiv preprint arXiv:2403.14926, 2024", "abstract": "Electronic health record (EHR) systems contain a wealth of multimodal clinical data including structured data like clinical codes and unstructured data such as clinical notes. However, many existing EHR-focused studies has traditionally either \u2026"}, {"title": "Tree-of-Reasoning Question Decomposition for Complex Question Answering with Large Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29928/31621", "details": "K Zhang, J Zeng, F Meng, Y Wang, S Sun, L Bai\u2026 - Proceedings of the AAAI \u2026, 2024", "abstract": "Large language models (LLMs) have recently demonstrated remarkable performance across various natual language processing tasks. In the field of multi- hop reasoning, the Chain-of-thought (CoT) prompt method has emerged as a \u2026"}]
