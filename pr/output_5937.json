[{"title": "General Time Transformer: an Encoder-only Foundation Model for Zero-Shot Multivariate Time Series Forecasting", "link": "https://cfeng783.github.io/pubs/CIKM24_GTT.pdf", "details": "C Feng, L Huang, D Krompass - 2024", "abstract": "Abstract We present General Time Transformer (GTT), an encoder-only style foundation model for zero-shot multivariate time series forecasting. GTT is pretrained on a large dataset of 200M high-quality time series samples spanning diverse \u2026"}, {"title": "PerFedHypID: A Personalized Federated Hypernetworks based aggregation approach for Intrusion Detection Systems", "link": "https://www.researchsquare.com/article/rs-4767476/latest.pdf", "details": "C Abhijit, YA Jerusha, SI SP, V Varadharajan - 2024", "abstract": "Abstract Traditional Network Intrusion Detection Systems (NIDS) face scalability challenges due to the vast amount of data generated by Internet of Things (IoT) devices, coupled with growing privacy concerns. Federated Learning (FL) emerges \u2026"}, {"title": "Model Debiasing by Learnable Data Augmentation", "link": "https://arxiv.org/pdf/2408.04955", "details": "P Morerio, R Ragonesi, V Murino - arXiv preprint arXiv:2408.04955, 2024", "abstract": "Deep Neural Networks are well known for efficiently fitting training data, yet experiencing poor generalization capabilities whenever some kind of bias dominates over the actual task labels, resulting in models learning\" shortcuts\". In essence, such \u2026"}]
