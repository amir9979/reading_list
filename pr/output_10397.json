[{"title": "Frozen Large-scale Pretrained Vision-Language Models are the Effective Foundational Backbone for Multimodal Breast Cancer Prediction", "link": "https://ieeexplore.ieee.org/iel8/6221020/6363502/10769012.pdf", "details": "HQ Vo, L Wang, KK Wong, CF Ezeana, X Yu, W Yang\u2026 - IEEE Journal of Biomedical \u2026, 2024", "abstract": "Breast cancer is a pervasive global health concern among women. Leveraging multimodal data from enterprise patient databases-including Picture Archiving and Communication Systems (PACS) and Electronic Health Records (EHRs)-holds \u2026"}, {"title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2412.09827", "details": "C Li, C Ding, K Luan, X Di - arXiv preprint arXiv:2412.09827, 2024", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. LoRA is one of the most widely used methods, which assumes that the optimization process is essentially low \u2026"}, {"title": "How Private are Language Models in Abstractive Summarization?", "link": "https://arxiv.org/pdf/2412.12040", "details": "A Hughes, N Aletras, N Ma - arXiv preprint arXiv:2412.12040, 2024", "abstract": "Language models (LMs) have shown outstanding performance in text summarization including sensitive domains such as medicine and law. In these settings, it is important that personally identifying information (PII) included in the source \u2026"}, {"title": "Can Language Models Rival Mathematics Students? Evaluating Mathematical Reasoning through Textual Manipulation and Human Experiments", "link": "https://arxiv.org/pdf/2412.11908", "details": "A Nikolaiev, Y Stathopoulos, S Teufel - arXiv preprint arXiv:2412.11908, 2024", "abstract": "In this paper we look at the ability of recent large language models (LLMs) at solving mathematical problems in combinatorics. We compare models LLaMA-2, LLaMA-3.1, GPT-4, and Mixtral against each other and against human pupils and \u2026"}, {"title": "Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases", "link": "https://arxiv.org/pdf/2412.11472", "details": "P Mugambi, A Meliou, M Fiterau - arXiv preprint arXiv:2412.11472, 2024", "abstract": "A crucial step in cohort studies is to extract the required cohort from one or more study datasets. This step is time-consuming, especially when a researcher is presented with a dataset that they have not previously worked with. When the cohort \u2026"}, {"title": "Multi-Hop Interpretable Meta Learning for Few-Shot Temporal Knowledge Graph Completion", "link": "https://www.sciencedirect.com/science/article/pii/S0893608024009109", "details": "L Bai, S Han, L Zhu - Neural Networks, 2024", "abstract": "Multi-hop path completion is a key part of temporal knowledge graph completion, which aims to infer complex relationships and obtain interpretable completion results. However, the traditional multi-hop path completion models mainly focus on \u2026"}, {"title": "Active learning for extracting rare adverse events from electronic health records: A study in pediatric cardiology", "link": "https://www.sciencedirect.com/science/article/pii/S1386505624004246", "details": "S Quennelle, S Malekzadeh-Milani, N Garcelon\u2026 - International Journal of \u2026, 2024", "abstract": "Objective Automate the extraction of adverse events from the text of electronic medical records of patients hospitalized for cardiac catheterization. Methods We focused on events related to cardiac catheterization as defined by the NCDR \u2026"}, {"title": "A few-shot learning method based on knowledge graph in large language models", "link": "https://link.springer.com/article/10.1007/s41060-024-00699-3", "details": "FL Wang, D Shi, J Aguilar, X Cui - International Journal of Data Science and Analytics, 2024", "abstract": "The emergence of large language models has significantly transformed natural language processing and text generation. Fine-tuning these models for specific domains enables them to generate answers tailored to the unique requirements of \u2026"}, {"title": "A Distributed Collaborative Retrieval Framework Excelling in All Queries and Corpora based on Zero-shot Rank-Oriented Automatic Evaluation", "link": "https://arxiv.org/pdf/2412.11832", "details": "TY Che, XL Mao, C Xu, CX Xin, HD Xu, JY Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Numerous retrieval models, including sparse, dense and llm-based methods, have demonstrated remarkable performance in predicting the relevance between queries and corpora. However, the preliminary effectiveness analysis experiments indicate \u2026"}]
