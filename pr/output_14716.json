[{"title": "Encoding of pretrained large language models mirrors the genetic architectures of human psychological traits.", "link": "https://www.medrxiv.org/content/10.1101/2025.03.27.25324744.full.pdf", "details": "B Xu, N Obradovich, W Zheng, R Loughnan, L Shao\u2026 - medRxiv, 2025", "abstract": "Recent advances in large language models (LLMs) have prompted a frenzy in utilizing them as universal translators for biomedical terms. However, the black box nature of LLMs has forced researchers to rely on artificially designed benchmarks \u2026"}]
