[{"title": "Why are Visually-Grounded Language Models Bad at Image Classification?", "link": "https://arxiv.org/pdf/2405.18415", "details": "Y Zhang, A Unell, X Wang, D Ghosh, Y Su, L Schmidt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Image classification is one of the most fundamental capabilities of machine vision intelligence. In this work, we revisit the image classification task using visually- grounded language models (VLMs) such as GPT-4V and LLaVA. We find that \u2026"}, {"title": "Multi-hop Question Answering", "link": "https://www.nowpublishers.com/article/DownloadSummary/INR-102", "details": "V Mavi, A Jangra, J Adam - Foundations and Trends\u00ae in Information Retrieval, 2024", "abstract": "Abstract The task of Question Answering (QA) has attracted significant research interest for a long time. Its relevance to language understanding and knowledge retrieval tasks, along with the simple setting, makes the task of QA crucial for strong \u2026"}, {"title": "Observational Scaling Laws and the Predictability of Language Model Performance", "link": "https://arxiv.org/pdf/2405.10938", "details": "Y Ruan, CJ Maddison, T Hashimoto - arXiv preprint arXiv:2405.10938, 2024", "abstract": "Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different \u2026"}, {"title": "Calibrating Reasoning in Language Models with Internal Consistency", "link": "https://arxiv.org/pdf/2405.18711", "details": "Z Xie, J Guo, T Yu, S Li - arXiv preprint arXiv:2405.18711, 2024", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various reasoning tasks, aided by techniques like chain-of-thought (CoT) prompting that elicits verbalized reasoning. However, LLMs often generate text with obvious \u2026"}, {"title": "TSCMamba: Mamba Meets Multi-View Learning for Time Series Classification", "link": "https://arxiv.org/pdf/2406.04419", "details": "MA Ahamed, Q Cheng - arXiv preprint arXiv:2406.04419, 2024", "abstract": "Time series classification (TSC) on multivariate time series is a critical problem. We propose a novel multi-view approach integrating frequency-domain and time-domain features to provide complementary contexts for TSC. Our method fuses continuous \u2026"}, {"title": "An Empirical Study and Analysis of Text-to-Image Generation Using Large Language Model-Powered Textual Representation", "link": "https://arxiv.org/pdf/2405.12914", "details": "Z Tan, M Yang, L Qin, H Yang, Y Qian, Q Zhou\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "One critical prerequisite for faithful text-to-image generation is the accurate understanding of text inputs. Existing methods leverage the text encoder of the CLIP model to represent input prompts. However, the pre-trained CLIP model can merely \u2026"}, {"title": "JEMHopQA: Dataset for Japanese Explainable Multi-Hop Question Answering", "link": "https://aclanthology.org/2024.lrec-main.831.pdf", "details": "A Ishii, N Inoue, H Suzuki, S Sekine - Proceedings of the 2024 Joint International \u2026, 2024", "abstract": "We present JEMHopQA, a multi-hop QA dataset for the development of explainable QA systems. The dataset consists not only of question-answer pairs, but also of supporting evidence in the form of derivation triples, which contributes to making the \u2026"}, {"title": "Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning", "link": "https://arxiv.org/pdf/2405.11640", "details": "Z Gu, F Liu, C Yin, P Zhang - arXiv preprint arXiv:2405.11640, 2024", "abstract": "The adoption of large language models (LLMs) in healthcare has attracted significant research interest. However, their performance in healthcare remains under- investigated and potentially limited, due to i) they lack rich domain-specific \u2026"}, {"title": "Prompt Tuning for Few-shot Relation Extraction via Modeling Global and Local Graphs", "link": "https://aclanthology.org/2024.lrec-main.1158.pdf", "details": "Z Zhang, Y Yang, B Chen - Proceedings of the 2024 Joint International Conference \u2026, 2024", "abstract": "Recently, prompt-tuning has achieved very significant results for few-shot tasks. The core idea of prompt-tuning is to insert prompt templates into the input, thus converting the classification task into a masked language modeling problem. However, for few \u2026"}]
