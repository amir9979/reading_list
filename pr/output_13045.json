[{"title": "Learning Conformal Abstention Policies for Adaptive Risk Management in Large Language and Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06884", "details": "S Tayebati, D Kumar, N Darabi, D Jayasuriya\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language and Vision-Language Models (LLMs/VLMs) are increasingly used in safety-critical applications, yet their opaque decision-making complicates risk assessment and reliability. Uncertainty quantification (UQ) helps assess prediction \u2026"}, {"title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training", "link": "https://arxiv.org/pdf/2502.11455", "details": "F Weng, J Lou, J Feng, M Huang, W Wang - arXiv preprint arXiv:2502.11455, 2025", "abstract": "Safety alignment is critical in pre-training large language models (LLMs) to generate responses aligned with human values and refuse harmful queries. Unlike LLM, the current safety alignment of VLMs is often achieved with post-hoc safety fine-tuning \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "Language Models Can See Better: Visual Contrastive Decoding For LLM Multimodal Reasoning", "link": "https://arxiv.org/pdf/2502.11751", "details": "Y Pang, B Yang, H Tu, Y Cao, Z Zhang - arXiv preprint arXiv:2502.11751, 2025", "abstract": "Although Large Language Models (LLMs) excel in reasoning and generation for language tasks, they are not specifically designed for multimodal challenges. Training Multimodal Large Language Models (MLLMs), however, is resource \u2026"}, {"title": "Scalable Language Models with Posterior Inference of Latent Thought Vectors", "link": "https://arxiv.org/pdf/2502.01567%3F", "details": "D Kong, M Zhao, D Xu, B Pang, S Wang, E Honig, Z Si\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We propose a novel family of language models, Latent-Thought Language Models (LTMs), which incorporate explicit latent thought vectors that follow an explicit prior model in latent space. These latent thought vectors guide the autoregressive \u2026"}, {"title": "Evaluating the Meta-and Object-Level Reasoning of Large Language Models for Question Answering", "link": "https://arxiv.org/pdf/2502.10338", "details": "N Ferguson, L Guillou, A Bundy, K Nuamah - arXiv preprint arXiv:2502.10338, 2025", "abstract": "Large Language Models (LLMs) excel in natural language tasks but still face challenges in Question Answering (QA) tasks requiring complex, multi-step reasoning. We outline the types of reasoning required in some of these tasks, and \u2026"}, {"title": "Large language models improve transferability of electronic health record-based predictions across countries and coding systems", "link": "https://www.medrxiv.org/content/medrxiv/early/2025/02/04/2025.02.03.25321597.full.pdf", "details": "M Kirchler, M Ferro, V Lorenzini, FinnGen, C Lippert\u2026 - medRxiv, 2025", "abstract": "Variation in medical practices and reporting standards across healthcare systems limits the transferability of prediction models based on structured electronic health record (EHR) data. We introduce GRASP, a novel transformer-based architecture \u2026"}, {"title": "ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language Interactions for Computer-Aided Diagnosis", "link": "https://arxiv.org/pdf/2502.10620", "details": "X Li, X Hou, Z Huang, Y Gan - arXiv preprint arXiv:2502.10620, 2025", "abstract": "Recent advancements in large language models (LLMs) have demonstrated extraordinary comprehension capabilities with remarkable breakthroughs on various vision-language tasks. However, the application of LLMs in generating reliable \u2026"}, {"title": "Advancing Vision-Language Models with Generative AI", "link": "https://www.preprints.org/frontend/manuscript/10b5ed95bd23954c58eef830d9d74bfa/download_pub", "details": "A Vats, R Raja - 2025", "abstract": "Generative AI within large vision-language models (LVLMs) has revolutionized multimodal learning, enabling machines to understand and generate visual content from textual descriptions with unprecedented accuracy. This paper explores state-of \u2026"}]
