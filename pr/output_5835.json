[{"title": "Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training", "link": "https://aclanthology.org/2024.findings-acl.680.pdf", "details": "Q Guo, R Wang, J Guo, X Tan, J Bian, Y Yang - Findings of the Association for \u2026, 2024", "abstract": "While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the \u201creversal curse\u201d. It is a typical example that the model knows \u201cA's father is B\u201d, but is unable to \u2026"}, {"title": "ProtoMix: Augmenting Health Status Representation Learning via Prototype-based Mixup", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671937", "details": "Y Xu, X Jiang, X Chu, Y Xiao, C Zhang, H Ding, J Zhao\u2026 - Proceedings of the 30th \u2026, 2024", "abstract": "With the widespread adoption of electronic health records (EHR) data, deep learning techniques have been broadly utilized for various health prediction tasks. Nevertheless, the labeled data scarcity issue restricts the prediction power of these \u2026"}, {"title": "R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation", "link": "https://arxiv.org/pdf/2408.09743", "details": "X Wang, Y Li, F Wang, S Wang, C Li, B Jiang - arXiv preprint arXiv:2408.09743, 2024", "abstract": "Inspired by the tremendous success of Large Language Models (LLMs), existing X- ray medical report generation methods attempt to leverage large models to achieve better performance. They usually adopt a Transformer to extract the visual features of \u2026"}, {"title": "On the Interchangeability of Positional Embeddings in Multilingual Neural Machine Translation Models", "link": "https://arxiv.org/pdf/2408.11382", "details": "V Gumma, PA Chitale, K Bali - arXiv preprint arXiv:2408.11382, 2024", "abstract": "Standard Neural Machine Translation (NMT) models have traditionally been trained with Sinusoidal Positional Embeddings (PEs), which are inadequate for capturing long-range dependencies and are inefficient for long-context or document-level \u2026"}]
