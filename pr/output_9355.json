[{"title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality", "link": "https://arxiv.org/pdf/2411.11531", "details": "V Chekalina, A Razzigaev, E Goncharova, A Kuznetsov - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper we present an approach to reduce hallucinations in Large Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional modality. Our method involves transforming input text into a set of KG embeddings and using \u2026"}, {"title": "BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices", "link": "https://arxiv.org/pdf/2411.10640", "details": "X Lu, Y Chen, C Chen, H Tan, B Chen, Y Xie, R Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence and growing popularity of multimodal large language models (MLLMs) have significant potential to enhance various aspects of daily life, from improving communication to facilitating learning and problem-solving. Mobile \u2026"}, {"title": "Group Robust Best-of-K Decoding of Language Models for Pluralistic Alignment", "link": "https://openreview.net/pdf%3Fid%3DJI6j4NUGHv", "details": "S Yoon, W Bankes, S Son, A Petrovic, SS Ramesh\u2026 - Pluralistic Alignment Workshop at \u2026", "abstract": "The desirable behaviour of a chat agent can be described with multiple criteria, such as harmlessness, helpfulness, and conciseness, each of which can be scored by a reward model. While each user, or a group of users, may perceive each criterion with \u2026"}, {"title": "Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations", "link": "https://arxiv.org/pdf/2411.07237", "details": "C Malaviya, JC Chang, D Roth, M Iyyer, M Yatskar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model users often issue queries that lack specification, where the context under which a query was issued--such as the user's identity, the query's intent, and the criteria for a response to be useful--is not explicit. For instance, a good response \u2026"}, {"title": "Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning", "link": "https://aclanthology.org/2024.emnlp-main.1258.pdf", "details": "S Wu, S Yang, Z Chen, Q Su - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "This study addresses the challenges of assessing and enhancing social-pragmatic inference in large language models (LLMs). We first highlight the inadequacy of current accuracy-based multiple choice question answering (MCQA) formats in \u2026"}, {"title": "LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote Sensing Vision-Language Interpretation", "link": "https://arxiv.org/pdf/2411.09301", "details": "Z Li, D Muhtar, F Gu, X Zhang, P Xiao, G He, X Zhu - arXiv preprint arXiv:2411.09301, 2024", "abstract": "Automatically and rapidly understanding Earth's surface is fundamental to our grasp of the living environment and informed decision-making. This underscores the need for a unified system with comprehensive capabilities in analyzing Earth's surface to \u2026"}, {"title": "From One to Zero: RAG-IM Adapts Language Models for Interpretable Zero-Shot Clinical Predictions", "link": "https://openreview.net/forum%3Fid%3D3OYjWzqqC1", "details": "S Mahbub, C Ellington, S Alinejad, K Wen, Y Luo\u2026 - Adaptive Foundation Models \u2026", "abstract": "Clinical machine learning models must adapt to new settings such as different hospitals, clinicians, or patient populations. These differing environments present related but subtly distinct tasks, where diseases and medical interventions share \u2026"}, {"title": "Continual Memorization of Factoids in Large Language Models", "link": "https://arxiv.org/pdf/2411.07175", "details": "H Chen, J Geng, A Bhaskar, D Friedman, D Chen - arXiv preprint arXiv:2411.07175, 2024", "abstract": "Large language models can absorb a massive amount of knowledge through pretraining, but pretraining is inefficient for acquiring long-tailed or specialized facts. Therefore, fine-tuning on specialized or new knowledge that reflects changes in the \u2026"}, {"title": "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.988.pdf", "details": "W Wang, Y Mao, T Dongdong, D Hongchao, N Guan\u2026 - Findings of the Association \u2026, 2024", "abstract": "Large language models (LLMs) exhibit excellent performance in various tasks. However, the memory requirements of LLMs present a great challenge when deploying on memory-limited devices, even for quantized LLMs. This paper \u2026"}]
