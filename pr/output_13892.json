[{"title": "Syntactic Learnability of Echo State Neural Language Models at Scale", "link": "https://arxiv.org/pdf/2503.01724%3F", "details": "R Ueda, T Kuribayashi, S Kando, K Inui - arXiv preprint arXiv:2503.01724, 2025", "abstract": "What is a neural model with minimum architectural complexity that exhibits reasonable language learning capability? To explore such a simple but sufficient neural language model, we revisit a basic reservoir computing (RC) model, Echo \u2026"}, {"title": "Mitigation of outcome conflation in predicting patient outcomes using electronic health records", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaf033/8064347", "details": "SM Reincke, C Espinosa, P Chung, T James, E Berson\u2026 - Journal of the American \u2026, 2025", "abstract": "Objectives Artificial intelligence (AI) models utilizing electronic health record data for disease prediction can enhance risk stratification but may lack specificity, which is crucial for reducing the economic and psychological burdens associated with false \u2026"}, {"title": "Zero-shot Medical Event Prediction Using a Generative Pre-trained Transformer on Electronic Health Records", "link": "https://arxiv.org/pdf/2503.05893", "details": "E Redekop, Z Wang, R Kulkarni, M Pleasure, A Chin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Longitudinal data in electronic health records (EHRs) represent an individuals clinical history through a sequence of codified concepts, including diagnoses, procedures, medications, and laboratory tests. Foundational models, such as \u2026"}, {"title": "Language Models Predict Empathy Gaps Between Social In-groups and Out-groups", "link": "https://arxiv.org/pdf/2503.01030", "details": "Y Hou, H Daum\u00e9 III, R Rudinger - arXiv preprint arXiv:2503.01030, 2025", "abstract": "Studies of human psychology have demonstrated that people are more motivated to extend empathy to in-group members than out-group members (Cikara et al., 2011). In this study, we investigate how this aspect of intergroup relations in humans is \u2026"}, {"title": "XIFBench: Evaluating Large Language Models on Multilingual Instruction Following", "link": "https://arxiv.org/pdf/2503.07539", "details": "Z Li, K Chen, Y Long, X Bai, Y Zhang, X Wei, J Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable instruction-following capabilities across various applications. However, their performance in multilingual settings remains poorly understood, as existing evaluations lack fine-grained \u2026"}, {"title": "Gender Encoding Patterns in Pretrained Language Model Representations", "link": "https://arxiv.org/pdf/2503.06734", "details": "M Zakizadeh, MT Pilehvar - arXiv preprint arXiv:2503.06734, 2025", "abstract": "Gender bias in pretrained language models (PLMs) poses significant social and ethical challenges. Despite growing awareness, there is a lack of comprehensive investigation into how different models internally represent and propagate such \u2026"}, {"title": "ChatVLA: Unified Multimodal Understanding and Robot Control with Vision-Language-Action Model", "link": "https://arxiv.org/pdf/2502.14420", "details": "Z Zhou, Y Zhu, M Zhu, J Wen, N Liu, Z Xu, W Meng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Humans possess a unified cognitive ability to perceive, comprehend, and interact with the physical world. Why can't large language models replicate this holistic understanding? Through a systematic analysis of existing training paradigms in \u2026"}, {"title": "A Survey on Large Language Models for Automated Planning", "link": "https://arxiv.org/pdf/2502.12435", "details": "M Aghzal, E Plaku, GJ Stein, Z Yao - arXiv preprint arXiv:2502.12435, 2025", "abstract": "The planning ability of Large Language Models (LLMs) has garnered increasing attention in recent years due to their remarkable capacity for multi-step reasoning and their ability to generalize across a wide range of domains. While some \u2026"}, {"title": "BoT: Breaking Long Thought Processes of o1-like Large Language Models through Backdoor Attack", "link": "https://arxiv.org/pdf/2502.12202", "details": "Z Zhu, H Zhang, M Zhang, R Wang, G Wu, K Xu, B Wu - arXiv preprint arXiv \u2026, 2025", "abstract": "Longer thought, better performance: large language models with deep reasoning capabilities, particularly o1-like models, have demonstrated remarkable performance by generating extensive thought processes during inference. This trade-off reveals a \u2026"}]
