[{"title": "Teaching Language Models to Critique via Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.03492", "details": "Z Xie, L Chen, W Mao, J Xu, L Kong - arXiv preprint arXiv:2502.03492, 2025", "abstract": "Teaching large language models (LLMs) to critique and refine their outputs is crucial for building systems that can iteratively improve, yet it is fundamentally limited by the ability to provide accurate judgments and actionable suggestions. In this work, we \u2026"}, {"title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models", "link": "https://arxiv.org/pdf/2502.06663", "details": "X Xing, Z Liu, S Xiao, B Gao, Y Liang, W Zhang, H Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge \u2026"}, {"title": "Scaling Embedding Layers in Language Models", "link": "https://arxiv.org/pdf/2502.01637%3F", "details": "D Yu, E Cohen, B Ghazi, Y Huang, P Kamath, R Kumar\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We propose SCONE ($\\textbf {S} $ calable, $\\textbf {C} $ ontextualized, $\\textbf {O} $ ffloaded, $\\textbf {N} $-gram $\\textbf {E} $ mbedding), a method for extending input embedding layers to enhance language model performance as layer size scales. To \u2026"}, {"title": "CE-LoRA: Computation-Efficient LoRA Fine-Tuning for Language Models", "link": "https://arxiv.org/pdf/2502.01378", "details": "G Chen, Y He, Y Hu, K Yuan, B Yuan - arXiv preprint arXiv:2502.01378, 2025", "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across various tasks but demand substantial computational resources even for fine-tuning computation. Although Low-Rank Adaptation (LoRA) significantly alleviates memory \u2026"}, {"title": "Dynamic link prediction: Using language models and graph structures for temporal knowledge graph completion with emerging entities and relations", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002702", "details": "R Ong, J Sun, YK Guo, O Serban - Expert Systems with Applications, 2025", "abstract": "Abstract Knowledge graphs (KGs) represent real-world facts through entities and relations. However, static KGs fail to capture continuously emerging entities and relations over time. Temporal knowledge graphs address this by incorporating time \u2026"}, {"title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "link": "https://arxiv.org/pdf/2501.16961%3F", "details": "M Raza, N Milic-Frayling - arXiv preprint arXiv:2501.16961, 2025", "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that \u2026"}, {"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "HaluCheck: Explainable and verifiable automation for detecting hallucinations in LLM responses", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425003343", "details": "S Heo, S Son, H Park - Expert Systems with Applications, 2025", "abstract": "Large language models have become integral to various aspects of modern life, but a critical challenge persists: hallucinations. This work contributes to expert systems research by providing a systematic framework for enhancing AI reliability and \u2026"}, {"title": "Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant", "link": "https://arxiv.org/pdf/2501.17546", "details": "G He, N Aishwarya, U Gadiraju - arXiv preprint arXiv:2501.17546, 2025", "abstract": "Explainable artificial intelligence (XAI) methods are being proposed to help interpret and understand how AI systems reach specific predictions. Inspired by prior work on conversational user interfaces, we argue that augmenting existing XAI methods with \u2026"}]
