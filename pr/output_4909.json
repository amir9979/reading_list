[{"title": "Reflective Instruction Tuning: Mitigating Hallucinations in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2407.11422", "details": "J Zhang, T Wang, H Zhang, P Lu, F Zheng - arXiv preprint arXiv:2407.11422, 2024", "abstract": "Large vision-language models (LVLMs) have shown promising performance on a variety of vision-language tasks. However, they remain susceptible to hallucinations, generating outputs misaligned with visual content or instructions. While various \u2026"}, {"title": "On Speeding Up Language Model Evaluation", "link": "https://arxiv.org/pdf/2407.06172", "details": "JP Zhou, CK Belardi, R Wu, T Zhang, CP Gomes\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks. Developing a model of this nature, from training to inference, requires making \u2026"}, {"title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering", "link": "https://arxiv.org/pdf/2407.21368", "details": "D Guo, D Terzopoulos - arXiv preprint arXiv:2407.21368, 2024", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in recent years, and they have been extended to the medical domain. Although demonstrating satisfactory performance on medical Visual Question Answering (VQA) tasks \u2026"}, {"title": "NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models", "link": "https://arxiv.org/pdf/2407.10380", "details": "P Pandya, AS Talwarr, V Gupta, T Kataria, V Gupta\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Cognitive textual and visual reasoning tasks, such as puzzles, series, and analogies, demand the ability to quickly reason, decipher, and evaluate patterns both textually and spatially. While LLMs and VLMs, through extensive training on large amounts of \u2026"}, {"title": "Leveraging LLM Reasoning Enhances Personalized Recommender Systems", "link": "https://arxiv.org/pdf/2408.00802", "details": "AY Tsai, A Kraft, L Jin, C Cai, A Hosseini, T Xu, Z Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements have showcased the potential of Large Language Models (LLMs) in executing reasoning tasks, particularly facilitated by Chain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve clear, definitive \u2026"}, {"title": "Position Paper: Dual-System Language Models via Next-Action Prediction", "link": "https://openreview.net/pdf%3Fid%3D9ZVfz8DGC8", "details": "Z Du, WJ Su - ICML 2024 Workshop on LLMs and Cognition", "abstract": "In current Large Language Model (LLM) practices, each token is appended sequentially to the output. In contrast, humans are capable of revising and correcting what we write. Inspired by this gap, in this position paper, we propose a dual-system \u2026"}, {"title": "Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models", "link": "https://arxiv.org/pdf/2407.19474", "details": "N Bitton-Guetta, A Slobodkin, A Maimon, E Habba\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Imagine observing someone scratching their arm; to understand why, additional context would be necessary. However, spotting a mosquito nearby would immediately offer a likely explanation for the person's discomfort, thereby alleviating \u2026"}, {"title": "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning", "link": "https://arxiv.org/pdf/2407.06112", "details": "Y Zhang, S Mao, W Wu, Y Xia, T Ge, M Lan, F Wei - arXiv preprint arXiv:2407.06112, 2024", "abstract": "This paper introduces BI-Directional DEliberation Reasoning (BIDDER), a novel reasoning approach to enhance the decision rationality of language models. Traditional reasoning methods typically rely on historical information and employ uni \u2026"}, {"title": "Distilling System 2 into System 1", "link": "https://arxiv.org/pdf/2407.06023", "details": "P Yu, J Xu, J Weston, I Kulikov - arXiv preprint arXiv:2407.06023, 2024", "abstract": "Large language models (LLMs) can spend extra compute during inference to generate intermediate thoughts, which helps to produce better final responses. Since Chain-of-Thought (Wei et al., 2022), many such System 2 techniques have been \u2026"}]
