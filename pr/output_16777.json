[{"title": "Examining the Visual Search Behaviour of Experts When Screening for the Presence of Diabetic Retinopathy in Fundus Images", "link": "https://www.mdpi.com/2077-0383/14/9/3046", "details": "TI Murphy, JA Armitage, LA Abel, P van Wijngaarden\u2026 - Journal of Clinical Medicine, 2025", "abstract": "Objectives: This study investigated the visual search behaviour of optometrists and fellowship-trained ophthalmologists when screening for diabetic retinopathy in retinal photographs. Methods: Participants assessed and graded retinal photographs on a \u2026"}, {"title": "Enhanced Retinal Vessel Segmentation Using Dynamic Contrast Stretching and Mathematical Morphology on Fundus Images", "link": "https://onlinelibrary.wiley.com/doi/pdf/10.1155/acis/8831503", "details": "EM Chakour, Y Mrad, A Mansouri, Y Elloumi\u2026 - \u2026 Intelligence and Soft \u2026, 2025", "abstract": "Retinal vessel segmentation algorithms are crucial in automated retinal disease screening systems, as accurate determination of blood vessel structures is vital for ocular disease identification and diagnosis. In this study, we propose an efficient \u2026"}, {"title": "A BERT-Style Self-Supervised Learning CNN for Disease Identification from Retinal Images", "link": "https://arxiv.org/pdf/2504.18049", "details": "X Li, W Zhu, P Qiu, OM Dumitrascu, A Youssef, Y Wang - arXiv preprint arXiv \u2026, 2025", "abstract": "In the field of medical imaging, the advent of deep learning, especially the application of convolutional neural networks (CNNs) has revolutionized the analysis and interpretation of medical images. Nevertheless, deep learning methods usually \u2026", "entry_id": "http://arxiv.org/abs/2504.18049v1", "updated": "2025-04-25 03:38:55", "published": "2025-04-25 03:38:55", "authors": "Xin Li;Wenhui Zhu;Peijie Qiu;Oana M. Dumitrascu;Amal Youssef;Yalin Wang", "summary": "In the field of medical imaging, the advent of deep learning, especially the\napplication of convolutional neural networks (CNNs) has revolutionized the\nanalysis and interpretation of medical images. Nevertheless, deep learning\nmethods usually rely on large amounts of labeled data. In medical imaging\nresearch, the acquisition of high-quality labels is both expensive and\ndifficult. The introduction of Vision Transformers (ViT) and self-supervised\nlearning provides a pre-training strategy that utilizes abundant unlabeled\ndata, effectively alleviating the label acquisition challenge while broadening\nthe breadth of data utilization. However, ViT's high computational density and\nsubstantial demand for computing power, coupled with the lack of localization\ncharacteristics of its operations on image patches, limit its efficiency and\napplicability in many application scenarios. In this study, we employ\nnn-MobileNet, a lightweight CNN framework, to implement a BERT-style\nself-supervised learning approach. We pre-train the network on the unlabeled\nretinal fundus images from the UK Biobank to improve downstream application\nperformance. We validate the results of the pre-trained model on Alzheimer's\ndisease (AD), Parkinson's disease (PD), and various retinal diseases\nidentification. The results show that our approach can significantly improve\nperformance in the downstream tasks. In summary, this study combines the\nbenefits of CNNs with the capabilities of advanced self-supervised learning in\nhandling large-scale unlabeled data, demonstrating the potential of CNNs in the\npresence of label scarcity.", "comment": null, "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.AI", "links": "http://arxiv.org/abs/2504.18049v1;http://arxiv.org/pdf/2504.18049v1", "pdf_url": "http://arxiv.org/pdf/2504.18049v1"}, {"title": "RESIST: Rationale-Enhanced and Reward Model-Based End-to-End Social Influence Dialogue System", "link": "https://dl.acm.org/doi/pdf/10.1145/3736580", "details": "T Wu, J Zhu, W Zhou, H Li - ACM Transactions on Multimedia Computing \u2026, 2025", "abstract": "Developing proactive social influence dialogue systems presents a significant challenge, particularly in non-cooperative scenarios where the system's goals may conflict with those of the user. Traditional methods often focus on training models to \u2026"}, {"title": "Performance and Effectiveness of Diabetic Retinopathy Screening in Portugal: An Outcome-Based Evaluation", "link": "https://www.mdpi.com/2077-0383/14/10/3344", "details": "I Coelho-Costa, A Silva-Pereira, P Mota-Moreira\u2026 - Journal of Clinical Medicine, 2025", "abstract": "Background/Objectives: Diabetic retinopathy (DR) is the leading cause of preventable blindness among working-age adults. Early detection through screening programs is essential for managing the condition and preventing visual impairment \u2026"}, {"title": "Active learning in computational pathology with noise detection empowered by loss-based prior and feature analysis", "link": "https://www.sciencedirect.com/science/article/pii/S1746809425004641", "details": "Y Huang, J Li, H An, T Luo, Z Ji, Y Song, H Liu\u2026 - \u2026 Signal Processing and \u2026, 2025", "abstract": "AI-based histopathological image analysis has significantly advanced the field of computer-aided diagnosis. While labeled data can enhance model performance, manual annotation by pathologists is labor-intensive and time-consuming, with \u2026"}, {"title": "Explainable Artificial Intelligence-Assisted Exploration of Clinically Significant Diabetic Retinal Neurodegeneration on OCT Images", "link": "https://www.sciencedirect.com/science/article/pii/S2666914525001022", "details": "M Yoshida, T Murakami, K Ishihara, Y Mori\u2026 - Ophthalmology Science, 2025", "abstract": "Purpose To explore clinically significant diabetic retinal neurodegeneration (DRN) in optical coherence tomography (OCT) images using explainable artificial intelligence (XAI) and subsequent evaluation by retinal specialists. Design Single-center \u2026"}, {"title": "Parallel Scaling Law for Language Models", "link": "https://arxiv.org/pdf/2505.10475", "details": "M Chen, B Hui, Z Cui, J Yang, D Liu, J Sun, J Lin, Z Liu - arXiv preprint arXiv \u2026, 2025", "abstract": "It is commonly believed that scaling language models should commit a significant space or time cost, by increasing the parameters (parameter scaling) or output tokens (inference-time scaling). We introduce the third and more inference-efficient \u2026", "entry_id": "http://arxiv.org/abs/2505.10475v1", "updated": "2025-05-15 16:24:45", "published": "2025-05-15 16:24:45", "authors": "Mouxiang Chen;Binyuan Hui;Zeyu Cui;Jiaxi Yang;Dayiheng Liu;Jianling Sun;Junyang Lin;Zhongxin Liu", "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.CL", "links": "http://arxiv.org/abs/2505.10475v1;http://arxiv.org/pdf/2505.10475v1", "pdf_url": "http://arxiv.org/pdf/2505.10475v1"}, {"title": "Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining", "link": "https://arxiv.org/pdf/2505.12711", "details": "Q Sun, Z Guo, R Peng, H Chen, J Wang - arXiv preprint arXiv:2505.12711, 2025", "abstract": "Recent advances in computational pathology and artificial intelligence have significantly enhanced the utilization of gigapixel whole-slide images and and additional modalities (eg, genomics) for pathological diagnosis. Although deep \u2026", "entry_id": "http://arxiv.org/abs/2505.12711v2", "updated": "2025-05-20 12:57:58", "published": "2025-05-19 05:07:34", "authors": "Qichen Sun;Zhengrui Guo;Rui Peng;Hao Chen;Jinzhuo Wang", "summary": "Recent advances in computational pathology and artificial intelligence have\nsignificantly enhanced the utilization of gigapixel whole-slide images and and\nadditional modalities (e.g., genomics) for pathological diagnosis. Although\ndeep learning has demonstrated strong potential in pathology, several key\nchallenges persist: (1) fusing heterogeneous data types requires sophisticated\nstrategies beyond simple concatenation due to high computational costs; (2)\ncommon scenarios of missing modalities necessitate flexible strategies that\nallow the model to learn robustly in the absence of certain modalities; (3) the\ndownstream tasks in CPath are diverse, ranging from unimodal to multimodal,\ncnecessitating a unified model capable of handling all modalities. To address\nthese challenges, we propose ALTER, an any-to-any tri-modal pretraining\nframework that integrates WSIs, genomics, and pathology reports. The term \"any\"\nemphasizes ALTER's modality-adaptive design, enabling flexible pretraining with\nany subset of modalities, and its capacity to learn robust, cross-modal\nrepresentations beyond WSI-centric approaches. We evaluate ALTER across\nextensive clinical tasks including survival prediction, cancer subtyping, gene\nmutation prediction, and report generation, achieving superior or comparable\nperformance to state-of-the-art baselines.", "comment": null, "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV;cs.AI", "links": "http://arxiv.org/abs/2505.12711v2;http://arxiv.org/pdf/2505.12711v2", "pdf_url": "http://arxiv.org/pdf/2505.12711v2"}]
