[{"title": "Empirical Analysis of Dialogue Relation Extraction with Large Language Models", "link": "https://arxiv.org/pdf/2404.17802", "details": "G Li, Z Xu, Z Shang, J Liu, K Ji, Y Guo - arXiv preprint arXiv:2404.17802, 2024", "abstract": "Dialogue relation extraction (DRE) aims to extract relations between two arguments within a dialogue, which is more challenging than standard RE due to the higher person pronoun frequency and lower information density in dialogues. However \u2026"}, {"title": "A Survey of Deep Learning-based Radiology Report Generation Using Multimodal Data", "link": "https://arxiv.org/pdf/2405.12833", "details": "X Wang, G Figueredo, R Li, WE Zhang, W Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Automatic radiology report generation can alleviate the workload for physicians and minimize regional disparities in medical resources, therefore becoming an important topic in the medical image analysis field. It is a challenging task, as the \u2026"}, {"title": "EFTNAS: Searching for Efficient Language Models in First-Order Weight-Reordered Super-Networks", "link": "https://aclanthology.org/2024.lrec-main.497.pdf", "details": "JP Munoz, Y Zheng, N Jain - Proceedings of the 2024 Joint International Conference \u2026, 2024", "abstract": "Transformer-based models have demonstrated outstanding performance in natural language processing (NLP) tasks and many other domains, eg, computer vision. Depending on the size of these models, which have grown exponentially in the past \u2026"}, {"title": "MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization", "link": "https://arxiv.org/pdf/2405.04163", "details": "G Balde, S Roy, M Mondal, N Ganguly - arXiv preprint arXiv:2405.04163, 2024", "abstract": "This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for fine- tuning pre-trained language models (PLMs) like BertSumAbs, BART, and PEGASUS for improved medical text summarization. In contrast to existing domain adaptation \u2026"}, {"title": "Mammo-CLIP: A Vision Language Foundation Model to Enhance Data Efficiency and Robustness in Mammography", "link": "https://arxiv.org/pdf/2405.12255", "details": "S Ghosh, CB Poynton, S Visweswaran\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The lack of large and diverse training data on Computer-Aided Diagnosis (CAD) in breast cancer detection has been one of the concerns that impedes the adoption of the system. Recently, pre-training with large-scale image text datasets via Vision \u2026"}, {"title": "Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray", "link": "https://arxiv.org/pdf/2404.14750", "details": "Q Deng, Z Huang, Y Wang, Z Wang, Z Wang, X Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Medical vision-language pre-training has emerged as a promising approach for learning domain-general representations of medical image and text. Current algorithms that exploit the global and local alignment between medical image and \u2026"}]
