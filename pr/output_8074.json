[{"title": "PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction", "link": "https://arxiv.org/pdf/2410.17247", "details": "L Xing, Q Huang, X Dong, J Lu, P Zhang, Y Zang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In large vision-language models (LVLMs), images serve as inputs that carry a wealth of information. As the idiom\" A picture is worth a thousand words\" implies, representing a single image in current LVLMs can require hundreds or even \u2026"}, {"title": "EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679582", "details": "Y Zhu, C Ren, Z Wang, X Zheng, S Xie, J Feng, X Zhu\u2026 - Proceedings of the 33rd \u2026, 2024", "abstract": "The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary \u2026"}, {"title": "To read or not to read\u2013A cross-sectional study of Swedish primary care patients' adoption of patient accessible electronic health records", "link": "https://journals.sagepub.com/doi/full/10.1177/20552076241287636", "details": "I Muli, \u00c5 Cajander, H Hvitfeldt, YT Lagerros\u2026 - Digital Health, 2024", "abstract": "Objective Patient-accessible electronic health records (PAEHR) were implemented in the Stockholm region of Sweden seven years ago. This study examines socio- demographic and psychographic factors associated with reading/not reading these \u2026"}, {"title": "CLR2G: Cross modal Contrastive Learning on Radiology Report Generation", "link": "https://dl.acm.org/doi/abs/10.1145/3627673.3679668", "details": "H Xue, Q Ma, G Liu, J Qu, Y Liu, A Liu - Proceedings of the 33rd ACM International \u2026, 2024", "abstract": "The automatic generation of radiological imaging reports aims to produce accurate and coherent clinical descriptions based on X-ray images. This facilitates clinicians in completing the arduous task of report writing and advances clinical automation \u2026"}, {"title": "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models", "link": "https://arxiv.org/pdf/2410.09079", "details": "A Chang, J Wang, H Liu, P Bhatia, C Xiao, T Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Parameter Efficient Fine-Tuning (PEFT) offers an efficient solution for fine-tuning large pretrained language models for downstream tasks. However, most PEFT strategies are manually designed, often resulting in suboptimal performance. Recent \u2026"}, {"title": "Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models", "link": "https://arxiv.org/pdf/2410.03258", "details": "G Balde, S Roy, M Mondal, N Ganguly - arXiv preprint arXiv:2410.03258, 2024", "abstract": "In this work, we show a fundamental limitation in vocabulary adaptation approaches that use Byte-Pair Encoding (BPE) tokenization scheme for fine-tuning pretrained language models (PLMs) to expert domains. Current approaches trivially append the \u2026"}]
