[{"title": "Enhancing Robustness of Vision-Language Models through Orthogonality Learning and Cross-Regularization", "link": "https://arxiv.org/pdf/2407.08374", "details": "J Li, Z Jie, E Ricci, L Ma, N Sebe - arXiv preprint arXiv:2407.08374, 2024", "abstract": "Efficient finetuning of vision-language models (VLMs) like CLIP for specific downstream tasks is gaining significant attention. Previous works primarily focus on prompt learning to adapt the CLIP into a variety of downstream tasks, however \u2026"}]
