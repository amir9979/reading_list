[{"title": "Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective", "link": "https://arxiv.org/pdf/2405.16747", "details": "A Tomihari, I Sato - arXiv preprint arXiv:2405.16747, 2024", "abstract": "The two-stage fine-tuning (FT) method, linear probing then fine-tuning (LP-FT), consistently outperforms linear probing (LP) and FT alone in terms of accuracy for both in-distribution (ID) and out-of-distribution (OOD) data. This success is largely \u2026"}, {"title": "Language Models Need Inductive Biases to Count Inductively", "link": "https://arxiv.org/pdf/2405.20131", "details": "Y Chang, Y Bisk - arXiv preprint arXiv:2405.20131, 2024", "abstract": "Counting is a fundamental example of generalization, whether viewed through the mathematical lens of Peano's axioms defining the natural numbers or the cognitive science literature for children learning to count. The argument holds for both cases \u2026"}, {"title": "Unelicitable Backdoors in Language Models via Cryptographic Transformer Circuits", "link": "https://arxiv.org/pdf/2406.02619", "details": "A Draguns, A Gritsevskiy, SR Motwani, C Rogers-Smith\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid proliferation of open-source language models significantly increases the risks of downstream backdoor attacks. These backdoors can introduce dangerous behaviours during model deployment and can evade detection by conventional \u2026"}, {"title": "TAIA: Large Language Models are Out-of-Distribution Data Learners", "link": "https://arxiv.org/pdf/2405.20192", "details": "S Jiang, Y Liao, Y Zhang, Y Wang, Y Wang - arXiv preprint arXiv:2405.20192, 2024", "abstract": "Fine-tuning on task-specific question-answer pairs is a predominant method for enhancing the performance of instruction-tuned large language models (LLMs) on downstream tasks. However, in certain specialized domains, such as healthcare or \u2026"}, {"title": "An Analysis Method for the Impact of GenAI Code Suggestions on Software Engineers' Thought Processes", "link": "https://ojs.aaai.org/index.php/AAAI-SS/article/download/31257/33417", "details": "T Yonekawa, H Yamano, I Sakata - Proceedings of the AAAI Symposium Series, 2024", "abstract": "Interactive generative AI can be used in software programming to generate sufficient quality of code. Software developers can utilize the output code of generative AI as well as website resources from search engine results. In this research, we present a \u2026"}, {"title": "Exploring and Mitigating Shortcut Learning for Generative Large Language Models", "link": "https://aclanthology.org/2024.lrec-main.602.pdf", "details": "Z Sun, Y Xiao, J Li, Y Ji, W Chen, M Zhang - Proceedings of the 2024 Joint \u2026, 2024", "abstract": "Recent generative large language models (LLMs) have exhibited incredible instruction-following capabilities while keeping strong task completion ability, even without task-specific fine-tuning. Some works attribute this to the bonus of the new \u2026"}, {"title": "A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks", "link": "https://arxiv.org/pdf/2405.10251", "details": "X Ni, P Li - arXiv preprint arXiv:2405.10251, 2024", "abstract": "Recent efforts have evaluated large language models (LLMs) in areas such as commonsense reasoning, mathematical reasoning, and code generation. However, to the best of our knowledge, no work has specifically investigated the performance \u2026"}, {"title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?", "link": "https://arxiv.org/pdf/2405.16908", "details": "G Yona, R Aharoni, M Geva - arXiv preprint arXiv:2405.16908, 2024", "abstract": "We posit that large language models (LLMs) should be capable of expressing their intrinsic uncertainty in natural language. For example, if the LLM is equally likely to output two contradicting answers to the same question, then its generated response \u2026"}, {"title": "BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation", "link": "https://arxiv.org/pdf/2405.17039", "details": "C Jia, P Wang, Z Li, YC Li, Z Zhang, N Tang, Y Yu - arXiv preprint arXiv:2405.17039, 2024", "abstract": "Large language models (LLMs) have catalyzed a paradigm shift in natural language processing, yet their limited controllability poses a significant challenge for downstream applications. We aim to address this by drawing inspiration from the \u2026"}]
