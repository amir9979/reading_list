[{"title": "B-AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Black-box Adversarial Visual-Instructions", "link": "https://ieeexplore.ieee.org/abstract/document/10816024/", "details": "H Zhang, W Shao, H Liu, Y Ma, P Luo, Y Qiao, N Zheng\u2026 - IEEE Transactions on \u2026, 2024", "abstract": "Large Vision-Language Models (LVLMs) have shown significant progress in responding well to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent \u2026"}, {"title": "X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models", "link": "https://arxiv.org/pdf/2412.01824%3F", "details": "Z Sun, Z Chu, P Zhang, T Wu, X Dong, Y Zang, Y Xiong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In-context generation is a key component of large language models'(LLMs) open- task generalization capability. By leveraging a few examples as context, LLMs can perform both in-domain and out-of-domain tasks. Recent advancements in auto \u2026"}]
