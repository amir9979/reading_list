[{"title": "Evaluating the performance and fragility of large language models on the self-assessment for neurological surgeons", "link": "https://arxiv.org/pdf/2505.23477", "details": "K Vishwanath, A Alyakin, M Ghosh, JV Lee, DA Alber\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 **questions** are widely used by neurosurgical residents to prepare for written board examinations. Recently, these **questions** have also served as benchmarks for evaluating **large** **language** **models** \u2026 Robustness of **Large** **Language** **Models** in \u2026", "entry_id": "http://arxiv.org/abs/2505.23477v1", "updated": "2025-05-29 14:27:14", "published": "2025-05-29 14:27:14", "authors": "Krithik Vishwanath;Anton Alyakin;Mrigayu Ghosh;Jin Vivian Lee;Daniel Alexander Alber;Karl L. Sangwon;Douglas Kondziolka;Eric Karl Oermann", "summary": "The Congress of Neurological Surgeons Self-Assessment for Neurological\nSurgeons (CNS-SANS) questions are widely used by neurosurgical residents to\nprepare for written board examinations. Recently, these questions have also\nserved as benchmarks for evaluating large language models' (LLMs) neurosurgical\nknowledge. This study aims to assess the performance of state-of-the-art LLMs\non neurosurgery board-like questions and to evaluate their robustness to the\ninclusion of distractor statements. A comprehensive evaluation was conducted\nusing 28 large language models. These models were tested on 2,904 neurosurgery\nboard examination questions derived from the CNS-SANS. Additionally, the study\nintroduced a distraction framework to assess the fragility of these models. The\nframework incorporated simple, irrelevant distractor statements containing\npolysemous words with clinical meanings used in non-clinical contexts to\ndetermine the extent to which such distractions degrade model performance on\nstandard medical benchmarks. 6 of the 28 tested LLMs achieved board-passing\noutcomes, with the top-performing models scoring over 15.7% above the passing\nthreshold. When exposed to distractions, accuracy across various model\narchitectures was significantly reduced-by as much as 20.4%-with one model\nfailing that had previously passed. Both general-purpose and medical\nopen-source models experienced greater performance declines compared to\nproprietary variants when subjected to the added distractors. While current\nLLMs demonstrate an impressive ability to answer neurosurgery board-like exam\nquestions, their performance is markedly vulnerable to extraneous, distracting\ninformation. These findings underscore the critical need for developing novel\nmitigation strategies aimed at bolstering LLM resilience against in-text\ndistractions, particularly for safe and effective clinical deployment.", "comment": "22 pages, 3 main figures, 3 supplemental figures", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.23477v1;http://arxiv.org/pdf/2505.23477v1", "pdf_url": "http://arxiv.org/pdf/2505.23477v1"}, {"title": "A Comprehensive Evaluation of Multi-Modal Large Language Models for Endoscopy Analysis", "link": "https://arxiv.org/pdf/2505.23601", "details": "S Liu, B Zheng, W Chen, Z Peng, Z Yin, J Shao, J Hu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 the capabilities of Multimodal **Large** **Language** **Models** (MLLMs), we employ the GPT-4o-mini API to rephrase **questions** from the original \u2026 bootstrapping strategy to create high-quality datasets, boosting performance in visual **question** **answering** and \u2026", "entry_id": "http://arxiv.org/abs/2505.23601v1", "updated": "2025-05-29 16:14:34", "published": "2025-05-29 16:14:34", "authors": "Shengyuan Liu;Boyun Zheng;Wenting Chen;Zhihao Peng;Zhenfei Yin;Jing Shao;Jiancong Hu;Yixuan Yuan", "summary": "Endoscopic procedures are essential for diagnosing and treating internal\ndiseases, and multi-modal large language models (MLLMs) are increasingly\napplied to assist in endoscopy analysis. However, current benchmarks are\nlimited, as they typically cover specific endoscopic scenarios and a small set\nof clinical tasks, failing to capture the real-world diversity of endoscopic\nscenarios and the full range of skills needed in clinical workflows. To address\nthese issues, we introduce EndoBench, the first comprehensive benchmark\nspecifically designed to assess MLLMs across the full spectrum of endoscopic\npractice with multi-dimensional capacities. EndoBench encompasses 4 distinct\nendoscopic scenarios, 12 specialized clinical tasks with 12 secondary subtasks,\nand 5 levels of visual prompting granularities, resulting in 6,832 rigorously\nvalidated VQA pairs from 21 diverse datasets. Our multi-dimensional evaluation\nframework mirrors the clinical workflow--spanning anatomical recognition,\nlesion analysis, spatial localization, and surgical operations--to holistically\ngauge the perceptual and diagnostic abilities of MLLMs in realistic scenarios.\nWe benchmark 23 state-of-the-art models, including general-purpose,\nmedical-specialized, and proprietary MLLMs, and establish human clinician\nperformance as a reference standard. Our extensive experiments reveal: (1)\nproprietary MLLMs outperform open-source and medical-specialized models\noverall, but still trail human experts; (2) medical-domain supervised\nfine-tuning substantially boosts task-specific accuracy; and (3) model\nperformance remains sensitive to prompt format and clinical task complexity.\nEndoBench establishes a new standard for evaluating and advancing MLLMs in\nendoscopy, highlighting both progress and persistent gaps between current\nmodels and expert clinical reasoning. We publicly release our benchmark and\ncode.", "comment": "36 pages, 18 figures", "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.23601v1;http://arxiv.org/pdf/2505.23601v1", "pdf_url": "http://arxiv.org/pdf/2505.23601v1"}, {"title": "Can Large Language Models Match the Conclusions of Systematic Reviews?", "link": "https://arxiv.org/pdf/2505.22787", "details": "C Polzak, A Lozano, MW Sun, J Burgess, Y Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "\u2026 MedREQAL: Examining **medical** knowledge recall of **large** **language** **models** via **question** **answering**. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, Findings of the Association for Computational Linguistics: ACL 2024, pages 14459\u201314469 \u2026", "entry_id": "http://arxiv.org/abs/2505.22787v1", "updated": "2025-05-28 18:58:09", "published": "2025-05-28 18:58:09", "authors": "Christopher Polzak;Alejandro Lozano;Min Woo Sun;James Burgess;Yuhui Zhang;Kevin Wu;Serena Yeung-Levy", "summary": "Systematic reviews (SR), in which experts summarize and analyze evidence\nacross individual studies to provide insights on a specialized topic, are a\ncornerstone for evidence-based clinical decision-making, research, and policy.\nGiven the exponential growth of scientific articles, there is growing interest\nin using large language models (LLMs) to automate SR generation. However, the\nability of LLMs to critically assess evidence and reason across multiple\ndocuments to provide recommendations at the same proficiency as domain experts\nremains poorly characterized. We therefore ask: Can LLMs match the conclusions\nof systematic reviews written by clinical experts when given access to the same\nstudies? To explore this question, we present MedEvidence, a benchmark pairing\nfindings from 100 SRs with the studies they are based on. We benchmark 24 LLMs\non MedEvidence, including reasoning, non-reasoning, medical specialist, and\nmodels across varying sizes (from 7B-700B). Through our systematic evaluation,\nwe find that reasoning does not necessarily improve performance, larger models\ndo not consistently yield greater gains, and knowledge-based fine-tuning\ndegrades accuracy on MedEvidence. Instead, most models exhibit similar\nbehavior: performance tends to degrade as token length increases, their\nresponses show overconfidence, and, contrary to human experts, all models show\na lack of scientific skepticism toward low-quality findings. These results\nsuggest that more work is still required before LLMs can reliably match the\nobservations from expert-conducted SRs, even though these systems are already\ndeployed and being used by clinicians. We release our codebase and benchmark to\nthe broader research community to further investigate LLM-based SR systems.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL", "links": "http://arxiv.org/abs/2505.22787v1;http://arxiv.org/pdf/2505.22787v1", "pdf_url": "http://arxiv.org/pdf/2505.22787v1"}, {"title": "Domain Specific Benchmarks for Evaluating Multimodal **Large Language Models**", "link": "https://www.preprints.org/frontend/manuscript/d56e264011a4a69f9edd5f4fdcfbb212/download_pub", "details": "K Anjum, MA Arshad, K Hayawi, E Polyzos, A Tariq\u2026 - 2025", "abstract": "\u2026 For instance, even leading models like GPT-4 have demonstrated significant limitations in specialized financial **question** **answering** , \u2026 financial nuances to interpreting specialized engineering diagrams or **medical** imagery\u2014these \u2026"}, {"title": "A Survey on the Impact of Pre-Trained Language Models in Sentiment Classification Task", "link": "https://link.springer.com/article/10.1007/s41060-025-00805-z", "details": "H Gautam, A Gaur, DK Yadav - International Journal of Data Science and Analytics, 2025", "abstract": "\u2026 Finally, Section 8 summarizes our findings and discusses potential future directions for sentiment analysis and **large** **language** **models**. \u2026 are essential for understanding downstream language tasks such as sentiment analysis, **question** \u2026"}, {"title": "From Chat Logs to Collective Insights: Aggregative Question Answering", "link": "https://arxiv.org/pdf/2505.23765", "details": "W Zhang, W Kim, Y Deng - arXiv preprint arXiv:2505.23765, 2025", "abstract": "\u2026 Potential Errors in Model-derived Annotations Although we employed powerful **large** **language** **models** and pipelines (such as GPT-4o and TnTLLM) to infer attributes and assign taxonomy labels, errors and inconsistencies may still occur \u2026", "entry_id": "http://arxiv.org/abs/2505.23765v1", "updated": "2025-05-29 17:59:55", "published": "2025-05-29 17:59:55", "authors": "Wentao Zhang;Woojeong Kim;Yuntian Deng", "summary": "Conversational agents powered by large language models (LLMs) are rapidly\nbecoming integral to our daily interactions, generating unprecedented amounts\nof conversational data. Such datasets offer a powerful lens into societal\ninterests, trending topics, and collective concerns. Yet, existing approaches\ntypically treat these interactions as independent and miss critical insights\nthat could emerge from aggregating and reasoning across large-scale\nconversation logs. In this paper, we introduce Aggregative Question Answering,\na novel task requiring models to reason explicitly over thousands of\nuser-chatbot interactions to answer aggregative queries, such as identifying\nemerging concerns among specific demographics. To enable research in this\ndirection, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative\nquestions derived from 182,330 real-world chatbot conversations. Experiments\nshow that existing methods either struggle to reason effectively or incur\nprohibitive computational costs, underscoring the need for new approaches\ncapable of extracting collective insights from large-scale conversational data.", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI;cs.LG", "links": "http://arxiv.org/abs/2505.23765v1;http://arxiv.org/pdf/2505.23765v1", "pdf_url": "http://arxiv.org/pdf/2505.23765v1"}, {"title": "Interventional Pain **Medicine**", "link": "https://www.researchgate.net/profile/Timothy-Olivier/publication/392159403_Assessing_ChatGPT_responses_to_patient_questions_on_epidural_steroid_injections_A_comparative_study_of_general_vs_specific_queries/links/6836fc54df0e3f544f5b82af/Assessing-ChatGPT-responses-to-patient-questions-on-epidural-steroid-injections-A-comparative-study-of-general-vs-specific-queries.pdf", "details": "T Olivier, Z Ma, A Patel, W Shi, M Murtuza, NE Hatchard\u2026", "abstract": "\u2026 integrated into **healthcare** , with **large** **language** **models** (LLMs) like ChatGPT being widely used by patients to **answer** **medical** **questions**. Given the \u2026 patient concerns, especially in procedural **medicine**. To date, no studies have specifically \u2026"}, {"title": "Evaluating the performance of artificial intelligence in summarizing pre-coded text to support evidence synthesis: a comparison between chatbots and humans", "link": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-025-02532-2", "details": "K Nordmann, S Sauter, M Stein, J Aigner, MC Redlich\u2026 - BMC **Medical** Research \u2026, 2025", "abstract": "\u2026 **large** **language** **models**. Secondly, caution is advised in generalising the findings of this study, as the text parts used for eliciting the **answers** were \u2026 As the underlying **large** **language** **models** of chatbots are quickly evolving, longitudinal \u2026"}, {"title": "Fine-grained entity disambiguation through numeric pattern awareness in transformer models", "link": "https://link.springer.com/article/10.1007/s40747-025-01936-3", "details": "J Jang, S Kim, H Moon, SH Shin, M Yun, C Wiseman - Complex & Intelligent Systems, 2025", "abstract": "\u2026 Knowledge base **question** **answering** systems rely on entity linking to connect textual mentions in natural language with corresponding \u2026 **medical** diagnostics, financial analysis, scientific research, autonomous systems, and numerical \u2026"}]
