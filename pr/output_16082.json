[{"title": "SmallPlan: Leverage Small Language Models for Sequential Path Planning with Simulation-Powered, LLM-Guided Distillation", "link": "https://arxiv.org/pdf/2505.00831", "details": "QPM Pham, KTN Nguyen, NH Doan, CA Pham, K Inui\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Efficient path planning in robotics, particularly within large-scale, dynamic environments, remains a significant hurdle. While Large Language Models (LLMs) offer strong reasoning capabilities, their high computational cost and limited \u2026"}, {"title": "Retrieval-augmented in-context learning for multimodal large language models in disease classification", "link": "https://arxiv.org/pdf/2505.02087", "details": "Z Zhan, S Zhou, X Zhou, Y Xiao, J Wang, J Deng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Objectives: We aim to dynamically retrieve informative demonstrations, enhancing in- context learning in multimodal large language models (MLLMs) for disease classification. Methods: We propose a Retrieval-Augmented In-Context Learning \u2026"}, {"title": "Role of Model Size and Prompting Strategies in Extracting Labels from Free-Text Radiology Reports with Open-Source Large Language Models", "link": "https://link.springer.com/article/10.1007/s10278-025-01505-7", "details": "B Khosravi, T Dapamede, F Li, Z Chisango, A Bikmal\u2026 - Journal of Imaging \u2026, 2025", "abstract": "Extracting accurate labels from radiology reports is essential for training medical image analysis models. Large language models (LLMs) show promise for automating this process. The purpose of this study is to evaluate how model size and \u2026"}]
