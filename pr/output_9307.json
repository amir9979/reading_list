[{"title": "Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising", "link": "https://arxiv.org/pdf/2411.03053%3F", "details": "T Huang, J Meng, H Chen, G Zheng, X Yang, X Yi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We investigate the construction of gradient-guided conditional diffusion models for reconstructing private images, focusing on the adversarial interplay between differential privacy noise and the denoising capabilities of diffusion models. While \u2026"}, {"title": "Interpretability as Approximation: Understanding Black-Box Models by Decision Boundary", "link": "https://www.mdpi.com/2079-9292/13/22/4339", "details": "H Dong, B Liu, D Ye, G Liu - Electronics, 2024", "abstract": "Currently, interpretability methods focus more on less objective human- understandable semantics. To objectify and standardize interpretability research, in this study, we provide notions of interpretability based on approximation theory. We \u2026"}, {"title": "Efficient Vision-Language pre-training via domain-specific learning for human activities", "link": "https://aclanthology.org/2024.emnlp-main.454.pdf", "details": "A Bulat, Y Ouali, R Guerrero, B Martinez\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Abstract Current Vision-Language (VL) models owe their success to large-scale pre- training on web-collected data, which in turn requires high-capacity architectures and large compute resources for training. We posit that when the downstream tasks are \u2026"}, {"title": "Enhancing Vision-Language Model Safety through Progressive Concept-Bottleneck-Driven Alignment", "link": "https://arxiv.org/pdf/2411.11543", "details": "Z Liu, Y Nie, Y Tan, X Yue, Q Cui, C Wang, X Zhu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Benefiting from the powerful capabilities of Large Language Models (LLMs), pre- trained visual encoder models connected to LLMs form Vision Language Models (VLMs). However, recent research shows that the visual modality in VLMs is highly \u2026"}, {"title": "Evolved Hierarchical Masking for Self-Supervised Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10742293/", "details": "Z Feng, S Zhang - IEEE Transactions on Pattern Analysis and Machine \u2026, 2024", "abstract": "Existing Masked Image Modeling methods apply fixed mask patterns to guide the self- supervised training. As those mask patterns resort to different criteria to depict image contents, sticking to a fixed pattern leads to a limited vision cues modeling capability \u2026"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://arxiv.org/pdf/2411.03313%3F", "details": "H Zilong, Y Qinghao, K Bingyi, F Jiashi, F Haoqi - arXiv preprint arXiv:2411.03313, 2024", "abstract": "We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised \u2026"}, {"title": "Joint Vision-Language Social Bias Removal for CLIP", "link": "https://arxiv.org/pdf/2411.12785", "details": "H Zhang, Y Guo, M Kankanhalli - arXiv preprint arXiv:2411.12785, 2024", "abstract": "Vision-Language (VL) pre-trained models such as CLIP show prominent capabilities in various downstream tasks. Despite this promise, VL models are notoriously limited by their inherent social biases. A typical demonstration is that VL models often \u2026"}, {"title": "Self-supervised learning for chest computed tomography: training strategies and effect on downstream applications", "link": "https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-11/issue-6/064003/Self-supervised-learning-for-chest-computed-tomography--training-strategies/10.1117/1.JMI.11.6.064003.short", "details": "A Tariq, G Ramasamy, B Patel, I Banerjee - Journal of Medical Imaging, 2024", "abstract": "Purpose Self-supervised pre-training can reduce the amount of labeled training data needed by pre-learning fundamental visual characteristics of the medical imaging data. We investigate several self-supervised training strategies for chest computed \u2026"}]
