'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Ehragent: Code empowers large language models for few-'
[{"title": "CroSSL: Cross-modal Self-Supervised Learning for Time-series through Latent Masking", "link": "https://dl.acm.org/doi/abs/10.1145/3616855.3635795", "details": "S Deldari, D Spathis, M Malekzadeh, F Kawsar\u2026 - Proceedings of the 17th \u2026, 2024", "abstract": "Limited availability of labeled data for machine learning on multimodal time-series extensively hampers progress in the field. Self-supervised learning (SSL) is a promising approach to learn data representations without relying on labels \u2026"}, {"title": "RelayAttention for Efficient Large Language Model Serving with Long System Prompts", "link": "https://arxiv.org/html/2402.14808v1", "details": "L Zhu, X Wang, W Zhang, RWH Lau - arXiv preprint arXiv:2402.14808, 2024", "abstract": "Practical large language model (LLM) services may involve a long system prompt, which specifies the instructions, examples, and knowledge documents of the task and is reused across numerous requests. However, the long system prompt causes \u2026"}, {"title": "Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity", "link": "https://arxiv.org/pdf/2402.13130", "details": "I Rep, D Duki\u0107, J \u0160najder - arXiv preprint arXiv:2402.13130, 2024", "abstract": "While BERT produces high-quality sentence embeddings, its pre-training computational cost is a significant drawback. In contrast, ELECTRA delivers a cost- effective pre-training objective and downstream task performance improvements, but \u2026"}, {"title": "Transformer-based Causal Language Models Perform Clustering", "link": "https://arxiv.org/pdf/2402.12151", "details": "X Wu, LR Varshney - arXiv preprint arXiv:2402.12151, 2024", "abstract": "Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still a concern. Recent works have shown great improvements \u2026"}, {"title": "AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning", "link": "https://arxiv.org/html/2403.09113v1", "details": "R Zhang, R Qiang, SA Somayajula, P Xie - arXiv preprint arXiv:2403.09113, 2024", "abstract": "Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient \u2026"}, {"title": "Interactive optimization of relation extraction via knowledge graph representation learning", "link": "https://link.springer.com/article/10.1007/s12650-024-00955-5", "details": "Y Liu, Y Ma, Y Zhang, R Yu, Z Zhang, Y Meng, Z Zhou - Journal of Visualization, 2024", "abstract": "Relation extraction is a vital task in constructing large-scale knowledge graphs, aiming to identify factual relations between entities from plain texts and generate triples. However, it is inevitable that a large amount of noise will be generated and \u2026"}, {"title": "ICON: Improving Inter-Report Consistency of Radiology Report Generation via Lesion-aware Mix-up Augmentation", "link": "https://arxiv.org/html/2402.12844v1", "details": "W Hou, Y Cheng, K Xu, Y Hu, W Li, J Liu - arXiv preprint arXiv:2402.12844, 2024", "abstract": "Previous research on radiology report generation has made significant progress in terms of increasing the clinical accuracy of generated reports. In this paper, we emphasize another crucial quality that it should possess, ie, inter-report consistency \u2026"}, {"title": "COPR: Continual Human Preference Learning via Optimal Policy Regularization", "link": "https://arxiv.org/html/2402.14228v1", "details": "H Zhang, L Gui, Y Lei, Y Zhai, Y Zhang, Y He, H Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reinforcement Learning from Human Feedback (RLHF) is commonly utilized to improve the alignment of Large Language Models (LLMs) with human preferences. Given the evolving nature of human preferences, continual alignment becomes more \u2026"}]
