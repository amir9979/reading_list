[{"title": "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models", "link": "https://arxiv.org/pdf/2410.12011", "details": "K Tatariya, V Araujo, T Bauwens, M de Lhoneux - arXiv preprint arXiv:2410.12011, 2024", "abstract": "Pixel-based language models have emerged as a compelling alternative to subword- based language modelling, particularly because they can represent virtually any script. PIXEL, a canonical example of such a model, is a vision transformer that has \u2026"}, {"title": "Tracing the Evolution of Information Transparency for OpenAI's GPT Models through a Biographical Approach", "link": "https://ojs.aaai.org/index.php/AIES/article/download/31757/33924", "details": "Z Xu, E Mustafaraj - Proceedings of the AAAI/ACM Conference on AI, Ethics \u2026, 2024", "abstract": "Abstract Information transparency, the open disclosure of information about models, is crucial for proactively evaluating the potential societal harm of large language models (LLMs) and developing effective risk mitigation measures. Adapting the \u2026"}, {"title": "Responsible AI in Open Ecosystems: Reconciling Innovation with Risk Assessment and Disclosure", "link": "https://arxiv.org/pdf/2409.19104", "details": "M Chakraborti, BJ Prestoza, N Vincent, S Frey - arXiv preprint arXiv:2409.19104, 2024", "abstract": "The rapid scaling of AI has spurred a growing emphasis on ethical considerations in both development and practice. This has led to the formulation of increasingly sophisticated model auditing and reporting requirements, as well as governance \u2026"}, {"title": "Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Generator-Validator Fine-tuning", "link": "https://arxiv.org/pdf/2410.12164", "details": "J Xing, Y He, M Zhou, H Dong, S Han, D Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this work, we propose Table-LLM-Specialist, or Table-Specialist for short, as a new self-trained fine-tuning paradigm specifically designed for table tasks. Our insight is that for each table task, there often exist two dual versions of the same task, one \u2026"}, {"title": "Multimodal Auto Validation For Self-Refinement in Web Agents", "link": "https://arxiv.org/pdf/2410.00689%3F", "details": "R Azam, T Abuelsaad, A Vempaty, A Jagmohan - arXiv preprint arXiv:2410.00689, 2024", "abstract": "As our world digitizes, web agents that can automate complex and monotonous tasks are becoming essential in streamlining workflows. This paper introduces an approach to improving web agent performance through multi-modal validation and \u2026"}, {"title": "Self-Data Distillation for Recovering Quality in Pruned Large Language Models", "link": "https://arxiv.org/pdf/2410.09982", "details": "V Thangarasa, G Venkatesh, N Sinnadurai, S Lie - arXiv preprint arXiv:2410.09982, 2024", "abstract": "Large language models have driven significant progress in natural language processing, but their deployment requires substantial compute and memory resources. As models scale, compression techniques become essential for \u2026"}, {"title": "Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs", "link": "https://arxiv.org/pdf/2410.10739", "details": "I Jindal, C Badrinath, P Bharti, L Vinay, SD Sharma - arXiv preprint arXiv:2410.10739, 2024", "abstract": "Large Language Models (LLMs) for public use require continuous pre-training to remain up-to-date with the latest data. The models also need to be fine-tuned with specific instructions to maintain their ability to follow instructions accurately. Typically \u2026"}, {"title": "Safety-Aware Fine-Tuning of Large Language Models", "link": "https://arxiv.org/pdf/2410.10014", "details": "HK Choi, X Du, Y Li - arXiv preprint arXiv:2410.10014, 2024", "abstract": "Fine-tuning Large Language Models (LLMs) has emerged as a common practice for tailoring models to individual needs and preferences. The choice of datasets for fine- tuning can be diverse, introducing safety concerns regarding the potential inclusion \u2026"}, {"title": "Negative-Prompt-driven Alignment for Generative Language Model", "link": "https://arxiv.org/pdf/2410.12194", "details": "S Qiao, N Xv, B Liu, X Geng - arXiv preprint arXiv:2410.12194, 2024", "abstract": "Large language models have achieved remarkable capabilities, but aligning their outputs with human values and preferences remains a significant challenge. Existing alignment methods primarily focus on positive examples while overlooking the \u2026"}]
