[{"title": "Mapping 1,000+ Language Models via the Log-Likelihood Vector", "link": "https://arxiv.org/pdf/2502.16173", "details": "M Oyama, H Yamagiwa, Y Takase, H Shimodaira - arXiv preprint arXiv:2502.16173, 2025", "abstract": "To compare autoregressive language models at scale, we propose using log- likelihood vectors computed on a predefined text set as model features. This approach has a solid theoretical basis: when treated as model coordinates, their \u2026"}, {"title": "CoT2Align: Cross-Chain of Thought Distillation via Optimal Transport Alignment for Language Models with Different Tokenizers", "link": "https://arxiv.org/pdf/2502.16806", "details": "AD Le, T Vu, NL Hai, NTN Diep, LN Van, T Le\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) achieve state-of-the-art performance across various NLP tasks but face deployment challenges due to high computational costs and memory constraints. Knowledge distillation (KD) is a promising solution, transferring \u2026"}, {"title": "Words or Vision: Do Vision-Language Models Have Blind Faith in Text?", "link": "https://arxiv.org/pdf/2503.02199", "details": "A Deng, T Cao, Z Chen, B Hooi - arXiv preprint arXiv:2503.02199, 2025", "abstract": "Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual \u2026"}, {"title": "PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14504", "details": "Y Meng, K Li, C Huang, C Gao, X Chen, Y Li, X Zhang - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across a range of multimodal tasks. However, their inference efficiency is constrained by the large number of visual tokens processed during decoding. To address this \u2026"}, {"title": "Big-Math: A Large-Scale, High-Quality Math Dataset for Reinforcement Learning in Language Models", "link": "https://arxiv.org/pdf/2502.17387", "details": "A Albalak, D Phung, N Lile, R Rafailov, K Gandhi\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Increasing interest in reasoning models has led math to become a prominent testing ground for algorithmic and methodological improvements. However, existing open math datasets either contain a small collection of high-quality, human-written \u2026"}, {"title": "Fine-grained knowledge fusion for retrieval-augmented medical visual question answering", "link": "https://www.sciencedirect.com/science/article/pii/S1566253525001320", "details": "X Liang, D Wang, B Jing, Z Jiao, R Li, R Liu, Q Miao\u2026 - Information Fusion, 2025", "abstract": "Given that medical image analysis often requires experts to recall typical symptoms from diagnostic archives or their own experience, implementing retrieval augmentation in multi-modal tasks like Medical Visual Question Answering \u2026"}, {"title": "LLM-Fusion: A Novel Multimodal Fusion Model for Accelerated Material Discovery", "link": "https://arxiv.org/pdf/2503.01022", "details": "O Boyar, I Priyadarsini, S Takeda, L Hamada - arXiv preprint arXiv:2503.01022, 2025", "abstract": "Discovering materials with desirable properties in an efficient way remains a significant problem in materials science. Many studies have tackled this problem by using different sets of information available about the materials. Among them \u2026"}, {"title": "Diffusion Models are Zero-Shot Generative Text-Vision Retrievers", "link": "https://ieeexplore.ieee.org/abstract/document/10888226/", "details": "B Li, Z Xie, X Zhang, X Zhu, Z Lei - ICASSP 2025-2025 IEEE International Conference \u2026, 2025", "abstract": "Large-scale text-to-image diffusion models have demonstrated impressive capabilities for downstream tasks by leveraging strong vision-language alignment from generative pre-training. Recently, a number of works have explored how to use \u2026"}, {"title": "Evaluating Generative AI Models for Image-Text Modification", "link": "https://ieeexplore.ieee.org/iel8/6287639/10820123/10909117.pdf", "details": "J Soni, H Upadhyay, PPA Victor, S Tripathi - IEEE Access, 2025", "abstract": "Diffusion-based Image Editing models that utilize text prompts and reference images were developed to mitigate the limitations of the text-based image generation models in retaining the generated image's structure. The domain oversaw the development \u2026"}]
