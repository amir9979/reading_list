[{"title": "Can Large Language Models beat wall street? Evaluating GPT-4's impact on financial decision-making with MarketSenseAI", "link": "https://link.springer.com/article/10.1007/s00521-024-10613-4", "details": "G Fatouros, K Metaxas, J Soldatos, D Kyriazis - Neural Computing and Applications, 2024", "abstract": "This paper introduces MarketSenseAI, an innovative framework leveraging GPT-4's advanced reasoning for selecting stocks in financial markets. By integrating Chain of Thought and In-Context Learning, MarketSenseAI analyzes diverse data sources \u2026"}, {"title": "Kernel-Aware Graph Prompt Learning for Few-Shot Anomaly Detection", "link": "https://arxiv.org/pdf/2412.17619", "details": "F Tao, GS Xie, F Zhao, X Shu - arXiv preprint arXiv:2412.17619, 2024", "abstract": "Few-shot anomaly detection (FSAD) aims to detect unseen anomaly regions with the guidance of very few normal support images from the same class. Existing FSAD methods usually find anomalies by directly designing complex text prompts to align \u2026"}, {"title": "ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models", "link": "https://arxiv.org/pdf/2412.12848", "details": "Y Sun, W Gao, J Ma, H Lin, Z Luo, W Zhang - arXiv preprint arXiv:2412.12848, 2024", "abstract": "With the rise and widespread use of Large Language Models (LLMs), ensuring their safety is crucial to prevent harm to humans and promote ethical behaviors. However, directly assessing value valence (ie, support or oppose) by leveraging large-scale \u2026"}, {"title": "Confidence in the Reasoning of Large Language Models", "link": "https://assets.pubpub.org/8ahvoupt/Pawitan%2520%26%2520Holmes%2520\\(2024\\)_Just%2520Accepted-21734387493774.pdf", "details": "Y Pawitan, C Holmes - arXiv preprint arXiv:2412.15296, 2024", "abstract": "There is a growing literature on reasoning by large language models (LLMs), but the discussion on the uncertainty in their responses is still lacking. Our aim is to assess the extent of confidence that LLMs have in their answers and how it correlates with \u2026"}, {"title": "Enhancing Multi-Step Mathematical Reasoning in Large Language Models with Step-by-Step Similarity Prompts and Answer Voting", "link": "http://poster-openaccess.com/files/ICIC2024/818.pdf", "details": "Q Ye, X Ji, RH Hou, JP Liu, T Ruan", "abstract": "Complex reasoning problems, especially multi-step mathematical reasoning problems, are a difficult class of NLP tasks to solve. Existing methods such as Manual-CoT improve the accuracy of reasoning tasks by manually designing \u2026"}]
