'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [HW-GPT-Bench: Hardware-Aware Architecture Benchmark fo'
[{"title": "Small Language Models Need Strong Verifiers to Self-Correct Reasoning", "link": "https://arxiv.org/pdf/2404.17140", "details": "Y Zhang, M Khalifa, L Logeswaran, J Kim, M Lee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether \u2026"}, {"title": "Continuous Predictive Modeling of Clinical Notes and ICD Codes in Patient Health Records", "link": "https://arxiv.org/pdf/2405.11622", "details": "MH Caralt, CBL Ng, M Rei - arXiv preprint arXiv:2405.11622, 2024", "abstract": "Electronic Health Records (EHR) serve as a valuable source of patient information, offering insights into medical histories, treatments, and outcomes. Previous research has developed systems for detecting applicable ICD codes that should be assigned \u2026"}, {"title": "Observational Scaling Laws and the Predictability of Language Model Performance", "link": "https://arxiv.org/pdf/2405.10938", "details": "Y Ruan, CJ Maddison, T Hashimoto - arXiv preprint arXiv:2405.10938, 2024", "abstract": "Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different \u2026"}, {"title": "BELIEVE: Belief-enhanced instruction generation and augmentation for zero-shot bias mitigation", "link": "https://www.amazon.science/publications/believe-belief-enhanced-instruction-generation-and-augmentation-for-zero-shot-bias-mitigation", "details": "L Bauer, N Mehrabi, P Goyal, KW Chang, A Galstyan\u2026 - 2024", "abstract": "Abstract Language models, pre-trained on large amounts of unmoderated content, have been shown to contain societal biases. Mitigating such biases typically requires access to model parameters and training schemas. In this work, we address bias \u2026"}, {"title": "DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for Unconventional Reasoning", "link": "https://arxiv.org/pdf/2405.11559", "details": "SV Mathur, AR Jindal, M Shrivastava - arXiv preprint arXiv:2405.11559, 2024", "abstract": "While significant work has been done in the field of NLP on vertical thinking, which involves primarily logical thinking, little work has been done towards lateral thinking, which involves looking at problems from an unconventional perspective and defying \u2026"}, {"title": "A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks", "link": "https://arxiv.org/pdf/2405.10251", "details": "X Ni, P Li - arXiv preprint arXiv:2405.10251, 2024", "abstract": "Recent efforts have evaluated large language models (LLMs) in areas such as commonsense reasoning, mathematical reasoning, and code generation. However, to the best of our knowledge, no work has specifically investigated the performance \u2026"}, {"title": "Generalization Measures for Zero-Shot Cross-Lingual Transfer", "link": "https://arxiv.org/pdf/2404.15928", "details": "S Bassi, D Ataman, K Cho - arXiv preprint arXiv:2404.15928, 2024", "abstract": "A model's capacity to generalize its knowledge to interpret unseen inputs with different characteristics is crucial to build robust and reliable machine learning systems. Language model evaluation tasks lack information metrics about model \u2026"}, {"title": "Human-Centered Evaluation and Auditing of Language Models", "link": "https://dl.acm.org/doi/abs/10.1145/3613905.3636302", "details": "Z Xiao, WH Deng, MS Lam, M Eslami, J Kim, M Lee\u2026 - Extended Abstracts of the \u2026, 2024", "abstract": "The recent advancements in Large Language Models (LLMs) have significantly impacted numerous, and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues \u2026"}, {"title": "Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation", "link": "https://arxiv.org/pdf/2405.12119", "details": "Z He, Z Xie, H Steck, D Liang, R Jha, N Kallus\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) are revolutionizing conversational recommender systems by adeptly indexing item content, understanding complex conversational contexts, and generating relevant item titles. However, controlling the distribution of \u2026"}]
