[{"title": "Vision-Language Models for Automated Chest X-ray Interpretation: Leveraging ViT and GPT-2", "link": "https://arxiv.org/pdf/2501.12356%3F", "details": "MR Islam, MZ Hossain, M Ahmed, M Samu, S Sultana - arXiv preprint arXiv \u2026, 2025", "abstract": "Radiology plays a pivotal role in modern medicine due to its non-invasive diagnostic capabilities. However, the manual generation of unstructured medical reports is time consuming and prone to errors. It creates a significant bottleneck in clinical \u2026"}, {"title": "ELAINE-medLLM: Lightweight English Japanese Chinese Trilingual Large Language Model for Bio-medical Domain", "link": "https://aclanthology.org/2025.coling-main.313.pdf", "details": "K Yano, Z Luo, J Huang, Q Xie, M Asada, C Yuan\u2026 - Proceedings of the 31st \u2026, 2025", "abstract": "Abstract We propose ELAINE (EngLish-jApanese-chINesE)-medLLM, a trilingual (English, Japanese, Chinese) large language model adapted for the bio-medical domain based on Llama-3-8B. The training dataset was carefully curated in terms of \u2026"}, {"title": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment", "link": "https://arxiv.org/pdf/2501.07525", "details": "D Gu, Y Gao, Y Zhou, M Zhou, D Metaxas - arXiv preprint arXiv:2501.07525, 2025", "abstract": "Automated chest radiographs interpretation requires both accurate disease classification and detailed radiology report generation, presenting a significant challenge in the clinical workflow. Current approaches either focus on classification \u2026"}, {"title": "Scaling Large Vision-Language Models for Enhanced Multimodal Comprehension In Biomedical Image Analysis", "link": "https://arxiv.org/pdf/2501.15370", "details": "R Umeike, N Getty, F Xia, R Stevens - arXiv preprint arXiv:2501.15370, 2025", "abstract": "Large language models (LLMs) have demonstrated immense capabilities in understanding textual data and are increasingly being adopted to help researchers accelerate scientific discovery through knowledge extraction (information retrieval) \u2026"}, {"title": "Bridging Contrastive Learning and Domain Adaptation: Theoretical Perspective and Practical Application", "link": "https://arxiv.org/pdf/2502.00052", "details": "GI Quintana, L Vancamberg, V Jugnon, A Desolneux\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "This work studies the relationship between Contrastive Learning and Domain Adaptation from a theoretical perspective. The two standard contrastive losses, NT- Xent loss (Self-supervised) and Supervised Contrastive loss, are related to the Class \u2026"}, {"title": "MedS $^ 3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking", "link": "https://arxiv.org/pdf/2501.12051%3F", "details": "S Jiang, Y Liao, Z Chen, Y Zhang, Y Wang, Y Wang - arXiv preprint arXiv:2501.12051, 2025", "abstract": "Medical language models (MLMs) have become pivotal in advancing medical natural language processing. However, prior models that rely on pre-training or supervised fine-tuning often exhibit low data efficiency and limited practicality in real \u2026"}, {"title": "Hierarchical Autoregressive Transformers: Combining Byte-and Word-Level Processing for Robust, Adaptable Language Models", "link": "https://arxiv.org/pdf/2501.10322", "details": "P Neitemeier, B Deiseroth, C Eichenberg, L Balles - arXiv preprint arXiv:2501.10322, 2025", "abstract": "Tokenization is a fundamental step in natural language processing, breaking text into units that computational models can process. While learned subword tokenizers have become the de-facto standard, they present challenges such as large \u2026"}, {"title": "How to Bridge the Gap between Modalities: Survey on Multimodal Large Language Model", "link": "https://ieeexplore.ieee.org/abstract/document/10841938/", "details": "S Song, X Li, S Li, S Zhao, J Yu, J Ma, X Mao, W Zhang\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "We explore Multimodal Large Language Models (MLLMs), which integrate LLMs like GPT-4 to handle multimodal data, including text, images, audio, and more. MLLMs demonstrate capabilities such as generating image captions and answering image \u2026"}, {"title": "Expanding the generality of neural fields", "link": "https://dr.ntu.edu.sg/bitstream/10356/182229/2/yslan-thesis-final-copy.pdf", "details": "Y Lan - 2025", "abstract": "Neural fields have emerged as a groundbreaking approach to representing 3D shapes, garnering significant attention due to their compatibility with modern deep- learning techniques. Neural fields, which parameterize physical properties of scenes \u2026"}]
