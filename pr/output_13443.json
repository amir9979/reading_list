[{"title": "Scaling Laws for Upcycling Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2502.03009", "details": "SP Liew, T Kato, S Takase - arXiv preprint arXiv:2502.03009, 2025", "abstract": "Pretraining large language models (LLMs) is resource-intensive, often requiring months of training time even with high-end GPU clusters. There are two approaches of mitigating such computational demands: reusing smaller models to train larger \u2026"}, {"title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models", "link": "https://arxiv.org/pdf/2502.03199%3F", "details": "J Wu, Y Shen, S Liu, Y Tang, S Song, X Wang, L Cai - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the \u2026"}, {"title": "scMamba: A Pre-Trained Model for Single-Nucleus RNA Sequencing Analysis in Neurodegenerative Disorders", "link": "https://arxiv.org/pdf/2502.19429", "details": "G Oh, B Choi, S Jin, I Jung, JC Ye - arXiv preprint arXiv:2502.19429, 2025", "abstract": "Single-nucleus RNA sequencing (snRNA-seq) has significantly advanced our understanding of the disease etiology of neurodegenerative disorders. However, the low quality of specimens derived from postmortem brain tissues, combined with the \u2026"}, {"title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization", "link": "https://arxiv.org/pdf/2502.04306%3F", "details": "Y Wang, L Yang, G Li, M Wang, B Aragam - arXiv preprint arXiv:2502.04306, 2025", "abstract": "Recent research has leveraged large language model multi-agent systems for complex problem-solving while trying to reduce the manual effort required to build them, driving the development of automated agent workflow optimization methods \u2026"}, {"title": "Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models", "link": "https://arxiv.org/pdf/2502.03715", "details": "R Cai, C Wang, Q Cai, D Shen, H Xiong - arXiv preprint arXiv:2502.03715, 2025", "abstract": "Knowledge Graph-based recommendations have gained significant attention due to their ability to leverage rich semantic relationships. However, constructing and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy of KGs \u2026"}, {"title": "Large Language Models as Attribution Regularizers for Efficient Model Training", "link": "https://arxiv.org/pdf/2502.20268", "details": "D Vukadin, M \u0160ili\u0107, G Dela\u010d - arXiv preprint arXiv:2502.20268, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains. However, effectively leveraging their vast knowledge for training smaller downstream models remains an open challenge, especially in domains like \u2026"}, {"title": "A Training Data Recipe to Accelerate A* Search with Large Language Models", "link": "http://www.boyangli.org/paper/Gupta-EMNLP-2024.pdf", "details": "D Gupta, B Li", "abstract": "Abstract Combining Large Language Models (LLMs) with heuristic search algorithms like A* holds the promise of enhanced LLM reasoning and scalable inference. To accelerate training and reduce computational demands, we investigate the coreset \u2026"}, {"title": "Smoothing Out Hallucinations: Mitigating LLM Hallucination with Smoothed Knowledge Distillation", "link": "https://arxiv.org/pdf/2502.11306", "details": "H Nguyen, Z He, SA Gandre, U Pasupulety\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) often suffer from hallucination, generating factually incorrect or ungrounded content, which limits their reliability in high-stakes applications. A key factor contributing to hallucination is the use of hard labels during \u2026"}, {"title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies", "link": "https://arxiv.org/pdf/2502.08554", "details": "SSY Kim, JW Vaughan, QV Liao, T Lombrozo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study \u2026"}]
