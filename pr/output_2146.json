[{"title": "Vitreous levels of pigment epithelium-derived factor and vascular endothelial growth factor in diabetic and non-diabetic retinopathy: associated factors and anatomical \u2026", "link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11106866/", "details": "R Al-Dwairi, T El-Elimat, A Aleshawi, A Al Sharie\u2026 - International Journal of \u2026, 2024", "abstract": "Background This study aims to investigate the factors affecting the vitreous levels of pigment epithelium-derived factor (PEDF) and vascular endothelial growth factor (VGEF) among patients with pars plana vitrectomy (PPV). Also, this study correlates \u2026"}, {"title": "Knowledge-grounded Adaptation Strategy for Vision-language Models: Building Unique Case-set for Screening Mammograms for Residents Training", "link": "https://arxiv.org/pdf/2405.19675", "details": "AU Khan, J Garrett, T Bradshaw, L Salkowski, JJ Jeong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "A visual-language model (VLM) pre-trained on natural images and text pairs poses a significant barrier when applied to medical contexts due to domain shift. Yet, adapting or fine-tuning these VLMs for medical use presents considerable hurdles \u2026"}, {"title": "X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions", "link": "https://arxiv.org/pdf/2405.19744", "details": "C Li, W Yang, J Zhang, J Lu, S Wang, C Zong - arXiv preprint arXiv:2405.19744, 2024", "abstract": "Large language models respond well in high-resource languages like English but struggle in low-resource languages. It may arise from the lack of high-quality instruction following data in these languages. Directly translating English samples \u2026"}, {"title": "Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training", "link": "https://arxiv.org/pdf/2405.19654", "details": "J Yang, B Su, WX Zhao, JR Wen - arXiv preprint arXiv:2405.19654, 2024", "abstract": "Medical vision-language pre-training methods mainly leverage the correspondence between paired medical images and radiological reports. Although multi-view spatial images and temporal sequences of image-report pairs are available in off-the-shelf \u2026"}, {"title": "On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts", "link": "https://www.researchgate.net/profile/Toluwani-Aremu/publication/377742905_On_the_Reliability_of_Large_Language_Models_to_Misinformed_and_Demographically-Informed_Prompts/links/6637d1ff7091b94e93f401f8/On-the-Reliability-of-Large-Language-Models-to-Misinformed-and-Demographically-Informed-Prompts.pdf", "details": "T Aremu, O Akinwehinmi, C Nwagu, SI Ahmed, R Orji\u2026 - 2024", "abstract": "We investigate and observe the behaviour and performance of Large Language Model (LLM)-backed chatbots in addressing misinformed prompts and questions with demographic information within the domains of Climate Change and Mental \u2026"}]
