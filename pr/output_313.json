'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Language Models for Text Classification: Is In-Context'
[{"title": "Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models", "link": "https://arxiv.org/pdf/2403.08281", "details": "N Ding, Y Chen, G Cui, X Lv, R Xie, B Zhou, Z Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three \u2026"}, {"title": "Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation", "link": "https://arxiv.org/pdf/2403.07860", "details": "S Zhao, S Hao, B Zi, H Xu, KYK Wong - arXiv preprint arXiv:2403.07860, 2024", "abstract": "Text-to-image generation has made significant advancements with the introduction of text-to-image diffusion models. These models typically consist of a language model that interprets user prompts and a vision model that generates corresponding \u2026"}, {"title": "LCD Benchmark: Long Clinical Document Benchmark on Mortality Prediction", "link": "https://www.medrxiv.org/content/medrxiv/early/2024/03/27/2024.03.26.24304920.full.pdf", "details": "WJ Yoon, S Chen, Y Gao, D Dligach, DS Bitterman\u2026 - medRxiv, 2024", "abstract": "Natural Language Processing (NLP) is a study of automated processing of text data. Application of NLP in the clinical domain is important due to the rich unstructured information implanted in clinical documents, which often remains inaccessible in \u2026"}, {"title": "DINGO: Towards Diverse and Fine-Grained Instruction-Following Evaluation", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29768/31322", "details": "Z Gu, X Sun, F Lian, Z Kang, C Xu, J Fan - Proceedings of the AAAI Conference on \u2026, 2024", "abstract": "Instruction-following is particularly crucial for large language models (LLMs) to support diverse user requests. While existing work has made progress in aligning LLMs with human preferences, evaluating their capabilities on instruction-following \u2026"}, {"title": "Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models", "link": "https://arxiv.org/html/2402.18154v1", "details": "Z Jin, P Cao, H Yuan, Y Chen, J Xu, H Li, X Jiang, K Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external \u2026"}, {"title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models", "link": "https://arxiv.org/html/2402.19427v1", "details": "S De, SL Smith, A Fernando, A Botev\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated \u2026"}, {"title": "How does Architecture Influence the Base Capabilities of Pre-trained Language Models? A Case Study Based on FFN-Wider Transformer Models", "link": "https://arxiv.org/pdf/2403.02436", "details": "X Lu, Y Zhao, B Qin - arXiv preprint arXiv:2403.02436, 2024", "abstract": "Pre-trained language models have been proven to possess strong base capabilities, which not only excel in in-distribution language modeling but also show powerful abilities in out-of-distribution language modeling, transfer learning and few-shot \u2026"}, {"title": "Few-Shot Recalibration of Language Models", "link": "https://arxiv.org/pdf/2403.18286", "details": "XL Li, U Khandelwal, K Guu - arXiv preprint arXiv:2403.18286, 2024", "abstract": "Recent work has uncovered promising ways to extract well-calibrated confidence estimates from language models (LMs), where the model's confidence score reflects how likely it is to be correct. However, while LMs may appear well-calibrated over \u2026"}, {"title": "Language models scale reliably with over-training and on downstream tasks", "link": "https://arxiv.org/pdf/2403.08540", "details": "SY Gadre, G Smyrnis, V Shankar, S Gururangan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Scaling laws are useful guides for developing language models, but there are still gaps between current scaling studies and how language models are ultimately trained and evaluated. For instance, scaling is usually studied in the compute \u2026"}]
