[{"title": "Clinical decision support using **large language models** in otolaryngology: a systematic review", "link": "https://link.springer.com/article/10.1007/s00405-025-09504-8", "details": "R Filali Ansary, JR Lechien - European Archives of Oto-Rhino-Laryngology, 2025", "abstract": "\u2026 This systematic review **evaluated** the diagnostic accuracy of **large** **language** **models** (LLMs) \u2026 **Large** **language** **models** (LLMs) are increasingly used in medicine and surgery as adjunctive \u2026 This systematic review **evaluated** the diagnostic \u2026"}, {"title": "Can **Large Language Models** Verify System Software? A Case Study Using FSCQ as a Benchmark", "link": "https://dl.acm.org/doi/pdf/10.1145/3713082.3730382", "details": "J Qin, A Du, D Zhang, M Lentz, D Zhuo - Proceedings of the 2025 Workshop on Hot \u2026, 2025", "abstract": "\u2026 The advent of **large** **language** **models** (LLMs) has opened new possibilities, achieving state-of-the-art performance in various code \u2026 **evaluate** Gemini 1.5 Pro with both a 1M-token context window and a truncated 128k-token context window \u2026"}, {"title": "Financial Inclusion with **Large Language Models** : Prompt Design and **Evaluation** for Easy Japanese Generation", "link": "https://link.springer.com/chapter/10.1007/978-981-96-7071-0_17", "details": "M Yagi, S Woo, Y Zhang, H Takahashi - JSAI International Symposium on Artificial \u2026, 2025", "abstract": "\u2026 examines using **large** **language** **models** (LLMs) to generate Easy Japanese for financial literacy education and proposes a reference-free **evaluation** framework. The study assesses the effectiveness of LLMs through manual, automated, and \u2026"}, {"title": "Lean copilot: **Large language models** as copilots for theorem proving in lean", "link": "https://neus-2025.github.io/files/papers/paper_33.pdf", "details": "P Song, K Yang, A Anandkumar - Preprint, 2025", "abstract": "\u2026 Neural theorem proving combines **large** **language** **models** (LLMs) with proof assistants such as Lean, where the correctness of formal proofs \u2026 We **evaluate** on all 168 theorems in the book that have a tactic-style proof. Their proofs have 5.85 \u2026"}, {"title": "AIHeurEval: Generating Heuristic **Evaluations** on Multiple UI Screens with Multimodal **Large Language Models**", "link": "https://link.springer.com/chapter/10.1007/978-3-031-94168-9_22", "details": "Y Wang, F Xhakaj - International Conference on Human-Computer \u2026, 2025", "abstract": "\u2026 User interface (UI) design often requires many rounds of feedback from heuristic **evaluations** by human experts, which is \u2026 using **large** **language** **models** (LLMs) to automate UI design; however, existing works only diagnose a singular UI screen at a \u2026"}, {"title": "Enhancing Jailbreak Resistance in **Large Language Models** Using Model Merge", "link": "https://www.computer.org/csdl/proceedings-article/spw/2025/664300a111/27k6omz1ZzG", "details": "S Hiromi, H Kinoshita, M Yamada, T Miura - 2025 IEEE Security and Privacy \u2026, 2025", "abstract": "\u2026 In the next section, we **evaluate** theeffectiveness of the \u2026 **evaluation** focuses on jailbreak attack resistance andfollows three main steps:1) Create a security-specialized model using a jailbreakdataset.2) Merge the resulting specialized model with an \u2026"}, {"title": "Using **large language models** to extract plant functional traits from unstructured text", "link": "https://bsapubs.onlinelibrary.wiley.com/doi/pdf/10.1002/aps3.70011", "details": "V Domazetoski, H Kreft, H Bestova, P Wieder\u2026 - Applications in Plant \u2026, 2025", "abstract": "\u2026 Annotated Python code for preprocessing of the data; training and **evaluation** of the keyword search, logistic regression, and **large** **language** **models** ; and trait extraction with the trained models is available on GitHub (https://github.com/ViktorDomazetoski/NLP-PlantTraits) \u2026"}, {"title": "Can Uncertainty Metrics Guide Search? **Evaluating** Search-Time Decision-Making in **Large Language Models**", "link": "https://www.preprints.org/frontend/manuscript/cfa1128dc674d33c6255127248a5c4f3/download_pub", "details": "PF Guo, YD Tsai, SD Lin - 2025", "abstract": "Sampling-based search methods for **Large** **Language** **Models** (LLMs), such as Chain of Thought (CoT) and Tree of Thought (ToT), improve accuracy by exploring multiple reasoning paths. These approaches can be enhanced by search algorithms \u2026"}, {"title": "Exploring Prompt Patterns for Effective Vulnerability Repair in Real-World Code by **Large Language Models**", "link": "https://dl.acm.org/doi/abs/10.1145/3716815.3729010", "details": "Y Luo, B Li, A Singhal, P Tseng, L Zhang, Q Zou, X Sun\u2026 - Proceedings of the 2025 \u2026, 2025", "abstract": "\u2026 To answer RQ1, we **evaluated** LLMs using vulnerable code samples from three large datasets [3, 7, 13], and all these samples were contained within single files. As shown in Table 1, of these samples, 2749 samples has fewer than 40 lines, 1286 \u2026"}]
