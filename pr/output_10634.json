[{"title": "DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings", "link": "https://arxiv.org/pdf/2411.16236", "details": "H Liu, Y Lu - arXiv preprint arXiv:2411.16236, 2024", "abstract": "This paper presents a novel method to improve the robustness of foundation models to group-based biases. We propose a simple yet effective method, called DoubleCCA, that leverages random sentences and Canonical Correlation Analysis \u2026"}, {"title": "DataSculpt: Cost-Efficient Label Function Design via Prompting Large Language Models", "link": "https://openproceedings.org/2025/conf/edbt/paper-73.pdf", "details": "N Guan, K Chen, N Koudas - 2025", "abstract": "Programmatic weak supervision methodologies expedite the labeling of extensive datasets using label functions (LFs) that encapsulate heuristic data sources. Nonetheless, the creation of precise LFs necessitates domain expertise and \u2026"}, {"title": "Autonomous medical evaluation for guideline adherence of large language models", "link": "https://www.nature.com/articles/s41746-024-01356-6", "details": "D Fast, LC Adams, F Busch, C Fallon, M Huppertz\u2026 - npj Digital Medicine, 2024", "abstract": "Abstract Autonomous Medical Evaluation for Guideline Adherence (AMEGA) is a comprehensive benchmark designed to evaluate large language models' adherence to medical guidelines across 20 diagnostic scenarios spanning 13 specialties. It \u2026"}, {"title": "POINTS1. 5: Building a Vision-Language Model towards Real World Applications", "link": "https://arxiv.org/pdf/2412.08443", "details": "Y Liu, L Tian, X Zhou, X Gao, K Yu, Y Yu, J Zhou - arXiv preprint arXiv:2412.08443, 2024", "abstract": "Vision-language models have made significant strides recently, demonstrating superior performance across a range of tasks, eg optical character recognition and complex diagram analysis. Building on this trend, we introduce a new vision \u2026"}]
