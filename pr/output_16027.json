[{"title": "PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models", "link": "https://arxiv.org/pdf/2504.08966", "details": "M Dhouib, D Buscaldi, S Vanier, A Shabou - arXiv preprint arXiv:2504.08966, 2025", "abstract": "Visual Language Models require substantial computational resources for inference due to the additional input tokens needed to represent visual information. However, these visual tokens often contain redundant and unimportant information, resulting in \u2026"}, {"title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning", "link": "https://arxiv.org/pdf/2504.05632", "details": "S Kabra, A Jha, C Reddy - arXiv preprint arXiv:2504.05632, 2025", "abstract": "Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate \u2026"}, {"title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data", "link": "https://arxiv.org/pdf/2504.09967", "details": "X Zhu, F Mo, Z Zhang, J Wang, Y Shi, M Wu, C Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The emergence of medical generalist foundation models has revolutionized conventional task-specific model development paradigms, aiming to better handle multiple tasks through joint training on large-scale medical datasets. However, recent \u2026"}, {"title": "Minimal Data Maximum Impact: Lessons Learned from Real-World Unstructured Data in Paediatric Care", "link": "https://raw.githubusercontent.com/mlresearch/v281/main/assets/kawatra25a/kawatra25a.pdf", "details": "JS Kawatra, S Sabu, P Rajendran, C Baumgartner\u2026 - AAAI Bridge Program on AI \u2026, 2025", "abstract": "Digital health records contains significant volume of pertinent, routine information locked within unstructured texts. Current processes requires costly human annotation from a limited number of expert annotators with sufficient domain knowledge and \u2026"}, {"title": "RadRevise: A Benchmark Dataset for Instruction-Based Radiology Report Editing", "link": "https://raw.githubusercontent.com/mlresearch/v281/main/assets/huang25a/huang25a.pdf", "details": "Y Huang, JN Acosta, P Rajpurkar - AAAI Bridge Program on AI for Medicine and \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) can assist radiologists by making precise edits to radiology reports based on human instructions. However, evaluating the quality of such modifications has been challenging due to the lack of publicly \u2026"}, {"title": "Parameter-efficient fine-tuning in large language models: a survey of methodologies", "link": "https://link.springer.com/article/10.1007/s10462-025-11236-4", "details": "L Wang, S Chen, L Jiang, S Pan, R Cai, S Yang\u2026 - Artificial Intelligence Review, 2025", "abstract": "The large language models, as predicted by scaling law forecasts, have made groundbreaking progress in many fields, particularly in natural language generation tasks, where they have approached or even surpassed human levels. However, the \u2026"}, {"title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions", "link": "https://arxiv.org/pdf/2504.05571", "details": "O Ovadia, M Brief, R Lemberg, E Sheetrit - arXiv preprint arXiv:2504.05571, 2025", "abstract": "While Large Language Models (LLMs) acquire vast knowledge during pre-training, they often lack domain-specific, new, or niche information. Continual pre-training (CPT) attempts to address this gap but suffers from catastrophic forgetting and \u2026"}, {"title": "How Can Objects Help Video-Language Understanding?", "link": "https://arxiv.org/pdf/2504.07454%3F", "details": "Z Tang, S Wang, J Cho, J Yoo, C Sun - arXiv preprint arXiv:2504.07454, 2025", "abstract": "How multimodal large language models (MLLMs) perceive the visual world remains a mystery. To one extreme, object and relation modeling may be implicitly implemented with inductive biases, for example by treating objects as tokens. To the \u2026"}, {"title": "Efficient Tuning of Large Language Models for Knowledge-Grounded Dialogue Generation", "link": "https://arxiv.org/pdf/2504.07754%3F", "details": "B Zhang, H Ma, D Li, J Ding, J Wang, B Xu, HF Lin - arXiv preprint arXiv:2504.07754, 2025", "abstract": "Large language models (LLMs) demonstrate remarkable text comprehension and generation capabilities but often lack the ability to utilize up-to-date or domain- specific knowledge not included in their training data. To address this gap, we \u2026"}]
