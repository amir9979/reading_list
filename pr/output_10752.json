[{"title": "MetaRuleGPT: Recursive Numerical Reasoning of Language Models Trained with Simple Rules", "link": "https://arxiv.org/pdf/2412.13536", "details": "K Chen, L Wang, Q Zhang, R Xu - arXiv preprint arXiv:2412.13536, 2024", "abstract": "Recent studies have highlighted the limitations of large language models in mathematical reasoning, particularly their inability to capture the underlying logic. Inspired by meta-learning, we propose that models should acquire not only task \u2026"}, {"title": "HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models", "link": "https://arxiv.org/pdf/2412.08378", "details": "S Zhu, W Dong, J Song, Y Guo, B Zheng - arXiv preprint arXiv:2412.08378, 2024", "abstract": "Recently, there has been growing interest in the capability of multimodal large language models (MLLMs) to process high-resolution images. A common approach currently involves dynamically cropping the original high-resolution image into \u2026"}, {"title": "Heuristic-Induced Multimodal Risk Distribution Jailbreak Attack for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2412.05934", "details": "M Teng, J Xiaojun, D Ranjie, L Xinfeng, H Yihao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the rapid advancement of multimodal large language models (MLLMs), concerns regarding their security have increasingly captured the attention of both academia and industry. Although MLLMs are vulnerable to jailbreak attacks \u2026"}, {"title": "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces", "link": "https://arxiv.org/pdf/2412.14171%3F", "details": "J Yang, S Yang, AW Gupta, R Han, L Fei-Fei, S Xie - arXiv preprint arXiv:2412.14171, 2024", "abstract": "Humans possess the visual-spatial intelligence to remember spaces from sequential visual observations. However, can Multimodal Large Language Models (MLLMs) trained on million-scale video datasets also``think in space''from videos? We present \u2026"}, {"title": "Smoothed Embeddings for Robust Language Models", "link": "https://www.merl.com/publications/docs/TR2024-170.pdf", "details": "H Ryo, MRU Rashid, A Lewis, J Liu, T Koike-Akino\u2026", "abstract": "Improving the safety and reliability of large language models (LLMs) is a crucial aspect of realizing trustworthy AI systems. Although alignment methods aim to suppress harmful content generation, LLMs are often still vulnerable to jail-breaking \u2026"}, {"title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models", "link": "https://arxiv.org/pdf/2412.15287", "details": "Y Chow, G Tennenholtz, I Gur, V Zhuang, B Dai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent studies have indicated that effectively utilizing inference-time compute is crucial for attaining better performance from large language models (LLMs). In this work, we propose a novel inference-aware fine-tuning paradigm, in which the model \u2026"}, {"title": "OG-RAG: Ontology-Grounded Retrieval-Augmented Generation For Large Language Models", "link": "https://arxiv.org/pdf/2412.15235", "details": "K Sharma, P Kumar, Y Li - arXiv preprint arXiv:2412.15235, 2024", "abstract": "This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented Generation method designed to enhance LLM-generated responses by anchoring retrieval processes in domain-specific ontologies. While LLMs are widely used for \u2026"}, {"title": "CareBot: A Pioneering Full-Process Open-Source Medical Language Model", "link": "https://arxiv.org/pdf/2412.15236", "details": "L Zhao, W Zeng, X Shi, H Zhou - arXiv preprint arXiv:2412.15236, 2024", "abstract": "Recently, both closed-source LLMs and open-source communities have made significant strides, outperforming humans in various general domains. However, their performance in specific professional domains such as medicine, especially within the \u2026"}, {"title": "UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models", "link": "https://arxiv.org/pdf/2412.11803", "details": "B Xue, F Mi, Q Zhu, H Wang, R Wang, S Wang, E Yu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' \u2026"}]
