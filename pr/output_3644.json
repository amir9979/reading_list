[{"title": "AutoRAG: grounding text and symbols", "link": "https://link.springer.com/article/10.1007/s13218-024-00850-z", "details": "T Schulz, M Luttermann, R M\u00f6ller - KI-K\u00fcnstliche Intelligenz, 2024", "abstract": "In safety critical domains such as the healthcare domain, systems for natural language question answering demand special correctness guarantees. Modeling problem domains formally allows for automatic transparent reasoning, but handling \u2026"}, {"title": "Diverse and Fine-Grained Instruction-Following Ability Exploration with Synthetic Data", "link": "https://arxiv.org/pdf/2407.03942", "details": "Z Gu, X Sun, F Lian, Z Kang, CZ Xu, J Fan - arXiv preprint arXiv:2407.03942, 2024", "abstract": "Instruction-following is particularly crucial for large language models (LLMs) to support diverse user requests. While existing work has made progress in aligning LLMs with human preferences, evaluating their capabilities on instruction following \u2026"}, {"title": "RegMix: Data Mixture as Regression for Language Model Pre-training", "link": "https://arxiv.org/pdf/2407.01492", "details": "Q Liu, X Zheng, N Muennighoff, G Zeng, L Dou, T Pang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The data mixture for large language model pre-training significantly impacts performance, yet how to determine an effective mixture remains unclear. We propose RegMix to automatically identify a high-performing data mixture by formulating it as a \u2026"}, {"title": "Out-Of-Context Prompting Boosts Fairness and Robustness in Large Language Model Predictions", "link": "https://arxiv.org/pdf/2406.07685", "details": "L Cotta, CJ Maddison - arXiv preprint arXiv:2406.07685, 2024", "abstract": "Frontier Large Language Models (LLMs) are increasingly being deployed for high- stakes decision-making. On the other hand, these models are still consistently making predictions that contradict users' or society's expectations, eg, hallucinating \u2026"}]
