[{"title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models", "link": "https://arxiv.org/pdf/2408.15313", "details": "W Zhang, PHS Torr, M Elhoseiny, A Bibi - arXiv preprint arXiv:2408.15313, 2024", "abstract": "Fine-tuning large language models (LLMs) on human preferences, typically through reinforcement learning from human feedback (RLHF), has proven successful in enhancing their capabilities. However, ensuring the safety of LLMs during the fine \u2026"}, {"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "Great Memory, Shallow Reasoning: Limits of $ k $ NN-LMs", "link": "https://arxiv.org/pdf/2408.11815", "details": "S Geng, W Zhao, AM Rush - arXiv preprint arXiv:2408.11815, 2024", "abstract": "$ K $-nearest neighbor language models ($ k $ NN-LMs), which integrate retrieval with next-word prediction, have demonstrated strong performance in language modeling as well as downstream NLP benchmarks. These results have led \u2026"}, {"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task Specific Expert Pruning", "link": "https://arxiv.org/pdf/2409.01483", "details": "S Sarkar, L Lausen, V Cevher, S Zha, T Brox, G Karypis - arXiv preprint arXiv \u2026, 2024", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative to dense models in language modeling. These models use conditionally activated feedforward subnetworks in transformer blocks, allowing for a separation between \u2026"}, {"title": "LLMs in Production", "link": "https://link.springer.com/content/pdf/10.1007/978-3-031-65647-7_8.pdf", "details": "U Kamath, K Keenan, G Somers, S Sorenson - Large Language Models: A Deep Dive \u2026, 2024", "abstract": "The promise of LLMs has largely been driven through research efforts, where analytic performance is often prioritized over other practical aspects of their usage. Translating this promise into real-world production-grade applications is rapidly \u2026"}, {"title": "Pushing the Limits of Vision-Language Models in Remote Sensing without Human Annotations", "link": "https://arxiv.org/pdf/2409.07048", "details": "K Cha, D Yu, J Seo - arXiv preprint arXiv:2409.07048, 2024", "abstract": "The prominence of generalized foundation models in vision-language integration has witnessed a surge, given their multifarious applications. Within the natural domain, the procurement of vision-language datasets to construct these foundation \u2026"}, {"title": "Selecting from Multiple Strategies Improves the Foreseeable Reasoning of Tool-Augmented Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-3-031-70352-2_12", "details": "Y Wu, A Henriksson - Joint European Conference on Machine Learning and \u2026, 2024", "abstract": "Large language models (LLMs) can be augmented by interacting with external tools and knowledge bases, allowing them to overcome some of their known limitations, such as not having access to up-to-date information or struggling to solve math \u2026"}, {"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}]
