[{"title": "Measuring AI Ability to Complete Long Tasks", "link": "https://arxiv.org/pdf/2503.14499%3F", "details": "T Kwa, B West, J Becker, A Deng, K Garcia, M Hasin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of AI systems in terms of human capabilities, we propose a new metric: 50%-task-completion time horizon \u2026"}, {"title": "DNA Bench: When Silence is Smarter--Benchmarking Over-Reasoning in Reasoning LLMs", "link": "https://arxiv.org/pdf/2503.15793%3F", "details": "M Hashemi, O Bamgbose, ST Madhusudhan, JS Nair\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Test-time scaling has significantly improved large language model performance, enabling deeper reasoning to solve complex problems. However, this increased reasoning capability also leads to excessive token generation and unnecessary \u2026"}, {"title": "HCAST: Human-Calibrated Autonomy Software Tasks", "link": "https://arxiv.org/pdf/2503.17354", "details": "D Rein, J Becker, A Deng, S Nix, C Canal, D O'Connel\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "To understand and predict the societal impacts of highly autonomous AI systems, we need benchmarks with grounding, ie, metrics that directly connect AI performance to real-world effects we care about. We present HCAST (Human-Calibrated Autonomy \u2026"}, {"title": "Neuronal Activation States as Sample Embeddings for Data Selection in Task-Specific Instruction Tuning", "link": "https://arxiv.org/pdf/2503.15573%3F", "details": "D Ma, G Shang, Z Chen, L Qin, Y Luo, L Pan, S Fan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Task-specific instruction tuning enhances the performance of large language models (LLMs) on specialized tasks, yet efficiently selecting relevant data for this purpose remains a challenge. Inspired by neural coactivation in the human brain, we propose \u2026"}, {"title": "Uncertainty Quantification and Confidence Calibration in Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2503.15850", "details": "X Liu, T Chen, L Da, C Chen, Z Lin, H Wei - arXiv preprint arXiv:2503.15850, 2025", "abstract": "Large Language Models (LLMs) excel in text generation, reasoning, and decision- making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce \u2026"}, {"title": "FLUE: Streamlined Uncertainty Estimation for Large Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/33840/35995", "details": "S Gao, T Gong, Z Lin, R Xu, H Zhou, J Li - Proceedings of the AAAI Conference on \u2026, 2025", "abstract": "Uncertainty estimation is essential for practical applications such as decision- making, risk assessment, and human-AI collaboration. However, Uncertainty estimation in open-ended question-answering (QA) tasks presents unique \u2026"}, {"title": "HERA: Hybrid Edge-cloud Resource Allocation for Cost-Efficient AI Agents", "link": "https://arxiv.org/pdf/2504.00434", "details": "S Liu, H Shen, S Che, M Ghandi, M Li - arXiv preprint arXiv:2504.00434, 2025", "abstract": "In the realm of AI, large language models (LLMs) like GPT-4, central to the operation of AI agents, predominantly operate in the cloud, incurring high operational costs. With local-based small language models (SLMs) becoming more accurate, the \u2026"}, {"title": "Efficient Inference for Large Reasoning Models: A Survey", "link": "https://arxiv.org/pdf/2503.23077", "details": "Y Liu, J Wu, Y He, H Gao, H Chen, B Bi, J Zhang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Reasoning Models (LRMs) significantly improve the reasoning ability of Large Language Models (LLMs) by learning to reason, exhibiting promising performance in complex task-solving. However, their deliberative reasoning process leads to \u2026"}, {"title": "ScriptSmith: A Unified LLM Framework for Enhancing IT Operations via Automated Bash Script Generation, Assessment, and Refinement", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/35147/37302", "details": "P Aggarwal, O Chatterjee, T Dai, S Samanta\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "In the rapidly evolving landscape of site reliability engineering (SRE), the demand for efficient and effective solutions to manage and resolve issues in site and cloud applications is paramount. This paper presents an innovative approach to action \u2026"}]
