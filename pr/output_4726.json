[{"title": "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models", "link": "https://arxiv.org/pdf/2407.21417", "details": "Z Wu, Y Zhang, P Qi, Y Xu, R Han, Y Zhang, J Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Modern language models (LMs) need to follow human instructions while being faithful; yet, they often fail to achieve both. Here, we provide concrete evidence of a trade-off between instruction following (ie, follow open-ended instructions) and \u2026"}, {"title": "Compact Language Models via Pruning and Knowledge Distillation", "link": "https://arxiv.org/pdf/2407.14679", "details": "S Muralidharan, ST Sreenivas, R Joshi, M Chochowski\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) targeting different deployment scales and sizes are currently produced by training each variant from scratch; this is extremely compute- intensive. In this paper, we investigate if pruning an existing LLM and then re-training \u2026"}, {"title": "Understanding the Interplay of Scale, Data, and Bias in Language Models: A Case Study with BERT", "link": "https://arxiv.org/pdf/2407.21058", "details": "M Ali, S Panda, Q Shen, M Wick, A Kobren - arXiv preprint arXiv:2407.21058, 2024", "abstract": "In the current landscape of language model research, larger models, larger datasets and more compute seems to be the only way to advance towards intelligence. While there have been extensive studies of scaling laws and models' scaling behaviors, the \u2026"}, {"title": "Multi-Object Hallucination in Vision-Language Models", "link": "https://arxiv.org/pdf/2407.06192", "details": "X Chen, Z Ma, X Zhang, S Xu, S Qian, J Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large vision language models (LVLMs) often suffer from object hallucination, producing objects not present in the given images. While current benchmarks for object hallucination primarily concentrate on the presence of a single object class \u2026"}, {"title": "Generative Retrieval with Few-shot Indexing", "link": "https://chuanmeng.github.io/files/papers/fewshotgr.pdf", "details": "A Askari, C Meng, M Aliannejadi, Z Ren, E Kanoulas\u2026", "abstract": "Existing generative retrieval (GR) approaches rely on training-based indexing, ie, finetuning a model to memorise the associations between a query and the document identifier (docid) of a relevant document. Training-based indexing has three \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}, {"title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "link": "https://arxiv.org/pdf/2407.16667", "details": "H Xu, W Zhang, Z Wang, F Xiao, R Zheng, Y Feng, Z Ba\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, advanced Large Language Models (LLMs) such as GPT-4 have been integrated into many real-world applications like Code Copilot. These applications have significantly expanded the attack surface of LLMs, exposing them to a variety of \u2026"}, {"title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models", "link": "https://arxiv.org/pdf/2407.10873", "details": "R Zhang, F Liu, X Lin, Z Wang, Z Lu, Q Zhang - arXiv preprint arXiv:2407.10873, 2024", "abstract": "Automated heuristic design (AHD) has gained considerable attention for its potential to automate the development of effective heuristics. The recent advent of large language models (LLMs) has paved a new avenue for AHD, with initial efforts \u2026"}, {"title": "Evaluating Large Language Models with fmeval", "link": "https://arxiv.org/pdf/2407.12872", "details": "P Schw\u00f6bel, L Franceschi, MB Zafar, K Vasist\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "fmeval is an open source library to evaluate large language models (LLMs) in a range of tasks. It helps practitioners evaluate their model for task performance and along multiple responsible AI dimensions. This paper presents the library and \u2026"}]
