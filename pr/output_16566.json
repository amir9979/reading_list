[{"title": "Guiding Medical Vision-Language Models with Diverse Visual Prompts: Framework Design and Comprehensive Exploration of Prompt Variations", "link": "https://aclanthology.org/2025.naacl-long.587.pdf", "details": "K Zhu, Z Qin, H Yi, Z Jiang, Q Lao, S Zhang, K Li - \u2026 of the 2025 Conference of the \u2026, 2025", "abstract": "While mainstream vision-language models (VLMs) have advanced rapidly in understanding image-level information, they still lack the ability to focus on specific areas designated by humans. Rather, they typically rely on large volumes of high \u2026"}, {"title": "GroundCocoa: A Benchmark for Evaluating Compositional & Conditional Reasoning in Language Models", "link": "https://aclanthology.org/2025.naacl-long.420.pdf", "details": "H Kohli, S Kumar, H Sun - Proceedings of the 2025 Conference of the Nations of \u2026, 2025", "abstract": "The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their reasoning to \u2026"}, {"title": "Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math", "link": "https://arxiv.org/pdf/2504.21233", "details": "H Xu, B Peng, H Awadalla, D Chen, YC Chen, M Gao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Chain-of-Thought (CoT) significantly enhances formal reasoning capabilities in Large Language Models (LLMs) by training them to explicitly generate intermediate reasoning steps. While LLMs readily benefit from such techniques, improving \u2026"}, {"title": "ALGOPUZZLEVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Algorithmic Multimodal Puzzles", "link": "https://aclanthology.org/2025.naacl-long.486.pdf", "details": "D Ghosal, V Toh, YK Chia, S Poria - Proceedings of the 2025 Conference of the \u2026, 2025", "abstract": "This paper introduces the novel task of multimodal puzzle solving, framed within the context of visual question-answering. We present a new dataset, AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal language models \u2026"}, {"title": "Social determinants of health extraction from clinical notes across institutions using large language models", "link": "https://www.nature.com/articles/s41746-025-01645-8", "details": "VK Keloth, S Selek, Q Chen, C Gilman, S Fu, Y Dang\u2026 - npj Digital Medicine, 2025", "abstract": "Detailed social determinants of health (SDoH) is often buried within clinical text in EHRs. Most current NLP efforts for SDoH have limitations, investigating limited factors, deriving data from a single institution, using specific patient cohorts/note \u2026"}, {"title": "Exploring Multimodal Language Models for Sustainability Disclosure Extraction: A Comparative Study", "link": "https://aclanthology.org/2025.insights-1.13.pdf", "details": "T Gupta, T Goel, I Verma - The Sixth Workshop on Insights from Negative Results \u2026, 2025", "abstract": "Sustainability metrics have increasingly become a crucial non-financial criterion in investment decision-making. Organizations worldwide are recognizing the importance of sustainability and are proactively highlighting their efforts through \u2026"}, {"title": "Enhancing Structure-aware Protein Language Models with Efficient Fine-tuning for Various Protein Prediction Tasks", "link": "https://www.biorxiv.org/content/10.1101/2025.04.23.650337.full.pdf", "details": "Y Zhang, Y Qin, M Pourmirzaei, Q Shao, D Wang, D Xu - bioRxiv, 2025", "abstract": "Proteins are crucial in a wide range of biological and engineering processes. Large protein language models (PLMs) can significantly advance our understanding and engineering of proteins. However, the effectiveness of PLMs in prediction and design \u2026"}, {"title": "A resilient generative model in few-shot question answering", "link": "https://www.sciencedirect.com/science/article/pii/S0950705125006756", "details": "A Zou, Y Chen, R Huang, Y Qin - Knowledge-Based Systems, 2025", "abstract": "In few-shot question answering (QA), only a limited number of training cases are available to tune pre-trained language models (PLMs) for fitting to the task objective. Because a PLM often contains a large number of parameters optimized by a \u2026"}, {"title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "link": "https://arxiv.org/pdf/2505.04847", "details": "MS Tamber, FS Bao, C Xu, G Luo, S Kazi, M Bae, M Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce hallucinations by grounding responses in contexts. However, even when provided context, LLMs still frequently introduce unsupported information or contradictions \u2026"}]
