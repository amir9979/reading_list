[{"title": "Quantifying decision support level of explainable automatic classification of diagnoses in Spanish medical records", "link": "https://www.sciencedirect.com/science/article/pii/S0010482524012125", "details": "N Lebe\u00f1a, A P\u00e9rez, A Casillas - Computers in Biology and Medicine, 2024", "abstract": "Abstract Background and Objective: In the realm of automatic Electronic Health Records (EHR) classification according to the International Classification of Diseases (ICD) there is a notable gap of non-black box approaches and more in Spanish \u2026"}, {"title": "Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs", "link": "https://arxiv.org/pdf/2408.14397", "details": "X Zhang, JN Acosta, HY Zhou, P Rajpurkar - arXiv preprint arXiv:2408.14397, 2024", "abstract": "Recent advancements in artificial intelligence have significantly improved the automatic generation of radiology reports. However, existing evaluation methods fail to reveal the models' understanding of radiological images and their capacity to \u2026"}, {"title": "Latent Space Interpretation for Stylistic Analysis and Explainable Authorship Attribution", "link": "https://arxiv.org/pdf/2409.07072", "details": "M Alshomary, N Ri, M Apidianaki, A Patel, S Muresan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent state-of-the-art authorship attribution methods learn authorship representations of texts in a latent, non-interpretable space, hindering their usability in real-world applications. Our work proposes a novel approach to interpreting these \u2026"}, {"title": "Contrastive Learning with Transformer initialization and clustering prior for text representation", "link": "https://www.sciencedirect.com/science/article/pii/S1568494624009360", "details": "C Liu, X Chen, P Hu, J Lin, J Wang, X Geng - Applied Soft Computing, 2024", "abstract": "Acquiring labeled data for learning sentence embeddings in Natural Language Processing poses challenges due to limited availability and high costs. In order to tackle this issue, we introduce a novel method called Contrastive Learning with \u2026"}, {"title": "Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators", "link": "https://arxiv.org/pdf/2408.12325", "details": "D Yang, D Xiao, J Wei, M Li, Z Chen, K Li, L Zhang - arXiv preprint arXiv:2408.12325, 2024", "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) are prone to generate responses that contradict verifiable facts, ie, unfaithful hallucination content. Existing efforts generally focus on optimizing model parameters or editing semantic \u2026"}]
