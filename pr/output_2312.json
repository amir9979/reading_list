[{"title": "ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification", "link": "https://arxiv.org/pdf/2405.14608", "details": "XM Le, L Luo, U Aickelin, MT Tran - arXiv preprint arXiv:2405.14608, 2024", "abstract": "Multivariate time series classification (MTSC) has attracted significant research attention due to its diverse real-world applications. Recently, exploiting transformers for MTSC has achieved state-of-the-art performance. However, existing methods \u2026"}, {"title": "Score-CDM: Score-Weighted Convolutional Diffusion Model for Multivariate Time Series Imputation", "link": "https://arxiv.org/pdf/2405.13075", "details": "S Zhang, S Wang, H Miao, H Chen, C Fan, J Zhang - arXiv preprint arXiv:2405.13075, 2024", "abstract": "Multivariant time series (MTS) data are usually incomplete in real scenarios, and imputing the incomplete MTS is practically important to facilitate various time series mining tasks. Recently, diffusion model-based MTS imputation methods have \u2026"}, {"title": "SiET: Spatial information enhanced transformer for multivariate time series anomaly detection", "link": "https://www.sciencedirect.com/science/article/pii/S0950705124005628", "details": "W Xiong, P Wang, X Sun, J Wang - Knowledge-Based Systems, 2024", "abstract": "Anomaly detection in a multivariate time series using unsupervised methods presents a formidable challenge. The existing strategies focused on delineating intrinsic patterns over a temporal dimension and outputting a better representation of \u2026"}, {"title": "HybridBNN: Joint Training of Deterministic and Stochastic Layers in Bayesian Neural Nets", "link": "https://openreview.net/pdf%3Fid%3Dea3ERGY8bm", "details": "A Nejatbakhsh, J Boussard - Sixth Symposium on Advances in Approximate \u2026", "abstract": "Bayesian Neural Nets are proposed as flexible models that can provide calibrated uncertainty estimates for out-of-distribution data. Due to the high dimensionality of BNN posteriors and the intractability of exact inference, numerous approximate \u2026"}, {"title": "Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure", "link": "https://arxiv.org/pdf/2406.01170", "details": "C Ding, G Pang - arXiv preprint arXiv:2406.01170, 2024", "abstract": "As vision-language models like CLIP are widely applied to zero-shot tasks and gain remarkable performance on in-distribution (ID) data, detecting and rejecting out-of- distribution (OOD) inputs in the zero-shot setting have become crucial for ensuring \u2026"}, {"title": "Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data", "link": "https://arxiv.org/pdf/2405.07925", "details": "M Morafah, M Reisser, B Lin, C Louizos - arXiv preprint arXiv:2405.07925, 2024", "abstract": "The proliferation of edge devices has brought Federated Learning (FL) to the forefront as a promising paradigm for decentralized and collaborative model training while preserving the privacy of clients' data. However, FL struggles with a significant \u2026"}, {"title": "Disentangled Anomaly Detection For Multivariate Time Series", "link": "https://dl.acm.org/doi/abs/10.1145/3589335.3651492", "details": "X Jie, X Zhou, C Su, Z Zhou, Y Yuan, J Bu, H Wang - \u2026 Proceedings of the ACM on Web \u2026, 2024", "abstract": "Anomaly detection in time series that aims to identify unusual patterns has attracted a lot of attention recently. However, the representation of abnormal and normal data is difffcult to be distinguished because they are usually entangled. Recently \u2026"}, {"title": "DGCformer: Deep Graph Clustering Transformer for Multivariate Time Series Forecasting", "link": "https://arxiv.org/pdf/2405.08440", "details": "Q Liu, Y Fang, P Jiang, G Li - arXiv preprint arXiv:2405.08440, 2024", "abstract": "Multivariate time series forecasting tasks are usually conducted in a channel- dependent (CD) way since it can incorporate more variable-relevant information. However, it may also involve a lot of irrelevant variables, and this even leads to \u2026"}, {"title": "SDformer: Transformer with Spectral Filter and Dynamic Attention for Multivariate Time Series Long-term Forecasting", "link": "https://gengyulyu.github.io/homepage/assets/pdf/SDformer.pdf", "details": "Z Zhou, G Lyu, Y Huang, Z Wang, Z Jia, Z Yang", "abstract": "Transformer has gained widespread adoption in modeling time series due to the exceptional ability of its self-attention mechanism in capturing long-range dependencies. However, when processing time series data with numerous variates \u2026"}]
