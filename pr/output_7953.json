[{"title": "Are Expert-Level Language Models Expert-Level Annotators?", "link": "https://arxiv.org/pdf/2410.03254", "details": "YM Tseng, WL Chen, CC Chen, HH Chen - arXiv preprint arXiv:2410.03254, 2024", "abstract": "Data annotation refers to the labeling or tagging of textual data with relevant information. A large body of works have reported positive results on leveraging LLMs as an alternative to human annotators. However, existing studies focus on classic \u2026"}, {"title": "AI as Humanity's Salieri: Quantifying Linguistic Creativity of Language Models via Systematic Attribution of Machine Text against Web Text", "link": "https://arxiv.org/pdf/2410.04265", "details": "X Lu, M Sclar, S Hallinan, N Mireshghallah, J Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Creativity has long been considered one of the most difficult aspect of human intelligence for AI to mimic. However, the rise of Large Language Models (LLMs), like ChatGPT, has raised questions about whether AI can match or even surpass human \u2026"}, {"title": "Tree of Attributes Prompt Learning for Vision-Language Models", "link": "https://arxiv.org/pdf/2410.11201", "details": "T Ding, W Li, Z Miao, H Pfister - arXiv preprint arXiv:2410.11201, 2024", "abstract": "Prompt learning has proven effective in adapting vision language models for downstream tasks. However, existing methods usually append learnable prompt tokens solely with the category names to obtain textual features, which fails to fully \u2026"}, {"title": "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models", "link": "https://arxiv.org/pdf/2409.17455", "details": "Y Zhou, R Tang, Z Yao, Z Zhu - arXiv preprint arXiv:2409.17455, 2024", "abstract": "Language models (LMs), despite their advances, often depend on spurious correlations, undermining their accuracy and generalizability. This study addresses the overlooked impact of subtler, more complex shortcuts that compromise model \u2026"}, {"title": "Improving Instruction-Following in Language Models through Activation Steering", "link": "https://arxiv.org/pdf/2410.12877", "details": "A Stolfo, V Balachandran, S Yousefi, E Horvitz, B Nushi - arXiv preprint arXiv \u2026, 2024", "abstract": "The ability to follow instructions is crucial for numerous real-world applications of language models. In pursuit of deeper insights and more powerful capabilities, we derive instruction-specific vector representations from language models and use \u2026"}, {"title": "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models", "link": "https://arxiv.org/pdf/2410.12011", "details": "K Tatariya, V Araujo, T Bauwens, M de Lhoneux - arXiv preprint arXiv:2410.12011, 2024", "abstract": "Pixel-based language models have emerged as a compelling alternative to subword- based language modelling, particularly because they can represent virtually any script. PIXEL, a canonical example of such a model, is a vision transformer that has \u2026"}, {"title": "Probing Language Models on Their Knowledge Source", "link": "https://arxiv.org/pdf/2410.05817", "details": "Z Tighidet, A Mogini, J Mei, B Piwowarski, P Gallinari - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) often encounter conflicts between their learned, internal (parametric knowledge, PK) and external knowledge provided during inference (contextual knowledge, CK). Understanding how LLMs models prioritize \u2026"}, {"title": "Transformer-based Language Models for Reasoning in the Description Logic ALCQ", "link": "https://arxiv.org/pdf/2410.09613", "details": "A Poulis, E Tsalapati, M Koubarakis - arXiv preprint arXiv:2410.09613, 2024", "abstract": "Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order \u2026"}, {"title": "RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models", "link": "https://arxiv.org/pdf/2409.19886", "details": "S Chen, W Jiang, B Lin, JT Kwok, Y Zhang - arXiv preprint arXiv:2409.19886, 2024", "abstract": "Recent works show that assembling multiple off-the-shelf large language models (LLMs) can harness their complementary abilities. To achieve this, routing is a promising method, which learns a router to select the most suitable LLM for each \u2026"}]
