[{"title": "Health Equity in the Era of Large Language Models", "link": "https://search.proquest.com/openview/b6949cb4345ae9d0c66216be120af11a/1%3Fpq-origsite%3Dgscholar%26cbl%3D105486", "details": "AA Tierney - The American Journal of Managed Care, 2025", "abstract": "Solutions shared by these regulations and guidelines are to (1) ensure diverse representation in training data and in teams that develop artificial intelligence (AI) tools,(2) develop techniques to evaluate AI-enabled health care tool performance \u2026"}, {"title": "Privacy Risks and Memorization of Spurious Correlated Data", "link": "https://openreview.net/pdf%3Fid%3DBZHrxFDSur", "details": "C Zhang, J Pang, S Mauw - Workshop on Spurious Correlation and Shortcut \u2026", "abstract": "Neural networks are vulnerable to privacy attacks aimed at stealing sensitive data. The risks are amplified in real-world scenario when models are trained on limited and biased data. In this work, we investigate the impact of spurious correlation bias \u2026"}, {"title": "Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning", "link": "https://arxiv.org/pdf/2502.18080", "details": "W Yang, S Ma, Y Lin, F Wei - arXiv preprint arXiv:2502.18080, 2025", "abstract": "Recent studies have shown that making a model spend more time thinking through longer Chain of Thoughts (CoTs) enables it to gain significant improvements in complex reasoning tasks. While current researches continue to explore the benefits \u2026"}, {"title": "MuDAF: Long-Context Multi-Document Attention Focusing through Contrastive Learning on Attention Heads", "link": "https://arxiv.org/pdf/2502.13963%3F", "details": "W Liu, N Wu, S Yang, W Ding, S Liang, M Gong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) frequently show distracted attention due to irrelevant information in the input, which severely impairs their long-context capabilities. Inspired by recent studies on the effectiveness of retrieval heads in long \u2026"}, {"title": "PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection", "link": "https://arxiv.org/pdf/2502.12119", "details": "J Bi, Y Wang, D Yan, X Xiao, A Hecker, V Tresp, Y Ma - arXiv preprint arXiv \u2026, 2025", "abstract": "Visual instruction tuning refines pre-trained Multimodal Large Language Models (MLLMs) to enhance their real-world task performance. However, the rapid expansion of visual instruction datasets introduces significant data redundancy \u2026"}, {"title": "Neuromorphic Principles for Efficient Large Language Models on Intel Loihi 2", "link": "https://openreview.net/pdf%3Fid%3DqaDM1R2nlm", "details": "S Abreu, SB Shrestha, RJ Zhu, J Eshraghian - First Workshop on Scalable Optimization for \u2026", "abstract": "Large language models (LLMs) deliver impressive performance but require large amounts of energy. In this work, we present a MatMul-free LLM architecture adapted for Intel's neuromorphic processor, Loihi 2. Our approach leverages Loihi 2's support \u2026"}, {"title": "Measuring the Layer-Wise Impact of Image Shortcuts on Deep Model Features", "link": "https://openreview.net/pdf%3Fid%3D5sigk5jNqt", "details": "N Tsoy, N Konstantinov - Workshop on Spurious Correlation and Shortcut \u2026", "abstract": "Shortcuts, spurious patterns that perform well only on the training distribution, pose a major challenge to deep network reliability (Geirhos et al., 2020). In this work, we investigate the layer-wise impact of image shortcuts on learned features. First, we \u2026"}, {"title": "Forecasting Rare Language Model Behaviors", "link": "https://arxiv.org/pdf/2502.16797", "details": "E Jones, M Tong, J Mu, M Mahfoud, J Leike, R Grosse\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Standard language model evaluations can fail to capture risks that emerge only at deployment scale. For example, a model may produce safe responses during a small- scale beta test, yet reveal dangerous information when processing billions of \u2026"}, {"title": "Reducing Hallucinations of Medical Multimodal Large Language Models with Visual Retrieval-Augmented Generation", "link": "https://arxiv.org/pdf/2502.15040", "details": "YW Chu, K Zhang, C Malon, MR Min - arXiv preprint arXiv:2502.15040, 2025", "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive performance in vision and text tasks. However, hallucination remains a major challenge, especially in fields like healthcare where details are critical. In this work, we show \u2026"}]
