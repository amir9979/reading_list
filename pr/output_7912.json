[{"title": "Counterfactual Generative Modeling with Variational Causal Inference", "link": "https://arxiv.org/pdf/2410.12730", "details": "Y Wu, L McConnell, C Iriondo - arXiv preprint arXiv:2410.12730, 2024", "abstract": "Estimating an individual's potential outcomes under counterfactual treatments is a challenging task for traditional causal inference and supervised learning approaches when the outcome is high-dimensional (eg gene expressions, facial images) and \u2026"}, {"title": "Simulating clinical features on chest radiographs for medical image exploration and CNN explainability using a style-based generative adversarial autoencoder", "link": "https://www.nature.com/articles/s41598-024-75886-0", "details": "KA Hasenstab, L Hahn, N Chao, A Hsiao - Scientific Reports, 2024", "abstract": "Explainability of convolutional neural networks (CNNs) is integral for their adoption into radiological practice. Commonly used attribution methods localize image areas important for CNN prediction but do not characterize relevant imaging features \u2026"}, {"title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?", "link": "https://arxiv.org/pdf/2410.13523", "details": "C Liu, Z Wan, H Wang, Y Chen, T Qaiser, C Jin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Medical Vision-Language Pre-training (MedVLP) has made significant progress in enabling zero-shot tasks for medical image understanding. However, training MedVLP models typically requires large-scale datasets with paired, high-quality \u2026"}, {"title": "Leveraging Coarse-to-Fine Grained Representations in Contrastive Learning for Differential Medical Visual Question Answering", "link": "https://papers.miccai.org/miccai-2024/paper/1957_paper.pdf", "details": "X Liang, Y Wang, D Wang, Z Jiao, H Zhong, M Yang\u2026 - International Conference on \u2026, 2024", "abstract": "Abstract Chest X-ray Differential Medical Visual Question Answering (Diff-MedVQA) is a novel multi-modal task designed to answer questions about diseases, especially their differences, based on a main image and a reference image. Compared to the \u2026"}, {"title": "Energy-Based Conceptual Diffusion Model", "link": "https://openreview.net/pdf%3Fid%3DUKCPaTcJAo", "details": "Y Qin, X Xu, H Wang, X Li - Neurips Safe Generative AI Workshop 2024", "abstract": "Diffusion models have shown impressive sample generation capabilities across various domains. However, current methods are still lacking in human- understandable explanations and interpretable control:(1) they do not provide a \u2026"}, {"title": "Generative Models for Counterfactual Explanations", "link": "https://human-interpretable-ai.github.io/assets/pdf/5_Generative_Models_for_Counte.pdf", "details": "D Kirilenko, P Barbiero, M Gjoreski, M Lu\u0161trek\u2026 - 2024", "abstract": "Counterfactual explanations have emerged as an effective method of explaining machine learning models. These explanations elucidate how to tweak the model input in order to flip its output. Generative approaches serve as a tool for creating \u2026"}]
