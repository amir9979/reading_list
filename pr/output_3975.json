[{"title": "On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning", "link": "https://arxiv.org/pdf/2406.14197", "details": "F Nowak, A Svete, A Butoi, R Cotterell - arXiv preprint arXiv:2406.14197, 2024", "abstract": "The performance of modern language models (LMs) has been improved by chain-of- thought (CoT) reasoning, ie, the process of generating intermediate results that guide the model towards a final answer. A possible explanation for this improvement is that \u2026"}, {"title": "Extraction of sleep information from clinical notes of Alzheimer's disease patients using natural language processing", "link": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae177/7713266", "details": "S Sivarajkumar, TYC Tam, HA Mohammad, S Viggiano\u2026 - Journal of the American \u2026, 2024", "abstract": "Objectives Alzheimer's disease (AD) is the most common form of dementia in the United States. Sleep is one of the lifestyle-related factors that has been shown critical for optimal cognitive function in old age. However, there is a lack of research \u2026"}, {"title": "Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding", "link": "https://arxiv.org/pdf/2406.12295", "details": "K Zhang, J Wang, N Ding, B Qi, E Hua, X Lv, B Zhou - arXiv preprint arXiv:2406.12295, 2024", "abstract": "Large Language Models (LLMs) demonstrate impressive performance in diverse applications, yet they face significant drawbacks, including high inference latency, expensive training cost, and generation of hallucination. Collaborative decoding \u2026"}, {"title": "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2406.12050", "details": "Z Zhang, Z Liang, W Yu, D Yu, M Jia, D Yu, M Jiang - arXiv preprint arXiv:2406.12050, 2024", "abstract": "Supervised fine-tuning enhances the problem-solving abilities of language models across various mathematical reasoning tasks. To maximize such benefits, existing research focuses on broadening the training set with various data augmentation \u2026"}, {"title": "Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models", "link": "https://arxiv.org/pdf/2406.14091", "details": "D Lee, D Rim, M Choi, J Choo - arXiv preprint arXiv:2406.14091, 2024", "abstract": "Although language models (LMs) demonstrate exceptional capabilities on various tasks, they are potentially vulnerable to extraction attacks, which represent a significant privacy risk. To mitigate the privacy concerns of LMs, machine unlearning \u2026"}, {"title": "Information Guided Regularization for Fine-tuning Language Models", "link": "https://arxiv.org/pdf/2406.14005", "details": "M Sharma, N Muralidhar, S Xu, RB Yosuf\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The pretraining-fine-tuning paradigm has been the de facto strategy for transfer learning in modern language modeling. With the understanding that task adaptation in LMs is often a function of parameters shared across tasks, we argue that a more \u2026"}, {"title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs", "link": "https://arxiv.org/pdf/2406.14282", "details": "J Wang, M Chen, B Hu, D Yang, Z Liu, Y Shen, P Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Improving the performance of large language models (LLMs) in complex question- answering (QA) scenarios has always been a research focal point. Recent studies have attempted to enhance LLMs' performance by combining step-wise planning \u2026"}, {"title": "What Are the Odds? Language Models Are Capable of Probabilistic Reasoning", "link": "https://arxiv.org/pdf/2406.12830", "details": "A Paruchuri, J Garrison, S Liao, J Hernandez\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language models (LM) are capable of remarkably complex linguistic tasks; however, numerical reasoning is an area in which they frequently struggle. An important but rarely evaluated form of reasoning is understanding probability distributions. In this \u2026"}, {"title": "Mitigating Social Biases in Language Models through Unlearning", "link": "https://arxiv.org/pdf/2406.13551", "details": "O Dige, D Singh, TF Yau, Q Zhang, B Bolandraftar\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Mitigating bias in language models (LMs) has become a critical problem due to the widespread deployment of LMs. Numerous approaches revolve around data pre- processing and fine-tuning of language models, tasks that can be both time \u2026"}]
