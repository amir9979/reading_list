[{"title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks", "link": "https://arxiv.org/pdf/2409.07353", "details": "MZ Hossain, A Imteaj - arXiv preprint arXiv:2409.07353, 2024", "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets, have significantly advanced AI by excelling in vision-language tasks. However, these models remain vulnerable to adversarial attacks, particularly jailbreak attacks, which \u2026"}, {"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task Specific Expert Pruning", "link": "https://arxiv.org/pdf/2409.01483", "details": "S Sarkar, L Lausen, V Cevher, S Zha, T Brox, G Karypis - arXiv preprint arXiv \u2026, 2024", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative to dense models in language modeling. These models use conditionally activated feedforward subnetworks in transformer blocks, allowing for a separation between \u2026"}, {"title": "Pushing the Limits of Vision-Language Models in Remote Sensing without Human Annotations", "link": "https://arxiv.org/pdf/2409.07048", "details": "K Cha, D Yu, J Seo - arXiv preprint arXiv:2409.07048, 2024", "abstract": "The prominence of generalized foundation models in vision-language integration has witnessed a surge, given their multifarious applications. Within the natural domain, the procurement of vision-language datasets to construct these foundation \u2026"}, {"title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models", "link": "https://arxiv.org/pdf/2409.01584", "details": "S Ozaki, K Hayashi, Y Sakai, H Kamigaito, K Hayashi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow \u2026"}, {"title": "In Defense of RAG in the Era of Long-Context Language Models", "link": "https://arxiv.org/pdf/2409.01666", "details": "T Yu, A Xu, R Akkiraju - arXiv preprint arXiv:2409.01666, 2024", "abstract": "Overcoming the limited context limitations in early-generation LLMs, retrieval- augmented generation (RAG) has been a reliable solution for context-based answer generation in the past. Recently, the emergence of long-context LLMs allows the \u2026"}, {"title": "On the Relationship between Truth and Political Bias in Language Models", "link": "https://arxiv.org/pdf/2409.05283", "details": "S Fulay, W Brannon, S Mohanty, C Overney\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Language model alignment research often attempts to ensure that models are not only helpful and harmless, but also truthful and unbiased. However, optimizing these objectives simultaneously can obscure how improving one aspect might impact the \u2026"}, {"title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries", "link": "https://arxiv.org/pdf/2409.00844", "details": "B Yang, F Cui, K Paster, J Ba, P Vaezipoor, S Pitis\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid development and dynamic nature of large language models (LLMs) make it difficult for conventional quantitative benchmarks to accurately assess their capabilities. We propose report cards, which are human-interpretable, natural \u2026"}, {"title": "PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions", "link": "https://arxiv.org/pdf/2409.05076", "details": "Y Zhang, R Xie, J Chen, X Sun, Y Wang - arXiv preprint arXiv:2409.05076, 2024", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated their powerful multimodal capabilities. However, they also face serious safety problems, as adversaries can induce robustness issues in LVLMs through the use of well \u2026"}, {"title": "Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models", "link": "https://arxiv.org/pdf/2409.09510", "details": "A Salemi, H Zamani - arXiv preprint arXiv:2409.09510, 2024", "abstract": "Privacy-preserving methods for personalizing large language models (LLMs) are relatively under-explored. There are two schools of thought on this topic:(1) generating personalized outputs by personalizing the input prompt through retrieval \u2026"}]
