'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Bridging Different Language Models and Generative Visi'
[{"title": "Fine-Tuning Language Models with Reward Learning on Policy", "link": "https://arxiv.org/html/2403.19279v1", "details": "H Lang, F Huang, Y Li - arXiv preprint arXiv:2403.19279, 2024", "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as an effective approach to aligning large language models (LLMs) to human preferences. RLHF contains three steps, ie, human preference collecting, reward learning, and policy \u2026"}, {"title": "Synth $^ 2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings", "link": "https://arxiv.org/pdf/2403.07750", "details": "S Sharifzadeh, C Kaplanis, S Pathak, D Kumaran, A Ilic\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The creation of high-quality human-labeled image-caption datasets presents a significant bottleneck in the development of Visual-Language Models (VLMs). We propose a novel approach that leverages the strengths of Large Language Models \u2026"}, {"title": "Aligning Large and Small Language Models via Chain-of-Thought Reasoning", "link": "https://aclanthology.org/2024.eacl-long.109.pdf", "details": "L Ranaldi, A Freitas - Proceedings of the 18th Conference of the European \u2026, 2024", "abstract": "Abstract Chain-of-Thought (CoT) prompting empowersthe reasoning abilities of Large Language Models (LLMs), eliciting them to solve complexreasoning tasks in a step-wise manner. However, these capabilities appear only in models with billions of \u2026"}, {"title": "Emergent Abilities in Reduced-Scale Generative Language Models", "link": "https://arxiv.org/html/2404.02204v1", "details": "S Muckatira, V Deshpande, V Lialin, A Rumshisky - arXiv preprint arXiv:2404.02204, 2024", "abstract": "Large language models can solve new tasks without task-specific fine-tuning. This ability, also known as in-context learning (ICL), is considered an emergent ability and is primarily seen in large language models with billions of parameters. This study \u2026"}, {"title": "BEnQA: A Question Answering and Reasoning Benchmark for Bengali and English", "link": "https://arxiv.org/pdf/2403.10900", "details": "S Shafayat, HM Hasan, MRC Mahim, RA Putri\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this study, we introduce BEnQA, a dataset comprising parallel Bengali and English exam questions for middle and high school levels in Bangladesh. Our dataset consists of approximately 5K questions covering several subjects in science with \u2026"}, {"title": "$\\mathbf {(N, K)} $-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model", "link": "https://arxiv.org/html/2403.07191v1", "details": "Y Zhang, L Chen, B Liu, Y Yang, Q Cui, Y Tao, H Yang - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advances in reinforcement learning (RL) algorithms aim to enhance the performance of language models at scale. Yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these \u2026"}, {"title": "Generative Language Models for Personalized Information Understanding", "link": "https://scholarworks.umass.edu/cgi/viewcontent.cgi%3Farticle%3D4123%26context%3Ddissertations_2", "details": "P Cai - 2024", "abstract": "A major challenge in information understanding stems from the diverse nature of the audience, where individuals possess varying preferences, experiences, educational and cultural backgrounds. Consequently, adopting a one-size-fits-all approach to \u2026"}, {"title": "Tree-of-Reasoning Question Decomposition for Complex Question Answering with Large Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/29928/31621", "details": "K Zhang, J Zeng, F Meng, Y Wang, S Sun, L Bai\u2026 - Proceedings of the AAAI \u2026, 2024", "abstract": "Large language models (LLMs) have recently demonstrated remarkable performance across various natual language processing tasks. In the field of multi- hop reasoning, the Chain-of-thought (CoT) prompt method has emerged as a \u2026"}, {"title": "Visual CoT: Unleashing Chain-of-Thought Reasoning in Multi-Modal Language Models", "link": "https://arxiv.org/pdf/2403.16999", "details": "H Shao, S Qian, H Xiao, G Song, Z Zong, L Wang, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This paper presents Visual CoT, a novel pipeline that leverages the reasoning capabilities of multi-modal large language models (MLLMs) by incorporating visual Chain-of-Thought (CoT) reasoning. While MLLMs have shown promise in various \u2026"}]
