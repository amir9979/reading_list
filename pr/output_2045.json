[{"title": "Ask Me in English Instead: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries", "link": "https://openreview.net/pdf%3Fid%3DGpGSlMoiBn", "details": "Y Jin, M Chandra, G Verma, Y Hu, M De Choudhury\u2026 - The Web Conference 2024", "abstract": "Large language models (LLMs) are transforming the ways the general public accesses and consumes information. Their influence is particularly pronounced in pivotal sectors like healthcare, where lay individuals are increasingly appropriating \u2026"}, {"title": "An Extensible Evaluation Framework Applied to Clinical Text Deidentification Natural Language Processing Tools: Multisystem and Multicorpus Study", "link": "https://www.jmir.org/2024/1/e55676/", "details": "PM Heider, SM Meystre - Journal of Medical Internet Research, 2024", "abstract": "Background Clinical natural language processing (NLP) researchers need access to directly comparable evaluation results for applications such as text deidentification across a range of corpus types and the means to easily test new systems or corpora \u2026"}, {"title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models", "link": "https://arxiv.org/pdf/2405.18218", "details": "Y Zhang, Y Li, X Wang, Q Shen, B Plank, B Bischl\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Overparametrized transformer networks are the state-of-the-art architecture for Large Language Models (LLMs). However, such models contain billions of parameters making large compute a necessity, while raising environmental concerns. To \u2026"}, {"title": "MM-InstructEval: Zero-Shot Evaluation of (Multimodal) Large Language Models on Multimodal Reasoning Tasks", "link": "https://arxiv.org/pdf/2405.07229", "details": "X Yang, W Wu, S Feng, M Wang, D Wang, Y Li, Q Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rising popularity of multimodal large language models (MLLMs) has sparked a significant increase in research dedicated to evaluating these models. However, current evaluation studies predominantly concentrate on the ability of models to \u2026"}]
