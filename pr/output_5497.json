[{"title": "Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models", "link": "https://arxiv.org/pdf/2407.20271", "details": "H Tang, Y Liu, X Liu, K Zhang, Y Zhang, Q Liu, E Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in machine learning, especially in Natural Language Processing (NLP), have led to the development of sophisticated models trained on vast datasets, but this progress has raised concerns about potential sensitive \u2026"}, {"title": "Retrieve, Generate, Evaluate: A Case Study for Medical Paraphrases Generation with Small Language Models", "link": "https://arxiv.org/pdf/2407.16565", "details": "I Buhnila, A Sinha, M Constant - arXiv preprint arXiv:2407.16565, 2024", "abstract": "Recent surge in the accessibility of large language models (LLMs) to the general population can lead to untrackable use of such models for medical-related recommendations. Language generation via LLMs models has two key problems \u2026"}, {"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning", "link": "https://arxiv.org/pdf/2407.21011", "details": "Y Du, B Chang, NC Dvornek - arXiv preprint arXiv:2407.21011, 2024", "abstract": "Recent advancements in Contrastive Language-Image Pre-training (CLIP) have demonstrated notable success in self-supervised representation learning across various tasks. However, the existing CLIP-like approaches often demand extensive \u2026"}, {"title": "Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?", "link": "https://arxiv.org/pdf/2408.08685", "details": "Z Zhang, X Wang, H Zhou, Y Yu, M Zhang, C Yang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Graph neural networks (GNNs) are vulnerable to adversarial perturbations, especially for topology attacks, and many methods that improve the robustness of GNNs have received considerable attention. Recently, we have witnessed the \u2026"}, {"title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?", "link": "https://arxiv.org/pdf/2407.17417", "details": "MA Panaitescu-Liess, Z Che, B An, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this \u2026"}, {"title": "AbdomenAtlas: A large-scale, detailed-annotated, & multi-center dataset for efficient transfer learning and open algorithmic benchmarking", "link": "https://arxiv.org/pdf/2407.16697", "details": "W Li, C Qu, X Chen, PRAS Bassi, Y Shi, Y Lai, Q Yu\u2026 - Medical Image Analysis, 2024", "abstract": "We introduce the largest abdominal CT dataset (termed AbdomenAtlas) of 20,460 three-dimensional CT volumes sourced from 112 hospitals across diverse populations, geographies, and facilities. AbdomenAtlas provides 673 K high-quality \u2026"}, {"title": "UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models", "link": "https://arxiv.org/pdf/2407.16160", "details": "L Qi, H Yongyi, L Defu, Z Zhi, X Tong, L Che, C Enhong - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Entity Linking (MEL) is a crucial task that aims at linking ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on using \u2026"}, {"title": "Open Challenges on Fairness of Artificial Intelligence in Medical Imaging Applications", "link": "https://arxiv.org/pdf/2407.16953", "details": "E Ferrante, R Echeveste - arXiv preprint arXiv:2407.16953, 2024", "abstract": "Recently, the research community of computerized medical imaging has started to discuss and address potential fairness issues that may emerge when developing and deploying AI systems for medical image analysis. This chapter covers some of \u2026"}]
