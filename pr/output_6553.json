[{"title": "Enhancing Audio-Language Models through Self-Supervised Post-Training with Text-Audio Pairs", "link": "https://arxiv.org/pdf/2408.09269", "details": "A Sinha, C Migozzi, A Rey, C Zhang - arXiv preprint arXiv:2408.09269, 2024", "abstract": "Research on multi-modal contrastive learning strategies for audio and text has rapidly gained interest. Contrastively trained Audio-Language Models (ALMs), such as CLAP, which establish a unified representation across audio and language \u2026"}, {"title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents", "link": "https://arxiv.org/pdf/2408.12337", "details": "KS Phogat, SA Puranam, S Dasaratha, C Harsha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain \u2026"}, {"title": "Can Visual Language Models Replace OCR-Based Visual Question Answering Pipelines in Production? A Case Study in Retail", "link": "https://arxiv.org/pdf/2408.15626", "details": "B Lamm, J Keuper - arXiv preprint arXiv:2408.15626, 2024", "abstract": "Most production-level deployments for Visual Question Answering (VQA) tasks are still build as processing pipelines of independent steps including image pre- processing, object-and text detection, Optical Character Recognition (OCR) and \u2026"}, {"title": "Regression Residual Reasoning with Pseudo-labeled Contrastive Learning for Uncovering Multiple Complex Compositional Relations", "link": "https://www.ijcai.org/proceedings/2024/0384.pdf", "details": "C Li, Y He, J Ren, R Bai, Y Zhao, H Yu, X Jiang\u2026", "abstract": "Abstract Abstract Visual Reasoning (AVR) has been widely studied in literature. Our study reveals that AVR models tend to rely on appearance matching rather than a genuine understanding of underlying rules. We hence develop a challenging \u2026"}]
