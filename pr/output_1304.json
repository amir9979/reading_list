'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Autonomous Data Selection with Language Models for Mat'
[{"title": "Causal Evaluation of Language Models", "link": "https://arxiv.org/pdf/2405.00622", "details": "S Chen, B Peng, M Chen, R Wang, M Xu, X Zeng\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Causal reasoning is viewed as crucial for achieving human-level machine intelligence. Recent advances in language models have expanded the horizons of artificial intelligence across various domains, sparking inquiries into their potential for \u2026"}, {"title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models", "link": "https://arxiv.org/pdf/2405.00402", "details": "L Ranaldi, A Freitas - arXiv preprint arXiv:2405.00402, 2024", "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches \u2026"}, {"title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision", "link": "https://arxiv.org/pdf/2405.04086", "details": "Y Tong, S Wang, D Li, Y Wang, S Han, Z Lin, C Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While Large Language Models (LLMs) have demonstrated proficiency in handling complex queries, much of the past work has depended on extensively annotated datasets by human experts. However, this reliance on fully-supervised annotations \u2026"}, {"title": "Gaze-infused BERT: Do human gaze signals help pre-trained language models?", "link": "https://link.springer.com/article/10.1007/s00521-024-09725-8", "details": "B Wang, B Liang, L Zhou, R Xu - Neural Computing and Applications, 2024", "abstract": "This research delves into the intricate connection between self-attention mechanisms in large-scale pre-trained language models, like BERT, and human gaze patterns, with the aim of harnessing gaze information to enhance the performance of natural \u2026"}, {"title": "On the Effects of Fine-tuning Language Models for Text-Based Reinforcement Learning", "link": "https://arxiv.org/pdf/2404.10174", "details": "M Gruppi, S Dan, K Murugesan, S Chaudhury - arXiv preprint arXiv:2404.10174, 2024", "abstract": "Text-based reinforcement learning involves an agent interacting with a fictional environment using observed text and admissible actions in natural language to complete a task. Previous works have shown that agents can succeed in text-based \u2026"}, {"title": "More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness", "link": "https://arxiv.org/pdf/2404.18870", "details": "AJ Li, S Krishna, H Lakkaraju - arXiv preprint arXiv:2404.18870, 2024", "abstract": "The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power. Despite the effectiveness of \u2026"}, {"title": "HFT: Half Fine-Tuning for Large Language Models", "link": "https://arxiv.org/pdf/2404.18466", "details": "T Hui, Z Zhang, S Wang, W Xu, Y Sun, H Wu - arXiv preprint arXiv:2404.18466, 2024", "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of \u2026"}, {"title": "Model & Data Insights using Pre-trained Language Models", "link": "https://openreview.net/pdf%3Fid%3DL5T3ZqsD0j", "details": "S Asgari, A Khani, AH Khasahmadi, A Sanghi\u2026 - ICLR 2024 Workshop on \u2026", "abstract": "We propose TExplain, using language models to interpret pre-trained image classifiers' features. Our approach connects the feature space of image classifiers with language models, generating explanatory sentences during inference. By \u2026"}, {"title": "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval", "link": "https://arxiv.org/pdf/2404.18424", "details": "S Zhuang, X Ma, B Koopman, J Lin, G Zuccon - arXiv preprint arXiv:2404.18424, 2024", "abstract": "The current use of large language models (LLMs) for zero-shot document ranking follows one of two ways: 1) prompt-based re-ranking methods, which require no further training but are feasible for only re-ranking a handful of candidate documents \u2026"}]
