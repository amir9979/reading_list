[{"title": "Language models encode the value of numbers linearly", "link": "https://aclanthology.org/2025.coling-main.47.pdf", "details": "F Zhu, D Dai, Z Sui - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) have exhibited impressive competence in various tasks, but their internal mechanisms on mathematical problems are still under- explored. In this paper, we study a fundamental question: how language models \u2026"}, {"title": "Reasoning Language Models: A Blueprint", "link": "https://arxiv.org/pdf/2501.11223%3F", "details": "M Besta, J Barth, E Schreiber, A Kubicek, A Catarino\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning language models (RLMs), also known as Large Reasoning Models (LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have redefined AI's problem-solving capabilities by extending large language models \u2026"}, {"title": "When Evolution Strategy Meets Language Models Tuning", "link": "https://aclanthology.org/2025.coling-main.357.pdf", "details": "B Huang, Y Jiang, M Chen, Y Wang, H Chen, W Wang - Proceedings of the 31st \u2026, 2025", "abstract": "Supervised Fine-tuning has been pivotal in training autoregressive language models, yet it introduces exposure bias. To mitigate this, Post Fine-tuning, including on-policy and off-policy methods, has emerged as a solution to enhance models \u2026"}, {"title": "Sibyl: Empowering Empathetic Dialogue Generation in Large Language Models via Sensible and Visionary Commonsense Inference", "link": "https://aclanthology.org/2025.coling-main.10.pdf", "details": "L Wang, J Li, C Yang, Z Lin, H Tang, H Liu, Y Cao\u2026 - Proceedings of the 31st \u2026, 2025", "abstract": "Recently, there has been a heightened interest in building chatbots based on Large Language Models (LLMs) to emulate human-like qualities in multi-turn conversations. Despite having access to commonsense knowledge to better \u2026"}, {"title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies", "link": "https://arxiv.org/pdf/2502.08554", "details": "SSY Kim, JW Vaughan, QV Liao, T Lombrozo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study \u2026"}, {"title": "META-LORA: Memory-Efficient Sample Reweighting for Fine-Tuning Large Language Models", "link": "https://aclanthology.org/2025.coling-main.568.pdf", "details": "W Li, L Zou, M Tang, Q Yu, W Li, C Li - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "Supervised fine-tuning (SFT) is widely adopted for tailoring large language models (LLMs) to specific downstream tasks. However, the substantial computational demands of LLMs hinder iterative exploration of fine-tuning datasets and accurate \u2026"}, {"title": "Topology-of-Question-Decomposition: Enhancing Large Language Models with Information Retrieval for Knowledge-Intensive Tasks", "link": "https://aclanthology.org/2025.coling-main.191.pdf", "details": "W Li, J Wang, LC Yu, X Zhang - Proceedings of the 31st International Conference on \u2026, 2025", "abstract": "Large language models (LLMs) are increasingly deployed for general problem- solving across various domains yet remain constrained to chaining immediate reasoning steps and depending solely on parametric knowledge. Integrating an \u2026"}, {"title": "Selective Self-to-Supervised Fine-Tuning for Generalization in Large Language Models", "link": "https://arxiv.org/pdf/2502.08130", "details": "S Gupta, Y Nandwani, A Yehudai, D Khandelwal\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Fine-tuning Large Language Models (LLMs) on specific datasets is a common practice to improve performance on target tasks. However, this performance gain often leads to overfitting, where the model becomes too specialized in either the task \u2026"}, {"title": "Embedding-Driven Diversity Sampling to Improve Few-Shot Synthetic Data Generation", "link": "https://arxiv.org/pdf/2501.11199", "details": "I Lopez, FN Haredasht, K Caoili, JH Chen, A Chaudhari - arXiv preprint arXiv \u2026, 2025", "abstract": "Accurate classification of clinical text often requires fine-tuning pre-trained language models, a process that is costly and time-consuming due to the need for high-quality data and expert annotators. Synthetic data generation offers an alternative, though \u2026"}]
