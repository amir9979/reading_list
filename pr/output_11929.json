[{"title": "Integrated Image-Text Augmentation for Few-Shot Learning in Vision-Language Models", "link": "https://dl.acm.org/doi/abs/10.1145/3712700", "details": "R Wang, H Zuo, Z Fang, J Lu - ACM Transactions on Intelligent Systems and \u2026", "abstract": "Vision-language models, such as the Contrastive Language-Image Pre-Training (CLIP) model, have achieved significant success in image classification tasks. CLIP demonstrates high expressive power in few-shot learning scenarios due to its pairing \u2026"}, {"title": "Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models", "link": "https://arxiv.org/pdf/2501.09997", "details": "Q Liu, X Chen, Y Ding, S Xu, S Wu, L Wang - arXiv preprint arXiv:2501.09997, 2025", "abstract": "Hallucination has emerged as a significant barrier to the effective application of Large Language Models (LLMs). In this work, we introduce a novel Attention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination detection in LLMs. The \u2026"}, {"title": "Evolving Deeper LLM Thinking", "link": "https://arxiv.org/pdf/2501.09891", "details": "KH Lee, I Fischer, YH Wu, D Marwood, S Baluja\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We explore an evolutionary search strategy for scaling inference time compute in Large Language Models. The proposed approach, Mind Evolution, uses a language model to generate, recombine and refine candidate responses. The proposed \u2026"}]
