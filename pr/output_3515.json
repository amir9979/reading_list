[{"title": "Aligning Language Models with the Human World", "link": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi%3Farticle%3D1241%26context%3Ddissertations", "details": "R LIU - 2024", "abstract": "Abstract The field of Natural Language Processing (NLP) has undergone a significant transformation with the emergence of large language models (LMs). These models have enabled the development of human-like conversational \u2026"}, {"title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?", "link": "https://arxiv.org/pdf/2406.16316", "details": "Y Jinnai - arXiv preprint arXiv:2406.16316, 2024", "abstract": "Alignment of the language model with human preferences is a common approach to making a language model useful to end users. However, most alignment work is done in English, and human preference datasets are dominated by English \u2026"}, {"title": "LMCK: pre-trained language models enhanced with contextual knowledge for Vietnamese natural language inference", "link": "https://link.springer.com/article/10.1007/s11042-024-19671-1", "details": "NLT Nguyen, KTK Phan, TV Huynh, KV Nguyen - Multimedia Tools and Applications, 2024", "abstract": "Abstract Natural Language Inference (NLI) has gathered significant attention in recent years due to its application. However, to apply to other downstream tasks, the NLI task should be extended its boundaries by adopting prominent approaches such \u2026"}, {"title": "Entropy-Based Decoding for Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2406.17519", "details": "Z Qiu, Z Ou, B Wu, J Li, A Liu, I King - arXiv preprint arXiv:2406.17519, 2024", "abstract": "Augmenting Large Language Models (LLMs) with retrieved external knowledge has proven effective for improving the factual accuracy of generated responses. Despite their success, retrieval-augmented LLMs still face the distractibility issue, where the \u2026"}, {"title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models", "link": "https://arxiv.org/pdf/2407.02408", "details": "S Wang, P Wang, T Zhou, Y Dong, Z Tan, J Li - arXiv preprint arXiv:2407.02408, 2024", "abstract": "As Large Language Models (LLMs) are increasingly deployed to handle various natural language processing (NLP) tasks, concerns regarding the potential negative societal impacts of LLM-generated content have also arisen. To evaluate the biases \u2026"}, {"title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application", "link": "https://arxiv.org/pdf/2407.01885", "details": "C Yang, W Lu, Y Zhu, Y Wang, Q Chen, C Gao, B Yan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in various domains, attracting significant interest from both academia and industry. Despite their impressive performance, the substantial size and computational demands of LLMs \u2026"}, {"title": "The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models", "link": "https://arxiv.org/pdf/2406.19999", "details": "X Chen, B Liao, J Qi, P Eustratiadis, C Monz, A Bisazza\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Following multiple instructions is a crucial ability for large language models (LLMs). Evaluating this ability comes with significant challenges:(i) limited coherence between multiple instructions,(ii) positional bias where the order of instructions \u2026"}, {"title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization", "link": "https://arxiv.org/pdf/2406.16743", "details": "Z Zhao, X Zhang, K Xu, X Hu, R Zhang, Z Du, Q Guo\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the widespread application of Large Language Models (LLMs), it has become a significant concern to ensure their safety and prevent harmful responses. While current safe-alignment methods based on instruction fine-tuning and Reinforcement \u2026"}, {"title": "Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation", "link": "https://arxiv.org/pdf/2406.16356", "details": "R Hida, J Ohmura, T Sekiya - arXiv preprint arXiv:2406.16356, 2024", "abstract": "Instruction-tuned Large Language Models (LLMs) have achieved remarkable performance across various benchmark tasks. While providing instructions to LLMs for guiding their generations is user-friendly, assessing their instruction-following \u2026"}]
