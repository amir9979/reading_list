[{"title": "Privacy-preserving LLM-based chatbots for hypertensive patient self-management", "link": "https://www.sciencedirect.com/science/article/pii/S2352648325000133", "details": "S Montagna, S Ferretti, LC Klopfenstein, M Ungolo\u2026 - Smart Health, 2025", "abstract": "Medical chatbots are becoming a basic component in telemedicine, propelled by advancements in Large Language Models (LLMs). However, LLMs' integration into clinical settings comes with several issues, with privacy concerns being particularly \u2026"}, {"title": "SurGen: 1020 H&E-stained Whole Slide Images With Survival and Genetic Markers", "link": "https://arxiv.org/pdf/2502.04946", "details": "C Myles, IH Um, C Marshall, D Harris-Birtill\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "$\\textbf {Background} $: Cancer remains one of the leading causes of morbidity and mortality worldwide. Comprehensive datasets that combine histopathological images with genetic and survival data across various tumour sites are essential for \u2026"}, {"title": "Optimizing Singular Spectrum for Large Language Model Compression", "link": "https://arxiv.org/pdf/2502.15092", "details": "D Li, T Shen, Y Zhou, B Yang, Z Liu, M Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, yet prohibitive parameter complexity often hinders their deployment. Existing singular value decomposition (SVD) based compression methods simply deem singular \u2026"}, {"title": "Counterfactual Bidirectional Co-Attention Transformer for Integrative Histology-Genomic Cancer Risk Stratification", "link": "https://ieeexplore.ieee.org/abstract/document/10910138/", "details": "Z Ji, Y Ge, C Chukwudi, U Kaicheng, SM Zhang\u2026 - IEEE Journal of Biomedical \u2026, 2025", "abstract": "Applying deep learning to predict patient prognostic survival outcomes using histological whole-slide images (WSIs) and genomic data is challenging due to the morphological and transcriptomic heterogeneity present in the tumor \u2026"}, {"title": "EyeBench: A Call for More Rigorous Evaluation of Retinal Image Enhancement", "link": "https://arxiv.org/pdf/2502.14260", "details": "W Zhu, X Dong, X Li, Y Xiong, X Chen, P Qiu, VK Vasa\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Over the past decade, generative models have achieved significant success in enhancement fundus images. However, the evaluation of these models still presents a considerable challenge. A comprehensive evaluation benchmark for fundus image \u2026"}, {"title": "Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline", "link": "https://arxiv.org/pdf/2502.18531", "details": "X Gui, H Lv, X Wang, L Lv, Y Xiao, L Wang - arXiv preprint arXiv:2502.18531, 2025", "abstract": "Background: Recruitment for cohorts involving complex liver diseases, such as hepatocellular carcinoma and liver cirrhosis, often requires interpreting semantically complex criteria. Traditional manual screening methods are time-consuming and \u2026"}, {"title": "Leveraging large language models for structured information extraction from pathology reports", "link": "https://arxiv.org/pdf/2502.12183", "details": "JB Balasubramanian, D Adams, I Roxanis\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Background: Structured information extraction from unstructured histopathology reports facilitates data accessibility for clinical research. Manual extraction by experts is time-consuming and expensive, limiting scalability. Large language models \u2026"}, {"title": "Modular Prompt Learning Improves Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14125", "details": "Z Huang, T Pedapati, PY Chen, J Gao - arXiv preprint arXiv:2502.14125, 2025", "abstract": "Pre-trained vision-language models are able to interpret visual concepts and language semantics. Prompt learning, a method of constructing prompts for text encoders or image encoders, elicits the potentials of pre-trained models and readily \u2026"}, {"title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "link": "https://arxiv.org/pdf/2502.05142", "details": "Z Yang, X Xu, J Zhang, G Wang, MK Kalra, P Yan - arXiv preprint arXiv:2502.05142, 2025", "abstract": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting diverse clinical tasks from thoracic disease detection to postoperative monitoring. However, task-specific classification models are limited in scope, require costly labeled data \u2026"}]
