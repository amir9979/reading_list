[{"title": "Smoothie: Label Free Language Model Routing", "link": "https://openreview.net/pdf%3Fid%3DpPSWHsgqRp", "details": "N Guha, MF Chen, T Chow, IS Khare, C Re - The Thirty-eighth Annual Conference on Neural \u2026", "abstract": "Large language models (LLMs) are increasingly used in applications where LLM inputs may span many different tasks. Recent work has found that the choice of LLM is consequential, and different LLMs may be good for different input samples. Prior \u2026"}, {"title": "SeRA: Self-Reviewing and Alignment of Large Language Models using Implicit Reward Margins", "link": "https://arxiv.org/pdf/2410.09362", "details": "J Ko, S Dingliwal, B Ganesh, S Sengupta, S Bodapati\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Direct alignment algorithms (DAAs), such as direct preference optimization (DPO), have become popular alternatives for Reinforcement Learning from Human Feedback (RLHF) due to their simplicity, efficiency, and stability. However, the \u2026"}, {"title": "Graph-based Uncertainty Metrics for Long-form Language Model Outputs", "link": "https://arxiv.org/pdf/2410.20783", "details": "M Jiang, Y Ruan, P Sattigeri, S Roukos, T Hashimoto - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly improved text generation capabilities, but these systems are still known to hallucinate, and granular uncertainty estimation for long-form LLM generations \u2026"}, {"title": "Fine-Tuning Large Language Models to Appropriately Abstain with Semantic Entropy", "link": "https://arxiv.org/pdf/2410.17234", "details": "BA Tjandra, M Razzak, J Kossen, K Handa, Y Gal - arXiv preprint arXiv:2410.17234, 2024", "abstract": "Large Language Models (LLMs) are known to hallucinate, whereby they generate plausible but inaccurate text. This phenomenon poses significant risks in critical applications, such as medicine or law, necessitating robust hallucination mitigation \u2026"}, {"title": "Graph-based Uncertainty Metrics for Long-form Language Model Generations", "link": "https://openreview.net/pdf%3Fid%3DYgJPQW0lkO", "details": "M Jiang, Y Ruan, P Sattigeri, S Roukos, T Hashimoto - The Thirty-eighth Annual \u2026, 2024", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly improved text generation capabilities, but these systems are still known to hallucinate, and granular uncertainty estimation for long-form LLM generations \u2026"}, {"title": "PoisonedParrot: Subtle Data Poisoning Attacks to Elicit Copyright-Infringing Content from Large Language Models", "link": "https://openreview.net/pdf%3Fid%3DZXgvPANlwe", "details": "MA Panaitescu-Liess, P Pathmanathan, Y Kaya, Z Che\u2026 - Neurips Safe Generative AI \u2026", "abstract": "As the capabilities of large language models (LLMs) continue to expand, their usage has become increasingly prevalent. However, as reflected in numerous ongoing lawsuits related to LLM-generated content, addressing copyright infringement \u2026"}, {"title": "Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models", "link": "https://arxiv.org/pdf/2410.19385", "details": "L Barkley, B van der Merwe - arXiv preprint arXiv:2410.19385, 2024", "abstract": "Large Language Models (LLMs) are powerful computational models trained on extensive corpora of human-readable text, enabling them to perform general- purpose language understanding and generation. LLMs have garnered significant \u2026"}]
