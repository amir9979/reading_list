[{"title": "Can Language Models Follow Multiple Turns of Entangled Instructions?", "link": "https://arxiv.org/pdf/2503.13222%3F", "details": "C Han - arXiv preprint arXiv:2503.13222, 2025", "abstract": "Despite significant achievements in improving the instruction-following capabilities of large language models (LLMs), the ability to process multiple potentially entangled or conflicting instructions remains a considerable challenge. Real-world scenarios \u2026"}, {"title": "How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?", "link": "https://arxiv.org/pdf/2504.02767", "details": "A Algaba, V Holst, F Tori, M Mobini, B Verbeken\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The spread of scientific knowledge depends on how researchers discover and cite previous work. The adoption of large language models (LLMs) in the scientific research process introduces a new layer to these citation practices. However, it \u2026"}, {"title": "Alignment for Efficient Tool Calling of Large Language Models", "link": "https://arxiv.org/pdf/2503.06708%3F", "details": "H Xu, Z Wang, Z Zhu, L Pan, X Chen, L Chen, K Yu - arXiv preprint arXiv:2503.06708, 2025", "abstract": "Recent advancements in tool learning have enabled large language models (LLMs) to integrate external tools, enhancing their task performance by expanding their knowledge boundaries. However, relying on tools often introduces tradeoffs between \u2026"}, {"title": "Reasoning Under 1 Billion: Memory-Augmented Reinforcement Learning for Large Language Models", "link": "https://arxiv.org/pdf/2504.02273", "details": "H Le, D Do, D Nguyen, S Venkatesh - arXiv preprint arXiv:2504.02273, 2025", "abstract": "Recent advances in fine-tuning large language models (LLMs) with reinforcement learning (RL) have shown promising improvements in complex reasoning tasks, particularly when paired with chain-of-thought (CoT) prompting. However, these \u2026"}, {"title": "XIFBench: Evaluating Large Language Models on Multilingual Instruction Following", "link": "https://arxiv.org/pdf/2503.07539%3F", "details": "Z Li, K Chen, Y Long, X Bai, Y Zhang, X Wei, J Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable instruction-following capabilities across various applications. However, their performance in multilingual settings remains poorly understood, as existing evaluations lack fine-grained \u2026"}, {"title": "Found In The Distribution: Utilizing Latent Dirichlet Allocation Improves Long Context Comprehension of Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10890215/", "details": "Z Guan, X Liang, S Zhang - ICASSP 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Large Language Models, even when specifically trained to process long input contexts, struggle to capture relevant information located in the middle of their input. This phenomenon is known as the\" lost-in-the-middle\" problem. In this study, We \u2026"}]
