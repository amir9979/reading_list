[{"title": "A General-Purpose Multimodal Foundation Model for Dermatology", "link": "https://arxiv.org/pdf/2410.15038", "details": "S Yan, Z Yu, C Primiero, C Vico-Alonso, Z Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Diagnosing and treating skin diseases require advanced visual skills across multiple domains and the ability to synthesize information from various imaging modalities. Current deep learning models, while effective at specific tasks such as diagnosing \u2026"}, {"title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models", "link": "https://arxiv.org/pdf/2410.18252", "details": "M Noukhovitch, S Huang, S Xhonneux, A Hosseini\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously generating from the large language model (LLM) policy, labelling with a reward model, and learning using feedback on the LLM's own outputs. While performant, this \u2026"}, {"title": "MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images", "link": "https://arxiv.org/pdf/2410.15881", "details": "P Meseguer, R del Amor, V Naranjo - arXiv preprint arXiv:2410.15881, 2024", "abstract": "Vision-language supervision has made remarkable strides in learning visual representations from textual guidance. In digital pathology, vision-language models (VLM), pre-trained on curated datasets of histological image-captions, have been \u2026"}, {"title": "Foundation Models for Slide-level Cancer Subtyping in Digital Pathology", "link": "https://arxiv.org/pdf/2410.15886", "details": "P Meseguer, R del Amor, A Colomer, V Naranjo - arXiv preprint arXiv:2410.15886, 2024", "abstract": "Since the emergence of the ImageNet dataset, the pretraining and fine-tuning approach has become widely adopted in computer vision due to the ability of ImageNet-pretrained models to learn a wide variety of visual features. However, a \u2026"}, {"title": "EchoApex: A General-Purpose Vision Foundation Model for Echocardiography", "link": "https://arxiv.org/pdf/2410.11092", "details": "AA Amadou, Y Zhang, S Piat, P Klein, I Schmuecking\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Quantitative evaluation of echocardiography is essential for precise assessment of cardiac condition, monitoring disease progression, and guiding treatment decisions. The diverse nature of echo images, including variations in probe types \u2026"}, {"title": "Vision Foundation Model Enables Generalizable Object Pose Estimation", "link": "https://openreview.net/forum%3Fid%3DFTpKGuxEfy", "details": "K Chen, Y Ma, X Lin, S James, J Zhou, YH Liu\u2026 - The Thirty-eighth Annual \u2026", "abstract": "Object pose estimation plays a crucial role in robotic manipulation, however, its practical applicability still suffers from limited generalizability. This paper addresses the challenge of generalizable object pose estimation, particularly focusing on \u2026"}]
