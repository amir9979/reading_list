[{"title": "RAG-Modulo: Solving Sequential Tasks using Experience, Critics, and Language Models", "link": "https://arxiv.org/pdf/2409.12294", "details": "A Jain, C Jermaine, V Unhelkar - arXiv preprint arXiv:2409.12294, 2024", "abstract": "Large language models (LLMs) have recently emerged as promising tools for solving challenging robotic tasks, even in the presence of action and observation uncertainties. Recent LLM-based decision-making methods (also referred to as LLM \u2026"}, {"title": "Aligning Language Models Using Follow-up Likelihood as Reward Signal", "link": "https://arxiv.org/pdf/2409.13948", "details": "C Zhang, D Chong, F Jiang, C Tang, A Gao, G Tang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In natural human-to-human conversations, participants often receive feedback signals from one another based on their follow-up reactions. These reactions can include verbal responses, facial expressions, changes in emotional state, and other \u2026"}, {"title": "RRM: Robust Reward Model Training Mitigates Reward Hacking", "link": "https://arxiv.org/pdf/2409.13156", "details": "T Liu, W Xiong, J Ren, L Chen, J Wu, R Joshi, Y Gao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. However, traditional RM training, which relies on response pairs tied to specific prompts, struggles to disentangle prompt-driven preferences \u2026"}, {"title": "Rule Extrapolation in Language Models: A Study of Compositional Generalization on OOD Prompts", "link": "https://arxiv.org/abs/2409.13728", "details": "A M\u00e9sz\u00e1ros, S Ujv\u00e1ry, W Brendel, P Reizinger\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "LLMs show remarkable emergent abilities, such as inferring concepts from presumably out-of-distribution prompts, known as in-context learning. Though this success is often attributed to the Transformer architecture, our systematic \u2026"}, {"title": "Investigating Layer Importance in Large Language Models", "link": "https://arxiv.org/pdf/2409.14381", "details": "Y Zhang, Y Dong, K Kawaguchi - arXiv preprint arXiv:2409.14381, 2024", "abstract": "Large language models (LLMs) have gained increasing attention due to their prominent ability to understand and process texts. Nevertheless, LLMs largely remain opaque. The lack of understanding of LLMs has obstructed the deployment in \u2026"}, {"title": "RAD-Bench: Evaluating Large Language Models Capabilities in Retrieval Augmented Dialogues", "link": "https://arxiv.org/pdf/2409.12558", "details": "TL Kuo, FT Liao, MW Hsieh, FC Chang, PC Hsu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In real-world applications with Large Language Models (LLMs), external retrieval mechanisms-such as Search-Augmented Generation (SAG), tool utilization, and Retrieval-Augmented Generation (RAG)-are often employed to enhance the quality \u2026"}, {"title": "Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data", "link": "https://arxiv.org/pdf/2409.12437", "details": "J Zhou, A Ghaddar, G Zhang, L Ma, Y Hu, S Pal\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite recent advances in training and prompting strategies for Large Language Models (LLMs), these models continue to face challenges with complex logical reasoning tasks that involve long reasoning chains. In this work, we explore the \u2026"}, {"title": "CITI: Enhancing Tool Utilizing Ability in Large Language Models without Sacrificing General Performance", "link": "https://arxiv.org/pdf/2409.13202", "details": "Y Hao, P Cao, Z Jin, H Liao, K Liu, J Zhao - arXiv preprint arXiv:2409.13202, 2024", "abstract": "Tool learning enables the Large Language Models (LLMs) to interact with the external environment by invoking tools, enriching the accuracy and capability scope of LLMs. However, previous works predominantly focus on improving model's tool \u2026"}, {"title": "RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code", "link": "https://arxiv.org/pdf/2409.15154", "details": "J Chen, Q Zhong, Y Wang, K Ning, Y Liu, Z Xu, Z Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence of Large Language Models (LLMs) has significantly influenced various aspects of software development activities. Despite their benefits, LLMs also pose notable risks, including the potential to generate harmful content and being \u2026"}]
