[{"title": "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction", "link": "https://arxiv.org/pdf/2409.16783", "details": "J Zhang, Y Zhou, Y Liu, Z Li, S Hu - arXiv preprint arXiv:2409.16783, 2024", "abstract": "Automated red teaming is an effective method for identifying misaligned behaviors in large language models (LLMs). Existing approaches, however, often focus primarily on improving attack success rates while overlooking the need for comprehensive test \u2026"}, {"title": "HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2409.16191", "details": "H Que, F Duan, L He, Y Mou, W Zhou, J Liu, W Rong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks (eg, long-context understanding), and many benchmarks have been proposed. However, we observe that long text generation capabilities are \u2026"}, {"title": "Investigating Layer Importance in Large Language Models", "link": "https://arxiv.org/pdf/2409.14381", "details": "Y Zhang, Y Dong, K Kawaguchi - arXiv preprint arXiv:2409.14381, 2024", "abstract": "Large language models (LLMs) have gained increasing attention due to their prominent ability to understand and process texts. Nevertheless, LLMs largely remain opaque. The lack of understanding of LLMs has obstructed the deployment in \u2026"}, {"title": "RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code", "link": "https://arxiv.org/pdf/2409.15154", "details": "J Chen, Q Zhong, Y Wang, K Ning, Y Liu, Z Xu, Z Zhao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The emergence of Large Language Models (LLMs) has significantly influenced various aspects of software development activities. Despite their benefits, LLMs also pose notable risks, including the potential to generate harmful content and being \u2026"}, {"title": "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models", "link": "https://arxiv.org/pdf/2409.18943", "details": "J Li, L Zhang, Y Li, Z Liu, R Luo, L Chen, M Yang - arXiv preprint arXiv:2409.18943, 2024", "abstract": "The instruction-following ability of large language models enables humans to interact with AI agents in a natural way. However, when required to generate responses of a specific length, large language models often struggle to meet users' needs due to \u2026"}, {"title": "CITI: Enhancing Tool Utilizing Ability in Large Language Models without Sacrificing General Performance", "link": "https://arxiv.org/pdf/2409.13202", "details": "Y Hao, P Cao, Z Jin, H Liao, K Liu, J Zhao - arXiv preprint arXiv:2409.13202, 2024", "abstract": "Tool learning enables the Large Language Models (LLMs) to interact with the external environment by invoking tools, enriching the accuracy and capability scope of LLMs. However, previous works predominantly focus on improving model's tool \u2026"}, {"title": "Predicting and analyzing memorization within fine-tuned Large Language Models", "link": "https://arxiv.org/pdf/2409.18858", "details": "J Dentan, D Buscaldi, A Shabou, S Vanier - arXiv preprint arXiv:2409.18858, 2024", "abstract": "Large Language Models have received significant attention due to their abilities to solve a wide range of complex tasks. However these models memorize a significant proportion of their training data, posing a serious threat when disclosed at inference \u2026"}, {"title": "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method", "link": "https://arxiv.org/pdf/2409.14781", "details": "W Zhang, R Zhang, J Guo, M de Rijke, Y Fan, X Cheng - arXiv preprint arXiv \u2026, 2024", "abstract": "As the scale of training corpora for large language models (LLMs) grows, model developers become increasingly reluctant to disclose details on their data. This lack of transparency poses challenges to scientific evaluation and ethical deployment \u2026"}, {"title": "Enhancing Advanced Visual Reasoning Ability of Large Language Models", "link": "https://arxiv.org/pdf/2409.13980", "details": "Z Li, D Liu, C Zhang, H Wang, T Xue, W Cai - arXiv preprint arXiv:2409.13980, 2024", "abstract": "Recent advancements in Vision-Language (VL) research have sparked new benchmarks for complex visual reasoning, challenging models' advanced reasoning ability. Traditional Vision-Language Models (VLMs) perform well in visual perception \u2026"}]
