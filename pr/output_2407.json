[{"title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models", "link": "https://arxiv.org/pdf/2406.02224", "details": "T Fan, G Ma, Y Kang, H Gu, L Fan, Q Yang - arXiv preprint arXiv:2406.02224, 2024", "abstract": "Recent research in federated large language models (LLMs) has primarily focused on enabling clients to fine-tune their locally deployed homogeneous LLMs collaboratively or on transferring knowledge from server-based LLMs to small \u2026"}, {"title": "Knowledge-grounded Adaptation Strategy for Vision-language Models: Building Unique Case-set for Screening Mammograms for Residents Training", "link": "https://arxiv.org/pdf/2405.19675", "details": "AU Khan, J Garrett, T Bradshaw, L Salkowski, JJ Jeong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "A visual-language model (VLM) pre-trained on natural images and text pairs poses a significant barrier when applied to medical contexts due to domain shift. Yet, adapting or fine-tuning these VLMs for medical use presents considerable hurdles \u2026"}, {"title": "Super Tiny Language Models", "link": "https://arxiv.org/pdf/2405.14159", "details": "D Hillier, L Guertler, C Tan, P Agrawal, C Ruirui\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large language models (LLMs) has led to significant improvements in natural language processing but also poses challenges due to their high computational and energy demands. This paper introduces a series of research \u2026"}, {"title": "Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for Electronic Health Records", "link": "https://aclanthology.org/2024.cl4health-1.23.pdf", "details": "J Lov\u00f3n-Melgarejo, T Ben-Haddi, J Di Scala\u2026 - Proceedings of the First \u2026, 2024", "abstract": "The lack of standardized evaluation benchmarks in the medical domain for text inputs can be a barrier to widely adopting and leveraging the potential of natural language models for health-related downstream tasks. This paper revisited an \u2026"}, {"title": "UIT-DarkCow team at ImageCLEFmedical Caption 2024: Diagnostic Captioning for Radiology Images Efficiency with Transformer Models", "link": "https://arxiv.org/pdf/2405.17002", "details": "Q Van Nguyen, QH Pham, DQ Tran, TKB Nguyen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Purpose: This study focuses on the development of automated text generation from radiology images, termed diagnostic captioning, to assist medical professionals in reducing clinical errors and improving productivity. The aim is to provide tools that \u2026"}, {"title": "CorpusLM: Towards a Unified Language Model on Corpus for Knowledge-Intensive Tasks", "link": "https://www.zhouyujia.cn/attaches/SIGIR2024_CorpusLM.pdf", "details": "X Li, Z Dou, Y Zhou, F Liu - 2024", "abstract": "Large language models (LLMs) have gained significant attention in various fields but prone to hallucination, especially in knowledgeintensive (KI) tasks. To address this, retrieval-augmented generation (RAG) has emerged as a popular solution to \u2026"}, {"title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2405.07551", "details": "S Yin, W You, Z Ji, G Zhong, J Bai - arXiv preprint arXiv:2405.07551, 2024", "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math \u2026"}, {"title": "CAM: A cross-lingual adaptation framework for low-resource language speech recognition", "link": "https://www.sciencedirect.com/science/article/pii/S1566253524002847", "details": "Q Hu, Y Zhang, X Zhang, Z Han, X Yu - Information Fusion, 2024", "abstract": "In this paper, a novel cross-lingual adaptation framework called CAM is presented for low-resource language speech recognition (LLSR). It is based on the recent popular adapter method. CAM is achieved by adapting self-supervised speech models \u2026"}]
