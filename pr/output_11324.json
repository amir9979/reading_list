[{"title": "GIT-CXR: End-to-End Transformer for Chest X-Ray Report Generation", "link": "https://arxiv.org/pdf/2501.02598", "details": "I S\u00eerbu, IR S\u00eerbu, J Bogojeska, T Rebedea - arXiv preprint arXiv:2501.02598, 2025", "abstract": "Medical imaging is crucial for diagnosing, monitoring, and treating medical conditions. The medical reports of radiology images are the primary medium through which medical professionals attest their findings, but their writing is time consuming \u2026"}, {"title": "Open-world Multi-modal Machine Learning Decision Model Based on Uncertain Data Analysis for Fetal Heart Diagnosis", "link": "https://www.sciencedirect.com/science/article/pii/S0020025524017821", "details": "G Zhu, Z Qin, H Xiong, S Kumari, MJF Alenazi, Y Guo\u2026 - Information Sciences, 2025", "abstract": "Abstract Machine learning-generated diagnostic decision for fetal heart screening can assist doctors in diagnosing fetal conditions more quickly and accurately. However, due to the uncertainties in fetal heart data, there has always been a gap in \u2026"}, {"title": "Attention enhanced residual network for automatic pulmonary tuberculosis detection on chest radiographs images", "link": "https://www.sciencedirect.com/science/article/pii/S1051200424005992", "details": "Y Liu, F Liu, S Tu, S Liu, B Han - Digital Signal Processing, 2025", "abstract": "Pulmonary tuberculosis (TB) is a common disease in developing countries that spreads through direct contact or through the air. Early detection of people with tuberculosis plays a key role in preventing transmission and saving costs ultimately \u2026"}, {"title": "2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining", "link": "https://arxiv.org/pdf/2501.00958", "details": "W Zhang, H Zhang, X Li, J Sun, Y Shen, W Lu, D Zhao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Compared to image-text pair data, interleaved corpora enable Vision-Language Models (VLMs) to understand the world more naturally like humans. However, such existing datasets are crawled from webpage, facing challenges like low knowledge \u2026"}, {"title": "Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models", "link": "https://arxiv.org/pdf/2412.18609%3F", "details": "J Yi, ST Wasim, Y Luo, M Naseer, J Gall - arXiv preprint arXiv:2412.18609, 2024", "abstract": "We present an efficient encoder-free approach for video-language understanding that achieves competitive performance while significantly reducing computational overhead. Current video-language models typically rely on heavyweight image \u2026"}, {"title": "SAT: Spatial Aptitude Training for Multimodal Language Models", "link": "https://arxiv.org/pdf/2412.07755", "details": "A Ray, J Duan, R Tan, D Bashkirova, R Hendrix\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Spatial perception is a fundamental component of intelligence. While many studies highlight that large multimodal language models (MLMs) struggle to reason about space, they only test for static spatial reasoning, such as categorizing the relative \u2026"}, {"title": "MMFactory: A Universal Solution Search Engine for Vision-Language Tasks", "link": "https://arxiv.org/pdf/2412.18072", "details": "WC Fan, T Rahman, L Sigal - arXiv preprint arXiv:2412.18072, 2024", "abstract": "With advances in foundational and vision-language models, and effective fine-tuning techniques, a large number of both general and special-purpose models have been developed for a variety of visual tasks. Despite the flexibility and accessibility of these \u2026"}, {"title": "NSEC-YOLO: Real-time lesion detection on chest X-ray with adaptive noise suppression and global perception aggregation", "link": "https://www.sciencedirect.com/science/article/pii/S1687850724004655", "details": "XY Zhang, LJ Liu, X Yang, L Liu, W Peng - Journal of Radiation Research and Applied \u2026, 2025", "abstract": "Chest diseases significantly threaten respiratory health, making early and accurate diagnosis essential for improving patient survival rates. Traditional detection methods face difficulties in accurately identifying and localizing chest lesions \u2026"}, {"title": "ICONS: Influence Consensus for Vision-Language Data Selection", "link": "https://arxiv.org/pdf/2501.00654", "details": "X Wu, M Xia, R Shao, Z Deng, PW Koh, O Russakovsky - arXiv preprint arXiv \u2026, 2024", "abstract": "Visual Instruction Tuning typically requires a large amount of vision-language training data. This data often containing redundant information that increases computational costs without proportional performance gains. In this work, we \u2026"}]
