'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [Fine-Tuning Large Vision-Language Models as Decision-Making '
[{"title": "Balancing Similarity and Complementarity for Federated Learning", "link": "https://arxiv.org/pdf/2405.09892", "details": "K Yan, S Cui, A Wuerkaixi, J Zhang, B Han, G Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In mobile and IoT systems, Federated Learning (FL) is increasingly important for effectively using data while maintaining user privacy. One key challenge in FL is managing statistical heterogeneity, such as non-iid data, arising from numerous \u2026"}, {"title": "Eyes Can Deceive: Benchmarking Counterfactual Reasoning Abilities of Multi-modal Large Language Models", "link": "https://arxiv.org/pdf/2404.12966", "details": "Y Li, W Tian, Y Jiao, J Chen, YG Jiang - arXiv preprint arXiv:2404.12966, 2024", "abstract": "Counterfactual reasoning, as a crucial manifestation of human intelligence, refers to making presuppositions based on established facts and extrapolating potential outcomes. Existing multimodal large language models (MLLMs) have exhibited \u2026"}, {"title": "Graph learning with label attention and hyperbolic embedding for temporal event prediction in healthcare", "link": "https://napier-repository.worktribe.com/preview/3635477/1-s2.0-S0925231224005071-main.pdf", "details": "U Naseem, S Thapa, Q Zhang, S Wang, J Rashid, L Hu\u2026 - Neurocomputing, 2024", "abstract": "The digitization of healthcare systems has led to the proliferation of electronic health records (EHRs), serving as comprehensive repositories of patient information. However, the vast volume and complexity of EHR data present challenges in \u2026"}, {"title": "Comparison of Pretrained Models for Optimized Transformer Based Question Answering System", "link": "https://ieeexplore.ieee.org/abstract/document/10527306/", "details": "T Gokcimen, B Das - 2024 12th International Symposium on Digital \u2026, 2024", "abstract": "This study delves into the evaluation and optimization of transformer-based models for question-answering systems, focusing on health-related inquiries. Utilizing a specialized dataset extracted from Wikipedia articles, transformer models, namely \u2026"}, {"title": "MedDr: Diagnosis-Guided Bootstrapping for Large-Scale Medical Vision-Language Learning", "link": "https://arxiv.org/pdf/2404.15127", "details": "S He, Y Nie, Z Chen, Z Cai, H Wang, S Yang, H Chen - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advancement of large-scale vision-language models has showcased remarkable capabilities across various tasks. However, the lack of extensive and high-quality image-text data in medicine has greatly hindered the development of \u2026"}, {"title": "EPI-SQL: Enhancing Text-to-SQL Translation with Error-Prevention Instructions", "link": "https://arxiv.org/pdf/2404.14453", "details": "X Liu, Z Tan - arXiv preprint arXiv:2404.14453, 2024", "abstract": "The conversion of natural language queries into SQL queries, known as Text-to-SQL, is a critical yet challenging task. This paper introduces EPI-SQL, a novel methodological framework leveraging Large Language Models (LLMs) to enhance \u2026"}, {"title": "Predicting future disorders via temporal knowledge graphs and medical ontologies", "link": "https://ieeexplore.ieee.org/iel7/6221020/6363502/10504898.pdf", "details": "M Postiglione, D Bean, Z Kraljevic, RJB Dobson\u2026 - IEEE Journal of Biomedical \u2026, 2024", "abstract": "Despite the vast potential for insights and value present in Electronic Health Records (EHRs), it is challenging to fully leverage all the available information, particularly that contained in the free-text data written by clinicians describing the health status of \u2026"}, {"title": "Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering", "link": "https://arxiv.org/pdf/2404.14464", "details": "L Jiapeng, L Runze, L Yabo, Z Tong, L Mingling\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multi-hop question answering is a knowledge-intensive complex problem. Large Language Models (LLMs) use their Chain of Thoughts (CoT) capability to reason complex problems step by step, and retrieval-augmentation can effectively alleviate \u2026"}, {"title": "Enabling action crossmodality for a pretrained large language model", "link": "https://www.sciencedirect.com/science/article/pii/S2949719124000207", "details": "A Caesar, O \u00d6zdemir, C Weber, S Wermter - Natural Language Processing Journal, 2024", "abstract": "Natural language processing and vision tasks have seen large improvements recently through the rise of Transformer architectures. The high performing large language models (LLMs) benefit from large textual datasets that are numerously \u2026"}]
