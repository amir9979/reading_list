[{"title": "Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models", "link": "https://arxiv.org/pdf/2405.09605", "details": "AA Ivanova, A Sathe, B Lipkin, U Kumar, S Radkani\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The ability to build and leverage world models is essential for a general-purpose AI agent. Testing such capabilities is hard, in part because the building blocks of world models are ill-defined. We present Elements of World Knowledge (EWOK), a \u2026"}, {"title": "An in-depth evaluation of federated learning on biomedical natural language processing for information extraction", "link": "https://www.nature.com/articles/s41746-024-01126-4", "details": "L Peng, G Luo, S Zhou, J Chen, Z Xu, J Sun, R Zhang - NPJ Digital Medicine, 2024", "abstract": "Abstract Language models (LMs) such as BERT and GPT have revolutionized natural language processing (NLP). However, the medical field faces challenges in training LMs due to limited data access and privacy constraints imposed by \u2026"}, {"title": "Advancing Delirium Classification: A Clinical Notes-based Natural Language Processing-Supported Machine Learning Model", "link": "https://www.sciencedirect.com/science/article/pii/S2666521224000073", "details": "S Amjad, NE Holmes, K Kishore, M Young, J Bailey\u2026 - Intelligence-Based Medicine, 2024", "abstract": "Objective The study of the epidemiology of delirium in hospitalized patients is challenging. We aimed to identify the presence or absence of delirium from clinical text notes using natural language processing (NLP) techniques and machine \u2026"}, {"title": "NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition", "link": "https://arxiv.org/pdf/2405.07609", "details": "E Merdjanovska, A Aynetdinov, A Akbik - arXiv preprint arXiv:2405.07609, 2024", "abstract": "Available training data for named entity recognition (NER) often contains a significant percentage of incorrect labels for entity types and entity boundaries. Such label noise poses challenges for supervised learning and may significantly deteriorate model \u2026"}, {"title": "Exploring Activation Patterns of Parameters in Language Models", "link": "https://arxiv.org/pdf/2405.17799", "details": "Y Wang, D Dai, Z Sui - arXiv preprint arXiv:2405.17799, 2024", "abstract": "Most work treats large language models as black boxes without in-depth understanding of their internal working mechanism. In order to explain the internal representations of LLMs, we propose a gradient-based metric to assess the \u2026"}, {"title": "Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models", "link": "https://arxiv.org/pdf/2405.10431", "details": "S Furniturewala, S Jandial, A Java, P Banerjee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Existing debiasing techniques are typically training-based or require access to the model's internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine \u2026"}, {"title": "Characterizing the Accuracy-Efficiency Trade-off of Low-rank Decomposition in Language Models", "link": "https://arxiv.org/pdf/2405.06626", "details": "C Moar, M Pellauer, H Kwon - arXiv preprint arXiv:2405.06626, 2024", "abstract": "Large language models (LLMs) have emerged and presented their general problem- solving capabilities with one model. However, the model size has increased dramatically with billions of parameters to enable such broad problem-solving \u2026"}, {"title": "GRAMMAR: Grounded and Modular Evaluation of Domain-Specific Retrieval-Augmented Language Models", "link": "https://arxiv.org/pdf/2404.19232", "details": "X Li, M Liu, S Gao - arXiv preprint arXiv:2404.19232, 2024", "abstract": "Retrieval-augmented Generation (RAG) systems have been actively studied and deployed across various industries to query on domain-specific knowledge base. However, evaluating these systems presents unique challenges due to the scarcity of \u2026"}, {"title": "Frustratingly Easy Test-Time Adaptation of Vision-Language Models", "link": "https://arxiv.org/pdf/2405.18330", "details": "M Farina, G Franchi, G Iacca, M Mancini, E Ricci - arXiv preprint arXiv:2405.18330, 2024", "abstract": "Vision-Language Models seamlessly discriminate among arbitrary semantic categories, yet they still suffer from poor generalization when presented with challenging examples. For this reason, Episodic Test-Time Adaptation (TTA) \u2026"}]
