[{"title": "LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models", "link": "https://arxiv.org/pdf/2411.09595", "details": "Z Wang, J Lorraine, Y Wang, H Su, J Zhu, S Fidler\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived \u2026"}, {"title": "Association Between Patient Portal Engagement and Weight Loss Outcomes in Patients After Bariatric Surgery: Longitudinal Observational Study Using Electronic \u2026", "link": "https://www.jmir.org/2024/1/e56573/", "details": "X Zhang, K Kang, C Yan, Y Feng, S Vandekar, D Yu\u2026 - Journal of Medical Internet \u2026, 2024", "abstract": "Background Bariatric surgery is an effective intervention for obesity, but comprehensive postoperative self-management is essential for optimal outcomes. While patient portals are generally seen as beneficial in engaging patients in health \u2026"}, {"title": "Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model", "link": "https://arxiv.org/pdf/2412.04729", "details": "KP Yu, A Dave, R Ambrus, J Mercat - arXiv preprint arXiv:2412.04729, 2024", "abstract": "Most of the current vision-language models (VLMs) for videos struggle to understand videos longer than a few seconds. This is primarily due to the fact that they do not scale to utilizing a large number of frames. In order to address this limitation, we \u2026"}, {"title": "The Vulnerability of Language Model Benchmarks: Do They Accurately Reflect True LLM Performance?", "link": "https://arxiv.org/pdf/2412.03597", "details": "S Banerjee, A Agarwal, E Singh - arXiv preprint arXiv:2412.03597, 2024", "abstract": "The pursuit of leaderboard rankings in Large Language Models (LLMs) has created a fundamental paradox: models excel at standardized tests while failing to demonstrate genuine language understanding and adaptability. Our systematic \u2026"}]
