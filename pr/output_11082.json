[{"title": "Read Like a Radiologist: Efficient Vision-Language Model for 3D Medical Imaging Interpretation", "link": "https://arxiv.org/pdf/2412.13558", "details": "C Lee, S Park, CI Shin, WH Choi, HJ Park, JE Lee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recent medical vision-language models (VLMs) have shown promise in 2D medical image interpretation. However extending them to 3D medical imaging has been challenging due to computational complexities and data scarcity. Although a few \u2026"}, {"title": "Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning", "link": "https://arxiv.org/pdf/2412.08614", "details": "F Lu, W Wu, K Zheng, S Ma, B Gong, J Liu, W Zhai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Generating detailed captions comprehending text-rich visual content in images has received growing attention for Large Vision-Language Models (LVLMs). However, few studies have developed benchmarks specifically tailored for detailed captions to \u2026"}, {"title": "PVC: Progressive Visual Token Compression for Unified Image and Video Processing in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2412.09613%3F", "details": "C Yang, X Dong, X Zhu, W Su, J Wang, H Tian, Z Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Vision-Language Models (VLMs) have been extended to understand both images and videos. Visual token compression is leveraged to reduce the considerable token length of visual inputs. To meet the needs of different tasks \u2026"}, {"title": "HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding", "link": "https://arxiv.org/pdf/2412.16158", "details": "C Tao, S Su, X Zhu, C Zhang, Z Chen, J Liu, W Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The rapid advance of Large Language Models (LLMs) has catalyzed the development of Vision-Language Models (VLMs). Monolithic VLMs, which avoid modality-specific encoders, offer a promising alternative to the compositional ones \u2026"}, {"title": "VisionZip: Longer is Better but Not Necessary in Vision Language Models", "link": "https://arxiv.org/pdf/2412.04467", "details": "S Yang, Y Chen, Z Tian, C Wang, J Li, B Yu, J Jia - arXiv preprint arXiv:2412.04467, 2024", "abstract": "Recent advancements in vision-language models have enhanced performance by increasing the length of visual tokens, making them much longer than text tokens and significantly raising computational costs. However, we observe that the visual tokens \u2026"}, {"title": "Enhancing radiology report generation through pre-trained language models", "link": "https://link.springer.com/article/10.1007/s13748-024-00358-5", "details": "G Leonardi, L Portinale, A Santomauro - Progress in Artificial Intelligence, 2024", "abstract": "In the healthcare field, the ability to integrate and process data from various modalities, such as medical images, clinical notes, and patient records, plays a central role in enabling Artificial Intelligence models to provide more informed \u2026"}, {"title": "Synthetic Vision: Training Vision-Language Models to Understand Physics", "link": "https://arxiv.org/pdf/2412.08619", "details": "V Balazadeh, M Ataei, H Cheong, AH Khasahmadi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Physical reasoning, which involves the interpretation, understanding, and prediction of object behavior in dynamic environments, remains a significant challenge for current Vision-Language Models (VLMs). In this work, we propose two methods to \u2026"}, {"title": "Contrastive concept-phrase pre-training for generating clinically accurate and interpretable chest X-ray reports", "link": "https://link.springer.com/article/10.1007/s00521-024-10640-1", "details": "A Tubaishat, T Zia, D Windridge, M Nawaz, S Razzaq - Neural Computing and \u2026, 2024", "abstract": "Automated radiology report generation is an emerging field for improving patient care and alleviating radiologist workload. However, existing methods face a range of challenges such as limited data availability, clinical metric performance, and \u2026"}, {"title": "Adversarial Neural Radiance Networks: A Unified Approach for High-Quality Image Synthesis and 3D Scene Representation", "link": "https://www.researchgate.net/profile/Matthew-White-61/publication/387538505_Adversarial_Neural_Radiance_Networks_A_Unified_Approach_for_High-Quality_Image_Synthesis_and_3D_Scene_Representation/links/67733b2ffb9aff6eaaf8c204/Adversarial-Neural-Radiance-Networks-A-Unified-Approach-for-High-Quality-Image-Synthesis-and-3D-Scene-Representation.pdf", "details": "J Martin, S Harris, M White", "abstract": "Generative Adversarial Networks (GANs) have revolutionized the field of generative modeling, providing powerful tools for synthesizing realistic and high-quality images. Since their introduction by Goodfellow et al. in 2014, GANs have demonstrated \u2026"}]
