[{"title": "Leveraging large language models for structured information extraction from pathology reports", "link": "https://arxiv.org/pdf/2502.12183", "details": "JB Balasubramanian, D Adams, I Roxanis\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Background: Structured information extraction from unstructured histopathology reports facilitates data accessibility for clinical research. Manual extraction by experts is time-consuming and expensive, limiting scalability. Large language models \u2026"}, {"title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models", "link": "https://arxiv.org/pdf/2502.06663", "details": "X Xing, Z Liu, S Xiao, B Gao, Y Liang, W Zhang, H Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge \u2026"}, {"title": "Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function", "link": "https://arxiv.org/pdf/2502.03591", "details": "M Asadi, K Sodok\u00e9, IJ Gerard, M Kersten-Oertel - arXiv preprint arXiv:2502.03591, 2025", "abstract": "In this work, we present a novel approach to multi-label chest X-ray (CXR) image classification that enhances clinical interpretability while maintaining a streamlined, single-model, single-run training pipeline. Leveraging the CheXpert dataset and \u2026"}, {"title": "Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More", "link": "https://arxiv.org/pdf/2502.11494", "details": "Z Wen, Y Gao, S Wang, J Zhang, Q Zhang, W Li, C He\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision tokens in multimodal large language models often dominate huge computational overhead due to their excessive length compared to linguistic modality. Abundant recent methods aim to solve this problem with token pruning \u2026"}, {"title": "Evaluating automated radiology reports", "link": "https://www.mecha-health.ai/blog/Evaluating-automated-radiology-reports", "details": "A Abdulaal, A Ijishakin, NM Brown", "abstract": "Automated radiology report generation can reduce radiologists' workload and enhance patient care, yet its adoption in clinical practice remains limited [1]. A key challenge is assessing the clinical quality of generated reports. This update explores \u2026"}, {"title": "Rethinking Homogeneity of Vision and Text Tokens in Large Vision-and-Language Models", "link": "https://arxiv.org/pdf/2502.01906", "details": "CW Kuo, S Zhu, F Chen, X Shen, L Wen - arXiv preprint arXiv:2502.01906, 2025", "abstract": "Large vision-and-language models (LVLMs) typically treat visual and textual embeddings as homogeneous inputs to a large language model (LLM). However, these inputs are inherently different: visual inputs are multi-dimensional and \u2026"}, {"title": "Minerva: A Programmable Memory Test Benchmark for Language Models", "link": "https://arxiv.org/pdf/2502.03358%3F", "details": "M Xia, V Ruehle, S Rajmohan, R Shokri - arXiv preprint arXiv:2502.03358, 2025", "abstract": "How effectively can LLM-based AI assistants utilize their memory (context) to perform various tasks? Traditional data benchmarks, which are often manually crafted, suffer from several limitations: they are static, susceptible to overfitting, difficult to interpret \u2026"}, {"title": "Every Expert Matters: Towards Effective Knowledge Distillation for Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2502.12947", "details": "G Kim, G Chu, E Yang - arXiv preprint arXiv:2502.12947, 2025", "abstract": "With the emergence of Mixture-of-Experts (MoE), the efficient scaling of model size has accelerated the development of large language models in recent years. However, their high memory requirements prevent their use in resource-constrained \u2026"}, {"title": "Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification", "link": "https://arxiv.org/pdf/2501.19086%3F", "details": "X Sun, X Zou, Y Wu, G Wang, S Zhang - arXiv preprint arXiv:2501.19086, 2025", "abstract": "X-ray imaging is pivotal in medical diagnostics, offering non-invasive insights into a range of health conditions. Recently, vision-language models, such as the Contrastive Language-Image Pretraining (CLIP) model, have demonstrated potential \u2026"}]
