[{"title": "Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?", "link": "https://arxiv.org/pdf/2410.23856", "details": "Z Zhou, R Tao, J Zhu, Y Luo, Z Wang, B Han - arXiv preprint arXiv:2410.23856, 2024", "abstract": "This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We \u2026"}, {"title": "Fine-grained Pluggable Gradient Ascent for Knowledge Unlearning in Language Models", "link": "https://aclanthology.org/2024.emnlp-main.566.pdf", "details": "XH Feng, C Chen, Y Li, Z Lin - Proceedings of the 2024 Conference on Empirical \u2026, 2024", "abstract": "Pre-trained language models acquire knowledge from vast amounts of text data, which can inadvertently contain sensitive information. To mitigate the presence of undesirable knowledge, the task of knowledge unlearning becomes crucial for \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}, {"title": "Text2Afford: Probing Object Affordance Prediction abilities of Language Models solely from Text", "link": "https://aclanthology.org/2024.conll-1.27.pdf", "details": "S Adak, D Agrawal, A Mukherjee, S Aditya - Proceedings of the 28th Conference on \u2026, 2024", "abstract": "We investigate the knowledge of object affordances in pre-trained language models (LMs) and pre-trained Vision-Language models (VLMs). A growing body of literature shows that PTLMs fail inconsistently and non-intuitively, demonstrating a lack of \u2026"}, {"title": "Assisted Few-Shot Learning for Vision-Language Models in Agricultural Stress Phenotype Identification", "link": "https://openreview.net/pdf%3Fid%3DWutpswD3ea", "details": "MA Arshad, TZ Jubery, AK Singh, A Singh, C Hegde\u2026 - Adaptive Foundation Models \u2026", "abstract": "In the agricultural sector, labeled data for crop diseases and stresses are often scarce due to high annotation costs. We propose an Assisted Few-Shot Learning approach to enhance vision-language models (VLMs) for image classification tasks \u2026"}, {"title": "Axes of Robustness of Neural Language Models", "link": "https://is.muni.cz/th/m805b/PhD_thesis_Michal_Stefanik.pdf", "details": "M \u0160TEF\u00c1NIK", "abstract": "In recent years, language models have emerged into a technology adopted in a wide variety of applications, nowadays largely exceeding traditional natural language processing tasks. Thanks to their versatility and adaptability, modern language \u2026"}, {"title": "Structured Codes and Free-Text Notes: Measuring Information Complementarity in Electronic Health Records", "link": "https://www.medrxiv.org/content/10.1101/2024.10.28.24316294.full.pdf", "details": "TM Seinen, JA Kors, EM van mulligen, PR Rijnbeek - medRxiv, 2024", "abstract": "Background: Electronic health records (EHRs) consist of both structured data (eg, diagnostic codes) and unstructured data (eg, clinical notes). It's commonly believed that unstructured clinical narratives provide more comprehensive information \u2026"}, {"title": "How Far Can We Extract Diverse Perspectives from Large Language Models?", "link": "https://aclanthology.org/2024.emnlp-main.306.pdf", "details": "S Hayati, M Lee, D Rajagopal, D Kang - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "Collecting diverse human opinions is costly and challenging. This leads to a recent trend in exploiting large language models (LLMs) for generating diverse data for potential scalable and efficient solutions. However, the extent to which LLMs can \u2026"}, {"title": "Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2410.21728", "details": "K Luo, Z Ding, Z Weng, L Qiao, M Zhao, X Li, D Yin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While Chain of Thought (CoT) prompting approaches have significantly consolidated the reasoning capabilities of large language models (LLMs), they still face limitations that require extensive human effort or have performance needs to be improved \u2026"}]
