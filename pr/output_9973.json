[{"title": "Rapid Response: Mitigating LLM Jailbreaks with a Few Examples", "link": "https://arxiv.org/pdf/2411.07494", "details": "A Peng, J Michael, H Sleight, E Perez, M Sharma - arXiv preprint arXiv:2411.07494, 2024", "abstract": "As large language models (LLMs) grow more powerful, ensuring their safety against misuse becomes crucial. While researchers have focused on developing robust defenses, no method has yet achieved complete invulnerability to attacks. We \u2026"}]
