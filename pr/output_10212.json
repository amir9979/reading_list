[{"title": "Distributed, communication-efficient, and differentially private estimation of KL divergence", "link": "https://arxiv.org/pdf/2411.16478%3F", "details": "M Scott, S Biswas, G Cormode, C Maple - arXiv preprint arXiv:2411.16478, 2024", "abstract": "A key task in managing distributed, sensitive data is to measure the extent to which a distribution changes. Understanding this drift can effectively support a variety of federated learning and analytics tasks. However, in many practical settings sharing \u2026"}, {"title": "Visual Text Generation in the Wild", "link": "https://link.springer.com/content/pdf/10.1007/978-3-031-73668-1_6.pdf", "details": "X Wang, P Wang, F Huang, C Yao", "abstract": "Recently, with the rapid advancements of generative models, the field of visual text generation has witnessed significant progress. However, it is still challenging to render high-quality text images in realworld scenarios, as three critical criteria should \u2026"}, {"title": "PrivAgent: Agentic-based Red-teaming for LLM Privacy Leakage", "link": "https://arxiv.org/pdf/2412.05734", "details": "Y Nie, Z Wang, Y Yu, X Wu, X Zhao, W Guo, D Song - arXiv preprint arXiv:2412.05734, 2024", "abstract": "Recent studies have discovered that LLMs have serious privacy leakage concerns, where an LLM may be fooled into outputting private information under carefully crafted adversarial prompts. These risks include leaking system prompts, personally \u2026"}]
