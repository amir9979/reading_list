[{"title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs", "link": "https://arxiv.org/pdf/2503.01743%3F", "details": "A Abouelenin, A Ashfaq, A Atkinson, H Awadalla\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality web and synthetic data, significantly outperforming recent \u2026"}, {"title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models", "link": "https://arxiv.org/pdf/2503.05005", "details": "B Jamialahmadi, P Kavehzadeh, M Rezagholizadeh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Deploying large language models (LLMs) in real-world applications is often hindered by strict computational and latency constraints. While dynamic inference offers the flexibility to adjust model behavior based on varying resource budgets, existing \u2026"}, {"title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models", "link": "https://arxiv.org/pdf/2503.01464", "details": "B Nazarov, D Frolova, Y Lubarsky, A Gaissinski\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed on domain-specific data has shown significant promise. However, commercial use of such LLMs is limited by the high computational cost required for their deployment at \u2026"}, {"title": "SAIF: A Sparse Autoencoder Framework for Interpreting and Steering Instruction Following of Language Models", "link": "https://arxiv.org/pdf/2502.11356", "details": "Z He, H Zhao, Y Qiao, F Yang, A Payani, J Ma, M Du - arXiv preprint arXiv \u2026, 2025", "abstract": "The ability of large language models (LLMs) to follow instructions is crucial for their practical applications, yet the underlying mechanisms remain poorly understood. This paper presents a novel framework that leverages sparse autoencoders (SAE) to \u2026"}, {"title": "Adaptive Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge", "link": "https://arxiv.org/pdf/2502.13010%3F", "details": "MR Rezaei, RS Fard, J Parker, RG Krishnan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have significantly advanced medical question- answering by leveraging extensive clinical data and medical literature. However, the rapid evolution of medical knowledge and the labor-intensive process of manually \u2026"}, {"title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models", "link": "https://arxiv.org/pdf/2502.21321", "details": "K Kumar, T Ashraf, O Thawakar, RM Anwer\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have transformed the natural language processing landscape and brought to life diverse applications. Pretraining on vast web-scale data has laid the foundation for these models, yet the research community is now \u2026"}, {"title": "Smoothing Out Hallucinations: Mitigating LLM Hallucination with Smoothed Knowledge Distillation", "link": "https://arxiv.org/pdf/2502.11306", "details": "H Nguyen, Z He, SA Gandre, U Pasupulety\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) often suffer from hallucination, generating factually incorrect or ungrounded content, which limits their reliability in high-stakes applications. A key factor contributing to hallucination is the use of hard labels during \u2026"}, {"title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies", "link": "https://arxiv.org/pdf/2502.08554", "details": "SSY Kim, JW Vaughan, QV Liao, T Lombrozo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study \u2026"}, {"title": "Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering", "link": "https://arxiv.org/pdf/2502.06193", "details": "R Wang, J Guo, C Gao, G Fan, CY Chong, X Xia - arXiv preprint arXiv:2502.06193, 2025", "abstract": "Recently, large language models (LLMs) have been deployed to tackle various software engineering (SE) tasks like code generation, significantly advancing the automation of SE tasks. However, assessing the quality of these LLM-generated \u2026"}]
