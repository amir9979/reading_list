[{"title": "Generalization vs Memorization: Tracing Language Models' Capabilities Back to Pretraining Data", "link": "https://arxiv.org/pdf/2407.14985", "details": "A Antoniades, X Wang, Y Elazar, A Amayuelas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the proven utility of large language models (LLMs) in real-world applications, there remains a lack of understanding regarding how they leverage their large-scale pretraining text corpora to achieve such capabilities. In this work, we investigate the \u2026"}, {"title": "Specialist vision-language models for clinical ophthalmology", "link": "https://arxiv.org/abs/2407.08410", "details": "R Holland, TRP Taylor, C Holmes, S Riedl, J Mai\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Clinicians spend a significant amount of time reviewing medical images and transcribing their findings regarding patient diagnosis, referral and treatment in text form. Vision-language models (VLMs), which automatically interpret images and \u2026"}]
