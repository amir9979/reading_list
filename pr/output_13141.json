[{"title": "ConceptCLIP: Towards Trustworthy Medical AI via Concept-Enhanced Contrastive Langauge-Image Pre-training", "link": "https://arxiv.org/pdf/2501.15579", "details": "Y Nie, S He, Y Bie, Y Wang, Z Chen, S Yang, H Chen - arXiv preprint arXiv \u2026, 2025", "abstract": "Trustworthiness is essential for the precise and interpretable application of artificial intelligence (AI) in medical imaging. Traditionally, precision and interpretability have been addressed as separate tasks, namely medical image analysis and explainable \u2026"}, {"title": "Do we really have to filter out random noise in pre-training data for language models?", "link": "https://arxiv.org/pdf/2502.06604", "details": "J Ru, Y Xie, X Zhuang, Y Yin, Y Zou - arXiv preprint arXiv:2502.06604, 2025", "abstract": "Web-scale pre-training datasets are the cornerstone of LLMs' success. However, text data curated from the internet inevitably contains random noise caused by decoding errors or unregulated web content. In contrast to previous works that focus on low \u2026"}, {"title": "Weakly supervised multi-modal contrastive learning framework for predicting the HER2 scores in breast cancer", "link": "https://www.sciencedirect.com/science/article/pii/S0895611125000114", "details": "J Shi, D Sun, Z Jiang, J Du, W Wang, Y Zheng, H Wu - Computerized Medical Imaging \u2026, 2025", "abstract": "Human epidermal growth factor receptor 2 (HER2) is an important biomarker for prognosis and prediction of treatment response in breast cancer (BC). HER2 scoring is typically evaluated by pathologist microscopic observation on \u2026"}, {"title": "SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features", "link": "https://arxiv.org/pdf/2502.14786", "details": "M Tschannen, A Gritsenko, X Wang, MF Naeem\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We introduce SigLIP 2, a family of new multilingual vision-language encoders that build on the success of the original SigLIP. In this second iteration, we extend the original image-text training objective with several prior, independently developed \u2026"}, {"title": "Transferring Textual Preferences to Vision-Language Understanding through Model Merging", "link": "https://arxiv.org/pdf/2502.13487", "details": "CA Li, TH Lin, YN Chen, H Lee - arXiv preprint arXiv:2502.13487, 2025", "abstract": "Large vision-language models (LVLMs) perform outstandingly across various multimodal tasks. However, their ability to evaluate generated content remains limited, and training vision-language reward models (VLRMs) with preference data is \u2026"}, {"title": "Weighted Contrastive Learning With Hard Negative Mining for Positive and Unlabeled Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10870373/", "details": "B Yuan, C Gong, D Tao, J Yang - IEEE Transactions on Neural Networks and \u2026, 2025", "abstract": "Positive and unlabeled (PU) learning aims to train a suitable classifier simply based on a set of positive data and unlabeled data. The state-of-the-art methods usually formulate PU learning as a cost-sensitive learning problem, in which every unlabeled \u2026"}, {"title": "MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders", "link": "https://arxiv.org/pdf/2502.14753", "details": "M Varma, A Kumar, R van der Sluijs, S Ostmeier\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical images are acquired at high resolutions with large fields of view in order to capture fine-grained features necessary for clinical decision-making. Consequently, training deep learning models on medical images can incur large computational \u2026"}, {"title": "Large-scale benchmarking and boosting transfer learning for medical image analysis", "link": "https://www.sciencedirect.com/science/article/pii/S1361841525000350", "details": "MRH Taher, F Haghighi, MB Gotway, J Liang - Medical Image Analysis, 2025", "abstract": "Transfer learning, particularly fine-tuning models pretrained on photographic images to medical images, has proven indispensable for medical image analysis. There are numerous models with distinct architectures pretrained on various datasets using \u2026"}, {"title": "TESS 2: A Large-Scale Generalist Diffusion Language Model", "link": "https://arxiv.org/pdf/2502.13917", "details": "J Tae, H Ivison, S Kumar, A Cohan - arXiv preprint arXiv:2502.13917, 2025", "abstract": "We introduce TESS 2, a general instruction-following diffusion language model that outperforms contemporary instruction-tuned diffusion models, as well as matches and sometimes exceeds strong autoregressive (AR) models. We train TESS 2 by first \u2026"}]
