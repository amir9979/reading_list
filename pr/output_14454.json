[{"title": "Boosting the Generalization and Reasoning of Vision Language Models with Curriculum Reinforcement Learning", "link": "https://arxiv.org/pdf/2503.07065", "details": "H Deng, D Zou, R Ma, H Luo, Y Cao, Y Kang - arXiv preprint arXiv:2503.07065, 2025", "abstract": "While state-of-the-art vision-language models (VLMs) have demonstrated remarkable capabilities in complex visual-text tasks, their success heavily relies on massive model scaling, limiting their practical deployment. Small-scale VLMs offer a \u2026"}, {"title": "Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models", "link": "https://arxiv.org/pdf/2503.20492", "details": "F Zeng, Z Cheng, F Zhu, XY Zhang - arXiv preprint arXiv:2503.20492, 2025", "abstract": "Reliable prediction by classifiers is crucial for their deployment in high security and dynamically changing situations. However, modern neural networks often exhibit overconfidence for misclassified predictions, highlighting the need for confidence \u2026"}, {"title": "MindGYM: Enhancing Vision-Language Models via Synthetic Self-Challenging Questions", "link": "https://arxiv.org/pdf/2503.09499", "details": "Z Xu, D Chen, Z Ling, Y Li, Y Shen - arXiv preprint arXiv:2503.09499, 2025", "abstract": "Large vision-language models (VLMs) face challenges in achieving robust, transferable reasoning abilities due to reliance on labor-intensive manual instruction datasets or computationally expensive self-supervised methods. To address these \u2026"}, {"title": "From Captions to Rewards (CAREVL): Leveraging Large Language Model Experts for Enhanced Reward Modeling in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.06260", "details": "M Dai, J Sun, Z Zhao, S Liu, R Li, J Gao, X Li - arXiv preprint arXiv:2503.06260, 2025", "abstract": "Aligning large vision-language models (LVLMs) with human preferences is challenging due to the scarcity of fine-grained, high-quality, and multimodal preference data without human annotations. Existing methods relying on direct \u2026"}, {"title": "AdvFusion: Adapter-based Knowledge Transfer for Code Summarization on Code Language Models", "link": "https://figshare.le.ac.uk/articles/conference_contribution/AdvFusion_Adapter-based_Knowledge_Transfer_for_Code_Summarization_on_Code_Language_Models/28658645/1/files/53208368.pdf", "details": "F Chen, I Saberi, A Esmaeili, F Fard - 2025", "abstract": "Programming languages can benefit from one an-other by utilizing a pre-trained model for software engineeringtasks such as code summarization and method name prediction. While full fine-tuning of Code Language Models (Code-LMs) hasbeen \u2026"}, {"title": "Self-training elicits concise reasoning in large language models", "link": "https://arxiv.org/pdf/2502.20122", "details": "T Munkhbat, N Ho, S Kim, Y Yang, Y Kim, SY Yun - arXiv preprint arXiv:2502.20122, 2025", "abstract": "Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens \u2026"}, {"title": "Combinatorial Optimization via LLM-driven Iterated Fine-tuning", "link": "https://arxiv.org/pdf/2503.06917", "details": "P Awasthi, S Gollapudi, R Kumar, K Munagala - arXiv preprint arXiv:2503.06917, 2025", "abstract": "We present a novel way to integrate flexible, context-dependent constraints into combinatorial optimization by leveraging Large Language Models (LLMs) alongside traditional algorithms. Although LLMs excel at interpreting nuanced, locally specified \u2026"}, {"title": "A Weighted Cross-entropy Loss for Mitigating LLM Hallucinations in Cross-lingual Continual Pretraining", "link": "https://ieeexplore.ieee.org/abstract/document/10888877/", "details": "Y Fan, R Li, G Zhang, C Shi, X Wang - \u2026 2025-2025 IEEE International Conference on \u2026, 2025", "abstract": "Recently, due to the explosive advances of large language models (LLMs) on English, cross-lingual continual pretraining has been widely applied in obtaining Chinese LLMs. However, previous studies showed that these LLMs have suffered \u2026"}, {"title": "Prune'n Predict: Optimizing LLM Decision-making with Conformal Prediction", "link": "https://openreview.net/pdf%3Fid%3DgENDUvkytD", "details": "H Vishwakarma, A Mishler, T Cook, N Dalmasso\u2026 - \u2026 : The Next Frontier in Reliable AI", "abstract": "Large language models (LLMs) are empowering decision-making in several applications, including tool or API usage and answering multiple-choice questions (MCQs). However, incorrect outputs pose significant risks in high-stakes domains like \u2026"}]
