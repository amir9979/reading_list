[{"title": "BiasICL: In-Context Learning and Demographic Biases of Vision Language Models", "link": "https://arxiv.org/pdf/2503.02334", "details": "S Xu, J Janizek, Y Jiang, R Daneshjou - arXiv preprint arXiv:2503.02334, 2025", "abstract": "Vision language models (VLMs) show promise in medical diagnosis, but their performance across demographic subgroups when using in-context learning (ICL) remains poorly understood. We examine how the demographic composition of \u2026"}, {"title": "MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning via Modality Alignment and Retention", "link": "https://arxiv.org/pdf/2503.00374", "details": "T Wang, J Fan, D Zhang, D Liu, Y Xia, H Huang, W Cai - arXiv preprint arXiv \u2026, 2025", "abstract": "Histopathology and transcriptomics are fundamental modalities in oncology, encapsulating the morphological and molecular aspects of the disease. Multi-modal self-supervised learning has demonstrated remarkable potential in learning \u2026"}, {"title": "Words or Vision: Do Vision-Language Models Have Blind Faith in Text?", "link": "https://arxiv.org/pdf/2503.02199", "details": "A Deng, T Cao, Z Chen, B Hooi - arXiv preprint arXiv:2503.02199, 2025", "abstract": "Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual \u2026"}, {"title": "MedHEval: Benchmarking Hallucinations and Mitigation Strategies in Medical Large Vision-Language Models", "link": "https://arxiv.org/pdf/2503.02157", "details": "A Chang, L Huang, P Bhatia, T Kass-Hout, F Ma\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision Language Models (LVLMs) are becoming increasingly important in the medical domain, yet Medical LVLMs (Med-LVLMs) frequently generate hallucinations due to limited expertise and the complexity of medical applications \u2026"}, {"title": "SurGen: 1020 H&E-stained Whole Slide Images With Survival and Genetic Markers", "link": "https://arxiv.org/pdf/2502.04946", "details": "C Myles, IH Um, C Marshall, D Harris-Birtill\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "$\\textbf {Background} $: Cancer remains one of the leading causes of morbidity and mortality worldwide. Comprehensive datasets that combine histopathological images with genetic and survival data across various tumour sites are essential for \u2026"}, {"title": "Multimodal Distillation-Driven Ensemble Learning for Long-Tailed Histopathology Whole Slide Images Analysis", "link": "https://arxiv.org/pdf/2503.00915", "details": "X Ling, Y Ping, J Li, J Peng, Y Chen, M Ouyang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Multiple Instance Learning (MIL) plays a significant role in computational pathology, enabling weakly supervised analysis of Whole Slide Image (WSI) datasets. The field of WSI analysis is confronted with a severe long-tailed distribution problem, which \u2026"}, {"title": "Measures of retinal health successfully capture risk for Alzheimer's disease and related dementias at midlife", "link": "https://journals.sagepub.com/doi/full/10.1177/13872877251321114", "details": "A Barrett-Young, A Reuben, A Caspi, K Cheyne\u2026 - Journal of Alzheimer's \u2026, 2025", "abstract": "Background Identification of at-risk individuals who would benefit from early intervention for Alzheimer's disease and related dementias (ADRD) is critical as new treatments are developed. Measures of retinal health could offer accessible and low \u2026"}, {"title": "Swarm learning with weak supervision enables automatic breast cancer detection in magnetic resonance imaging", "link": "https://www.nature.com/articles/s43856-024-00722-5", "details": "OL Saldanha, J Zhu, G M\u00fcller-Franzes, ZI Carrero\u2026 - Communications Medicine, 2025", "abstract": "Background Over the next 5 years, new breast cancer screening guidelines recommending magnetic resonance imaging (MRI) for certain patients will significantly increase the volume of imaging data to be analyzed. While this increase \u2026"}, {"title": "Open-source framework for detecting bias and overfitting for large pathology images", "link": "https://arxiv.org/pdf/2503.01827", "details": "A Sildnes, N Shvetsov, M Tafavvoghi, VNN Tran\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Even foundational models that are trained on datasets with billions of data samples may develop shortcuts that lead to overfitting and bias. Shortcuts are non-relevant patterns in data, such as the background color or color intensity. So, to ensure the \u2026"}]
