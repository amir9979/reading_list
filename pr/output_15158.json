[{"title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models", "link": "https://arxiv.org/pdf/2504.05258", "details": "A Bazaga, R Blloshmi, B Byrne, A de Gispert - arXiv preprint arXiv:2504.05258, 2025", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating coherent text, understanding context, and performing reasoning tasks. However, they struggle with temporal reasoning, which requires processing time-related information \u2026"}, {"title": "Language Models of Code are Few-Shot Planners and Reasoners for Multi-Document Summarization with Attribution", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34676/36831", "details": "A Nandy, S Bandyopadhyay - Proceedings of the AAAI Conference on Artificial \u2026, 2025", "abstract": "Document summarization has greatly benefited from advances in large language models (LLMs). In real-world situations, summaries often need to be generated from multiple documents with diverse sources and authors, lacking a clear information \u2026"}, {"title": "Multi-View Empowered Structural Graph Wordification for Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34652/36807", "details": "Z Liu, L Wu, M He, Z Guan, H Zhao, N Feng - Proceedings of the AAAI Conference on \u2026, 2025", "abstract": "Significant efforts have been dedicated to integrating the powerful Large Language Models (LLMs) with diverse modalities, particularly focusing on the fusion of language, vision and audio data. However, the graph-structured data, which is \u2026"}, {"title": "Frozen Language Models Are Gradient Coherence Rectifiers in Vision Transformers", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32176/34331", "details": "L Bai, Z Xiong, H Lin, G Xu, X Xie, R Guo, Z Kang\u2026 - Proceedings of the AAAI \u2026, 2025", "abstract": "Large language models (LLMs) have demonstrated remarkable performance in multimodal tasks even with frozen LLM Block and only a few trainable parameters. However, the underlying mechanisms of how LLMs enhance multimodal \u2026"}, {"title": "Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models", "link": "https://arxiv.org/pdf/2504.05050", "details": "J Lian, J Pan, L Wang, Y Wang, S Mei, LP Chau - arXiv preprint arXiv:2504.05050, 2025", "abstract": "Large language models (LLMs) are foundational explorations to artificial general intelligence, yet their alignment with human values via instruction tuning and preference learning achieves only superficial compliance. Here, we demonstrate that \u2026"}, {"title": "FLUE: Streamlined Uncertainty Estimation for Large Language Models", "link": "https://ojs.aaai.org/index.php/AAAI/article/download/33840/35995", "details": "S Gao, T Gong, Z Lin, R Xu, H Zhou, J Li - Proceedings of the AAAI Conference on \u2026, 2025", "abstract": "Uncertainty estimation is essential for practical applications such as decision- making, risk assessment, and human-AI collaboration. However, Uncertainty estimation in open-ended question-answering (QA) tasks presents unique \u2026"}, {"title": "Exploring Conversational Adaptability: Assessing the Proficiency of Large Language Models in Dynamic Alignment with Updated User Intent", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34534/36689", "details": "YC Chen, HH Huang - Proceedings of the AAAI Conference on Artificial \u2026, 2025", "abstract": "This paper presents a practical problem in dialogue systems: the capability to adapt to changing user intentions and resolve inconsistencies in conversation histories. It is crucial in scenarios like train ticket booking, where travel plans often change \u2026"}, {"title": "Beyond Accuracy: The Role of Calibration in Self-Improving Large Language Models", "link": "https://arxiv.org/pdf/2504.02902", "details": "L Huang, D Li, H Liu, L Cheng - arXiv preprint arXiv:2504.02902, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable self-improvement capabilities, whereby models iteratively revise their outputs through self-generated feedback. While this reflective mechanism has shown promise in enhancing task \u2026"}, {"title": "STAF-LLM: A scalable and task-adaptive fine-tuning framework for large language models in medical domain", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425012047", "details": "T Xu, L Chen, Z Hu, B Li - Expert Systems with Applications, 2025", "abstract": "Recent large language models (LLMs) have demonstrated remarkable performance across various NLP tasks. However, their application in the medical domain is often limited by a lack of specialized medical knowledge, which is crucial for practical \u2026"}]
