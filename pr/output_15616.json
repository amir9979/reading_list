[{"title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "link": "https://arxiv.org/pdf/2503.23145", "details": "A Wei, T Suresh, J Cao, N Kannan, Y Wu, K Yan\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Inductive program synthesis, or programming by example, requires synthesizing functions from input-output examples that generalize to unseen inputs. While large language model agents have shown promise in programming tasks guided by \u2026"}, {"title": "From Teacher to Colleague: How Coding Experience Shapes Developer Perceptions of AI Tools", "link": "https://arxiv.org/pdf/2504.13903", "details": "I Zakharov, E Koshchenko, A Sergeyuk - arXiv preprint arXiv:2504.13903, 2025", "abstract": "AI-assisted development tools promise productivity gains and improved code quality, yet their adoption among developers remains inconsistent. Prior research suggests that professional expertise influences technology adoption, but its role in shaping \u2026"}, {"title": "A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems", "link": "https://arxiv.org/pdf/2504.09037", "details": "Z Ke, F Jiao, Y Ming, XP Nguyen, A Xu, DX Long, M Li\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Reasoning is a fundamental cognitive process that enables logical inference, problem-solving, and decision-making. With the rapid advancement of large language models (LLMs), reasoning has emerged as a key capability that \u2026"}, {"title": "Investigating legal question generation using large language models", "link": "https://link.springer.com/article/10.1007/s10506-025-09452-y", "details": "A Deroy, K Ghosh, S Ghosh - Artificial Intelligence and Law, 2025", "abstract": "We propose the task of legal question generation (QG) as an application in Legal NLP. Specifically, the task is to generate a question, given a context and an optional keyword. We create the first dataset for the QG task in the legal domain, called \u2026"}, {"title": "Large language models are human-like annotators", "link": "https://link.springer.com/chapter/10.1007/978-3-031-88720-8_45", "details": "M Marreddy, SR Oota, M Gupta - European Conference on Information Retrieval, 2025", "abstract": "Large Language Models Are Human-Like Annotators | SpringerLink Skip to main content Advertisement Springer Nature Link Account Menu Find a journal Publish with us Track your research Search Cart 1.Home 2.Advances in Information \u2026"}, {"title": "Knowledge-Centered Dual-Process Reasoning for Math Word Problems with Large Language Models", "link": "https://ieeexplore.ieee.org/abstract/document/10946242/", "details": "J Liu, Z Huang, Q Liu, Z Ma, C Zhai, E Chen - IEEE Transactions on Knowledge and \u2026, 2025", "abstract": "Math word problem (MWP) serves as a critical milestone for assessing the text mining ability and knowledge mastery level of models. Recent advancements have witnessed large language models (LLMs) showcasing remarkable performance on \u2026"}, {"title": "Boosting Large Language Models with Mask Fine-Tuning", "link": "https://arxiv.org/pdf/2503.22764", "details": "M Zhang, Y Bai, H Wang, Y Wang, Q Dong, Y Fu - arXiv preprint arXiv:2503.22764, 2025", "abstract": "The model is usually kept integral in the mainstream large language model (LLM) fine-tuning protocols. No works have questioned whether maintaining the integrity of the model is indispensable for performance. In this work, we introduce Mask Fine \u2026"}, {"title": "Automating Evaluation of AI Text Generation in Healthcare with a Large Language Model (LLM)-as-a-Judge", "link": "https://www.medrxiv.org/content/10.1101/2025.04.22.25326219.full.pdf", "details": "EL Croxford, YL Gao, E First, N Pellegrino, M Schnier\u2026 - medRxiv, 2025", "abstract": "Electronic Health Records (EHRs) store vast amounts of clinical information that are difficult for healthcare providers to summarize and synthesize relevant details to their practice. To reduce cognitive load on providers, generative AI with Large Language \u2026"}, {"title": "Generalization Bias in Large Language Model Summarization of Scientific Research", "link": "https://arxiv.org/pdf/2504.00025", "details": "U Peters, B Chin-Yee - arXiv preprint arXiv:2504.00025, 2025", "abstract": "Artificial intelligence chatbots driven by large language models (LLMs) have the potential to increase public science literacy and support scientific research, as they can quickly summarize complex scientific information in accessible terms. However \u2026"}]
