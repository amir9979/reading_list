[{"title": "Mental Modeling of Reinforcement Learning Agents by Language Models", "link": "https://arxiv.org/pdf/2406.18505", "details": "W Lu, X Zhao, J Spisak, JH Lee, S Wermter - arXiv preprint arXiv:2406.18505, 2024", "abstract": "Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it \u2026"}, {"title": "Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models", "link": "https://arxiv.org/pdf/2407.02666", "details": "AS Chen, AM Lessing, A Tang, G Chada, L Smith\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Legged robots are physically capable of navigating a diverse variety of environments and overcoming a wide range of obstructions. For example, in a search and rescue mission, a legged robot could climb over debris, crawl through gaps, and navigate \u2026"}, {"title": "MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models", "link": "https://aclanthology.org/2024.findings-naacl.18.pdf", "details": "Z Su, Z Lin, B Baixue, H Chen, S Hu, W Zhou, G Ding\u2026 - Findings of the Association \u2026, 2024", "abstract": "Generative language models are usually pre-trained on large text corpus via predicting the next token (ie, sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language \u2026"}, {"title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs", "link": "https://arxiv.org/pdf/2406.14282", "details": "J Wang, M Chen, B Hu, D Yang, Z Liu, Y Shen, P Wei\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Improving the performance of large language models (LLMs) in complex question- answering (QA) scenarios has always been a research focal point. Recent studies have attempted to enhance LLMs' performance by combining step-wise planning \u2026"}, {"title": "SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation", "link": "https://arxiv.org/pdf/2406.12975", "details": "X Liu, T Sun, T Xu, F Wu, C Wang, X Wang, J Gao - arXiv preprint arXiv:2406.12975, 2024", "abstract": "Large Language Models (LLMs) have transformed machine learning but raised significant legal concerns due to their potential to produce text that infringes on copyrights, resulting in several high-profile lawsuits. The legal landscape is \u2026"}, {"title": "Adaptive Rank Selections for Low-Rank Approximation of Language Models", "link": "https://aclanthology.org/2024.naacl-long.13.pdf", "details": "S Gao, T Hua, YC Hsu, Y Shen, H Jin - Proceedings of the 2024 Conference of the \u2026, 2024", "abstract": "Abstract Singular Value Decomposition (SVD) or its weighted variants has significantly progressed in compressing language models. Previous works assume the same importance for all operations and assign the same number of ranks for \u2026"}, {"title": "This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes", "link": "https://aclanthology.org/2024.naacl-long.213.pdf", "details": "B Li, S Haider, C Callison-Burch - Proceedings of the 2024 Conference of the North \u2026, 2024", "abstract": "Abstract Do the Spratly Islands belong to China, the Philippines, or Vietnam? A pretrained large language model (LLM) may answer differently if asked in the languages of each claimant country: Chinese, Tagalog, or Vietnamese. This \u2026"}, {"title": "Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding", "link": "https://arxiv.org/pdf/2406.12295", "details": "K Zhang, J Wang, N Ding, B Qi, E Hua, X Lv, B Zhou - arXiv preprint arXiv:2406.12295, 2024", "abstract": "Large Language Models (LLMs) demonstrate impressive performance in diverse applications, yet they face significant drawbacks, including high inference latency, expensive training cost, and generation of hallucination. Collaborative decoding \u2026"}, {"title": "Learn Beyond The Answer: Training Language Models with Reflection for Mathematical Reasoning", "link": "https://arxiv.org/pdf/2406.12050", "details": "Z Zhang, Z Liang, W Yu, D Yu, M Jia, D Yu, M Jiang - arXiv preprint arXiv:2406.12050, 2024", "abstract": "Supervised fine-tuning enhances the problem-solving abilities of language models across various mathematical reasoning tasks. To maximize such benefits, existing research focuses on broadening the training set with various data augmentation \u2026"}]
