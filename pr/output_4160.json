[{"title": "On the Discriminability of Self-Supervised Representation Learning", "link": "https://arxiv.org/pdf/2407.13541", "details": "Z Song, W Qiang, C Zheng, F Sun, H Xiong - arXiv preprint arXiv:2407.13541, 2024", "abstract": "Self-supervised learning (SSL) has recently achieved significant success in downstream visual tasks. However, a notable gap still exists between SSL and supervised learning (SL), especially in complex downstream tasks. In this paper, we \u2026"}, {"title": "Controlling the Fidelity and Diversity of Deep Generative Models via Pseudo Density", "link": "https://arxiv.org/pdf/2407.08659", "details": "S Li, C Liu, T Zhang, H Le, S S\u00fcsstrunk, M Salzmann - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce an approach to bias deep generative models, such as GANs and diffusion models, towards generating data with either enhanced fidelity or increased diversity. Our approach involves manipulating the distribution of training and \u2026"}, {"title": "Integrating Amortized Inference with Diffusion Models for Learning Clean Distribution from Corrupted Images", "link": "https://arxiv.org/pdf/2407.11162", "details": "Y Wang, W Bai, W Luo, W Chen, H Sun - arXiv preprint arXiv:2407.11162, 2024", "abstract": "Diffusion models (DMs) have emerged as powerful generative models for solving inverse problems, offering a good approximation of prior distributions of real-world image data. Typically, diffusion models rely on large-scale clean signals to \u2026"}, {"title": "Diffusion Models and Representation Learning: A Survey", "link": "https://arxiv.org/pdf/2407.00783", "details": "M Fuest, P Ma, M Gui, JS Fischer, VT Hu, B Ommer - arXiv preprint arXiv:2407.00783, 2024", "abstract": "Diffusion Models are popular generative modeling methods in various vision tasks, attracting significant attention. They can be considered a unique instance of self- supervised learning methods due to their independence from label annotation. This \u2026"}, {"title": "Self-Guided Generation of Minority Samples Using Diffusion Models", "link": "https://arxiv.org/pdf/2407.11555", "details": "S Um, JC Ye - arXiv preprint arXiv:2407.11555, 2024", "abstract": "We present a novel approach for generating minority samples that live on low- density regions of a data manifold. Our framework is built upon diffusion models, leveraging the principle of guided sampling that incorporates an arbitrary energy \u2026"}, {"title": "Repulsive Score Distillation for Diverse Sampling of Diffusion Models", "link": "https://arxiv.org/pdf/2406.16683", "details": "N Zilberstein, M Mardani, S Segarra - arXiv preprint arXiv:2406.16683, 2024", "abstract": "Score distillation sampling has been pivotal for integrating diffusion models into generation of complex visuals. Despite impressive results it suffers from mode collapse and lack of diversity. To cope with this challenge, we leverage the gradient \u2026"}, {"title": "Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems", "link": "https://arxiv.org/pdf/2407.11288", "details": "YU Al\u00e7alar, M Ak\u00e7akaya - arXiv preprint arXiv:2407.11288, 2024", "abstract": "Diffusion models have emerged as powerful generative techniques for solving inverse problems. Despite their success in a variety of inverse problems in imaging, these models require many steps to converge, leading to slow inference time \u2026"}, {"title": "Provable Statistical Rates for Consistency Diffusion Models", "link": "https://arxiv.org/pdf/2406.16213", "details": "Z Dou, M Chen, M Wang, Z Yang - arXiv preprint arXiv:2406.16213, 2024", "abstract": "Diffusion models have revolutionized various application domains, including computer vision and audio generation. Despite the state-of-the-art performance, diffusion models are known for their slow sample generation due to the extensive \u2026"}]
