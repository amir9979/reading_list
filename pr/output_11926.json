[{"title": "Dynamically Scaled Temperature in Self-Supervised Contrastive Learning", "link": "https://ieeexplore.ieee.org/abstract/document/10820841/", "details": "S Manna, S Chattopadhyay, R Dey, U Pal\u2026 - IEEE Transactions on \u2026, 2025", "abstract": "In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples of different classes is primarily affected by the presence of \u2026"}, {"title": "Neighbor Does Matter: Density-Aware Contrastive Learning for Medical Semi-supervised Segmentation", "link": "https://arxiv.org/pdf/2412.19871", "details": "F Tang, Z Xu, M Hu, W Li, P Xia, Y Zhong, H Wu, J Su\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In medical image analysis, multi-organ semi-supervised segmentation faces challenges such as insufficient labels and low contrast in soft tissues. To address these issues, existing studies typically employ semi-supervised segmentation \u2026"}, {"title": "Hybrid cross-modality fusion network for medical image segmentation with contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0952197625000739", "details": "X Zhou, Q Song, J Nie, Y Feng, H Liu, F Liang, L Chen\u2026 - Engineering Applications of \u2026, 2025", "abstract": "Medical image segmentation has been widely adopted in artificial intelligence-based clinical applications. The integration of medical texts into image segmentation models has significantly improved the segmentation performance. It is crucial to \u2026"}, {"title": "SHYI: Action Support for Contrastive Learning in High-Fidelity Text-to-Image Generation", "link": "https://arxiv.org/abs/2501.09055", "details": "T Xia, L Xiao, Y Montorfani, F Pavia, E Simsar\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In this project, we address the issue of infidelity in text-to-image generation, particularly for actions involving multiple objects. For this we build on top of the CONFORM framework which uses Contrastive Learning to improve the accuracy of \u2026"}, {"title": "Synthetic Feature Augmentation Improves Generalization Performance of Language Models", "link": "https://arxiv.org/pdf/2501.06434", "details": "A Choudhary, C Thiels, H Salehinejad - arXiv preprint arXiv:2501.06434, 2025", "abstract": "Training and fine-tuning deep learning models, especially large language models (LLMs), on limited and imbalanced datasets poses substantial challenges. These issues often result in poor generalization, where models overfit to dominant classes \u2026"}, {"title": "Supervision-free Vision-Language Alignment", "link": "https://arxiv.org/pdf/2501.04568%3F", "details": "G Giannone, R Li, Q Feng, E Perevodchikov, R Chen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation \u2026"}, {"title": "Improving Self-Supervised Medical Image Pre-Training by Early Alignment with Human Eye Gaze Information", "link": "https://ieeexplore.ieee.org/abstract/document/10839445/", "details": "S Wang, Z Zhao, Z Shen, B Wang, Q Wang, D Shen - IEEE Transactions on Medical \u2026, 2025", "abstract": "Alignment between human knowledge and machine learning models is crucial for achieving efficient and interpretable AI systems. However, conventional self- supervised pre-training methods often suffer from low efficiency, as they do not \u2026"}, {"title": "Small Language Models (SLMs) Can Still Pack a Punch: A survey", "link": "https://arxiv.org/pdf/2501.05465", "details": "S Subramanian, V Elango, M Gungor - arXiv preprint arXiv:2501.05465, 2025", "abstract": "As foundation AI models continue to increase in size, an important question arises-is massive scale the only path forward? This survey of about 160 papers presents a family of Small Language Models (SLMs) in the 1 to 8 billion parameter range that \u2026"}, {"title": "HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models", "link": "https://arxiv.org/pdf/2412.20622", "details": "A Seth, D Manocha, C Agarwal - arXiv preprint arXiv:2412.20622, 2024", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable performance in performing complex multimodal tasks. However, they are still plagued by object hallucination: the misidentification or misclassification of objects \u2026"}]
