[{"title": "Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning", "link": "https://arxiv.org/pdf/2505.13081", "details": "X Yang, J Lu, E Yu - arXiv preprint arXiv:2505.13081, 2025", "abstract": "This paper uncovers a critical yet overlooked phenomenon in multi-modal large language models (MLLMs): detrimental concept drift within chain-of-thought (CoT) reasoning during non-stationary reinforcement fine-tuning (RFT), where reasoning \u2026", "entry_id": "http://arxiv.org/abs/2505.13081v1", "updated": "2025-05-19 13:13:38", "published": "2025-05-19 13:13:38", "authors": "Xiaoyu Yang;Jie Lu;En Yu", "summary": "This paper uncovers a critical yet overlooked phenomenon in multi-modal large\nlanguage models (MLLMs): detrimental concept drift within chain-of-thought\n(CoT) reasoning during non-stationary reinforcement fine-tuning (RFT), where\nreasoning token distributions evolve unpredictably, thereby introducing\nsignificant biases in final predictions. To address this, we are pioneers in\nestablishing the theoretical bridge between concept drift theory and RFT\nprocesses by formalizing CoT's autoregressive token streams as non-stationary\ndistributions undergoing arbitrary temporal shifts. Leveraging this framework,\nwe propose a novel counterfact-aware RFT that systematically decouples\nbeneficial distribution adaptation from harmful concept drift through concept\ngraph-empowered LLM experts generating counterfactual reasoning trajectories.\nOur solution, Counterfactual Preference Optimization (CPO), enables stable RFT\nin non-stationary environments, particularly within the medical domain, through\ncustom-tuning of counterfactual-aware preference alignment. Extensive\nexperiments demonstrate our superior performance of robustness, generalization\nand coordination within RFT. Besides, we also contributed a large-scale dataset\nCXR-CounterFact (CCF), comprising 320,416 meticulously curated counterfactual\nreasoning trajectories derived from MIMIC-CXR. Our code and data are public.", "comment": "17 pages, 5figures", "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG;cs.CV", "links": "http://arxiv.org/abs/2505.13081v1;http://arxiv.org/pdf/2505.13081v1", "pdf_url": "http://arxiv.org/pdf/2505.13081v1"}, {"title": "EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy", "link": "https://arxiv.org/pdf/2505.15206", "details": "CK Ng, L Bai, G Wang, Y Wang, H Gao, K Yuan, C Jin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In endoscopic procedures, autonomous tracking of abnormal regions and following circumferential cutting markers can significantly reduce the cognitive burden on endoscopists. However, conventional model-based pipelines are fragile for each \u2026", "entry_id": "http://arxiv.org/abs/2505.15206v1", "updated": "2025-05-21 07:35:00", "published": "2025-05-21 07:35:00", "authors": "Chi Kit Ng;Long Bai;Guankun Wang;Yupeng Wang;Huxin Gao;Kun Yuan;Chenhan Jin;Tieyong Zeng;Hongliang Ren", "summary": "In endoscopic procedures, autonomous tracking of abnormal regions and\nfollowing circumferential cutting markers can significantly reduce the\ncognitive burden on endoscopists. However, conventional model-based pipelines\nare fragile for each component (e.g., detection, motion planning) requires\nmanual tuning and struggles to incorporate high-level endoscopic intent,\nleading to poor generalization across diverse scenes. Vision-Language-Action\n(VLA) models, which integrate visual perception, language grounding, and motion\nplanning within an end-to-end framework, offer a promising alternative by\nsemantically adapting to surgeon prompts without manual recalibration. Despite\ntheir potential, applying VLA models to robotic endoscopy presents unique\nchallenges due to the complex and dynamic anatomical environments of the\ngastrointestinal (GI) tract. To address this, we introduce EndoVLA, designed\nspecifically for continuum robots in GI interventions. Given endoscopic images\nand surgeon-issued tracking prompts, EndoVLA performs three core tasks: (1)\npolyp tracking, (2) delineation and following of abnormal mucosal regions, and\n(3) adherence to circular markers during circumferential cutting. To tackle\ndata scarcity and domain shifts, we propose a dual-phase strategy comprising\nsupervised fine-tuning on our EndoVLA-Motion dataset and reinforcement\nfine-tuning with task-aware rewards. Our approach significantly improves\ntracking performance in endoscopy and enables zero-shot generalization in\ndiverse scenes and complex sequential tasks.", "comment": null, "journal_ref": null, "primary_category": "cs.RO", "categories": "cs.RO;cs.AI", "links": "http://arxiv.org/abs/2505.15206v1;http://arxiv.org/pdf/2505.15206v1", "pdf_url": "http://arxiv.org/pdf/2505.15206v1"}, {"title": "Improved Multiclass Lung Disease Classification Using Segmentation and Deep Learning from Chest X-Ray Images", "link": "https://www.tandfonline.com/doi/abs/10.1080/02564602.2025.2501936", "details": "VK Yadav, J Singhai - IETE Technical Review, 2025", "abstract": "Chest X-Ray (CXR) imaging has developed as an important technique for identifying lung diseases, especially in low-and middle-income nations where tuberculosis and pneumonia are serious health problems. With the onset of the COVID-19 pandemic \u2026"}]
