[{"title": "VLMine: Long-Tail Data Mining with Vision Language Models", "link": "https://arxiv.org/pdf/2409.15486", "details": "M Ye, GP Meyer, Z Zhang, D Park, SK Mustikovela\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Ensuring robust performance on long-tail examples is an important problem for many real-world applications of machine learning, such as autonomous driving. This work focuses on the problem of identifying rare examples within a corpus of unlabeled \u2026"}, {"title": "Expert-level vision-language foundation model for real-world radiology and comprehensive evaluation", "link": "https://arxiv.org/pdf/2409.16183", "details": "X Liu, G Yang, Y Luo, J Mao, X Zhang, M Gao, S Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Radiology is a vital and complex component of modern clinical workflow and covers many tasks. Recently, vision-language (VL) foundation models in medicine have shown potential in processing multimodal information, offering a unified solution for \u2026"}, {"title": "Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding", "link": "https://arxiv.org/abs/2409.14485", "details": "Y Shu, P Zhang, Z Liu, M Qin, J Zhou, T Huang, B Zhao - arXiv preprint arXiv \u2026, 2024", "abstract": "Although current Multi-modal Large Language Models (MLLMs) demonstrate promising results in video understanding, processing extremely long videos remains an ongoing challenge. Typically, MLLMs struggle with handling thousands of tokens \u2026"}, {"title": "TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans", "link": "https://arxiv.org/pdf/2409.16666", "details": "A Chatziagapi, B Chaudhuri, A Kumar, R Ranjan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce a novel framework that learns a dynamic neural radiance field (NeRF) for full-body talking humans from monocular videos. Prior work represents only the body pose or the face. However, humans communicate with their full body \u2026"}, {"title": "Arc2Face: A Foundation Model for ID-Consistent Human Faces", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05442.pdf", "details": "FP Papantoniou, A Lattas, S Moschoglou, J Deng\u2026", "abstract": "This paper presents Arc2Face, an identity-conditioned face foundation model, which, given the ArcFace embedding of a person, can generate diverse photo-realistic images with an unparalleled degree of face similarity than existing models. Despite \u2026"}, {"title": "Robust image representations with counterfactual contrastive learning", "link": "https://arxiv.org/pdf/2409.10365", "details": "M Roschewitz, FDS Ribeiro, T Xia, G Khara, B Glocker - arXiv preprint arXiv \u2026, 2024", "abstract": "Contrastive pretraining can substantially increase model generalisation and downstream performance. However, the quality of the learned representations is highly dependent on the data augmentation strategy applied to generate positive \u2026"}, {"title": "Multi-objective Evolution of Heuristic Using Large Language Model", "link": "https://arxiv.org/pdf/2409.16867", "details": "S Yao, F Liu, X Lin, Z Lu, Z Wang, Q Zhang - arXiv preprint arXiv:2409.16867, 2024", "abstract": "Heuristics are commonly used to tackle diverse search and optimization problems. Design heuristics usually require tedious manual crafting with domain knowledge. Recent works have incorporated large language models (LLMs) into automatic \u2026"}, {"title": "Evaluation of pretrained language models on music understanding", "link": "https://arxiv.org/pdf/2409.11449", "details": "Y Vasilakis, R Bittner, J Pauwels - arXiv preprint arXiv:2409.11449, 2024", "abstract": "Music-text multimodal systems have enabled new approaches to Music Information Research (MIR) applications such as audio-to-text and text-to-audio retrieval, text- based song generation, and music captioning. Despite the reported success, little \u2026"}, {"title": "HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2409.16191", "details": "H Que, F Duan, L He, Y Mou, W Zhou, J Liu, W Rong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks (eg, long-context understanding), and many benchmarks have been proposed. However, we observe that long text generation capabilities are \u2026"}]
