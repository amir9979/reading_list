[{"title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors", "link": "https://arxiv.org/pdf/2404.17807", "details": "G Li, P Wang, J Liu, Y Guo, K Ji, Z Shang, Z Xu - arXiv preprint arXiv:2404.17807, 2024", "abstract": "Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot \u2026"}, {"title": "A Trajectory Perspective on the Role of Data Sampling Techniques in Offline Reinforcement Learning", "link": "https://www.ifaamas.org/Proceedings/aamas2024/pdfs/p1229.pdf", "details": "J Liu, Y Ma, J Hao, Y Hu, Y Zheng, T Lv, C Fan - Proceedings of the 23rd International \u2026, 2024", "abstract": "In recent years, offline reinforcement learning (RL) algorithms have gained considerable attention. However, the role of data sampling techniques in offline RL has been somewhat overlooked, despite their potential to enhance online RL \u2026"}, {"title": "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation", "link": "https://arxiv.org/pdf/2404.19335", "details": "X Liu, C Liu, Z Zhang, C Li, L Wang, Y Lan, C Shen - arXiv preprint arXiv:2404.19335, 2024", "abstract": "Large language models have shown their ability to become effective few-shot learners with prompting, revoluting the paradigm of learning with data scarcity. However, this approach largely depends on the quality of prompt initialization, and \u2026"}, {"title": "HFT: Half Fine-Tuning for Large Language Models", "link": "https://arxiv.org/pdf/2404.18466", "details": "T Hui, Z Zhang, S Wang, W Xu, Y Sun, H Wu - arXiv preprint arXiv:2404.18466, 2024", "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of \u2026"}, {"title": "Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks", "link": "https://openreview.net/pdf%3Fid%3Dtr0TcqitMH", "details": "S Xu, L Pang, H Shen, X Cheng, TS Chua - The Web Conference 2024, 2024", "abstract": "Making the contents generated by Large Language Model (LLM) such as ChatGPT, accurate, credible and traceable is crucial, especially in complex knowledge- intensive tasks that require multi-step reasoning and each step needs knowledge to \u2026"}, {"title": "Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/pdf/2405.00175", "details": "A Salemi, H Zamani - arXiv preprint arXiv:2405.00175, 2024", "abstract": "This paper introduces uRAG--a framework with a unified retrieval engine that serves multiple downstream retrieval-augmented generation (RAG) systems. Each RAG system consumes the retrieval results for a unique purpose, such as open-domain \u2026"}, {"title": "MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models", "link": "https://arxiv.org/pdf/2405.13053", "details": "J Xu, J Lai, Y Huang - arXiv preprint arXiv:2405.13053, 2024", "abstract": "The\\textit {pretrain+ fine-tune} paradigm is foundational in deploying large language models (LLMs) across a diverse range of downstream applications. Among these, Low-Rank Adaptation (LoRA) stands out for its parameter-efficient fine-tuning \u2026"}, {"title": "DuetSim: Building User Simulator with Dual Large Language Models for Task-Oriented Dialogues", "link": "https://arxiv.org/pdf/2405.13028", "details": "X Luo, Z Tang, J Wang, X Zhang - arXiv preprint arXiv:2405.13028, 2024", "abstract": "User Simulators play a pivotal role in training and evaluating task-oriented dialogue systems. Traditional user simulators typically rely on human-engineered agendas, resulting in generated responses that often lack diversity and spontaneity. Although \u2026"}]
