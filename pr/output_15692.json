[{"title": "A Post-trainer's Guide to Multilingual Training Data: Uncovering Cross-lingual Transfer Dynamics", "link": "https://arxiv.org/pdf/2504.16677", "details": "L Shimabucoro, A Ustun, M Fadaee, S Ruder - arXiv preprint arXiv:2504.16677, 2025", "abstract": "In order for large language models to be useful across the globe, they are fine-tuned to follow instructions on multilingual data. Despite the ubiquity of such post-training, a clear understanding of the dynamics that enable cross-lingual transfer remains \u2026"}, {"title": "Multi-Label Few-Shot Image Classification via Pairwise Feature Augmentation and Flexible Prompt Learning", "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32578/34733", "details": "H Liu, Y Wang, X Zhang, F Zhang, W Wang, F Ma, H Yu - Proceedings of the AAAI \u2026, 2025", "abstract": "Multi-label few-shot image classification is a crucial and challenging task due to limited annotated data and elusive category specificity. However, research on this topic is still in the rudimentary stage and few methods are available. Existing \u2026"}, {"title": "Explainable differential diagnosis with dual-inference large language models", "link": "https://www.nature.com/articles/s44401-025-00015-6", "details": "S Zhou, M Lin, S Ding, J Wang, C Chen, GB Melton\u2026 - npj Health Systems, 2025", "abstract": "Automatic differential diagnosis (DDx) involves identifying potential conditions that could explain a patient's symptoms and its accurate interpretation is of substantial significance. While large language models (LLMs) have demonstrated remarkable \u2026"}, {"title": "AD-GPT: Large Language Models in Alzheimer's Disease", "link": "https://arxiv.org/pdf/2504.03071", "details": "Z Liu, L Tang, Z Sun, Z Liu, Y Lyu, W Ruan, Y Xu\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large language models (LLMs) have emerged as powerful tools for medical information retrieval, yet their accuracy and depth remain limited in specialized domains such as Alzheimer's disease (AD), a growing global health challenge. To \u2026"}, {"title": "Evaluating Multi-Hop Reasoning in Large Language Models: A Chemistry-Centric Case Study", "link": "https://arxiv.org/pdf/2504.16414", "details": "M Khodadad, AS Kasmaee, M Astaraki, N Sherck\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "In this study, we introduced a new benchmark consisting of a curated dataset and a defined evaluation process to assess the compositional reasoning capabilities of large language models within the chemistry domain. We designed and validated a \u2026"}, {"title": "Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics", "link": "https://arxiv.org/pdf/2504.17665", "details": "Z Al-Khalili, N Howell, D Klakow - arXiv preprint arXiv:2504.17665, 2025", "abstract": "Assisting LLMs with code generation improved their performance on mathematical reasoning tasks. However, the evaluation of code-assisted LLMs is generally restricted to execution correctness, lacking a rigorous evaluation of their generated \u2026"}, {"title": "Prompts De-Biasing Augmentation to Mitigate Gender Stereotypes in Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-96-6008-7_19", "details": "BJ Chen, S Binnewies, B Stantic - Asian Conference on Intelligent Information and \u2026, 2025", "abstract": "Abstract Large Language Models (LLMs) have manifested impressive ability in the natural language processing (NLP) area, especially in the power of generating and understanding human languages. However, the training of LLMs is a double-edged \u2026"}]
