[{"title": "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark", "link": "https://aclanthology.org/2024.emnlp-main.759.pdf", "details": "F Liu, Z Li, H Zhou, Q Yin, J Yang, X Tang, C Luo\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "The adoption of large language models (LLMs) to assist clinicians has attracted remarkable attention. Existing works mainly adopt the close-ended question- answering (QA) task with answer options for evaluation. However, many clinical \u2026"}, {"title": "SCITUNE: Aligning Large Language Models with Human-Curated Scientific Multimodal Instructions", "link": "https://aclanthology.org/2024.nlp4science-1.7.pdf", "details": "S Horawalavithana, S Munikoti, I Stewart, H Kvinge\u2026 - \u2026 of the 1st Workshop on NLP \u2026, 2024", "abstract": "Instruction finetuning is a popular paradigm to align large language models (LLM) with human intent. Despite its popularity, this idea is less explored in improving LLMs to align existing foundation models with scientific disciplines, concepts and goals. In \u2026"}, {"title": "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "link": "https://aclanthology.org/2024.emnlp-main.418.pdf", "details": "J Chen, C Gui, R Ouyang, A Gao, S Chen, G Chen\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "The rapid development of multimodal large language models (MLLMs), such as GPT- 4V, has led to significant advancements. However, these models still face challenges in medical multimodal capabilities due to limitations in the quantity and quality of \u2026"}]
