[{"title": "Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement", "link": "https://arxiv.org/pdf/2502.02573%3F", "details": "S Abbasloo - arXiv preprint arXiv:2502.02573, 2025", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem- solving, a crucial, ubiquitous, and complex domain. This paper explores the \u2026"}, {"title": "Toward Responsible Federated Large Language Models: Leveraging a Safety Filter and Constitutional AI", "link": "https://arxiv.org/pdf/2502.16691", "details": "E Noh, J Baek - arXiv preprint arXiv:2502.16691, 2025", "abstract": "Recent research has increasingly focused on training large language models (LLMs) using federated learning, known as FedLLM. However, responsible AI (RAI), which aims to ensure safe responses, remains underexplored in the context of FedLLM. In \u2026"}, {"title": "Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach", "link": "https://arxiv.org/pdf/2502.05171", "details": "J Geiping, S McLeish, N Jain, J Kirchenbauer, S Singh\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We study a novel language model architecture that is capable of scaling test-time computation by implicitly reasoning in latent space. Our model works by iterating a recurrent block, thereby unrolling to arbitrary depth at test-time. This stands in \u2026"}, {"title": "LATTE-CXR: Locally Aligned TexT and imagE, Explainable dataset for Chest X-Rays", "link": "https://physionet.org/content/latte-cxr/", "details": "E Ghelichkhan, T Tasdizen", "abstract": "Local annotation of medical data is both expensive and time-consuming due to the high cost of expert annotators, the precision required for accurate annotation, and the inherent challenges of medical diagnosis. To address these problems, we developed \u2026"}, {"title": "Position: Editing Large Language Models Poses Serious Safety Risks", "link": "https://arxiv.org/pdf/2502.02958", "details": "P Youssef, Z Zhao, D Braun, J Schl\u00f6tterer, C Seifert - arXiv preprint arXiv:2502.02958, 2025", "abstract": "Large Language Models (LLMs) contain large amounts of facts about the world. These facts can become outdated over time, which has led to the development of knowledge editing methods (KEs) that can change specific facts in LLMs with limited \u2026"}, {"title": "Scalable Best-of-N Selection for Large Language Models via Self-Certainty", "link": "https://arxiv.org/pdf/2502.18581", "details": "Z Kang, X Zhao, D Song - arXiv preprint arXiv:2502.18581, 2025", "abstract": "Best-of-N selection is a key technique for improving the reasoning performance of Large Language Models (LLMs) through increased test-time computation. Current state-of-the-art methods often employ computationally intensive reward models for \u2026"}, {"title": "Large Language Models as Attribution Regularizers for Efficient Model Training", "link": "https://arxiv.org/pdf/2502.20268", "details": "D Vukadin, M \u0160ili\u0107, G Dela\u010d - arXiv preprint arXiv:2502.20268, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains. However, effectively leveraging their vast knowledge for training smaller downstream models remains an open challenge, especially in domains like \u2026"}, {"title": "Emergent Symbolic Mechanisms Support Abstract Reasoning in Large Language Models", "link": "https://arxiv.org/pdf/2502.20332", "details": "Y Yang, D Campbell, K Huang, M Wang, J Cohen\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Many recent studies have found evidence for emergent reasoning capabilities in large language models, but debate persists concerning the robustness of these capabilities, and the extent to which they depend on structured reasoning \u2026"}, {"title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models", "link": "https://arxiv.org/pdf/2502.03199%3F", "details": "J Wu, Y Shen, S Liu, Y Tang, S Song, X Wang, L Cai - arXiv preprint arXiv \u2026, 2025", "abstract": "Despite their impressive capacities, Large language models (LLMs) often struggle with the hallucination issue of generating inaccurate or fabricated content even when they possess correct knowledge. In this paper, we extend the exploration of the \u2026"}]
