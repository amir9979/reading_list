[{"title": "Exploring Multi-Grained Concept Annotations for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2412.05939", "details": "X Xu, T Niu, Y Xie, L Qin, W Che, MY Kan - arXiv preprint arXiv:2412.05939, 2024", "abstract": "Multimodal Large Language Models (MLLMs) excel in vision--language tasks by pre- training solely on coarse-grained concept annotations (eg, image captions). We hypothesize that integrating fine-grained concept annotations (eg, object labels and \u2026"}, {"title": "FlashSloth: Lightning Multimodal Large Language Models via Embedded Visual Compression", "link": "https://arxiv.org/pdf/2412.04317", "details": "B Tong, B Lai, Y Zhou, G Luo, Y Shen, K Li, X Sun, R Ji - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite a big leap forward in capability, multimodal large language models (MLLMs) tend to behave like a sloth in practical use, ie, slow response and large latency. Recent efforts are devoted to building tiny MLLMs for better efficiency, but the \u2026"}, {"title": "Retrieval-Augmented Semantic Parsing: Using Large Language Models to Improve Generalization", "link": "https://arxiv.org/pdf/2412.10207", "details": "X Zhang, Q Meng, J Bos - arXiv preprint arXiv:2412.10207, 2024", "abstract": "Open-domain semantic parsing remains a challenging task, as models often rely on heuristics and struggle to handle unseen concepts. In this paper, we investigate the potential of large language models (LLMs) for this task and introduce Retrieval \u2026"}, {"title": "GeoTool-GPT: a trainable method for facilitating Large Language Models to master GIS tools", "link": "https://www.tandfonline.com/doi/abs/10.1080/13658816.2024.2438937", "details": "C Wei, Y Zhang, X Zhao, Z Zeng, Z Wang, J Lin\u2026 - International Journal of \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) excel in natural language-relevant tasks like text generation and question answering Q&A. To further expand their application, efforts focus on enabling LLMs to utilize real-world tools. However, their tool-use \u2026"}, {"title": "Training Large Language Models to Reason in a Continuous Latent Space", "link": "https://arxiv.org/pdf/2412.06769%3F", "details": "S Hao, S Sukhbaatar, DJ Su, X Li, Z Hu, J Weston\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) are restricted to reason in the\" language space\", where they typically express the reasoning process with a chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue that language space may \u2026"}, {"title": "Enhancing Fine-Grained Vision-Language Pretraining with Negative Augmented Samples", "link": "https://arxiv.org/pdf/2412.10029", "details": "Y Wang, D Gao, L Yi, L Jin, J Zhang, L Yang, X Cai - arXiv preprint arXiv:2412.10029, 2024", "abstract": "Existing Vision-Language Pretraining (VLP) methods have achieved remarkable improvements across a variety of vision-language tasks, confirming their effectiveness in capturing coarse-grained semantic correlations. However, their \u2026"}, {"title": "Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models", "link": "https://arxiv.org/pdf/2412.08615", "details": "J Li, Y Hao, H Xu, X Wang, Y Hong - arXiv preprint arXiv:2412.08615, 2024", "abstract": "Despite the advancements in training Large Language Models (LLMs) with alignment techniques to enhance the safety of generated content, these models remain susceptible to jailbreak, an adversarial attack method that exposes security \u2026"}, {"title": "Pre-train, Align, and Disentangle: Empowering Sequential Recommendation with Large Language Models", "link": "https://arxiv.org/pdf/2412.04107", "details": "Y Wang, J Pan, X Zhao, P Jia, W Wang, Y Wang, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Sequential recommendation (SR) aims to model the sequential dependencies in users' historical interactions to better capture their evolving interests. However, existing SR approaches primarily rely on collaborative data, which leads to \u2026"}, {"title": "Multi-Objective Alignment of Large Language Models Through Hypervolume Maximization", "link": "https://arxiv.org/pdf/2412.05469", "details": "S Mukherjee, A Lalitha, S Sengupta, A Deshmukh\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multi-objective alignment from human feedback (MOAHF) in large language models (LLMs) is a challenging problem as human preferences are complex, multifaceted, and often conflicting. Recent works on MOAHF considered a-priori multi-objective \u2026"}]
