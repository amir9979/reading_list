[{"title": "Deliberative alignment: Reasoning enables safer language models", "link": "https://arxiv.org/pdf/2412.16339", "details": "MY Guan, M Joglekar, E Wallace, S Jain, B Barak\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large-scale language models increasingly impact safety-critical domains, ensuring their reliable adherence to well-defined principles remains a fundamental challenge. We introduce Deliberative Alignment, a new paradigm that directly \u2026"}, {"title": "On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena", "link": "https://arxiv.org/pdf/2501.04662", "details": "T Naous, W Xu - arXiv preprint arXiv:2501.04662, 2025", "abstract": "Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages. In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by \u2026"}, {"title": "Grounding Deliberate Reasoning in Multimodal Large Language Models", "link": "https://link.springer.com/chapter/10.1007/978-981-96-2061-6_2", "details": "J Chen, Y Liu, D Li, X An, W Deng, Z Feng, Y Zhao\u2026 - International Conference on \u2026, 2024", "abstract": "Abstract The rise of Multimodal Large Language Models, renowned for their advanced instruction-following and reasoning capabilities, has significantly propelled the field of visual reasoning. However, due to limitations in their image \u2026"}, {"title": "LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models", "link": "https://arxiv.org/pdf/2501.00055", "details": "M Yu, J Fang, Y Zhou, X Fan, K Wang, S Pan, Q Wen - arXiv preprint arXiv \u2026, 2024", "abstract": "While safety-aligned large language models (LLMs) are increasingly used as the cornerstone for powerful systems such as multi-agent frameworks to solve complex real-world problems, they still suffer from potential adversarial queries, such as \u2026"}, {"title": "Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization", "link": "https://arxiv.org/pdf/2412.18279%3F", "details": "J Liu, C Wang, CY Liu, L Zeng, R Yan, Y Sun, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The role of reinforcement learning (RL) in enhancing the reasoning of large language models (LLMs) is becoming increasingly significant. Despite the success of RL in many scenarios, there are still many challenges in improving the reasoning of \u2026"}, {"title": "SKEWACT: Red Teaming Large Language Models via Activation-Skewed Adversarial Prompt Optimization", "link": "https://openreview.net/pdf%3Fid%3DQPdVqbcBgi", "details": "H Guo, S Cheng, G Tao, G Shen, Z Zhang, S An\u2026", "abstract": "Abstract Large Language Models (LLMs) have become increasingly impactful across various domains, including coding and data analysis. However, their widespread adoption has raised concerns about misuse, particularly in generating harmful or \u2026"}, {"title": "Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models", "link": "https://arxiv.org/pdf/2412.19450%3F", "details": "H Moon, J Seo, S Lee, C Park, H Lim - arXiv preprint arXiv:2412.19450, 2024", "abstract": "One of the key strengths of Large Language Models (LLMs) is their ability to interact with humans by generating appropriate responses to given instructions. This ability, known as instruction-following capability, has established a foundation for the use of \u2026"}, {"title": "Physics Reasoner: Knowledge-Augmented Reasoning for Solving Physics Problems with Large Language Models", "link": "https://arxiv.org/pdf/2412.13791", "details": "X Pang, R Hong, Z Zhou, F Lv, X Yang, Z Liang, B Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Physics problems constitute a significant aspect of reasoning, necessitating complicated reasoning ability and abundant physics knowledge. However, existing large language models (LLMs) frequently fail due to a lack of knowledge or incorrect \u2026"}, {"title": "Eliciting Causal Abilities in Large Language Models for Reasoning Tasks", "link": "https://arxiv.org/pdf/2412.15314", "details": "Y Wang, Z Luo, J Wang, Z Zhou, Y Chen, B Han - arXiv preprint arXiv:2412.15314, 2024", "abstract": "Prompt optimization automatically refines prompting expressions, unlocking the full potential of LLMs in downstream tasks. However, current prompt optimization methods are costly to train and lack sufficient interpretability. This paper proposes \u2026"}]
