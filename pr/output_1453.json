'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [HTML] [Shortcut learning in medical AI hinders generalizatio'
[{"title": "Contrastive Representation for Data Filtering in Cross-Domain Offline Reinforcement Learning", "link": "https://arxiv.org/pdf/2405.06192", "details": "X Wen, C Bai, K Xu, X Yu, Y Zhang, X Li, Z Wang - arXiv preprint arXiv:2405.06192, 2024", "abstract": "Cross-domain offline reinforcement learning leverages source domain data with diverse transition dynamics to alleviate the data requirement for the target domain. However, simply merging the data of two domains leads to performance degradation \u2026"}, {"title": "Interactive decision tree creation and enhancement with complete visualization for explainable modeling", "link": "https://link.springer.com/chapter/10.1007/978-3-031-46549-9_1", "details": "B Kovalerchuk, A Dunn, A Worland, S Wagle - Artificial Intelligence and Visualization \u2026, 2024", "abstract": "To increase the interpretability and prediction accuracy of the Machine Learning (ML) models, visualization of ML models is a key part of the ML process. Decision Trees (DTs) are essential in machine learning because they are used to understand many \u2026"}, {"title": "Towards Accurate and Stronger Local Differential Privacy for Federated Learning with Staircase Randomized Response", "link": "https://yhongcs.github.io/pub/codaspy24.pdf", "details": "M Varun, S Feng, H Wang, S Sural, Y Hong - 14th ACM Conference on Data and \u2026, 2024", "abstract": "Federated Learning (FL), a privacy-preserving training approach, has proven to be effective, yet its vulnerability to attacks that extract information from model weights is widely recognized. To address such privacy concerns, Local Differential Privacy \u2026"}, {"title": "Transitive Vision-Language Prompt Learning for Domain Generalization", "link": "https://arxiv.org/pdf/2404.18758", "details": "L Wang, Y Jin, Z Chen, J Wu, M Li, Y Lu, H Wang - arXiv preprint arXiv:2404.18758, 2024", "abstract": "The vision-language pre-training has enabled deep models to make a huge step forward in generalizing across unseen domains. The recent learning method based on the vision-language pre-training model is a great tool for domain generalization \u2026"}, {"title": "Charting a new course in healthcare: early-stage AI algorithm registration to enhance trust and transparency", "link": "https://www.nature.com/articles/s41746-024-01104-w", "details": "ME van Genderen, D van de Sande, L Hooft, AA Reis\u2026 - npj Digital Medicine, 2024", "abstract": "AI holds the potential to transform healthcare, promising improvements in patient care. Yet, realizing this potential is hampered by over-reliance on limited datasets and a lack of transparency in validation processes. To overcome these obstacles, we \u2026"}, {"title": "Structure-aware feature stylization for domain generalization", "link": "https://www.sciencedirect.com/science/article/pii/S1077314224000973", "details": "M Cheraghalikhani, M Noori, D Osowiechi, GAV Hakim\u2026 - Computer Vision and Image \u2026, 2024", "abstract": "Generalizing to out-of-distribution (OOD) data is a challenging task for existing deep learning approaches. This problem largely comes from the common but often incorrect assumption of statistical learning algorithms that the source and target data \u2026"}, {"title": "TrajDeleter: Enabling Trajectory Forgetting in Offline Reinforcement Learning Agents", "link": "https://arxiv.org/pdf/2404.12530", "details": "C Gong, K Li, J Yao, T Wang - arXiv preprint arXiv:2404.12530, 2024", "abstract": "Reinforcement learning (RL) trains an agent from experiences interacting with the environment. In scenarios where online interactions are impractical, offline RL, which trains the agent using pre-collected datasets, has become popular. While this new \u2026"}, {"title": "Counterfactual Data Augmentation for Debiased Coupon Recommendations Based on Potential Knowledge", "link": "https://dl.acm.org/doi/pdf/10.1145/3589335.3648306", "details": "J Fang, G Zhang, Q Cui, L Gu, L Li, J Gu, J Zhou - \u2026 Proceedings of the ACM on Web \u2026, 2024", "abstract": "In real-world coupon recommendations, the coupon allocation process is influenced by both the recommendation model trained with historical interaction data and marketing tactics aimed at specific commercial goals. These tactics can cause an \u2026"}, {"title": "Select Your Own Counterparts: Self-Supervised Graph Contrastive Learning With Positive Sampling", "link": "https://ieeexplore.ieee.org/abstract/document/10507017/", "details": "Z Wang, D Yu, S Shen, S Zhang, H Liu, S Yao, M Guo - IEEE Transactions on Neural \u2026, 2024", "abstract": "Contrastive learning (CL) has emerged as a powerful approach for self-supervised learning. However, it suffers from sampling bias, which hinders its performance. While the mainstream solutions, hard negative mining (HNM) and supervised CL \u2026"}]
