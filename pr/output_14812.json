[{"title": "Reasoning Inconsistencies and How to Mitigate Them in Deep Learning", "link": "https://arxiv.org/pdf/2504.02577", "details": "E Arakelyan - arXiv preprint arXiv:2504.02577, 2025", "abstract": "The recent advancements in Deep Learning models and techniques have led to significant strides in performance across diverse tasks and modalities. However, while the overall capabilities of models show promising growth, our understanding of \u2026"}, {"title": "Semantic role extraction in law texts: a comparative analysis of language models for legal information extraction", "link": "https://link.springer.com/article/10.1007/s10506-025-09437-x", "details": "RM Bakker, AJ Schoevers, RAN van Drie\u2026 - Artificial Intelligence and \u2026, 2025", "abstract": "Norms are essential in our society: they dictate how individuals should behave and interact within a community. They can be written down in laws or other written sources. Interpretations often differ; this is where formalisations offer a solution. They \u2026"}, {"title": "Can large language models independently complete tasks? A dynamic evaluation framework for multi-turn task planning and completion", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225008070", "details": "J Gao, J Cui, H Wu, L Xiang, H Zhao, X Li, M Fang\u2026 - Neurocomputing, 2025", "abstract": "Large language models (LLMs) are increasingly relied upon for multi-turn dialogue to conduct complex tasks. However, existing benchmarks mainly evaluate LLMs as agents, overlooking their potential as independent systems to accomplish complex \u2026"}, {"title": "Language model personalization via reward factorization", "link": "https://arxiv.org/pdf/2503.06358", "details": "I Shenfeld, F Faltings, P Agrawal, A Pacchiano - arXiv preprint arXiv:2503.06358, 2025", "abstract": "Modern large language models (LLMs) are optimized for human-aligned responses using Reinforcement Learning from Human Feedback (RLHF). However, existing RLHF approaches assume a universal preference model and fail to account for \u2026"}]
