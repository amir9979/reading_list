[{"title": "Towards Utilising a Range of Neural Activations for Comprehending Representational Associations", "link": "https://arxiv.org/pdf/2411.10019", "details": "L O'Mahony, NS Nikolov, DJP O'Sullivan - arXiv preprint arXiv:2411.10019, 2024", "abstract": "Recent efforts to understand intermediate representations in deep neural networks have commonly attempted to label individual neurons and combinations of neurons that make up linear directions in the latent space by examining extremal neuron \u2026"}, {"title": "Joint Vision-Language Social Bias Removal for CLIP", "link": "https://arxiv.org/pdf/2411.12785", "details": "H Zhang, Y Guo, M Kankanhalli - arXiv preprint arXiv:2411.12785, 2024", "abstract": "Vision-Language (VL) pre-trained models such as CLIP show prominent capabilities in various downstream tasks. Despite this promise, VL models are notoriously limited by their inherent social biases. A typical demonstration is that VL models often \u2026"}, {"title": "Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models", "link": "https://aclanthology.org/2024.emnlp-main.1133.pdf", "details": "Y Nakagi, T Matsuyama, N Koide-Majima\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "In recent studies, researchers have used large language models (LLMs) to explore semantic representations in the brain; however, they have typically assessed different levels of semantic content, such as speech, objects, and stories, separately \u2026"}, {"title": "Skills-in-Context: Unlocking Compositionality in Large Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.812.pdf", "details": "J Chen, X Pan, D Yu, K Song, X Wang, D Yu, J Chen - Findings of the Association for \u2026, 2024", "abstract": "We investigate how to elicit compositional generalization capabilities in large language models (LLMs). Compositional generalization empowers LLMs to solve complex problems by combining foundational skills, a critical reasoning ability akin to \u2026"}, {"title": "Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models", "link": "https://arxiv.org/pdf/2411.00492", "details": "DX Long, DN Yen, AT Luu, K Kawaguchi, MY Kan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu et al., 2023), designed to improve the large language model (LLM) generation. Specifically, it guides an LLM to fulfill an input instruction by simulating multiple \u2026"}, {"title": "FactTest: Factuality Testing in Large Language Models with Statistical Guarantees", "link": "https://arxiv.org/pdf/2411.02603", "details": "F Nie, X Hou, S Lin, J Zou, H Yao, L Zhang - arXiv preprint arXiv:2411.02603, 2024", "abstract": "The propensity of Large Language Models (LLMs) to generate hallucinations and non-factual content undermines their reliability in high-stakes domains, where rigorous control over Type I errors (the conditional probability of incorrectly \u2026"}, {"title": "Membership Inference Attacks against Large Language Models via Self-prompt Calibration", "link": "https://fi.ee.tsinghua.edu.cn/~gaochen/papers/NeurIPS2024-SPV-MIA.pdf", "details": "W Fu, H Wang, G Liu, Y Li, T Jiang", "abstract": "Abstract Membership Inference Attacks (MIA) aim to infer whether a target data record has been utilized for model training or not. Existing MIAs designed for large language models (LLMs) can be bifurcated into two types: reference-free and \u2026"}]
