[{"title": "Learning Hierarchically using Formal Concepts", "link": "https://openreview.net/pdf%3Fid%3DosauNVSVvg", "details": "D Vemuri, S Adhikari, A Saha, VN Balasubramanian - Second Workshop on Visual Concepts", "abstract": "Learning semantics is crucial for deep learning models to be trustworthy and more aligned with human-like reasoning. Concept-based models offer a promising approach by learning classes in terms of interpretable semantic abstractions \u2026"}, {"title": "Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation", "link": "https://arxiv.org/pdf/2505.24361", "details": "R Ferrod, CF Dantas, L Di Caro, D Ienco - arXiv preprint arXiv:2505.24361, 2025", "abstract": "Multi-modal RGB and Depth (RGBD) data are predominant in many domains such as robotics, autonomous driving and remote sensing. The combination of these multi- modal data enhances environmental perception by providing 3D spatial context \u2026", "entry_id": "http://arxiv.org/abs/2505.24361v1", "updated": "2025-05-30 08:53:35", "published": "2025-05-30 08:53:35", "authors": "Roger Ferrod;C\u00e1ssio F. Dantas;Luigi Di Caro;Dino Ienco", "summary": "Multi-modal RGB and Depth (RGBD) data are predominant in many domains such as\nrobotics, autonomous driving and remote sensing. The combination of these\nmulti-modal data enhances environmental perception by providing 3D spatial\ncontext, which is absent in standard RGB images. Although RGBD multi-modal data\ncan be available to train computer vision models, accessing all sensor\nmodalities during the inference stage may be infeasible due to sensor failures\nor resource constraints, leading to a mismatch between data modalities\navailable during training and inference. Traditional Cross-Modal Knowledge\nDistillation (CMKD) frameworks, developed to address this task, are typically\nbased on a teacher/student paradigm, where a multi-modal teacher distills\nknowledge into a single-modality student model. However, these approaches face\nchallenges in teacher architecture choices and distillation process selection,\nthus limiting their adoption in real-world scenarios. To overcome these issues,\nwe introduce CroDiNo-KD (Cross-Modal Disentanglement: a New Outlook on\nKnowledge Distillation), a novel cross-modal knowledge distillation framework\nfor RGBD semantic segmentation. Our approach simultaneously learns\nsingle-modality RGB and Depth models by exploiting disentanglement\nrepresentation, contrastive learning and decoupled data augmentation with the\naim to structure the internal manifolds of neural network models through\ninteraction and collaboration. We evaluated CroDiNo-KD on three RGBD datasets\nacross diverse domains, considering recent CMKD frameworks as competitors. Our\nfindings illustrate the quality of CroDiNo-KD, and they suggest reconsidering\nthe conventional teacher/student paradigm to distill information from\nmulti-modal data to single-modality neural networks.", "comment": null, "journal_ref": null, "primary_category": "cs.CV", "categories": "cs.CV", "links": "http://arxiv.org/abs/2505.24361v1;http://arxiv.org/pdf/2505.24361v1", "pdf_url": "http://arxiv.org/pdf/2505.24361v1"}, {"title": "Deep learning driven interpretable and informed decision making model for brain tumour prediction using explainable AI", "link": "https://www.nature.com/articles/s41598-025-03358-0", "details": "KM Adnan, TM Ghazal, M Saleem, MS Farooq\u2026 - Scientific Reports, 2025", "abstract": "Brain Tumours are highly complex, particularly when it comes to their initial and accurate diagnosis, as this determines patient prognosis. Conventional methods rely on MRI and CT scans and employ generic machine learning techniques, which are \u2026"}, {"title": "From Invariant Representations to Invariant Data: Provable Robustness to Spurious Correlations via Noisy Counterfactual Matching", "link": "https://arxiv.org/pdf/2505.24843", "details": "R Bai, Y Ji, Z Zhou, DI Inouye - arXiv preprint arXiv:2505.24843, 2025", "abstract": "Spurious correlations can cause model performance to degrade in new environments. Prior causality-inspired works aim to learn invariant representations (eg, IRM) but typically underperform empirical risk minimization (ERM). Recent \u2026", "entry_id": "http://arxiv.org/abs/2505.24843v1", "updated": "2025-05-30 17:42:32", "published": "2025-05-30 17:42:32", "authors": "Ruqi Bai;Yao Ji;Zeyu Zhou;David I. Inouye", "summary": "Spurious correlations can cause model performance to degrade in new\nenvironments. Prior causality-inspired works aim to learn invariant\nrepresentations (e.g., IRM) but typically underperform empirical risk\nminimization (ERM). Recent alternatives improve robustness by leveraging\ntest-time data, but such data may be unavailable in practice. To address these\nissues, we take a data-centric approach by leveraging invariant data pairs,\npairs of samples that would have the same prediction with the optimally robust\nclassifier. We prove that certain counterfactual pairs will naturally satisfy\nthis invariance property and introduce noisy counterfactual matching (NCM), a\nsimple constraint-based method for leveraging invariant pairs for enhanced\nrobustness, even with a small set of noisy pairs-in the ideal case, each pair\ncan eliminate one spurious feature. For linear causal models, we prove that the\ntest domain error can be upper bounded by the in-domain error and a term that\ndepends on the counterfactuals' diversity and quality. We validate on a\nsynthetic dataset and demonstrate on real-world benchmarks that linear probing\non a pretrained backbone improves robustness.", "comment": null, "journal_ref": null, "primary_category": "cs.LG", "categories": "cs.LG", "links": "http://arxiv.org/abs/2505.24843v1;http://arxiv.org/pdf/2505.24843v1", "pdf_url": "http://arxiv.org/pdf/2505.24843v1"}, {"title": "DiffCoR: Exposing AI-Generated Image by Using Stable Diffusion Model Based on Consistent Representation Learning", "link": "https://ieeexplore.ieee.org/iel8/8782664/9024218/11018794.pdf", "details": "VN Tran, P Choi, HS Le, SH Lee, KR Kwon - IEEE Open Journal of the Computer \u2026, 2025", "abstract": "Diffusion-based generative models have significantly advanced the field of image synthesis, presenting additional challenges regarding the integrity and authenticity of digital images. Consequently, the identification of AI-generated images has become \u2026"}, {"title": "Compositional Text-to-Image Generation with Feedforward Layout Generation", "link": "https://link.springer.com/chapter/10.1007/978-3-031-91979-4_3", "details": "S Liu, W Nie, AC Cheng, M Mardani, C Liu, B Eckart\u2026 - European Conference on \u2026, 2025", "abstract": "Current text-to-image models often struggle with complex prompts, requiring additional inputs for better control. Recently, BlobGen introduced blob representation to enhance compositionality in generative models. However, this method relies \u2026"}, {"title": "A Mathematical Perspective On Contrastive Learning", "link": "https://arxiv.org/pdf/2505.24134", "details": "R Baptista, AM Stuart, S Tran - arXiv preprint arXiv:2505.24134, 2025", "abstract": "Multimodal contrastive learning is a methodology for linking different data modalities; the canonical example is linking image and text data. The methodology is typically framed as the identification of a set of encoders, one for each modality, that align \u2026", "entry_id": "http://arxiv.org/abs/2505.24134v1", "updated": "2025-05-30 02:09:37", "published": "2025-05-30 02:09:37", "authors": "Ricardo Baptista;Andrew M. Stuart;Son Tran", "summary": "Multimodal contrastive learning is a methodology for linking different data\nmodalities; the canonical example is linking image and text data. The\nmethodology is typically framed as the identification of a set of encoders, one\nfor each modality, that align representations within a common latent space. In\nthis work, we focus on the bimodal setting and interpret contrastive learning\nas the optimization of (parameterized) encoders that define conditional\nprobability distributions, for each modality conditioned on the other,\nconsistent with the available data. This provides a framework for multimodal\nalgorithms such as crossmodal retrieval, which identifies the mode of one of\nthese conditional distributions, and crossmodal classification, which is\nsimilar to retrieval but includes a fine-tuning step to make it task specific.\n  The framework we adopt also gives rise to crossmodal generative models. This\nprobabilistic perspective suggests two natural generalizations of contrastive\nlearning: the introduction of novel probabilistic loss functions, and the use\nof alternative metrics for measuring alignment in the common latent space. We\nstudy these generalizations of the classical approach in the multivariate\nGaussian setting. In this context we view the latent space identification as a\nlow-rank matrix approximation problem. This allows us to characterize the\ncapabilities of loss functions and alignment metrics to approximate natural\nstatistics, such as conditional means and covariances; doing so yields novel\nvariants on contrastive learning algorithms for specific mode-seeking and for\ngenerative tasks. The framework we introduce is also studied through numerical\nexperiments on multivariate Gaussians, the labeled MNIST dataset, and on a data\nassimilation application arising in oceanography.", "comment": "44 pages, 15 figures", "journal_ref": null, "primary_category": "stat.ML", "categories": "stat.ML;cs.CV;cs.LG", "links": "http://arxiv.org/abs/2505.24134v1;http://arxiv.org/pdf/2505.24134v1", "pdf_url": "http://arxiv.org/pdf/2505.24134v1"}]
