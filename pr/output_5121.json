[{"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Trustworthy Response Generation in Chinese", "link": "https://dl.acm.org/doi/pdf/10.1145/3686807", "details": "H Wang, S Zhao, Z Qiang, Z Li, C Liu, N Xi, Y Du, B Qin\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the hallucination about medical facts due to \u2026"}, {"title": "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models", "link": "https://arxiv.org/pdf/2408.03560", "details": "AS Joaquin, B Wang, Z Liu, N Asher, B Lim, P Muller\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite advancements, fine-tuning Large Language Models (LLMs) remains costly due to the extensive parameter count and substantial data requirements for model generalization. Accessibility to computing resources remains a barrier for the open \u2026"}, {"title": "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios", "link": "https://arxiv.org/pdf/2408.01963", "details": "S Ackerman, E Rabinovich, E Farchi, A Anaby-Tavor - arXiv preprint arXiv \u2026, 2024", "abstract": "We evaluate the robustness of several large language models on multiple datasets. Robustness here refers to the relative insensitivity of the model's answers to meaning- preserving variants of their input. Benchmark datasets are constructed by introducing \u2026"}, {"title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "link": "https://arxiv.org/pdf/2408.02103", "details": "P Wang, X Wang, C Lou, S Mao, P Xie, Y Jiang - arXiv preprint arXiv:2408.02103, 2024", "abstract": "In-context learning (ICL) is a few-shot learning paradigm that involves learning mappings through input-output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language \u2026"}, {"title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models", "link": "https://arxiv.org/pdf/2408.02632", "details": "M Diao, R Li, S Liu, G Liao, J Wang, X Cai, W Xu - arXiv preprint arXiv:2408.02632, 2024", "abstract": "As large language models (LLMs) continue to advance in capability and influence, ensuring their security and preventing harmful outputs has become crucial. A promising approach to address these concerns involves training models to \u2026"}, {"title": "Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?", "link": "https://arxiv.org/pdf/2408.02651", "details": "MB Karkevandi, N Vishwamitra, P Najafirad - arXiv preprint arXiv:2408.02651, 2024", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in natural language tasks, but their safety and morality remain contentious due to their training on internet text corpora. To address these concerns, alignment techniques \u2026"}, {"title": "Using Large Language Models for the Interpretation of Building Regulations", "link": "https://arxiv.org/pdf/2407.21060", "details": "S Fuchs, M Witbrock, J Dimyadi, R Amor - arXiv preprint arXiv:2407.21060, 2024", "abstract": "Compliance checking is an essential part of a construction project. The recent rapid uptake of building information models (BIM) in the construction industry has created more opportunities for automated compliance checking (ACC). BIM enables sharing \u2026"}, {"title": "Progressively Selective Label Enhancement for Language Model Alignment", "link": "https://arxiv.org/pdf/2408.02599", "details": "B Liu, N Xu, X Geng - arXiv preprint arXiv:2408.02599, 2024", "abstract": "Large Language Models have demonstrated impressive capabilities in various language tasks but may produce content that misaligns with human expectations, raising ethical and legal concerns. Therefore, it is important to explore the limitations \u2026"}]
