[{"title": "Overview of ELOQUENT 2024\u2014shared tasks for evaluating generative language model quality", "link": "https://link.springer.com/chapter/10.1007/978-3-031-71908-0_3", "details": "J Karlgren, L D\u00fcrlich, E Gogoulou, L Guillou, J Nivre\u2026 - International Conference of \u2026, 2024", "abstract": "ELOQUENT is a set of shared tasks for evaluating the quality and usefulness of generative language models. ELOQUENT aims to apply high-level quality criteria, grounded in experiences from deploying models in real-life tasks, and to formulate \u2026"}, {"title": "REM: A Ranking-Based Automatic Evaluation Method for LLMs", "link": "https://link.springer.com/chapter/10.1007/978-3-031-72344-5_25", "details": "J Yang, Y Tan, W Hu, Z Yang, X Zhou, Z Luo, W Luo - International Conference on \u2026, 2024", "abstract": "Abstract The emergence of Large Language Models (LLMs) has garnered attention due to their remarkable comprehension and generation capabilities across various language tasks and application scenarios. However, traditional evaluation methods \u2026"}, {"title": "A Large Language Model to Detect Negated Expressions in Radiology Reports", "link": "https://link.springer.com/article/10.1007/s10278-024-01274-9", "details": "Y Su, YB Babore, CE Kahn - Journal of Imaging Informatics in Medicine, 2024", "abstract": "Natural language processing (NLP) is crucial to extract information accurately from unstructured text to provide insights for clinical decision-making, quality improvement, and medical research. This study compared the performance of a rule \u2026"}, {"title": "Overview of the CLEF-2024 CheckThat! lab: check-worthiness, subjectivity, persuasion, roles, authorities, and adversarial robustness", "link": "https://link.springer.com/chapter/10.1007/978-3-031-71908-0_2", "details": "A Barr\u00f3n-Cede\u00f1o, F Alam, JM Stru\u00df, P Nakov\u2026 - International Conference of \u2026, 2024", "abstract": "We describe the seventh edition of the CheckThat! lab, part of the 2024 Conference and Labs of the Evaluation Forum (CLEF). Previous editions of CheckThat! focused on the main tasks of the information verification pipeline: check-worthiness \u2026"}, {"title": "Advancing Equitable AI in Radiology through Contrastive Learning", "link": "https://pubs.rsna.org/doi/full/10.1148/ryai.240530", "details": "PM Johnson - Radiology: Artificial Intelligence, 2024", "abstract": "Patricia M. Johnson, PhD, is an assistant professor of radiology at NYU Langone Health. Her research is centered on the development and application of deep learning techniques for MR image reconstruction and disease detection, with a \u2026"}, {"title": "SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation", "link": "https://arxiv.org/pdf/2409.13321", "details": "J Wu, Y Kim, D Shi, D Cliffton, F Liu, H Wu - arXiv preprint arXiv:2409.13321, 2024", "abstract": "Inspired by the success of large language models (LLMs), there is growing research interest in developing LLMs in the medical domain to assist clinicians. However, for hospitals, using closed-source commercial LLMs involves privacy issues, and \u2026"}, {"title": "LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of Relational Knowledge in Language Models", "link": "https://arxiv.org/pdf/2408.15729", "details": "M Ploner, J Wiland, S Pohl, A Akbik - arXiv preprint arXiv:2408.15729, 2024", "abstract": "Knowledge probing evaluates the extent to which a language model (LM) has acquired relational knowledge during its pre-training phase. It provides a cost- effective means of comparing LMs of different sizes and training setups and is useful \u2026"}, {"title": "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization", "link": "https://arxiv.org/pdf/2409.14907", "details": "A Srivastava, S Joshi, T Chakraborty, MS Akhtar - arXiv preprint arXiv:2409.14907, 2024", "abstract": "In mental health counseling, condensing dialogues into concise and relevant summaries (aka counseling notes) holds pivotal significance. Large Language Models (LLMs) exhibit remarkable capabilities in various generative tasks; however \u2026"}, {"title": "Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities", "link": "https://arxiv.org/pdf/2409.03444", "details": "W Lu, RK Luu, MJ Buehler - arXiv preprint arXiv:2409.03444, 2024", "abstract": "The advancement of Large Language Models (LLMs) for domain applications in fields such as materials science and engineering depends on the development of fine-tuning strategies that adapt models for specialized, technical capabilities. In this \u2026"}]
