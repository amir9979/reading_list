[{"title": "VLM-KG: Multimodal Radiology Knowledge Graph Generation", "link": "https://arxiv.org/pdf/2505.17042", "details": "A Abdullah, ST Kim - arXiv preprint arXiv:2505.17042, 2025", "abstract": "Vision-Language Models (VLMs) have demonstrated remarkable success in natural language generation, excelling at instruction following and structured output generation. Knowledge graphs play a crucial role in radiology, serving as valuable \u2026", "entry_id": "http://arxiv.org/abs/2505.17042v1", "updated": "2025-05-13 06:11:10", "published": "2025-05-13 06:11:10", "authors": "Abdullah Abdullah;Seong Tae Kim", "summary": "Vision-Language Models (VLMs) have demonstrated remarkable success in natural\nlanguage generation, excelling at instruction following and structured output\ngeneration. Knowledge graphs play a crucial role in radiology, serving as\nvaluable sources of factual information and enhancing various downstream tasks.\nHowever, generating radiology-specific knowledge graphs presents significant\nchallenges due to the specialized language of radiology reports and the limited\navailability of domain-specific data. Existing solutions are predominantly\nunimodal, meaning they generate knowledge graphs only from radiology reports\nwhile excluding radiographic images. Additionally, they struggle with long-form\nradiology data due to limited context length. To address these limitations, we\npropose a novel multimodal VLM-based framework for knowledge graph generation\nin radiology. Our approach outperforms previous methods and introduces the\nfirst multimodal solution for radiology knowledge graph generation.", "comment": "10 pages, 2 figures", "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.CV;cs.IR;cs.LG", "links": "http://arxiv.org/abs/2505.17042v1;http://arxiv.org/pdf/2505.17042v1", "pdf_url": "http://arxiv.org/pdf/2505.17042v1"}, {"title": "Lunguage: A Benchmark for Structured and Sequential Chest X-ray Interpretation", "link": "https://arxiv.org/pdf/2505.21190", "details": "JH Moon, G Choi, P Rabaey, MG Kim, HG Hong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Radiology reports convey detailed clinical observations and capture diagnostic reasoning that evolves over time. However, existing evaluation methods are limited to single-report settings and rely on coarse metrics that fail to capture fine-grained \u2026", "entry_id": "http://arxiv.org/abs/2505.21190v1", "updated": "2025-05-27 13:40:00", "published": "2025-05-27 13:40:00", "authors": "Jong Hak Moon;Geon Choi;Paloma Rabaey;Min Gwan Kim;Hyuk Gi Hong;Jung-Oh Lee;Hangyul Yoon;Eun Woo Doe;Jiyoun Kim;Harshita Sharma;Daniel C. Castro;Javier Alvarez-Valle;Edward Choi", "summary": "Radiology reports convey detailed clinical observations and capture\ndiagnostic reasoning that evolves over time. However, existing evaluation\nmethods are limited to single-report settings and rely on coarse metrics that\nfail to capture fine-grained clinical semantics and temporal dependencies. We\nintroduce LUNGUAGE,a benchmark dataset for structured radiology report\ngeneration that supports both single-report evaluation and longitudinal\npatient-level assessment across multiple studies. It contains 1,473 annotated\nchest X-ray reports, each reviewed by experts, and 80 of them contain\nlongitudinal annotations to capture disease progression and inter-study\nintervals, also reviewed by experts. Using this benchmark, we develop a\ntwo-stage framework that transforms generated reports into fine-grained,\nschema-aligned structured representations, enabling longitudinal\ninterpretation. We also propose LUNGUAGESCORE, an interpretable metric that\ncompares structured outputs at the entity, relation, and attribute level while\nmodeling temporal consistency across patient timelines. These contributions\nestablish the first benchmark dataset, structuring framework, and evaluation\nmetric for sequential radiology reporting, with empirical results demonstrating\nthat LUNGUAGESCORE effectively supports structured report evaluation. The code\nis available at: https://github.com/SuperSupermoon/Lunguage", "comment": null, "journal_ref": null, "primary_category": "cs.CL", "categories": "cs.CL;cs.AI", "links": "http://arxiv.org/abs/2505.21190v1;http://arxiv.org/pdf/2505.21190v1", "pdf_url": "http://arxiv.org/pdf/2505.21190v1"}]
