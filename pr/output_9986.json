[{"title": "Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic Vision-language Context Sparsification", "link": "https://arxiv.org/pdf/2412.00876", "details": "W Huang, Z Zhai, Y Shen, S Cao, F Zhao, X Xu, Z Ye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in vision understanding, reasoning, and interaction. However, the inference computation and memory increase progressively with the generation of output tokens \u2026"}, {"title": "Accelerating Multimodel Large Language Models by Searching Optimal Vision Token Reduction", "link": "https://arxiv.org/pdf/2412.00556", "details": "S Zhao, Z Wang, F Juefei-Xu, X Xia, M Liu, X Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Prevailing Multimodal Large Language Models (MLLMs) encode the input image (s) as vision tokens and feed them into the language backbone, similar to how Large Language Models (LLMs) process the text tokens. However, the number of vision \u2026"}, {"title": "Evaluating and Advancing Multimodal Large Language Models in Ability Lens", "link": "https://arxiv.org/pdf/2411.14725", "details": "F Chen, C Gou, J Liu, Y Yang, Z Li, J Zhang, Z Sun\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As multimodal large language models (MLLMs) advance rapidly, rigorous evaluation has become essential, providing further guidance for their development. In this work, we focus on a unified and robust evaluation of\\textbf {vision perception} abilities, the \u2026"}, {"title": "Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective", "link": "https://arxiv.org/pdf/2412.00554", "details": "Y Zhou, B Di Eugenio, L Cheng - arXiv preprint arXiv:2412.00554, 2024", "abstract": "This paper studies the performance of large language models (LLMs), particularly regarding demographic fairness, in solving real-world healthcare tasks. We evaluate state-of-the-art LLMs with three prevalent learning frameworks across six diverse \u2026"}, {"title": "MC-NEST--Enhancing Mathematical Reasoning in Large Language Models with a Monte Carlo Nash Equilibrium Self-Refine Tree", "link": "https://arxiv.org/pdf/2411.15645", "details": "G Rabby, F Keya, P Zamil, S Auer - arXiv preprint arXiv:2411.15645, 2024", "abstract": "Mathematical reasoning has proven to be a critical yet challenging task for large language models (LLMs), as they often struggle with complex multi-step problems. To address these limitations, we introduce the Monte Carlo Nash Equilibrium Self \u2026"}, {"title": "Efficient Self-Improvement in Multimodal Large Language Models: A Model-Level Judge-Free Approach", "link": "https://arxiv.org/pdf/2411.17760", "details": "S Deng, W Zhao, YJ Li, K Wan, D Miranda, A Kale\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-improvement in multimodal large language models (MLLMs) is crucial for enhancing their reliability and robustness. However, current methods often rely heavily on MLLMs themselves as judges, leading to high computational costs and \u2026"}, {"title": "CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels", "link": "https://arxiv.org/pdf/2412.02819", "details": "L Wei, H Yan, X Lu, J Zhu, J Wang, W Zhang - arXiv preprint arXiv:2412.02819, 2024", "abstract": "Large Language Models (LLMs) have been well-researched in many long-context tasks. However, due to high annotation costs, high-quality long-context summary datasets for training or evaluation are scarce, limiting further research. In this work \u2026"}, {"title": "Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning", "link": "https://arxiv.org/pdf/2412.02904", "details": "R Krishnan, P Khanna, O Tickoo - arXiv preprint arXiv:2412.02904, 2024", "abstract": "Large language models (LLMs) have revolutionized the field of natural language processing with their impressive reasoning and question-answering capabilities. However, these models are sometimes prone to generating credible-sounding but \u2026"}, {"title": "A Real-World Benchmark for Evaluating Fine-Grained Issue Solving Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2411.18019", "details": "R Hu, C Peng, J Ren, B Jiang, X Meng, Q Wu, P Gao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Automatically resolving software issues is crucial for software development in practice, impacting the software quality and user experience. The process of resolving real-world issues encompasses tasks such as question-answering (QA) \u2026"}]
