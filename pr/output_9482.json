[{"title": "Eliciting In-Context Learning in Vision-Language Models for Videos Through Curated Data Distributional Properties", "link": "https://aclanthology.org/2024.emnlp-main.1137.pdf", "details": "K Yu, Z Zhang, F Hu, S Storks, J Chai - Proceedings of the 2024 Conference on \u2026, 2024", "abstract": "A major reason behind the recent success of large language models (LLMs) is their incontext learning capability, which makes it possible to rapidly adapt them to downstream textbased tasks by prompting them with a small number of relevant \u2026"}, {"title": "Improving Referring Ability for Biomedical Language Models", "link": "https://aclanthology.org/2024.findings-emnlp.375.pdf", "details": "J Jiang, F Cheng, A Aizawa - Findings of the Association for Computational \u2026, 2024", "abstract": "Existing auto-regressive large language models (LLMs) are primarily trained using documents from general domains. In the biomedical domain, continual pre-training is a prevalent method for domain adaptation to inject professional knowledge into \u2026"}, {"title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models", "link": "https://arxiv.org/pdf/2411.08733%3F", "details": "S Singla, Z Wang, T Liu, A Ashfaq, Z Hu, EP Xing - arXiv preprint arXiv:2411.08733, 2024", "abstract": "Aligning Large Language Models (LLMs) traditionally relies on costly training and human preference annotations. Self-alignment seeks to reduce these expenses by enabling models to align themselves. To further lower costs and achieve alignment \u2026"}, {"title": "Language-Emphasized Cross-Lingual In-Context Learning for Multilingual LLM", "link": "https://link.springer.com/chapter/10.1007/978-981-97-9437-9_26", "details": "J Li, X Wei, X Wang, N Zhuang, L Wang, J Dang - CCF International Conference on \u2026, 2024", "abstract": "With the recent rise of large language models (LLMs), in-context learning (ICL) has shown remarkable performance, eliminating the need for fine-tuning parameters and reducing the reliance on extensive labeled data. However, the intricacies of cross \u2026"}, {"title": "Self-Generated Critiques Boost Reward Modeling for Language Models", "link": "https://arxiv.org/pdf/2411.16646", "details": "Y Yu, Z Chen, A Zhang, L Tan, C Zhu, RY Pang, Y Qian\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reward modeling is crucial for aligning large language models (LLMs) with human preferences, especially in reinforcement learning from human feedback (RLHF). However, current reward models mainly produce scalar scores and struggle to \u2026"}, {"title": "Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning", "link": "https://aclanthology.org/2024.emnlp-main.565.pdf", "details": "J Li, H Zhang, F Zhang, TW Chang, K Kuang, L Chen\u2026 - Proceedings of the 2024 \u2026, 2024", "abstract": "Reinforcement learning from human feedback (RLHF) and AI-generated feedback (RLAIF) have become prominent techniques that significantly enhance the functionality of pre-trained language models (LMs). These methods harness \u2026"}, {"title": "Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent", "link": "https://arxiv.org/pdf/2411.02265%3F", "details": "X Sun, Y Chen, Y Huang, R Xie, J Zhu, K Zhang, S Li\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this paper, we introduce Hunyuan-Large, which is currently the largest open- source Transformer-based mixture of experts model, with a total of 389 billion parameters and 52 billion activation parameters, capable of handling up to 256K \u2026"}, {"title": "Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models", "link": "https://arxiv.org/pdf/2410.21728", "details": "K Luo, Z Ding, Z Weng, L Qiao, M Zhao, X Li, D Yin\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "While Chain of Thought (CoT) prompting approaches have significantly consolidated the reasoning capabilities of large language models (LLMs), they still face limitations that require extensive human effort or have performance needs to be improved \u2026"}, {"title": "Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design", "link": "https://aclanthology.org/2024.findings-emnlp.990.pdf", "details": "R Bhagwatkar, S Nayak, P Bashivan, I Rish - Findings of the Association for \u2026, 2024", "abstract": "Abstract Vision-Language Models (VLMs) have seen a significant increase in both research interest and real-world applications across various domains, including healthcare, autonomous systems, and security. However, their growing prevalence \u2026"}]
