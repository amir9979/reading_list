[{"title": "Deliberative alignment: Reasoning enables safer language models", "link": "https://arxiv.org/pdf/2412.16339", "details": "MY Guan, M Joglekar, E Wallace, S Jain, B Barak\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large-scale language models increasingly impact safety-critical domains, ensuring their reliable adherence to well-defined principles remains a fundamental challenge. We introduce Deliberative Alignment, a new paradigm that directly \u2026"}, {"title": "TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation", "link": "https://arxiv.org/pdf/2412.03069", "details": "L Qu, H Zhang, Y Liu, X Wang, Y Jiang, Y Gao, H Ye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We present TokenFlow, a novel unified image tokenizer that bridges the long- standing gap between multimodal understanding and generation. Prior research attempt to employ a single reconstruction-targeted Vector Quantization (VQ) encoder \u2026"}, {"title": "Revisiting MLLMs: An In-Depth Analysis of Image Classification Abilities", "link": "https://arxiv.org/pdf/2412.16418", "details": "H Liu, L Xiao, J Liu, X Li, Z Feng, S Yang, J Wang - arXiv preprint arXiv:2412.16418, 2024", "abstract": "With the rapid advancement of Multimodal Large Language Models (MLLMs), a variety of benchmarks have been introduced to evaluate their capabilities. While most evaluations have focused on complex tasks such as scientific comprehension \u2026"}, {"title": "Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over Aligned Large Language Models", "link": "https://arxiv.org/pdf/2412.12865", "details": "Y Fan, Y Hong, Q Wang, J Bao, H Jiang, Y Song - arXiv preprint arXiv:2412.12865, 2024", "abstract": "Alignment, endowing a pre-trained Large language model (LLM) with the ability to follow instructions, is crucial for its real-world applications. Conventional supervised fine-tuning (SFT) methods formalize it as causal language modeling typically with a \u2026"}, {"title": "Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization", "link": "https://arxiv.org/pdf/2412.18279%3F", "details": "J Liu, C Wang, CY Liu, L Zeng, R Yan, Y Sun, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "The role of reinforcement learning (RL) in enhancing the reasoning of large language models (LLMs) is becoming increasingly significant. Despite the success of RL in many scenarios, there are still many challenges in improving the reasoning of \u2026"}, {"title": "GeoTool-GPT: a trainable method for facilitating Large Language Models to master GIS tools", "link": "https://www.tandfonline.com/doi/abs/10.1080/13658816.2024.2438937", "details": "C Wei, Y Zhang, X Zhao, Z Zeng, Z Wang, J Lin\u2026 - International Journal of \u2026, 2024", "abstract": "Abstract Large Language Models (LLMs) excel in natural language-relevant tasks like text generation and question answering Q&A. To further expand their application, efforts focus on enabling LLMs to utilize real-world tools. However, their tool-use \u2026"}, {"title": "Training large language models to reason in a continuous latent space", "link": "https://arxiv.org/pdf/2412.06769%3F", "details": "S Hao, S Sukhbaatar, DJ Su, X Li, Z Hu, J Weston\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) are restricted to reason in the\" language space\", where they typically express the reasoning process with a chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue that language space may \u2026"}, {"title": "XTransplant: A Probe into the Upper Bound Performance of Multilingual Capability and Culture Adaptability in LLMs via Mutual Cross-lingual Feed-forward \u2026", "link": "https://arxiv.org/pdf/2412.12686", "details": "Y Ye, X Feng, X Feng, L Qin, Y Huang, L Huang, W Ma\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Current large language models (LLMs) often exhibit imbalances in multilingual capabilities and cultural adaptability, largely due to their English-centric pretraining data. To address this imbalance, we propose a probing method named XTransplant \u2026"}, {"title": "Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models", "link": "https://arxiv.org/pdf/2412.08615", "details": "J Li, Y Hao, H Xu, X Wang, Y Hong - arXiv preprint arXiv:2412.08615, 2024", "abstract": "Despite the advancements in training Large Language Models (LLMs) with alignment techniques to enhance the safety of generated content, these models remain susceptible to jailbreak, an adversarial attack method that exposes security \u2026"}]
