[{"title": "FairFlow: An Automated Approach to Model-based Counterfactual Data Augmentation For NLP", "link": "https://arxiv.org/pdf/2407.16431", "details": "EK Tokpo, T Calders - arXiv preprint arXiv:2407.16431, 2024", "abstract": "Despite the evolution of language models, they continue to portray harmful societal biases and stereotypes inadvertently learned from training data. These inherent biases often result in detrimental effects in various applications. Counterfactual Data \u2026"}, {"title": "AbdomenAtlas: A Large-Scale, Detailed-Annotated, & Multi-Center Dataset for Efficient Transfer Learning and Open Algorithmic Benchmarking", "link": "https://arxiv.org/pdf/2407.16697", "details": "W Li, C Qu, X Chen, PRAS Bassi, Y Shi, Y Lai, Q Yu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We introduce the largest abdominal CT dataset (termed AbdomenAtlas) of 20,460 three-dimensional CT volumes sourced from 112 hospitals across diverse populations, geographies, and facilities. AbdomenAtlas provides 673K high-quality \u2026"}, {"title": "GCON: Differentially Private Graph Convolutional Network via Objective Perturbation", "link": "https://arxiv.org/pdf/2407.05034", "details": "J Wei, Y Zhu, X Xiao, E Bao, Y Yang, K Cai, BC Ooi - arXiv preprint arXiv:2407.05034, 2024", "abstract": "Graph Convolutional Networks (GCNs) are a popular machine learning model with a wide range of applications in graph analytics, including healthcare, transportation, and finance. Similar to other neural networks, a GCN may memorize parts of the \u2026"}, {"title": "LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models", "link": "https://arxiv.org/pdf/2406.19486", "details": "S Guo, S Damani, K Chang - arXiv preprint arXiv:2406.19486, 2024", "abstract": "In prompt tuning, a prefix or suffix text is added to the prompt, and the embeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix are optimized to gain more control over language models for specific tasks. This approach eliminates the \u2026"}, {"title": "IRIT-Berger-Levrault at SemEval-2024: How Sensitive Sentence Embeddings are to Hallucinations?", "link": "https://aclanthology.org/2024.semeval-1.86.pdf", "details": "N Bendahman, K Pinel-Sauvagnat, G Hubert, M Billami - Proceedings of the 18th \u2026, 2024", "abstract": "This article presents our participation to Task 6 of SemEval-2024, named SHROOM (a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes), which aims at detecting hallucinations. We propose two types of approaches for the \u2026"}, {"title": "Multi-Turn Hidden Backdoor in Large Language Model-powered Chatbot Models", "link": "https://dl.acm.org/doi/pdf/10.1145/3634737.3656289", "details": "B Chen, N Ivanov, G Wang, Q Yan - Proceedings of the 19th ACM Asia Conference on \u2026, 2024", "abstract": "Large Language Model (LLM)-powered chatbot services like GPTs, simulating human-to-human conversation via machine-generated text, are used in numerous fields. They are enhanced by the model fine-tuning process and the utilization of \u2026"}, {"title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation", "link": "https://arxiv.org/pdf/2406.19371", "details": "CM Pham, S Sun, M Iyyer - arXiv preprint arXiv:2406.19371, 2024", "abstract": "Existing research on instruction following largely focuses on tasks with simple instructions and short responses. In this work, we explore multi-constraint instruction following for generating long-form text. We create Suri, a dataset with 20K human \u2026"}]
