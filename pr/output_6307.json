[{"title": "MyThisYourThat for interpretable identification of systematic bias in federated learning for biomedical images", "link": "https://www.nature.com/articles/s41746-024-01226-1", "details": "K Naumova, A Devos, SP Karimireddy, M Jaggi\u2026 - npj Digital Medicine, 2024", "abstract": "Distributed collaborative learning is a promising approach for building predictive models for privacy-sensitive biomedical images. Here, several data owners (clients) train a joint model without sharing their original data. However, concealed systematic \u2026"}, {"title": "ED $^ 4$: Explicit Data-level Debiasing for Deepfake Detection", "link": "https://arxiv.org/pdf/2408.06779", "details": "J Cheng, Y Zhang, Q Zou, Z Yan, C Liang, Z Wang, C Li - arXiv preprint arXiv \u2026, 2024", "abstract": "Learning intrinsic bias from limited data has been considered the main reason for the failure of deepfake detection with generalizability. Apart from the discovered content and specific-forgery bias, we reveal a novel spatial bias, where detectors inertly \u2026"}, {"title": "Enhanced Industrial Action Recognition through Self-Supervised Visual Transformers", "link": "https://ieeexplore.ieee.org/iel8/6287639/6514899/10668864.pdf", "details": "Y Xiao, H Xiang, T Wang, Y Wang - IEEE Access, 2024", "abstract": "Precise recognition of operator actions is crucial in industrial automation for enhancing production efficiency and ensuring safety standards. This study introduces a novel self-supervised pretraining framework using visual transformers to \u2026"}]
