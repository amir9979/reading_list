[{"title": "VLMine: Long-Tail Data Mining with Vision Language Models", "link": "https://arxiv.org/pdf/2409.15486", "details": "M Ye, GP Meyer, Z Zhang, D Park, SK Mustikovela\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Ensuring robust performance on long-tail examples is an important problem for many real-world applications of machine learning, such as autonomous driving. This work focuses on the problem of identifying rare examples within a corpus of unlabeled \u2026"}, {"title": "EMIT-Event-Based Masked Auto Encoding for Irregular Time Series", "link": "https://arxiv.org/pdf/2409.16554", "details": "H Patel, R Qiu, A Irwin, S Sadiq, S Wang - arXiv preprint arXiv:2409.16554, 2024", "abstract": "Irregular time series, where data points are recorded at uneven intervals, are prevalent in healthcare settings, such as emergency wards where vital signs and laboratory results are captured at varying times. This variability, which reflects critical \u2026"}, {"title": "Protocol for Designing a Model to Predict the likelihood of Psychosis From electronic health records using natural language Processing and Machine learning", "link": "https://www.thepermanentejournal.org/doi/pdf/10.7812/tpj.28.issue-3%23page%3D33", "details": "I Stavers-Sosa, DJ Cronkite, LD Gerstley, A Kelley\u2026 - The Permanente Journal, 2024", "abstract": "Introduction Rapid identification of individuals developing a psychotic spectrum disorder (PSD) is crucial because untreated psychosis is associated with poor outcomes and decreased treatment response. Lack of recognition of early psychotic \u2026"}, {"title": "Expert-level vision-language foundation model for real-world radiology and comprehensive evaluation", "link": "https://arxiv.org/pdf/2409.16183", "details": "X Liu, G Yang, Y Luo, J Mao, X Zhang, M Gao, S Zhang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Radiology is a vital and complex component of modern clinical workflow and covers many tasks. Recently, vision-language (VL) foundation models in medicine have shown potential in processing multimodal information, offering a unified solution for \u2026"}, {"title": "Supplementary Materials for FlexAttention for Efficient High-Resolution Vision-Language Models", "link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03642-supp.pdf", "details": "J Li, D Chen, T Cai, P Chen, Y Hong, Z Chen, Y Shen\u2026", "abstract": "\u2013V* Bench contains 191 high-resolution images from SA-1B dataset [4] with an average resolution of 2246\u00d7 1582. There are two sub-tasks in this benchmark: attribute recognition and spatial relationship reasoning. Following [10] we select the \u2026"}]
