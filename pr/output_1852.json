[{"title": "Small Language Models Need Strong Verifiers to Self-Correct Reasoning", "link": "https://arxiv.org/pdf/2404.17140", "details": "Y Zhang, M Khalifa, L Logeswaran, J Kim, M Lee\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether \u2026"}, {"title": "A Systematic Analysis on the Temporal Generalization of Language Models in Social Media", "link": "https://arxiv.org/pdf/2405.13017", "details": "A Ushio, J Camacho-Collados - arXiv preprint arXiv:2405.13017, 2024", "abstract": "In machine learning, temporal shifts occur when there are differences between training and test splits in terms of time. For streaming data such as news or social media, models are commonly trained on a fixed corpus from a certain period of time \u2026"}, {"title": "A Dynamic Model of Performative Human-ML Collaboration: Theory and Empirical Evidence", "link": "https://arxiv.org/pdf/2405.13753", "details": "T S\u00fchr, S Samadi, C Farronato - arXiv preprint arXiv:2405.13753, 2024", "abstract": "Machine learning (ML) models are increasingly used in various applications, from recommendation systems in e-commerce to diagnosis prediction in healthcare. In this paper, we present a novel dynamic framework for thinking about the deployment \u2026"}, {"title": "Federated Domain-Specific Knowledge Transfer on Large Language Models Using Synthetic Data", "link": "https://arxiv.org/pdf/2405.14212", "details": "H Li, X Zhao, D Guo, H Gu, Z Zeng, Y Han, Y Song\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) demonstrate unparalleled performance and generalization ability, LLMs are widely used and integrated into various applications. When it comes to sensitive domains, as commonly described in federated learning \u2026"}, {"title": "Evaluating LLMs for Temporal Entity Extraction from Pediatric Clinical Text in Rare Diseases Context", "link": "https://aclanthology.org/2024.cl4health-1.18.pdf", "details": "JJ Andrew, M Vincent, A Burgun, N Garcelon - Proceedings of the First Workshop on \u2026, 2024", "abstract": "The aim of this work is to extract Temporal Entities from patients' EHR from pediatric hospital specialising in Rare Diseases, thus allowing to create a patient timeline relative to diagnosis. We aim to perform an evaluation of NLP tools and Large \u2026"}, {"title": "A Transformer-Based Approach for Smart Invocation of Automatic Code Completion", "link": "https://arxiv.org/pdf/2405.14753", "details": "A de Moor, A van Deursen, M Izadi - arXiv preprint arXiv:2405.14753, 2024", "abstract": "Transformer-based language models are highly effective for code completion, with much research dedicated to enhancing the content of these completions. Despite their effectiveness, these models come with high operational costs and can be \u2026"}, {"title": "Temporal Scaling Law for Large Language Models", "link": "https://arxiv.org/pdf/2404.17785", "details": "Y Xiong, X Chen, X Ye, H Chen, Z Lin, H Lian, J Niu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, Large Language Models (LLMs) are widely adopted in a wide range of tasks, leading to increasing attention towards the research on how scaling LLMs affects their performance. Existing works, termed as Scaling Laws, have discovered \u2026"}, {"title": "Towards Comprehensive and Efficient Post Safety Alignment of Large Language Models via Safety Patching", "link": "https://arxiv.org/pdf/2405.13820", "details": "W Zhao, Y Hu, Z Li, Y Deng, Y Zhao, B Qin, TS Chua - arXiv preprint arXiv \u2026, 2024", "abstract": "Safety alignment of large language models (LLMs) has been gaining increasing attention. However, current safety-aligned LLMs suffer from the fragile and imbalanced safety mechanisms, which can still be induced to generate unsafe \u2026"}, {"title": "BELIEVE: Belief-enhanced instruction generation and augmentation for zero-shot bias mitigation", "link": "https://www.amazon.science/publications/believe-belief-enhanced-instruction-generation-and-augmentation-for-zero-shot-bias-mitigation", "details": "L Bauer, N Mehrabi, P Goyal, KW Chang, A Galstyan\u2026 - 2024", "abstract": "Abstract Language models, pre-trained on large amounts of unmoderated content, have been shown to contain societal biases. Mitigating such biases typically requires access to model parameters and training schemas. In this work, we address bias \u2026"}]
