[{"title": "Leveraging Coarse-to-Fine Grained Representations in Contrastive Learning for Differential Medical Visual Question Answering", "link": "https://papers.miccai.org/miccai-2024/paper/1957_paper.pdf", "details": "X Liang, Y Wang, D Wang, Z Jiao, H Zhong, M Yang\u2026 - International Conference on \u2026, 2024", "abstract": "Abstract Chest X-ray Differential Medical Visual Question Answering (Diff-MedVQA) is a novel multi-modal task designed to answer questions about diseases, especially their differences, based on a main image and a reference image. Compared to the \u2026"}, {"title": "FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models", "link": "https://arxiv.org/pdf/2410.04810", "details": "H Chen, H Li, Y Zhang, G Zhang, J Bi, P Torr, J Gu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "One-Shot Federated Learning (OSFL), a special decentralized machine learning paradigm, has recently gained significant attention. OSFL requires only a single round of client data or model upload, which reduces communication costs and \u2026"}, {"title": "T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data", "link": "https://arxiv.org/pdf/2410.05016", "details": "H Thimonier, JLDM Costa, F Popineau, A Rimmel\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-supervision is often used for pre-training to foster performance on a downstream task by constructing meaningful representations of samples. Self-supervised learning (SSL) generally involves generating different views of the same sample and thus \u2026"}, {"title": "Rethinking Fair Representation Learning for Performance-Sensitive Tasks", "link": "https://arxiv.org/pdf/2410.04120", "details": "C Jones, FS Ribeiro, M Roschewitz, DC Castro\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "We investigate the prominent class of fair representation learning methods for bias mitigation. Using causal reasoning to define and formalise different sources of dataset bias, we reveal important implicit assumptions inherent to these methods. We \u2026"}, {"title": "Failure-Proof Non-Contrastive Self-Supervised Learning", "link": "https://arxiv.org/pdf/2410.04959", "details": "E Sansone, T Lebailly, T Tuytelaars - arXiv preprint arXiv:2410.04959, 2024", "abstract": "We identify sufficient conditions to avoid known failure modes, including representation, dimensional, cluster and intracluster collapses, occurring in non- contrastive self-supervised learning. Based on these findings, we propose a \u2026"}, {"title": "CROCODILE: Causality Aids Robustness via Contrastive Disentangled", "link": "https://books.google.com/books%3Fhl%3Den%26lr%3Dlang_en%26id%3D3TMmEQAAQBAJ%26oi%3Dfnd%26pg%3DPA105%26ots%3DuDUMFX9jHi%26sig%3DpVJ-bS0qqi_t1efvL1fQw4dE8lw", "details": "G Carloni, SA Tsaftaris, S Colantonio\u00b9 - Uncertainty for Safe Utilization of Machine Learning \u2026", "abstract": "Deep learning image classifiers often struggle with domain shift, leading to significant performance degradation in real-world applications. In this paper, we introduce our CROCODILE framework, showing how tools from causality can foster a \u2026"}, {"title": "Real-World Benchmarks Make Membership Inference Attacks Fail on Diffusion Models", "link": "https://arxiv.org/pdf/2410.03640", "details": "C Liang, J You - arXiv preprint arXiv:2410.03640, 2024", "abstract": "Membership inference attacks (MIAs) on diffusion models have emerged as potential evidence of unauthorized data usage in training pre-trained diffusion models. These attacks aim to detect the presence of specific images in training datasets of diffusion \u2026"}, {"title": "Pruning then Reweighting: Towards Data-Efficient Training of Diffusion Models", "link": "https://arxiv.org/pdf/2409.19128", "details": "Y Li, Y Zhang, S Liu, X Lin - arXiv preprint arXiv:2409.19128, 2024", "abstract": "Despite the remarkable generation capabilities of Diffusion Models (DMs), conducting training and inference remains computationally expensive. Previous works have been devoted to accelerating diffusion sampling, but achieving data \u2026"}, {"title": "DiffDGSS: Generalizable Retinal Image Segmentation with Deterministic Representation from Diffusion Models", "link": "https://papers.miccai.org/miccai-2024/paper/1173_paper.pdf", "details": "Y Xie, J Qu, H Xie, T Wang, B Lei - \u2026 Conference on Medical Image Computing and \u2026, 2024", "abstract": "Acquiring a comprehensive segmentation map of the retinal image serves as the preliminary step in developing an interpretable diagnostic tool for retinopathy. However, the inherent complexity of retinal anatomical structures and lesions, along \u2026"}]
