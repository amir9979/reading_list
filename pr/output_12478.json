[{"title": "From My View to Yours: Ego-Augmented Learning in Large Vision Language Models for Understanding Exocentric Daily Living Activities", "link": "https://arxiv.org/pdf/2501.05711", "details": "D Reilly, MK Govind, S Das - arXiv preprint arXiv:2501.05711, 2025", "abstract": "Large Vision Language Models (LVLMs) have demonstrated impressive capabilities in video understanding, yet their adoption for Activities of Daily Living (ADL) remains limited by their inability to capture fine-grained interactions and spatial relationships \u2026"}, {"title": "Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation", "link": "https://arxiv.org/pdf/2501.03545%3F", "details": "C Samarinas, A Krubner, A Salemi, Y Kim, H Zamani - arXiv preprint arXiv \u2026, 2025", "abstract": "This paper presents ICAT, an evaluation framework for measuring coverage of diverse factual information in long-form text generation. ICAT breaks down a long output text into a list of atomic claims and not only verifies each claim through \u2026"}, {"title": "Recalibrated cross-modal alignment network for radiology report generation with weakly supervised contrastive learning", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425000168", "details": "X Hou, X Li, Z Liu, S Sang, M Lu, Y Zhang - Expert Systems with Applications, 2025", "abstract": "Automatic radiology report generation is rapidly becoming an essential method for medical diagnosis and precision medicine, which will help clinical doctors make more informed decisions and achieve better results. Most previous studies mainly \u2026"}, {"title": "FreqSpace-NeRF: A fourier-enhanced Neural Radiance Fields method via dual-domain contrastive learning for novel view synthesis", "link": "https://www.sciencedirect.com/science/article/pii/S009784932500010X", "details": "X Yu, X Tian, J Chen, Y Wang - Computers & Graphics, 2025", "abstract": "Abstract Inspired by Neural Radiance Field's (NeRF) groundbreaking success in novel view synthesis, current methods mostly employ variants of various deep neural network architectures, and use the combination of multi-scale feature maps with the \u2026"}, {"title": "Leveraging Language Models for Summarizing Mental State Examinations: A Comprehensive Evaluation and Dataset Release", "link": "https://aclanthology.org/2025.coling-main.182.pdf", "details": "NK Sahu, M Yadav, M Chaturvedi, S Gupta, HR Lone - Proceedings of the 31st \u2026, 2025", "abstract": "Mental health disorders affect a significant portion of the global population, with diagnoses primarily conducted through Mental State Examinations (MSEs). MSEs serve as structured assessments to evaluate behavioral and cognitive functioning \u2026"}, {"title": "MiniMedGPT: Efficient Large Vision-Language Model for medical Visual Question Answering", "link": "https://www.sciencedirect.com/science/article/pii/S0167865525000017", "details": "AR Alsabbagh, T Mansour, M Al-Kharabsheh\u2026 - Pattern Recognition Letters, 2025", "abstract": "Abstract While Large Vision-Language Models (LVLMs) like GPT-4 and Gemini demonstrate significant potential, their utilization in the medical domain remains largely unexplored. This is due to challenges attributed to prolonged training and \u2026"}, {"title": "Expert evaluation of large language models for clinical dialogue summarization", "link": "https://www.nature.com/articles/s41598-024-84850-x", "details": "D Fraile Navarro, E Coiera, TW Hambly, Z Triplett\u2026 - Scientific Reports, 2025", "abstract": "We assessed the performance of large language models' summarizing clinical dialogues using computational metrics and human evaluations. The comparison was done between automatically generated and human-produced summaries. We \u2026"}, {"title": "Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval", "link": "https://arxiv.org/pdf/2501.09134", "details": "D Deanda, YP Masupalli, J Yang, Y Lee, Z Cao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Medical images and reports offer invaluable insights into patient health. The heterogeneity and complexity of these data hinder effective analysis. To bridge this gap, we investigate contrastive learning models for cross-domain retrieval, which \u2026"}, {"title": "LLaVA-ST: A Multimodal Large Language Model for Fine-Grained Spatial-Temporal Understanding", "link": "https://arxiv.org/pdf/2501.08282", "details": "H Li, J Chen, Z Wei, S Huang, T Hui, J Gao, X Wei\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recent advancements in multimodal large language models (MLLMs) have shown promising results, yet existing approaches struggle to effectively handle both temporal and spatial localization simultaneously. This challenge stems from two key \u2026"}]
