[{"title": "Mitigating Multilingual Hallucination in Large Vision-Language Models", "link": "https://arxiv.org/pdf/2408.00550", "details": "X Qu, M Song, W Wei, J Dong, Y Cheng - arXiv preprint arXiv:2408.00550, 2024", "abstract": "While Large Vision-Language Models (LVLMs) have exhibited remarkable capabilities across a wide range of tasks, they suffer from hallucination problems, where models generate plausible yet incorrect answers given the input image-query \u2026"}, {"title": "Event-Based Contrastive Learning for Medical Time Series", "link": "https://openreview.net/pdf%3Fid%3DTEG1wypeoD", "details": "N Oufattole, H Jeong, M Mcdermott, A Balagopalan\u2026 - 2024", "abstract": "In clinical practice, one often needs to identify whether a patient is at high risk of adverse outcomes after some key medical event. For example, quantifying the risk of adverse outcomes after an acute cardiovascular event helps healthcare providers \u2026"}]
