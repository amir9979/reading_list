[{"title": "Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models", "link": "https://arxiv.org/pdf/2412.11041", "details": "D Wu, X Lu, Y Zhao, B Qin - arXiv preprint arXiv:2412.11041, 2024", "abstract": "Although large language models (LLMs) achieve effective safety alignment at the time of release, they still face various safety challenges. A key issue is that fine- tuning often compromises the safety alignment of LLMs. To address this issue, we \u2026"}, {"title": "MetaRuleGPT: Recursive Numerical Reasoning of Language Models Trained with Simple Rules", "link": "https://arxiv.org/pdf/2412.13536", "details": "K Chen, L Wang, Q Zhang, R Xu - arXiv preprint arXiv:2412.13536, 2024", "abstract": "Recent studies have highlighted the limitations of large language models in mathematical reasoning, particularly their inability to capture the underlying logic. Inspired by meta-learning, we propose that models should acquire not only task \u2026"}, {"title": "Guiding Generative Protein Language Models with Reinforcement Learning", "link": "https://arxiv.org/pdf/2412.12979", "details": "F Stocco, M Artigues-Lleixa, A Hunklinger, T Widatalla\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Autoregressive protein language models (pLMs) have emerged as powerful tools to efficiently design functional proteins with extraordinary diversity, as evidenced by the successful generation of diverse enzyme families, including lysozymes or carbonic \u2026"}, {"title": "MetaMorph: Multimodal Understanding and Generation via Instruction Tuning", "link": "https://arxiv.org/pdf/2412.14164", "details": "S Tong, D Fan, J Zhu, Y Xiong, X Chen, K Sinha\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this work, we propose Visual-Predictive Instruction Tuning (VPiT)-a simple and effective extension to visual instruction tuning that enables a pretrained LLM to quickly morph into an unified autoregressive model capable of generating both text \u2026"}, {"title": "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces", "link": "https://arxiv.org/pdf/2412.14171", "details": "J Yang, S Yang, AW Gupta, R Han, L Fei-Fei, S Xie - arXiv preprint arXiv:2412.14171, 2024", "abstract": "Humans possess the visual-spatial intelligence to remember spaces from sequential visual observations. However, can Multimodal Large Language Models (MLLMs) trained on million-scale video datasets also``think in space''from videos? We present \u2026"}, {"title": "Heuristic-Induced Multimodal Risk Distribution Jailbreak Attack for Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2412.05934", "details": "M Teng, J Xiaojun, D Ranjie, L Xinfeng, H Yihao\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "With the rapid advancement of multimodal large language models (MLLMs), concerns regarding their security have increasingly captured the attention of both academia and industry. Although MLLMs are vulnerable to jailbreak attacks \u2026"}, {"title": "Smoothed Embeddings for Robust Language Models", "link": "https://www.merl.com/publications/docs/TR2024-170.pdf", "details": "H Ryo, MRU Rashid, A Lewis, J Liu, T Koike-Akino\u2026", "abstract": "Improving the safety and reliability of large language models (LLMs) is a crucial aspect of realizing trustworthy AI systems. Although alignment methods aim to suppress harmful content generation, LLMs are often still vulnerable to jail-breaking \u2026"}, {"title": "EXAONE 3.5: Series of Large Language Models for Real-world Use Cases", "link": "https://arxiv.org/pdf/2412.04862", "details": "LG Research, S An, K Bae, E Choi, K Choi, SJ Choi\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "This technical report introduces the EXAONE 3.5 instruction-tuned language models, developed and released by LG AI Research. The EXAONE 3.5 language models are offered in three configurations: 32B, 7.8 B, and 2.4 B. These models feature several \u2026"}, {"title": "Physics Reasoner: Knowledge-Augmented Reasoning for Solving Physics Problems with Large Language Models", "link": "https://arxiv.org/pdf/2412.13791", "details": "X Pang, R Hong, Z Zhou, F Lv, X Yang, Z Liang, B Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Physics problems constitute a significant aspect of reasoning, necessitating complicated reasoning ability and abundant physics knowledge. However, existing large language models (LLMs) frequently fail due to a lack of knowledge or incorrect \u2026"}]
