[{"title": "REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability", "link": "https://arxiv.org/pdf/2412.08513", "details": "KK Wickstr\u00f8m, T Br\u00fcsch, MC Kampffmeyer, R Jenssen - arXiv preprint arXiv \u2026, 2024", "abstract": "Incorporating uncertainty is crucial to provide trustworthy explanations of deep learning models. Recent works have demonstrated how uncertainty modeling can be particularly important in the unsupervised field of representation learning explainable \u2026"}, {"title": "Frame Representation Hypothesis: Multi-Token LLM Interpretability and Concept-Guided Text Generation", "link": "https://arxiv.org/pdf/2412.07334", "details": "PHV Valois, LS Souza, EK Shimomoto, K Fukui - arXiv preprint arXiv:2412.07334, 2024", "abstract": "Interpretability is a key challenge in fostering trust for Large Language Models (LLMs), which stems from the complexity of extracting reasoning from model's parameters. We present the Frame Representation Hypothesis, a theoretically robust \u2026"}, {"title": "Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2411.14432", "details": "Y Dong, Z Liu, HL Sun, J Yang, W Hu, Y Rao, Z Liu - arXiv preprint arXiv:2411.14432, 2024", "abstract": "Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1. Despite various efforts to improve LLM reasoning, high \u2026"}, {"title": "Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models", "link": "https://arxiv.org/pdf/2412.02674%3F", "details": "Y Song, H Zhang, C Eisenach, S Kakade, D Foster\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-improvement is a mechanism in Large Language Model (LLM) pre-training, post- training and test-time inference. We explore a framework where the model verifies its own outputs, filters or reweights data based on this verification, and distills the filtered \u2026"}]
