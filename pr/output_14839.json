[{"title": "Counterfactual Language Reasoning for Explainable Recommendation Systems", "link": "https://arxiv.org/pdf/2503.08051", "details": "G Li, H Yang, X Liu, Z Wu, X Dai - arXiv preprint arXiv:2503.08051, 2025", "abstract": "Explainable recommendation systems leverage transparent reasoning to foster user trust and improve decision-making processes. Current approaches typically decouple recommendation generation from explanation creation, violating causal \u2026"}, {"title": "Can large language models independently complete tasks? A dynamic evaluation framework for multi-turn task planning and completion", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225008070", "details": "J Gao, J Cui, H Wu, L Xiang, H Zhao, X Li, M Fang\u2026 - Neurocomputing, 2025", "abstract": "Large language models (LLMs) are increasingly relied upon for multi-turn dialogue to conduct complex tasks. However, existing benchmarks mainly evaluate LLMs as agents, overlooking their potential as independent systems to accomplish complex \u2026"}]
