[{"title": "A Cross-Sectional Study of GPT-4\u2013Based Plain Language Translation of Clinical Notes to Improve Patient Comprehension of Disease Course and Management", "link": "https://ai.nejm.org/doi/abs/10.1056/AIoa2400402", "details": "A Kumar, H Wang, KW Muir, V Mishra, M Engelhard - NEJM AI, 2025", "abstract": "Abstract Background The 21st Century Cures Act provides patients with access to their clinical notes, but most patients, particularly those with limited health literacy, have difficulty understanding and utilizing them for health decisions and care \u2026"}, {"title": "Classifying Unstructured Text in Electronic Health Records for Mental Health Prediction Models: Large Language Model Evaluation Study", "link": "https://medinform.jmir.org/2025/1/e65454/", "details": "NC Cardamone, M Olfson, T Schmutte, L Ungar, T Liu\u2026 - JMIR Medical Informatics, 2025", "abstract": "Background: Prediction models have demonstrated a range of applications across medicine, including using electronic health record (EHR) data to identify hospital readmission and mortality risk. Large language models (LLMs) can transform \u2026"}, {"title": "OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models", "link": "https://arxiv.org/pdf/2501.12975", "details": "C Sun, Y Li, D Wu, B Boulet - arXiv preprint arXiv:2501.12975, 2025", "abstract": "Large Language Models (LLMs) are highly capable but require significant computational resources for both training and inference. Within the LLM family, smaller models (those with fewer than 10 billion parameters) also perform well \u2026"}]
