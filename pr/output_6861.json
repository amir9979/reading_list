[{"title": "Reasoning and Planning with Large Language Models in Code Development", "link": "https://dl.acm.org/doi/pdf/10.1145/3637528.3671452", "details": "H Ding, Z Fan, I Guehring, G Gupta, W Ha, J Huan\u2026 - Proceedings of the 30th \u2026, 2024", "abstract": "Large Language Models (LLMs) are revolutionizing the field of code development by leveraging their deep understanding of code patterns, syntax, and semantics to assist developers in various tasks, from code generation and testing to code \u2026"}, {"title": "Pairwise Proximal Policy Optimization: Language Model Alignment with Comparative RL", "link": "https://openreview.net/pdf%3Fid%3D7iaAlIlV2H", "details": "T Wu, B Zhu, R Zhang, Z Wen, K Ramchandran, J Jiao - First Conference on Language \u2026", "abstract": "LLMs may exhibit harmful behavior without aligning with human values. The dominant approach for steering LLMs towards beneficial behavior is Reinforcement Learning with Human Feedback (RLHF). This involves training a reward model with \u2026"}, {"title": "Path-Consistency: Prefix Enhancement for Efficient Inference in LLM", "link": "https://arxiv.org/pdf/2409.01281", "details": "J Zhu, Y Shen, J Zhao, A Zou - arXiv preprint arXiv:2409.01281, 2024", "abstract": "To enhance the reasoning capabilities of large language models (LLMs), self- consistency has gained significant popularity by combining multiple sampling with majority voting. However, the state-of-the-art self-consistency approaches consume \u2026"}, {"title": "Explaining decisions without explainability? Artificial intelligence and medicolegal accountability", "link": "https://www.sciencedirect.com/science/article/pii/S2514664524015613", "details": "MD McCradden, I Stedman - Future Healthcare Journal, 2024", "abstract": "Explanations are fundamental to our culture. From medical ethics to cookie policies, the range of situations where we seek explanations\u2013and in fact, in some cases, have a right to them\u2013is broad. It makes sense that, for artificial intelligence (AI) in medicine \u2026"}, {"title": "Self-Evolutionary Large Language Models through Uncertainty-Enhanced Preference Optimization", "link": "https://arxiv.org/pdf/2409.11212", "details": "J Wang, Y Zhou, X Zhang, M Bao, P Yan - arXiv preprint arXiv:2409.11212, 2024", "abstract": "Iterative preference optimization has recently become one of the de-facto training paradigms for large language models (LLMs), but the performance is still underwhelming due to too much noisy preference data yielded in the loop. To \u2026"}, {"title": "Efficient Mixture of Experts based on Large Language Models for Low-Resource Data Preprocessing", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671873", "details": "M Yan, Y Wang, K Pang, M Xie, J Li - Proceedings of the 30th ACM SIGKDD \u2026, 2024", "abstract": "Data preprocessing (DP) that transforms erroneous and raw data to a clean version is a cornerstone of the data mining pipeline. Due to the diverse requirements of downstream tasks, data scientists and domain experts have to handcraft domain \u2026"}, {"title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models", "link": "https://arxiv.org/pdf/2408.15778", "details": "J Gui, Y Liu, J Cheng, X Gu, X Liu, H Wang, Y Dong\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across various tasks, showcasing complex problem-solving abilities. Understanding and executing complex rules, along with multi-step planning, are fundamental to logical \u2026"}, {"title": "Assessing Contamination in Large Language Models: Introducing the LogProber method", "link": "https://arxiv.org/pdf/2408.14352", "details": "N Yax, PY Oudeyer, S Palminteri - arXiv preprint arXiv:2408.14352, 2024", "abstract": "In machine learning, contamination refers to situations where testing data leak into the training set. The issue is particularly relevant for the evaluation of the performance of Large Language Models (LLMs), which are generally trained on \u2026"}, {"title": "GraphWiz: An Instruction-Following Language Model for Graph Computational Problems", "link": "https://dl.acm.org/doi/abs/10.1145/3637528.3672010", "details": "N Chen, Y Li, J Tang, J Li - Proceedings of the 30th ACM SIGKDD Conference on \u2026, 2024", "abstract": "Large language models (LLMs) have achieved impressive success across various domains, but their capability in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel \u2026"}]
