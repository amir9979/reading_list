[{"title": "Do Larger Language Models Imply Better Reasoning? A Pretraining Scaling Law for Reasoning", "link": "https://arxiv.org/pdf/2504.03635", "details": "X Wang, S Tan, M Jin, WY Wang, R Panda, Y Shen - arXiv preprint arXiv:2504.03635, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks requiring complex reasoning. However, the effects of scaling on their reasoning abilities remain insufficiently understood. In this paper, we \u2026"}, {"title": "Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent", "link": "https://arxiv.org/pdf/2504.04702", "details": "B Chen, Z Shi, Z Song, J Zhang - arXiv preprint arXiv:2504.04702, 2025", "abstract": "Recent advancements in Transformer-based architectures have led to impressive breakthroughs in natural language processing tasks, with models such as GPT-4, Claude, and Gemini demonstrating human-level reasoning abilities. However \u2026"}, {"title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models", "link": "https://arxiv.org/pdf/2504.05258", "details": "A Bazaga, R Blloshmi, B Byrne, A de Gispert - arXiv preprint arXiv:2504.05258, 2025", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating coherent text, understanding context, and performing reasoning tasks. However, they struggle with temporal reasoning, which requires processing time-related information \u2026"}, {"title": "Improving Multilingual Retrieval-Augmented Language Models through Dialectic Reasoning Argumentations", "link": "https://arxiv.org/pdf/2504.04771", "details": "L Ranaldi, F Ranaldi, FM Zanzotto, B Haddow, A Birch - arXiv preprint arXiv \u2026, 2025", "abstract": "Retrieval-augmented generation (RAG) is key to enhancing large language models (LLMs) to systematically access richer factual knowledge. Yet, using RAG brings intrinsic challenges, as LLMs must deal with potentially conflicting knowledge \u2026"}, {"title": "Entropy-Based Block Pruning for Efficient Large Language Models", "link": "https://arxiv.org/pdf/2504.03794", "details": "L Yang, Y Xu, J Tan, D Sahoo, S Savarese, C Xiong\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "As large language models continue to scale, their growing computational and storage demands pose significant challenges for real-world deployment. In this work, we investigate redundancy within Transformer-based models and propose an \u2026"}, {"title": "Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models", "link": "https://arxiv.org/pdf/2504.05050", "details": "J Lian, J Pan, L Wang, Y Wang, S Mei, LP Chau - arXiv preprint arXiv:2504.05050, 2025", "abstract": "Large language models (LLMs) are foundational explorations to artificial general intelligence, yet their alignment with human values via instruction tuning and preference learning achieves only superficial compliance. Here, we demonstrate that \u2026"}, {"title": "What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models", "link": "https://arxiv.org/pdf/2503.24235%3F", "details": "Q Zhang, F Lyu, Z Sun, L Wang, W Zhang, Z Guo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as``test-time computing''has emerged as a prominent research focus. Recent studies demonstrate \u2026"}, {"title": "Agentic Large Language Models, a survey", "link": "https://arxiv.org/pdf/2503.23037", "details": "A Plaat, M van Duijn, N van Stein, M Preuss\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "There is great interest in agentic LLMs, large language models that act as agents. We review the growing body of work in this area and provide a research agenda. Agentic LLMs are LLMs that (1) reason,(2) act, and (3) interact. We organize the \u2026"}, {"title": "Beyond Accuracy: The Role of Calibration in Self-Improving Large Language Models", "link": "https://arxiv.org/pdf/2504.02902", "details": "L Huang, D Li, H Liu, L Cheng - arXiv preprint arXiv:2504.02902, 2025", "abstract": "Large Language Models (LLMs) have demonstrated remarkable self-improvement capabilities, whereby models iteratively revise their outputs through self-generated feedback. While this reflective mechanism has shown promise in enhancing task \u2026"}]
