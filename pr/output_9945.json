[{"title": "The Radiance of Neural Fields: Democratizing Photorealistic and Dynamic Robotic Simulation", "link": "https://arxiv.org/pdf/2411.16940", "details": "G Nuthall, R Bowden, O Mendez - arXiv preprint arXiv:2411.16940, 2024", "abstract": "As robots increasingly coexist with humans, they must navigate complex, dynamic environments rich in visual information and implicit social dynamics, like when to yield or move through crowds. Addressing these challenges requires significant \u2026"}, {"title": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "link": "https://arxiv.org/pdf/2411.06869", "details": "J Kim, H Chung, BH Kim - arXiv preprint arXiv:2411.06869, 2024", "abstract": "Category-agnostic pose estimation (CAPE) has traditionally relied on support images with annotated keypoints, a process that is often cumbersome and may fail to fully capture the necessary correspondences across diverse object categories. Recent \u2026"}, {"title": "Informed Augmentation Selection Improves Tabular Contrastive Learning", "link": "https://openreview.net/pdf%3Fid%3DGFu8qDtVQa", "details": "A Khoeini, S Peng, M Ester - NeurIPS 2024 Workshop: Self-Supervised Learning \u2026", "abstract": "While contrastive learning (CL) has demonstrated success in image data, its application to tabular data remains relatively unexplored. The effectiveness of CL heavily depends on data augmentations, yet the suitability of tabular augmentation \u2026"}, {"title": "Uni-Mlip: Unified Self-supervision for Medical Vision Language Pre-training", "link": "https://arxiv.org/pdf/2411.15207", "details": "A Bawazir, K Wu, W Li - arXiv preprint arXiv:2411.15207, 2024", "abstract": "Recent advancements in vision-language pre-training via contrastive learning have significantly improved performance across computer vision tasks. However, in the medical domain, obtaining multimodal data is often costly and challenging due to \u2026"}, {"title": "VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models", "link": "https://arxiv.org/pdf/2412.01095", "details": "M Ye, W Liu, P He - arXiv preprint arXiv:2412.01095, 2024", "abstract": "The rapid advancement of vision-language models (VLMs) has established a new paradigm in video anomaly detection (VAD): leveraging VLMs to simultaneously detect anomalies and provide comprehendible explanations for the decisions \u2026"}, {"title": "Free $^ 2$ Guide: Gradient-Free Path Integral Control for Enhancing Text-to-Video Generation with Large Vision-Language Models", "link": "https://arxiv.org/pdf/2411.17041", "details": "J Kim, BS Kim, JC Ye - arXiv preprint arXiv:2411.17041, 2024", "abstract": "Diffusion models have achieved impressive results in generative tasks like text-to- image (T2I) and text-to-video (T2V) synthesis. However, achieving accurate text alignment in T2V generation remains challenging due to the complex temporal \u2026"}, {"title": "ReVisionLLM: Recursive Vision-Language Model for Temporal Grounding in Hour-Long Videos", "link": "https://arxiv.org/pdf/2411.14901", "details": "T Hannan, MM Islam, J Gu, T Seidl, G Bertasius - arXiv preprint arXiv:2411.14901, 2024", "abstract": "Large language models (LLMs) excel at retrieving information from lengthy text, but their vision-language counterparts (VLMs) face difficulties with hour-long videos, especially for temporal grounding. Specifically, these VLMs are constrained by frame \u2026"}, {"title": "ACE: Action Concept Enhancement of Video-Language Models in Procedural Videos", "link": "https://arxiv.org/pdf/2411.15628", "details": "R Ghoddoosian, N Agarwal, I Dwivedi, B Darisuh - arXiv preprint arXiv:2411.15628, 2024", "abstract": "Vision-language models (VLMs) are capable of recognizing unseen actions. However, existing VLMs lack intrinsic understanding of procedural action concepts. Hence, they overfit to fixed labels and are not invariant to unseen action synonyms \u2026"}, {"title": "Med-2E3: A 2D-Enhanced 3D Medical Multimodal Large Language Model", "link": "https://arxiv.org/pdf/2411.12783", "details": "Y Shi, X Zhu, Y Hu, C Guo, M Li, J Wu - arXiv preprint arXiv:2411.12783, 2024", "abstract": "The analysis of 3D medical images is crucial for modern healthcare, yet traditional task-specific models are becoming increasingly inadequate due to limited generalizability across diverse clinical scenarios. Multimodal large language models \u2026"}]
