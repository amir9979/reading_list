'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [How does Architecture Influence the Base Capabilities '
[{"title": "Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering", "link": "https://arxiv.org/html/2403.04890v1", "details": "O Gramopadhye, SS Nachane, P Chanda\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large Language models (LLMs) have demonstrated significant potential in transforming healthcare by automating tasks such as clinical documentation, information retrieval, and decision support. In this aspect, carefully engineered \u2026"}, {"title": "Chain-of-Spot: Interactive Reasoning Improves Large Vision-Language Models", "link": "https://arxiv.org/pdf/2403.12966", "details": "Z Liu, Y Dong, Y Rao, J Zhou, J Lu - arXiv preprint arXiv:2403.12966, 2024", "abstract": "In the realm of vision-language understanding, the proficiency of models in interpreting and reasoning over visual content has become a cornerstone for numerous applications. However, it is challenging for the visual encoder in Large \u2026"}, {"title": "Language models scale reliably with over-training and on downstream tasks", "link": "https://arxiv.org/pdf/2403.08540", "details": "SY Gadre, G Smyrnis, V Shankar, S Gururangan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Scaling laws are useful guides for developing language models, but there are still gaps between current scaling studies and how language models are ultimately trained and evaluated. For instance, scaling is usually studied in the compute \u2026"}, {"title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models", "link": "https://arxiv.org/pdf/2403.18814", "details": "Y Li, Y Zhang, C Wang, Z Zhong, Y Chen, R Chu, S Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In this work, we introduce Mini-Gemini, a simple and effective framework enhancing multi-modality Vision Language Models (VLMs). Despite the advancements in VLMs facilitating basic visual dialog and reasoning, a performance gap persists compared \u2026"}, {"title": "Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models", "link": "https://arxiv.org/html/2403.02178v1", "details": "C Chen, X Wang, TE Lin, A Lv, Y Wu, X Gao, JR Wen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine- tuning approaches sought to mitigate this by leveraging more precise supervisory \u2026"}, {"title": "Debiasing Large Visual Language Models", "link": "https://arxiv.org/pdf/2403.05262", "details": "YF Zhang, W Yu, Q Wen, X Wang, Z Zhang, L Wang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the realms of computer vision and natural language processing, Large Vision- Language Models (LVLMs) have become indispensable tools, proficient in generating textual descriptions based on visual inputs. Despite their advancements \u2026"}, {"title": "Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models", "link": "https://arxiv.org/pdf/2403.17589", "details": "Y Zhang, W Zhu, H Tang, Z Ma, K Zhou, L Zhang - arXiv preprint arXiv:2403.17589, 2024", "abstract": "With the emergence of pre-trained vision-language models like CLIP, how to adapt them to various downstream classification tasks has garnered significant attention in recent research. The adaptation strategies can be typically categorized into three \u2026"}, {"title": "Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models", "link": "https://arxiv.org/html/2402.19014v1", "details": "X Li, Y Wu, X Jiang, Z Guo, M Gong, H Cao, Y Liu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Recently, the advent of Large Visual-Language Models (LVLMs) has received increasing attention across various domains, particularly in the field of visual document understanding (VDU). Different from conventional vision-language tasks \u2026"}, {"title": "Generative Language Models for Personalized Information Understanding", "link": "https://scholarworks.umass.edu/cgi/viewcontent.cgi%3Farticle%3D4123%26context%3Ddissertations_2", "details": "P Cai - 2024", "abstract": "A major challenge in information understanding stems from the diverse nature of the audience, where individuals possess varying preferences, experiences, educational and cultural backgrounds. Consequently, adopting a one-size-fits-all approach to \u2026"}]
