[{"title": "CoT2Align: Cross-Chain of Thought Distillation via Optimal Transport Alignment for Language Models with Different Tokenizers", "link": "https://arxiv.org/pdf/2502.16806", "details": "AD Le, T Vu, NL Hai, NTN Diep, LN Van, T Le\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) achieve state-of-the-art performance across various NLP tasks but face deployment challenges due to high computational costs and memory constraints. Knowledge distillation (KD) is a promising solution, transferring \u2026"}, {"title": "Mapping 1,000+ Language Models via the Log-Likelihood Vector", "link": "https://arxiv.org/pdf/2502.16173", "details": "M Oyama, H Yamagiwa, Y Takase, H Shimodaira - arXiv preprint arXiv:2502.16173, 2025", "abstract": "To compare autoregressive language models at scale, we propose using log- likelihood vectors computed on a predefined text set as model features. This approach has a solid theoretical basis: when treated as model coordinates, their \u2026"}, {"title": "Improving Clinical Question Answering with Multi-Task Learning: A Joint Approach for Answer Extraction and Medical Categorization", "link": "https://arxiv.org/pdf/2502.13108%3F", "details": "P Pattnayak, HL Patel, A Agarwal, B Kumar, S Panda\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Clinical Question Answering (CQA) plays a crucial role in medical decision-making, enabling physicians to extract relevant information from Electronic Medical Records (EMRs). While transformer-based models such as BERT, BioBERT, and \u2026"}, {"title": "Every Expert Matters: Towards Effective Knowledge Distillation for Mixture-of-Experts Language Models", "link": "https://arxiv.org/pdf/2502.12947", "details": "G Kim, G Chu, E Yang - arXiv preprint arXiv:2502.12947, 2025", "abstract": "With the emergence of Mixture-of-Experts (MoE), the efficient scaling of model size has accelerated the development of large language models in recent years. However, their high memory requirements prevent their use in resource-constrained \u2026"}, {"title": "Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images", "link": "https://arxiv.org/pdf/2502.13928", "details": "S Wu, FY Sun, K Wen, N Haber - arXiv preprint arXiv:2502.13928, 2025", "abstract": "Recent studies have shown that Large Vision-Language Models (VLMs) tend to neglect image content and over-rely on language-model priors, resulting in errors in visually grounded tasks and hallucinations. We hypothesize that this issue arises \u2026"}, {"title": "PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models", "link": "https://arxiv.org/pdf/2502.14504", "details": "Y Meng, K Li, C Huang, C Gao, X Chen, Y Li, X Zhang - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across a range of multimodal tasks. However, their inference efficiency is constrained by the large number of visual tokens processed during decoding. To address this \u2026"}, {"title": "Mechanistic Understanding of Language Models in Syntactic Code Completion", "link": "https://arxiv.org/pdf/2502.18499", "details": "S Miller, D Rai, Z Yao - arXiv preprint arXiv:2502.18499, 2025", "abstract": "Recently, language models (LMs) have shown impressive proficiency in code generation tasks, especially when fine-tuned on code-specific datasets, commonly known as Code LMs. However, our understanding of the internal decision-making \u2026"}, {"title": "Toward Responsible Federated Large Language Models: Leveraging a Safety Filter and Constitutional AI", "link": "https://arxiv.org/pdf/2502.16691", "details": "E Noh, J Baek - arXiv preprint arXiv:2502.16691, 2025", "abstract": "Recent research has increasingly focused on training large language models (LLMs) using federated learning, known as FedLLM. However, responsible AI (RAI), which aims to ensure safe responses, remains underexplored in the context of FedLLM. In \u2026"}, {"title": "Enhancing Generalization in Camera Trap Image Recognition: Fine-Tuning Visual Language Models", "link": "https://www.sciencedirect.com/science/article/pii/S0925231225004989", "details": "Z Yang, Y Tian, L Wang, J Zhang - Neurocomputing, 2025", "abstract": "This study introduces a novel fine-tuning approach for enhancing the generalization capabilities of visual language models in the context of wildlife monitoring, particularly for camera trap image recognition. In this paper, we introduce Ecological \u2026"}]
