[{"title": "Context-DPO: Aligning Language Models for Context-Faithfulness", "link": "https://arxiv.org/abs/2412.15280", "details": "B Bi, S Huang, Y Wang, T Yang, Z Zhang, H Huang\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Reliable responses from large language models (LLMs) require adherence to user instructions and retrieved information. While alignment techniques help LLMs align with human intentions and values, improving context-faithfulness through alignment \u2026"}, {"title": "Comparative diagnostic accuracy of GPT-4o and LLaMA 3-70b: Proprietary vs. open-source large language models in radiology", "link": "https://www.sciencedirect.com/science/article/pii/S0899707124003127", "details": "D Li, K Gupta, M Bhaduri, P Sathiadoss, S Bhatnagar\u2026 - Clinical Imaging, 2024", "abstract": "2\\. Methods This prospective study adheres to the Checklist for Artificial Intelligence in Medical Imaging and was exempt from research ethics board review due to the use of publicly available data. The Radiology Diagnosis Please dataset, comprising 287 \u2026"}]
