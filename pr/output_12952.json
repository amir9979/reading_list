[{"title": "Scaling Large Vision-Language Models for Enhanced Multimodal Comprehension In Biomedical Image Analysis", "link": "https://arxiv.org/pdf/2501.15370", "details": "R Umeike, N Getty, F Xia, R Stevens - arXiv preprint arXiv:2501.15370, 2025", "abstract": "Large language models (LLMs) have demonstrated immense capabilities in understanding textual data and are increasingly being adopted to help researchers accelerate scientific discovery through knowledge extraction (information retrieval) \u2026"}, {"title": "KIA: Knowledge-Guided Implicit Vision-Language Alignment for Chest X-Ray Report Generation", "link": "https://aclanthology.org/2025.coling-main.276.pdf", "details": "H Yin, S Zhou, P Wang, Z Wu, Y Hao - \u2026 of the 31st International Conference on \u2026, 2025", "abstract": "Report generation (RG) faces challenges in understanding complex medical images and establishing cross-modal semantic alignment in radiology image-report pairs. Previous methods often overlook fine-grained cross-modal interaction, leading to \u2026"}, {"title": "FreqSpace-NeRF: A fourier-enhanced Neural Radiance Fields method via dual-domain contrastive learning for novel view synthesis", "link": "https://www.sciencedirect.com/science/article/pii/S009784932500010X", "details": "X Yu, X Tian, J Chen, Y Wang - Computers & Graphics, 2025", "abstract": "Abstract Inspired by Neural Radiance Field's (NeRF) groundbreaking success in novel view synthesis, current methods mostly employ variants of various deep neural network architectures, and use the combination of multi-scale feature maps with the \u2026"}, {"title": "Learning Conformal Abstention Policies for Adaptive Risk Management in Large Language and Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06884", "details": "S Tayebati, D Kumar, N Darabi, D Jayasuriya\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language and Vision-Language Models (LLMs/VLMs) are increasingly used in safety-critical applications, yet their opaque decision-making complicates risk assessment and reliability. Uncertainty quantification (UQ) helps assess prediction \u2026"}, {"title": "Leveraging Language Models for Summarizing Mental State Examinations: A Comprehensive Evaluation and Dataset Release", "link": "https://aclanthology.org/2025.coling-main.182.pdf", "details": "NK Sahu, M Yadav, M Chaturvedi, S Gupta, HR Lone - Proceedings of the 31st \u2026, 2025", "abstract": "Mental health disorders affect a significant portion of the global population, with diagnoses primarily conducted through Mental State Examinations (MSEs). MSEs serve as structured assessments to evaluate behavioral and cognitive functioning \u2026"}, {"title": "Advancing General Multimodal Capability of Vision-language Models with Pyramid-descent Visual Position Encoding", "link": "https://arxiv.org/pdf/2501.10967", "details": "Z Chen, M Li, Z Chen, N Du, X Li, Y Zou - arXiv preprint arXiv:2501.10967, 2025", "abstract": "Vision-language Models (VLMs) have shown remarkable capabilities in advancing general artificial intelligence, yet the irrational encoding of visual positions persists in inhibiting the models' comprehensive perception performance across different levels \u2026"}, {"title": "Towards normalized clinical information extraction in Chinese radiology report with large language models", "link": "https://www.sciencedirect.com/science/article/pii/S0957417425002076", "details": "Q Xu, X Xu, C Zhou, Z Liu, F Huang, S Li, L Zhu, Z Bai\u2026 - Expert Systems with \u2026, 2025", "abstract": "Radiology reports serve as a fundamental component within electronic medical records. Converting unstructured free-text reports into structured formats holds paramount importance for the management and utilization of radiology reports. In this \u2026"}]
