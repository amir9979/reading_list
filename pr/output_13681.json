[{"title": "Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge", "link": "https://arxiv.org/pdf/2503.04036", "details": "X Cui, JTZ Wei, S Swayamdipta, R Jia - arXiv preprint arXiv:2503.04036, 2025", "abstract": "Data watermarking in language models injects traceable signals, such as specific token sequences or stylistic patterns, into copyrighted text, allowing copyright holders to track and verify training data ownership. Previous data watermarking techniques \u2026"}, {"title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models", "link": "https://arxiv.org/pdf/2502.10250%3F", "details": "GK Kumar, I Chaabane, K Wu - arXiv preprint arXiv:2502.10250, 2025", "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved \u2026"}, {"title": "Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG", "link": "https://arxiv.org/pdf/2502.08356", "details": "K Bhushan, Y Nandwani, D Khandelwal, S Gupta\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a prominent method for incorporating domain knowledge into Large Language Models (LLMs). While RAG enhances response relevance by incorporating retrieved domain knowledge in the \u2026"}, {"title": "Multi-Agent Verification: Scaling Test-Time Compute with Goal Verifiers", "link": "https://openreview.net/pdf%3Fid%3DH22e93wnMe", "details": "S Lifshitz, SA McIlraith, Y Du - Workshop on Reasoning and Planning for Large \u2026", "abstract": "Scaling test-time computation has recently emerged as a promising direction for improving large language model (LLM) performance. A common approach relies on external verifiers---models or programs that assess solution quality---to select \u2026"}, {"title": "SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence", "link": "https://arxiv.org/pdf/2502.08767", "details": "Z Liu, RA Amjad, R Adkathimar, T Wei, H Tong - arXiv preprint arXiv:2502.08767, 2025", "abstract": "Providing Language Models (LMs) with relevant evidence in the context (either via retrieval or user-provided) can significantly improve their ability to provide factually correct grounded responses. However, recent studies have found that LMs often \u2026"}, {"title": "Franken-Adapter: Cross-Lingual Adaptation of LLMs by Embedding Surgery", "link": "https://arxiv.org/pdf/2502.08037", "details": "F Jiang, H Yu, G Chung, T Cohn - arXiv preprint arXiv:2502.08037, 2025", "abstract": "The capabilities of Large Language Models (LLMs) in low-resource languages lag far behind those in English, making their universal accessibility a significant challenge. To alleviate this, we present $\\textit {Franken-Adapter} $, a modular \u2026"}, {"title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment", "link": "https://arxiv.org/pdf/2503.04647", "details": "W Yang, J Wu, C Wang, C Zong, J Zhang - arXiv preprint arXiv:2503.04647, 2025", "abstract": "Direct Preference Optimization (DPO) has become a prominent method for aligning Large Language Models (LLMs) with human preferences. While DPO has enabled significant progress in aligning English LLMs, multilingual preference alignment is \u2026"}, {"title": "Can Large Language Models Be Query Optimizer for Relational Databases?", "link": "https://arxiv.org/pdf/2502.05562", "details": "J Tan, K Zhao, R Li, JX Yu, C Piao, H Cheng, H Meng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Query optimization, which finds the optimized execution plan for a given query, is a complex planning and decision-making problem within the exponentially growing plan space in database management systems (DBMS). Traditional optimizers heavily \u2026"}, {"title": "ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization", "link": "https://arxiv.org/pdf/2502.05605", "details": "Y Zeng, X Cui, X Jin, G Liu, Z Sun, Q He, D Li, N Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we \u2026"}]
