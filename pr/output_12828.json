[{"title": "EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models", "link": "https://arxiv.org/pdf/2502.06663", "details": "X Xing, Z Liu, S Xiao, B Gao, Y Liang, W Zhang, H Lin\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge \u2026"}, {"title": "Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models", "link": "https://arxiv.org/pdf/2502.04404", "details": "XW Yang, XY Zhu, WD Wei, DC Zhang, JJ Shao\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The integration of slow-thinking mechanisms into large language models (LLMs) offers a promising way toward achieving Level 2 AGI Reasoners, as exemplified by systems like OpenAI's o1. However, several significant challenges remain, including \u2026"}, {"title": "Scalable Language Models with Posterior Inference of Latent Thought Vectors", "link": "https://arxiv.org/pdf/2502.01567%3F", "details": "D Kong, M Zhao, D Xu, B Pang, S Wang, E Honig, Z Si\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "We propose a novel family of language models, Latent-Thought Language Models (LTMs), which incorporate explicit latent thought vectors that follow an explicit prior model in latent space. These latent thought vectors guide the autoregressive \u2026"}, {"title": "CE-LoRA: Computation-Efficient LoRA Fine-Tuning for Language Models", "link": "https://arxiv.org/pdf/2502.01378", "details": "G Chen, Y He, Y Hu, K Yuan, B Yuan - arXiv preprint arXiv:2502.01378, 2025", "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across various tasks but demand substantial computational resources even for fine-tuning computation. Although Low-Rank Adaptation (LoRA) significantly alleviates memory \u2026"}, {"title": "Teaching Language Models to Critique via Reinforcement Learning", "link": "https://arxiv.org/pdf/2502.03492", "details": "Z Xie, L Chen, W Mao, J Xu, L Kong - arXiv preprint arXiv:2502.03492, 2025", "abstract": "Teaching large language models (LLMs) to critique and refine their outputs is crucial for building systems that can iteratively improve, yet it is fundamentally limited by the ability to provide accurate judgments and actionable suggestions. In this work, we \u2026"}, {"title": "EVEv2: Improved Baselines for Encoder-Free Vision-Language Models", "link": "https://arxiv.org/pdf/2502.06788", "details": "H Diao, X Li, Y Cui, Y Wang, H Deng, T Pan, W Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Existing encoder-free vision-language models (VLMs) are rapidly narrowing the performance gap with their encoder-based counterparts, highlighting the promising potential for unified multimodal systems with structural simplicity and efficient \u2026"}, {"title": "Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective", "link": "https://arxiv.org/pdf/2502.01524%3F", "details": "X Ma, H Xie, SJ Qin - arXiv preprint arXiv:2502.01524, 2025", "abstract": "The integration of vision-language modalities has been a significant focus in multimodal learning, traditionally relying on Vision-Language Pretrained Models. However, with the advent of Large Language Models (LLMs), there has been a \u2026"}, {"title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "link": "https://arxiv.org/pdf/2502.06589", "details": "Y Zhuang, J Yang, H Jiang, X Liu, K Cheng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous agents typically rely on complex prompting or extensive fine-tuning, which often fails to introduce new capabilities while preserving strong generalizability. We introduce \u2026"}, {"title": "ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization", "link": "https://arxiv.org/pdf/2502.05605", "details": "Y Zeng, X Cui, X Jin, G Liu, Z Sun, Q He, D Li, N Yang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we \u2026"}]
