[{"title": "A Knowledge Graph Embedding Model for Answering Factoid Entity Questions", "link": "https://dl.acm.org/doi/pdf/10.1145/3678003", "details": "P Jafarzadeh, F Ensan, M Ali Akbar Alavi\u2026 - ACM Transactions on \u2026, 2024", "abstract": "Factoid entity questions (FEQ), which seek answers in the form of a single entity from knowledge sources such as DBpedia and Wikidata, constitute a substantial portion of user queries in search engines. This paper introduces the Knowledge Graph \u2026"}, {"title": "A Closer Look at Benchmarking Self-Supervised Pre-training with Image Classification", "link": "https://arxiv.org/pdf/2407.12210", "details": "M Marks, M Knott, N Kondapaneni, E Cole, T Defraeye\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Self-supervised learning (SSL) is a machine learning approach where the data itself provides supervision, eliminating the need for external labels. The model is forced to learn about the data structure or context by solving a pretext task. With SSL, models \u2026"}, {"title": "A Systematic Evaluation of GPT-4V's Multimodal Capability for Chest X-ray Image Analysis", "link": "https://www.sciencedirect.com/science/article/pii/S2950162824000535", "details": "Y Liu, Y Li, Z Wang, X Liang, L Liu, L Wang, L Cui, Z Tu\u2026 - Meta-Radiology, 2024", "abstract": "This work evaluates GPT-4V's multimodal capability for medical image analysis, focusing on three representative tasks radiology report generation, medical visual question answering, and medical visual grounding. For the evaluation, a set of \u2026"}, {"title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "link": "https://arxiv.org/pdf/2407.10817", "details": "T Vu, K Krishna, S Alzubi, C Tar, M Faruqui, YH Sung - arXiv preprint arXiv \u2026, 2024", "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large \u2026"}, {"title": "UNK-VQA: A Dataset and a Probe into the Abstention Ability of Multi-modal Large Models", "link": "https://ieeexplore.ieee.org/abstract/document/10620618/", "details": "Y Guo, F Jiao, Z Shen, L Nie, M Kankanhalli - IEEE Transactions on Pattern Analysis \u2026, 2024", "abstract": "Teaching Visual Question Answering (VQA) models to refrain from answering unanswerable questions is necessary for building a trustworthy AI system. Existing studies, though have explored various aspects of VQA but somewhat ignored this \u2026"}, {"title": "LLMBox: A Comprehensive Library for Large Language Models", "link": "https://arxiv.org/pdf/2407.05563", "details": "T Tang, Y Hu, B Li, W Luo, Z Qin, H Sun, J Wang, S Xu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "To facilitate the research on large language models (LLMs), this paper presents a comprehensive and unified library, LLMBox, to ease the development, use, and evaluation of LLMs. This library is featured with three main merits:(1) a unified data \u2026"}, {"title": "On Speeding Up Language Model Evaluation", "link": "https://arxiv.org/pdf/2407.06172", "details": "JP Zhou, CK Belardi, R Wu, T Zhang, CP Gomes\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks. Developing a model of this nature, from training to inference, requires making \u2026"}, {"title": "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated", "link": "https://arxiv.org/pdf/2407.10969", "details": "H Wang, S Ma, R Wang, F Wei - arXiv preprint arXiv:2407.10969, 2024", "abstract": "We introduce, Q-Sparse, a simple yet effective approach to training sparsely- activated large language models (LLMs). Q-Sparse enables full sparsity of activations in LLMs which can bring significant efficiency gains in inference. This is \u2026"}, {"title": "Evaluating Large Language Models with fmeval", "link": "https://arxiv.org/pdf/2407.12872", "details": "P Schw\u00f6bel, L Franceschi, MB Zafar, K Vasist\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "fmeval is an open source library to evaluate large language models (LLMs) in a range of tasks. It helps practitioners evaluate their model for task performance and along multiple responsible AI dimensions. This paper presents the library and \u2026"}]
