[{"title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models", "link": "https://arxiv.org/pdf/2408.00724", "details": "Y Wu, Z Sun, S Li, S Welleck, Y Yang - arXiv preprint arXiv:2408.00724, 2024", "abstract": "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth \u2026"}, {"title": "Algorithmic Language Models with Neurally Compiled Libraries", "link": "https://arxiv.org/pdf/2407.04899", "details": "L Saldyt, S Kambhampati - arXiv preprint arXiv:2407.04899, 2024", "abstract": "Important tasks such as reasoning and planning are fundamentally algorithmic, meaning that solving them robustly requires acquiring true reasoning or planning algorithms, rather than shortcuts. Large Language Models lack true algorithmic \u2026"}, {"title": "A Training Data Recipe to Accelerate A* Search with Language Models", "link": "https://arxiv.org/pdf/2407.09985", "details": "D Gupta, B Li - arXiv preprint arXiv:2407.09985, 2024", "abstract": "Recent works in AI planning have proposed to combine LLMs with iterative tree- search algorithms like A* and MCTS, where LLMs are typically used to calculate the heuristic, guiding the planner towards the goal. However, combining these \u2026"}, {"title": "Interpretable Differential Diagnosis with Dual-Inference Large Language Models", "link": "https://arxiv.org/pdf/2407.07330", "details": "S Zhou, S Ding, J Wang, M Lin, GB Melton, R Zhang - arXiv preprint arXiv:2407.07330, 2024", "abstract": "Methodological advancements to automate the generation of differential diagnosis (DDx) to predict a list of potential diseases as differentials given patients' symptom descriptions are critical to clinical reasoning and applications such as decision \u2026"}, {"title": "AI Safety in Generative AI Large Language Models: A Survey", "link": "https://arxiv.org/pdf/2407.18369", "details": "J Chua, Y Li, S Yang, C Wang, L Yao - arXiv preprint arXiv:2407.18369, 2024", "abstract": "Large Language Model (LLMs) such as ChatGPT that exhibit generative AI capabilities are facing accelerated adoption and innovation. The increased presence of Generative AI (GAI) inevitably raises concerns about the risks and safety \u2026"}, {"title": "On Speeding Up Language Model Evaluation", "link": "https://arxiv.org/pdf/2407.06172", "details": "JP Zhou, CK Belardi, R Wu, T Zhang, CP Gomes\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks. Developing a model of this nature, from training to inference, requires making \u2026"}, {"title": "GRAD-SUM: Leveraging Gradient Summarization for Optimal Prompt Engineering", "link": "https://arxiv.org/pdf/2407.12865", "details": "D Austin, E Chartock - arXiv preprint arXiv:2407.12865, 2024", "abstract": "Prompt engineering for large language models (LLMs) is often a manual time- intensive process that involves generating, evaluating, and refining prompts iteratively to ensure high-quality outputs. While there has been work on automating \u2026"}, {"title": "Generalization vs Memorization: Tracing Language Models' Capabilities Back to Pretraining Data", "link": "https://arxiv.org/pdf/2407.14985", "details": "A Antoniades, X Wang, Y Elazar, A Amayuelas\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite the proven utility of large language models (LLMs) in real-world applications, there remains a lack of understanding regarding how they leverage their large-scale pretraining text corpora to achieve such capabilities. In this work, we investigate the \u2026"}, {"title": "Steering Language Models with Game-Theoretic Solvers", "link": "https://openreview.net/pdf%3Fid%3D5QLtIodDmu", "details": "I Gemp, R Patel, Y Bachrach, M Lanctot, V Dasagi\u2026 - Agentic Markets Workshop at ICML \u2026", "abstract": "Mathematical models of strategic interactions among rational agents have long been studied in game theory. However the interactions studied are often over a small set of discrete actions which is very different from how humans communicate in natural \u2026"}]
