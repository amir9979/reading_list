[{"title": "Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones?", "link": "https://arxiv.org/pdf/2502.19557", "details": "Y Zhang, L Wang, M Fang, Y Du, C Huang, J Wang\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Distilling large language models (LLMs) typically involves transferring the teacher model's responses through supervised fine-tuning (SFT). However, this approach neglects the potential to distill both data (output content) and reward signals (quality \u2026"}, {"title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models", "link": "https://arxiv.org/pdf/2502.21321", "details": "K Kumar, T Ashraf, O Thawakar, RM Anwer\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) have transformed the natural language processing landscape and brought to life diverse applications. Pretraining on vast web-scale data has laid the foundation for these models, yet the research community is now \u2026"}, {"title": "The Multilingual Mind: A Survey of Multilingual Reasoning in Language Models", "link": "https://arxiv.org/pdf/2502.09457", "details": "A Ghosh, D Datta, S Saha, C Agarwal - arXiv preprint arXiv:2502.09457, 2025", "abstract": "While reasoning and multilingual capabilities in Language Models (LMs) have achieved remarkable progress in recent years, their integration into a unified paradigm, multilingual reasoning, is at a nascent stage. Multilingual reasoning \u2026"}, {"title": "GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation", "link": "https://arxiv.org/pdf/2502.18990", "details": "J He, J Neville, M Wan, L Yang, H Liu, X Xu, X Song\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Large Language Models (LLMs) can enhance their capabilities as AI assistants by integrating external tools, allowing them to access a wider range of information. While recent LLMs are typically fine-tuned with tool usage examples during \u2026"}, {"title": "Seeing is Understanding: Unlocking Causal Attention into Modality-Mutual Attention for Multimodal LLMs", "link": "https://arxiv.org/pdf/2503.02597", "details": "WY Wang, Z Wang, H Suzuki, Y Kobayashi - arXiv preprint arXiv:2503.02597, 2025", "abstract": "Recent Multimodal Large Language Models (MLLMs) have demonstrated significant progress in perceiving and reasoning over multimodal inquiries, ushering in a new research era for foundation models. However, vision-language misalignment in \u2026"}, {"title": "MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems", "link": "https://arxiv.org/pdf/2503.03686", "details": "R Ye, S Tang, R Ge, Y Du, Z Yin, S Chen, J Shao - arXiv preprint arXiv:2503.03686, 2025", "abstract": "LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks. However, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability \u2026"}, {"title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?", "link": "https://arxiv.org/pdf/2502.19361", "details": "Y He, S Li, J Liu, W Wang, X Bu, G Zhang, Z Peng\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Recently, o1-like models have drawn significant attention, where these models produce the long Chain-of-Thought (CoT) reasoning steps to improve the reasoning abilities of existing Large Language Models (LLMs). In this paper, to understand the \u2026"}, {"title": "Towards label-only membership inference attack against pre-trained large language models", "link": "https://arxiv.org/pdf/2502.18943", "details": "Y He, B Li, L Liu, Z Ba, W Dong, Y Li, Z Qin, K Ren\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "Membership Inference Attacks (MIAs) aim to predict whether a data sample belongs to the model's training set or not. Although prior research has extensively explored MIAs in Large Language Models (LLMs), they typically require accessing to complete \u2026"}, {"title": "Building Safe GenAI Applications: An End-to-End Overview of Red Teaming for Large Language Models", "link": "https://arxiv.org/pdf/2503.01742", "details": "A Purpura, S Wadhwa, J Zymet, A Gupta, A Luo\u2026 - arXiv preprint arXiv \u2026, 2025", "abstract": "The rapid growth of Large Language Models (LLMs) presents significant privacy, security, and ethical concerns. While much research has proposed methods for defending LLM systems against misuse by malicious actors, researchers have \u2026"}]
