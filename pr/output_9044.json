[{"title": "Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?", "link": "https://arxiv.org/pdf/2410.23856", "details": "Z Zhou, R Tao, J Zhu, Y Luo, Z Wang, B Han - arXiv preprint arXiv:2410.23856, 2024", "abstract": "This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We \u2026"}, {"title": "Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines", "link": "https://arxiv.org/pdf/2410.21220", "details": "Z Zhang, Y Zhang, X Ding, X Yue - arXiv preprint arXiv:2410.21220, 2024", "abstract": "Search engines enable the retrieval of unknown information with texts. However, traditional methods fall short when it comes to understanding unfamiliar visual content, such as identifying an object that the model has never seen before. This \u2026"}, {"title": "Scalable Data Ablation Approximations for Language Models through Modular Training and Merging", "link": "https://arxiv.org/pdf/2410.15661", "details": "C Na, I Magnusson, AH Jha, T Sherborne, E Strubell\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Training data compositions for Large Language Models (LLMs) can significantly affect their downstream performance. However, a thorough data ablation study exploring large sets of candidate data mixtures is typically prohibitively expensive \u2026"}, {"title": "Using a natural language processing toolkit to classify electronic health records by psychiatric diagnosis", "link": "https://journals.sagepub.com/doi/pdf/10.1177/14604582241296411", "details": "A Hutto, TM Zikry, B Bohac, T Rose, J Staebler, J Slay\u2026 - Health Informatics Journal, 2024", "abstract": "Objective: We analyzed a natural language processing (NLP) toolkit's ability to classify unstructured EHR data by psychiatric diagnosis. Expertise can be a barrier to using NLP. We employed an NLP toolkit (CLARK) created to support studies led by \u2026"}, {"title": "A Survey of Small Language Models", "link": "https://arxiv.org/pdf/2410.20011", "details": "C Van Nguyen, X Shen, R Aponte, Y Xia, S Basu, Z Hu\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Small Language Models (SLMs) have become increasingly important due to their efficiency and performance to perform various language tasks with minimal computational resources, making them ideal for various settings including on-device \u2026"}, {"title": "SETLEXSEM CHALLENGE: Using Set Operations to Evaluate the Lexical and Semantic Robustness of Language Models", "link": "https://openreview.net/pdf%3Fid%3DMd1mEoPEaQ", "details": "NA Dronen, B Akhbari, M Gawali - The Thirty-eight Conference on Neural Information \u2026", "abstract": "Set theory is foundational to mathematics and, when sets are finite, to reasoning about the world. An intelligent system should perform set operations consistently, regardless of superficial variations in the operands. Initially designed for semantically \u2026"}, {"title": "Fundamental Limits of Prompt Compression: A Rate-Distortion Framework for Black-Box Language Models", "link": "https://openreview.net/pdf%3Fid%3DTeBKVfhP2M", "details": "A Nagle, A Girish, M Bondaschi, M Gastpar\u2026 - The Thirty-eighth Annual \u2026", "abstract": "We formalize the problem of prompt compression for large language models (LLMs) and present a framework to unify token-level prompt compression methods which create hard prompts for black-box models. We derive the distortion-rate function for \u2026"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/pdf/2410.22685", "details": "YS Grewal, EV Bonilla, TD Bui - arXiv preprint arXiv:2410.22685, 2024", "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the- art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional \u2026"}, {"title": "Axes of Robustness of Neural Language Models", "link": "https://is.muni.cz/th/m805b/PhD_thesis_Michal_Stefanik.pdf", "details": "M \u0160TEF\u00c1NIK", "abstract": "In recent years, language models have emerged into a technology adopted in a wide variety of applications, nowadays largely exceeding traditional natural language processing tasks. Thanks to their versatility and adaptability, modern language \u2026"}]
