'*Sent by Google Scholar Alerts (scholaralerts-noreply@google.com). Created by [fire](https://fire.fundersclub.com/).*\n\n---\n### \n\n### \n\n### [PDF] [Phi-3 technical report: A highly capable language mode'
[{"title": "Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?", "link": "https://arxiv.org/pdf/2404.12728", "details": "C Qin, W Xia, T Wang, F Jiao, Y Hu, B Ding, R Chen\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Analogical reasoning is a unique ability of humans to address unfamiliar challenges by transferring strategies from relevant past experiences. One key finding in psychology is that compared with irrelevant past experiences, recalling relevant ones \u2026"}, {"title": "Achieving> 97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners", "link": "https://arxiv.org/pdf/2404.14963", "details": "Q Zhong, K Wang, Z Xu, J Liu, L Ding, B Du, D Tao - arXiv preprint arXiv:2404.14963, 2024", "abstract": "Chain of Thought prompting strategy has enhanced the performance of Large Language Models (LLMs) across various NLP tasks. However, it still has shortcomings when dealing with complex reasoning tasks, following~\\citet {cot_wei} \u2026"}, {"title": "Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs", "link": "https://arxiv.org/pdf/2404.13033", "details": "B Guo, H Wang, W Xiao, H Chen, Z Lee, S Han\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "In the burgeoning field of Large Language Models (LLMs) like ChatGPT and LLaMA, Prompt Engineering (PE) is renowned for boosting zero-shot or in-context learning (ICL) through prompt modifications. Yet, the realm of the sample design for \u2026"}, {"title": "Characterizing LLM Abstention Behavior in Science QA with Context Perturbations", "link": "https://arxiv.org/pdf/2404.12452", "details": "B Wen, B Howe, LL Wang - arXiv preprint arXiv:2404.12452, 2024", "abstract": "The correct model response in the face of uncertainty is to abstain from answering a question so as not to mislead the user. In this work, we study the ability of LLMs to abstain from answering context-dependent science questions when provided \u2026"}, {"title": "Retrieval Augmented Generation for Domain-specific Question Answering", "link": "https://arxiv.org/pdf/2404.14760", "details": "S Sharma, DS Yoon, F Dernoncourt, D Sultania\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Question answering (QA) has become an important application in the advanced development of large language models. General pre-trained large language models for question-answering are not trained to properly understand the knowledge or \u2026"}, {"title": "On the Empirical Complexity of Reasoning and Planning in LLMs", "link": "https://arxiv.org/pdf/2404.11041", "details": "L Kang, Z Zhao, D Hsu, WS Lee - arXiv preprint arXiv:2404.11041, 2024", "abstract": "Large Language Models (LLMs) work surprisingly well for some complex reasoning problems via chain-of-thought (CoT) or tree-of-thought (ToT), but the underlying reasons remain unclear. We seek to understand the performance of these methods \u2026"}, {"title": "AlpaPICO: Extraction of PICO Frames from Clinical Trial Documents Using LLMs", "link": "https://www.sciencedirect.com/science/article/pii/S1046202324000896", "details": "M Ghosh, S Mukherjee, A Ganguly, P Basuchowdhuri\u2026 - Methods, 2024", "abstract": "In recent years, there has been a surge in the publication of clinical trial reports, making it challenging to conduct systematic reviews. Automatically extracting Population, Intervention, Comparator, and Outcome (PICO) from clinical trial studies \u2026"}, {"title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning", "link": "https://proceedings.mlr.press/v238/e-ildiz24a/e-ildiz24a.pdf", "details": "ME Ildiz, Z Zhao, S Oymak - International Conference on Artificial Intelligence and \u2026, 2024", "abstract": "Large language models exhibit strong multitasking capabilities, however, their learning dynamics as a function of task characteristics, sample size, and model complexity remain mysterious. For instance, it is known that, as the model size grows \u2026"}, {"title": "Stronger Random Baselines for In-Context Learning", "link": "https://arxiv.org/pdf/2404.13020", "details": "G Yauney, D Mimno - arXiv preprint arXiv:2404.13020, 2024", "abstract": "Evaluating the in-context learning classification performance of language models poses challenges due to small dataset sizes, extensive prompt-selection using the validation set, and intentionally difficult tasks that lead to near-random performance \u2026"}]
