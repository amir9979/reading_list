[{"title": "Partial Multi-View Multi-Label Classification via Semantic Invariance Learning and Prototype Modeling", "link": "https://openreview.net/pdf%3Fid%3D5ap1MmUqO6", "details": "C Liu, G Xu, J Wen, Y Liu, C Huang, Y Xu - Forty-first International Conference on Machine \u2026", "abstract": "The difficulty of partial multi-view multi-label learning lies in coupling the consensus of multi-view data with the task relevance of multi-label classification, under the condition where partial views and labels are unavailable. In this paper, we seek to \u2026"}, {"title": "Attention-Based Variational Autoencoder Models for Human\u2013Human Interaction Recognition via Generation", "link": "https://www.researchgate.net/profile/Bonny-Banerjee/publication/381484009_Attention-Based_Variational_Autoencoder_Models_for_Human-Human_Interaction_Recognition_via_Generation/links/6670dd17a54c5f0b946ac4af/Attention-Based-Variational-Autoencoder-Models-for-Human-Human-Interaction-Recognition-via-Generation.pdf", "details": "B Banerjee, M Baruah - Sensors", "abstract": "The remarkable human ability to predict others' intent during physical interactions develops at a very early age and is crucial for development. Intent prediction, defined as the simultaneous recognition and generation of human\u2013human interactions, has \u2026"}, {"title": "Bidirectional Variational Autoencoders", "link": "https://sipi.usc.edu/~kosko/IJCNN-2024-BVAE-to-appear-17May2024.pdf", "details": "B Kosko, O Adigun", "abstract": "We present the new bidirectional variational autoencoder (BVAE) network architecture. The BVAE uses a single neural network both to encode and decode instead of an encoderdecoder network pair. The network encodes in the forward \u2026"}, {"title": "SUGARCREPE++ Dataset: Vision-Language Model Sensitivity to Semantic and Lexical Alterations", "link": "https://arxiv.org/pdf/2406.11171", "details": "SH Dumpala, A Jaiswal, C Sastry, E Milios, S Oore\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Despite their remarkable successes, state-of-the-art large language models (LLMs), including vision-and-language models (VLMs) and unimodal language models (ULMs), fail to understand precise semantics. For example, semantically equivalent \u2026"}]
