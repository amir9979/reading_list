[{"title": "Direct Alignment of Language Models via Quality-Aware Self-Refinement", "link": "https://arxiv.org/pdf/2405.21040", "details": "R Yu, Y Wang, X Jiao, Y Zhang, JT Kwok - arXiv preprint arXiv:2405.21040, 2024", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been commonly used to align the behaviors of Large Language Models (LLMs) with human preferences. Recently, a popular alternative is Direct Policy Optimization (DPO), which replaces \u2026"}, {"title": "Calibrating Reasoning in Language Models with Internal Consistency", "link": "https://arxiv.org/pdf/2405.18711", "details": "Z Xie, J Guo, T Yu, S Li - arXiv preprint arXiv:2405.18711, 2024", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in various reasoning tasks, aided by techniques like chain-of-thought (CoT) prompting that elicits verbalized reasoning. However, LLMs often generate text with obvious \u2026"}, {"title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment", "link": "https://arxiv.org/pdf/2405.19332", "details": "S Zhang, D Yu, H Sharma, Z Yang, S Wang, H Hassan\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed \u2026"}, {"title": "A Generative Approach for Treatment Effect Estimation under Collider Bias: From an Out-of-Distribution Perspective", "link": "https://openreview.net/pdf%3Fid%3DkUj9b2CezT", "details": "B Li, H Li, A Wu, M Zhu, Q Cao, K Kuang - Forty-first International Conference on Machine \u2026", "abstract": "Resulting from non-random sample selection caused by both the treatment and outcome, collider bias poses a unique challenge to treatment effect estimation using observational data whose distribution differs from that of the target population. In this \u2026"}, {"title": "Why are Visually-Grounded Language Models Bad at Image Classification?", "link": "https://arxiv.org/pdf/2405.18415", "details": "Y Zhang, A Unell, X Wang, D Ghosh, Y Su, L Schmidt\u2026 - arXiv preprint arXiv \u2026, 2024", "abstract": "Image classification is one of the most fundamental capabilities of machine vision intelligence. In this work, we revisit the image classification task using visually- grounded language models (VLMs) such as GPT-4V and LLaVA. We find that \u2026"}, {"title": "FuRL: Visual-Language Models as Fuzzy Rewards for Reinforcement Learning", "link": "https://arxiv.org/pdf/2406.00645", "details": "Y Fu, H Zhang, D Wu, W Xu, B Boulet - arXiv preprint arXiv:2406.00645, 2024", "abstract": "In this work, we investigate how to leverage pre-trained visual-language models (VLM) for online Reinforcement Learning (RL). In particular, we focus on sparse reward tasks with pre-defined textual task descriptions. We first identify the problem \u2026"}, {"title": "Language Models Need Inductive Biases to Count Inductively", "link": "https://arxiv.org/pdf/2405.20131", "details": "Y Chang, Y Bisk - arXiv preprint arXiv:2405.20131, 2024", "abstract": "Counting is a fundamental example of generalization, whether viewed through the mathematical lens of Peano's axioms defining the natural numbers or the cognitive science literature for children learning to count. The argument holds for both cases \u2026"}, {"title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models", "link": "https://arxiv.org/pdf/2406.02224", "details": "T Fan, G Ma, Y Kang, H Gu, L Fan, Q Yang - arXiv preprint arXiv:2406.02224, 2024", "abstract": "Recent research in federated large language models (LLMs) has primarily focused on enabling clients to fine-tune their locally deployed homogeneous LLMs collaboratively or on transferring knowledge from server-based LLMs to small \u2026"}, {"title": "Small Language Models for Application Interactions: A Case Study", "link": "https://arxiv.org/pdf/2405.20347", "details": "B Li, Y Zhang, S Bubeck, J Pathuri, I Menache - arXiv preprint arXiv:2405.20347, 2024", "abstract": "We study the efficacy of Small Language Models (SLMs) in facilitating application usage through natural language interactions. Our focus here is on a particular internal application used in Microsoft for cloud supply chain fulfilment. Our \u2026"}]
