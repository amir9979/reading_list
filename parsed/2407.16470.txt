% a. Describe the dataset filtration We evaluated our methods on the  dataset. % Dataset filtration A first dataset filtration involved selecting only natural translations, without perturbations, as findings from perturbed data may not be applicable to the detection of natural hallucinations .

% b. Validation and test split The validation and test split was decided based on the translation direction. % Val For the validation set, we selected the two translation directions , which encompasses  sentences. This choice was made as extensive resources and established benchmarks are available for this language pair , with the expectation that the models would exhibit generalizability to less frequently used language pairs. % Test For the test set, the other 16 pairs were used: more precisely, it includes four pairs with English and a HRL ( , , , ), three pairs with English and a LRL (, , and ), and one non-English HRL-LRL pair ().  The test set includes  sentence pairs. This test set excludes six sentence pairs that were removed due to sensitive content flagged and filtered out by LLMs. A more detailed description of the dataset is available in .

%

We consider two settings: (1)  introduced by the authors of . (2) ---a new setting we added due to data imbalance and ease of evaluation. %Our research framework is divided into two paradigms:% c. Describe the two paradigms and how they differ in terms of dataset% Severity ranking the classification of hallucinations was based on four severity levels: , , , and . This fine-grained categorization aimed to capture the nuances in the extent and impact of hallucinations on the translated output.  We use this setting only as  in ., both for consistency with the  benchmark, but also to assess the relevance of our binary detection approach.

% In the original framework proposed by  , the classification of hallucinations was based on four severity levels: , , , and . This fine-grained categorization aimed to capture the nuances in the extent and impact of hallucinations on the translated output.  We use this paradigm as our , both for consistency with the  benchmark, but also to assess the relevance of our new framework, binary detection.% analysis couple by couple -> binary in some way% Binary detection%We've decided to shift the question to a hallucination detection study. . In this setting, all three instances of hallucinations were labelled as , regardless of their severity. We also change the way the evaluation was done in , with an appropriate prompt (), and threshold calculation for binary classification for embeddings cosine similarity, see . The primary reason for choosing this setting is the significant class imbalance in , largely due to the scarcity of hallucinations across different severity levels. Some translation directions have particularly imbalanced data, for example , with the following distribution: out of 148 sentence pairs, we have 141  (96.6\%), 1  (0.68\%), 2  (1.4\%), and 4  (2.8\%). High class imbalance can affect the ability of model to perform well~. % explains how binarisation techniques with an appropriate preprocessing are simple but useful mechanisms to improve classifiers' performance in imbalanced domains. %Evaluation the correct  on two samples our of  samples is particularly problematic. %High class imbalance can affect the ability of model to perform well, especially on datasets smaller than 2000 entries , and more precisely,  explains how binarisation techniques with an appropriate preprocessing are simple but useful mechanisms to improve classifiers' performance in imbalanced domains. % . %  % ------------------------- EXPERIMENTAL SETUP / 2 LLMs% We are the first to use LLMs to evaluate hallucination detection from MT systems.  We assessed the performances of eight LLMs, mixing capabilities models across LLMs families. We evaluate OpenAI's  and ; Cohere's  and ;   Mistral's ; Anthropic's   and  and Meta's . More details about the selection are in .

First, we built our prompt design by differentiated system and user prompts for better results . The system prompt contained the task description, and optionally, the inclusion of Chain-of-Thought (CoT), while the user prompt contained, for each sentence pair, the source text and MT text, as well as a direct hallucination classification question.

% - Prompt origin We derived the task description prompts from the  and  prompts in . The CoT prompts were inspired by  from , and by the human annotation guidelines and severity level definitions from . All prompts are available . More details about the chosen hyperparameters with LLMs can be found in .

% Validation and Test We determined the optimal prompts for each model using the  validation set, evaluating three prompts and two CoT proposals for binary detection. The best prompt for each model was selected based on the average MCC across both translation directions.  % ,chosen for its robustness to class imbalance.  The MCC was chosen as the primary metric for binary detection due to its superiority in providing a single, easily interpretable value between -1 and +1. This value encapsulates the model's performance for the confusion matrix scores, making it more robust to class imbalance.

% ------------------------- EXPERIMENTAL SETUP / 3 EMBEDDINGS

We assessed the performance of three LLM-related embedding spaces: OpenAI's , Cohere's , and Mistral's . Additionally, we included , the multilingual embedding space used as the base for . Specifically, we calculated the cosine distance between embeddings of the source text and the machine-translated text. This approach draws on previous studies showing that hallucinated translations tend to have embeddings that are significantly distanced from those of the source text .

% --------- Binary Detection%   We binarised the cosine similarity scores of embeddings using an optimal threshold value determined from the validation set. This threshold, established by maximizing the F1-score from the precision-recall curve, was then applied to the test set for binary hallucination detection across all language pairs. Each embedding space was independently processed to maintain the integrity of the evaluation.

% ====================================================

The languages acronyms follow this mapping throughout the paper: Arabic (), Chinese (), English (), German (), Kashmiri (), Manipuri (), Russian (), Spanish (), and Yoruba ().

% Adds vertical space between tables% Adds vertical space between tables% ------ Selection

The selection information from the  dataset indicates the sampling strategy used to select sentence pairs for each translation direction and data source, which includes  sampling to maintain data diversity,  sampling favoring potentially problematic translations based on detector quantiles, and  sampling, according to the detectors to increase the likelihood of capturing hallucinations. A closer look at the selection distribution is available % =========== Appendix C : Ablation study We designed tailored prompts for this approach, just as for our main binary approach, this time to generate multiclass predictions. For severity ranking, each prompt has a different assigned CoT.

See % --------------- Prompt 1 - GEval1

See % --------------- Prompt 2 - GEval1 and definition% -------Prompt3

See % --------------- Prompt 3 - GEval1 and definition See  and % ------------ CoT 1% ------------ CoT 2 We evaluated three prompts and two CoT variations on the validation set to select the best prompt (). The prompt that achieved the highest average ROC AUC for both directions () was chosen for each method. Subsequently, in the testing phase, each model was assessed with its optimal prompt.

We computed the cosine similarity between the source text and machine-translated text embeddings for each embedding space and took the negative of these results. This approach ensures that hallucinations (indicative of embeddings that are farther apart) correspond to higher numbers, consistent with the ranking scale used in hallucination evaluation. Since this method does not require parameter tuning, the validation set was not utilized for thresholding in contrast to the binary approach.

In the same way as in the binary detection setting, the validation results  allowed to select the otpimal prompt for each LLM, and then evaluate this best prompt across the test set, using here the ROC AUC score. Testing results aredisplayed , and presents ROC AUC scores for all methods per translation direction. For HRLs, embeddings' high performance remains consistent with the binary hallucination approach.  However,  remains the state-of-the-art in overall performance for severity ranking. The generalizability of these results requires further evaluation due to significant class imbalances in the dataset. Notably, in 11 of the 18 language directions, fewer than five samples are present in at least one hallucination severity category, see .

% When considering the severity ranking of hallucinations using the ROC AUC metric,  obtains the best overall performance with a score of 0.81, followed by SONAR-cos at 0.80. Among the embedding-based methods, GPT-cos and Cohere-cos achieve the highest average ROC AUC scores of 0.75 and 0.76, respectively, across all language directions. Notably, the performance of all models is generally higher for high-resource language (HRLs) directions compared to low-resource language (LRL) directions, with average ROC AUC scores of 0.88 and 0.75 for HRLs and LRLs, respectively, using the  model. The Sonnet model exhibits the best performance among the evaluated models on LRL directions, with an average MCC of 0.29 and an average ROC AUC of 0.55.% % --------- Severity ranking% This approach eliminates the parameter tuning on the validation set, as the metric is designed to directly assess both discrete outputs (from LLMs) and continuous outputs (from embeddings and baselines).% =========== Appendix D: Prompts% \clearpage% Experiment framework For the evaluation of LLMs, we used  to ensure reproducibility of results, except for  that was ran locally.  We set the  to  for minimum randomness and the  to  to avoid verbose.% that is not controlled by the prompt and task understanding, meaning that the models will truncate the output to  tokens maximum, which allows a more efficient post-processing and limited resources. This value was selected as the total number of tokens for the labels is . All the experiments were zero-shot, with an exhaustive label (for example,  for ). These choices showed the highest performances in previous research . 

We selected the following models for our evaluation: , widely adopted in both academic research and industrial applications due to its robust performance and versatility; , the latest GPT model, optimised for better human-computer interaction; , known for its large context window, well-suited for tasks that require extended language understanding and generation; , an enhanced version of , demonstrating strong performance in multilingual tasks, achieving impressive BLEU scores in benchmark datasets such as ; , currently the most performant open model from Mistral, excelling in various language tasks; , showing strong capabilities in multilingual tasks, similar to ; , known as the "most intelligent" Claude model, offering advanced language understanding and generation capabilities; and , the most capable openly available LLM from Meta, evaluated in its 70B size for comprehensive performance analysis. These models were chosen based on their demonstrated performance in various benchmarks and their potential to handle a wide range of language tasks effectively.

% [1] https://txt.cohere.com/command-r-plus-microsoft-azure/% % OPTIONAL: Why these models (if space)% After careful consideration, we selected and  selection is justified by their widespread adoption in both academic research and industrial applications.  holds a larger context window compared to GPT3.5, making it well-suited for tasks involving extended language understanding and generation. Additionally, \crplus, Mistral Large and Claude Sonnet have demonstrated strong performance in multilingual tasks, achieving impressive BLEU scores in benchmark datasets such as {FLoRES and WMT23}. As a comparison, we added , currently the most performant Mistral open model, as well as , the "most intelligent" Claude model. Moreover,  is the most capable openly available LLM to date from Meta, which we wanted to evaluate in its two available sizes, 8B and 70B.% % Some words about why we excluded 3 models% We decided to exclude % ======================== ============ ============ ============ ============ % ======================== ============ ============ ============ ============ % ======================== ============ ============ ============ ============ % ======================== ============ ============ ============ ============ % ============ AOB / OPTIONAL / provides MCC scores per LLM for each of the prompts and CoT variations evaluated on the validation set. The most robust LLMs across prompt variations in the validation set, specifically Sonnet, , and , exhibit superior performance across language resource settings in the test set. This suggests that extensive prompt engineering might not be required for these models in the current task, as the performance using the optimal prompt from the validation set aligns with high performance on the test set. % - Validation and Test set displays the performances of evaluated methods on the test set grouped by translation directions and resource setting. The results indicate that the highest scores for HRLs are achieved in translations to English, whereas for LRLs, the highest scores are from translations originating in English or Spanish. Additionally, these findings underscore that no single model uniformly excels across all translation directions. 

% =====================%More precisely, the embedding binary detection allowed us to identify  as the best-performing embedding for hallucination detection, even outperforming the current . Moreover, both  models showed great results and robustness with relatively close results. % ========= Future Work% Future work may include more representativity of LRL speakers in NLP-focused tasks, both for dataset creation and NLP-task evaluation and interpretation. % Also, CoT was implemented manually with prompt juxtaposition, but experimenting with AutoCoT could enable optimised results.% % We used the macro MCC score as the primary evaluation metric, which is particularly useful for assessing the model's performance in detecting hallucinations. It provides a balanced measure of the model's ability to correctly identify hallucinations while minimizing false positives and false negatives. However, it is crucial to acknowledge that the weighted MCC score yields more representative results, particularly considering the infrequent nature of hallucinations, a phenomenon that is even more pronounced in LRL.% Also, a few LLMs used, such as Cohere's models, were built for optimised Retrieval Augmented Generation: an interesting study to augment LLMs capabilities with LRLs would be to link the models with a dataset of correct translation pairs to assess its understanding of underlying patterns in non-translating pairs. % Finally, a wider  and deeper evaluation, could include prompting in the target language when assessing the hallucination, which would need extensive human design and evaluation of the prompt, as prompt translation may be hallucination. .% 1. It has been established than hallucinations negatively impact MT performance.% 2. However, detection remains challenging in particular for low-resource languages.% 3. We investigate...% 4. We find... (include numbers, mention best-performing model): What we find is that the choice of model is essential for performance. For high-resource, \llama greatly outperforms even the previous state of the art by as much as XXX MEASURE. However, for low-resource languages we observe that Claude Sonnet outperforms other LLM models by XXX MEASURE.%. 5. Takeaway: The key takeaway from our study is that LLMs can perform as well as previously proposed models (despite not being explicitly trained for the task), although for low-resource languages their advantage is less pronounced. Recent advancements in massively multilingual machine translation systems have significantly enhanced translation accuracy; however, even the best performing systems still generate hallucinations, severely impacting user trust. Detecting hallucinations in Machine Translation (MT) remains a critical challenge, particularly since existing methods excel with High-Resource Languages (HRLs) but exhibit substantial limitations when applied to Low-Resource Languages (LRLs). This paper evaluates hallucination detection approaches using %  Large Language Models (LLMs) and semantic similarity within massively multilingual embeddings. Our study spans 16 language directions, covering HRLs, LRLs, with diverse scripts. We find that the choice of model is essential for performance. On average, for HRLs, %greatly  outperforms %even  the previous state of the art by as much as 0.16 MCC (Matthews Correlation Coefficient). However, for LRLs we observe that  outperforms other LLMs on average by 0.03 MCC. The key takeaway from our study is that LLMs can achieve performance comparable or even better than previously proposed models, despite not being explicitly trained for any machine translation task. However, their advantage is less significant for LRLs. % Our approach achieves performance improvements over current state-of-the-art models for both HRLs and LRL.%A translation is qualified as a hallucination when it contains information completely unrelated to the source text. % The propensity of MT systems to hallucinate varies significantly across languages and translation directions, with LRLs continuing to lag behind high-resource languages (HRLs) in hallucination rate, which significantly undermines user trust. %Effectively assessing the tendency of models to hallucinate, particularly in low-resource settings, is crucial for improving the trustworthiness of MT systems. % Claude SonnetIntroduction51844,wu_tacl_a_00563,guerreiro-etal-2023-lookingfan2020englishcentricTeam2022kudugunta2023madlad400ENRaunak2022,XuDale2023ENHRLs ENLRLsHRLLRLBLASER-QECosta-jussàDuquenne2023\llamaBLASER-QEClaude SonnetBLASER-QEgreatlyExperimental setupQuality assessment of the datasetDale2023DEEN301guerreiro2023xcometENARENZHENRUENESENKSENMNENYOESYO2,558Hallucination detection settingSeverity rankingBinary detectionSeverity rankingNo HallucinationSmall HallucinationPartial HallucinationFull Hallucinationablation studyBinary detectionHallucinationENRUNo HallucinationSmallPartialFullPrusa2016,Sordo2005,Fernández2013LLMs for hallucination detectionGPT4-turboGPT4oCommand RMistral-8x22bClaude SonnetClaude Opus\llama\texttt, \texttt and \texttt were initially taken into account, but were excluded due to poor task understanding.Kong2023Evaluate HallucinationEvaluate Coherence in the Summarization TaskG-EvalLiu2023Evaluation StepsG-EvalHalOmiDEENEmbeddingssec:exp_embeddingstext-embedding-3-largeEmbed v3mistral-embedSONARBLASER-QEDale2022ResultsLLMs are the new SOTA for hallucination detectionfig:results_binary_colorsBLASER-QEBLASER-QEClaude SonnetGPT4oBLASER-QEKSENYOENENMNIKocmi2023Embedding-based hallucination detectors remain competitive for HRLsBLASER-QESONARSONARENDELLMs' contrastive performances across LRLsSonnetOpusGPT4oMistralMNENNo hallucinationSonnetBLASER-QEBLASER-QESonnetBLASER-QESonnetDale2023fig:binary_test_barplotEmbeddings are high performers for non-Latin scripts, while LLMs can generalise to non-English centric translationsHRLsENAR,RU,ZHHada2023ESYOOpusBLASER-QEMistralOpusSonnetYOESBLASER-QEfig:emb_vs_llmsLlama3-70BConclusionLimitationsNo HallucinationNo hallucinationENDEDale2023referenceRelated Worksec:app_rwguerreiro2023xcometHeffernan2022Feng2022Dale2022HalomiA Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine TranslationDale2023Costa-jussàDuquenne2023Zhu, XuG-EvalLiu2023Kocmi2023fernandes-etal-2023-devilDataset descriptionsec:app_datasetLanguage acronyms mappingARZHENDEKAMNRUESYOHallucination distributionDistribution of Hallucination in the severity ranking framework1emDistribution of Hallucination in the binary detection framework1emSelection distributionsec:selectionuniformbiasedworstAblation studysec:app_ablationseverity rankingDale2023LLMs for severity rankingPrompt designSeverity ranking, Prompt1: \textit  inspiredSeverity ranking, Prompt2: \textitinspired, with \textit's hallucination deifnitionSeverity ranking, Prompt3: \textit inspired, with \textit's hallucination deifnition, and language precisionChain of Thoughts for severity rankingPrompt evaluationDEENEmbeddings for severity rankingResultsBLASER-QE0.7\textwidth!%

  -3mmValidation results for hallucination detection across prompt variations for severity ranking.-4mmtab:val_results_ranking\textwidth!%

  -3mmROC-AUC results for severity hallucination ranking across HRL and LRL directions. \\ \textit-4mmtab:ranking_resultsPromptssec:app_promptsbinary detectionBinary detection, Prompt1 - from \textitBinary detection, Prompt2 - from \textit with language precisionBinary detection, Prompt3 - Human designed promptBinary detection, Chain of ThoughtsLLMs experimentssec:app_LLM_expLLMs hyperparametersLangChainTEMPERATURE0MAX\_OUTPUT\_TOKEN15binary detectionKocmi2023Wei2022LLMs selectionsec:llm_choiceGPT4-turboGPT4oCommand-RCommand R+Command Rhttps://txt.cohere.com/command-r-plus-microsoft-azure/FLoRES and WMT23Mistral 8x22bClaude SonnetCommand R+Claude OpusLLama3-70BBinary detection resultssec:binary_resultValidation resultssec:app_val_bin\autorefGPT4o0.8\textwidth!%

  Validation results for binary hallucination detection across prompt variations. Bold values indicate the best performing prompt per model. In the case of ties, we favor shorter prompts without CoT.tab:val_results_binaryTest results\autorefwidth=\textwidthfigures/results_ress_directions.pngMCC average score across high and low resource levels, for different directions. The best performing models differ significantlly between HRLs and LRLs. For HRLs, \llama greatly outperforms other methods, whereas for LRLs, best performers differ from and to LRLs, with \texttt and \texttt models closely competing. Embeddings demonstrate impressive results, particularly for the \texttt directions.fig:binary_test_barplot