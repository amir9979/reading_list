provides a comprehensive collection of 38 subtasks centered around temporal reasoning tasks. It is widely observed that a substantial portion of these tasks relies on mathematical skills for calculating and reasoning about time. % This reliance highlights a broader challenge in LLMs, where understanding and reasoning through complex relations often reveal limitations. For example, within the  category, the  subtask requires the calculation of event frequencies or intervals. In the  task, mathematics provides a standardized method of time representation, such as the 24-hour format and date calculation formulas, enabling different temporal expressions to be accurately understood and converted. Based on these observations, we categorize temporal tasks into two categories. The specific subtasks under each category are shown in Figure~. Below is our classification:

Inspired by , we construct  for each temporal task to establish a connection between mathematics and temporal tasks. We utilize the  dataset , which comprises a diversified collection of mathematical problems with detailed rationales.  From this dataset, we select five mathematical question-CoT pairs and employ GPT-4 to generate  rationales by mimicking mathematical reasoning. Since pure-time questions lack mathematical rationales,  is specifically designed for math-time tasks. We compare  with two prompting methods: (1) , which samples five question-answer pairs per task, and (2) ~, where GPT-4 is used to generate step-by-step rationales for each task. We conduct the experiments using  under the 5-shot setting and report the accuracy for each task. As shown in Figure~, integrating mathematical reasoning into temporal tasks leads to a significant enhancement in model performance, with  outperforming traditional prompting methods in all math-time tasks.

Given the established correlation between mathematics and temporal reasoning, it is intuitive to instruct models in mastering mathematical reasoning to establish a solid foundation for advanced temporal reasoning abilities. This connection motivates our investigation into how varying degrees of mathematical instruction influence model performance. Specifically, we select 180k mathematical CoT rationales from the  and perform scaling experiments by fine-tuning the  with different volumes of math instructions~(i.e., 0, 50k, 100k, 150k, and 180k). We evaluate the models on both math-time tasks and pure-time tasks under the 5-shot setting. The results are shown in Figure~. After supervised fine-tuning on 50k math instruction tuning instances, the model exhibits a notable improvement in performing math-time tasks, with accuracy increasing from 56.4 to 63.3. However, It is worth noting that this enhancement in mathematical skills has a minimal impact on pure-time tasks, with a maximum enhancement of 1.9. Additionally, our analysis indicates a declining trend in performance across both task categories as the volume of math instructions increases. We believe this decline results from overfitting to mathematical tasks due to excessive data, adversely impacting the model's temporal reasoning capability~.

We use  7B and 13B~ as our base pre-trained model. For SFT, we select 100k instances from ~, the most representative dataset for mathematical reasoning instruction tuning. For self-critic temporal optimization, we focus on pure temporal reasoning tasks, which encompass 19 subtasks. We reserve 100 instances for evaluation and utilize the remaining data for training. If a subtask contains fewer than 5,000 samples, we maintain all of them. Otherwise, we randomly select 5,000 instances. In total, we use 35,655 instances for optimization.

We conduct a comprehensive evaluation across all temporal reasoning tasks, encompassing a total of 38 tasks. Following ~, we assess the model performance on 100 examples for each task, amounting to a total of 3,800 instances. Consistent with prior work~, we evaluate the model's temporal abilities under the 5-shot setting and utilize greedy decoding (i.e., temperature = 0) for generating model's responses. We extract the prediction from the response and calculate the accuracy of each subtask.

We utilize four/eight NVIDIA Tesla A100 GPUs to train models. To facilitate parallel training, we employ DeepSpeed Zero-Stage 3~ and FlashAttention2~. For SFT, we use a learning rate of 2e-5, a batch size of 128, and a cosine scheduler with a 3\% warm-up period for 2 epochs. For candidate response generation, we sample  candidate responses with temperature , . When evaluating candidate responses, as there is variance to these scores, in our experiments we also use sampled decoding (with the same parameters) and generate these evaluations multiple (3) times and take the average. For DPO, we follow the hyper-parameters from   with a batch size 32, learning rate 5e-7, a warm ratio of 0.1 using linear warmup scheduler for 9 epochs.

To ensure the fairness of the experiments, we select baseline models built upon the foundational model . The baselines are selected based on the following dimensions:

Table~ presents the results of  across 38 temporal tasks. From the results, we observe: (1)  surpasses counterpart LLMs in average accuracy of 10.0 and 7.6 scores, and outperforms other competitive math-solving and code-solving models with a clear margin, achieving the SOTA results on average. We also discover  consistently outperforms all 13B models in average performance, achieving a maximum performance gain of 7.1.  (2) Mathematical models do not show significant advantages in solving math-related tasks. This phenomenon is also observed in LLMs enhanced for coding abilities and temporal prediction capabilities. It indicates that excessive training on specific abilities leads the model to overfit in task-centric enhancements, diminishing its performance in other areas~. (3) It is worth noting that  underperforms  in the  task (i.e., scoring 66.3 vs 67.0) when evaluated under the 13B model size parameter. The superior performance of  can be attributed to its advanced general math-solving abilities, which facilitate more accurate computations in time-related scenarios. However, other mathematical models like  and  do not achieve the same effectiveness in handling the  task. A detailed case study for illustration is in Appendix~.