We begin with five CommonCrawl dumps from 2019 to 2023, processed through the CCNet~ pipeline, in accordance with~. From the preprocessed dataset, 500 GB of text data are randomly selected as our baseline, yielding approximately 125 billion tokens for additional quality filtering. In each experiment, we train a decoder-only model with 1.3B parameters, using the same model architecture as~. Each model is trained on 25B tokens until performance levels off, according to~, which takes approximately 4 days on 4 nodes with 8 NVIDIA Tesla V100 GPUs. We use pre-trained GPT-2 models~ as default meta-models to calculate quality factors for each sample. The smaller and larger models have 124M and 774M parameters, respectively. We later perform ablation studies to discuss impacts by the pre-training data. Following~, we utilize the  library~ to evaluate zero-shot performance across various downstream tasks of each model trained on documents retained through specific quality filtering method. We encompasses a variety of tasks and widely used datasets~, including sentence completion (Hellaswag~ and LAMBADA~), coreference resolution (Winogrande~), natural language inference (ARC~), and multiple-choice question answering (PIQA~, OpenbookQA~, BoolQ~).

 We compare  random selection, binary classification~, importance resampling~ and perplexity gating~. All quality filters will keep 70\% of the unfiltered documents in align with~, if not specified otherwise. As for binary classification, we choose Wikipedia, books and OpenWebText as positive samples and unfiltered CommonCrawl documents as negative ones, following~. We set the shape parameter of Pareto distribution , following~. As to importance resampling, we follow the settings in~, with OpenWebText~ as the target dataset. As for perplexity gating, we follow~ as well as our cleaning ratio, keeping documents with perplexity ranging from 15th to 85th percentiles, resulting in keeping the middle 70\% documents of the unfiltered dataset. Perplexity is computed by the larger of the meta-models, the one with higher capacity and ability.

 Table~ shows the comparison between various data quality filter methods. In summary:

Notably, for binary classification~ and importance resampling~, we use the best results from various reference datasets, specifically OpenWebText. The results for perplexity gating~ use the larger model's perplexity in our meta-models for a fair comparison. Ablations concerning the reference datasets of the aforementioned methods will be discussed in subsequent sections.

 We detail ablation studies with meta-models trained on different datasets in Table~. Besides the meta-models trained on WebText, results of which are shown in Table~, we trained meta-models on a subset of Wikipedia, OpenWebText, and unfiltered CommonCrawl data with no more than 25B tokens. Each dataset was used to train meta-models for 1 epoch. The results demonstrate that all experiments outperform the baseline of random selection. Training on unfiltered CommonCrawl or OpenWebText yielded results competitive with those from other quality filtering methods. Furthermore, training on Wikipedia achieved results very close to the best, with a marginal gap of 0.15\%.

 We perform experiments to investigate impacts brought by using pairs of meta-models with different sizes. The results are briefly presented in Table~. When using a pair of meta-models with relatively small differences in the number of parameters to estimate the quality factors of data, there is a certain degree of performance degradation in the downstream tasks. Reducing the size of the larger models in meta-models from 774M to 335M decreases the average performance on downstream tasks by 0.96\%. Conversely, increasing the size of the smaller models in meta-models from 124M to 335M results in a decrease of 1.28\% in performance. This suggests that a larger parameter gap may more effectively amplify differences in how models fit textual data, allowing for a more reliable assessment of the quality factor. Detailed exploration of this hypothesis is left as future work.

 We also examine the impacts of different reference datasets on popular quality filtering methods that rely on a reference. Results are shown in Table~. Binary classification using OpenWebText as the positive class results in the best performance, similar to importance resampling with the same dataset as a reference. This aligns with the findings in~, which confirm that OpenWebText has superior data quality. Binary classification with a mixed dataset including OpenWebText, Wikipedia, and books yields inferior results, possibly due to the classifier's training recipe, such as the mixing ratio of the three datasets. Surprisingly, importance resampling with Wikipedia results in similar average accuracy to the random baseline, with much better accuracy in ARC and BoolQ but significantly worse performance in sentence completion tasks like Hellaswag and LAMBADA, possibly due to the serious domain shift towards Wikipedia. In conclusion, the choice of reference datasets has a significant impact on the performance of quality filters that rely on references.

Training large language models requires diverse data. Current quality filters, by favoring text data similar to the reference dataset, may discard documents on informal topics or from minorities, reducing the trained model's knowledge diversity~. How can we assess a dataset's data diversity? We introduce a metric to measure a document group's semantic diversity. 

 Following~, we define semantic diversity as the exponential of the Shannon entropy of the semantic similarity matrix's eigenvalues. For a set of text documents  and a semantic similarity function , we obtain a similarity matrix , where each entry . Denoting  as the eigenvalues of , we define semantic diversity as follows.

A pre-trained language model extracts each document's semantic embedding, using cosine similarity as the similarity function. In our experiments, we utilize the  model~ with the  library due to its efficiency and outstanding performance in various text embedding-related retrieval and clustering tasks.

 Computational constraints prevent calculating semantic diversity for all documents in the dataset. Experiments on the unfiltered dataset help select an appropriate document count for calculating the semantic diversity metric. For each experiment, we randomly select  samples, calculate their semantic diversity score, and repeat this process 10 times to compute the average score and standard deviation. Results are displayed in Figure~. Results indicate that semantic diversity stabilizes when the group exceeds 10,000 samples, with a standard deviation of 0.12. We choose 10,000 samples for subsequent experiments to balance accuracy and efficiency.

 Our experiments showed that semantic diversity effectively reflects data diversity under multi-datasets settings. We selected five datasets with diverse topics or writing styles, including news articles (CC-News~), movie reviews (IMDB~), forums (Reddit ), Wikipedia, and crawled web pages (OpenWebText~). We extracted the same number of samples from one or more of the above datasets, creating a mixed subset of 10,000 samples. We then averaged the relationship between semantic diversity and the number of datasets (N). Figure~ shows a positive correlation between semantic diversity and the number of datasets (N), indicating that semantic diversity accurately reflects data diversity within datasets.

 We assess the semantic diversity of datasets resulting from various quality filtering methods. The results are presented in Table~. Most quality filters achieve higher diversity than the original unfiltered dataset, likely due to the removal of a large number of machine-generated spams with similar semantic meanings. The results indicate that importance resampling achieves the highest diversity, at 56.25, attributed to its resampling strategy.  results in greater diversity compared to the most commonly used binary classification, thanks to its reference-free nature. Perplexity gating reduces the diversity of the original dataset, supporting the conclusion from~ that filtering data based solely on perplexity thresholds can introduce unexpected bias to data diversity.

We train decoder-only transformer~ models using Megatron-DeepSpeed~. The hyperparameters used in the training process is listed in Table~.

Let's start with the parametric loss function introduced by Chinchilla~ scaling law.

 where  represents the minimal achievable loss, corresponding to the entropy of natural text. The scaling law, indicating the optimized numbers of  and , follows a power-law form:

 where  and  represent the model and data scaling exponents, respectively. In order to present  and  with scaling exponents, we have

Let , the parametric loss  can be presented as:

Then, we can obtain the partial derivatives of  with respect to N expressed in terms of  and .

It's obvious that

 which means that the expected loss decreases when model size increases under same training tokens.

We can further get 

Because , we have

 and since , we have

Thus, we have

That means that at a specific , the slope of the tangent to the  curve () decreases as  increases (i.e., the larger the , the steeper the tangent). In all, we've proven that

Owing to this monotonic relationship, we can infer the value of  from the slope of the tangent. For a given , a steeper tangent (with a greater absolute value of the slope) indicates a larger :

It's impossible to calculate the slope of the tangent  in the real scenario, we can only acquire the slope of the secant line by assessing the cross-entropy loss on two models with different sizes (i.e. a pair of ). Next, we will prove that the slope of the tangent has a positive relationship with the slope of the secant line. Therefore, we can build direct relationship between the slope of the secant line and .

Given a pair of meta-models with  and  parameters where , we can denote the slope of the secant line as:

For a larger ,  is smaller for every . This lead to a smaller , or a larger , that is

 Previous works~ typically use sampling without replacement, selecting data based on a rating score to balance quality and diversity. This approach often results in improved downstream performance. We conducted experiments to determine whether this sampling strategy could enhance the downstream performance of . Following~, we introduced a temperature term  to adjust sample diversity. Here,  means top-k selection, while  indicates uniform sampling. Results in Table~ indicate that top-k selection is the optimal data selection method for  due to its reference-free nature and the unnecessary use of noisy sampling strategies to enhance data diversity.

To further validate the robustness of , we conducted ablation experiments using various training hyperparameters on 1.3B models. Our focus was primarily on two hyperparameters: learning rate (default ) and global batch size (default 256). We doubled the default values for each in the ablation study. The results are presented in Table~. The results indicate that an increase in global batch size significantly reduces performance in both settings with different quality filters, as it halves the training steps. Conversely, increasing the learning rate slightly affects downstream accuracy. Overall,  remains robust across a range of training hyperparameters, consistently surpassing binary classification, its top competitor, as shown in Table~.

High-quality data is crucial for the pre-training performance of large language models. Unfortunately, existing quality filtering methods rely on a known high-quality dataset as reference, which can introduce potential bias and compromise diversity. In this paper, we propose , a novel approach that evaluates text quality based on the perplexity difference between two language models trained on the same data, thereby eliminating the influence of the reference dataset in the filtering process. An theoretical analysis shows that  is equivalent to an inverse utilization of scaling laws. Through training models with 1.3B parameters on the same data source processed by various quality filters, we find  can improve zero-shot performance of pre-trained models in downstream tasks. To assess the bias introduced by quality filtering, we introduce , a metric of utilizing text embedding models for semantic representations. Extensive experiments reveal that  is a reliable indicator of dataset diversity, and  achieves an optimal balance between downstream performance and semantic diversity. semantic diversitysemantic diversityIntroductiongpt3, gopher, refinedwebgpt3, pile, palmdsirdolmadata-pruningquratingchinchilladata-pruning, ccnet-0.5emWe introduce , a novel metric that correlates directly with the quality of training data through the lens of model scaling laws, offering a more precise and unbiased approach to data curation.     quality factorWe propose , a new quality filtering method that utilizes the  to curate high-quality datasets without relying on reference data, thereby mitigating the risk of bias and enhancing the representativeness of the training corpus.     quality factorTo evaluate the data diversity of filtered datasets, we introduce  as a novel and reliable metric. Extensive experiments demonstrate that  effectively preserves the richness and variety of the raw data compared to conventional quality filtering approaches. semantic diversity-5mmwidth=\textwidthassets/methodology/scalinglaw.pdffig:method-illuwidth=\textwidthassets/methodology/scalinglaw_avg.pdffig:method-avg-2mm     \textbf A visual diagram illustrates the theoretical result that high-quality data accelerates the rate of loss decrease as model parameters increase, resulting in larger model scaling exponents .     \textbf We calculated the average loss of GPT-2 models of different sizes on several datasets with recognized quality levels: Wikipedia, OpenWebText, and Books3 represent high-quality data, while Unfiltered CommonCrawl represents low-quality data. The results closely align with the theoretical analysis shown in (a), which indicates that high-quality data accelerates the rate of loss decrease as model parameters increase.     -2mmfig:method-fullMethodologysec:methodOverview.2017scalinglaw, openai-scalinglaw, chinchilla, meta-mm-scalinglawdeepseekllmpiledeepseekllm, meta-mm-scalinglaw, openai-scalinglaw, chinchillaquality factorquality factordeepseekllmquality factorQuality factor.quality factorquality factor

    d_i := _p (x_i)}{_q (x_i)} Quality factor is positively correlated with data quality.chinchilla, openai-scalinglaw, openai-mm-scalinglaw, meta-mm-scalinglawdeepseekllmchinchilla      (N, D) = E + {N^\alpha} + {D^\beta} meta-mm-scalinglawopenai-scalinglaw, chinchilla     N_{opt}\propto C^{a}\quad D_{opt}\propto C^{b} deepseekllm, chinchilla      (N, D) = E + {N^{(1-a)\eta}} + {D^{a\eta}}\   app:dv1fig:method-illu     a \propto -{\partial N} \bigg|_{N = N_0} app:dv2fig:method-illu-5mm {c}

    a \propto -(N_q) - (N_p)}{N_q - N_p}, \\[10pt]     d = 2^{(N_p) - (N_q)} = 2^{-((N_q) - (N_p))}  \\ d  a  casesarraydeepseekllm\textit  is positively correlated with data qualityfig:method-avgfig:method-illuquality factorSelecting high-quality data with \textit.quality factor\OurMethodfig:system-designExperimentssec-exp Zero-shot downstream accuracy of models trained with different quality filters. We cover a variety of tasks and widely used datasets~\citep, including sentence completion, coreference resolution, natural language inference and multiple-choice question answering. For binary classification \cite and importance resampling~\citep, we leverage the best results from various reference datasets, whereas perplexity gating~\citep utilizes the larger model's perplexity in our meta-models. tab:vs-quality-filter-3mmData Quality Evaluationsec:downstreamSetup.ccnetredpajamav1fp8lmchinchilla, refinedweb, data-pruninggpt2refinedweblm-evaluation-harnessevalharnessrefinedweb, gpt3, palm, cerebras, pythiahellaswaglambadawinograndearcpiqaopenbookqaboolqBaselines.gpt3, pile, palm, llamadsirdata-pruningredpajamav1glam, palmgpt3, pile, palmdsiropenwebtextdata-pruningResults.tab:vs-quality-filterOn average,  a 0.62\% improvement over the widely-used binary classification quality filtering method and a 0.73\% improvement over importance resampling, achieving the state-of-the-art performance.  a 1.12\% improvement in average accuracy over perplexity gating, a competing reference-free quality filtering approach. gpt3, palm, llamadsirdata-pruning Ablations on effects of meta-models training data within the \OurMethod framework. The results reveal that meta-models trained on alternative datasets also showcase competitive performance, indicating that there is not an overly strong dependency on meta-models pretrained on WebText, emphasizing the robustness and flexibility of \OurMethod variants. tab:self-trained For model pairs trained on WebText, we directly use OpenAI GPT-2 models from HuggingFace, which is the meta-models used in the original \OurMethod framework.-3mmMeta-models trained on various datasets exhibit competitive and comparable performance.tab:self-trainedtab:vs-quality-filterAblations on different sizes of meta-models.tab:abla-sizes-detailAblations on reference datasets.tab:abla-referencedeepseekllm%  Ablation studies on the effects of reference data. We varied the reference datasets for binary classification~\citep and importance resampling~\citep. The results indicate that OpenWebText is the optimal reference dataset choice for both reference-dependent quality filtering methods. tab:abla-reference This experiment uses a mixed dataset as reference dataset following~\citep, with OpenWebText, Wikipedia, and books. The classification scores are directly obtained from quality signals provided by Redpajama V2.-3mmData Diversity Evaluationsec:diversityccnet, dolmaSemantic diversity metric.vendi-4mm  = \exp\left( - \sum_{i=1}^n \lambda_i \log \lambda_i \right) bge-base-en-v1.5bgesentence\_transformersSelecting a proper size of documents.fig:diversity-abla-10ksamples Ablations on effects of sizes of meta-models. To note, the original \OurMethod uses a pair of meta-models with 124M and 774M parameters, respectively. tab:abla-sizes-detail-1mm-3mmThe proposed metric can reflect data semantic diversity.ccnewsimdbhttps://www.reddit.comopenwebtextfig:diversity-abla-workQuality filtering with quality factor keeps the diversity of the unfiltered dataset.table:quality_diversityccnetRelated WorkQuality Filtering.gpt3, palmdsirllamaccnetredpajamav1ccnet, dolmadata-pruningScaling Laws.2017scalinglaw, openai-scalinglawchinchillacrossling-scalinglawopenai-mm-scalinglaw, cl-scalinglawmeta-mm-scalinglawdeepseekllmConclusionsec:conclusionmeta-modelsquality factorsLimitationscustom\thetableA.\arabictable0AppendixHyperparameters of training language modelsapp:hypertransformermdeep, megatrontable:hyperpara-lmDerivation of \OurMethodapp:derivationPositive correlation between  and the negative tangent slopeapp:dv1chinchilla      (N, D) = E + {N^\alpha} + {D^\beta}

             N_{opt}\propto C^{a}\quad D_{opt}\propto C^{b} \\         \quad a={\alpha+\beta},\quad b={\alpha+\beta}     gathered     {\beta}={a}-1

              (N, D) = E + {N^{(1-a)\eta}} + {D^{a\eta}} \\     gathered     }{\partial N}=A\cdot (a-1)\eta \cdot N^{(a-1)\eta-1} 

    }{\partial N} < 0

             {\partial a \partial N} &= A\cdot \eta \cdot N^{(a-1)\eta-1}\\         &\quad + A\cdot (a-1)\eta \cdot \eta\cdot \cdot N^{(a-1)\eta-1}\\         &= A\cdot \eta \cdot N^{(a-1)\eta-1}\\         &\quad \cdot \left[1 + (a-1)\eta\cdot  \right]     aligned     A \cdot \eta \cdot N^{(a-1)\eta-1} > 0

     1 + (a-1)\eta\cdot  < 0

    {\partial a \partial N} < 0

             )}{\partial N} > 0, \quad         )}{\partial a \partial N} > 0     gathered     a \propto -{\partial N} \bigg|_{N = N_0}

Ablations on hyperparameters used in training 1.3B language models. Numbers in \gray represent the default values, as shown in Table~\ref. \\ \textbf BS. = Batch Size, Hella. = HellaSwag, Winog. = Winogrande. tab:abla-hyper1mmGeneralizing from tangent slope to secant slopeapp:dv2meta-models     }{\Delta N} = (N_q) - (N_p)}{N_q - N_p} = ^{N_q} {\partial N} dN}{N_q - N_p}

    a \propto -}{\Delta N} Sampling \textit top-k selectiongpt3, pile, dsir, quratingquratingtab:sampling Ablations on sampling vs. top-k selection. Note that the top-k results are identical to the original \OurMethod results reported in Table~\ref. We compare top-k data selection to sampling without replacement following~\citep. tab:sampling-3mmAblation Study on Hyperparameterstab:abla-hypertab:vs-quality-filter