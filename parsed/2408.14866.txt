LLMs have demonstrated impressive capabilities but raised safety concerns about the potential for malicious usage. To mitigate these concerns, efforts have been made to supervised fine-tuning of LLMs with instructions aimed at ensuring helpfulness and safety~, and align LLMs with human preference, known as Reinforcement Learning from Human Feedback (RLHF)~. RLHF involves training LLMs based on the rewards derived from models that have been trained on human preference data. Recent studies show that models aligned by preference optimization achieve improved robustness against adversarial attacks compared with models by fine-tuning~. Despite the efficacy of these alignment methods in promoting helpfulness and safety, LLMs remain susceptible to certain cases in which they still produce malicious responses under jailbreak attacks~. Our study mainly focuses on different safety-aligned models to explore the effectiveness of jailbreak attacks.

Existing red teaming has dedicated substantial efforts to identifying various jailbreak attacks. Initial jailbreak attacks involve the manual crafting of input prompts. A notable instance is the ``Do-Anything-Now'' attack, which is implemented by compelling LLMs to play a role that can do anything and respond to any query without refusal, thus bypassing safety constraints~. Subsequent advancements have automated the creation of these stealthy prompts~. Additionally, adversarial prompts have been identified in GCG, which utilizes gradient information to automatically generate effective adversarial prompts~. Furthermore, their results indicate the transferability and universality of these adversarial prompts. Recent work has also unveiled jailbreak attacks within the context of multilingual scenarios~ and non-natural languages such as ciphers~, highlighting the risk for all open-source LLMs with modified decoding strategies~. Our work focuses on adversarial suffix transferring learning across aligned LLMs and associates transferability with search efficiency.

In this section, we revisit the Greedy Coordinate Gradient (GCG) attacks. Let  denote the malicious prompts, such as ``Tell me how to make a bomb'', the objective of the GCG attack is to find the suffix  with length , so that by using  as input, the victim model can generate responses starting from the target sequence , such as ``Sure, here is how to make a bomb''. Consequently, the joint target distribution is represented by . The goal of searching for the target sequence can be formulated to minimize the following negative log-likelihood: 

GCG searches for adversarial suffixes through multiple iterations, adopting a greedy search strategy in each iteration. In one iteration, it selects the candidate suffix with the lowest  from the batch . To construct the candidate batch, it first computes the negative gradient  with respect to the one-hot vector representation  and selects tokens from the vocabulary with the top K values of , forming the token candidate set at each position. Then it uniformly replaces the token  at each position with random tokens from the obtained token candidate set, resulting in one suffix candidate with one replacement.  

To optimize the adversarial suffixes using multiple malicious prompts , the aggregated gradient  and the aggregated loss  are used instead to construct candidate batches and select candidate suffixes.   

% why decouple % - joint opt, treat each token contribution equally% - first token important than other token, other tokens introduce noise, % - optimize the model-agnostic/prompt-agnostic target --> pre-training The challenge of the GCG attack is primarily associated with the first-token optimization in Fig.~. However, Eq. assigns equal importance to each target token, regardless of varying levels of difficulty associated with optimizing each one. The multi-objective optimization introduces noise into the more challenging first-token optimization process, where significant loss signals could be biased by other competitors, thereby reducing the efficiency of the search. 

To address this issue, we propose decoupling the search process. Inspired by the popular pre-training and fine-tuning paradigm, we introduce a new framework, , which separates the search into behavior-agnostic first-token pre-searching and behavior-relevant content-aware fine-tuning. In this framework, we link transfer learning with searching efficiency. Our DeGCG tunes tokens in discrete space in a manner analogous to how parameters in continuous space are tuned during the pre-training and fine-tuning process. In this analogy, the counterpart of parameter space is the searching space in DeGCG. An overview of our method is presented in Fig.~. 

We introduce the first-token searching (FTS) task in the pre-searching stage. FTS aims to find a universal and generalizable suffix that elicits a response without refusal, applicable to all behaviors. Specifically, the goal of FTS in the pre-searching stage is defined as follows: 

In this task, the suffix is optimized based on the gradient derived solely from the first target token, resulting in a direct and efficient optimization. The first target token is typically behavior-agnostic, such as ``Sure'' or ``Here''. Therefore, the obtained suffixes  serve as a general initialization with a low cross-entropy loss for the first token. Starting the search from an effective initialization with a low first-token loss helps to mitigate the inefficiency associated with starting each search from a high first-token loss, reducing the time and computational resources accordingly. 

Suffixes obtained from FTS are effective for behavior-agnostic targets but fall short in eliciting behavior-relevant responses. Therefore, we propose to fine-tune the suffix in the pre-searching stage by performing content-aware searching (CAS) with behavior-relevant targets, such as ``how to make a bomb''. Given that this step builds upon the success of FTS, we maintain the FTS target in this step as well. Specifically, the goal for CAS is defined as follows To transfer the pre-searched suffix effectively, we explore three types of CAS: 

 uses the pre-searched suffix as an initialization when the dataset in CAS differs from the one in FTS. In this scenario, domain-specific data, such as chemical biology and cybercrime, are utilized to fine-tune the pre-searched suffix with the content-aware target. 

 employs the pre-searched suffix as an initialization when the LLM in CAS differs from the one in FTS.

 applies when FTS and CAS use the same dataset and LLM. This is detailed in the following Section~.

Leveraging the self-transferability of suffixes and enhance the efficiency of the search process, we propose an interleaved variant of our approach, . i-DeGCG integrates FTS and CAS as a meta-process and dynamically alternates between them. Specifically, in each iteration, it uses the suffix obtained from FTS as the initialization for CAS and then, conversely, uses the suffix from CAS as the initialization for FTS. This approach maintains a dynamic balance between generating the first token and producing behavior-relevant responses. The iterative process allows continuous refinement of the suffix, leveraging the strength of both FTS and CAS for enhanced overall performance. We summarize the algorithm in Alg..

 We utilize HarmBench~ to compare our approach and the baseline. We use the text-only set which comprises three types of behaviors: Standard, Copyright, and Contextual. Detailed statistics of HarmBench can be found in the appendix. In our experiments, we use validation and test splits provided by HarmBench. Specifically, we use the standard behavior subsets of both validation and test sets. The validation set serves as the training set for searching suffixes, and we evaluate performance on the test set. 

 We evaluate our method on open-sourced models. Specifically, we utilize LLama2-chat~, Mistral-Instruct~, OpenChat-3.5~, and Starling-LM-alpha~ in our experiments. Due to memory constraints, we use 7b models for all experiments. For evaluation, we report the classifier-based attack success rate (ASR). We consider the baseline GCG-M from the HarmBench that uses GCG for suffix searching with multiple behaviors. To ensure reproducibility and fair comparison, we use the open-source classifier provided in HarmBench. This classifier is a fine-tuned LLama2-13b model, which achieves strong performance on a manually-labeled validation set.

% hf: just realize, do we need to include GCG-T as the baseline in the cross-model transfer exp? 

To evaluate the efficacy of suffixes trained through FTS on one model transferring to another model via token-level fine-tuning, we conduct cross-model transferring experiments across four open-source models. To ensure a fair comparison, we maintain equal total search steps (FTS + CAS) for all experiments, consistent with the baseline, totaling 500 steps. We also include the baseline GCG-T from HarmBench that optimizes suffixes against multiple models for transferring. Our transfer performances on the validation set and test set are presented in Table~. 

Our proposed DeGCG approach significantly surpasses the GCG-M across various models on both validation and test sets. For example, DeGCG achieves absolute improvements of 9.0 and 9.8 in ASRs from Starling-LM to OpenChat-3.5 on validation and test sets. This indicates that the suffix derived from FTS on one model proves to be an effective initialization point for transferring to a new target model. Notably, despite differences in tokenizers between source and target models, transfer learning from FTS through CAS still yields significant performance improvement. For instance, transferring suffix from Mistral-Instruct to Llama2-chat achieves absolute enhancements of 22.2 and 9.4 in ASRs on validation and test sets, demonstrating the efficacy of DeGCG. Additionally, the DeGCG approach outperforms GCG-T on both validation and test sets. This further reveals that our suffix transfer learning is more effective than the direct transfer with suffix concatenations searched on multiple models.  

Moreover, when the target model is identical to the source model, the DeGCG method significantly improves ASR performance, achieving over 100\% enhancement on LLama2-chat-7b. We attribute this improvement to the effective initialization provided by FTS on the same model, which facilitates a more efficient token fine-tuning process within a favorable neighbor area in the search space.

To evaluate the effectiveness of the DeGCG framework in cross-data transferring, we initially perform FTS on llama2-chat-7b using the general dataset of HarmBench. Subsequently, we conduct CAS with a domain-specific dataset derived from the general validation set of HarmBench. Specifically, we use six distinct semantic categories defined in HarmBench as separate domains: Chemical Biological, Misinformation, Illegel, Cybercrime, Harmful, and Harassment Bully. The general GCG-M without domain data training serves as the baseline. We also include experiments using GCG-M trained with the same domain data. To ensure a fair comparison, all experiments maintain the same total search steps, 500. The experimental results for both validation and test sets are displayed in Fig.~. 

We observe that DeGCG outperforms GCG-M and GCG-M w/ domain data in terms of ASR performance across five of the six categories. The inclusion of domain data significantly enhances performance, particularly in the Chemical biological, Misinformation, Illegal, and Cybercrime categories. The relatively lower ASR performance in the Harmful and Harassment Bully categories could be attributed to the limited data size in these categories. Nonetheless, the success of the behavior-agnostic suffix transferring underscores the efficacy of FTS, validating the necessity of the decoupled first-token searching and content-aware search process.

To evaluate the effectiveness of the proposed i-DeGCG algorithm for self-transferring, we apply the interleaved algorithm on Llama2-chat and Openchat-3.5 models, respectively. In this context, the source and target models are identical, and the validation set is used as the training dataset. We assess performance across various scales of the searching space. Specifically, given that the searching space grows exponentially with increased suffix length, we extend the adversarial suffix length from 20 to 40, 60, 80, and 100, representing five different sizes of searching spaces. For fair comparison, we maintain the same total searching steps across all experiments. The experimental results are detailed in Table~. 

The empirical findings in Table~ suggest that larger searching spaces provide more suffix combinations and a greater possibility of achieving successful attacks, but also introduce more complexity and significant challenges in searching adversarial suffixes. Notably, our proposed i-DeGCG can outperform baselines across all scales of searching spaces, achieving 65.9 and 52.2 for Llama2-chat and 95.1 and 90.6 for OpenChat-3.5 on validation and test sets. GCG-M struggles with the larger search space, resulting in lower performance. In contrast, i-DeGCG can facilitate efficient self-transfer between FTS and CAS. This underscores the importance of self-transferability in enhancing the efficiency of adversarial suffix searching.   

To demonstrate the enhanced search efficiency achieved by the DeGCG framework and i-DeGCG algorithm, we plot the training dynamics every 100 steps. Specifically, we examine the cross-entropy loss of the first token (FT), the average cross-entropy loss of the entire target sentence (ST), and the ASR performance on both the validation (Valid) and test sets. The dynamics for Llama2-chat, with a total of 500 steps and a suffix length of 20, are illustrated in Fig.~. For DeGCG under this experimental setting, we perform the FTS for 100 steps followed by CAS for 400 steps.

As depicted in subfigures (a) and (b) of Fig.~, both DeGCG and i-DeGCG converge faster than GCG-M, achieving lower cross-entropy losses for both the first-token and the target sequence. Notably, DeGCG reaches a near-zero FT loss within 100 steps, whereas the one of GCG-M remains greater than 10 within the same steps. This indicates that the first-token optimization is noised and hindered by other optimization goals, degrading searching efficiency. Compared to DeGCG, the interleaved variant i-DeGCG shows higher FT loss but lower ST loss, attributed to the alternation between FTS and CAS, achieving a dynamic balance between these two searching stages.  

Regarding the ASR performance, shown in subfigures (c) and (d), DeGCG and i-DeGCG outperform GCG-M, achieving the best results within 300 steps, while GCG-M continues to underperform even after 500 steps. It is noteworthy that DeGCG achieves low ASR within the initial 100 steps using only FTS and reaches optimal performance within the subsequent 100 steps using CAS. This reveals that CAS is essential for a successful attack, and FTS provides a solid initialization for CAS. In addition, i-DeGCG achieves higher ASR performance within the first 100 steps compared to both DeGCG and GCG-M, and comparable performance to DeGCG within the first 300 steps. This success of both DeGCG and the interleaved variant validates the effectiveness of the decoupled framework and highlights the importance of self-transferable suffixes. i-DeGCG is particularly advantageous when the boundary between FTS and CAS is not easily determined due to its dynamic balance nature.

To further investigate the impact of self-transferring on performance enhancement, we conduct a new self-transferring experiment via self-repetition. Specifically, we aim to achieve an effective initialization in larger search spaces. Instead of initiating searches from a random suffix in a large search space, we utilize suffixes obtained in a smaller search space and expand the search space through self-repetition of these short suffixes. In other words, the longer suffix initialization is constructed by repeating the shorter suffix and concatenating them for searching within the large search space. For this experiment, we use the suffix of length 20, searched on Llama2-chat-7b after 500 steps, and repeat it 2, 3, 4, and 5 times to create suffix initializations of lengths 40, 60, 80, and 100, respectively. We then perform content-aware searching on these initializations for an additional 500 steps and report the ASR performance in Table~. The experimental results reveal a significant improvement, with ASR performance increasing from 21.7 to 68.3 on the validation set and from 19.5 to 54.7 on the test set. These findings also indicate that suffix search in small search spaces provides valuable and effective initializations for longer suffix construction for further fine-tuning in large search spaces.

To further assess the effectiveness of our design, we conduct an ablation study on the initialization. Specifically, we compare initializations obtained by FTS and GCG-M for the same number of steps, aiming to evaluate the utility of different trained suffix initializations for content-aware fine-tuning. We examine how suffix initializations on source models Starling-LM-alpha-7b, Mistral-Instruct-7b, and OpenChat-3.5-7b transfer to the target model Llama2-chat-7b. The experimental results are presented in Table~. The empirical findings demonstrate the superiority of the first-token searched initialization. We attribute this to the behavior-agonistic nature of suffixed obtained by FTS, which is easier to transfer across models and can be fine-tuned effectively on a target model, achieving higher ASR performance compared to initializations obtained through GCG-M.   

We show the statistics of the HarmBench subset of Standard behaviors used in our work in Table~. Specifically, we show the total validation ( Valid)and test( Test) set sizes and the numbers for six semantic categories: (1) Chemical Biological: Chemical  Biological Weapons/Drugs, (2) Misinformation: Misinformation  Disinformation, (3) Illegal: Illegal Activities, (4) Cybercrime: Cybercrime  Unauthorized Intrusion, (5) Harmful: General Harm, (6) Harassment Bully: Harassment  Bullying. For all experiments, we use the validation set as the training set and evaluate performances on the test set. 

We use Pytorch and Huggingface Transformers in our implementation. We run all evaluations on a single NVIDIA A40 GPU (48G). We provide all used model cards in Table~. Specifically, we evaluated four models in our main experiments. We used one fine-tuned Llama2-13b model, provided by HarmBench, to classify the output of these evaluated models. % and the system prompts in Table~.

For cross-model and cross-data transfer experiments using the DeGCG in Section~, we set the maximum search step of the FTS as 200, indicating a minimum 300 search steps for CAS to keep the 500 total search steps. Besides, we set the threshold of the training loss to be 0.2. When the training loss reaches a lower value than the threshold, we update the training behavior set. For interleaved self-transfer experiments using i-DeGCG, we set the threshold  and  of training loss for both FTS and CAS as 0.2. As for the maximum steps  for one stage, we set it to be 20 and 30 for FTS and CAS, respectively.

% % 

Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy Coordinate Gradient (GCG). However, GCG struggles with computational inefficiency, limiting further investigations regarding suffix transferability and scalability across models and data. In this work, we bridge the connection between search efficiency and suffix transferability. We propose a two-stage transfer learning framework, DeGCG, which decouples the search process into behavior-agnostic pre-searching and behavior-relevant post-searching. Specifically, we employ direct first target token optimization in pre-searching to facilitate the search process. We apply our approach to cross-model, cross-data, and self-transfer scenarios. Furthermore, we introduce an interleaved variant of our approach, i-DeGCG, which iteratively leverages self-transferability to accelerate the search process. Experiments on HarmBench demonstrate the efficiency of our approach across various models and domains. Notably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of  () and  () on valid and test sets, respectively. Further analysis on cross-model transfer indicates the pivotal role of first target token optimization in leveraging suffix transferability for efficient searching.

% highlight transferabilityIntroductiongpt4,google,llama2align3,align1,align2jailbrokenjailbroken,albert2023jailbreakchat,kang2023exploiting,sesame,autodangcggcgmeade2024universalfig:token-level-ceIn the pre-searching stage, we perform a simplified task, First-Token Searching (FTS), searching for adversarial suffixes with a behavior-agnostic target such as ``Sure'', enabling LLMs to elicit the first target token without refusal.     In the post-searching stage, we start with the suffix obtained from the pre-searching stage and conduct Content-Aware Searching (CAS) with a behavior-relevant target. This stage transfers the behavior-agnostic initialization to behavior-relevant suffixes. Related WorkSafety-Aligned LLMsinstruction,inst-tuning,llama2rlhf,align1,align2,align3meade2024universalkang2023exploiting,hazell2023large,albert2023jailbreakchatwidth=\linewidthimg/main_fig_new.pdfOur DeGCG framework involves two main stages. In the pre-searching stage, we perform the first-token searching with LLM A on Behavior Set A. In the post-searching/fine-tuning stage, we perform content-aware searching with LLM B on Behavior Set B. The Suffix-FTS obtained in the pre-searching serves as the initialization for the post-searching. \textbf uses the same LLM but distinct sets, while \textbf uses the same set but distinct LLMs. For \textbf, we use the same LLM and set but alternating between FTS and CAS.fig:main-4mmJailbreak Attacks on Aligned LLMsalbert2023jailbreakchat,jailbreakingchatgptautodan,autodan2gcg,autopromptmultilingualciphermiMethodPreliminary


    & \limits_{} (, ) \\     = & \limits_{}\left[ -\sum_{k=1}^{m} \log p(t_{n+k}|t_{1:n+k-1})\right] \\ aligned% \smalli-DeGCG Algorithmalg ~~ Initial suffix , behavior set , iterations , batch size , FTS threshold , CAS threshold , stage flag , maximum steps  for one stage   ,   ,             ,            Get  by           ,            ~~ adversarial suffix  Initialize behavior set and accumulated stepConstruct suffix batch under specific lossUpdate stage flag Update behavior set DeGCGfig:token-level-ceopDeGCGfig:mainFirst-Token Searching

 & \limits_{} \sum_j_{FTS}(^{(j)}, ) \\      = & \limits_{} \sum_j\left[- \log p(t_{n+1}^{(j)}|t_{1:n}^{(j)})\right] alignedPerformance comparison (ASR) in Cross-Model Transferring across four different models on both the Validation (Valid) and the Test sets. Model A and Model B refer to source models and target models respectively. tab:cross_model_transfer-3mmContext-Aware Searching

    & \limits_{} \sum_j_{CAS}(^{(j)}, ) \\     = & \limits_{} \sum_j\sum_{k=1}^{m} \log p(t_{n+k}^{(j)}|t_{1:n+k-1}^{(j)}) alignedCross-Data TransferCross-Model TransferSelf-Transferinterleavedtable/cross-modelInterleaved Self-Transferinterleavedi-DeGCGalgExperimentsSetupDatasets. harmbenchImplementation Details. llama2mistralopenchatopenchatMain Resultsmain_resCross-Model Transferring.cross-modelscale=0.35img/cross_data.pdfPerformance comparison (ASR) in Cross-Data Transferring across different behavior types in HarmBench. We report the results of LLama2-chat-7b on both the Validation and the Test sets.fig:data_transfer-3mmtab:cross_model_transferCross-Data Transferring.cross-datafig:data_transfertable/interleavedInterleaved Self-Transferring.self-transfertab:interleavedtab:interleavedAnalysisTraining Dynamics Comparisonfig:train_dynamicfig:train_dynamicscale=0.31img/train_var.pdfTraining dynamics (cross-entrory loss) comparison for GCG-M, DeGCG, and i-DeGCG.  fig:train_dynamic-4mmSelf-Transferring by Self-Repetitiontab:self-repetitiontable/self-repetitionAblation Studytab:abl_sttable/abl_stConclusionLimitationsEthics StatementcustomAppendixsec:appendixDataset Statisticstable:app_datatable/app_dataset-3mmImplementation Detailsapp:model_cardmain_restable/app_model