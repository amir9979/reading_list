Self-supervised learning has fueled the recent development of foundation models by leveraging vast amounts of unlabeled data which are commonly found in digital pathology. Trained on hundreds of thousands of tissue patches, typically spanning across multiple cancer types, these models are able to learn powerful task-agnostic tissue representations. CTransPath~ and Lunit~ foundation models trained on the entire TCGA cohort~ have shown improvements across a variety of primary analysis tasks such as tumor subtyping, mitosis detection, and cell segmentation. Huang  fine-tuned the CLIP~ model using the histopathology text-image pairs from Twitter to produce PLIP~ which improved the tumor detection and tissue grading and subtyping tasks. UNI~ and Virchow~ are trained on some of the largest private data cohorts with 100,000 and 1,000,000 WSIs respectively. Among these, only Phikon~ and Virchow~ explored their performance on a secondary analysis task of mutation prediction while only Phikon explored the task of survival prediction. However, their tests on secondary analysis tasks were limited and didn't produce unanimous conclusions on survival prediction task.

The weakly-supervised learning nature of MIL models suits perfectly for the analysis of local regions-of-interest in gigapixel WSIs. The MIL-based deep models have seen tremendous success in computational pathology in the recent years~. Ilse ~ proposed the first learnable attention-based aggregation strategy in MIL models (ABMIL) that outperformed the traditional pooling methods. Subsequent works such as CLAM~ and VarMIL~ built on top of this method by improving latent representations of the patch and slide features. The onset of self-attention has enabled the integration of transformer-based aggregation strategies in MIL models such as TransMIL~. The consistent success of MIL models have made it a default strategy for the analysis of WSIs and in this work we use the aforementioned MIL methods that have been used extensively in the literature.

% (add CA125 criteria used and also PFS data)

Ovarian bevacizumab response dataset~ is a publicly available dataset provided by the Cancer Imaging Archive (TCIA). The dataset consists of 286 hematoxylin and eosin (H) stained whole section WSIs from 78 patients scanned at  magnification from the tissue bank of the Tri-Service General Hospital and the National Defense Medical Center, Taipei, Taiwan. The dataset also includes the clinical information of the patients such as the PFS along with the treatment effectiveness of the bevacizumab treatment. The ground-truth binary treatment response was identified based on the pre- and post-treatment CA-125 concentrations, with the bevacizumab treatment being effective for 160 patient slides and ineffective for the remaining 126 slides in the cohort. Fig.~a. shows the patient distribution across the different ovarian cancer subtypes in the dataset and Fig.~b. shows the slide-level distribution along with the subtype-wise binary effectiveness label splits.

For training the model, we divide the dataset into 3 folds with training (70\%) and validation (15\%) splits, and we use the same held-out testing split (15\%) to evaluate the models across all folds. Our test set has an equal class distribution with 37 slides each in the effective and ineffective treatment classes (total test set size = 74 slides). The data splits are done at the patient level so that all slides from a patient belong to the same split. Additionally, we conduct experiments exclusively on the serous subtype (includes peritoneal serous papillary carcinoma and papillary serous carcinoma) which is the majority subtype in the dataset as shown in Fig.~.

We formulate the problem of treatment response prediction from WSIs using two approaches. First is the binary classification approach where the model predicts the treatment effectiveness from WSI whether the treatment was effective () or ineffective (). Second is the survival prediction problem where the model uses the WSIs to predict the hazard score of the patient relative to other patients in the cohort. 

We denote the WSI as  and the corresponding binary treatment label, time-to-event, and censor status as , , and  respectively. Our dataset can then be represented as , where  is the total number of WSIs in the dataset. Each WSI can be treated as a bag of tissue patches denoted by  which can be represented as , where  is the number of patches extracted from each WSI. As part of the pre-processing step, each patch is passed through the color normalization module where a reference patch is used to normalize the stains across different patches. 

Each patch  is passed through a pre-trained histopathology foundation model, denoted by  to produce the corresponding feature representation ,

 where  are the parameters of the pre-trained foundation model and the asterisk indicates the parameters are frozen. Each WSI can now be represented as a bag of patch features as, . This bag of features is passed to the MIL model denoted by  in order to aggregate the patch-level features of a WSI  to form a slide-level representation  in a learnable manner. This can be represented as, 

 where  denotes the trainable parameters of the MIL model . The slide-level representation  is used for predicting the treatment response for the patient corresponding to the WSI . The slide-level representation is passed to the MLP layers denoted by  to predict the binary treatment response  as follows,

 where  denotes the trainable parameters of the MLP layers. In the same way, the MLP layers can be used to predict the logarithmic hazard score  from the slide-level representation as follows,

Given the model predictions  and , we use the ground-truth treatment response   along with the time-to-event  and censor status  corresponding to WSI  to train the model parameters. For training the classification model, we use the binary cross-entropy loss function  and for the survival prediction model, we use the cox negative partial log-likelihood loss function ~, which can be calculated as follows,

% along with the model prediction  in a binary cross-entropy loss function  to train the model parameters of the MIL model  and the MLP layers  in an end-to-end manner with the patch features  as input to the model.  Eq.~ shows the binary cross entropy loss function where  denotes the number of WSIs in the training set and Eq.~ denotes the cox negative partial log-likelihood function where  denotes the risk set at time . In both cases, we minimize the loss functions while updating the parameters of MIL model  and MLP layers  while the parameters of the encoder model  are frozen.

In our experiments, we use a patch size of  at the original  magnification and sample  patches from each WSI. We use the Macenko stain normalization technique~ to alleviate the staining disparities across different WSIs by performing the normalization across all extracted patches. Further, for training the models, we use the binary cross-entropy loss (Eq.~) for the classification setting and the cox partial log-likelihood loss (Eq.~) for the survival prediction setting. For all our experiments, we use Adam optimizer~ with a learning rate of  and a weight decay of . All models are trained for a maximum of  epochs and the model at the best validation performance epoch during the training process is used for inference. To ensure the statistical stability of models, we train all the models with 10 different random seeds across 3 folds and report the 3-fold average metric with the best-performing seed. We use the accuracy and AUC scores as the metrics to evaluate the performance of the models as our test set has an equal class distribution. To evaluate the survival models, we use the commonly used concordance index (c-index) metric~ in addition to evaluating the risk stratification using the Kaplan-Meier (KM) curves with the log-rank test. For all our experiments, we use the NVIDIA GeForce RTX 3090 and RTX A6000 GPUs to train the models.