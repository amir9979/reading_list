In this section, we summarize the main steps of the classical MIL pipeline, that we enhance with our Context-Aware Regularization in the next section.

%  Each WSI -- taken at the level of magnification the closest to 4 Microns Per Pixel (MPP) -- is split into  by  patches to be fed into a 2D U-net matter detection model , trained on a pancancer dataset. The slide without background and artefacts (at level 0.5 MPP) is then tesselated into tiles of identical size, and only  tiles from the tissue region of each WSI are selected at random for computational efficiency.   Each WSI is segmented to keep only the tissue and remove the background (e.g. using the otsu method). %  The tissue parts are then tessellated into tiles of size  pixels taken at 20X magnitude (/pixel) and each WSI is reduced to a set of  tiles of tissue selected at random. %  A pre-trained feature extractor is then used to map each tile into a low-dimensional tile feature space of dimension . This results in a matrix representation  for the WSI indexed by .

%The encoder is a GNN made of 2 Message Passing layers (MP) before being fed to two branches. The spatial decoder consists in 2 Fully-Connected (FC) layers, followed by an Inner Product Decoder (IP) to reconstruct the original adjacency matrix.%  The feature extractor is a pretrained model chosen to be highly expressive to capture  the most relevant features within the original images. Rather than using % a feature extractor trained on ImageNet, we choose to extract features from each tile of the WSIs based on a state-of-the-art self-supervised model, Phikon, trained directly on histopathology data; see . It extracts -dimensional features from each tile such that one WSI in the dataset, indexed by , is represented as . In the pipeline shown in fig.~, the learnt weights are kept frozen. % % We build a graph  for each WSI in the dataset. Each  vertex corresponds to a tile and the adjacency matrix  is computed based on the Euclidean distance between the  coordinates tiles in the original 2D image.% , see Sec.\ .  The MIL model  is a parametric model trained to aggregate the tile features of a WSI and estimate a risk associated with the overall survival of the patient  %  The parameters  of the MIL model  are optimized to minimize a survival loss , such as the Cox loss. Formally, this corresponds to the optimization problem % %  where  is the number of training WSIs and  is the overall survival risk of patient . %  Examples of such MIL models are ABMIL , Chowder , and AdditiveMIL . %  It is worth noting that the spatial relationships between tiles are not used by , since their ordering is random in .

We propose a general approach to leverage local spatial context in computational histopathology.  %  Our pipeline, which can be applied to any task or MIL model, is depicted in fig.~.

For each WSI, we build a graph  where the vertices are the tiles features , as described in the previous section, and  is the adjacency matrix computed based on the euclidean distance between the spatial coordinates of the tiles in the original WSI for a given number  of nearest neighbors.

To embed the spatial structure of the WSI into the tiles features, we introduce a spatial encoder  of parameters  and a spatial decoder  of parameters  before the classical MIL model  of  as illustrated in Fig.~% In , the authors introduce a new architecture capable of capturing the whole structure of a graph, the Graph AutoEncoder (GAE). 

Here, the goal of  is to distill the spatial information contained in an input WSI graph   % with degree matrix   into tiles features , resulting in a new low-dimensional Context-Aware embedding  of the WSI.  To achieve this goal,  aims at reconstructing the input adjacency matrix  from  during training while, concurrently,  aims at predicting the patient risk from . %  Formally, this corresponds to adding a Context-Aware Regularization term  to the training optimization problem of classical MIL : %  where the same notations as in  are used and, %  By reformulating the training problem as a  optimization task, the models' parameters are obtained by simultaneously solving a pair of objectives, which may initially appear orthogonal.  %  When , the method boils down to the classical MIL pipeline, whereas  reduces the task to encoding the spatial context only as in a Graph AutoEncoder (GAE) . %  Note that the spatial decoder  is not required at inference.

The spatial encoder  and spatial decoder  are obtained by stacking up, respectively  and , graph convolutional network () layers: % a lower dimensional subspace  while allowing for a reconstruction of the original graph structure  with a spatial decoder. % Namely,      where  is a learnable weight matrix and the matrix  may be preprocessed.  %and  the symmetrically normalized adjacency matrix with  being the degree matrix of .  If we denote the composition of a function  by itself  times as , then, % % and  the sigmoid function.

Similarly to a GAE, the last layer of the spatial decoder is an inner-product decoder with a sigmoid function , that aims at reconstructing the input adjacency matrix , %The weights are learnt from backpropagating a Binary Cross Entropy loss. As illustrated in Fig.\ , beyond the conventional MIL pipeline, we add a decoder to the latent representation of each WSI in order to reconstruct the original spatial context.% % We propose to add a regularization term to the loss function in order to account for spatial constraints in each of the  slides constituting our dataset. Precisely, considering a WSI labelled as  along with its associated graph , the objective is to generate the most accurate prediction . Concurrently, we enforce the slide's latent representation to retain enough contextual information so that the predicted adjacency matrix  retrieves as closely as possible the original graph structure. To achieve this, the considered loss function is the weighted average between a loss to solve the original problem balanced with a Context-Aware Regularization, as follows,% %     %     \min_{\theta} \sum_{1\leq i \leq N_{}} \Big( \beta _{}\big(^{(i)}(\theta), A^{(i)}\big) + (1-\beta) _{}\big(^{(i)}(\theta), y^{(i)}\big)\Big),% % where, % %     %      _{}((\theta), A) \coloneqq n^{-2} \sum_{p,q} A_{pq} \log \sigma\big( _{pq}(\theta) \big) + (1-A_{pq}) \log \Big(1 - \sigma \big(_{pq}(\theta) \big)\Big).% % %The choice of the mixing coefficient  involves a delicate balance between retaining contextual information and prioritizing , mirroring the decision-making process from pathologists. % By reformulating the problem as a  optimization task, the model's parameters are obtained by simultaneously solving a pair of objectives, which may initially appear orthogonal. Besides, when , the method boils down to the traditional MIL pipeline, whereas  reduces the task to retrieving the spatial context only. %The influence of context is known to vary depending on the task or the dataset at hand, thus we do not expect the hyperparameter tuning of  to be universal across tasks nor datasets. 

Reporting task-related scores alone is not enough to quantify the amount of Context-Awareness in a tiles embedding space. %  To overcome this issue, we propose a novel  metric based on . 

Let  be tiles descriptors, we denote  the adjacency matrix based on the  nearest neighbors for the euclidean distance between the components of . %  This is different from , defined in sec.~, that is based on the distance between the spatial coordinates of the tiles. %   can be any representation of the tiles, here it will either be the features  or the embeddings  as defined in sec.~.

We propose to use the  similarity between the adjacency matrix based on tiles descriptors  and the adjacency matrix based on the spatial coordinates  for the same WSI as our metric of . %  Since we have directed graphs and the adjacency matrices  and  are non-symmetric, we propose this extension of the original  similarity

where , where , resp. , is the diagonal matrix counting the incoming, resp. outcoming, edges and  denotes the Frobenius norm.

Intuitively,  is a matrix capturing the degrees of similarity between all tiles when one travels in the original graph corresponding to . %  Direct neighbors are the most similar tiles, followed by neighbors of neighbors, and so on. %  As a result,  is close to 1 when the neighbors in the tiles descriptors space and the spatial coordinates are almost the same and it smoothly decreases towards 0 when those neighbors become dissimilar between the tiles representations and the spatial coordinates.

% Once training is completed, each WSI originally represented as a graph  is embedded into a lower dimensional vector , see eq.~. Our  assessment consists in quantifying how much spatial information is retained in the encoded vector  as compared to . % % % To do so, we compare the spatial arrangement of the tiles within the original slide represented by the matrix  (where  is the spatial affinity between tiles  and ), to a new adjacency matrix  that we construct based on ; see App.~ and ~. If these two matrices are similar, it indicates that the embeddings learnt by the model conform to the spatial arrangement of the tiles. In other words, the same tiles remain neighbors in the new embedding space as in the original feature space. Therefore, the question of how much spatial information a MIL model has retained now comes down to quantitavely comparing two adjacency matrices. % To measure the distance between two adjacency matrices in a scalable way, we opt for the  similarity, see . For instance, consider a graph consisting of two cliques connected by an edge. Removing this edge would significantly disrupt information flow compared to removing an edge within either clique. Because the  metric emphasizes on the -hop neighborhoods over direct edge-to-edge comparisons (both pairs of graph differ only by one edge), it accurately distinguishes between these scenarios and assigns a higher similarity score to cases with less impact on the overall connectivity. The  metric is obtained through a proxy function  defined as, % %         S(A) \approx ( - \epsilon A)^{-1} =  + \epsilon A + \epsilon^2 A^2 + \dots .% % %A -hop neighborhood in a graph refers to the set of nodes that can be reached from a given node within  hops or steps, which is precisely what the powers of , and consequently the  metric, unravel. % It is sensitive to information flow and higher order neighborhoods because  encapsulates information about paths of length  within the graph. For two adjacency matrices  and , their similarity can now be computed as,% \left(A^{(1)}, A^{(2)}\right) = % {1 + ||S(A^{(1)}) - S(A^{(2)})||_F},% % where the  denotes the Frobenius norm. Evaluating the similarity between different orders of neighborhoods becomes especially meaningful when inputting graphs to  layers, as their propagation equations are dictated by these sets, see eq.~. %Additionally,  is demonstrated to exhibit some desirable robustness properties in the face of small graph perturbations, such as random edge removal. We used H slides of patients with glioblastoma from the datasets TCGA GBM~ and TCGA LGG~.%, and CPTAC-GBM~.  We filtered cases according to the latest WHO classification for gliomas~. See App.~ for more details. % The WHO 2021 classification defines glioblastoma as IDH-wild type and H3-wild type brain tumor with at least one of the following features: necrosis and/or microvascular proliferation, TERT promoter mutation, EGFR amplification, or concomitant gain of chromosome 7 and loss of chromosome 10.% We will refer as TCGA GBM to those glioblastoma cases from the datasets TCGA GBM and TCGA LGG after reclassification.% TCGA GBM contains 352 cases from 18 centers.% and CPTAC GBM contains x cases from y centers.% % % This change of classification of glioblastoma has been shown to have a negative impact on the prognostic value of previously published biomarkers . Therefore, it is clinically important to evaluate previous and new prognostic models on glioblastoma using the new WHO classification. We used H slides of patients with colon adenocarcinoma from TCGA. The TCGA COAD dataset contains a total of 431 cases from 24 centers.

All models were trained and evaluated on TCGA COAD and TCGA GBM using 5-fold nested cross validation  to allow for hyperparameters tuning and assess the generalisation independently on those datasets. %  Three repeats were used in the inner loop, corresponding to three different random initializations of the MIL or CARMIL models. %  As a result, metric evaluation on each of the  test splits was performed using an ensemble of  models ( inner validation splits and  repeats). Ensembling was performed by averaging the risk output of the models of an ensemble. In all the tables, we show the mean (std) C-index for OS obtained using 5-fold nested cross validation. The best results are in bold. %  For tissue segmentation, a 2D U-net  trained on a pancancer dataset of manually annotated WSIs is used. %  Tile features of dimension  are computed using a state-of-the-art self-supervised model, Phikon, trained on pancancer H slides from TCGA . %  The parameters of Phikon are kept frozen in all our experiments. %  The preprocessing is the same for all the models we compare to.

The Cox loss was employed in the supervised training of all models, utilizing overall survival labels. This corresponds to  in eq.~. %  The CAR loss, denoted as  in eq.~, is applied across all CAR models and we use  in eq.~ for the total loss accross all CAR models.  The choice of  followed the empirical observation that  and  have similar range of values during the first epoch of training. %  Adam optimizer  with momentum  and  is used for training with a learning rate on the grid  for all models. The maximum learning rate value  was chosen heuristically to be the smallest value on the grid for which most MIL models diverged during training. The number of training epochs is optimized on the grid . % %  One NVIDIA Tesla T4 GPU with 16GB of VRAM and 8 Intel(R) Xeon(R) 2.00GHz CPUs are used for training and inference of each model.

In tables ~ and , we report the performance of various MIL models for the challenging task of survival prediction on TCGA COAD and TCGA GBM. %  In table~, we compare classical MIL models, selected for being agnostic to the spatial context, to their performance when enhanced with our CAR scheme. %  In total, CAR improved C-index values by up to 4.8 percentage points (pp) in  settings and on average the C-index increased by  pp on TCGA COAD and  pp on TCGA GBM. %  In addition, we compare classical MIL models enhanced with CAR to state-of-the-art model architectures that were designed specifically to leverage graphs of tiles.  %  CARMIL models perform similarly or better than these more sophisticated models in terms of C-index; see table .  % % This suggests that even the simplest existing MIL models (e.g. MeanPool), when enhanced with CAR, competes with -- and even outperforms -- more complex architectures such as Vision Transformers and their local version (LaMIL), or Graph Neural Networks (GNN). % % Besides, in table~, we also compare classical MIL models, selected for being agnostic to the spatial context, to their performance when combined with our CAR scheme. % % In total, CAR improved C-index values by up to 4.8 percentage points (pp) in  settings and on average it improved the C-index of  pp for TCGA COAD and  pp on TCGA GBM.% % This allows us to clearly point out the benefits of incorporating spatial elements through regularization .% % % On both datasets, nearly all models benefit from our spatial regularization and outperform their original version.%  This suggests our CAR method improves performance by successfully integrating spatial context through regularization. % The impact of the CAR formulation on the robustness of the model is not clear from the standard deviation scores and yet still remains an open question.In this section, we compile evidence supporting the successful injection of spatial information in the proposed CAR models and its associated performance benefits. First, we assess whether CAR models genuinely exploit the input graph for their predictions. To this end, we perturb the graph at inference time by randomly shuffling all the off-diagonal terms of the adjacency matrix . If the CAR models were to fail to exploit the graph structure, this disruption would not impact their performance. However, the results reported in table  indicate that graph shuffling leads to a degradation in the model's performance, showcasing that the graph structure is indeed used in the model's decision-making process.

% In fig., we compared heatmaps measuring the mean spatial distance between each tile of a WSI (TCGA GBM)and its nearest neighbors in the original embedding space of either Phikon or the proposed CARABMIL spatial encoder.% % % The heatmaps suggest that the tiles embedding of CARABMIL are more aligned with the spatial arrangement of tiles on this WSI from TCAG GBM.% {TODO} Secondly, we assess the  of trained CARMIL models compared to the feature extractor, using the  metric that we defined in sec.~.  %  For each WSI, the adjacency matrix computed in the embedding space learnt by the spatial encoder of fig.~ is compared to the original adjacency matrix that accounts for the spatial arrangement of the tiles within the slide.  %  The  provides us with a score between 0 and 1. %  A higher  score indicates a higher degree of spatial consistency in the learnt embedding space as it implies that the arrangement in the embedding space closely aligns with the original spatial organization within the slide. We average this slide-level score across the whole TCGA COAD and GBM datasets, see table~. In app.~, we showcase an example of a WSI illustrating how the embeddings provided by CARMIL encoders are more spatially consistent than the original features. Moreover, in fig.~, we can clearly see how the spatial encoders implement more  than the feature extractor (dotted lines). Indeed,  is almost always greater for CARMIL models than for the feature extractor. Therefore, these findings confirm the successful injection of spatial knowledge resulting from the CAR. Additionally, we explored the relationship between spatial information incorporated by the spatial encoder and C-index performance. In TCGA COAD, the performance seems to correlate with the level of , potentially providing insights into colon cancer. However, in TCGA GBM,  it is uncertain whether adding spatial elements improves performance, and understanding how  influences overall performance remains an open question.

% Lastly, we show in fig.~ an example of a slide whose embedding given by CARABMIL encoder exhibits greater spatial consistency than the original features. % 

Each WSI  consists of a set of  tiles. For each tile , we keep track of its spatial coordinates in the 2D plane formed by the tissue region, , in addition to the -dimensional features vector  produced by the feature extractor for that tile. We thus compute the gaussian kernel, ,

and we set the diagonal to . Provided  the number of neighbors, we select the  nearest neighbors for each node based on the similarity matrix . The adjacency matrix  is defined such that  equals  if tile  is one of the nearest neighbors of tile , and  otherwise. %The degree matrix  is a diagonal matrix accounting for the degree of each node, .

Adjacency matrices in the embedding space are used for the evaluation of  using .

Consider training of our model complete and the final parameters to have converged to . Given a WSI, represented as , our spatial encoder returns a lower dimensional vector . Observe that  is the -dimensional embedding for tile . Based on this vector, we construct an adjacency matrix , following the same principle as before, but this time based on the affinity between embeddings rather than using the spatial coordinates of the tiles, namely, ,

and we set the diagonal to . We similarly pick the  nearest neighbors for each tile and we construct the adjacency matrix , that we refer to as the adjacency matrix in the embedding space. Therefore,  is the affinity between the embeddings of the tiles  and .

Observe that both adjacency matrices,  and , are non-symmetric. Indeed, they are derived by taking the -nearest neighbors of each node in the kernel matrices  and , which is an inherently non-symmetric operation. In simple words, tile  can be connected to tile , but  is not necessarly a neighbor of , meaning the induced graphs are directed. In , the authors introduce a proxy function defined for undirected graphs with symmetric adjacency matrix  and degree matrix  as

We extend this definition to directed graphs by considering a non-symmetric adjacency matrix  and a degree matrix that accounts for the number of edges entering or leaving each node. Namely, considering , where , resp. , is the diagonal matrix counting the incoming, resp. outcoming, edges, then we can refer back to eq.  to generalize the definition of  similarity between directed graphs. Given  and , as described in sec.  and , and their associated degree matrices  and , we can now quantitatively assess the amount of spatial information, or , of any CARMIL model by computing,

In table , we assess the  of the best-performing CARMIL model from the  models evaluated through nested cross-validation, see sec. . For each WSI in each dataset, we first compute the spatial adjacency matrix  with  nearest neighbors, as in sec. . Then, for all rows in table  except the first, the matrix  is computed based on the embedding vector  from the model's encoder after training, also with , see sec. . For the first row, the adjacency matrix  is based on the feature vector  generated by the feature extractor. The similarity score given by eq.  is averaged across all slides within each dataset to produce the table's values, along with the C-index mean performance of the corresponding model. In fig. , we report these same results in a scatter plot to better illustrate two important findings. First, by comparing the scores from the feature extractor to the other models on both datasets, we confirm the successful injection of  into our CARMIL models. As a side note, it is worth mentionning here that, even though  lies between 0 (indicating very dissimilar graphs) to 1 (for identical graphs), the interpolation between these extremes does not seem to evenly spread out within the interval . This would explain the small variations in our table . In fact, as evidenced in the tables of results from the original paper , most values are closer to  than . Nevertheless, for our analysis, only the relative ordering of these quantities is key in proving the enhanced spatial awareness provided by our method. Second, we try to correlate gains in performance with the amount of added  in the CARMIL model. Conclusions  such as the more spatial knowledge is incorporated, the better the model perform, are rather difficult to draw.

Consider a WSI, from which  tiles are sampled. Passing this slide to our feature extractor, we get a vector . For each tile, we compute the mean of the eucliden distance between the -dimensional features of this very tile with the features of all its  spatial nearest neighbors within the slide. This results in a vector   that accounts for how well aligned the features learnt by the feature extractor conform to the spatial arrangement of the slide. If the features exactly reflect the spatial context of each tile, the coefficients in the vector  should be fairly constant and of low magnitude. Their variations are shown in fig.~, where we superposed the underlying slide with the values of . Next, we pass these features through our CARMIL encoder at inference time, following the same procedure but using the embedding vector  -- with the same notation as before. This results in a vector . We report the coefficients in fig.~. To obtain similarly scaled heatmaps, we jointly normalize the coefficients of both matrices by their maximum value, ensuring all their coefficients range between  and . Note that both tile features  and tile embeddings  are first normalized to have magnitude , ensuring a fair comparison that mitigates high-dimensional concentration effects on vector norms. 

From fig.~, we can clearly see that the embeddings generated by the CARMIL encoder evolve smoothly in the 2d plane, resulting in a uniformly low heatmap value across the slide. In comparison, the tile features provided by the feature extractor Phikon exhibit less alignment with the spatial organization of the tiles, providing another qualitative indication of the enhanced spatial consideration in CARMIL models.