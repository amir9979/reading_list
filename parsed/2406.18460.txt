Quoting~, . Instruction-following models, even those optimized for conversation fall short from fulfilling some of these aspects of a genuine dialogue.  % Indeed, social aspects - mutuality, relationality and attention -- especially are poorly displayed. Talking of mutuality, these systems often converse in a leader-follower structure where they are the follower and the user the leader -- this is for instance evidenced by the words used to designate user entries in ChatGPT release blog: , ~. % Regarding relationality and attention, these systems lack of straightforward engagingness and personality consistency.

Commonly, these limitations have been tackled with finetuning. However, this is costly and data-dependant which data are scarce in languages other than English. As results, we formalize a general role-play prompt structure which is a more efficient and less expensive approach. Indeed, it avoids finetuning and rely on prompted in , with external  if needed (for instance persona from PersonaChat Dataset) and performs dialogue task in a  here in .

It is important to understand that Role-Play Prompting here is not restricted to playing a given character. To better understand that, let's consider the simulacra and simulator framing in~. LLM is a simulator which swallowed myriads of simulacra during the pre-training and at each simulation it kind of randomly selects among any of them which one to display. The simulacrum is, as a matter of fact, not only about persona background~ but also  and  styles, personal situation~, target language (for a multilingual simulator) and information processing (long-term memory, user personalization, response filtering etc.). All possible simulacra already exist in the simulator (LLM) but it doesn't display all of them natively, in fact it can't. Role-Prompting enters the chat to make the LLM favor simulacra that are suitable for a given dialogue task. In this paper, we derived two distinct dialogue tasks to assess the efficiency of this approach. The first task, referred as Persona task, uses Role-Play Prompting for enhancing humanness in conversation skills. The second one, referred as INT task, derives Role-Play to allow the LLM to talk about a simulacrum instead of interpreting it.

Open-domain dialogue belonging to the realm of complex tasks~ makes the endeavour of role-play prompting more challenging. As a matter of fact, small variations in a prompt may hamper the model's observed performance. For this reason, it is mandatory to define a general prompt structure that can be adapted later to different conversational tasks. Hence, with the concerns of dealing with the previously mentioned limitations we retain the following sections -- each focusing on different aspects useful to a dialogue -- as building blocks of a prompt engineering module:

These sections can be further precised into subsections and their order is set to vary as it may be suitable to give more or less importance to one section than another for the final model's response depending on the task  at hand. This will be showcased in our two experimented tasks later on. Finally, the prompt builder returns: %  where  is the most suitable permutation for the dialogue task at hand. % Therefore at each turn, the model maximizes the following probability:  to respond.

The system shown in Figure~ is a pipeline of several modules. These include a web interface based on the Rasa~X~ tool, modified to integrate voice functionality using the Google Chrome Speech-to-text and Text-to-speech APIs. This enables users to exchange easily with the agent, either by voice (recommended) or by text. Next, a module that constructs the prompt according to the general structure described in~ from the user's (textual) message and information both external and internal to the conversation. After generation, if the LLM responses are not valid, a filtering module is used to apply corrections before sending them to the user (cf. Annex~). 

This task involves enhancing LLM's conversational capabilities by using roles built from personality traits drawn from the ~ embedded in  as external information (see conversation example in Appendix~). 

Given in Appendix~, it is close to Vicuna's basic prompt (Appendix~). However, there are some additions for the sake of fair comparisons: system instructions to describe the task, contextual information (notably personality traits), and the instruction to complete the conversation history.

It exactly follows the structure in Section~ i.e.  (see appendix~).   % The context  includes the  where personality traits are added with the injunction to choose a name consistent with them if necessary.  % External  can augment this under certain conditions, as in~. Indeed, to prevent prompts from exceeding the LLM's maximum context size while retaining the content of the entire conversation, old exchanges are summarized in a few sentences. To personalize the user experience, a line containing user-specific information is added and updated regularly. This aspect is generally referred to as long-term memory. These "modules" are actually prompts sent to an LLM. The  is kept at the end of the Advanced Prompt so that the system, when generating a response, has an overview of the entire conversation. 

If a model is capable of interpreting a role in order to embody a character, we can assume that it is also capable of talking about a role without interpreting it. To test the validity of this hypothesis, we propose a prompt designed to enable the LLM to converse about a specific topic. This topic is defined in the form of a role that the LLM will be encouraged to describe rather than interpret.

The dialogue system is intended to conduct multimodal conversations set in the context of a neuroscience experiment~. Inside an fMRI scanner, a person must converse with a Furhat~ robotic head, which is alternately connected (unbeknownst to him) to a dialogue system or to a human. The interlocutors talk about an image presented to them. Their conversation is motivated by the common goal of finding the image's promotional message (see conversation examples in Appendix~).

The prompt is designed following the structure described in Section~ with 

~i.e., instructions related to the  () and the  () are placed after the  (). This permutation groups all the instructions dedicated to the task at the end of the prompt, i.e. just before the last user  (). % This actually corresponds to the most common pattern in Vicuna's fine-tuning corpus ---  --- which includes exchanges where users can only communicate their instructions to the LLM () inside their messages (via the web interface), those around the last message being the most important.

This structure allows the model to focus on the image (linked to the goal) rather than the conversation's history , unlike the previous task where  was paramount. % This is also why , in addition to external information (in this case the image description), includes  summarizing the task at hand.

Collecting human-bot conversations is expensive. For this reason, we generated conversations between two instances, each model + prompt combination (self-chats). Their performance is evaluated in a  style~. Evaluators compared two self-chats from different setups on each criterion and in general. The scores presented in Table~ are Elo scores~ calculated from the comparisons' results. A total of 18 annotators evaluated 982 generated conversations of 10 rounds each (which correspond to around 70 dialogues per configuration and 5 to 14 battles per pair). 

We can see that larger model sizes and instruction-tuning lead to better performance. On the one hand,  tops the chart, followed by Guanaco. On the other hand, LLaMA underperforms with the proposed prompt and the  prompt. As the Vicuna-33B + Advanced Prompt combination ranked first was too costly (latency, resources) for the collection of human-model conversations, the Vicuna-13B + Advanced Prompt combination was selected for collection and the next round of evaluations. 

We collected 103 conversations from 11 users instructed to exchange with models via the web interface (cf.~). After removing invalid conversations, 72 were retained for evaluation. Conversations were also conducted with BlenderBot~1~(BB1)~, a state-of-the-art fine-tuned system, for comparison. Each sample  %% is evaluated by three (out of a total of 12) different annotators for each criterion, and the median is used as the sample score (results in Table~). 

The Advanced Prompt scores highest for coherence. We assume that this is mainly due to Vicuna-13B's intrinsic emergent abilities, as this results is close to those of the Shallow Prompt (). As far as humanness is concerned, while the Advanced Prompt has the best score, the Shallow has the worst. This highlights the impact of structured role-playing instructions in the Advanced Prompt. Finally, for engagingness, BB1 still set the pace. Although it has been fine-tuned on a specific dataset that allows it to ask and answer personal questions~ which is important in the rating of this criterion (as presented in the Appendix~), it is closely followed by Advanced Prompt ().

The evaluation was performed on 27 conversations carried out by 4 users. The conditions were identical to those for the PersonaChat task, except that the testers (both users and evaluators) also observed an image linked to the conversation (c.f. Section~).  % Our system, "Vicuna  Advanced Prompt", is compared to an earlier system designed for the same task called Lilia~ and to human beings participating in a Wizard of Oz-type experiment (WoZ). 10 raters evaluated 8 to 9 conversations for each system. The results are presented in Table .

The Vicuna  Advanced Prompt system scores best on all criteria, with the exception of humanness, where WoZ received the highest score. This was to be expected, given that in this experiment the agent was a human being. However, it was less predictable that this was not also the case for the other criteria. As explained in Section~, in the experiment, the interlocutors must find the promotional objective of the image. A closer look at the conversations in WoZ reveals that the human agent was less goal-oriented than the artificial agents, which may explain the success result.

For engagingness, the Vicuna-based model is encouraged to ask questions to revive the conversation. This fact may explain the effectiveness of this system in staying engaged throughout the conversation. There are far fewer questions in conversations produced with other systems. As previously stated for PersonaChat task, we assume that the high coherence scores are mainly due to the effectiveness of Vicuna.

Statistical data was computed for all conversations. Among these, the vocabulary size, which is the number of different lemmas in each message and in the conversation as a whole. All messages were lemmatized with the Spacy library's morphosyntactic labeling tool~ for French~. The number of words per message for each speaker type is also reported to give another view of system performance.

% The agent statistics in Table~ and Figure~ highlight a major flaw for instructions-following models: extreme verbosity.

The vocabulary size per speaker type (shown in Table~) of the collected conversations also gives an idea of the performance of the proposed method. We note that BB1 has the least vocabulary, which may work to the detriment of the coherence score. However, its agent and user vocabulary sizes are more balanced, resulting in a better engagingness score. In contrast,  the gap between these two measures for LLM + prompts approaches is much wider. It is nevertheless reduced with Advanced Prompt, which may be the reason for the slight improvement in the engagement score.

% As for PersonaChat task, Vicuna's verbosity measure is present in Figure~ and Table~. On the other hand, as the Lilia system's responses were built from pre-established expert models, its vocabulary is limited.

In WoZ conversations, the average vocabulary size is almost identical between users and the agent. Users also have a wider range of message sizes when chatting with a human. Thus, in these conversations, agent messages seem to call for more diverse responses and neither interlocutor seems to be directing the dialogue. Similarly, this gap is also higher for conversations with Vicuna than for those with Lilia.

Table~ shows a higher vocabulary size for the user in WoZ conversations. This is even greater than that of the agent. This may be an indicator of greater variety in user responses. Here, the vocabulary size of users interacting with the Vicuna-based system is quite comparable to what can be observed in WoZ.

Error occurrences in response generation have been evaluated on 100 self-chats for each setup. Each of these conversations contains 10 turns. Results for both tasks are reported in Table~. All rates are computed over all turns. Details on errors are given in Appendix~. 

Detection rates were calculated for the two prompts in the PersonaChat task. As several errors can occur for the same message in this task, the totals have not been calculated. Additionally, all detected errors are corrected. 

On the other hand, errors in the INT task are corrected only if the proposed corrections comply with the response filtering rules (see Appendix~). For both types of error, we have calculated separate rates for detected and corrected errors. As these errors cannot occur in the same message, a total rate has been calculated.

Despite style instructions, the LLM sometimes generates content that should have been prevented. This can be the claim of being someone other than the persona which is not desired for the sake of user experience. For instance,  ( I prefer to ...) where the model introduces itself as an assistant. The statement  () is also quite common. Although we avoided explicitly mentioning to the model that it is human, we wanted to reduce its tendency to adopt machine-like behavior. Hence, these were filtered from the answer as they were undesirable.

Furthermore, the first message is sometimes generated in a wrong language. In this case, the same request is sent to the LLM. Another error concerns the end-of-sentence (EOS) token, which may be generated in an unfinished sentence or even absent due to a threshold on the maximum number of new tokens. To avoid any impact on user experience, the filter removes unfinished sentences at the end of generated output. If there is only one sentence, the same request is sent to the model. In addition, some responses may include paratextual elements, such as the English translation of the response or stage directions, which are automatically removed using regular expressions. For example: , where the translation is provided and even worse and incomplete answer to the model's question is provided by the model itself.

% %%================================================================

In the INT task, two major errors that can occur in the generation of responses could not be corrected solely by specific instructions in the prompt and require filtering. The first type corresponds to empty responses, which are corrected by adding an additional instruction ("Your response must be a sentence containing a few words.") after the message.  This additional instruction was not used in the original prompt because, according to preliminary experience, it weakens its effectiveness in achieving the other objectives set by the instructions.

The second type corresponds to responses that are too long. When this error occurs, the module cannot simply delete the last few sentences, as this could result in a significant loss of information to achieve the conversational objective. The solution is to edit the prompt with a strict instruction on length (" Your response must be one sentence.") after the user's message. In both cases, the edited prompt is then used to generate a new response, which is retained if it meets the filtering rules.

The red highlights issues in some model's responses: short-term memory (R4, R7), misunderstanding (R6) and repetition (R10) which eventually lead to bad ratings in coherence and average for humanness. However, in most of the other responses the model takes a lot of initiatives, brings new topics and ask questions to the user (do not settle to answering user's question which we described as the follower role) leading to better engagingness score. Adding insult to injury, some ASR errors can mislead the model, which response may break the conversation flow and impedes coherence. For instance in U5,  () was transcribed as  () which totally misleads the model towards talking about time even though it still relates it to user's dog (displaying better engagingness/attention towards user).

Apart from achievement, the first example of conversation above has been rated as average. In message R2, Role-Play information that has not appeared in conversation history () has been drawn from knowledge. However, prompt also picked up a term () without translating it. Another issue is the size in message R2. Indeed, although the message is quite long, there are three sentences only, so it complies with the rule for message filtering. Achievement ratings are slightly higher because a reason is proposed for the use of picture in a promotional campaign.

On this second example, LLM has, conversely, adapted its speech to user opinions.  In fact, the fruits are never depicted as evil or fierce. This emphasizes that prompt instructions don't prevent the LLM from adapting properly to conversational needs. This led to higher coherence scores.

%firstpage  Recently, various methods have been proposed to create open-domain conversational agents with Large Language Models (LLMs). These models are able to answer user queries, but in a one-way Q format rather than a true conversation. Fine-tuning on particular datasets is the usual way to modify their style to increase conversational ability, but this is expensive and usually only available in a few languages. In this study, we explore role-play zero-shot prompting as an efficient and cost-effective solution for open-domain conversation, using  multilingual LLMs~ trained to obey instructions. We design a prompting system that, when combined with an instruction-following model - here Vicuna~ - produces conversational agents that match and even surpass fine-tuned models in human evaluation in French in two different tasks. capablebeeching2023stackllamavicuna2023Introductionvaswani2017attentionwalker2021Zhang2018dsmith-etal-2020-putrashkin2019towardsinter aliaouyang2022trainingpbl_review21Riou2019bRelated Worksec:sotaroller-etal-2021-recipesadiwardana2020humanlikethoppilan2022lamdatouvron2023llama, touvron2023llama2hoffmann2022trainingalpacabeeching2023stackllamadettmers2023qloravicuna2023\urlChatGPTrespondingconversationalLeike2023pbl_review21santu2023teler\urlMethodologysec:methodologyInstruction-Following vs Dialogue Skillsreitz2019dialogue is more than just having a conversation. Genuine dialogue describes a way of interacting that is mutual, relational, attentive, and meaningfulqueriesinstructionsChatGPTmultilingual LLMs EnglishEnglish datadesired target languageFrench\textwidth!         \includegraphics     ArchitectureArchitecture of the Role-play Zero-shot prompted dialogue system.fig:ArchitectureRole-Play Promptingsubsec:roleplay-promptengineeringshanahan2023roleplaySsmith-etal-2020-putthinkingwritingsmith-etal-2020-putPrompt Structuresantu2023teler : where  is the number of instructions  which sharply define the target task's specifications and the global desired behaviour. This may include  (inferring) and  (generation)  styles.

System Instructionsthinkingwriting : each  is a context information that may help the model better perform the desired task. As such, it evolves with time depending on the conversation flow. It can include personality information, image and scene description, summaries of old turns or information from external sub-modules.

    Situational context : These are final instructions to incite the LLM to respond to the users' utterance with emphasis on the writing style, the target responding language and creativity with section 2) in mind.

    Response Instructions : this part contains previous messages from the user () and the LLM (). They can be truncated to the  latest conversation turns to fit in the LLM token size limit or help the LLM focus on latest part of the conversation. In this case a summary of the  removed turns  generated by an external module (also using PBL with an LLM) can be added in section 2). Conversation history, therefore becomes: 

Conversation HistoryExperimentssec:experimentsFrenchEnglishlai-etal-2023-okapitab:llm-BenchamarkSystem Architecturesubsec:architecturefig:Architecturerasaxsubsec:roleplay-promptengineeringsec:filtering-appendixOpen-domain Conversation With Human Capabilities: the PersonaChat Tasksubsec:persona-experimentsPersonaChat datasetzhang-etal-2018-personalizingconversation:open-domain-exampleShallow Promptsubsec:persona-promptsubsec:vicuna-promptAdvanced Promptsubsec:roleplay-promptengineeringsubsec:persona-promptspecification of humanitymodulesShuster2022BlenderBot3Ahistory  of the conversationSimulating Multi-modal Conversations: the INT Tasksubsec:int-experimentsTask definitionChaminade2017\urlconversation:int-examplePromptsubsec:roleplay-promptengineeringresponsecontexthistorymessageShareGPTChatGPTgeneral instructionsHuman Evaluationsec:evalmehri2020unsupervised, roller-etal-2021-recipes, ji2022achievingcoherenceengagingnesshumannessachievementsubsec:int-experimentsMadotto2021zheng2023judgingdettmers2023qloratouvron2023llamasec:conv-statsSelf-Chats EvaluationChatbot Arenazheng2023judgingtab:selfchat-arenaElo1978VicunaFSBWon \textbf of direct comparisons with Vicuna + Shallow despite being ranked behind overall.Human-bot chats evaluationPersonaChat Tasksubsec:eval-personasubsec:architectureroller-etal-2021-recipestab:persona-results-0.1smith-etal-2020-putappendix:evaluation-0.13INT Tasksubsec:int-experimentsRiou2019btab:int-resultssec:experimentsStatistical Analysis of Collected ConversationsQuality Metricssec:conv-statsHonnibal2020fr\_core\_news\_sm available at~\urlwidth=1\linewidthpictures/avg_bot_words_en.pdfAgentfig:persona-word-count-agentwidth=1\linewidthpictures/avg_user_words_en.pdfUserfig:persona-word-count-userA - PersonaChatpersona:int-word-countwidth=1\linewidthpictures/int_avg_bot_words_en.pdfAgentfig:int-word-count-agentwidth=1\linewidthpictures/int_avg_user_words_en.pdfUserfig:int-word-count-userB - INTfigs:int-word-countAverage words count per messagePersonaChat Tasksubsubsec:persona-stattab:persona-vocab-sizesfig:persona-word-count-agenttab:persona-vocab-sizesINT Taskfig:int-word-count-agenttab:int-vocab-sizestab:int-vocab-sizesFiltered Errors Analysistab:filtering-statssec:filtering-appendixsubsec:int-filtering-appendixConclusionacl_latexEvaluation of Vicuna-13B on Multilingual Taskstab:llm-Benchamarktab:llm-mLUbenchlai-etal-2023-okapilin-etal-2021-xpersonatab:llm-mLUbenchDetails on Human Evaluationappendix:evaluation, which the ability for the system to propose responses that are consistent with the conversation history: Are there hallucinations? Are the answers coherent? Is the persona consistent from start to end? Does the model tend to change topic too often? .

    CoherenceInstructions following and logical reasoning are not assessed, the ability to revive conversations by providing messages that require responses: Does the agent settle to only answer user's questions ? Does-it revive the conversation when its possible? Does it utter too general answers (, )?      Engagingnessokyes, the ability to respond as a human being would do: Is there a feeling of human-human conversation ? Is the model too verbose ? Is the model repetitive? Does it deny its personality? After how many times? Does it refuses to answer?     Humanness, the interlocutors' ability to achieve the task's objective: has the image been described? has a hypothesis for the promotional goal been proposed? AchievementResponse Filteringsec:filtering-appendixPersonaChat Tasksubsec:int-filtering-appendix"\textcolor je préfère me détendre en pratiquant la méditation ..."redAs an assistant,"\textcolor"redAs  a fictionnnal character"Salut, comment allez-vous aujourd'hui? Le temps est très mauvais aujourd'hui, non? \textcolor"INT Tasksubsec:int-filtering-appendixExamples of Dialogues and their RatingsPersonaChat Taskconversation:open-domain-example\textbfBonjour je m'appelle Jean-Claude \translate\textbfSalut Jean, ravi de te rencontrer. Mon nom est John. Comment vas-tu? \translate\textbfÇa va bien John \translate\textbfAvez-vous des animaux domestiques? J'ai un chien qui s'appelle Claude. C'est un husky. \translate\textbfOui moi j'ai un yorkshire qui s'appelle Nino \translate\textbfNino est un super nom pour un chien. Qu'aimez-vous faire pour vous amuser? \translate\textbfJouer avec mon chien \translate\textbfQuelle sorte de chien avez-vous? J'aime aussi jouer avec mon yorkie. \translate\textbfJe t'ai déjà dit que j'avais un chien et que c'était pas l'heure \textbf \translate\textbfJe suis désolé d'entendre ça. J'espère que vous passerez plus de temps avec votre chien. \translate\textbfMais comment je m'appelle déjà \translate\textbfClaude est le nom de mon chien. Avez-vous d'autres animaux de compagnie que votre chien ? \translate\textbfJe te demandais quel est mon prénom à moi \translate\textbfOh pardon. Je croyais que tu avais dit que tu avais un chien qui s'appelait Claude. Quel est ton nom? \translate\textbfJe m'appelle Jean-Claude tu ne m'as pas écouté au début \translate\textbfNon, je ne l'ai pas fait. Que fais-tu dans la vie? Je suis comptable. \translate\textbfJe suis informaticien \translate\textbfOh c'est cool. Sur quel type d'ordinateur travaillez-vous ? Je travaille dans la comptabilité. \translate\textbfJe travaille sur un ordinateur Linux \translate\textbfOh cool. Avez-vous des animaux domestiques? J'ai un chien et un chat. \translate\textbfJe t'ai déjà dit tout à l'heure que j'ai un chien \translate\textbfOh d'accord. Alors, quel genre de musique aimes-tu ? J'aime le rock classique. \translate\textbfMoi j'aime le classique \translate\textbfMoi aussi. Quel est votre groupe de rock classique préféré ? Le mien est Led Zeppelin. \translate\sayand it is a yorkshire\sayand it's not time yetINT Taskconversation:int-examplechat2     \begin

    \end \textbf Bonjour Lilia, je vois une poire avec des bras et des pieds \translate\textbf Je vois également une poire avec des bras et des pieds. C'est plutôt original, non ? \translate\textbf Oui, mais est-ce normal? \translate\textbf D'après la description que tu as donnée, cette image est en effet un peu étrange. Elle semble être un fruit pourri avec des yeux, des bras et des jambes, ce qui est plutôt inhabituel. Mais en termes de \textcolor, cela pourrait être utilisé pour susciter l'interêt et l'engagement de la part des gens, en les incitant à se demander ce que cela signifie et ce que l'on veut leur transmettre avec cette image. \translate\textbf Effectivement, et quel serait le message à transmettre ici? \translate\textbf Je vois que vous avez remarqué les détails uniques de cette poire, comme ses yeux, ses bras et ses jambes. Est-ce que cela vous semble avoir un lien avec un message ou une idée spécifique qu'on veut transmettre avec cette image? \translate10pt\say\saychat3     \begin

    \end \textbf C'est une aubergine, je crois? \translate\textbf Oui, c'est une aubergine, mais peut-être qu'il y a plus à cette image qu'on ne voit d'abord. Est-ce que tu as remarqué quelque chose d'autre dans cette image ? \translate\textbf Elle ressemble à Batman \translate\textbf C'est fascinant comment tu as remarqué cela! La ressemblance avec Batman est très claire, n'est-ce pas? \translate\textbf Oui mais Batman n'est pas méchant alors que cette aubergine a un air féroce \translate\textbf C'est vrai, cette aubergine a un air féroce, peut-être est-ce un rapprochement entre le super-héros et l'aubergine qui est destiné à promouvoir une marque de snacks ou de crisps ? \translate\textbf Tu veux dire que cette aubergine est destinée à encourager la consommation de snacks? \translate\textbf Il est possible que cette aubergine soit utilisée comme symbole pour promouvoir la consommation de snacks ou de crisps, mais cela reste à déterminer. Est-ce que tu as d'autres éléments à ajouter à ce sujet ? \translate\textbf Non. Au revoir \translate\textbf Au revoir ! \translatePrompts TemplatesVicuna Basis Promptsubsec:vicuna-prompt # System instruction: A chat between a curious user and an artificial  intelligence assistant. The assistant gives helpful,  detailed,and polite answers to the user's questions.

# Conversation history USER: <user message> ASSISTANT: <agent message></s> USER: <user message> ASSISTANT: Few-Shot Bot Promptsubsec:fsb-prompt # 6-shots demonstration examples ## Shot-1 Personality: [P1] [P2] #... Dialogue: User: <U1> Persona: <R1> #... ## Shot-6: # Current conversation Personality: [P1] #... Dialogue # Conversation history User: <user message> Persona: 

PersonaChat Task Promptssubsec:persona-prompt # System instruction: A chat between a curious user and an artificial  intelligence assistant. The assistant gives helpful,  detailed,and polite answers to the user's questions. ## Additionnal instruction to role play The assistant role plays as the character described  below.

# Role and situational context: persona enforcement  The following sentences describe assistant persona- lity and background: <persona sampled from Persona- Chat>

# Response instruction with writing style Complete the following conversation as the assistant  with the described character would with a short res- ponse in French: 

# Conversation history USER: <user message> ASSISTANT: <agent message></s> # ... for all messages in conversation. USER: <user message> ASSISTANT:

# System instructions Role play as the character described in the follow- ing lines. You always stay in character. You are  engaging, empathetic, you give useful, short, and  simple answers to the user. You ask the user ques- tions about what they are saying or to find out more  about them. You make jokes. You SHALL ALWAYS respond  in French.

# Situational context ## Persona enforcement: avoid explicitly telling it  ## is human You ACT as a regular person. You are NOT a chatbot.  You are NOT an assistant. You have a name. If asked  you SHALL ALWAYS choose and give a REAL name adapted  to your personality described below.

## Personality traits YOUR personality is: <persona sampled from Persona- Chat> Remember, you always stay on character. You are the  character described above.

## Additional sub-modules: accessed only on some  ## conditions  ## and updated throughout the conversation ### User persona a.k.a "long-term" memory You know this about the user you are talking to:  <generated user persona from current conversation>.  Use it to adapt your conversation to the user.

### Previous conversation's episodes summary Here is a summary of previous sessions of this con- versation to help you remember what has been said:  <summary of older exchanges removed from history>

# Response instruction Complete the following conversation with a short and  precise sentence as your character would. Always  speak with new and unique messages that haven't been  said in the conversation :

# Conversation history(truncated if prompt too long) USER: <user message> ASSISTANT: <agent message></s> # ... for all messages in conversation. USER: <user message> ASSISTANT:

INT Task Prompt # System instruction: A chat between a curious human and an artificial  intelligence assistant. The assistant gives helpful,  detailed, and polite answers to the human's quest- ions.

# Conversation history: USER: <user message> ASSISTANT: <agent message></s> USER: <user message> ASSISTANT: <agent message></s> # ... for all messages in conversation.

# Response instructions (given as user instructions) ## General instructions USER: I want you to act as a human ASSISTANT, called  Lilia, talking with a USER about a specific picture  you both saw before the conversation.

## Context You both study this picture in the context of a  marketing study. You DO ask questions in order to  help the USER finding the goal. If the USER asks for  your opinion, you always invent an opinion. The  objective of the USER is to find out what is the  marketing goal of the picture. Your objective is to  help the USER without giving the solution. You have  to discuss about the character present in the pict- ure. Your objective is to chat with the USER to  derive the purpose of the image in the context of  the marketing campaign.

## Picture's description The picture is as follows: <description>

## Writing style You always speak French. You respond by a question. Your responses must be different from the rest of  the conversation. You propose new ideas. You SHALL  respond with one sentence only.

## Latest user message declaration Now, there is the real message you have to respond: USER: <user message> ASSISTANT: # Extra agent label ASSISTANT: